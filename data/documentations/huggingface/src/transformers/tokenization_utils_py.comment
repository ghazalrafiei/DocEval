['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2020 The HuggingFace Inc. team.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' Slow tokenizers are saved in a vocabulary plus three separated files','line_number':46,'multiline':False]
['text':' Prevent empty string','line_number':83,'multiline':False]
['text':' indexes are counted left of the chars index.','line_number':114,'multiline':False]
['text':' "hello", index 0, is left of h, index 1 is between h and e.','line_number':115,'multiline':False]
['text':' index 5 is right of the "o".','line_number':116,'multiline':False]
['text':' States are going to capture every possible start (indexes as above)','line_number':118,'multiline':False]
['text':' as keys, and have as values, a pointer to the position in the trie','line_number':119,'multiline':False]
['text':' where we're at. This is a partial match for now.','line_number':120,'multiline':False]
['text':' This enables to keep track of multiple matches while we're iterating','line_number':121,'multiline':False]
['text':' the string','line_number':122,'multiline':False]
['text':' If the trie contains, "blowing", and "lower" and we encounter the','line_number':123,'multiline':False]
['text':' string "blower", we need to split into ["b", "lower"].','line_number':124,'multiline':False]
['text':' This is where we need to keep track of multiple possible starts.','line_number':125,'multiline':False]
['text':' This will contain every indices where we need','line_number':128,'multiline':False]
['text':' to cut.','line_number':129,'multiline':False]
['text':' We force to cut at offset 0 and len(text) (added later)','line_number':130,'multiline':False]
['text':' This is used by the lookahead which needs to skip over','line_number':133,'multiline':False]
['text':' some text where the full match exceeded the place in the initial','line_number':134,'multiline':False]
['text':' for loop','line_number':135,'multiline':False]
['text':' Main loop, Giving this algorithm O(n) complexity','line_number':137,'multiline':False]
['text':' Prevents the lookahead for matching twice','line_number':140,'multiline':False]
['text':' like extra_id_100 and id_100','line_number':141,'multiline':False]
['text':' This will track every state','line_number':144,'multiline':False]
['text':' that stop matching, we need to stop tracking them.','line_number':145,'multiline':False]
['text':' If we look at "lowball", we're going to match "l" (add it to states), "o", "w", then','line_number':146,'multiline':False]
['text':' fail on "b", we need to remove 0 from the valid states.','line_number':147,'multiline':False]
['text':' Whenever we found a match, we need to drop everything','line_number':149,'multiline':False]
['text':' this is a greedy algorithm, it will match on the first found token','line_number':150,'multiline':False]
['text':' In this case, we already have partial matches (But unfinished)','line_number':153,'multiline':False]
['text':' This is a final match, we need to reset and','line_number':156,'multiline':False]
['text':' store the results in `offsets`.','line_number':157,'multiline':False]
['text':' Lookahead to match longest first','line_number':159,'multiline':False]
['text':' Important in case of extra_id_1 vs extra_id_100','line_number':160,'multiline':False]
['text':' Here we are also actively looking for other earlier partial','line_number':161,'multiline':False]
['text':' matches','line_number':162,'multiline':False]
['text':' "[CLS]", "L", we need to match CLS even if L is special','line_number':163,'multiline':False]
['text':' This partial match is later, we can stop looking','line_number':166,'multiline':False]
['text':' This partial match is earlier, the trie pointer','line_number':169,'multiline':False]
['text':' was already updated, so index is + 1','line_number':170,'multiline':False]
['text':' Here lookstart == start and','line_number':174,'multiline':False]
['text':'      looktrie_pointer == trie_pointer','line_number':175,'multiline':False]
['text':' It wasn't updated yet so indices are current ones','line_number':176,'multiline':False]
['text':' End of string','line_number':194,'multiline':False]
['text':' End lookahead','line_number':197,'multiline':False]
['text':' Storing and resetting','line_number':199,'multiline':False]
['text':' The current character being looked at has a match within the trie','line_number':205,'multiline':False]
['text':' update the pointer (it will be stored back into states later).','line_number':206,'multiline':False]
['text':' Storing back the new pointer into the states.','line_number':209,'multiline':False]
['text':' Partial matches got longer by one.','line_number':210,'multiline':False]
['text':' The new character has not match in the trie, we need','line_number':213,'multiline':False]
['text':' to stop keeping track of this partial match.','line_number':214,'multiline':False]
['text':' We can't do it directly within the loop because of how','line_number':215,'multiline':False]
['text':' python iteration works','line_number':216,'multiline':False]
['text':' Either clearing the full start (we found a real match)','line_number':219,'multiline':False]
['text':' Or clearing only the partial matches that didn't work.','line_number':220,'multiline':False]
['text':' If this character is a starting character within the trie','line_number':227,'multiline':False]
['text':' start keeping track of this partial match.','line_number':228,'multiline':False]
['text':' We have a cut at the end with states.','line_number':232,'multiline':False]
['text':' This is a final match, we need to reset and','line_number':235,'multiline':False]
['text':' store the results in `offsets`.','line_number':236,'multiline':False]
['text':' Longest cut is always the one with lower start so the first','line_number':240,'multiline':False]
['text':' item so we need to break.','line_number':241,'multiline':False]
['text':' We have all the offsets now, we just need to do the actual splitting.','line_number':247,'multiline':False]
['text':' We need to eventually add the first part of the string and the eventual','line_number':248,'multiline':False]
['text':' last part.','line_number':249,'multiline':False]
['text':' This might happen if there's a match at index 0','line_number':261,'multiline':False]
['text':' we're also preventing zero-width cuts in case of two','line_number':262,'multiline':False]
['text':' consecutive matches','line_number':263,'multiline':False]
['text':' \t, \n, and \r are technically control characters but we treat them','line_number':273,'multiline':False]
['text':' as whitespace since they are generally considered as such.','line_number':274,'multiline':False]
['text':' These are technically control characters but we count them as whitespace','line_number':285,'multiline':False]
['text':' characters.','line_number':286,'multiline':False]
['text':' We treat all non-letter/number ASCII as punctuation.','line_number':298,'multiline':False]
['text':' Characters such as "^", "$", and "`" are not in the Unicode','line_number':299,'multiline':False]
['text':' Punctuation class but we treat them as punctuation anyways, for','line_number':300,'multiline':False]
['text':' consistency.','line_number':301,'multiline':False]
['text':' Checks if new_token is already in the ordered token_list','line_number':327,'multiline':False]
['text':' new_token is in token_list, don't add','line_number':329,'multiline':False]
['text':' 1. Init the parent class','line_number':350,'multiline':False]
['text':' 2. init `_added_tokens_decoder` if child class did not','line_number':354,'multiline':False]
['text':' 3. if a `added_tokens_decoder` is passed, we are loading from a saved tokenizer, we overwrite','line_number':358,'multiline':False]
['text':' 4 init the parent class','line_number':362,'multiline':False]
['text':' 4. If some of the special tokens are not part of the vocab, we add them, at the end.','line_number':365,'multiline':False]
['text':' the order of addition is the same as self.SPECIAL_TOKENS_ATTRIBUTES following `tokenizers`','line_number':366,'multiline':False]
['text':' Always raise an error if string because users should define the behavior','line_number':405,'multiline':False]
['text':' TODO this is fairly slow to improve!','line_number':466,'multiline':False]
['text':' only call this once, len gives the last index + 1','line_number':468,'multiline':False]
['text':' very important for fast and slow equivalence!','line_number':478,'multiline':False]
['text':' doing token.special=True changes the normalization! will fix in rust','line_number':484,'multiline':False]
['text':' this is important and the only reason why the AddedTokens in each class are normalized by default','line_number':485,'multiline':False]
['text':' Normalize if requested','line_number':490,'multiline':False]
['text':' the setter automatically updates the reverse map','line_number':501,'multiline':False]
['text':' convert non-special tokens to lowercase. Might be super slow as well?','line_number':565,'multiline':False]
['text':' don't split on any of the added tokens','line_number':579,'multiline':False]
['text':' "This is something<special_token_1>  else"','line_number':580,'multiline':False]
['text':' ["This is something", "<special_token_1>", "  else"]','line_number':583,'multiline':False]
['text':' A bit counter-intuitive but we strip the left of the string','line_number':591,'multiline':False]
['text':' since tok_extended.rstrip means the special token is eating all white spaces on its right','line_number':592,'multiline':False]
['text':' Strip white spaces on the left','line_number':594,'multiline':False]
['text':' Opposite here','line_number':596,'multiline':False]
['text':' ["This is something", "<special_token_1>", "else"]','line_number':608,'multiline':False]
['text':' Need to skip eventual empty (fully stripped) tokens','line_number':611,'multiline':False]
['text':' ["This", " is", " something", "<special_token_1>", "else"]','line_number':618,'multiline':False]
['text':' we pad in batch afterward','line_number':859,'multiline':False]
['text':' we pad in batch afterward','line_number':863,'multiline':False]
['text':' we pad in batch afterward','line_number':864,'multiline':False]
['text':' We convert the whole batch to tensors at the end','line_number':869,'multiline':False]
['text':' To avoid mixing byte-level and unicode for byte-level BPT','line_number':1005,'multiline':False]
['text':' we need to build string separately for added tokens and byte-level tokens','line_number':1006,'multiline':False]
['text':' cf. https://github.com/huggingface/transformers/issues/1133','line_number':1007,'multiline':False]
['text':' TODO @ArthurZ in version 5, special tokens should be handled in convert_tokens_to_string, while _convert_tokens_to_string','line_number':1010,'multiline':False]
