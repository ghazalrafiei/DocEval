['text':' Prefix text to help Transformer-XL and XLNet with short prompts as proposed by Aman Rusia','line_number':55,'multiline':False]
['text':' in https://github.com/rusiaaman/XLNet-gen#methodology','line_number':56,'multiline':False]
['text':' and https://medium.com/@amanrusia/xlnet-speaks-comparison-to-gpt-2-ea1a4e9ba39e','line_number':57,'multiline':False]
['text':' This is very specific. The logic is quite complex and needs to be done','line_number':75,'multiline':False]
['text':' as a "default".','line_number':76,'multiline':False]
['text':' It also defines both some preprocess_kwargs and generate_kwargs','line_number':77,'multiline':False]
['text':' which is why we cannot put them in their respective methods.','line_number':78,'multiline':False]
['text':' For XLNet and TransformerXL we add an article to the prompt to give more state to the model.','line_number':88,'multiline':False]
['text':' Recalculate some generate_kwargs linked to prefix.','line_number':91,'multiline':False]
['text':' overriding _parse_and_tokenize to allow for unusual language-modeling tokenizer arguments','line_number':156,'multiline':False]
['text':' Parse arguments','line_number':161,'multiline':False]
['text':' Allow empty prompts','line_number':243,'multiline':False]
['text':' If there is a prefix, we may need to adjust the generation length. Do so without permanently modifying','line_number':252,'multiline':False]
['text':' generate_kwargs, as some of the parameterization may come from the initialization of the pipeline.','line_number':253,'multiline':False]
['text':' BS x SL','line_number':270,'multiline':False]
['text':' Decode text','line_number':289,'multiline':False]
['text':' Remove PADDING prompt of the sequence if XLNet or Transfo-XL model is used','line_number':296,'multiline':False]
