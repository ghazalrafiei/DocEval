['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2023 The HuggingFace Inc. team.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' Prepare the number of candidate tokens','line_number':100,'multiline':False]
['text':' Prepare the kwargs for the assistant model','line_number':111,'multiline':False]
['text':' deepcopy crashes if we attempt to copy encoder outputs with grads','line_number':113,'multiline':False]
['text':' Prepare assistant model's keys of inputs','line_number':130,'multiline':False]
['text':' both are encoder-decoder','line_number':132,'multiline':False]
['text':' special case for encoder-decoder with decoder-only assistant (like DistilWhisper)','line_number':136,'multiline':False]
['text':' both are decoder-only','line_number':144,'multiline':False]
['text':' Prepare other attributes','line_number':148,'multiline':False]
['text':' 1. If it is not the first round of candidate generation, prepare the inputs based on the input_ids length','line_number':169,'multiline':False]
['text':' (which implicitly contains the number of accepted candidates from the previous round)','line_number':170,'multiline':False]
['text':' the assistant does not have the token after the last match, hence the -1','line_number':178,'multiline':False]
['text':' 2. Forecast next N tokens using the assistant model.','line_number':185,'multiline':False]
['text':' 3. Update variables for the next round of candidate generation','line_number':196,'multiline':False]
['text':' 4. Prepare variables for output','line_number':199,'multiline':False]
['text':' Adjust the max number of assistant tokens to use in the next iteration. This is a simple heuristic,','line_number':217,'multiline':False]
['text':' probably can be improved -- we want to balance the benefits of getting assistant tokens correct with the','line_number':218,'multiline':False]
['text':' cost of forecasting incorrect assistant tokens.','line_number':219,'multiline':False]
['text':' bloom is special','line_number':241,'multiline':False]
['text':' gptbigcode is too','line_number':253,'multiline':False]
