['text':' Copyright 2020 The HuggingFace Team. All rights reserved.','line_number':1,'multiline':False]
['text':'','line_number':2,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':3,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':4,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':5,'multiline':False]
['text':'','line_number':6,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':7,'multiline':False]
['text':'','line_number':8,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':9,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':10,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':11,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':12,'multiline':False]
['text':' limitations under the License.','line_number':13,'multiline':False]
['text':' If either is no-answer, then F1 is 1 if they agree, 0 otherwise','line_number':73,'multiline':False]
['text':' For unanswerable questions, only correct answer is empty string','line_number':95,'multiline':False]
['text':' When we created the data, we kept track of the alignment between original','line_number':258,'multiline':False]
['text':' (whitespace tokenized) tokens and our WordPiece tokenized tokens. So','line_number':259,'multiline':False]
['text':' now `orig_text` contains the span of our original text corresponding to the','line_number':260,'multiline':False]
['text':' span that we predicted.','line_number':261,'multiline':False]
['text':'','line_number':262,'multiline':False]
['text':' However, `orig_text` may contain extra characters that we don't want in','line_number':263,'multiline':False]
['text':' our prediction.','line_number':264,'multiline':False]
['text':'','line_number':265,'multiline':False]
['text':' For example, let's say:','line_number':266,'multiline':False]
['text':'   pred_text = steve smith','line_number':267,'multiline':False]
['text':'   orig_text = Steve Smith's','line_number':268,'multiline':False]
['text':'','line_number':269,'multiline':False]
['text':' We don't want to return `orig_text` because it contains the extra "'s".','line_number':270,'multiline':False]
['text':'','line_number':271,'multiline':False]
['text':' We don't want to return `pred_text` because it's already been normalized','line_number':272,'multiline':False]
['text':' (the SQuAD eval script also does punctuation stripping/lower casing but','line_number':273,'multiline':False]
['text':' our tokenizer does additional normalization like stripping accent','line_number':274,'multiline':False]
['text':' characters).','line_number':275,'multiline':False]
['text':'','line_number':276,'multiline':False]
['text':' What we really want to return is "Steve Smith".','line_number':277,'multiline':False]
['text':'','line_number':278,'multiline':False]
['text':' Therefore, we have to apply a semi-complicated alignment heuristic between','line_number':279,'multiline':False]
['text':' `pred_text` and `orig_text` to get a character-to-character alignment. This','line_number':280,'multiline':False]
['text':' can fail in certain cases in which case we just return `orig_text`.','line_number':281,'multiline':False]
['text':' We first tokenize `orig_text`, strip whitespace from the result','line_number':294,'multiline':False]
['text':' and `pred_text`, and check if they are the same length. If they are','line_number':295,'multiline':False]
['text':' NOT the same length, the heuristic has failed. If they are the same','line_number':296,'multiline':False]
['text':' length, we assume the characters are one-to-one aligned.','line_number':297,'multiline':False]
['text':' We then project the characters in `pred_text` back to `orig_text` using','line_number':317,'multiline':False]
['text':' the character-to-character alignment.','line_number':318,'multiline':False]
['text':' pylint: disable=invalid-name','line_number':415,'multiline':False]
['text':' keep track of the minimum score of null start+end of position 0','line_number':427,'multiline':False]
['text':' large and positive','line_number':428,'multiline':False]
['text':' the paragraph slice with min null score','line_number':429,'multiline':False]
['text':' the start logit at the slice with min null score','line_number':430,'multiline':False]
['text':' the end logit at the slice with min null score','line_number':431,'multiline':False]
['text':' if we could have irrelevant answers, get the min score of irrelevant','line_number':436,'multiline':False]
['text':' We could hypothetically create invalid predictions, e.g., predict','line_number':446,'multiline':False]
['text':' that the start of the span is in the question. We throw out all','line_number':447,'multiline':False]
['text':' invalid predictions.','line_number':448,'multiline':False]
['text':' pylint: disable=invalid-name','line_number':485,'multiline':False]
['text':' this is a non-null prediction','line_number':495,'multiline':False]
['text':' tok_text = " ".join(tok_tokens)','line_number':503,'multiline':False]
['text':'','line_number':504,'multiline':False]
['text':' # De-tokenize WordPieces that have been split off.','line_number':505,'multiline':False]
['text':' tok_text = tok_text.replace(" ##", "")','line_number':506,'multiline':False]
['text':' tok_text = tok_text.replace("##", "")','line_number':507,'multiline':False]
['text':' Clean whitespace','line_number':509,'multiline':False]
['text':' if we didn't include the empty option in the n-best, include it','line_number':524,'multiline':False]
['text':' In very rare edge cases we could only have single null prediction.','line_number':529,'multiline':False]
['text':' So we just create a nonce prediction in this case to avoid failure.','line_number':530,'multiline':False]
['text':' In very rare edge cases we could have no valid predictions. So we','line_number':534,'multiline':False]
['text':' just create a nonce prediction in this case to avoid failure.','line_number':535,'multiline':False]
['text':' predict "" iff the null score - the score of best non-null > threshold','line_number':567,'multiline':False]
['text':' pylint: disable=invalid-name','line_number':612,'multiline':False]
['text':' pylint: disable=invalid-name','line_number':616,'multiline':False]
['text':' keep track of the minimum score of null start+end of position 0','line_number':638,'multiline':False]
['text':' large and positive','line_number':639,'multiline':False]
['text':' if we could have irrelevant answers, get the min score of irrelevant','line_number':646,'multiline':False]
['text':' We could hypothetically create invalid predictions, e.g., predict','line_number':659,'multiline':False]
['text':' that the start of the span is in the question. We throw out all','line_number':660,'multiline':False]
['text':' invalid predictions.','line_number':661,'multiline':False]
['text':' XLNet un-tokenizer','line_number':696,'multiline':False]
['text':' Let's keep it simple for now and see if we need all this later.','line_number':697,'multiline':False]
['text':'','line_number':698,'multiline':False]
['text':' tok_start_to_orig_index = feature.tok_start_to_orig_index','line_number':699,'multiline':False]
['text':' tok_end_to_orig_index = feature.tok_end_to_orig_index','line_number':700,'multiline':False]
['text':' start_orig_pos = tok_start_to_orig_index[pred.start_index]','line_number':701,'multiline':False]
['text':' end_orig_pos = tok_end_to_orig_index[pred.end_index]','line_number':702,'multiline':False]
['text':' paragraph_text = example.paragraph_text','line_number':703,'multiline':False]
['text':' final_text = paragraph_text[start_orig_pos: end_orig_pos + 1].strip()','line_number':704,'multiline':False]
['text':' Previously used Bert untokenizer','line_number':706,'multiline':False]
['text':' Clean whitespace','line_number':713,'multiline':False]
['text':' In very rare edge cases we could have no valid predictions. So we','line_number':734,'multiline':False]
['text':' just create a nonce prediction in this case to avoid failure.','line_number':735,'multiline':False]
['text':' note(zhiliny): always predict best_non_null_entry','line_number':764,'multiline':False]
['text':' and the evaluation script will search for the best threshold','line_number':765,'multiline':False]
