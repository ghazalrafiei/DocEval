['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2023 MURGe-Lab and The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' See all TVLT models at https://huggingface.co/ZinengTang/tvlt-base','line_number':50,'multiline':False]
['text':' noise in [0, 1]','line_number':156,'multiline':False]
['text':' noise in [0, 1]','line_number':172,'multiline':False]
['text':' noise in [0, 1]','line_number':174,'multiline':False]
['text':' sort noise for each sample','line_number':187,'multiline':False]
['text':' ascend: small is keep, large is remove','line_number':188,'multiline':False]
['text':' keep the first subset','line_number':191,'multiline':False]
['text':' generate the binary mask: 0 is keep, 1 is remove','line_number':195,'multiline':False]
['text':' unshuffle to get the binary mask','line_number':198,'multiline':False]
['text':' create patch embeddings','line_number':224,'multiline':False]
['text':' create patch embeddings','line_number':253,'multiline':False]
['text':' Copied from transformers.models.vilt.modeling_vilt.ViltSelfAttention with Vilt->Tvlt','line_number':349,'multiline':False]
['text':' Take the dot product between "query" and "key" to get the raw attention scores.','line_number':381,'multiline':False]
['text':' Apply the attention mask is (precomputed for all layers in BertModel forward() function)','line_number':385,'multiline':False]
['text':' Normalize the attention scores to probabilities.','line_number':388,'multiline':False]
['text':' This is actually dropping out entire tokens to attend to, which might','line_number':391,'multiline':False]
['text':' seem a bit unusual, but is taken from the original Transformer paper.','line_number':392,'multiline':False]
['text':' Mask heads if we want to','line_number':395,'multiline':False]
['text':' Copied from transformers.models.vilt.modeling_vilt.ViltSelfOutput with Vilt->Tvlt','line_number':410,'multiline':False]
['text':' Copied from transformers.models.vilt.modeling_vilt.ViltAttention with Vilt->Tvlt','line_number':429,'multiline':False]
['text':' Prune linear layers','line_number':444,'multiline':False]
['text':' Update hyper params and store pruned heads','line_number':450,'multiline':False]
['text':' add attentions if we output them','line_number':460,'multiline':False]
['text':' Copied from transformers.models.vilt.modeling_vilt.ViltIntermediate with Vilt->Tvlt','line_number':464,'multiline':False]
['text':' Copied from transformers.models.vilt.modeling_vilt.ViltOutput with Vilt->Tvlt','line_number':481,'multiline':False]
['text':' Copied from transformers.models.vilt.modeling_vilt.ViltLayer with Vilt->Tvlt','line_number':497,'multiline':False]
['text':' in ViLT, layernorm is applied before self-attention','line_number':513,'multiline':False]
['text':' add self attentions if we output attention weights','line_number':519,'multiline':False]
['text':' first residual connection','line_number':521,'multiline':False]
['text':' in ViLT, layernorm is also applied after self-attention','line_number':524,'multiline':False]
['text':' second residual connection is done here','line_number':528,'multiline':False]
['text':' Copied from transformers.models.vilt.modeling_vilt.ViltEncoder with Vilt->Tvlt','line_number':536,'multiline':False]
['text':' Slightly different from the TF version which uses truncated_normal for initialization','line_number':604,'multiline':False]
['text':' cf https://github.com/pytorch/pytorch/pull/5617','line_number':605,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':690,'multiline':False]
['text':' Mask pixel if mask_pixel is True','line_number':751,'multiline':False]
['text':' Mask audio if mask_audio is True','line_number':765,'multiline':False]
['text':' Prepare for encoder inputs and attention masks','line_number':784,'multiline':False]
['text':' apply Transformer layers (blocks)','line_number':862,'multiline':False]
['text':' predictor projection','line_number':887,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':951,'multiline':False]
['text':' [batch_size, pixel_pixel_length], mean loss per patch','line_number':1012,'multiline':False]
['text':' mean loss on removed patches','line_number':1013,'multiline':False]
['text':' [batch_size, audio_pixel_length], mean loss per patch','line_number':1019,'multiline':False]
['text':' mean loss on removed patches','line_number':1020,'multiline':False]
['text':' unshuffle','line_number':1029,'multiline':False]
['text':' [batch_size, num_masked_pixel_patches, decoder_hidden_size]','line_number':1130,'multiline':False]
['text':' [batch_size, num_masked_audio_patches, decoder_hidden_size]','line_number':1133,'multiline':False]
['text':' Classifier head','line_number':1221,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1230,'multiline':False]
['text':' rank value','line_number':1281,'multiline':False]
