['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2022 Meta Platforms, Inc. and The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' proxy the call to the internal dictionary','line_number':82,'multiline':False]
['text':' We will verify our results on an image of cute cats','line_number':86,'multiline':False]
['text':' load config from file and command-line arguments','line_number':102,'multiline':False]
['text':' src, dst','line_number':239,'multiline':False]
['text':' now we need to handle the attentions','line_number':254,'multiline':False]
['text':' read in weights + bias of input projection layer of cross-attention','line_number':255,'multiline':False]
['text':' let's pop them','line_number':283,'multiline':False]
['text':' proj','line_number':286,'multiline':False]
['text':' second norm','line_number':300,'multiline':False]
['text':' mlp','line_number':314,'multiline':False]
['text':' patch merging','line_number':346,'multiline':False]
['text':' hidden states norms','line_number':364,'multiline':False]
['text':' src, dst','line_number':396,'multiline':False]
['text':' now we need to handle the attentions','line_number':411,'multiline':False]
['text':' read in weights + bias of input projection layer of cross-attention','line_number':412,'multiline':False]
['text':' let's pop them','line_number':440,'multiline':False]
['text':' proj','line_number':443,'multiline':False]
['text':' second norm','line_number':457,'multiline':False]
['text':' mlp','line_number':471,'multiline':False]
['text':' patch merging','line_number':503,'multiline':False]
['text':' hidden states norms','line_number':521,'multiline':False]
['text':' Backbone + Pixel Decoder','line_number':536,'multiline':False]
['text':' convolution layer for final features','line_number':576,'multiline':False]
['text':' proj layers','line_number':591,'multiline':False]
['text':' layers','line_number':603,'multiline':False]
['text':' proj','line_number':611,'multiline':False]
['text':' Transformer Decoder','line_number':620,'multiline':False]
['text':' add more','line_number':724,'multiline':False]
['text':' read in weights + bias of input projection layer of self-attention','line_number':753,'multiline':False]
['text':' next, add query, keys and values (in that order) to the state dict','line_number':760,'multiline':False]
['text':' find associated config file','line_number':829,'multiline':False]
['text':' dataset_name e.g 'coco'','line_number':831,'multiline':False]
['text':' task type e.g 'instance-segmentation'','line_number':836,'multiline':False]
['text':' config file corresponding to checkpoint','line_number':839,'multiline':False]
['text':' Test backbone','line_number':862,'multiline':False]
['text':' Test pixel decoder','line_number':870,'multiline':False]
['text':' Let's test the full model','line_number':882,'multiline':False]
['text':' modify original Mask2Former code to return mask and class logits','line_number':888,'multiline':False]
['text':' model_name_raw is something like maskformer2_swin_small_bs16_50ep','line_number':908,'multiline':False]
['text':' `segmentation_task_type` must be one of the following: `instance-segmentation`, `panoptic-segmentation`, `semantic-segmentation`','line_number':911,'multiline':False]
['text':' dataset name must be one of the following: `coco`, `ade`, `cityscapes`, `mapillary-vistas`','line_number':919,'multiline':False]
['text':' append the path to the parents to mask2former dir','line_number':972,'multiline':False]
['text':' import original Mask2Former config and model from original source code repo','line_number':974,'multiline':False]
