['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2022 Microsoft Research Asia and The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' See all Conditional DETR models at https://huggingface.co/models?filter=conditional_detr','line_number':60,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrObjectDetectionOutput with Detr->ConditionalDetr','line_number':139,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrSegmentationOutput with Detr->ConditionalDetr','line_number':203,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrFrozenBatchNorm2d with Detr->ConditionalDetr','line_number':273,'multiline':False]
['text':' move reshapes to the beginning','line_number':301,'multiline':False]
['text':' to make it user-friendly','line_number':302,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.replace_batch_norm with Detr->ConditionalDetr','line_number':313,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrConvEncoder','line_number':338,'multiline':False]
['text':' replace batch norm by frozen batch norm','line_number':368,'multiline':False]
['text':' send pixel_values through the model to get list of feature maps','line_number':387,'multiline':False]
['text':' downsample pixel_mask to match shape of corresponding feature_map','line_number':392,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrConvModel with Detr->ConditionalDetr','line_number':398,'multiline':False]
['text':' send pixel_values and pixel_mask through backbone to get list of (feature_map, pixel_mask) tuples','line_number':410,'multiline':False]
['text':' position encoding','line_number':414,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrLearnedPositionEmbedding with Detr->ConditionalDetr','line_number':457,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.build_position_encoding with Detr->ConditionalDetr','line_number':481,'multiline':False]
['text':' TODO find a better way of exposing other arguments','line_number':485,'multiline':False]
['text':' function to generate sine positional embedding for 2d coordinates','line_number':495,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrAttention','line_number':518,'multiline':False]
['text':' if key_value_states are provided this layer is used as a cross-attention layer','line_number':612,'multiline':False]
['text':' for the decoder','line_number':613,'multiline':False]
['text':' add position embeddings to the hidden states before projecting to queries and keys','line_number':617,'multiline':False]
['text':' add key-value position embeddings to the key value states','line_number':622,'multiline':False]
['text':' get query proj','line_number':627,'multiline':False]
['text':' get key, value proj','line_number':629,'multiline':False]
['text':' cross_attentions','line_number':631,'multiline':False]
['text':' self_attention','line_number':635,'multiline':False]
['text':' this operation is a bit awkward, but it's required to','line_number':666,'multiline':False]
['text':' make sure that attn_weights keeps its gradient.','line_number':667,'multiline':False]
['text':' In order to do so, attn_weights have to reshaped','line_number':668,'multiline':False]
['text':' twice and have to be reused in the following','line_number':669,'multiline':False]
['text':' head dimension of values','line_number':721,'multiline':False]
['text':' get query proj','line_number':749,'multiline':False]
['text':' get key, value proj','line_number':751,'multiline':False]
['text':' this operation is a bit awkward, but it's required to','line_number':783,'multiline':False]
['text':' make sure that attn_weights keeps its gradient.','line_number':784,'multiline':False]
['text':' In order to do so, attn_weights have to reshaped','line_number':785,'multiline':False]
['text':' twice and have to be reused in the following','line_number':786,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrEncoderLayer with DetrEncoderLayer->ConditionalDetrEncoderLayer,DetrConfig->ConditionalDetrConfig','line_number':811,'multiline':False]
['text':' Decoder Self-Attention projections','line_number':906,'multiline':False]
['text':' Decoder Cross-Attention projections','line_number':925,'multiline':False]
['text':' ========== Begin of Self-Attention =============','line_number':994,'multiline':False]
['text':' Apply projections here','line_number':995,'multiline':False]
['text':' shape: num_queries x batch_size x 256','line_number':996,'multiline':False]
['text':' target is the input of the first decoder layer. zero by default.','line_number':999,'multiline':False]
['text':' ============ End of Self-Attention =============','line_number':1016,'multiline':False]
['text':' ========== Begin of Cross-Attention =============','line_number':1022,'multiline':False]
['text':' Apply projections here','line_number':1023,'multiline':False]
['text':' shape: num_queries x batch_size x 256','line_number':1024,'multiline':False]
['text':' For the first decoder layer, we concatenate the positional embedding predicted from','line_number':1034,'multiline':False]
['text':' the object query (the positional embedding) into the original query (key) in DETR.','line_number':1035,'multiline':False]
['text':' Cross-Attention Block','line_number':1052,'multiline':False]
['text':' ============ End of Cross-Attention =============','line_number':1069,'multiline':False]
['text':' Fully Connected','line_number':1071,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrClassificationHead with Detr->ConditionalDetr','line_number':1088,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrMLPPredictionHead with DetrMLPPredictionHead->MLP','line_number':1107,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrPreTrainedModel with Detr->ConditionalDetr','line_number':1129,'multiline':False]
['text':' Slightly different from the TF version which uses truncated_normal for initialization','line_number':1149,'multiline':False]
['text':' cf https://github.com/pytorch/pytorch/pull/5617','line_number':1150,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrEncoder with Detr->ConditionalDetr,DETR->ConditionalDETR','line_number':1215,'multiline':False]
['text':' in the original ConditionalDETR, no layernorm is used at the end of the encoder, as "normalize_before" is set to False by default','line_number':1239,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1241,'multiline':False]
['text':' expand attention_mask','line_number':1304,'multiline':False]
['text':' [batch_size, seq_len] -> [batch_size, 1, target_seq_len, source_seq_len]','line_number':1306,'multiline':False]
['text':' add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)','line_number':1314,'multiline':False]
['text':' skip the layer','line_number':1318,'multiline':False]
['text':' we add object_queries as extra input to the encoder_layer','line_number':1324,'multiline':False]
['text':' in Conditional DETR, the decoder uses layernorm after the last decoder layer output','line_number':1368,'multiline':False]
['text':' query_scale is the FFN applied on f to generate transformation T','line_number':1373,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1379,'multiline':False]
['text':' expand encoder attention mask','line_number':1456,'multiline':False]
['text':' [batch_size, seq_len] -> [batch_size, 1, target_seq_len, source_seq_len]','line_number':1458,'multiline':False]
['text':' optional intermediate hidden states','line_number':1463,'multiline':False]
['text':' decoder layers','line_number':1466,'multiline':False]
['text':' [num_queries, batch_size, 2]','line_number':1473,'multiline':False]
['text':' get sine embedding for the query vector','line_number':1476,'multiline':False]
['text':' add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)','line_number':1480,'multiline':False]
['text':' apply transformation','line_number':1491,'multiline':False]
['text':' finally, apply layernorm','line_number':1531,'multiline':False]
['text':' add hidden states from the last decoder layer','line_number':1534,'multiline':False]
['text':' stack intermediate decoder activations','line_number':1538,'multiline':False]
['text':' Create backbone + positional encoding','line_number':1576,'multiline':False]
['text':' Create projection layer','line_number':1581,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1589,'multiline':False]
['text':' First, sent pixel_values + pixel_mask through Backbone to obtain the features','line_number':1660,'multiline':False]
['text':' pixel_values should be of shape (batch_size, num_channels, height, width)','line_number':1661,'multiline':False]
['text':' pixel_mask should be of shape (batch_size, height, width)','line_number':1662,'multiline':False]
['text':' get final feature map and downsampled mask','line_number':1665,'multiline':False]
['text':' Second, apply 1x1 convolution to reduce the channel dimension to d_model (256 by default)','line_number':1671,'multiline':False]
['text':' Third, flatten the feature map + object_queries of shape NxCxHxW to NxCxHW, and permute it to NxHWxC','line_number':1674,'multiline':False]
['text':' In other words, turn their shape into (batch_size, sequence_length, hidden_size)','line_number':1675,'multiline':False]
['text':' Fourth, sent flattened_features + flattened_mask + object_queries through encoder','line_number':1681,'multiline':False]
['text':' flattened_features is a Tensor of shape (batch_size, heigth*width, hidden_size)','line_number':1682,'multiline':False]
['text':' flattened_mask is a Tensor of shape (batch_size, heigth*width)','line_number':1683,'multiline':False]
['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':1693,'multiline':False]
['text':' Fifth, sent query embeddings + object_queries through the decoder (which is conditioned on the encoder output)','line_number':1701,'multiline':False]
['text':' decoder outputs consists of (dec_features, dec_hidden, dec_attn)','line_number':1705,'multiline':False]
['text':' CONDITIONAL DETR encoder-decoder model','line_number':1745,'multiline':False]
['text':' Object detection heads','line_number':1748,'multiline':False]
['text':' We add one for the "no object" class','line_number':1751,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1756,'multiline':False]
['text':' taken from https://github.com/Atten4Vis/conditionalDETR/blob/master/models/conditional_detr.py','line_number':1759,'multiline':False]
['text':' this is a workaround to make torchscript happy, as torchscript','line_number':1762,'multiline':False]
['text':' doesn't support dictionary with non-homogeneous values, such','line_number':1763,'multiline':False]
['text':' as a dict having both a Tensor and a list.','line_number':1764,'multiline':False]
['text':' First, sent images through CONDITIONAL_DETR base model to obtain encoder + decoder outputs','line_number':1827,'multiline':False]
['text':' class logits + predicted bounding boxes','line_number':1842,'multiline':False]
['text':' pred_boxes = self.bbox_predictor(sequence_output).sigmoid()','line_number':1852,'multiline':False]
['text':' First: create the matcher','line_number':1856,'multiline':False]
['text':' Second: create the criterion','line_number':1860,'multiline':False]
['text':' Third: compute the losses, based on outputs and labels','line_number':1869,'multiline':False]
['text':' Fourth: compute total loss, as a weighted sum of the various losses','line_number':1888,'multiline':False]
['text':' object detection model','line_number':1933,'multiline':False]
['text':' segmentation head','line_number':1936,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1948,'multiline':False]
['text':' First, get list of feature maps and object_queries','line_number':2025,'multiline':False]
['text':' Second, apply 1x1 convolution to reduce the channel dimension to d_model (256 by default)','line_number':2028,'multiline':False]
['text':' Third, flatten the feature map + object_queries of shape NxCxHxW to NxCxHW, and permute it to NxHWxC','line_number':2033,'multiline':False]
['text':' In other words, turn their shape into (batch_size, sequence_length, hidden_size)','line_number':2034,'multiline':False]
['text':' Fourth, sent flattened_features + flattened_mask + object_queries through encoder','line_number':2040,'multiline':False]
['text':' flattened_features is a Tensor of shape (batch_size, heigth*width, hidden_size)','line_number':2041,'multiline':False]
['text':' flattened_mask is a Tensor of shape (batch_size, heigth*width)','line_number':2042,'multiline':False]
['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':2052,'multiline':False]
['text':' Fifth, sent query embeddings + object_queries through the decoder (which is conditioned on the encoder output)','line_number':2060,'multiline':False]
['text':' decoder outputs consists of (dec_features, dec_hidden, dec_attn)','line_number':2066,'multiline':False]
['text':' Sixth, compute logits, pred_boxes and pred_masks','line_number':2081,'multiline':False]
['text':' FIXME h_boxes takes the last one computed, keep this in mind','line_number':2088,'multiline':False]
['text':' important: we need to reverse the mask, since in the original implementation the mask works reversed','line_number':2089,'multiline':False]
['text':' bbox_mask is of shape (batch_size, num_queries, number_of_attention_heads in bbox_attention, height/32, width/32)','line_number':2090,'multiline':False]
['text':' First: create the matcher','line_number':2101,'multiline':False]
['text':' Second: create the criterion','line_number':2105,'multiline':False]
['text':' Third: compute the losses, based on outputs and labels','line_number':2114,'multiline':False]
['text':' Fourth: compute total loss, as a weighted sum of the various losses','line_number':2127,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrMaskHeadSmallConv with Detr->ConditionalDetr','line_number':2167,'multiline':False]
['text':' here we concatenate x, the projected feature map, of shape (batch_size, d_model, heigth/32, width/32) with','line_number':2208,'multiline':False]
['text':' the bbox_mask = the attention maps of shape (batch_size, n_queries, n_heads, height/32, width/32).','line_number':2209,'multiline':False]
['text':' We expand the projected feature map to match the number of heads.','line_number':2210,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrMHAttentionMap with Detr->ConditionalDetr','line_number':2248,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.dice_loss','line_number':2277,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.sigmoid_focal_loss','line_number':2297,'multiline':False]
['text':' add modulating factor','line_number':2318,'multiline':False]
['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss.__init__','line_number':2346,'multiline':False]
['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss.loss_labels','line_number':2354,'multiline':False]
['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss.loss_cardinality','line_number':2389,'multiline':False]
['text':' Count the number of predictions that are NOT "no-object" (which is the last class)','line_number':2399,'multiline':False]
['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss.loss_boxes','line_number':2405,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrLoss.loss_masks','line_number':2430,'multiline':False]
['text':' TODO use valid to mask invalid areas due to padding in loss','line_number':2445,'multiline':False]
['text':' upsample predictions to the target size','line_number':2450,'multiline':False]
['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss._get_source_permutation_idx','line_number':2464,'multiline':False]
['text':' permute predictions following indices','line_number':2466,'multiline':False]
['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss._get_target_permutation_idx','line_number':2471,'multiline':False]
['text':' permute targets following indices','line_number':2473,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrLoss.get_loss','line_number':2478,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrLoss.forward','line_number':2490,'multiline':False]
['text':' Retrieve the matching between the outputs of the last layer and the targets','line_number':2504,'multiline':False]
['text':' Compute the average number of target boxes across all nodes, for normalization purposes','line_number':2507,'multiline':False]
['text':' (Niels): comment out function below, distributed training to be added','line_number':2510,'multiline':False]
['text':' if is_dist_avail_and_initialized():','line_number':2511,'multiline':False]
['text':'     torch.distributed.all_reduce(num_boxes)','line_number':2512,'multiline':False]
['text':' (Niels) in original implementation, num_boxes is divided by get_world_size()','line_number':2513,'multiline':False]
['text':' Compute all the requested losses','line_number':2516,'multiline':False]
['text':' In case of auxiliary losses, we repeat this process with the output of each intermediate layer.','line_number':2521,'multiline':False]
['text':' Intermediate masks losses are too costly to compute, we ignore them.','line_number':2527,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrMLPPredictionHead with Detr->ConditionalDetr','line_number':2536,'multiline':False]
['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrHungarianMatcher with DeformableDetr->ConditionalDetr','line_number':2558,'multiline':False]
['text':' We flatten to compute the cost matrices in a batch','line_number':2609,'multiline':False]
['text':' [batch_size * num_queries, num_classes]','line_number':2610,'multiline':False]
['text':' [batch_size * num_queries, 4]','line_number':2611,'multiline':False]
['text':' Also concat the target labels and boxes','line_number':2613,'multiline':False]
['text':' Compute the classification cost.','line_number':2617,'multiline':False]
['text':' Compute the L1 cost between boxes','line_number':2624,'multiline':False]
['text':' Compute the giou cost between boxes','line_number':2627,'multiline':False]
['text':' Final cost matrix','line_number':2630,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr._upcast','line_number':2639,'multiline':False]
['text':' Protects from numerical overflows in multiplications by upcasting to the equivalent higher type','line_number':2641,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.box_area','line_number':2648,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.box_iou','line_number':2665,'multiline':False]
['text':' [N,M,2]','line_number':2670,'multiline':False]
['text':' [N,M,2]','line_number':2671,'multiline':False]
['text':' [N,M,2]','line_number':2673,'multiline':False]
['text':' [N,M]','line_number':2674,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.generalized_box_iou','line_number':2682,'multiline':False]
['text':' degenerate boxes gives inf / nan results','line_number':2690,'multiline':False]
['text':' so do an early check','line_number':2691,'multiline':False]
['text':' [N,M,2]','line_number':2701,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr._max_by_axis','line_number':2707,'multiline':False]
['text':' type: (List[List[int]]) -> List[int]','line_number':2709,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.NestedTensor','line_number':2717,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.nested_tensor_from_tensor_list','line_number':2739,'multiline':False]
