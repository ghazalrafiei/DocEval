['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2023 The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' See all SeamlessM4T-v2 models at https://huggingface.co/models?filter=seamless_m4t_v2','line_number':55,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TGenerationOutput with SeamlessM4T->SeamlessM4Tv2','line_number':65,'multiline':False]
['text':'########### UTILS ################','line_number':341,'multiline':False]
['text':' Copied from transformers.models.roberta.modeling_roberta.create_position_ids_from_input_ids','line_number':344,'multiline':False]
['text':' The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.','line_number':355,'multiline':False]
['text':' Copied from transformers.models.bart.modeling_bart.shift_tokens_right','line_number':361,'multiline':False]
['text':' replace possible -100 values in labels by `pad_token_id`','line_number':372,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.format_speech_generation_kwargs with SeamlessM4T->SeamlessM4Tv2','line_number':405,'multiline':False]
['text':' attribute kwargs to models','line_number':423,'multiline':False]
['text':' If the key is already in a specific config, then it's been set with a','line_number':434,'multiline':False]
['text':' submodules specific value and we don't override','line_number':435,'multiline':False]
['text':'########### SPEECH ENCODER related code ################','line_number':443,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TConformerFeatureProjection.__init__','line_number':447,'multiline':False]
['text':' non-projected hidden states are needed for quantization','line_number':455,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TConformerFeedForward with SeamlessM4T->SeamlessM4Tv2','line_number':462,'multiline':False]
['text':' Ensure that we do not leak padded positions in depthwise convolution.','line_number':528,'multiline':False]
['text':' Put 0 where necessary','line_number':529,'multiline':False]
['text':' exchange the temporal dimension and the feature dimension','line_number':533,'multiline':False]
['text':' GLU mechanism','line_number':536,'multiline':False]
['text':' => (batch, 2*channel, dim)','line_number':537,'multiline':False]
['text':' => (batch, channel, dim)','line_number':539,'multiline':False]
['text':' Pad the sequence entirely on the left because of causal convolution.','line_number':542,'multiline':False]
['text':' 1D Depthwise Conv','line_number':545,'multiline':False]
['text':' self-attention mechanism','line_number':587,'multiline':False]
['text':' make sure query/key states can be != value states','line_number':590,'multiline':False]
['text':' project query_key_states and value_states','line_number':594,'multiline':False]
['text':' => (batch, head, time1, d_k)','line_number':599,'multiline':False]
['text':' fp16 compatibility','line_number':615,'multiline':False]
['text':' apply attention_mask if necessary','line_number':620,'multiline':False]
['text':' => (batch, head, time1, time2)','line_number':624,'multiline':False]
['text':' => (batch, head, time1, d_k)','line_number':628,'multiline':False]
['text':' => (batch, time1, hidden_size)','line_number':631,'multiline':False]
['text':' Copied from transformers.models.wav2vec2_conformer.modeling_wav2vec2_conformer.Wav2Vec2ConformerEncoderLayer.__init__ with Wav2Vec2->SeamlessM4Tv2, attention_dropout->speech_encoder_dropout, torch.nn->nn','line_number':644,'multiline':False]
['text':' Feed-forward 1','line_number':650,'multiline':False]
['text':' Self-Attention','line_number':654,'multiline':False]
['text':' Conformer Convolution','line_number':659,'multiline':False]
['text':' Feed-forward 2','line_number':662,'multiline':False]
['text':' 1. Feed-Forward 1 layer','line_number':676,'multiline':False]
['text':' 2. Self-Attention layer','line_number':683,'multiline':False]
['text':' 3. Convolutional Layer','line_number':693,'multiline':False]
['text':' 4. Feed-Forward 2 Layer','line_number':698,'multiline':False]
['text':' make sure padded tokens output 0','line_number':767,'multiline':False]
['text':' extend attention_mask','line_number':769,'multiline':False]
['text':' add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)','line_number':789,'multiline':False]
['text':' under deepspeed zero3 all gpus must run in sync','line_number':796,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TConformerAdapterLayer with SeamlessM4T->SeamlessM4Tv2','line_number':831,'multiline':False]
['text':' 1. residual convolution','line_number':841,'multiline':False]
['text':' Self-Attention','line_number':852,'multiline':False]
['text':' Feed-forward','line_number':864,'multiline':False]
['text':' Apply pooling to the residual to match the sequence length of the','line_number':884,'multiline':False]
['text':' multi-head attention output.','line_number':885,'multiline':False]
['text':' (batch, seq_len, feature_dim) -> (batch, feature_dim, seq_len)','line_number':886,'multiline':False]
['text':' (batch, feature_dim, seq_len) -> (batch, seq_len, feature_dim)','line_number':890,'multiline':False]
['text':' Apply pooling before feeding to the multihead-attention layer.','line_number':894,'multiline':False]
['text':' (batch, seq_len, feature_dim) -> (batch, feature_dim, seq_len)','line_number':895,'multiline':False]
['text':' (batch, feature_dim, seq_len) -> (batch, seq_len, feature_dim)','line_number':899,'multiline':False]
['text':' The rest of the computation is identical to a vanilla Transformer','line_number':912,'multiline':False]
['text':' encoder layer.','line_number':913,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TConformerAdapter with SeamlessM4T->SeamlessM4Tv2','line_number':930,'multiline':False]
['text':' down project hidden_states if necessary','line_number':940,'multiline':False]
['text':'########### TEXT / UNITS related code ################','line_number':948,'multiline':False]
['text':' Copied from transformers.models.m2m_100.modeling_m2m_100.M2M100SinusoidalPositionalEmbedding','line_number':951,'multiline':False]
['text':' in forward put the weights on the correct dtype and device of the param','line_number':965,'multiline':False]
['text':' zero pad','line_number':984,'multiline':False]
['text':' Create the position ids from the input token ids. Any padded tokens remain padded.','line_number':997,'multiline':False]
['text':' expand embeddings if needed','line_number':1005,'multiline':False]
['text':' Copied from transformers.models.bart.modeling_bart.BartAttention.__init__ with Bart->SeamlessM4Tv2','line_number':1033,'multiline':False]
['text':' move heads to 2nd position (B, T, H * D) -> (B, T, H, D) -> (B, H, T, D)','line_number':1067,'multiline':False]
['text':' use encoder_hidden_states if cross attention','line_number':1084,'multiline':False]
['text':' checking that the `sequence_length` of the `past_key_value` is the same as the he provided','line_number':1086,'multiline':False]
['text':' `encoder_hidden_states` to support prefix tuning','line_number':1087,'multiline':False]
['text':' reuse k,v, cross_attentions','line_number':1089,'multiline':False]
['text':' reuse k, v, self_attention','line_number':1096,'multiline':False]
['text':' if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.','line_number':1104,'multiline':False]
['text':' Further calls to cross_attention layer can then reuse all cross-attention','line_number':1105,'multiline':False]
['text':' key/value_states (first "if" case)','line_number':1106,'multiline':False]
['text':' if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of','line_number':1107,'multiline':False]
['text':' all previous decoder key/value_states. Further calls to uni-directional self-attention','line_number':1108,'multiline':False]
['text':' can concat previous decoder key/value_states to current projected key/value_states (third "elif" case)','line_number':1109,'multiline':False]
['text':' if encoder bi-directional self-attention `past_key_value` is always `None`','line_number':1110,'multiline':False]
['text':' (batch_size, n_heads, seq_length, key_length)','line_number':1116,'multiline':False]
['text':'  attn_output = torch.bmm(attn_probs, value_states) ?','line_number':1120,'multiline':False]
['text':' attn_output = attn_output.view(bsz, self.num_heads, tgt_len, self.head_dim) ?','line_number':1122,'multiline':False]
['text':' Copied from transformers.models.nllb_moe.modeling_nllb_moe.NllbMoeDenseActDense with NllbMoe->SeamlessM4Tv2,DenseActDense->FeedForwardNetwork, d_model->hidden_size','line_number':1132,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TEncoderLayer with SeamlessM4T->SeamlessM4Tv2','line_number':1155,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TDecoderLayer with SeamlessM4T->SeamlessM4Tv2','line_number':1219,'multiline':False]
['text':' Self Attention','line_number':1281,'multiline':False]
['text':' decoder uni-directional self-attention cached key/values tuple is at positions 1,2','line_number':1282,'multiline':False]
['text':' add present self-attn cache to positions 1,2 of present_key_value tuple','line_number':1284,'multiline':False]
['text':' Cross-Attention Block','line_number':1294,'multiline':False]
['text':' cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple','line_number':1301,'multiline':False]
['text':' add cross-attn to positions 3,4 of present_key_value tuple','line_number':1314,'multiline':False]
['text':' Fully Connected','line_number':1317,'multiline':False]
['text':' Self Attention','line_number':1383,'multiline':False]
['text':' Conv','line_number':1392,'multiline':False]
['text':' Apply padding mask to avoid leaking padded positions in the convolution layer','line_number':1395,'multiline':False]
['text':'########### SUB-MODELS related code ################','line_number':1418,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TPreTrainedModel._compute_sub_sample_lengths_from_attention_mask','line_number':1466,'multiline':False]
['text':' We slice out the tensor till the padding index.','line_number':1531,'multiline':False]
['text':' We set char_len to 1 for an unk token.','line_number':1551,'multiline':False]
['text':' By default, spaces are merged with the next subword.','line_number':1557,'multiline':False]
['text':' char_len includes the space.','line_number':1558,'multiline':False]
['text':' Add the space for the next subword.','line_number':1562,'multiline':False]
['text':' Subtract the space for the current subword.','line_number':1565,'multiline':False]
['text':' Merge space with punctuation mark by default.','line_number':1569,'multiline':False]
['text':' Subtract the space for the subword succeeding the punctuation mark.','line_number':1572,'multiline':False]
['text':' Get char token indices corresponding to the subwords.','line_number':1620,'multiline':False]
['text':' if batched sample, need to interleave per sample, and pad -> loss of parallelism','line_number':1640,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TSpeechEncoder with SeamlessM4T->SeamlessM4Tv2','line_number':1661,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1674,'multiline':False]
['text':' inspired from MBart and NllbMoe','line_number':1728,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TEncoder with SeamlessM4T->SeamlessM4Tv2','line_number':1739,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1786,'multiline':False]
['text':' retrieve input_ids and inputs_embeds','line_number':1840,'multiline':False]
['text':' expand attention_mask','line_number':1864,'multiline':False]
['text':' [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]','line_number':1866,'multiline':False]
['text':' add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)','line_number':1875,'multiline':False]
['text':' skip the layer','line_number':1879,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TDecoder with SeamlessM4T->SeamlessM4Tv2','line_number':1924,'multiline':False]
['text':' if embed_tokens defined, use its shape instead','line_number':1940,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1965,'multiline':False]
['text':' retrieve input_ids and inputs_embeds','line_number':2046,'multiline':False]
['text':' past_key_values_length','line_number':2059,'multiline':False]
['text':' expand encoder attention mask','line_number':2069,'multiline':False]
['text':' [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]','line_number':2071,'multiline':False]
['text':' embed positions','line_number':2076,'multiline':False]
['text':' decoder layers','line_number':2090,'multiline':False]
['text':' add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)','line_number':2097,'multiline':False]
['text':' add hidden states from the last decoder layer','line_number':2141,'multiline':False]
['text':' if embed_tokens defined, use its shape instead','line_number':2184,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':2225,'multiline':False]
['text':' create padding mask for character lengths','line_number':2268,'multiline':False]
['text':' upsample hidden states according to characters sequence lengths','line_number':2271,'multiline':False]
['text':' embed char positions','line_number':2273,'multiline':False]
['text':' update char hidden states with positions and char embeddings','line_number':2275,'multiline':False]
['text':' predict duration','line_number':2278,'multiline':False]
['text':' upsample char hidden states according to predicted duration','line_number':2283,'multiline':False]
['text':' decoder layers','line_number':2294,'multiline':False]
['text':' add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)','line_number':2299,'multiline':False]
['text':' add hidden states from the last decoder layer','line_number':2329,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TTextToUnitModel.__init__ with SeamlessM4T->SeamlessM4Tv2, Decoder->TextToUnitDecoder','line_number':2351,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':2362,'multiline':False]
['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':2392,'multiline':False]
['text':' decoder outputs consists of (dec_features, dec_hidden, dec_attn, padding_mask)','line_number':2400,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TTextToUnitForConditionalGeneration.__init__ with SeamlessM4T->SeamlessM4Tv2','line_number':2440,'multiline':False]
['text':' update config - used principaly for bos_token_id etc.','line_number':2446,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':2457,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TTextToUnitForConditionalGeneration.get_encoder','line_number':2460,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TTextToUnitForConditionalGeneration.get_decoder','line_number':2464,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TTextToUnitForConditionalGeneration.get_output_embeddings','line_number':2468,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TTextToUnitForConditionalGeneration.set_output_embeddings','line_number':2472,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TTextToUnitForConditionalGeneration.get_input_embeddings','line_number':2476,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TTextToUnitForConditionalGeneration.set_input_embeddings','line_number':2480,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TTextToUnitForConditionalGeneration._tie_weights','line_number':2535,'multiline':False]
['text':'########### VOCODER related code ################','line_number':2543,'multiline':False]
['text':' Copied from transformers.models.speecht5.modeling_speecht5.HifiGanResidualBlock','line_number':2563,'multiline':False]
['text':' Input: B x T x C; Output: B x T','line_number':2645,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4THifiGan with SeamlessM4T->SeamlessM4Tv2','line_number':2659,'multiline':False]
['text':' remove seq-len dim since this collapses to 1','line_number':2726,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':2756,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TCodeHifiGan._get_dur_output_lengths','line_number':2759,'multiline':False]
['text':' take care of edge cases where no padding or too many padding','line_number':2766,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TCodeHifiGan._get_output_hifigan_lengths','line_number':2774,'multiline':False]
['text':' 1D convolutional layer output length formula taken','line_number':2781,'multiline':False]
['text':' from https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html','line_number':2782,'multiline':False]
['text':' conv_pre','line_number':2790,'multiline':False]
['text':' upsampler','line_number':2793,'multiline':False]
['text':' resblock','line_number':2801,'multiline':False]
['text':' conv_post','line_number':2812,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TCodeHifiGan.forward with SeamlessM4T->SeamlessM4Tv2, spkr_id->speaker_id','line_number':2817,'multiline':False]
['text':' B x C x T','line_number':2839,'multiline':False]
['text':' if batched sample, need to interleave per sample, and pad -> loss of parallelism','line_number':2843,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TCodeHifiGan._init_weights','line_number':2867,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TCodeHifiGan.apply_weight_norm','line_number':2879,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TCodeHifiGan.remove_weight_norm','line_number':2888,'multiline':False]
['text':'########### WHOLE MODEL related code ################','line_number':2898,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToText with SeamlessM4T->SeamlessM4Tv2,SeamlessM4Tv2Tokenizer->SeamlessM4TTokenizer, SeamlessM4Tv2Processor->SeamlessM4TProcessor','line_number':2905,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':2925,'multiline':False]
['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':2997,'multiline':False]
['text':' decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)','line_number':3007,'multiline':False]
['text':' prepare text_decoder_input_ids','line_number':3119,'multiline':False]
['text':' overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.','line_number':3121,'multiline':False]
['text':' also accept __xxx__','line_number':3126,'multiline':False]
['text':' tgt_lang gets priority over decoder input ids','line_number':3133,'multiline':False]
['text':' only a warning, otherwise errors appear in the tests','line_number':3142,'multiline':False]
['text':' cut decoder_input_ids if past is used','line_number':3168,'multiline':False]
['text':' encoder_outputs is defined. input_ids not needed','line_number':3173,'multiline':False]
['text':' cached cross_attention states don't have to be reordered -> they are always the same','line_number':3185,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText.__init__ with SeamlessM4T->SeamlessM4Tv2','line_number':3205,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':3214,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText.get_encoder','line_number':3217,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText.get_decoder','line_number':3221,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText.get_output_embeddings','line_number':3225,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText.set_output_embeddings','line_number':3229,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText.get_input_embeddings','line_number':3233,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText.set_input_embeddings','line_number':3237,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText._tie_weights','line_number':3241,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText.forward','line_number':3248,'multiline':False]
['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':3291,'multiline':False]
['text':' decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)','line_number':3308,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText.generate','line_number':3347,'multiline':False]
['text':' overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.','line_number':3419,'multiline':False]
['text':' also accept __xxx__','line_number':3430,'multiline':False]
['text':' tgt_lang gets priority over decoder input ids','line_number':3437,'multiline':False]
['text':' only a warning, otherwise errors appear in the tests','line_number':3446,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText.prepare_inputs_for_generation','line_number':3462,'multiline':False]
['text':' cut decoder_input_ids if past is used','line_number':3472,'multiline':False]
['text':' encoder_outputs is defined. input_ids not needed','line_number':3477,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToText._reorder_cache','line_number':3486,'multiline':False]
['text':' cached cross_attention states don't have to be reordered -> they are always the same','line_number':3490,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToSpeech.__init__ with SeamlessM4T->SeamlessM4Tv2','line_number':3511,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':3521,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToSpeech.get_encoder','line_number':3527,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToSpeech.get_decoder','line_number':3531,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToSpeech.get_output_embeddings','line_number':3535,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToSpeech.set_output_embeddings','line_number':3539,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToSpeech.get_input_embeddings','line_number':3543,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToSpeech.set_input_embeddings','line_number':3547,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToSpeech._tie_weights','line_number':3553,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToSpeech.forward with SeamlessM4T->SeamlessM4Tv2','line_number':3561,'multiline':False]
['text':' if encoder_outputs is not None, it's probably used within a .generate method so no need to warn','line_number':3595,'multiline':False]
['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':3609,'multiline':False]
['text':' decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)','line_number':3619,'multiline':False]
['text':' also accept __xxx__','line_number':3723,'multiline':False]
['text':' overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.','line_number':3746,'multiline':False]
['text':' first generation','line_number':3752,'multiline':False]
['text':' prepare second generation','line_number':3756,'multiline':False]
['text':' repeat attention mask alongside batch dimension','line_number':3761,'multiline':False]
['text':' repeat attention mask alongside batch dimension','line_number':3765,'multiline':False]
['text':' get decoder last hidden state - must do a pass through the text decoder','line_number':3768,'multiline':False]
['text':' Manually trim the final EOS token','line_number':3770,'multiline':False]
['text':' Compute new attention mask','line_number':3777,'multiline':False]
['text':' REMOVE EOS and lang_id','line_number':3782,'multiline':False]
['text':' replace every other EOS','line_number':3784,'multiline':False]
['text':' compute t2u_char_input_ids','line_number':3789,'multiline':False]
['text':' Add pads for lang, EOS tokens as per NLLB "source" tokenizer mode.','line_number':3795,'multiline':False]
['text':' second pass','line_number':3802,'multiline':False]
['text':' The text-to-unit model is non auto-regressive. We keep the ability to use sampling with temperature','line_number':3813,'multiline':False]
['text':' apply softmax','line_number':3819,'multiline':False]
['text':' reshape to 2D: (batch_size, seq_len, t2u_vocab_size) -> (batch_size*seq_len, t2u_vocab_size)','line_number':3821,'multiline':False]
['text':' multinomial then reshape : (batch_size*seq_len)-> (batch_size,seq_len)','line_number':3823,'multiline':False]
['text':' replace eos per pad','line_number':3829,'multiline':False]
['text':' offset of control symbols','line_number':3832,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToSpeech.prepare_inputs_for_generation','line_number':3856,'multiline':False]
['text':' cut decoder_input_ids if past is used','line_number':3866,'multiline':False]
['text':' encoder_outputs is defined. input_ids not needed','line_number':3871,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForTextToSpeech._reorder_cache','line_number':3880,'multiline':False]
['text':' cached cross_attention states don't have to be reordered -> they are always the same','line_number':3884,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToSpeech.__init__ with SeamlessM4T->SeamlessM4Tv2','line_number':3904,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':3913,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToSpeech.get_encoder','line_number':3919,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToSpeech.get_decoder','line_number':3923,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToSpeech.get_output_embeddings','line_number':3927,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToSpeech.set_output_embeddings','line_number':3931,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToSpeech.get_input_embeddings','line_number':3935,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToSpeech.set_input_embeddings','line_number':3939,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToSpeech._tie_weights','line_number':3943,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToSpeech.forward with SeamlessM4T->SeamlessM4Tv2','line_number':3950,'multiline':False]
['text':' if encoder_outputs is not None, it's probably used within a .generate method so no need to warn','line_number':3985,'multiline':False]
['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':3999,'multiline':False]
['text':' decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)','line_number':4016,'multiline':False]
['text':' also accept __xxx__','line_number':4117,'multiline':False]
['text':' overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.','line_number':4139,'multiline':False]
['text':' first generation','line_number':4145,'multiline':False]
['text':' prepare second generation','line_number':4149,'multiline':False]
['text':' get last_hidden_state from encoder','line_number':4153,'multiline':False]
['text':' input modality = speech so new attention mask for the decoder','line_number':4156,'multiline':False]
['text':' repeat attention mask alongside batch dimension','line_number':4165,'multiline':False]
['text':' repeat attention mask alongside batch dimension','line_number':4168,'multiline':False]
['text':' get decoder last hidden state - must do a pass through the text decoder','line_number':4171,'multiline':False]
['text':' Manually trim the final EOS token','line_number':4173,'multiline':False]
['text':' Compute new attention mask','line_number':4180,'multiline':False]
['text':' REMOVE EOS and lang_id','line_number':4185,'multiline':False]
['text':' replace every other EOS','line_number':4187,'multiline':False]
['text':' compute t2u_char_input_ids','line_number':4192,'multiline':False]
['text':' Add pads for lang, EOS tokens as per NLLB "source" tokenizer mode.','line_number':4198,'multiline':False]
['text':' second pass','line_number':4205,'multiline':False]
['text':' The text-to-unit model is non auto-regressive. We keep the ability to use sampling with temperature','line_number':4216,'multiline':False]
['text':' apply softmax','line_number':4222,'multiline':False]
['text':' reshape to 2D: (batch_size, seq_len, t2u_vocab_size) -> (batch_size*seq_len, t2u_vocab_size)','line_number':4224,'multiline':False]
['text':' multinomial then reshape : (batch_size*seq_len)-> (batch_size,seq_len)','line_number':4226,'multiline':False]
['text':' replace eos per pad','line_number':4232,'multiline':False]
['text':' offset of control symbols','line_number':4235,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToSpeech._reorder_cache','line_number':4260,'multiline':False]
['text':' cached cross_attention states don't have to be reordered -> they are always the same','line_number':4264,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TForSpeechToSpeech.prepare_inputs_for_generation','line_number':4270,'multiline':False]
['text':' cut decoder_input_ids if past is used','line_number':4280,'multiline':False]
['text':' encoder_outputs is defined. input_ids not needed','line_number':4285,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TModel.__init__ with SeamlessM4T->SeamlessM4Tv2','line_number':4310,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':4321,'multiline':False]
['text':' these models already call post_init in their initialization','line_number':4328,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TModel.set_modality','line_number':4332,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TModel.get_encoder','line_number':4343,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TModel.get_output_embeddings','line_number':4350,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TModel.set_output_embeddings','line_number':4354,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TModel.get_input_embeddings','line_number':4358,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TModel.set_input_embeddings','line_number':4362,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TModel._tie_weights','line_number':4368,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TModel.forward with SeamlessM4T->SeamlessM4Tv2','line_number':4376,'multiline':False]
['text':' if encoder_outputs is not None, it's probably used within a .generate method so no need to warn','line_number':4430,'multiline':False]
['text':' if encoder_outputs is not None, it's probably used within a .generate method so no need to warn','line_number':4447,'multiline':False]
['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':4461,'multiline':False]
['text':' input modality = speech so new attention mask','line_number':4470,'multiline':False]
['text':' decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)','line_number':4479,'multiline':False]
['text':' also accept __xxx__','line_number':4597,'multiline':False]
['text':' overwrite text_decoder_input_ids if tgt_lang is passed. The latter gets priority over decoder_input_ids.','line_number':4629,'multiline':False]
['text':' tgt_lang gets priority over decoder input ids','line_number':4631,'multiline':False]
['text':' first generation','line_number':4637,'multiline':False]
['text':' prepare second generation','line_number':4654,'multiline':False]
['text':' get encoder last hidden states','line_number':4658,'multiline':False]
['text':' get last_hidden_state from encoder - must do a pass through the speech encoder','line_number':4660,'multiline':False]
['text':' input modality = speech so new attention mask for the decoder','line_number':4665,'multiline':False]
['text':' repeat attention mask alongside batch dimension','line_number':4677,'multiline':False]
['text':' repeat attention mask alongside batch dimension','line_number':4680,'multiline':False]
['text':' get decoder last hidden state - must do a pass through the text decoder','line_number':4683,'multiline':False]
['text':' Manually trim the final EOS token','line_number':4685,'multiline':False]
['text':' Compute new attention mask','line_number':4692,'multiline':False]
['text':' REMOVE EOS and lang_id','line_number':4697,'multiline':False]
['text':' replace every other EOS','line_number':4699,'multiline':False]
['text':' compute t2u_char_input_ids','line_number':4704,'multiline':False]
['text':' Add pads for lang, EOS tokens as per NLLB "source" tokenizer mode.','line_number':4710,'multiline':False]
['text':' second pass','line_number':4717,'multiline':False]
['text':' The text-to-unit model is non auto-regressive. We keep the ability to use sampling with temperature','line_number':4728,'multiline':False]
['text':' apply softmax','line_number':4734,'multiline':False]
['text':' reshape to 2D: (batch_size, seq_len, t2u_vocab_size) -> (batch_size*seq_len, t2u_vocab_size)','line_number':4736,'multiline':False]
['text':' multinomial then reshape : (batch_size*seq_len)-> (batch_size,seq_len)','line_number':4738,'multiline':False]
['text':' replace eos per pad','line_number':4744,'multiline':False]
['text':' offset of control symbols','line_number':4747,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TModel.prepare_inputs_for_generation','line_number':4771,'multiline':False]
['text':' cut decoder_input_ids if past is used','line_number':4781,'multiline':False]
['text':' encoder_outputs is defined. input_ids not needed','line_number':4786,'multiline':False]
['text':' Copied from transformers.models.seamless_m4t.modeling_seamless_m4t.SeamlessM4TModel._reorder_cache','line_number':4795,'multiline':False]
['text':' cached cross_attention states don't have to be reordered -> they are always the same','line_number':4799,'multiline':False]
