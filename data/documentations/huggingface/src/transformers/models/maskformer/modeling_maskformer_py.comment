['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2022 Meta Platforms, Inc.s and The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' See all MaskFormer models at https://huggingface.co/models?filter=maskformer','line_number':56,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrDecoderOutput','line_number':61,'multiline':False]
['text':' refactored from original implementation','line_number':269,'multiline':False]
['text':' refactored from original implementation','line_number':300,'multiline':False]
['text':' refactored from original implementation','line_number':344,'multiline':False]
['text':' using broadcasting to get a [num_queries, NUM_CLASSES] matrix','line_number':361,'multiline':False]
['text':' refactored from original implementation','line_number':367,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrAttention','line_number':407,'multiline':False]
['text':' if key_value_states are provided this layer is used as a cross-attention layer','line_number':501,'multiline':False]
['text':' for the decoder','line_number':502,'multiline':False]
['text':' add position embeddings to the hidden states before projecting to queries and keys','line_number':506,'multiline':False]
['text':' add key-value position embeddings to the key value states','line_number':511,'multiline':False]
['text':' get query proj','line_number':516,'multiline':False]
['text':' get key, value proj','line_number':518,'multiline':False]
['text':' cross_attentions','line_number':520,'multiline':False]
['text':' self_attention','line_number':524,'multiline':False]
['text':' this operation is a bit awkward, but it's required to','line_number':555,'multiline':False]
['text':' make sure that attn_weights keeps its gradient.','line_number':556,'multiline':False]
['text':' In order to do so, attn_weights have to reshaped','line_number':557,'multiline':False]
['text':' twice and have to be reused in the following','line_number':558,'multiline':False]
['text':' Copied from transformers.models.detr.modeling_detr.DetrDecoderLayer','line_number':583,'multiline':False]
['text':' Self Attention','line_number':659,'multiline':False]
['text':' Cross-Attention Block','line_number':671,'multiline':False]
['text':' Fully Connected','line_number':689,'multiline':False]
['text':' in DETR, the decoder uses layernorm after the last decoder layer output','line_number':728,'multiline':False]
['text':' expand encoder attention mask','line_number':806,'multiline':False]
['text':' [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]','line_number':808,'multiline':False]
['text':' optional intermediate hidden states','line_number':813,'multiline':False]
['text':' decoder layers','line_number':816,'multiline':False]
['text':' add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)','line_number':822,'multiline':False]
['text':' finally, apply layernorm','line_number':863,'multiline':False]
['text':' add hidden states from the last decoder layer','line_number':866,'multiline':False]
['text':' stack intermediate decoder activations','line_number':870,'multiline':False]
['text':' refactored from original implementation','line_number':889,'multiline':False]
['text':' iterate through batch size','line_number':946,'multiline':False]
['text':' downsample the target mask, save memory','line_number':948,'multiline':False]
['text':' Compute the classification cost. Contrary to the loss, we don't use the NLL,','line_number':951,'multiline':False]
['text':' but approximate it in 1 - proba[target class].','line_number':952,'multiline':False]
['text':' The 1 is a constant that doesn't change the matching, it can be ommitted.','line_number':953,'multiline':False]
['text':' flatten spatial dimension "q h w -> q (h w)"','line_number':955,'multiline':False]
['text':' [num_queries, height*width]','line_number':956,'multiline':False]
['text':' same for target_mask "c h w -> c (h w)"','line_number':957,'multiline':False]
['text':' [num_total_labels, height*width]','line_number':958,'multiline':False]
['text':' compute the focal loss between each mask pairs -> shape (num_queries, num_labels)','line_number':959,'multiline':False]
['text':' Compute the dice loss betwen each mask pairs -> shape (num_queries, num_labels)','line_number':961,'multiline':False]
['text':' final cost matrix','line_number':963,'multiline':False]
['text':' do the assigmented using the hungarian algorithm in scipy','line_number':965,'multiline':False]
['text':' It could be stacked in one tensor','line_number':969,'multiline':False]
['text':' copied and adapted from original implementation','line_number':987,'multiline':False]
['text':' get the maximum size in the batch','line_number':1030,'multiline':False]
['text':' compute finel size','line_number':1033,'multiline':False]
['text':' get metadata','line_number':1036,'multiline':False]
['text':' pad the tensors to the size of the biggest one','line_number':1041,'multiline':False]
['text':' shape = (batch_size, num_queries)','line_number':1070,'multiline':False]
['text':' shape = (batch_size, num_queries)','line_number':1072,'multiline':False]
['text':' target_classes is a (batch_size, num_labels, num_queries), we need to permute pred_logits "b q c -> b c q"','line_number':1077,'multiline':False]
['text':' shape (batch_size * num_queries, height, width)','line_number':1106,'multiline':False]
['text':' shape (batch_size, num_queries, height, width)','line_number':1108,'multiline':False]
['text':' pad all and stack the targets to the num_labels dimension','line_number':1109,'multiline':False]
['text':' upsample predictions to the target size, we have to add one dim to use interpolate','line_number':1112,'multiline':False]
['text':' permute predictions following indices','line_number':1126,'multiline':False]
['text':' permute labels following indices','line_number':1132,'multiline':False]
['text':' retrieve the matching between the outputs of the last layer and the labels','line_number':1171,'multiline':False]
['text':' compute the average number of target masks for normalization purposes','line_number':1173,'multiline':False]
['text':' get all the losses','line_number':1175,'multiline':False]
['text':' in case of auxiliary losses, we repeat this process with the output of each intermediate layer.','line_number':1180,'multiline':False]
['text':' Provide backwards compatibility from when the class inherited from nn.Sequential','line_number':1218,'multiline':False]
['text':' In nn.Sequential subclasses, the name given to the layer is its index in the sequence.','line_number':1219,'multiline':False]
['text':' In nn.Module subclasses they derived from the instance attribute they are assigned to e.g.','line_number':1220,'multiline':False]
['text':' self.my_layer_name = Layer()','line_number':1221,'multiline':False]
['text':' We can't give instance attributes integer names i.e. self.0 is not permitted and so need to register','line_number':1222,'multiline':False]
['text':' explicitly','line_number':1223,'multiline':False]
['text':' we use the last feature map','line_number':1314,'multiline':False]
['text':' copied and adapted from original implementation, also practically equal to DetrSinePositionEmbedding','line_number':1325,'multiline':False]
['text':' Maintain submodule indexing as if part of a Sequential block','line_number':1369,'multiline':False]
['text':' Provide backwards compatibility from when the class inherited from nn.Sequential','line_number':1404,'multiline':False]
['text':' In nn.Sequential subclasses, the name given to the layer is its index in the sequence.','line_number':1405,'multiline':False]
['text':' In nn.Module subclasses they derived from the instance attribute they are assigned to e.g.','line_number':1406,'multiline':False]
['text':' self.my_layer_name = Layer()','line_number':1407,'multiline':False]
['text':' We can't give instance attributes integer names i.e. self.0 is not permitted and so need to register','line_number':1408,'multiline':False]
['text':' explicitly','line_number':1409,'multiline':False]
['text':' TODD: add method to load pretrained weights of backbone','line_number':1432,'multiline':False]
['text':' for backwards compatibility','line_number':1435,'multiline':False]
['text':' the last feature is actually the output from the last layer','line_number':1463,'multiline':False]
['text':' repeat the queries "q c -> b q c"','line_number':1495,'multiline':False]
['text':' rearrange both image_features and object_queries "b c h w -> b (h w) c"','line_number':1501,'multiline':False]
['text':' FPN','line_number':1564,'multiline':False]
['text':' The MLP head','line_number':1573,'multiline':False]
['text':' I was not able to find the correct initializer in the original implementation','line_number':1575,'multiline':False]
['text':' we'll use xavier','line_number':1576,'multiline':False]
['text':' copied from DETR','line_number':1584,'multiline':False]
['text':' Slightly different from the TF version which uses truncated_normal for initialization','line_number':1586,'multiline':False]
['text':' cf https://github.com/pytorch/pytorch/pull/5617','line_number':1587,'multiline':False]
['text':' + 1 because we add the "null" class','line_number':1705,'multiline':False]
['text':' weight each loss by `self.weight_dict[<LOSS_NAME>]` including auxiliary losses','line_number':1739,'multiline':False]
['text':' get the auxiliary predictions (one for each decoder's layer)','line_number':1752,'multiline':False]
['text':' This code is a little bit cumbersome, an improvement can be to return a list of predictions. If we have auxiliary loss then we are going to return more than one element in the list','line_number':1754,'multiline':False]
['text':' get the masks','line_number':1759,'multiline':False]
['text':' Equivalent to einsum('lbqc, bchw -> lbqhw') but jit friendly','line_number':1762,'multiline':False]
['text':' go til [:-1] because the last one is always used','line_number':1772,'multiline':False]
['text':' get the masks','line_number':1782,'multiline':False]
['text':' sum up over the channels','line_number':1784,'multiline':False]
['text':' Equivalent to einsum('bqc, bchw -> bqhw') but jit friendly','line_number':1786,'multiline':False]
['text':' We need to have raw_outputs optionally be returned as a dict to use torch.compile. For backwards','line_number':1896,'multiline':False]
['text':' compatibility we convert to a dataclass for the rest of the model logic','line_number':1897,'multiline':False]
