['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2021 The HuggingFace Inc. team.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' here we list all keys to be renamed (original name on the left, our name on the right)','line_number':35,'multiline':False]
['text':' encoder layers: output projection, 2 feedforward neural networks and 2 layernorms','line_number':39,'multiline':False]
['text':' projection layer + position embeddings','line_number':51,'multiline':False]
['text':' layernorm','line_number':62,'multiline':False]
['text':' if just the base model, we should remove "vit" from all keys that start with "vit"','line_number':70,'multiline':False]
['text':' layernorm + classification head','line_number':73,'multiline':False]
['text':' we split up the matrix of each encoder layer into queries, keys and values','line_number':86,'multiline':False]
['text':' read in weights + bias of input projection layer (in timm, this is a single matrix + bias)','line_number':93,'multiline':False]
['text':' next, add query, keys and values (in that order) to the state dict','line_number':96,'multiline':False]
['text':' We will verify our results on an image of cute cats','line_number':124,'multiline':False]
['text':' define default ViT configuration','line_number':137,'multiline':False]
['text':' load original model from timm','line_number':141,'multiline':False]
['text':' detect unsupported ViT models in transformers','line_number':145,'multiline':False]
['text':' fc_norm is present','line_number':146,'multiline':False]
['text':' use of global average pooling in combination (or without) class token','line_number':150,'multiline':False]
['text':' CLIP style vit with norm_pre layer present','line_number':154,'multiline':False]
['text':' SigLIP style vit with attn_pool layer present','line_number':160,'multiline':False]
['text':' use of layer scale in ViT model blocks','line_number':166,'multiline':False]
['text':' Hybrid ResNet-ViTs','line_number':172,'multiline':False]
['text':' get patch size and image size from the patch embedding submodule','line_number':176,'multiline':False]
['text':' retrieve architecture-specific parameters from the timm model','line_number':180,'multiline':False]
['text':' check whether the model has a classification head or not','line_number':186,'multiline':False]
['text':' infer ImageNet subset from timm model','line_number':189,'multiline':False]
['text':' load state_dict of original model','line_number':198,'multiline':False]
['text':' remove and rename some keys in the state dict','line_number':201,'multiline':False]
['text':' load HuggingFace model','line_number':209,'multiline':False]
['text':' Check outputs on an image, prepared by ViTImageProcessor/DeiTImageProcessor','line_number':216,'multiline':False]
['text':' Required parameters','line_number':243,'multiline':False]
