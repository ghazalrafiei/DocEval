['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2022 The HuggingFace Inc. team.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' here we list all keys to be renamed (original name on the left, our name on the right)','line_number':45,'multiline':False]
['text':' fmt: off','line_number':49,'multiline':False]
['text':' stem:','line_number':50,'multiline':False]
['text':' backbone','line_number':57,'multiline':False]
['text':' transformer encoder','line_number':78,'multiline':False]
['text':' encoder layers: output projection, 2 feedforward neural networks and 2 layernorms','line_number':80,'multiline':False]
['text':' layernorm + pooler','line_number':93,'multiline':False]
['text':' if just the base model, we should remove "vit" from all keys that start with "vit"','line_number':103,'multiline':False]
['text':' layernorm + classification head','line_number':106,'multiline':False]
['text':' fmt: on','line_number':115,'multiline':False]
['text':' we split up the matrix of each encoder layer into queries, keys and values','line_number':120,'multiline':False]
['text':' read in weights + bias of input projection layer (in timm, this is a single matrix + bias)','line_number':127,'multiline':False]
['text':' next, add query, keys and values (in that order) to the state dict','line_number':130,'multiline':False]
['text':' We will verify our results on an image of cute cats','line_number':158,'multiline':False]
['text':' define default ViT hybrid configuration','line_number':171,'multiline':False]
['text':' load original model from timm','line_number':182,'multiline':False]
['text':' load state_dict of original model, remove and rename some keys','line_number':186,'multiline':False]
['text':' load HuggingFace model','line_number':202,'multiline':False]
['text':' create image processor','line_number':209,'multiline':False]
['text':' verify pixel values','line_number':234,'multiline':False]
['text':' verify logits','line_number':237,'multiline':False]
['text':' Required parameters','line_number':268,'multiline':False]
