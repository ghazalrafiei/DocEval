['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2023 The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' Copied from transformers.models.owlvit.image_processing_owlvit._upcast','line_number':65,'multiline':False]
['text':' Protects from numerical overflows in multiplications by upcasting to the equivalent higher type','line_number':67,'multiline':False]
['text':' Copied from transformers.models.owlvit.image_processing_owlvit.box_area','line_number':74,'multiline':False]
['text':' Copied from transformers.models.owlvit.image_processing_owlvit.box_iou','line_number':90,'multiline':False]
['text':' [N,M,2]','line_number':95,'multiline':False]
['text':' [N,M,2]','line_number':96,'multiline':False]
['text':' [N,M,2]','line_number':98,'multiline':False]
['text':' [N,M]','line_number':99,'multiline':False]
['text':' append dimensions to input_shape','line_number':134,'multiline':False]
['text':' multichannel case: append shape of last axis','line_number':138,'multiline':False]
['text':' NaNs detected, use NaN-safe min/max','line_number':162,'multiline':False]
['text':' Translate modes used by np.pad to those used by scipy.ndimage','line_number':303,'multiline':False]
['text':' All transformations expect numpy arrays.','line_number':418,'multiline':False]
['text':' We assume that all images have the same channel dimension format.','line_number':428,'multiline':False]
['text':' Copied from transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.post_process_object_detection','line_number':463,'multiline':False]
['text':' TODO: (amy) add support for other frameworks','line_number':483,'multiline':False]
['text':' Convert to [x0, y0, x1, y1] format','line_number':496,'multiline':False]
['text':' Convert from relative [0, 1] to absolute [0, height] coordinates','line_number':499,'multiline':False]
['text':' Copied from transformers.models.owlvit.image_processing_owlvit.OwlViTImageProcessor.post_process_image_guided_detection','line_number':519,'multiline':False]
['text':' Convert to [x0, y0, x1, y1] format','line_number':552,'multiline':False]
['text':' Apply non-maximum suppression (NMS)','line_number':555,'multiline':False]
['text':' Mask self-IoU.','line_number':563,'multiline':False]
['text':' Convert from relative [0, 1] to absolute [0, height] coordinates','line_number':566,'multiline':False]
['text':' Compute box display alphas based on prediction scores','line_number':571,'multiline':False]
['text':' Select scores for boxes matching the current query:','line_number':576,'multiline':False]
['text':' Apply threshold on scores before scaling','line_number':581,'multiline':False]
['text':' Scale box alpha such that the best box for each query has alpha 1.0 and the worst box has alpha 0.1.','line_number':584,'multiline':False]
['text':' All other boxes will either belong to a different query, or will not be shown.','line_number':585,'multiline':False]
