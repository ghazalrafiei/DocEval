['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2022 SHI Labs and The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' Copied from transformers.models.detr.image_processing_detr.max_across_indices','line_number':62,'multiline':False]
['text':' Copied from transformers.models.detr.image_processing_detr.get_max_height_width','line_number':70,'multiline':False]
['text':' Copied from transformers.models.detr.image_processing_detr.make_pixel_mask','line_number':89,'multiline':False]
['text':' Copied from transformers.models.detr.image_processing_detr.binary_mask_to_rle','line_number':108,'multiline':False]
['text':' Copied from transformers.models.detr.image_processing_detr.convert_segmentation_to_rle','line_number':131,'multiline':False]
['text':' Copied from transformers.models.detr.image_processing_detr.remove_low_and_no_objects','line_number':153,'multiline':False]
['text':' Copied from transformers.models.detr.image_processing_detr.check_segment_validity','line_number':182,'multiline':False]
['text':' Get the mask associated with the k class','line_number':184,'multiline':False]
['text':' Compute the area of all the stuff in query k','line_number':188,'multiline':False]
['text':' Eliminate disconnected tiny segments','line_number':192,'multiline':False]
['text':' Copied from transformers.models.detr.image_processing_detr.compute_segments','line_number':201,'multiline':False]
['text':' Weigh each mask by its prediction score','line_number':224,'multiline':False]
['text':' [height, width]','line_number':226,'multiline':False]
['text':' Keep track of instances of each class','line_number':228,'multiline':False]
['text':' Check if mask exists and large enough to be a segment','line_number':234,'multiline':False]
['text':' Add current object segment to final segmentation map','line_number':245,'multiline':False]
['text':' Copied from transformers.models.maskformer.image_processing_maskformer.convert_segmentation_map_to_binary_masks','line_number':262,'multiline':False]
['text':' Get unique ids (class or instance ids based on input)','line_number':275,'multiline':False]
['text':' Drop background label if applicable','line_number':278,'multiline':False]
['text':' Generate a binary mask for each object instance','line_number':282,'multiline':False]
['text':' (num_labels, height, width)','line_number':284,'multiline':False]
['text':' Convert instance ids to class ids','line_number':286,'multiline':False]
['text':' Copied from transformers.models.detr.image_processing_detr.DetrImageProcessor.rescale','line_number':490,'multiline':False]
['text':' Copied from transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.convert_segmentation_map_to_binary_masks','line_number':519,'multiline':False]
['text':' All transformations expect numpy arrays.','line_number':575,'multiline':False]
['text':' Add channel dimension if missing - needed for certain transformations','line_number':609,'multiline':False]
['text':' TODO: (Amy)','line_number':618,'multiline':False]
['text':' Remork segmentation map processing to include reducing labels and resizing which doesn't','line_number':619,'multiline':False]
['text':' drop segment IDs > 255.','line_number':620,'multiline':False]
['text':' Remove extra channel dimension if added for processing','line_number':630,'multiline':False]
['text':' Default value','line_number':675,'multiline':False]
['text':' Copied from transformers.models.detr.image_processing_detr.DetrImageProcessor._pad_image','line_number':752,'multiline':False]
['text':' Copied from transformers.models.detr.image_processing_detr.DetrImageProcessor.pad','line_number':780,'multiline':False]
['text':' Use instance2class_id mapping per image','line_number':1017,'multiline':False]
['text':' Use instance2class_id mapping per image','line_number':1022,'multiline':False]
['text':' we cannot batch them since they don't share a common class size','line_number':1048,'multiline':False]
['text':' This needs to be tokenized before sending to the model.','line_number':1062,'multiline':False]
['text':' Copied from transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.post_process_semantic_segmentation','line_number':1067,'multiline':False]
['text':' [batch_size, num_queries, num_classes+1]','line_number':1087,'multiline':False]
['text':' [batch_size, num_queries, height, width]','line_number':1088,'multiline':False]
['text':' Remove the null class `[..., :-1]`','line_number':1090,'multiline':False]
['text':' [batch_size, num_queries, height, width]','line_number':1092,'multiline':False]
['text':' Semantic segmentation logits of shape (batch_size, num_classes, height, width)','line_number':1094,'multiline':False]
['text':' Resize logits and compute semantic segmentation maps','line_number':1098,'multiline':False]
['text':' [batch_size, num_queries, num_classes+1]','line_number':1167,'multiline':False]
['text':' [batch_size, num_queries, height, width]','line_number':1168,'multiline':False]
['text':' Loop over items in batch size','line_number':1175,'multiline':False]
['text':' [Q, K]','line_number':1179,'multiline':False]
['text':' scores_per_image, topk_indices = scores.flatten(0, 1).topk(self.num_queries, sorted=False)','line_number':1183,'multiline':False]
['text':' mask_pred = mask_pred.unsqueeze(1).repeat(1, self.sem_seg_head.num_classes, 1).flatten(0, 1)','line_number':1188,'multiline':False]
['text':' Only consider scores with confidence over [threshold] for demo','line_number':1191,'multiline':False]
['text':' if this is panoptic segmentation, we only keep the "thing" classes','line_number':1198,'multiline':False]
['text':' Get segmentation map and segment information of batch item','line_number':1218,'multiline':False]
['text':' Return segmentation map in run-length encoding (RLE) format','line_number':1230,'multiline':False]
['text':' Copied from transformers.models.maskformer.image_processing_maskformer.MaskFormerImageProcessor.post_process_panoptic_segmentation','line_number':1237,'multiline':False]
['text':' [batch_size, num_queries, num_classes+1]','line_number':1287,'multiline':False]
['text':' [batch_size, num_queries, height, width]','line_number':1288,'multiline':False]
['text':' [batch_size, num_queries, height, width]','line_number':1293,'multiline':False]
['text':' Predicted label and score of each query (batch_size, num_queries)','line_number':1295,'multiline':False]
['text':' Loop over items in batch size','line_number':1298,'multiline':False]
['text':' No mask found','line_number':1306,'multiline':False]
['text':' Get segmentation map and segment information of batch item','line_number':1313,'multiline':False]
