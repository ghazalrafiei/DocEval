['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2023 The HuggingFace Team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' See all Clvp models at https://huggingface.co/models?filter=clvp','line_number':60,'multiline':False]
['text':' Copied from transformers.models.clip.modeling_clip.contrastive_loss','line_number':64,'multiline':False]
['text':' Copied from transformers.models.clip.modeling_clip.clip_loss with clip->clvp, image_loss->speech_loss','line_number':69,'multiline':False]
['text':' Copied from transformers.models.llama.modeling_llama.rotate_half','line_number':76,'multiline':False]
['text':' add the bos token at the beginning','line_number':127,'multiline':False]
['text':' locate where the valid tokens end and then add the eos token','line_number':140,'multiline':False]
['text':' if there are no pad tokens present, then add eos to the end','line_number':147,'multiline':False]
['text':' Copied from transformers.models.llama.modeling_llama.LlamaRMSNorm with Llama->Clvp','line_number':231,'multiline':False]
['text':' Copied from transformers.models.clip.modeling_clip.CLIPAttention._shape','line_number':309,'multiline':False]
['text':' Raise error when position_ids is None but rotary_pos_emb is provided, because we need that when applying','line_number':324,'multiline':False]
['text':' rotary_pos_emb to query and key states.','line_number':325,'multiline':False]
['text':' get query proj','line_number':331,'multiline':False]
['text':' Partial rotary embedding','line_number':349,'multiline':False]
['text':' [batch_size, num_heads, seq_length, head_dim]','line_number':366,'multiline':False]
['text':' Mask heads if we want to','line_number':384,'multiline':False]
['text':' Copied from transformers.models.gpt2.modeling_gpt2.GPT2MLP with GPT2->ClvpDecoderMLP','line_number':506,'multiline':False]
['text':' residual connection','line_number':559,'multiline':False]
['text':' residual connection','line_number':565,'multiline':False]
['text':' define group norms to be used before each attention layer','line_number':602,'multiline':False]
['text':' define the attention layers','line_number':611,'multiline':False]
['text':' process text','line_number':646,'multiline':False]
['text':' construct attention mask if not given','line_number':656,'multiline':False]
['text':' We add bos and eos input_ids in the modeling file instead of the tokenizer file to keep the logic simple','line_number':660,'multiline':False]
['text':' This logic is specific to ClvpConditioningEncoder and not used by other modules.','line_number':661,'multiline':False]
['text':' process each log-mel spectrogram into a single vector','line_number':675,'multiline':False]
['text':' process each log-mel spectrogram into a single vector','line_number':686,'multiline':False]
['text':' repeat if there is either (1 text vs N audios) or (N texts vs 1 audio)','line_number':699,'multiline':False]
['text':' If there is N texts and M audios we will raise error since the number of text and audio must be same.','line_number':704,'multiline':False]
['text':' expand attention_mask and create position_ids if needed','line_number':963,'multiline':False]
['text':' [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]','line_number':965,'multiline':False]
['text':' take the mean over axis 1 and get pooled output','line_number':1010,'multiline':False]
['text':' apply the projection layer','line_number':1013,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1049,'multiline':False]
['text':' Prepare head mask if needed','line_number':1125,'multiline':False]
['text':' 1.0 in head_mask indicate we keep the head','line_number':1126,'multiline':False]
['text':' attention_probs has shape bsz x num_attention_heads x N x N','line_number':1127,'multiline':False]
['text':' head_mask has shape num_hidden_layers x batch x num_attention_heads x N x N','line_number':1128,'multiline':False]
['text':' Add last hidden state','line_number':1189,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1219,'multiline':False]
['text':' decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)','line_number':1253,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1294,'multiline':False]
['text':' Check if conditioning_embeds are provided or not, if yes then concatenate the bos_token_id at the end of the conditioning_embeds.','line_number':1331,'multiline':False]
['text':' Then we must subtract the positional_ids because during the forward pass it will be added anyways, so we must cancel them out here.','line_number':1332,'multiline':False]
['text':' subtract the positional_ids here','line_number':1348,'multiline':False]
['text':' only last token for inputs_ids if past is defined in kwargs','line_number':1375,'multiline':False]
['text':' Some generation methods already pass only the last input ID','line_number':1379,'multiline':False]
['text':' Default to old behavior: keep only final ID','line_number':1383,'multiline':False]
['text':' create position_ids on the fly for batch generation','line_number':1394,'multiline':False]
['text':' if `inputs_embeds` are passed, we only want to use them in the 1st generation step','line_number':1405,'multiline':False]
['text':' Shift so that tokens < n predict n','line_number':1473,'multiline':False]
['text':' Flatten the tokens','line_number':1476,'multiline':False]
['text':' Copied from transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel._reorder_cache','line_number':1494,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':1548,'multiline':False]
['text':' taken from the original repo,','line_number':1551,'multiline':False]
['text':' link : https://github.com/neonbjb/tortoise-tts/blob/4003544b6ff4b68c09856e04d3eff9da26d023c2/tortoise/api.py#L117','line_number':1552,'multiline':False]
['text':' This means that no stop tokens were found so the sentence was still being generated, in that case we don't need','line_number':1569,'multiline':False]
['text':' to apply any padding so just skip to the next sequence of tokens.','line_number':1570,'multiline':False]
['text':' Use CLVP model's config for some fields (if specified) instead of those of speech & text components.','line_number':1781,'multiline':False]
['text':' since we will get the embeds of shape `(batch_size, seq_len, embedding_dim)` during the forward pass','line_number':1802,'multiline':False]
['text':' we must convert it to tokens, to make it compaitable with speech_transformer','line_number':1803,'multiline':False]
['text':' normalized features','line_number':1825,'multiline':False]
['text':' cosine similarity as logits','line_number':1829,'multiline':False]
['text':' If the input sequences are larger than (self.config.decoder_config.max_text_tokens - 3) then raise error,','line_number':1917,'multiline':False]
['text':' because we need to add 3 tokens ( 1 bos tokens and 2 eos tokens) to the input_ids in ClvpConditioningEncoder to','line_number':1918,'multiline':False]
['text':' properly sample','line_number':1919,'multiline':False]
['text':' All unused kwargs must be model kwargs','line_number':1931,'multiline':False]
['text':' pad input_ids as specified in the original repo','line_number':1935,'multiline':False]
['text':' link: https://github.com/neonbjb/tortoise-tts/blob/80f89987a5abda5e2b082618cd74f9c7411141dc/tortoise/api.py#L380','line_number':1936,'multiline':False]
['text':' pad to pad_to_max_mel_tokens if given, to replicate the original repo logic','line_number':1960,'multiline':False]
['text':' link: https://github.com/neonbjb/tortoise-tts/blob/80f89987a5abda5e2b082618cd74f9c7411141dc/tortoise/api.py#L430','line_number':1961,'multiline':False]
['text':' normalized features','line_number':1985,'multiline':False]
['text':' cosine similarity as logits','line_number':1989,'multiline':False]
