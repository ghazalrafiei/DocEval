['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2019 The Open AI Team Authors and The HuggingFace Inc. team.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' Porting notes:','line_number':126,'multiline':False]
['text':' this one is modeled after XLMTokenizer','line_number':127,'multiline':False]
['text':'','line_number':128,'multiline':False]
['text':' added:','line_number':129,'multiline':False]
['text':' - src_vocab_file,','line_number':130,'multiline':False]
['text':' - tgt_vocab_file,','line_number':131,'multiline':False]
['text':' - langs,','line_number':132,'multiline':False]
['text':' cache of sm.MosesPunctNormalizer instance','line_number':215,'multiline':False]
['text':' cache of sm.MosesTokenizer instance','line_number':217,'multiline':False]
['text':' hack override','line_number':253,'multiline':False]
['text':' hack override','line_number':257,'multiline':False]
['text':' ignore `lang` which is currently isn't explicitly passed in tokenization_utils.py and always results in lang=en','line_number':364,'multiline':False]
['text':' if lang != self.src_lang:','line_number':365,'multiline':False]
['text':'     raise ValueError(f"Expected lang={self.src_lang}, but got {lang}")','line_number':366,'multiline':False]
['text':' remove BPE','line_number':396,'multiline':False]
['text':' detokenize','line_number':399,'multiline':False]
['text':' no bos used in fairseq','line_number':424,'multiline':False]
['text':' no bos used in fairseq','line_number':452,'multiline':False]
['text':' no bos used in fairseq','line_number':485,'multiline':False]
