['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2020, The RAG Authors and The HuggingFace Inc. team.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' remove question_encoder, generator kwargs from kwargs','line_number':325,'multiline':False]
['text':' Load and initialize the question_encoder and generator','line_number':331,'multiline':False]
['text':' The distinction between question_encoder and generator at the model level is made','line_number':332,'multiline':False]
['text':' by the value of the flag `is_generator` that we need to set correctly.','line_number':333,'multiline':False]
['text':' instantiate config with corresponding kwargs','line_number':379,'multiline':False]
['text':' from modeling_tf_bart.py','line_number':594,'multiline':False]
['text':' aliasing to minimize code changing','line_number':596,'multiline':False]
['text':' whether retriever has to be used','line_number':599,'multiline':False]
['text':' encoder_outputs are pre-computed during RAG-token generation','line_number':606,'multiline':False]
['text':' see https://github.com/huggingface/transformers/blob/main/src/transformers/models/dpr/modeling_tf_dpr.py#L91','line_number':612,'multiline':False]
['text':' hidden states of question encoder => pooler_output','line_number':615,'multiline':False]
['text':' compute doc_scores','line_number':636,'multiline':False]
['text':' Decoder input without context documents','line_number':669,'multiline':False]
['text':' don't output retrieved docs','line_number':699,'multiline':False]
['text':' instantiate model','line_number':752,'multiline':False]
['text':' Adapted from https://github.com/huggingface/transformers/blob/main/src/transformers/modeling_tf_bart.py','line_number':765,'multiline':False]
['text':' if past is defined use only last decoder_input_ids','line_number':778,'multiline':False]
['text':' reshapes into (batch size, num beams, n_docs, ...), the cache format expected by RAG','line_number':818,'multiline':False]
['text':' reshapes back into the shape expected by beam search','line_number':824,'multiline':False]
['text':' RAG-token marginalization','line_number':834,'multiline':False]
['text':' twice','line_number':839,'multiline':False]
['text':' needs kwargs for generation','line_number':867,'multiline':False]
['text':' from modeling_tf_bart.py','line_number':935,'multiline':False]
['text':' Handle `generation_config` and kwargs that might update it','line_number':1064,'multiline':False]
['text':' All unused kwargs must be model kwargs','line_number':1068,'multiline':False]
['text':' set default parameters','line_number':1070,'multiline':False]
['text':' retrieve docs','line_number':1073,'multiline':False]
['text':' compute doc_scores','line_number':1093,'multiline':False]
['text':' expand batch_size & num_beam dimensions','line_number':1127,'multiline':False]
['text':' split n_docs dimensions','line_number':1130,'multiline':False]
['text':' repeat same last hidden states over `num_beams` dimension','line_number':1134,'multiline':False]
['text':' merge `batch_size`, `num_beams`, `num_docs` dims again','line_number':1138,'multiline':False]
['text':' correctly extend last_hidden_state and attention mask','line_number':1142,'multiline':False]
['text':' define start_len & additional parameters','line_number':1150,'multiline':False]
['text':' Adapted from tf_t5's & tf_bart's _shift_right','line_number':1217,'multiline':False]
['text':' replace possible -100 values in labels by `pad_token_id`','line_number':1234,'multiline':False]
['text':' "Verify that `labels` has only positive values and -100"','line_number':1241,'multiline':False]
['text':' Make sure the assertion op is called by wrapping the result in an identity no-op','line_number':1244,'multiline':False]
['text':' nll stands for 'negative log likelihood'','line_number':1250,'multiline':False]
['text':' shift tokens left (from original Pytorch's version)','line_number':1253,'multiline':False]
['text':' Adopted modeling_tf_bart + add smooth_loss to match with pytorch version','line_number':1264,'multiline':False]
['text':' Matt: As written, this loss is not XLA-compatible, but it's doing some very weird things','line_number':1267,'multiline':False]
['text':'       and I don't feel comfortable converting it.','line_number':1268,'multiline':False]
['text':' convert to logits','line_number':1274,'multiline':False]
['text':' sum and squeeze like torch','line_number':1288,'multiline':False]
['text':' instantiate model','line_number':1332,'multiline':False]
['text':' needs kwargs for generation','line_number':1381,'multiline':False]
['text':' from modeling_tf_bart.py','line_number':1450,'multiline':False]
['text':' shift tokens left','line_number':1511,'multiline':False]
['text':' bos_token_id is None for T5','line_number':1517,'multiline':False]
['text':' seq_logits.shape = (batch*n_docs, tgt_len , vocabs)','line_number':1530,'multiline':False]
['text':' (batch_size, n_docs, tgt_len, vocabs)','line_number':1534,'multiline':False]
['text':' done twice to get 4-D','line_number':1537,'multiline':False]
['text':' RAG-sequence marginalization','line_number':1539,'multiline':False]
['text':' calculate loss','line_number':1545,'multiline':False]
['text':' n_docs dimension','line_number':1546,'multiline':False]
['text':' logits dimension','line_number':1547,'multiline':False]
['text':' last-axis gathering only - use 2D-reshape-trick for Torch's style nD gathering','line_number':1551,'multiline':False]
['text':' 2d-gather torch equivalent: https://stackoverflow.com/questions/52129909/tensorflow-equivalent-of-torch-gather','line_number':1553,'multiline':False]
['text':' reshape 2D','line_number':1559,'multiline':False]
['text':' also 2D-index','line_number':1562,'multiline':False]
['text':' total sum of all (normalised) logits','line_number':1567,'multiline':False]
['text':' sum over tokens, exclude bos while scoring','line_number':1571,'multiline':False]
['text':' logsumexp over docs','line_number':1578,'multiline':False]
['text':' defaults to True','line_number':1599,'multiline':False]
['text':' defaults to 1','line_number':1600,'multiline':False]
['text':' defaults to 1','line_number':1601,'multiline':False]
['text':' put here so that not confused with num_doc_return_sequences','line_number':1673,'multiline':False]
['text':' first, generate beams from documents:','line_number':1679,'multiline':False]
['text':' (n_docs, max_len)','line_number':1680,'multiline':False]
['text':' n_docs * n_beam, tgt_len','line_number':1685,'multiline':False]
['text':' do_deduplication -- for TF, work on Eager mode only!','line_number':1687,'multiline':False]
['text':' after deduplication, this number can be less than n_docs*n_beam','line_number':1692,'multiline':False]
['text':' then, run model forwards to get nll scores:','line_number':1694,'multiline':False]
['text':' input_ids is None, need context_input_ids/mask and doc_scores','line_number':1698,'multiline':False]
['text':' (num_candidates*n_docs, max_len)','line_number':1710,'multiline':False]
['text':' doc_scores.shape = [batch, n_docs]','line_number':1715,'multiline':False]
['text':' [num_candidates, n_docs]','line_number':1716,'multiline':False]
['text':' add hypothesis','line_number':1729,'multiline':False]
['text':' used by generate(): tensors is a (batched) list of (candidates, len); len is varied across batch','line_number':1736,'multiline':False]
['text':' Initialize padded tensor with shape ( all_candidates , max_candidate_length ),','line_number':1738,'multiline':False]
['text':' where all_candidates counted from all inputs','line_number':1739,'multiline':False]
['text':' Normal tensor doesn't support slice assignment, so we need tf.Variable','line_number':1743,'multiline':False]
['text':' Assign, and then convert back to tensor','line_number':1746,'multiline':False]
