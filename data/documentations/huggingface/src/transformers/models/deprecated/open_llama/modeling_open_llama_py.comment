['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2023 EleutherAI and the HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' This code is based on EleutherAI's GPT-NeoX library and the GPT-NeoX','line_number':4,'multiline':False]
['text':' and OPT implementations in this library. It has been modified from its','line_number':5,'multiline':False]
['text':' original forms to accommodate minor architectural differences compared','line_number':6,'multiline':False]
['text':' to GPT-NeoX and OPT used by the Meta AI team that trained the model.','line_number':7,'multiline':False]
['text':'','line_number':8,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':9,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':10,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':11,'multiline':False]
['text':'','line_number':12,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':13,'multiline':False]
['text':'','line_number':14,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':15,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':16,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':17,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':18,'multiline':False]
['text':' limitations under the License.','line_number':19,'multiline':False]
['text':' Copied from transformers.models.llama.modeling_llama.LlamaRMSNorm with Llama->OpenLlama','line_number':48,'multiline':False]
['text':' Copied from transformers.models.llama.modeling_llama.LlamaRotaryEmbedding with Llama->OpenLlama','line_number':66,'multiline':False]
['text':' Build here to make `torch.jit.trace` work.','line_number':77,'multiline':False]
['text':' Different from paper, but it uses a different permutation in order to obtain the same calculation','line_number':87,'multiline':False]
['text':' x: [bs, num_attention_heads, seq_len, head_size]','line_number':93,'multiline':False]
['text':' Copied from transformers.models.llama.modeling_llama.LlamaLinearScalingRotaryEmbedding with Llama->OpenLlama','line_number':103,'multiline':False]
['text':' Different from paper, but it uses a different permutation in order to obtain the same calculation','line_number':117,'multiline':False]
['text':' Copied from transformers.models.llama.modeling_llama.LlamaDynamicNTKScalingRotaryEmbedding with Llama->OpenLlama','line_number':123,'multiline':False]
['text':' Different from paper, but it uses a different permutation in order to obtain the same calculation','line_number':144,'multiline':False]
['text':' Copied from transformers.models.llama.modeling_llama.apply_rotary_pos_emb','line_number':157,'multiline':False]
['text':' Copied from transformers.models.llama.modeling_llama.LlamaAttention._init_rope with Llama->OpenLlama','line_number':229,'multiline':False]
['text':' [bsz, nh, t, hd]','line_number':280,'multiline':False]
['text':' reuse k, v, self_attention','line_number':283,'multiline':False]
['text':' upcast attention to fp32','line_number':316,'multiline':False]
['text':' Self Attention','line_number':378,'multiline':False]
['text':' Fully Connected','line_number':389,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':538,'multiline':False]
['text':' retrieve input_ids and inputs_embeds','line_number':568,'multiline':False]
['text':' embed positions','line_number':603,'multiline':False]
['text':' decoder layers','line_number':618,'multiline':False]
['text':' add hidden states from the last decoder layer','line_number':659,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':683,'multiline':False]
['text':' decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)','line_number':751,'multiline':False]
['text':' move labels to correct device to enable model parallelism','line_number':774,'multiline':False]
['text':' Shift so that tokens < n predict n','line_number':776,'multiline':False]
['text':' Flatten the tokens','line_number':779,'multiline':False]
['text':' Enable model parallelism','line_number':783,'multiline':False]
['text':' Some generation methods already pass only the last input ID','line_number':805,'multiline':False]
['text':' Default to old behavior: keep only final ID','line_number':809,'multiline':False]
['text':' create position_ids on the fly for batch generation','line_number':816,'multiline':False]
['text':' if `inputs_embeds` are passed, we only want to use them in the 1st generation step','line_number':822,'multiline':False]
['text':' Initialize weights and apply final processing','line_number':870,'multiline':False]
