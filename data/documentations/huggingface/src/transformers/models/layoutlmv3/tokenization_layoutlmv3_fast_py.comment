['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2022 The HuggingFace Inc. team.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' The lists 'sep' and 'cls' must be cased in tuples for the object `post_processor_class`','line_number':196,'multiline':False]
['text':' additional properties','line_number':217,'multiline':False]
['text':' Copied from transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.__call__','line_number':225,'multiline':False]
['text':' Input type checking for clearer error','line_number':266,'multiline':False]
['text':' Strings are fine','line_number':269,'multiline':False]
['text':' List are fine as long as they are...','line_number':272,'multiline':False]
['text':' ... empty','line_number':274,'multiline':False]
['text':' ... list of strings','line_number':277,'multiline':False]
['text':' ... list with an empty list or with a list of strings','line_number':280,'multiline':False]
['text':' in case text + text_pair are provided, text = questions, text_pair = words','line_number':288,'multiline':False]
['text':' in case only text is provided => must be words','line_number':297,'multiline':False]
['text':' Copied from transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.batch_encode_plus','line_number':375,'multiline':False]
['text':' Backward compatibility for 'truncation_strategy', 'pad_to_max_length'','line_number':402,'multiline':False]
['text':' Copied from transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.tokenize','line_number':434,'multiline':False]
['text':' Copied from transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.encode_plus','line_number':444,'multiline':False]
['text':' Backward compatibility for 'truncation_strategy', 'pad_to_max_length'','line_number':479,'multiline':False]
['text':' Set the truncation and padding strategy and restore the initial configuration','line_number':539,'multiline':False]
['text':' we set this to True as LayoutLMv3 always expects pretokenized inputs','line_number':554,'multiline':False]
['text':' Convert encoding to dict','line_number':557,'multiline':False]
['text':' `Tokens` has type: Tuple[','line_number':558,'multiline':False]
['text':'                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],','line_number':559,'multiline':False]
['text':'                       List[EncodingFast]','line_number':560,'multiline':False]
['text':'                    ]','line_number':561,'multiline':False]
['text':' with nested dimensions corresponding to batch, overflows, sequence length','line_number':562,'multiline':False]
['text':' we use offsets to create the labels','line_number':572,'multiline':False]
['text':' Convert the output to have dict[list] from list[dict] and remove the additional overflows dimension','line_number':579,'multiline':False]
['text':' From (variable) shape (batch, overflows, sequence length) to ~ (batch * overflows, sequence length)','line_number':580,'multiline':False]
['text':' (we say ~ because the number of overflow varies with the example in the batch)','line_number':581,'multiline':False]
['text':'','line_number':582,'multiline':False]
['text':' To match each overflowing sample with the original sample in the batch','line_number':583,'multiline':False]
['text':' we add an overflow_to_sample_mapping array (see below)','line_number':584,'multiline':False]
['text':' If returning overflowing tokens, we need to return a mapping','line_number':591,'multiline':False]
['text':' from the batch idx to the original sample','line_number':592,'multiline':False]
['text':' create the token boxes','line_number':602,'multiline':False]
['text':' optionally, create the labels','line_number':633,'multiline':False]
['text':' Use the real label id for the first token of the word, and padding ids for the remaining tokens','line_number':651,'multiline':False]
['text':' finally, remove offsets if the user didn't want them','line_number':666,'multiline':False]
['text':' Copied from transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast._encode_plus','line_number':672,'multiline':False]
['text':' make it a batched input','line_number':695,'multiline':False]
['text':' 2 options:','line_number':696,'multiline':False]
['text':' 1) only text, in case text must be a list of str','line_number':697,'multiline':False]
['text':' 2) text + text_pair, in which case text = str and text_pair a list of str','line_number':698,'multiline':False]
['text':' Return tensor is None, then we can remove the leading batch axis','line_number':724,'multiline':False]
['text':' Overflowing tokens are returned as a batch of output so we keep them in this case','line_number':725,'multiline':False]
['text':' Copied from transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast._pad','line_number':739,'multiline':False]
['text':' Load from model defaults','line_number':771,'multiline':False]
['text':' Initialize attention mask if not present.','line_number':785,'multiline':False]
['text':' Copied from transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast.save_vocabulary','line_number':824,'multiline':False]
