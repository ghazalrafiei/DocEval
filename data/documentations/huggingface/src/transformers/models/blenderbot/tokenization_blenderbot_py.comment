['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2021 The Facebook Inc. and The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.bytes_to_unicode','line_number':49,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.get_pairs','line_number':74,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer.__init__ with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':173,'multiline':False]
['text':' Mask token behave like a normal word, i.e. include the space before it','line_number':196,'multiline':False]
['text':' these special tokens are not part of the vocab.json, let's add them in the correct order','line_number':203,'multiline':False]
['text':' how to handle errors in decoding','line_number':208,'multiline':False]
['text':' Should have added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions','line_number':218,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer.vocab_size with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':235,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer.get_vocab with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':239,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer.bpe with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':245,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer._tokenize with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':288,'multiline':False]
['text':' Maps all our bytes to unicode strings, avoiding control tokens of the BPE (spaces in our case)','line_number':295,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer._convert_token_to_id with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':299,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer._convert_id_to_token with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':304,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer.convert_tokens_to_string with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':309,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer.save_vocabulary with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':316,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer.get_special_tokens_mask with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':346,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer.create_token_type_ids_from_sequences with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':374,'multiline':False]
['text':' Copied from transformers.models.roberta.tokenization_roberta.RobertaTokenizer.prepare_for_tokenization with Roberta->Blenderbot, RoBERTa->Blenderbot','line_number':398,'multiline':False]
