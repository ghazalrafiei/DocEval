['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2023 The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' Add this unused argument to keep some important Copied from statements','line_number':150,'multiline':False]
['text':' Vocab    |    0    |    1    |   2    |    3    |  4   |  5   |  6   |   7  |   8  |  9','line_number':156,'multiline':False]
['text':' -------- | ------- | ------- | ------ | ------- | ---- | ---- | ---- | ---- | ---- | ----','line_number':157,'multiline':False]
['text':' spm  | '<unk>'   | '<s>' | '</s>' | 'an' | 'en' | '_d' | 'er' | 'in' | '_s' | '_a'','line_number':158,'multiline':False]
['text':' fairseq  | '<pad>'   | '<unk>' | '<s>' | '</s>' | 'an' | 'en' | '▁d' | 'er' | 'in' | '▁s'','line_number':159,'multiline':False]
['text':' Mimic fairseq token-to-id alignment for the first 4 token','line_number':161,'multiline':False]
['text':' The first "real" token "an" has position 4 in the original fairseq vocab and position 3 in the spm vocab','line_number':169,'multiline':False]
['text':' Copied from transformers.models.nllb.tokenization_nllb.NllbTokenizer.__getstate__','line_number':195,'multiline':False]
['text':' Copied from transformers.models.nllb.tokenization_nllb.NllbTokenizer.__setstate__','line_number':202,'multiline':False]
['text':' for backward compatibility','line_number':206,'multiline':False]
['text':' Copied from transformers.models.nllb.tokenization_nllb.NllbTokenizer.src_lang','line_number':291,'multiline':False]
['text':' Copied from transformers.models.nllb.tokenization_nllb.NllbTokenizer.get_special_tokens_mask','line_number':315,'multiline':False]
['text':' Copied from transformers.models.nllb.tokenization_nllb.NllbTokenizer.build_inputs_with_special_tokens','line_number':346,'multiline':False]
['text':' We don't expect to process pairs, but leave the pair logic for API consistency','line_number':371,'multiline':False]
['text':' Copied from transformers.models.nllb.tokenization_nllb.NllbTokenizer.create_token_type_ids_from_sequences','line_number':374,'multiline':False]
['text':' Copied from transformers.models.t5.tokenization_t5.T5Tokenizer.get_spm_processor','line_number':425,'multiline':False]
['text':' no dependency on protobuf','line_number':428,'multiline':False]
['text':' Copied from transformers.models.t5.tokenization_t5.T5Tokenizer.tokenize','line_number':443,'multiline':False]
['text':' Copied from transformers.models.t5.tokenization_t5.T5Tokenizer._tokenize','line_number':458,'multiline':False]
['text':' 1. Encode string + prefix ex: "<unk> Hey"','line_number':473,'multiline':False]
['text':' 2. Remove self.unk_token from ['<','unk','>', '▁Hey']','line_number':475,'multiline':False]
['text':' Need to return unknown token if the SP model returned 0','line_number':482,'multiline':False]
['text':' Copied from transformers.models.nllb.tokenization_nllb.NllbTokenizer.save_vocabulary','line_number':497,'multiline':False]
['text':' Copied from transformers.models.nllb.tokenization_nllb.NllbTokenizer.prepare_seq2seq_batch with eng_Latn->eng, fra_Latn->fra','line_number':515,'multiline':False]
['text':' Copied from transformers.models.nllb.tokenization_nllb.NllbTokenizer._switch_to_input_mode','line_number':528,'multiline':False]
['text':' Copied from transformers.models.nllb.tokenization_nllb.NllbTokenizer._switch_to_target_mode','line_number':532,'multiline':False]
['text':' https://github.com/facebookresearch/fairseq2/blob/c53f18e6be6b8b46b722f2249b8397b7eccd7ad3/src/fairseq2/models/nllb/tokenizer.py#L112-L116','line_number':551,'multiline':False]
