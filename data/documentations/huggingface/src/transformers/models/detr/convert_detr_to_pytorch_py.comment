['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2023 The HuggingFace Inc. team.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' initialize config','line_number':36,'multiline':False]
['text':' set label attributes','line_number':46,'multiline':False]
['text':' here we list all keys to be renamed (original name on the left, our name on the right)','line_number':63,'multiline':False]
['text':' stem','line_number':66,'multiline':False]
['text':' fmt: off','line_number':67,'multiline':False]
['text':' stages','line_number':73,'multiline':False]
['text':' shortcut','line_number':76,'multiline':False]
['text':' 3 convs','line_number':108,'multiline':False]
['text':' fmt: on','line_number':140,'multiline':False]
['text':' encoder layers: output projection, 2 feedforward neural networks and 2 layernorms','line_number':143,'multiline':False]
['text':' decoder layers: 2 times output projection, 2 feedforward neural networks and 3 layernorms','line_number':167,'multiline':False]
['text':' convolutional projection + query embeddings + layernorm of decoder + class and bounding box heads','line_number':210,'multiline':False]
['text':' first: transformer encoder','line_number':242,'multiline':False]
['text':' read in weights + bias of input projection layer (in PyTorch's MultiHeadAttention, this is a single matrix + bias)','line_number':244,'multiline':False]
['text':' next, add query, keys and values (in that order) to the state dict','line_number':247,'multiline':False]
['text':' next: transformer decoder (which is a bit more complex because it also includes cross-attention)','line_number':254,'multiline':False]
['text':' read in weights + bias of input projection layer of self-attention','line_number':256,'multiline':False]
['text':' next, add query, keys and values (in that order) to the state dict','line_number':259,'multiline':False]
['text':' read in weights + bias of input projection layer of cross-attention','line_number':266,'multiline':False]
['text':' next, add query, keys and values (in that order) of cross-attention to the state dict','line_number':271,'multiline':False]
['text':' We will verify our results on an image of cute cats','line_number':280,'multiline':False]
['text':' load default config','line_number':294,'multiline':False]
['text':' load original model from torch hub','line_number':297,'multiline':False]
['text':' rename keys','line_number':305,'multiline':False]
['text':' query, key and value matrices need special treatment','line_number':310,'multiline':False]
['text':' important: we need to prepend a prefix to each of the base model keys as the head models use different attributes for them','line_number':312,'multiline':False]
['text':' finally, create HuggingFace model and load state dict','line_number':336,'multiline':False]
['text':' verify our conversion on an image','line_number':341,'multiline':False]
['text':' Save model and image processor','line_number':358,'multiline':False]
['text':' Upload model and image processor to the hub','line_number':365,'multiline':False]
