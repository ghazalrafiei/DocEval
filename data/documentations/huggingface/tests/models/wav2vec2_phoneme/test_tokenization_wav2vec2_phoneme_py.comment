['text':' coding=utf-8','line_number':1,'multiline':False]
['text':' Copyright 2021 The HuggingFace Team. All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]
['text':' limitations under the License.','line_number':14,'multiline':False]
['text':' overwrite since phonemes require specific creation','line_number':60,'multiline':False]
['text':' toks_str = [t[1] for t in toks]','line_number':69,'multiline':False]
['text':' Ensure consistency','line_number':72,'multiline':False]
['text':' check adding a single token','line_number':92,'multiline':False]
['text':' xxx should be last token','line_number':95,'multiline':False]
['text':' aaa and ccc should be after xxx and 2 after aaa','line_number':99,'multiline':False]
['text':' mai should be <unk> (=3)','line_number':102,'multiline':False]
['text':' fmt: off','line_number':165,'multiline':False]
['text':' fmt: on','line_number':170,'multiline':False]
['text':' decode with word_del_token filter','line_number':172,'multiline':False]
['text':' decode with no word_del_token filter','line_number':178,'multiline':False]
['text':' fmt: off','line_number':242,'multiline':False]
['text':' fmt: on','line_number':247,'multiline':False]
['text':' fmt: off','line_number':261,'multiline':False]
['text':' ksssɾɾ|ɾɾ<pad>ɾɾ|<pad>ɾlll|ɭʲ -> k s ɾ ɾ | ɾ l | ɭʲ"','line_number':262,'multiline':False]
['text':' fmt: on','line_number':264,'multiline':False]
['text':' check Wav2Vec2CTCTokenizerOutput keys for char','line_number':267,'multiline':False]
['text':' check that order of chars is correct and identical for both outputs','line_number':273,'multiline':False]
['text':' check that offsets are actually correct for char','line_number':279,'multiline':False]
['text':' 0-1 is 11, 1-4 is 5, 4-6 is first 15, 6-7 is <pad> (thus not shown), 7-9 is second 15, 9-10 is word_delimiter_token,','line_number':280,'multiline':False]
['text':' 10-11 is <pad> (thus not shown), 11-12 is third 15, 12-15 is 8, 15-16 is word_delimiter_token, 16-17 is 98','line_number':281,'multiline':False]
['text':' transform list to ModelOutput','line_number':296,'multiline':False]
['text':' fmt: off','line_number':311,'multiline':False]
['text':' fmt: on','line_number':316,'multiline':False]
['text':' We assume that `decode` works as expected. All we will check now is','line_number':318,'multiline':False]
['text':' the output type is correct and the output is identical to `decode`','line_number':319,'multiline':False]
['text':' char','line_number':321,'multiline':False]
['text':' overwrite common','line_number':342,'multiline':False]
['text':' We usually have added tokens from the start in tests because our vocab fixtures are','line_number':352,'multiline':False]
['text':' smaller than the original vocabs - let's not assert this','line_number':353,'multiline':False]
['text':' self.assertEqual(vocab_size, all_size)','line_number':354,'multiline':False]
['text':' The default common tokenizer tests assumes that the output of `convert_tokens_to_string` is a string which','line_number':403,'multiline':False]
['text':' is not the case for Wav2Vec2PhonemeCTCTokenizer.','line_number':404,'multiline':False]
