['text':' The TF tokenizers are usually going to be used as pretrained tokenizers from existing model checkpoints,','line_number':38,'multiline':False]
['text':' so that's what we focus on here.','line_number':39,'multiline':False]
['text':' repeat for when fast_bert_tokenizer=false','line_number':46,'multiline':False]
['text':' Build model with some sample inputs','line_number':101,'multiline':False]
['text':' We may see small differences because the loaded model is compiled, so we need an epsilon for the test','line_number':107,'multiline':False]
