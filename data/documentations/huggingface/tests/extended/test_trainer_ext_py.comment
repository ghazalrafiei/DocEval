['text':' Copyright 2020 The HuggingFace Team. All rights reserved.','line_number':1,'multiline':False]
['text':'','line_number':2,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':3,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':4,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':5,'multiline':False]
['text':'','line_number':6,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':7,'multiline':False]
['text':'','line_number':8,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':9,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':10,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':11,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':12,'multiline':False]
['text':' limitations under the License.','line_number':13,'multiline':False]
['text':' noqa','line_number':47,'multiline':False]
['text':' verify that the trainer can handle non-distributed with n_gpu > 1','line_number':97,'multiline':False]
['text':' verify that the trainer can handle distributed with n_gpu > 1','line_number':102,'multiline':False]
['text':' XXX: apex breaks the trainer if it's run twice e.g. run_seq2seq.main() from the same','line_number':110,'multiline':False]
['text':' program and it breaks other tests that run from the same pytest worker, therefore until this is','line_number':111,'multiline':False]
['text':' sorted out it must be run only in an external program, that is distributed=True in this','line_number':112,'multiline':False]
['text':' test and only under one or more gpus - if we want cpu will need to make a special test','line_number':113,'multiline':False]
['text':'','line_number':114,'multiline':False]
['text':' specifically to the problem traced it to self.optimizer.step() - if it's run 2nd time via','line_number':115,'multiline':False]
['text':' 2nd main() call it botches the future eval.','line_number':116,'multiline':False]
['text':'','line_number':117,'multiline':False]
['text':' test 2nd time - was getting eval_loss': nan'','line_number':119,'multiline':False]
['text':' to reproduce the problem set distributed=False','line_number':120,'multiline':False]
['text':' as each sub-test is slow-ish split into multiple sub-tests to avoid CI timeout','line_number':126,'multiline':False]
['text':' test with the default log_level - should be info and thus log info once','line_number':128,'multiline':False]
['text':' test with low log_level and log_level_replica - should be noisy on all processes','line_number':130,'multiline':False]
['text':' now the info string should appear twice on 2 processes','line_number':131,'multiline':False]
['text':' test with high log_level and low log_level_replica','line_number':133,'multiline':False]
['text':' now the info string should appear once only on the replica','line_number':134,'multiline':False]
['text':' test with high log_level and log_level_replica - should be quiet on all processes','line_number':136,'multiline':False]
['text':' Check metrics','line_number':159,'multiline':False]
['text':' test if do_predict saves generations and metrics','line_number':168,'multiline':False]
['text':' force run in a new process','line_number':188,'multiline':False]
['text':' to allow deterministic fixed memory usage','line_number':192,'multiline':False]
['text':' Check metrics','line_number':195,'multiline':False]
['text':' sshleifer/student_marian_en_ro_6_1 has 54M parameter, 29M of which is `nn.Embedding` which','line_number':212,'multiline':False]
['text':' doesn't get quantized and remains in fp32. Therefore we only have 25M parameters quantized','line_number':213,'multiline':False]
['text':' in 2 bytes and the diff in optim memory usage is derived as so:','line_number':214,'multiline':False]
['text':'','line_number':215,'multiline':False]
['text':' - normal 25*8=~200MB (8 bytes per param)','line_number':216,'multiline':False]
['text':' - bnb    25*2= ~50MB (2 bytes per param)','line_number':217,'multiline':False]
['text':'','line_number':218,'multiline':False]
['text':' Thus we should expect ~150MB total memory saved.','line_number':219,'multiline':False]
['text':'','line_number':220,'multiline':False]
['text':' Peak memory should be the same - the total should be different by about that same margin','line_number':221,'multiline':False]
['text':'','line_number':222,'multiline':False]
['text':' After leaving a small margin to accommodate for differences between gpus let's check','line_number':223,'multiline':False]
['text':' that we have at least 120MB in savings','line_number':224,'multiline':False]
['text':' uncomment the following if this test starts failing - requires py38 for a new print feature','line_number':227,'multiline':False]
['text':' gpu_peak_mem_diff = gpu_peak_mem_orig - gpu_peak_mem_bnb','line_number':228,'multiline':False]
['text':' print(f"{gpu_alloc_mem_orig=}MB {gpu_peak_mem_orig=}MB {gpu_alloc_mem_orig+gpu_peak_mem_orig=}MB")','line_number':229,'multiline':False]
['text':' print(f" {gpu_alloc_mem_bnb=}MB  {gpu_peak_mem_bnb=}MB  {gpu_alloc_mem_bnb+gpu_peak_mem_bnb=}MB")','line_number':230,'multiline':False]
['text':' print(f"{gpu_alloc_mem_diff=}MB")','line_number':231,'multiline':False]
['text':' print(f"{gpu_peak_mem_diff=}MB")','line_number':232,'multiline':False]
['text':' print(f"{gpu_total_mem_orig=}MB, {gpu_total_mem_bnb=}MB")','line_number':233,'multiline':False]
['text':' print(f"{gpu_total_mem_diff=}MB, {gpu_total_mem_diff=}MB")','line_number':234,'multiline':False]
['text':' keep for quick debug','line_number':344,'multiline':False]
['text':' print(" ".join([f"\nPYTHONPATH={self.src_dir_str}"] +cmd)); die','line_number':345,'multiline':False]
