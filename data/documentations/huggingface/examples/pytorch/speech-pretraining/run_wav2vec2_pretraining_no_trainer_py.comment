['text':'!/usr/bin/env python','line_number':1,'multiline':False]
['text':' coding=utf-8','line_number':2,'multiline':False]
['text':' Copyright 2021 The HuggingFace Inc. team. All rights reserved.','line_number':3,'multiline':False]
['text':'','line_number':4,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':5,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':6,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':7,'multiline':False]
['text':'','line_number':8,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':9,'multiline':False]
['text':'','line_number':10,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':11,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':12,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':13,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':14,'multiline':False]
['text':' reformat list to dict and set to pytorch format','line_number':324,'multiline':False]
['text':' make sure masked sequence length is a Python scalar','line_number':336,'multiline':False]
['text':' make sure that no loss is computed on padded inputs','line_number':339,'multiline':False]
['text':' compute real output lengths according to convolution formula','line_number':341,'multiline':False]
['text':' sample randomly masked indices','line_number':348,'multiline':False]
['text':' sample negative indices','line_number':356,'multiline':False]
['text':' See all possible arguments in src/transformers/args.py','line_number':389,'multiline':False]
['text':' or by passing the --help flag to this script.','line_number':390,'multiline':False]
['text':' We now keep distinct sets of args, for a cleaner separation of concerns.','line_number':391,'multiline':False]
['text':' Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The','line_number':394,'multiline':False]
['text':' information sent is the one passed as arguments along with your Python/PyTorch versions.','line_number':395,'multiline':False]
['text':' Initialize the accelerator. We will let the accelerator handle device placement for us in this example.','line_number':398,'multiline':False]
['text':' set up weights and biases if available','line_number':405,'multiline':False]
['text':' If passed along, set the training seed now.','line_number':414,'multiline':False]
['text':' Handle the repository creation','line_number':418,'multiline':False]
['text':' Retrieve of infer repo_name','line_number':421,'multiline':False]
['text':' Create repo and retrieve repo_id','line_number':425,'multiline':False]
['text':' Clone repo locally','line_number':427,'multiline':False]
['text':' 1. Download and create train, validation dataset','line_number':433,'multiline':False]
['text':' We load all dataset configuration and datset split pairs passed in','line_number':434,'multiline':False]
['text':' ``args.dataset_config_names`` and ``args.dataset_split_names``','line_number':435,'multiline':False]
['text':' load dataset','line_number':438,'multiline':False]
['text':' Next, we concatenate all configurations and splits into a single training dataset','line_number':447,'multiline':False]
['text':' Take ``args.validation_split_percentage`` from the training dataset for the validation_split_percentage','line_number':454,'multiline':False]
['text':' 2. Now we preprocess the datasets including loading the audio, resampling and normalization','line_number':467,'multiline':False]
['text':' Thankfully, `datasets` takes care of automatically loading and resampling the audio,','line_number':468,'multiline':False]
['text':' so that we just need to set the correct target sampling rate and normalize the input','line_number':469,'multiline':False]
['text':' via the `feature_extractor`','line_number':470,'multiline':False]
['text':' make sure that dataset decodes audio with correct sampling rate','line_number':473,'multiline':False]
['text':' only normalized-inputs-training is supported','line_number':478,'multiline':False]
['text':' set max & min audio length in number of samples','line_number':484,'multiline':False]
['text':' load via mapped files via path','line_number':499,'multiline':False]
['text':' load audio files into numpy arrays','line_number':504,'multiline':False]
['text':' for large datasets it is advised to run the preprocessing on a','line_number':522,'multiline':False]
['text':' single machine first with ``args.preprocessing_only`` since there will mostly likely','line_number':523,'multiline':False]
['text':' be a timeout when running the script in distributed mode.','line_number':524,'multiline':False]
['text':' In a second step ``args.preprocessing_only`` can then be set to `False` to load the','line_number':525,'multiline':False]
['text':' cached dataset','line_number':526,'multiline':False]
['text':' 3. Load model','line_number':530,'multiline':False]
['text':' pretraining is only supported for "newer" stable layer norm architecture','line_number':533,'multiline':False]
['text':' apply_spec_augment has to be True, mask_feature_prob has to be 0.0','line_number':534,'multiline':False]
['text':' initialize random model','line_number':541,'multiline':False]
['text':' Activate gradient checkpointing if needed','line_number':544,'multiline':False]
['text':' 4. Define data collator, optimizer and scheduler','line_number':548,'multiline':False]
['text':' Optimizer','line_number':570,'multiline':False]
['text':' Prepare everything with our `accelerator`.','line_number':578,'multiline':False]
['text':' Scheduler and math around the number of training steps.','line_number':583,'multiline':False]
['text':' Afterwards we recalculate our number of training epochs','line_number':596,'multiline':False]
['text':' 5. Train','line_number':599,'multiline':False]
['text':' Only show the progress bar once on each machine.','line_number':612,'multiline':False]
['text':' compute num of losses','line_number':619,'multiline':False]
['text':' forward','line_number':627,'multiline':False]
['text':' divide loss by gradient accumulation steps since gradients','line_number':630,'multiline':False]
['text':' are accumulated for multiple backward passes in PyTorch','line_number':631,'multiline':False]
['text':' make sure that `num_losses` is summed for distributed training','line_number':635,'multiline':False]
['text':' and average gradients over losses of all devices','line_number':636,'multiline':False]
['text':' update step','line_number':644,'multiline':False]
['text':' compute grad norm for monitoring','line_number':646,'multiline':False]
['text':' update parameters','line_number':657,'multiline':False]
['text':' update gumbel temperature','line_number':668,'multiline':False]
['text':' 6. Log all results','line_number':681,'multiline':False]
['text':' save model every `args.saving_steps` steps','line_number':712,'multiline':False]
['text':' if completed steps > `args.max_train_steps` stop','line_number':728,'multiline':False]
['text':' 7. Validate!','line_number':732,'multiline':False]
['text':' init logs','line_number':735,'multiline':False]
['text':' sum over devices in multi-processing','line_number':752,'multiline':False]
