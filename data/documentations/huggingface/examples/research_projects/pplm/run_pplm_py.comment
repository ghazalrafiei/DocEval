['text':'! /usr/bin/env python3','line_number':1,'multiline':False]
['text':' coding=utf-8','line_number':2,'multiline':False]
['text':' Copyright (c) 2019 Uber Technologies, Inc.','line_number':4,'multiline':False]
['text':'','line_number':5,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':6,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':7,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':8,'multiline':False]
['text':'','line_number':9,'multiline':False]
['text':' http://www.apache.org/licenses/LICENSE-2.0','line_number':10,'multiline':False]
['text':'','line_number':11,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':12,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':13,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':14,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':15,'multiline':False]
['text':' limitations under the License.','line_number':16,'multiline':False]
['text':' Generate inital perturbed past','line_number':114,'multiline':False]
['text':' TODO fix this comment (SUMANTH)','line_number':125,'multiline':False]
['text':' Generate a mask is gradient perturbated is based on a past window','line_number':126,'multiline':False]
['text':' accumulate perturbations for num_iterations','line_number':142,'multiline':False]
['text':' make sure p_.grad is not None','line_number':148,'multiline':False]
['text':' Compute hidden using perturbed past','line_number':152,'multiline':False]
['text':' TODO: Check the layer-norm consistency of this with trained discriminator (Sumanth)','line_number':159,'multiline':False]
['text':' TODO why we need to do this assignment and not just using unpert_past? (Sumanth)','line_number':175,'multiline':False]
['text':' compute gradients','line_number':214,'multiline':False]
['text':' calculate gradient norms','line_number':217,'multiline':False]
['text':' normalize gradients','line_number':228,'multiline':False]
['text':' accumulate gradient','line_number':234,'multiline':False]
['text':' reset gradients, just to make sure','line_number':237,'multiline':False]
['text':' removing past from the graph','line_number':241,'multiline':False]
['text':' apply the accumulated perturbations to the past','line_number':247,'multiline':False]
['text':' collect one hot vectors for bags of words','line_number':456,'multiline':False]
['text':' Get past/probs for current output, except for last word','line_number':464,'multiline':False]
['text':' Note that GPT takes 2 inputs: past + current_token','line_number':465,'multiline':False]
['text':' run model forward to obtain unperturbed','line_number':467,'multiline':False]
['text':' check if we are abowe grad max length','line_number':481,'multiline':False]
['text':' modify the past if necessary','line_number':487,'multiline':False]
['text':' + SMALL_CONST','line_number':526,'multiline':False]
['text':' Fuse the modified model and original model','line_number':545,'multiline':False]
['text':' + SMALL_CONST','line_number':549,'multiline':False]
['text':' + SMALL_CONST','line_number':550,'multiline':False]
['text':' rescale','line_number':552,'multiline':False]
['text':' + SMALL_CONST','line_number':557,'multiline':False]
['text':' sample or greedy','line_number':560,'multiline':False]
['text':' update context/output_so_far appending the new token','line_number':567,'multiline':False]
['text':' set Random seed','line_number':615,'multiline':False]
['text':' set the device','line_number':619,'multiline':False]
['text':' load pretrained model','line_number':629,'multiline':False]
['text':' load tokenizer','line_number':634,'multiline':False]
['text':' Freeze GPT-2 weights','line_number':637,'multiline':False]
['text':' figure out conditioning text','line_number':641,'multiline':False]
['text':' generate unperturbed and perturbed texts','line_number':655,'multiline':False]
['text':' full_text_generation returns:','line_number':657,'multiline':False]
['text':' unpert_gen_tok_text, pert_gen_tok_texts, discrim_losses, losses_in_time','line_number':658,'multiline':False]
['text':' untokenize unperturbed text','line_number':684,'multiline':False]
['text':' filtering all words in the list composed of more than 1 token','line_number':698,'multiline':False]
['text':' w[0] because we are sure w has only 1 item because previous fitler','line_number':700,'multiline':False]
['text':' iterate through the perturbed texts','line_number':703,'multiline':False]
['text':' untokenize unperturbed text','line_number':706,'multiline':False]
['text':' keep the prefix, perturbed seq, original seq for each index','line_number':729,'multiline':False]
