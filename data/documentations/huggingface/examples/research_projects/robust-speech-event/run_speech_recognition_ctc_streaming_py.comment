['text':'!/usr/bin/env python','line_number':1,'multiline':False]
['text':' coding=utf-8','line_number':2,'multiline':False]
['text':' Copyright 2022 The HuggingFace Inc. team. All rights reserved.','line_number':3,'multiline':False]
['text':'','line_number':4,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':5,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':6,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':7,'multiline':False]
['text':'','line_number':8,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':9,'multiline':False]
['text':'','line_number':10,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':11,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':12,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':13,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':14,'multiline':False]
['text':' Will error if the minimal version of Transformers is not installed. Remove at your own risk.','line_number':52,'multiline':False]
['text':' split inputs and labels since they have to be of different lengths and need','line_number':287,'multiline':False]
['text':' different padding methods','line_number':288,'multiline':False]
['text':' replace padding with -100 to ignore loss correctly','line_number':311,'multiline':False]
['text':' See all possible arguments in src/transformers/training_args.py','line_number':320,'multiline':False]
['text':' or by passing the --help flag to this script.','line_number':321,'multiline':False]
['text':' We now keep distinct sets of args, for a cleaner separation of concerns.','line_number':322,'multiline':False]
['text':' If we pass only one argument to the script and it's the path to a json file,','line_number':326,'multiline':False]
['text':' let's parse it to get our arguments.','line_number':327,'multiline':False]
['text':' Detecting last checkpoint.','line_number':332,'multiline':False]
['text':' Setup logging','line_number':347,'multiline':False]
['text':' Log on each process the small summary:','line_number':355,'multiline':False]
['text':' Set the verbosity to info of the Transformers logger (on main process only):','line_number':360,'multiline':False]
['text':' Set seed before initializing model.','line_number':365,'multiline':False]
['text':' 1. First, let's load the dataset','line_number':368,'multiline':False]
['text':' `features` and `cast_column` won't be available after interleaving, so we'll use them here','line_number':375,'multiline':False]
['text':' make sure that the dataset decodes audio with a correct sampling rate','line_number':377,'multiline':False]
['text':' make sure that the dataset decodes audio with a correct sampling rate','line_number':388,'multiline':False]
['text':' `datasets` takes care of automatically loading and resampling the audio,','line_number':394,'multiline':False]
['text':' so we just need to set the correct target sampling rate and normalize the input','line_number':395,'multiline':False]
['text':' via the `feature_extractor`','line_number':396,'multiline':False]
['text':' 2. We remove some special characters from the datasets','line_number':443,'multiline':False]
['text':' that make training complicated and do not help in transcribing the speech','line_number':444,'multiline':False]
['text':' E.g. characters, such as `,` and `.` do not really have an acoustic characteristic','line_number':445,'multiline':False]
['text':' that could be easily picked up by the model','line_number':446,'multiline':False]
['text':' 3. Next, let's load the config as we might need it to create','line_number':465,'multiline':False]
['text':' the tokenizer','line_number':466,'multiline':False]
['text':' 4. Now we can instantiate the tokenizer and model','line_number':471,'multiline':False]
['text':' Note for distributed training, the .from_pretrained methods guarantee that only','line_number':472,'multiline':False]
['text':' one local process can concurrently download model & vocab.','line_number':473,'multiline':False]
['text':' load feature_extractor and tokenizer','line_number':480,'multiline':False]
['text':' adapt config','line_number':487,'multiline':False]
['text':' create model','line_number':507,'multiline':False]
['text':' freeze encoder','line_number':515,'multiline':False]
['text':' 5. Now we preprocess the datasets including loading the audio, resampling and normalization','line_number':519,'multiline':False]
['text':' `phoneme_language` is only relevant if the model is fine-tuned on phoneme classification','line_number':522,'multiline':False]
['text':' Preprocessing the datasets.','line_number':525,'multiline':False]
['text':' We need to read the audio files as arrays and tokenize the targets.','line_number':526,'multiline':False]
['text':' load audio','line_number':528,'multiline':False]
['text':' encode targets','line_number':535,'multiline':False]
['text':' 6. Next, we can prepare the training.','line_number':557,'multiline':False]
['text':' Let's use word error rate (WER) as our evaluation metric,','line_number':558,'multiline':False]
['text':' instantiate a data collator and the trainer','line_number':559,'multiline':False]
['text':' Define evaluation metrics during training, *i.e.* word error rate, character error rate','line_number':561,'multiline':False]
['text':' we do not want to group tokens when computing the metrics','line_number':571,'multiline':False]
['text':' Now save everything to be able to create a single processor later','line_number':578,'multiline':False]
['text':' save feature extractor, tokenizer and config','line_number':580,'multiline':False]
['text':' Instantiate custom data collator','line_number':597,'multiline':False]
['text':' trainer callback to reinitialize and reshuffle the streamable datasets at the beginning of each epoch','line_number':601,'multiline':False]
['text':' set_epoch() is handled by the Trainer','line_number':605,'multiline':False]
['text':' Initialize Trainer','line_number':609,'multiline':False]
['text':' 7. Finally, we can start training','line_number':621,'multiline':False]
['text':' Training','line_number':623,'multiline':False]
['text':' use last checkpoint if exist','line_number':625,'multiline':False]
['text':' Evaluation','line_number':644,'multiline':False]
['text':' Write model card and (optionally) push to hub','line_number':655,'multiline':False]
