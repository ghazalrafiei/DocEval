['text':'!/usr/bin/env python','line_number':1,'multiline':False]
['text':' coding=utf-8','line_number':2,'multiline':False]
['text':' Copyright 2022 The HuggingFace Inc. team. All rights reserved.','line_number':3,'multiline':False]
['text':'','line_number':4,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':5,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':6,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':7,'multiline':False]
['text':'','line_number':8,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':9,'multiline':False]
['text':'','line_number':10,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':11,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':12,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':13,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':14,'multiline':False]
['text':' Will error if the minimal version of Transformers is not installed. Remove at your own risks.','line_number':57,'multiline':False]
['text':' Numpy and TensorFlow compatible version of PyTorch RandomResizedCrop. Code adapted from:','line_number':202,'multiline':False]
['text':' https://pytorch.org/vision/main/_modules/torchvision/transforms/transforms.html#RandomResizedCrop','line_number':203,'multiline':False]
['text':' Fallback to central crop','line_number':218,'multiline':False]
['text':' See all possible arguments in src/transformers/training_args.py','line_number':235,'multiline':False]
['text':' or by passing the --help flag to this script.','line_number':236,'multiline':False]
['text':' We now keep distinct sets of args, for a cleaner separation of concerns.','line_number':237,'multiline':False]
['text':' If we pass only one argument to the script and it's the path to a json file,','line_number':240,'multiline':False]
['text':' let's parse it to get our arguments.','line_number':241,'multiline':False]
['text':' Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The','line_number':258,'multiline':False]
['text':' information sent is the one passed as arguments along with your Python/TensorFlow versions.','line_number':259,'multiline':False]
['text':' Checkpoints. Find the checkpoint the use when loading the model.','line_number':262,'multiline':False]
['text':' Setup logging','line_number':277,'multiline':False]
['text':' Set the verbosity to info of the Transformers logger (on main process only):','line_number':286,'multiline':False]
['text':' region Dataset and labels','line_number':293,'multiline':False]
['text':' Set seed before initializing model.','line_number':294,'multiline':False]
['text':' Initialize our dataset and prepare it for the 'image-classification' task.','line_number':297,'multiline':False]
['text':' See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at','line_number':318,'multiline':False]
['text':' https://huggingface.co/docs/datasets/loading_datasets.','line_number':319,'multiline':False]
['text':' Prepare label mappings.','line_number':321,'multiline':False]
['text':' We'll include these in the model's config to get human readable labels in the Inference API.','line_number':322,'multiline':False]
['text':' Load model image processor and configuration','line_number':329,'multiline':False]
['text':' If we don't have a validation split, split off a percentage of train as validation.','line_number':349,'multiline':False]
['text':' Define our data preprocessing function. It takes an image file path as input and returns','line_number':356,'multiline':False]
['text':' Write a note describing the resizing behaviour.','line_number':357,'multiline':False]
['text':' We instead set the target size as (shortest_edge, shortest_edge) to here to ensure all images are batchable.','line_number':359,'multiline':False]
['text':' image = np.array(image) # FIXME - use tf.image function','line_number':377,'multiline':False]
['text':' Set the validation transforms','line_number':417,'multiline':False]
['text':' Set the test transforms','line_number':432,'multiline':False]
['text':' Load the accuracy metric from the datasets package','line_number':442,'multiline':False]
['text':' Define our compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a','line_number':445,'multiline':False]
['text':' predictions and label_ids field) and has to return a dictionary string to float.','line_number':446,'multiline':False]
['text':' model.prepare_tf_dataset() wraps a Hugging Face dataset in a tf.data.Dataset which is ready to use in','line_number':496,'multiline':False]
['text':' training. This is the recommended way to use a Hugging Face dataset when training with Keras. You can also','line_number':497,'multiline':False]
['text':' use the lower-level dataset.to_tf_dataset() method, but you will have to specify things like column names','line_number':498,'multiline':False]
['text':' yourself if you use this method, whereas they are automatically inferred from the model input names when','line_number':499,'multiline':False]
['text':' using model.prepare_tf_dataset()','line_number':500,'multiline':False]
['text':' For more info see the docs:','line_number':501,'multiline':False]
['text':' https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset','line_number':502,'multiline':False]
['text':' https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.to_tf_dataset','line_number':503,'multiline':False]
['text':' Transformers models compute the right loss for their task by default when labels are passed, and will','line_number':529,'multiline':False]
['text':' use this for training unless you specify your own loss function in compile().','line_number':530,'multiline':False]
['text':' If we're not pushing to hub, at least save a local copy when we're done','line_number':591,'multiline':False]
