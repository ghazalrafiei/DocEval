['text':' Owner(s): ["module: type promotion"]','line_number':1,'multiline':False]
['text':' load_tests from torch.testing._internal.common_utils is used to automatically filter tests for','line_number':22,'multiline':False]
['text':' sharding on sandcastle. This line silences flake warnings','line_number':23,'multiline':False]
['text':' Not thread-safe decorator that runs the decorated test once with','line_number':26,'multiline':False]
['text':' the default dtype being torch.float and again with the default dtype','line_number':27,'multiline':False]
['text':' being torch.double.','line_number':28,'multiline':False]
['text':' In-place operations don't promote.','line_number':41,'multiline':False]
['text':' `int+float -> float` but `int.add_(float)` is rejected as an error.','line_number':42,'multiline':False]
['text':' Promoting inplace would require re-allocating and copying the memory of the','line_number':43,'multiline':False]
['text':' tensor data, since element size could change.','line_number':44,'multiline':False]
['text':' We treat bool as a separate category, which means uint8 cannot cast to bool.','line_number':62,'multiline':False]
['text':' We allow demotion from signed to unsigned, unlike numpy, because:','line_number':65,'multiline':False]
['text':' * We don't want the performance penalty of inspecting scalar values.','line_number':66,'multiline':False]
['text':' * We don't want 'signed' to be considered a distinct 'category'','line_number':67,'multiline':False]
['text':' in promotion rules.','line_number':68,'multiline':False]
['text':' We don't want signed to be a separate category because if it was,','line_number':69,'multiline':False]
['text':' uint16_tensor + 5 would result in a long_tensor, which is not what we want.','line_number':70,'multiline':False]
['text':' some basic examples','line_number':79,'multiline':False]
['text':' not a "wrapped number"','line_number':118,'multiline':False]
['text':' As per type promotion rules,','line_number':129,'multiline':False]
['text':' Complex Scalar and Float Tensor -> Complex Tensor with Value type of Float Tensor','line_number':130,'multiline':False]
['text':' Complex Scalar and Integral Tensor -> Complex Tensor with Value type of Complex Scalar','line_number':131,'multiline':False]
['text':' defaults to return complex64 (for bfloat16)','line_number':134,'multiline':False]
['text':' integral tensor','line_number':136,'multiline':False]
['text':' chalf is not supported on XLA','line_number':147,'multiline':False]
['text':' Same Value type','line_number':149,'multiline':False]
['text':' 0-D Tensor X 1-D Tensor','line_number':151,'multiline':False]
['text':' Python Scalar X 1-D Tensor','line_number':153,'multiline':False]
['text':' Higher Value Type','line_number':156,'multiline':False]
['text':' Special Case','line_number':161,'multiline':False]
['text':' Integral Tensor','line_number':166,'multiline':False]
['text':' CFloat Scalar','line_number':171,'multiline':False]
['text':' Lower Value type than CFloat','line_number':173,'multiline':False]
['text':' Higher Value type than CFloat','line_number':178,'multiline':False]
['text':' Integral Tensor','line_number':183,'multiline':False]
['text':' 0-D Tensor X 1-D Tensor','line_number':185,'multiline':False]
['text':' Python Scalar X 1-D Tensor','line_number':187,'multiline':False]
['text':' CDouble Scalar','line_number':190,'multiline':False]
['text':' Lower Value type than CDouble','line_number':193,'multiline':False]
['text':' Special Case','line_number':198,'multiline':False]
['text':' some examples from:','line_number':226,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/9515','line_number':227,'multiline':False]
['text':' integer overflow','line_number':235,'multiline':False]
['text':' not a "wrapped number"','line_number':237,'multiline':False]
['text':' adding a 0-dim tensor to a float doesn't promote to double unless first','line_number':242,'multiline':False]
['text':' type was integral.','line_number':243,'multiline':False]
['text':' inf','line_number':250,'multiline':False]
['text':' with scalar','line_number':255,'multiline':False]
['text':' bf + 100000 is inf','line_number':257,'multiline':False]
['text':' with tensor','line_number':265,'multiline':False]
['text':' Handles bfloat16 x float16 -> float32 promotion','line_number':270,'multiline':False]
['text':' with scalar','line_number':286,'multiline':False]
['text':' chalf + 100000 is inf','line_number':288,'multiline':False]
['text':' with tensor','line_number':296,'multiline':False]
['text':' If we don't convert the returned grad_input to the actual input type','line_number':340,'multiline':False]
['text':' we get an error like:','line_number':341,'multiline':False]
['text':' RuntimeError: Function SubBackward0 returned an invalid gradient at index 0 - expected type \','line_number':342,'multiline':False]
['text':' torch.FloatTensor but got torch.DoubleTensor','line_number':343,'multiline':False]
['text':' "_th_normal_ not supported on CPUType for Half" so simpler create and convert','line_number':359,'multiline':False]
['text':' verifies that torch.<op>(first, second) is the same as','line_number':370,'multiline':False]
['text':' torch.<op>(first.to(common_dtype), second.to(common_dtype)) in cases where that should hold.','line_number':371,'multiline':False]
['text':' Can also include half on CPU in cases where it will be promoted to a','line_number':374,'multiline':False]
['text':' supported dtype','line_number':375,'multiline':False]
['text':' Subtraction, the `-` operator, with a bool tensor is not supported.','line_number':385,'multiline':False]
['text':' test ops with non-contiguous tensors','line_number':389,'multiline':False]
['text':' this seems like odd behavior but ints also create float tensors, numpy doesn't have this function.','line_number':454,'multiline':False]
['text':' tensor against tensor','line_number':477,'multiline':False]
['text':' special case: in Python, True + True is an integer','line_number':498,'multiline':False]
['text':' Python internal type determination is good enough in this case','line_number':502,'multiline':False]
['text':' a and b belong to the same class','line_number':504,'multiline':False]
['text':' Spot check some result type for tensor against scalar (including single-element tensor).','line_number':507,'multiline':False]
['text':' test that comparing a zero dim tensor with another zero dim tensor has type promotion behavior','line_number':609,'multiline':False]
['text':' XLA tests fail for self.assertRaises for complex dtypes','line_number':626,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/28010','line_number':695,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/27824','line_number':710,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/28502','line_number':719,'multiline':False]
['text':' noqa: E712','line_number':721,'multiline':False]
['text':' Tests tensor/tensor division','line_number':730,'multiline':False]
['text':' Tests tensor/scalar division','line_number':734,'multiline':False]
['text':' Tests that requests for an integer quotient fail','line_number':746,'multiline':False]
['text':' Tests that requests for a floating quotient succeed','line_number':754,'multiline':False]
['text':' Tests that requests for an integer quotient fail','line_number':769,'multiline':False]
['text':' Tests that requests for a floating quotient succeed','line_number':776,'multiline':False]
['text':' ensure sparsity. Bool should already have sufficient sparsity.','line_number':784,'multiline':False]
['text':' very low precision for uncoalesced float16 sparse tensors since','line_number':803,'multiline':False]
['text':' ops like (s1 + s2).to_dense() will add four low-precision','line_number':804,'multiline':False]
['text':' floating point values.','line_number':805,'multiline':False]
['text':' uses default','line_number':809,'multiline':False]
['text':' Skip inplace tests that would fail due to inability to cast to the output type.','line_number':832,'multiline':False]
['text':' Some of these would also raise errors due to not being a supported op.','line_number':833,'multiline':False]
['text':' Test op(sparse, sparse)','line_number':846,'multiline':False]
['text':' sparse division only supports division by a scalar','line_number':852,'multiline':False]
['text':' Test op(dense, sparse)','line_number':855,'multiline':False]
['text':' sparse division only supports division by a scalar','line_number':863,'multiline':False]
['text':' mul: Didn't find kernel to dispatch to for operator 'aten::_nnz'','line_number':864,'multiline':False]
['text':' Test op(sparse, dense) not supported for all ops but 'mul'.','line_number':867,'multiline':False]
['text':' add(sparse, dense) is not supported. Use add(dense, sparse) instead.','line_number':868,'multiline':False]
['text':' sparse division only supports division by a scalar','line_number':869,'multiline':False]
['text':' No type promotions for inplace operations, hence suf=''','line_number':873,'multiline':False]
['text':' Test op(sparse, scalar)','line_number':876,'multiline':False]
['text':' add(sparse, dense) is not supported. Use add(dense, sparse) instead.','line_number':887,'multiline':False]
['text':' "mul_cpu" / "div_cpu" not implemented for 'Half'','line_number':888,'multiline':False]
['text':' Acquires results of binary ufunc type promotion.','line_number':957,'multiline':False]
['text':' Note: An "undesired failure," as opposed to an "expected failure"','line_number':970,'multiline':False]
['text':' is both expected (we know the test will fail) and','line_number':971,'multiline':False]
['text':' undesirable (if PyTorch was working properly the test would','line_number':972,'multiline':False]
['text':' not fail). This test is affected by three issues (see below)','line_number':973,'multiline':False]
['text':' that will cause undesired failures. It detects when these','line_number':974,'multiline':False]
['text':' issues will occur and updates this bool accordingly.','line_number':975,'multiline':False]
['text':' A NumPy array as the first argument to the plus operator','line_number':978,'multiline':False]
['text':' or as any argument to torch.add is not working as','line_number':979,'multiline':False]
['text':' intended.','line_number':980,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/36363.','line_number':981,'multiline':False]
['text':' Expects the same result if undesired_failure is false','line_number':987,'multiline':False]
['text':' and a different result otherwise.','line_number':988,'multiline':False]
['text':' Note: These cases prettyprint the failing inputs to make','line_number':989,'multiline':False]
['text':' debugging test failures easier.','line_number':990,'multiline':False]
['text':' cat: full and an empty tensor.','line_number':1027,'multiline':False]
['text':' This combinations do not support type conversion to a different class out type','line_number':1045,'multiline':False]
['text':' Verfies that unary ops require matching out types','line_number':1052,'multiline':False]
['text':' Verifies that the out= argument doesn't affect the computation, that','line_number':1086,'multiline':False]
['text':' is, out = op(...) and op(..., out=out) produce the same result.','line_number':1087,'multiline':False]
['text':' 0d tensors go to scalar overload, and it's tested separately','line_number':1131,'multiline':False]
['text':' first do a maybe dimensional boundary','line_number':1136,'multiline':False]
