['text':' Owner(s): ["oncall: quantization"]','line_number':1,'multiline':False]
['text':' ONEDNN only supports symmetric quantization of weight','line_number':114,'multiline':False]
['text':' set random quantized weight and bias before test torch scriptable','line_number':126,'multiline':False]
['text':' Run module with default-initialized parameters.','line_number':129,'multiline':False]
['text':' This tests that the constructor is correct.','line_number':130,'multiline':False]
['text':' Simple round-trip test to ensure weight()/set_weight() API','line_number':134,'multiline':False]
['text':' testing packed param implementation','line_number':137,'multiline':False]
['text':' Check if the module implementation matches calling the','line_number':142,'multiline':False]
['text':' ops directly','line_number':143,'multiline':False]
['text':' Test serialization of quantized Linear Module using state_dict','line_number':150,'multiline':False]
['text':' scripting will add __overloads__ to __dict__, which is why we script a copy','line_number':174,'multiline':False]
['text':' to be able to do the check in the next line','line_number':175,'multiline':False]
['text':' Test serialization','line_number':183,'multiline':False]
['text':' Test torch.package','line_number':192,'multiline':False]
['text':' noop, just make sure attribute "_modules" is restored correctly during torch.package import','line_number':205,'multiline':False]
['text':' noqa: E275','line_number':206,'multiline':False]
['text':' Test copy and deepcopy','line_number':208,'multiline':False]
['text':' Test JIT','line_number':227,'multiline':False]
['text':' Make sure `from_float` works for all linear variants','line_number':230,'multiline':False]
['text':' Test from_float.','line_number':234,'multiline':False]
['text':' Sequential allows swapping using "convert".','line_number':239,'multiline':False]
['text':' Smoke test to make sure the module actually runs','line_number':243,'multiline':False]
['text':' Smoke test extra_repr','line_number':246,'multiline':False]
['text':' testing Quantize API','line_number':252,'multiline':False]
['text':' testing Dequantize API','line_number':257,'multiline':False]
['text':' Make sure the weight shape is correct','line_number':287,'multiline':False]
['text':' Test members','line_number':299,'multiline':False]
['text':' Test properties','line_number':305,'multiline':False]
['text':' Test forward','line_number':312,'multiline':False]
['text':' Make sure the results match','line_number':318,'multiline':False]
['text':' assert_array_almost_equal compares using the following formula:','line_number':319,'multiline':False]
['text':'     abs(desired-actual) < 1.5 * 10**(-decimal)','line_number':320,'multiline':False]
['text':' (https://docs.scipy.org/doc/numpy/reference/generated/numpy.testing.assert_almost_equal.html)','line_number':321,'multiline':False]
['text':' We use decimal = 0 to ignore off-by-1 differences between reference','line_number':322,'multiline':False]
['text':' and test. Off-by-1 differences arise due to the order of round and','line_number':323,'multiline':False]
['text':' zero_point addition operation, i.e., if addition followed by round is','line_number':324,'multiline':False]
['text':' used by reference and round followed by addition is used by test, the','line_number':325,'multiline':False]
['text':' results may differ by 1.','line_number':326,'multiline':False]
['text':' For example, the result of round(2.5) + 1 is 3 while round(2.5 + 1) is','line_number':327,'multiline':False]
['text':' 4 assuming the rounding mode is round-to-nearest, ties-to-even.','line_number':328,'multiline':False]
['text':' skip numerics checking for reference module','line_number':329,'multiline':False]
['text':' Test serialization of quantized Conv Module using state_dict','line_number':333,'multiline':False]
['text':' Test serialization','line_number':364,'multiline':False]
['text':' Test copy and deepcopy','line_number':375,'multiline':False]
['text':' JIT testing','line_number':394,'multiline':False]
['text':' Help Module for ConvAdd2d since torch.ao.nn.intrinsic._FusedModule only support one input arg','line_number':400,'multiline':False]
['text':' Test from_float','line_number':405,'multiline':False]
['text':' Smoke test to make sure the module actually runs','line_number':418,'multiline':False]
['text':' Smoke test extra_repr','line_number':422,'multiline':False]
['text':' pad_mode','line_number':428,'multiline':False]
['text':' use_bias','line_number':429,'multiline':False]
['text':' use_channelwise','line_number':430,'multiline':False]
['text':' Tests the correctness of the conv2d module.','line_number':444,'multiline':False]
['text':' pad_mode','line_number':482,'multiline':False]
['text':' use_bias','line_number':483,'multiline':False]
['text':' use_channelwise','line_number':484,'multiline':False]
['text':' Tests the correctness of the conv2d module.','line_number':495,'multiline':False]
['text':' pad_mode','line_number':536,'multiline':False]
['text':' use_bias','line_number':537,'multiline':False]
['text':' use_channelwise','line_number':538,'multiline':False]
['text':' Tests the correctness of the conv2d module.','line_number':556,'multiline':False]
['text':' pad_mode','line_number':592,'multiline':False]
['text':' use_bias','line_number':593,'multiline':False]
['text':' use_channelwise','line_number':594,'multiline':False]
['text':' Tests the correctness of the conv2d module.','line_number':609,'multiline':False]
['text':' use_bias','line_number':650,'multiline':False]
['text':' use_channelwise','line_number':651,'multiline':False]
['text':' 3d doesn't support reflect padding','line_number':666,'multiline':False]
['text':' Tests the correctness of the conv3d module.','line_number':671,'multiline':False]
['text':' use_bias','line_number':712,'multiline':False]
['text':' use_channelwise','line_number':713,'multiline':False]
['text':' 3d doesn't support reflect padding','line_number':728,'multiline':False]
['text':' Tests the correctness of the conv3d module.','line_number':733,'multiline':False]
['text':' pad_mode','line_number':778,'multiline':False]
['text':' use_bias','line_number':779,'multiline':False]
['text':' use_channelwise','line_number':780,'multiline':False]
['text':' Tests the correctness of the conv2d module.','line_number':795,'multiline':False]
['text':' pad_mode','line_number':837,'multiline':False]
['text':' use_bias','line_number':838,'multiline':False]
['text':' use_channelwise','line_number':839,'multiline':False]
['text':' Tests the correctness of the conv2d module.','line_number':854,'multiline':False]
['text':' JIT Testing','line_number':914,'multiline':False]
['text':' Quantize the weights','line_number':1243,'multiline':False]
['text':' Ensure the module has the correct weights','line_number':1249,'multiline':False]
['text':' Call the bit qembedding operator directly','line_number':1254,'multiline':False]
['text':' include the last offset','line_number':1277,'multiline':False]
['text':' Get the scale and zero point for the weight tensor','line_number':1284,'multiline':False]
['text':' Quantize the weights to 8bits','line_number':1286,'multiline':False]
['text':' Ensure the module has the correct weights','line_number':1292,'multiline':False]
['text':' Call the qembedding_bag operator directly','line_number':1298,'multiline':False]
['text':' check that the weight makes sense','line_number':1336,'multiline':False]
['text':' check that the output makes sense','line_number':1343,'multiline':False]
['text':' batch size','line_number':1377,'multiline':False]
['text':' in_features','line_number':1378,'multiline':False]
['text':' out_features','line_number':1379,'multiline':False]
['text':' use_bias','line_number':1380,'multiline':False]
['text':' per_channel','line_number':1381,'multiline':False]
['text':' negative slope','line_number':1382,'multiline':False]
['text':' batch size','line_number':1396,'multiline':False]
['text':' in_features','line_number':1397,'multiline':False]
['text':' out_features','line_number':1398,'multiline':False]
['text':' use_bias','line_number':1399,'multiline':False]
['text':' negative slope','line_number':1400,'multiline':False]
['text':' Test serialization of quantized Conv Module using state_dict','line_number':1445,'multiline':False]
['text':' Test serialization','line_number':1476,'multiline':False]
['text':' Test copy and deepcopy','line_number':1487,'multiline':False]
['text':' need to fix this','line_number':1506,'multiline':False]
['text':' JIT testing','line_number':1507,'multiline':False]
['text':' Test from_float','line_number':1512,'multiline':False]
['text':' type: ignore[assignment]','line_number':1514,'multiline':False]
['text':' Smoke test to make sure the module actually runs','line_number':1519,'multiline':False]
['text':' Smoke test extra_repr','line_number':1522,'multiline':False]
['text':' qnnpack doesn't support unpacking conv3d','line_number':1553,'multiline':False]
['text':' qnnpack doesn't support unpacking conv3d','line_number':1585,'multiline':False]
['text':' Run module with default-initialized parameters.','line_number':1606,'multiline':False]
['text':' This tests that the constructor is correct.','line_number':1607,'multiline':False]
['text':' Simple round-trip test to ensure weight()/set_weight() API','line_number':1611,'multiline':False]
['text':' Check if the module implementation matches calling the','line_number':1616,'multiline':False]
['text':' ops directly','line_number':1617,'multiline':False]
['text':' Test serialization of dynamic quantized Linear Module using state_dict','line_number':1621,'multiline':False]
['text':' Test JIT','line_number':1662,'multiline':False]
['text':' Test from_float','line_number':1667,'multiline':False]
['text':' Smoke test to make sure the module actually runs','line_number':1675,'multiline':False]
['text':' Smoke test extra_repr','line_number':1678,'multiline':False]
['text':' Check that module matches the numerics of the op and ensure that module can be','line_number':1689,'multiline':False]
['text':' instantiated for all engines and dtypes','line_number':1690,'multiline':False]
['text':' fp16 dynamic quant is not supported for qnnpack or onednn','line_number':1713,'multiline':False]
['text':' Check that module matches the numerics of the op and ensure that module can be','line_number':1759,'multiline':False]
['text':' instantiated for all engines and dtypes','line_number':1760,'multiline':False]
['text':' fp16 dynamic quant is not supported for qnnpack or onednn','line_number':1764,'multiline':False]
['text':' Test default instantiation','line_number':1766,'multiline':False]
['text':' Check that module matches the numerics of the op and ensure that module can be','line_number':1811,'multiline':False]
['text':' instantiated for all engines and dtypes','line_number':1812,'multiline':False]
['text':' fp16 dynamic quant is not supported for qnnpack or onednn','line_number':1837,'multiline':False]
['text':' per channel affine','line_number':1865,'multiline':False]
['text':' TODO: add tests for conv and linear','line_number':1871,'multiline':False]
['text':' initialize ref rnn cell module','line_number':1906,'multiline':False]
['text':' reassign the weights from fp32 rnn cell modulea','line_number':1921,'multiline':False]
['text':' change the weight of fp_res, we first want to run a quantie and','line_number':1929,'multiline':False]
['text':' dequantize on the weight','line_number':1930,'multiline':False]
['text':' initialize ref rnn module','line_number':1959,'multiline':False]
['text':' quantize and dequantize the weights for fp32_rnn module','line_number':1982,'multiline':False]
['text':' embedding input','line_number':2001,'multiline':False]
['text':' embedding bag input','line_number':2004,'multiline':False]
['text':' TODO: torch.quint4x2 not supported in quantize_per_channel, need to add support','line_number':2045,'multiline':False]
['text':' quantize and dequantize the weight for fp32 module','line_number':2055,'multiline':False]
['text':' verify that the qmin/qmax arguments for weight q/dq are correctly','line_number':2076,'multiline':False]
['text':' taken from the observer','line_number':2077,'multiline':False]
