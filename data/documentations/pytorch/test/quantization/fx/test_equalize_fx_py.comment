['text':' Owner(s): ["oncall: quantization"]','line_number':1,'multiline':False]
['text':' Standard Libraries','line_number':47,'multiline':False]
['text':' Testing utils','line_number':51,'multiline':False]
['text':' Check the min/max input columns are correct','line_number':131,'multiline':False]
['text':' Check the min/max weight columns are correct','line_number':137,'multiline':False]
['text':' Check the equalization scale is correct','line_number':143,'multiline':False]
['text':' Check the input scale/zero-point values','line_number':152,'multiline':False]
['text':' During input-weight equalization, we will scale the weights so that','line_number':177,'multiline':False]
['text':' the following weight quantized observer will have the correct scaled qparams','line_number':178,'multiline':False]
['text':' Check the weight scale/zero-point values of the quantized observer','line_number':179,'multiline':False]
['text':' Scale the weights for input-weight equalization','line_number':182,'multiline':False]
['text':' Call forward on the weight quantization observer','line_number':193,'multiline':False]
['text':' Check the min/max weight rows are correct','line_number':196,'multiline':False]
['text':' Tests that we do not add an equalization observer due to both initial','line_number':292,'multiline':False]
['text':' nodes in the branch containing layers that need to be equalized.','line_number':293,'multiline':False]
['text':' Note that this should print out 2 warning messages for not being able','line_number':294,'multiline':False]
['text':' to equalize layers linear1 and linear1 because it is part of a branch','line_number':295,'multiline':False]
['text':' Tests that we will add an equalization observer because there is only','line_number':319,'multiline':False]
['text':' one initial node in the branch that needs to be equalized','line_number':320,'multiline':False]
['text':' Check if compile','line_number':384,'multiline':False]
['text':' Check min/max values of weight activation layers','line_number':559,'multiline':False]
['text':' Check min/max values of input activation layers','line_number':565,'multiline':False]
['text':' Skip the equalization and mul nodes','line_number':587,'multiline':False]
['text':' Check that the type of call_modules are the same (ex. nn.Linear, MinMaxObserver)','line_number':593,'multiline':False]
['text':' Check that the call_functions are the same (ex. F.linear)','line_number':599,'multiline':False]
['text':' Check the order of nodes in the graph','line_number':789,'multiline':False]
['text':' No equalization','line_number':805,'multiline':False]
['text':' Check if compile','line_number':813,'multiline':False]
['text':' With equalization','line_number':816,'multiline':False]
['text':' Check if compile','line_number':824,'multiline':False]
['text':' Hard coded so that the top layer has a higher quantization error','line_number':850,'multiline':False]
['text':' Quantize the float model','line_number':857,'multiline':False]
['text':' Get the SQNR between the float and quantized model','line_number':867,'multiline':False]
['text':' Construct the equalization_qconfig_dict equalizing layers with the highest','line_number':870,'multiline':False]
['text':' quantization errors','line_number':871,'multiline':False]
['text':' Create the selectively equalized model','line_number':874,'multiline':False]
['text':' Check the order of nodes in the graph','line_number':895,'multiline':False]
