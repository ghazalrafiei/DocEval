['text':' Owner(s): ["module: onnx"]','line_number':1,'multiline':False]
['text':' Import various models for testing','line_number':49,'multiline':False]
['text':' def import_model(proto, input, workspace=None, use_gpu=True):','line_number':77,'multiline':False]
['text':'    model_def = onnx.ModelProto.FromString(proto)','line_number':78,'multiline':False]
['text':'    onnx.checker.check_model(model_def)','line_number':79,'multiline':False]
['text':'','line_number':80,'multiline':False]
['text':'    if workspace is None:','line_number':81,'multiline':False]
['text':'        workspace = {}','line_number':82,'multiline':False]
['text':'    if isinstance(input, tuple):','line_number':83,'multiline':False]
['text':'        for i in range(len(input)):','line_number':84,'multiline':False]
['text':'            workspace[model_def.graph.input[i]] = input[i]','line_number':85,'multiline':False]
['text':'    else:','line_number':86,'multiline':False]
['text':'        workspace[model_def.graph.input[0]] = input','line_number':87,'multiline':False]
['text':'','line_number':88,'multiline':False]
['text':'    caffe2_out_workspace = c2.run_model(','line_number':89,'multiline':False]
['text':'        init_graph=None,','line_number':90,'multiline':False]
['text':'        predict_graph=graph_def,','line_number':91,'multiline':False]
['text':'        inputs=workspace,','line_number':92,'multiline':False]
['text':'        use_gpu=use_gpu)','line_number':93,'multiline':False]
['text':'    caffe2_out = caffe2_out_workspace[0]','line_number':94,'multiline':False]
['text':'    return caffe2_out','line_number':95,'multiline':False]
['text':' Special case for common case of passing a single Tensor','line_number':102,'multiline':False]
['text':' input might be nested - we want to move everything to GPU','line_number':139,'multiline':False]
['text':' Either user specified input or random (deterministic) input','line_number':166,'multiline':False]
['text':' set the training/test mode for the model','line_number':209,'multiline':False]
['text':' use the pre-trained model params if available','line_number':212,'multiline':False]
['text':' Either user specified input or random (deterministic) input','line_number':216,'multiline':False]
['text':' GPU-ize the model, if requested','line_number':219,'multiline':False]
['text':' Verify the model runs the same in Caffe2','line_number':223,'multiline':False]
['text':' NOTE: do_constant_folding is turned on only when model has','line_number':256,'multiline':False]
['text':' parameters embedded (which are needed for constant folding),','line_number':257,'multiline':False]
['text':' i.e. for self.embed_params=True case. self.embed_params=True','line_number':258,'multiline':False]
['text':' for the TestCaffe2BackendEmbed class defined at the bottom.','line_number':259,'multiline':False]
['text':' Note that the export call explicitly sets the names of not just the input,','line_number':320,'multiline':False]
['text':' but also the parameters. This test checks that the model can be loaded and','line_number':321,'multiline':False]
['text':' executed in Caffe2 backend correctly.','line_number':322,'multiline':False]
['text':' The export call explicitly sets the names of the input, and the first parameter.','line_number':352,'multiline':False]
['text':' But note that the target first parameter name is the same as the second parameter name.','line_number':353,'multiline':False]
['text':' This test checks that given this edge condition, the model can be loaded and executed','line_number':354,'multiline':False]
['text':' in Caffe2 backend correctly.','line_number':355,'multiline':False]
['text':' test that the model still runs with a different batch size','line_number':455,'multiline':False]
['text':' (save the model with a batch_size of 1 with rnn with a variable batch size,','line_number':456,'multiline':False]
['text':' otherwise expand will fail)','line_number':457,'multiline':False]
['text':' Constant folding works when model has parameters embedded. For this case, we need to disable it','line_number':459,'multiline':False]
['text':' test that the model still runs with a different batch size','line_number':512,'multiline':False]
['text':' (save the model with a batch_size of 1 with rnn with a variable batch size,','line_number':513,'multiline':False]
['text':' otherwise expand will fail)','line_number':514,'multiline':False]
['text':' Constant folding works when model has parameters embedded. For this case, we need to disable it','line_number':516,'multiline':False]
['text':' test that the model still runs with a different batch size','line_number':566,'multiline':False]
['text':' (save the model with a batch_size of 1 with rnn with a variable batch size,','line_number':567,'multiline':False]
['text':' otherwise expand will fail)','line_number':568,'multiline':False]
['text':' Constant folding works when model has parameters embedded. For this case, we need to disable it','line_number':570,'multiline':False]
['text':' Test that we are correctly splitting between init and','line_number':588,'multiline':False]
['text':' predict net. When we embed parameters, there should be more','line_number':589,'multiline':False]
['text':' ops in the init net.','line_number':590,'multiline':False]
['text':' dcgan is flaky on some seeds, see:','line_number':620,'multiline':False]
['text':' https://github.com/ProjectToffee/onnx/pull/70','line_number':621,'multiline':False]
['text':' state_dict = model_zoo.load_url(model_urls["dcgan_f"], progress=False)','line_number':634,'multiline':False]
['text':' TODO: figure out the numerical instabilities','line_number':660,'multiline':False]
['text':' state_dict = model_zoo.load_url(model_urls["inception_v3_google"], progress=False)','line_number':663,'multiline':False]
['text':' state_dict = model_zoo.load_url(model_urls["squeezenet1_0"], progress=False)','line_number':687,'multiline':False]
['text':' @skip("takes long to run, LAPACK needed for gpu")','line_number':692,'multiline':False]
['text':' Only support CPU version, since tracer is not working in GPU RNN.','line_number':759,'multiline':False]
['text':' TODO: Why index? This returns a tuple and test runner doesn't','line_number':923,'multiline':False]
['text':' support tuple comparison.','line_number':924,'multiline':False]
['text':' TODO: Why index? This returns a tuple and test runner doesn't','line_number':983,'multiline':False]
['text':' support tuple comparison.','line_number':984,'multiline':False]
['text':' TODO: Why index? This returns a tuple and test runner doesn't','line_number':992,'multiline':False]
['text':' support tuple comparison.','line_number':993,'multiline':False]
['text':' TODO: test with state_dict','line_number':1134,'multiline':False]
['text':' test for a pytorch optimization pass, see https://github.com/pytorch/pytorch/pull/7872','line_number':1226,'multiline':False]
['text':' work around for now: turn the dynamic sizes into constant','line_number':1394,'multiline':False]
['text':' TODO: Add test cases for prod once Caffe2 has support for ReduceProd','line_number':1465,'multiline':False]
['text':' test negative dim as well.','line_number':1537,'multiline':False]
['text':' test negative dim as well','line_number':1551,'multiline':False]
['text':' NB: InstanceNorm model includes unused weights, so skip this in TestCaffe2BackendEmbed','line_number':1563,'multiline':False]
['text':' TODO: We should have another pass to eliminate the unused initializers in ONNX models.','line_number':1564,'multiline':False]
['text':' ConstantFill is a deprecated experimental op (used in opsets < 9).','line_number':1794,'multiline':False]
['text':' Shape inference does not cover this op.','line_number':1795,'multiline':False]
['text':' InstanceNorm model (used in the subgraph) includes unused weights,','line_number':2035,'multiline':False]
['text':' so skip this in TestCaffe2BackendEmbed','line_number':2036,'multiline':False]
['text':' InstanceNorm model (used in the subgraph) includes unused weights,','line_number':2043,'multiline':False]
['text':' so skip this in TestCaffe2BackendEmbed','line_number':2044,'multiline':False]
['text':' in this model, the constant propagation in JIT doesn't work','line_number':2243,'multiline':False]
['text':' so we have ListConstruct in the symbolic','line_number':2244,'multiline':False]
['text':' BoxWithNMSLimits has requirements for the inputs, so randomly generated inputs','line_number':2392,'multiline':False]
['text':' in Caffe2BackendTestEmbed doesn't work with this op.','line_number':2393,'multiline':False]
['text':' The order of returned indices from Multinomial is undefined, so randomly generated inputs','line_number':2710,'multiline':False]
['text':' in Caffe2BackendTestEmbed doesn't work with this op.','line_number':2711,'multiline':False]
['text':' a bit of metaprogramming to set up all the rnn tests','line_number':3005,'multiline':False]
['text':' sanity check that a representative example does exist','line_number':3093,'multiline':False]
['text':' make sure no one accidentally disables all the tests without','line_number':3096,'multiline':False]
['text':' noticing','line_number':3097,'multiline':False]
['text':' add the same test suite as above, but switch embed_params=False','line_number':3103,'multiline':False]
['text':' to embed_params=True','line_number':3104,'multiline':False]
['text':' opset 7 tests','line_number':3111,'multiline':False]
['text':' opset 8 tests','line_number':3123,'multiline':False]
['text':' opset 10 tests','line_number':3135,'multiline':False]
['text':' add the same test suite as above, but switch embed_params=False','line_number':3148,'multiline':False]
['text':' to embed_params=True','line_number':3149,'multiline':False]
