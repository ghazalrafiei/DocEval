['text':' Owner(s): ["module: cuda"]','line_number':1,'multiline':False]
['text':' noqa: F811','line_number':38,'multiline':False]
['text':' NOTE: do **not** use methods that can have additional','line_number':126,'multiline':False]
['text':'       memory overhead, e.g., inplace random sampling methods.','line_number':127,'multiline':False]
['text':'       they can leave some memory occupied even after being','line_number':128,'multiline':False]
['text':'       deallocated, e.g., initialized RNG state, causing some','line_number':129,'multiline':False]
['text':'       memory checks below to fail.','line_number':130,'multiline':False]
['text':' comp > 0: increased','line_number':134,'multiline':False]
['text':' comp = 0: equal','line_number':135,'multiline':False]
['text':' comp < 0: decreased','line_number':136,'multiline':False]
['text':' emptying cache may happen (due to allocation or empty_cache), so','line_number':152,'multiline':False]
['text':' we can't assert new_c >= last_c','line_number':153,'multiline':False]
['text':' small ones','line_number':192,'multiline':False]
['text':' large ones','line_number':198,'multiline':False]
['text':' in case that tensors2[i] is empty','line_number':226,'multiline':False]
['text':' test empty_cache and reset_peak','line_number':244,'multiline':False]
['text':' advance a generator with a end flag','line_number':258,'multiline':False]
['text':' interlace','line_number':267,'multiline':False]
['text':' semi-random order','line_number':276,'multiline':False]
['text':' same dst stream different src streams','line_number':348,'multiline':False]
['text':' The copy() is synchronized on the current streams of both src and dst.','line_number':358,'multiline':False]
['text':' In the above test, the _sleep() op on s0 will not block the copy() on','line_number':359,'multiline':False]
['text':' s2, but both copies are synchronized on s1 in the dst device. Hence,','line_number':360,'multiline':False]
['text':' x is copied to y after x_plus_one is copied to y. If x and y are on','line_number':361,'multiline':False]
['text':' the same device, both copy() ops are synchronized on s1.','line_number':362,'multiline':False]
['text':' same src stream different dst streams','line_number':365,'multiline':False]
['text':' Similarly, both copy() ops are synchronized on s0.','line_number':375,'multiline':False]
['text':' Setup: create a serialized file object with a 'cuda:9' restore location','line_number':399,'multiline':False]
['text':' NB: this might not work in the future if serialization changes','line_number':403,'multiline':False]
['text':' deliberately using a different device','line_number':609,'multiline':False]
['text':' not necessary to check e_tik and e_tok, as elapsed_time would throw','line_number':689,'multiline':False]
['text':' exception if otherwise.','line_number':690,'multiline':False]
['text':' not necessary to check e_tik and e_tok, as elapsed_time would throw','line_number':706,'multiline':False]
['text':' exception if otherwise.','line_number':707,'multiline':False]
['text':' not necessary to check e_tik and e_tok, as elapsed_time would throw','line_number':732,'multiline':False]
['text':' exception if otherwise.','line_number':733,'multiline':False]
['text':' Skip the test for ROCm as per https://github.com/pytorch/pytorch/issues/53190','line_number':743,'multiline':False]
['text':' Without GIL, synchronizations in parent and child threads can','line_number':771,'multiline':False]
['text':' overlap. The total execution time should be a little bit longer','line_number':772,'multiline':False]
['text':' than spinning fifty million cycles and much shorter than twice of','line_number':773,'multiline':False]
['text':' that. However, testing absolute execution time is not reliable as','line_number':774,'multiline':False]
['text':' it may vary on different hardware in different environments.','line_number':775,'multiline':False]
['text':' Therefore, this test uses relative comparisons, checking if the','line_number':776,'multiline':False]
['text':' sum of parent and child threads execution time is greater than the','line_number':777,'multiline':False]
['text':' real execution time by least 40%.','line_number':778,'multiline':False]
['text':' This test is flaky for ROCm, see issue #62602','line_number':781,'multiline':False]
['text':' deliberately using a different device','line_number':835,'multiline':False]
['text':' deliberately calling from a different device','line_number':887,'multiline':False]
['text':' checks that the events preventing pinned memory from being re-used','line_number':925,'multiline':False]
['text':' too early are recorded on the correct GPU','line_number':926,'multiline':False]
['text':' delay the copy by 1s','line_number':935,'multiline':False]
['text':' Verifies that mem_get_info works, including when called for a different device','line_number':967,'multiline':False]
['text':' increasing to 8MB to force acquiring a new block and overcome blocksize differences across platforms','line_number':971,'multiline':False]
['text':' w/o syncing, mem_get_info will run before memory allocated has actually increased.','line_number':974,'multiline':False]
['text':' This race condition causes consistent failure','line_number':975,'multiline':False]
['text':' Test that wrap_with_cuda_memory_check successfully detects leak','line_number':986,'multiline':False]
['text':' increasing to 8MB to force acquiring a new block and overcome blocksize differences across platforms','line_number':996,'multiline':False]
['text':' assertRaisesRegex does not pass with Python for Jetson,','line_number':1008,'multiline':False]
['text':' even though the RuntimeError matches regex using re.match','line_number':1009,'multiline':False]
['text':' increasing to 8MB to force acquiring a new block and overcome blocksize differences across platforms','line_number':1016,'multiline':False]
['text':' This function must run with non-default current streams on all devices, otherwise it's meaningless.','line_number':1024,'multiline':False]
['text':' The intention is to test that to()'s backward (CopyBackward) interacts properly with the','line_number':1025,'multiline':False]
['text':' synchronization logic in torch/csrc/autograd/input_buffer.cpp.','line_number':1026,'multiline':False]
['text':' Unfortunately I need to make the tensors largeish.','line_number':1030,'multiline':False]
['text':' Bigger tensors = longer D2D transfers = more likely to expose races.','line_number':1031,'multiline':False]
['text':' Here to_backward_recipient = a*b is used only once, so MulBackward's InputBuffer slot only expects 1 input.','line_number':1037,'multiline':False]
['text':' This tests the situation where we don't call InputBuffer::accumulate for MulBackward's InputBuffer.','line_number':1038,'multiline':False]
['text':' Here to_backward_recipient = a*b is used twice, so MulBackward's InputBuffer slot expects 2 inputs.','line_number':1047,'multiline':False]
['text':' This tests the situation where we do call InputBuffer::accumulate for MulBackward's InputBuffer.','line_number':1048,'multiline':False]
['text':' Multiply by 2 here so to's backward creates gradient values that are different from the case above,','line_number':1052,'multiline':False]
['text':' to mitigate weirdness if the caching allocator happens to reuse memory regions that were populated','line_number':1053,'multiline':False]
['text':' with 1s by the case above','line_number':1054,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/16559','line_number':1067,'multiline':False]
['text':' Tries selected combinations of','line_number':1093,'multiline':False]
['text':'  - contiguous grads','line_number':1094,'multiline':False]
['text':'  - g.clone().t() which is not contiguous but still non overlapping and dense','line_number':1095,'multiline':False]
['text':'  - variants of g.clone()[:, :5] which are not non overlapping and dense','line_number':1096,'multiline':False]
['text':' Non overlapping and dense grads route into a multi tensor apply kernel,','line_number':1097,'multiline':False]
['text':' others use a fallback per-tensor kernel, so we should try both.','line_number':1098,'multiline':False]
['text':' When passing lists with mismatched dtypes to a raw','line_number':1122,'multiline':False]
['text':' _amp_foreach_non_finite_check_and_unscale_ call,','line_number':1123,'multiline':False]
['text':' it's expected to fall back to single-tensor TensorIterator kernel.','line_number':1124,'multiline':False]
['text':' Passing lists with mismatched devices to a raw','line_number':1130,'multiline':False]
['text':' _amp_foreach_non_finite_check_and_unscale_ call should raise errors.','line_number':1131,'multiline':False]
['text':' Creates a list of grads with mismatched dtypes and devices, to ensure','line_number':1138,'multiline':False]
['text':' scaler._unscale_grads_ organizes grads by dtype and device before calling','line_number':1139,'multiline':False]
['text':' _amp_foreach_non_finite_check_and_unscale_ on each set.','line_number':1140,'multiline':False]
['text':' If inject_inf >= 0, writes an inf into one grad for _unscale_grads_ to find.','line_number':1141,'multiline':False]
['text':' Ensures the inf/nan checking can find an inf injected onto any grad in the perfect storm.','line_number':1157,'multiline':False]
['text':' No inf was injected, ensures unscaling worked normally.','line_number':1165,'multiline':False]
['text':' inf was injected, ensures inf was found.','line_number':1170,'multiline':False]
['text':' Ensure that different instances of "device" objects that point to the same device','line_number':1175,'multiline':False]
['text':' are treated as identical keys by dicts.  GradScaler relies on this behavior, and may','line_number':1176,'multiline':False]
['text':' error otherwise in a way that's difficult to detect (a silent performance hit).','line_number':1177,'multiline':False]
['text':' Create some nested iterables of tensors on different devices.','line_number':1206,'multiline':False]
['text':' Same as above, but runs some of the models on device 1.','line_number':1215,'multiline':False]
['text':' GradScaler should transparently handle losses and gradients on multiple devices.','line_number':1216,'multiline':False]
['text':' This test could be combined with the test above, but I think it makes sense to treat','line_number':1217,'multiline':False]
['text':' multi-GPU operations separately.','line_number':1218,'multiline':False]
['text':' As an additional stress test, separately unscale for one of the optimizers.','line_number':1245,'multiline':False]
['text':' Make sure the found_infs were collected properly across optimizers and devices.','line_number':1251,'multiline':False]
['text':' The loss scale should have been multiplied by the growth factor 3 times and the backoff factor once.','line_number':1270,'multiline':False]
['text':' Copy mod_control1 and mod_scaling1 back the device 0 for comparison','line_number':1274,'multiline':False]
['text':' test regular','line_number':1296,'multiline':False]
['text':' test not copying on same device','line_number':1301,'multiline':False]
['text':' test out=','line_number':1303,'multiline':False]
['text':' test error msg','line_number':1315,'multiline':False]
['text':' check that tensors on device[0] are returned as-is','line_number':1345,'multiline':False]
['text':' check that the tensors not on device[0] have different version counters','line_number':1350,'multiline':False]
['text':' NOTE [ Version Counter in comm.*_coalesced ]','line_number':1351,'multiline':False]
['text':' Note: fails sometimes on the CI, passes on dual gfx906','line_number':1359,'multiline':False]
['text':' int is 2x shorter','line_number':1374,'multiline':False]
['text':' int is 2x shorter','line_number':1388,'multiline':False]
['text':' Since we have both cuda:0 and cuda:1 inputs, the outputs must be new.','line_number':1425,'multiline':False]
['text':' We can check that they have different version counters.','line_number':1426,'multiline':False]
['text':' NOTE [ Version Counter in comm.*_coalesced ]','line_number':1427,'multiline':False]
['text':' int is 2x shorter','line_number':1449,'multiline':False]
['text':' int is 2x shorter','line_number':1463,'multiline':False]
['text':' test regular','line_number':1476,'multiline':False]
['text':' for target @ same device, a view should be returned','line_number':1487,'multiline':False]
['text':' test out','line_number':1489,'multiline':False]
['text':' test error msg','line_number':1502,'multiline':False]
['text':' test error msg','line_number':1581,'multiline':False]
['text':' tests ability to scatter namedtuples and retrieve a list where each','line_number':1619,'multiline':False]
['text':' element is of the expected namedtuple type.','line_number':1620,'multiline':False]
['text':' tests ability to gather a list of namedtuples and return a namedtuple where each','line_number':1662,'multiline':False]
['text':' element is of the expected tensor type.','line_number':1663,'multiline':False]
['text':' test on CPU','line_number':1678,'multiline':False]
['text':' x must be a tensor','line_number':1680,'multiline':False]
['text':' test on GPU','line_number':1684,'multiline':False]
['text':' test on GPU','line_number':1704,'multiline':False]
['text':' test on CPU','line_number':1710,'multiline':False]
