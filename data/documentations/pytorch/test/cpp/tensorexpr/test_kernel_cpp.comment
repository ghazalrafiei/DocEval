['text':' parallel ','line_number':44,'multiline':True]
['text':' here, each mul has only one use, so it should be completely inlined','line_number':56,'multiline':False]
['text':' aten_mul only has one use, inlined completely','line_number':98,'multiline':False]
['text':' aten_sub should be removed by the CUDA backend by metavar rewriting','line_number':101,'multiline':False]
['text':' and by the CPU backend by horizontal fusion.','line_number':102,'multiline':False]
['text':' Check whether the intermediate buffer has been added to constants','line_number':131,'multiline':False]
['text':' Check the IR we produced','line_number':135,'multiline':False]
['text':' Check correctness','line_number':139,'multiline':False]
['text':' Check the IR we produced','line_number':167,'multiline':False]
['text':' Check the IR we produced','line_number':205,'multiline':False]
['text':' Check the IR we produced','line_number':243,'multiline':False]
['text':' The 4000000000 iterations loop will be split into 500000000 x 8 and the','line_number':271,'multiline':False]
['text':' outer loop will be parallel. If LLVM is not present, it will not be split,','line_number':272,'multiline':False]
['text':' and to cover both of these cases we're looking for 00000000ll; in the','line_number':273,'multiline':False]
['text':' output.','line_number':274,'multiline':False]
['text':' disabled: doesn't do stride propagation, and isn't being used currently','line_number':308,'multiline':False]
['text':' Test TensorExpr shape inference capabilities: it should only require shapes','line_number':310,'multiline':False]
['text':' for the inputs','line_number':311,'multiline':False]
['text':' Check the IR we produced','line_number':334,'multiline':False]
['text':' Check the IR we produced','line_number':372,'multiline':False]
['text':' Test that shape inference handles aten::unsqueeze','line_number':388,'multiline':False]
['text':' Check the IR we produced','line_number':422,'multiline':False]
['text':' Check sizes','line_number':436,'multiline':False]
['text':' Check the contents','line_number':444,'multiline':False]
['text':' Test that shape inference handles aten::cat','line_number':450,'multiline':False]
['text':' Check the IR we produced','line_number':476,'multiline':False]
['text':' Check sizes','line_number':489,'multiline':False]
['text':' Check the contents','line_number':497,'multiline':False]
['text':' Test that we throw an error when input list for aten::cat is empty','line_number':503,'multiline':False]
['text':' Test that we throw an error when 'dim' passed to aten::cat is invalid','line_number':520,'multiline':False]
['text':' Test that we properly promote input types for aten::cat','line_number':550,'multiline':False]
['text':' Check the IR we produced','line_number':575,'multiline':False]
['text':' Check sizes','line_number':588,'multiline':False]
['text':' Check the contents','line_number':597,'multiline':False]
['text':' Check sizes','line_number':759,'multiline':False]
['text':' Check the contents','line_number':768,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-magic-numbers)','line_number':811,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-magic-numbers)','line_number':813,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-magic-numbers)','line_number':815,'multiline':False]
['text':' Check sizes','line_number':824,'multiline':False]
['text':' Check the contents','line_number':833,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-use-transparent-functors)','line_number':858,'multiline':False]
['text':' namespace','line_number':866,'multiline':False]
['text':' Test lowering of sum on all axes.','line_number':869,'multiline':False]
['text':'dtype=','line_number':895,'multiline':True]
['text':' Check the IR we produced','line_number':903,'multiline':False]
['text':' Test lowering of sum on one axis.','line_number':933,'multiline':False]
['text':'keepdim=','line_number':954,'multiline':True]
['text':'dtype=','line_number':954,'multiline':True]
['text':' Check the IR we produced','line_number':974,'multiline':False]
['text':' Test lowering of sum on multiple axes.','line_number':995,'multiline':False]
['text':' Only iterate over positive values of axes to keep the running time','line_number':1007,'multiline':False]
['text':' reasonable, since the number of pairs is quadratic.','line_number':1008,'multiline':False]
['text':'keepdim=','line_number':1018,'multiline':True]
['text':' Check the IR we produced','line_number':1035,'multiline':False]
['text':' This test and the following ones testing Softmax only tests with dim set','line_number':1056,'multiline':False]
['text':' to one of the valid input dimensions. It does not test with dim=None','line_number':1057,'multiline':False]
['text':' because that is supposed to be deprecated.','line_number':1058,'multiline':False]
['text':' verification sting temporarily disabled until','line_number':1116,'multiline':False]
['text':' inlining of exp() is benchmarked and determined','line_number':1117,'multiline':False]
['text':' torch::jit::testing::FileCheck().run(verification_pattern,','line_number':1118,'multiline':False]
['text':' oss.str());','line_number':1119,'multiline':False]
['text':' verification sting temporarily disabled until','line_number':1195,'multiline':False]
['text':' inlining of exp() is benchmarked and determined','line_number':1196,'multiline':False]
['text':' torch::jit::testing::FileCheck().run(verification_pattern, oss.str());','line_number':1197,'multiline':False]
['text':' verification sting temporarily disabled until','line_number':1278,'multiline':False]
['text':' inlining of exp() is benchmarked and determined','line_number':1279,'multiline':False]
['text':' torch::jit::testing::FileCheck().run(verification_pattern, oss.str());','line_number':1280,'multiline':False]
['text':' Inline producer (mul) into reduction (sum).','line_number':1370,'multiline':False]
['text':' Check the IR we produced.','line_number':1386,'multiline':False]
['text':' We should have only one loop in the end.','line_number':1387,'multiline':False]
['text':' Inline producer (mul %2) into reduction (sum %4) but DO NOT','line_number':1407,'multiline':False]
['text':' inline the reduction into consumer (mul %4).','line_number':1408,'multiline':False]
['text':' Check the IR we produced.','line_number':1425,'multiline':False]
['text':' We should have two loops in the end.','line_number':1426,'multiline':False]
['text':' IRParser doesn't support tensor constants, so we insert a call to','line_number':1482,'multiline':False]
['text':' aten::ones and then const-prop it','line_number':1483,'multiline':False]
['text':' We set the name of the constant to include special characters that are','line_number':1486,'multiline':False]
['text':' not allowed. This should be fixed by the sanitizer in TensorExprKernel.','line_number':1487,'multiline':False]
['text':' Check if we have a constant node with illegal name in the graph.','line_number':1490,'multiline':False]
['text':' IRParser doesn't support tensor constants, so we insert a call to','line_number':1518,'multiline':False]
['text':' aten::ones and then const-prop it','line_number':1519,'multiline':False]
['text':' IRParser doesn't support tensor constants, so we generate several aten','line_number':1550,'multiline':False]
['text':' calls to produce non-contiguous constant tensor and then const-prop it','line_number':1551,'multiline':False]
['text':' TODO: Implement call_raw in IREval and remove the ifdef','line_number':1570,'multiline':False]
['text':' IRParser doesn't support tensor constants, so we generate several aten','line_number':1639,'multiline':False]
['text':' calls to produce non-contiguous constant tensor and then const-prop it','line_number':1640,'multiline':False]
['text':' Check that we could retrieve generated assembly','line_number':1645,'multiline':False]
['text':' Check that we could retrieve info about codegen parameters','line_number':1653,'multiline':False]
['text':' Expected buf args: [input0, output0, constant0]','line_number':1656,'multiline':False]
['text':' Check that our custom lowering is actually used','line_number':1701,'multiline':False]
['text':' Check the IR we produced','line_number':1728,'multiline':False]
['text':' TODO: To vectorize loopnest for 100x3 case, we need to flatten loops first.','line_number':1741,'multiline':False]
['text':' Check the IR we produced','line_number':1764,'multiline':False]
['text':' Verify the generated IR. We expect to see a scalar variable (Let) followed','line_number':1842,'multiline':False]
['text':' by a store to a 0-dim buffer.','line_number':1843,'multiline':False]
['text':' Verify that TEK::runFast works correctly with scalar outputs','line_number':1854,'multiline':False]
['text':' Verify that TEK::run works correctly with scalar outputs','line_number':1861,'multiline':False]
['text':' Verify that TEK::runFast works correctly with mixed scalar and tensor','line_number':1889,'multiline':False]
['text':' inputs/utputs','line_number':1890,'multiline':False]
['text':' Verify that TEK::run works correctly with mixed scalar and tensor','line_number':1899,'multiline':False]
['text':' inputs/utputs','line_number':1900,'multiline':False]
['text':' namespace jit','line_number':2132,'multiline':False]
['text':' namespace torch','line_number':2133,'multiline':False]
