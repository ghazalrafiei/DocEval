['text':' *** Tensor Expressions ***','line_number':1,'multiline':False]
['text':'','line_number':2,'multiline':False]
['text':' This tutorial covers basics of NNC's tensor expressions, shows basic APIs to','line_number':3,'multiline':False]
['text':' work with them, and outlines how they are used in the overall TorchScript','line_number':4,'multiline':False]
['text':' compilation pipeline. This doc is permanently a "work in progress" since NNC','line_number':5,'multiline':False]
['text':' is under active development and things change fast.','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':' This Tutorial's code is compiled in the standard pytorch build, and the','line_number':8,'multiline':False]
['text':' executable can be found in `build/bin/tutorial_tensorexpr`.','line_number':9,'multiline':False]
['text':'','line_number':10,'multiline':False]
['text':' *** What is NNC ***','line_number':11,'multiline':False]
['text':'','line_number':12,'multiline':False]
['text':' NNC stands for Neural Net Compiler. It is a component of TorchScript JIT','line_number':13,'multiline':False]
['text':' and it performs on-the-fly code generation for kernels, which are often a','line_number':14,'multiline':False]
['text':' combination of multiple aten (torch) operators.','line_number':15,'multiline':False]
['text':'','line_number':16,'multiline':False]
['text':' When the JIT interpreter executes a torchscript model, it automatically','line_number':17,'multiline':False]
['text':' extracts subgraphs from the torchscript IR graph for which specialized code','line_number':18,'multiline':False]
['text':' can be JIT generated. This usually improves performance as the 'combined'','line_number':19,'multiline':False]
['text':' kernel created from the subgraph could avoid unnecessary memory traffic that','line_number':20,'multiline':False]
['text':' is unavoidable when the subgraph is interpreted as-is, operator by operator.','line_number':21,'multiline':False]
['text':' This optimization is often referred to as 'fusion'. Relatedly, the process of','line_number':22,'multiline':False]
['text':' finding and extracting subgraphs suitable for NNC code generation is done by','line_number':23,'multiline':False]
['text':' a JIT pass called 'fuser'.','line_number':24,'multiline':False]
['text':'','line_number':25,'multiline':False]
['text':' *** What is TE ***','line_number':26,'multiline':False]
['text':'','line_number':27,'multiline':False]
['text':' TE stands for Tensor Expressions. TE is a commonly used approach for','line_number':28,'multiline':False]
['text':' compiling kernels performing tensor (~matrix) computation. The idea behind it','line_number':29,'multiline':False]
['text':' is that operators are represented as a mathematical formula describing what','line_number':30,'multiline':False]
['text':' computation they do (as TEs) and then the TE engine can perform mathematical','line_number':31,'multiline':False]
['text':' simplification and other optimizations using those formulas and eventually','line_number':32,'multiline':False]
['text':' generate executable code that would produce the same results as the original','line_number':33,'multiline':False]
['text':' sequence of operators, but more efficiently.','line_number':34,'multiline':False]
['text':'','line_number':35,'multiline':False]
['text':' NNC's design and implementation of TE was heavily inspired by Halide and TVM','line_number':36,'multiline':False]
['text':' projects.','line_number':37,'multiline':False]
['text':' Helper function to print a snippet from a big multi-line string','line_number':59,'multiline':False]
['text':' A tensor expression is a tree of expressions. Each expression has a type,','line_number':68,'multiline':False]
['text':' and that type defines what sub-expressions the current expression has.','line_number':69,'multiline':False]
['text':' For instance, an expression of type 'Mul' would have a type 'kMul' and','line_number':70,'multiline':False]
['text':' two subexpressions: LHS and RHS. Each of these two sub-expressions could','line_number':71,'multiline':False]
['text':' also be a 'Mul' or some other expression.','line_number':72,'multiline':False]
['text':'','line_number':73,'multiline':False]
['text':' Let's construct a simple TE:','line_number':74,'multiline':False]
['text':' Prints: Tensor expression: 5 * x','line_number':79,'multiline':False]
['text':' Here we created an expression representing a 5*x computation, where x is','line_number':81,'multiline':False]
['text':' an int variable.','line_number':82,'multiline':False]
['text':' Another, probably a more convenient, way to construct tensor expressions','line_number':84,'multiline':False]
['text':' is to use so called expression handles (as opposed to raw expressions','line_number':85,'multiline':False]
['text':' like we did in the previous example). Expression handles overload common','line_number':86,'multiline':False]
['text':' operations and allow us to express the same semantics in a more natural','line_number':87,'multiline':False]
['text':' way:','line_number':88,'multiline':False]
['text':' Prints: Tensor expression: 5 * x','line_number':93,'multiline':False]
['text':' Converting from handles to raw expressions and back is easy:','line_number':95,'multiline':False]
['text':' We could construct arbitrarily complex expressions using mathematical','line_number':101,'multiline':False]
['text':' and logical operations, casts between various data types, and a bunch of','line_number':102,'multiline':False]
['text':' intrinsics.','line_number':103,'multiline':False]
['text':' Prints: Tensor expression: float(5 * a) + b / ((sigmoid(c)) - 3.f)','line_number':109,'multiline':False]
['text':' An ultimate purpose of tensor expressions is to optimize tensor','line_number':111,'multiline':False]
['text':' computations, and in order to represent accesses to tensors data, there','line_number':112,'multiline':False]
['text':' is a special kind of expression - a load.','line_number':113,'multiline':False]
['text':' To construct a load we need two pieces: the base and the indices. The','line_number':114,'multiline':False]
['text':' base of a load is a Buf expression, which could be thought of as a','line_number':115,'multiline':False]
['text':' placeholder similar to Var, but with dimensions info.','line_number':116,'multiline':False]
['text':'','line_number':117,'multiline':False]
['text':' Let's construct a simple load:','line_number':118,'multiline':False]
['text':' Prints: Tensor expression: A[i, j]','line_number':124,'multiline':False]
['text':' Tensor Expressions constitute Tensor Statements, which are used to','line_number':126,'multiline':False]
['text':' represent computation of a given operator or a group of operators from a','line_number':127,'multiline':False]
['text':' fusion group.','line_number':128,'multiline':False]
['text':'','line_number':129,'multiline':False]
['text':' There are three main kinds of tensor statements:','line_number':130,'multiline':False]
['text':'  - block','line_number':131,'multiline':False]
['text':'  - store','line_number':132,'multiline':False]
['text':'  - loop','line_number':133,'multiline':False]
['text':'','line_number':134,'multiline':False]
['text':' A Store represents a store to a single element of a tensor (or to a','line_number':135,'multiline':False]
['text':' group of elements if it's a vectorized store). Store statements,','line_number':136,'multiline':False]
['text':' similarly to Load expressions, have a base and indices, but on top of','line_number':137,'multiline':False]
['text':' that they also include a value - an expression representing what needs','line_number':138,'multiline':False]
['text':' to be stored at the given memory location. Let's create a Store stmt:','line_number':139,'multiline':False]
['text':' Prints: Store statement: A[i, j] = i + j;','line_number':142,'multiline':False]
['text':' An operator fills the entire tensor, not just a single element, and to','line_number':144,'multiline':False]
['text':' represent this we need to use For stmt: let's wrap our store stmt with','line_number':145,'multiline':False]
['text':' two nested loops to represent that variables i and j need to iterate','line_number':146,'multiline':False]
['text':' over some ranges.','line_number':147,'multiline':False]
['text':' Prints:','line_number':152,'multiline':False]
['text':' Nested for loops:','line_number':153,'multiline':False]
['text':' for (const auto i : c10::irange(64)) {','line_number':154,'multiline':False]
['text':'   for (const auto j : c10::irange(32)) {','line_number':155,'multiline':False]
['text':'     A[i, j] = i + j;','line_number':156,'multiline':False]
['text':'   }','line_number':157,'multiline':False]
['text':' }','line_number':158,'multiline':False]
['text':' A Block statement is used when we need a sequence of other statements.','line_number':160,'multiline':False]
['text':' E.g. if a fusion group contains several operators, we initially define','line_number':161,'multiline':False]
['text':' separate loopnest for each of them and put them all into a common block:','line_number':162,'multiline':False]
['text':' Prints:','line_number':171,'multiline':False]
['text':' Compound Block statement:','line_number':172,'multiline':False]
['text':' {','line_number':173,'multiline':False]
['text':'   for (const auto i : c10::irange(64)) {','line_number':174,'multiline':False]
['text':'     for (const auto j : c10::irange(32)) {','line_number':175,'multiline':False]
['text':'       A[i, j] = i + j;','line_number':176,'multiline':False]
['text':'     }','line_number':177,'multiline':False]
['text':'   }','line_number':178,'multiline':False]
['text':'   for (const auto i : c10::irange(64)) {','line_number':179,'multiline':False]
['text':'     for (const auto j : c10::irange(32)) {','line_number':180,'multiline':False]
['text':'       B[i, j] = A[i, j];','line_number':181,'multiline':False]
['text':'     }','line_number':182,'multiline':False]
['text':'   }','line_number':183,'multiline':False]
['text':' }','line_number':184,'multiline':False]
['text':' Manually constructing nested loops and blocks to represent a computation','line_number':186,'multiline':False]
['text':' might be laborious, and instead we can use a 'Compute' API. This API','line_number':187,'multiline':False]
['text':' requires us to specify dimensions and a lambda to compute a single','line_number':188,'multiline':False]
['text':' element of the resulting tensor and returns a `Tensor` structure. This','line_number':189,'multiline':False]
['text':' structure is simply a pair of a buffer that was created to represent the','line_number':190,'multiline':False]
['text':' result of the computation (BufPtr) and a statement representing the','line_number':191,'multiline':False]
['text':' computation itself (StmtPtr).','line_number':192,'multiline':False]
['text':' Prints:','line_number':199,'multiline':False]
['text':' Stmt produced by 'Compute' API:','line_number':200,'multiline':False]
['text':' for (const auto i : c10::irange(64)) {','line_number':201,'multiline':False]
['text':'   for (const auto j : c10::irange(32)) {','line_number':202,'multiline':False]
['text':'     C[i, j] = i * j;','line_number':203,'multiline':False]
['text':'   }','line_number':204,'multiline':False]
['text':' }','line_number':205,'multiline':False]
['text':' To construct statements to represent computations with reductions, we','line_number':207,'multiline':False]
['text':' can use a 'Reduce' API - it is similar to 'Compute' but takes a couple','line_number':208,'multiline':False]
['text':' of extra arguments defining how to perform the reduction. Let's define a','line_number':209,'multiline':False]
['text':' simple 2D sum of C using that:','line_number':210,'multiline':False]
['text':' When a statement for the computation is generated, we might want to','line_number':223,'multiline':False]
['text':' apply some optimizations to it. These transformations allow us to end up','line_number':224,'multiline':False]
['text':' with a statement producing the same results, but more efficiently.','line_number':225,'multiline':False]
['text':'','line_number':226,'multiline':False]
['text':' Let's look at a couple of transformations that are used in NNC. We will','line_number':227,'multiline':False]
['text':' begin with constructing a Block statement like we did before.','line_number':228,'multiline':False]
['text':' Prints:','line_number':242,'multiline':False]
['text':' Stmt produced by 'Compute' API:','line_number':243,'multiline':False]
['text':' {','line_number':244,'multiline':False]
['text':'   for (const auto i : c10::irange(64)) {','line_number':245,'multiline':False]
['text':'     for (const auto j : c10::irange(32)) {','line_number':246,'multiline':False]
['text':'       C[i, j] = i * (j + 1);','line_number':247,'multiline':False]
['text':'     }','line_number':248,'multiline':False]
['text':'   }','line_number':249,'multiline':False]
['text':'   for (const auto i_1 : c10::irange(64)) {','line_number':250,'multiline':False]
['text':'     for (const auto j_1 : c10::irange(32)) {','line_number':251,'multiline':False]
['text':'       D[i_1, j_1] = (C[i_1, j_1]) - i_1;','line_number':252,'multiline':False]
['text':'     }','line_number':253,'multiline':False]
['text':'   }','line_number':254,'multiline':False]
['text':' }','line_number':255,'multiline':False]
['text':' One transformation we can apply to this computation is inlining: i.e.','line_number':257,'multiline':False]
['text':' taking the expression that defines values of C and substituting a load','line_number':258,'multiline':False]
['text':' from C with it.','line_number':259,'multiline':False]
['text':' To do that, we first need to create a special object called LoopNest -','line_number':260,'multiline':False]
['text':' all transformations are methods of this class. To create a loopnest we','line_number':261,'multiline':False]
['text':' need to provide a list of output buffers and the root statement:','line_number':262,'multiline':False]
['text':' We can always retrieve the Stmt back from LoopNest:','line_number':265,'multiline':False]
['text':' Prints:','line_number':268,'multiline':False]
['text':' LoopNest root stmt:','line_number':269,'multiline':False]
['text':' {','line_number':270,'multiline':False]
['text':'   for (const auto i : c10::irange(64)) {','line_number':271,'multiline':False]
['text':'     for (const auto j : c10::irange(32)) {','line_number':272,'multiline':False]
['text':'       C[i, j] = i * (j + 1);','line_number':273,'multiline':False]
['text':'     }','line_number':274,'multiline':False]
['text':'   }','line_number':275,'multiline':False]
['text':'   for (const auto i_1 : c10::irange(64)) {','line_number':276,'multiline':False]
['text':'     for (const auto j_1 : c10::irange(32)) {','line_number':277,'multiline':False]
['text':'       D[i_1, j_1] = (C[i_1, j_1]) - i_1;','line_number':278,'multiline':False]
['text':'     }','line_number':279,'multiline':False]
['text':'   }','line_number':280,'multiline':False]
['text':' }','line_number':281,'multiline':False]
['text':' Now we can apply the inlining transformation:','line_number':283,'multiline':False]
['text':' Prints:','line_number':287,'multiline':False]
['text':' Stmt after inlining:','line_number':288,'multiline':False]
['text':' {','line_number':289,'multiline':False]
['text':'   for (const auto i : c10::irange(64)) {','line_number':290,'multiline':False]
['text':'     for (const auto j : c10::irange(32)) {','line_number':291,'multiline':False]
['text':'       D[i, j] = i * (j + 1) - i;','line_number':292,'multiline':False]
['text':'     }','line_number':293,'multiline':False]
['text':'   }','line_number':294,'multiline':False]
['text':' }','line_number':295,'multiline':False]
['text':' We can also apply algebraic simplification to a statement:','line_number':297,'multiline':False]
['text':' Prints:','line_number':301,'multiline':False]
['text':' Stmt after simplification:','line_number':302,'multiline':False]
['text':' {','line_number':303,'multiline':False]
['text':'   for (const auto i : c10::irange(64)) {','line_number':304,'multiline':False]
['text':'     for (const auto j : c10::irange(32)) {','line_number':305,'multiline':False]
['text':'       D[i, j] = i * j;','line_number':306,'multiline':False]
['text':'     }','line_number':307,'multiline':False]
['text':'   }','line_number':308,'multiline':False]
['text':' }','line_number':309,'multiline':False]
['text':' Many loopnest transformations are stateless and can be applied without','line_number':311,'multiline':False]
['text':' creating a LoopNest object. In fact, we plan to make all transformations','line_number':312,'multiline':False]
['text':' stateless.','line_number':313,'multiline':False]
['text':' splitWithTail is one such transformation: it splits an iteration space','line_number':314,'multiline':False]
['text':' of a given loop into two with a given factor.','line_number':315,'multiline':False]
['text':' Call simplifier once more to fold some arithmetic.','line_number':318,'multiline':False]
['text':' Prints:','line_number':322,'multiline':False]
['text':' Stmt after splitWithTail:','line_number':323,'multiline':False]
['text':' {','line_number':324,'multiline':False]
['text':'   for (const auto i_outer : c10::irange(4)) {','line_number':325,'multiline':False]
['text':'     for (const auto i_inner : c10::irange(13)) {','line_number':326,'multiline':False]
['text':'       for (const auto j : c10::irange(32)) {','line_number':327,'multiline':False]
['text':'         D[i_inner + 13 * i_outer, j] = i_inner * j + 13 * (i_outer * j);','line_number':328,'multiline':False]
['text':'       }','line_number':329,'multiline':False]
['text':'     }','line_number':330,'multiline':False]
['text':'   }','line_number':331,'multiline':False]
['text':'   for (const auto i_tail : c10::irange(12)) {','line_number':332,'multiline':False]
['text':'     for (const auto j : c10::irange(32)) {','line_number':333,'multiline':False]
['text':'       D[i_tail + 52, j] = i_tail * j + 52 * j;','line_number':334,'multiline':False]
['text':'     }','line_number':335,'multiline':False]
['text':'   }','line_number':336,'multiline':False]
['text':' }','line_number':337,'multiline':False]
['text':' NNC supports a wide range of loop nest transformations, which we are not','line_number':339,'multiline':False]
['text':' listing here. Please refer to documentation in','line_number':340,'multiline':False]
['text':' https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/tensorexpr/loopnest.h','line_number':341,'multiline':False]
['text':' for more details.','line_number':342,'multiline':False]
['text':' An ultimate goal of tensor expressions is to be provide a mechanism to','line_number':347,'multiline':False]
['text':' execute a given computation in the fastest possible way. So far we've','line_number':348,'multiline':False]
['text':' looked at how we could describe what computation we're interested in, but','line_number':349,'multiline':False]
['text':' we haven't looked at how to actually execute it.','line_number':350,'multiline':False]
['text':'','line_number':351,'multiline':False]
['text':' All we've been dealing with was just symbols with no actual data','line_number':352,'multiline':False]
['text':' associated, in this section we would look at how we can bridge that gap.','line_number':353,'multiline':False]
['text':' Let's start by constructing a simple computation for us to work with:','line_number':355,'multiline':False]
['text':' And let's lower it to a loop nest, as we did in the previous section. We','line_number':363,'multiline':False]
['text':' can pass Tensor object directly:','line_number':364,'multiline':False]
['text':' Prints:','line_number':367,'multiline':False]
['text':' {','line_number':368,'multiline':False]
['text':'   for (const auto i : c10::irange(64)) {','line_number':369,'multiline':False]
['text':'     for (const auto j : c10::irange(32)) {','line_number':370,'multiline':False]
['text':'       X[i, j] = (A[i, j]) + (B[i, j]);','line_number':371,'multiline':False]
['text':'     }','line_number':372,'multiline':False]
['text':'   }','line_number':373,'multiline':False]
['text':' Now imagine that we have two actual tensors 64x32 that we want sum','line_number':375,'multiline':False]
['text':' together, how do we pass those tensors to the computation and how do we','line_number':376,'multiline':False]
['text':' carry it out?','line_number':377,'multiline':False]
['text':'','line_number':378,'multiline':False]
['text':' Codegen object is aimed at providing exactly that functionality. Codegen','line_number':379,'multiline':False]
['text':' is an abstract class and concrete codegens are derived from it.','line_number':380,'multiline':False]
['text':' Currently, we have three codegens:','line_number':381,'multiline':False]
['text':'  1) Simple Evaluator,','line_number':382,'multiline':False]
['text':'  2) LLVM Codegen for CPU,','line_number':383,'multiline':False]
['text':'  3) CUDA Codegen.','line_number':384,'multiline':False]
['text':' In this example we will be using Simple Evaluator, since it's available','line_number':385,'multiline':False]
['text':' everywhere.','line_number':386,'multiline':False]
['text':' To create a codegen, we need to provide the statement - it specifies the','line_number':388,'multiline':False]
['text':' computation we want to perform - and a list of placeholders and tensors','line_number':389,'multiline':False]
['text':' used in the computation. The latter part is crucial since that's the only','line_number':390,'multiline':False]
['text':' way the codegen could use to correlate symbols in the statement to actual','line_number':391,'multiline':False]
['text':' data arrays that we will be passing when we will actually be performing','line_number':392,'multiline':False]
['text':' the computation.','line_number':393,'multiline':False]
['text':'','line_number':394,'multiline':False]
['text':' Let's create a Simple IR Evaluator codegen for our computation:','line_number':395,'multiline':False]
['text':' We are using the simplest codegen and in it almost no work is done at the','line_number':398,'multiline':False]
['text':' construction step. Real codegens such as CUDA and LLVM perform','line_number':399,'multiline':False]
['text':' compilation during that stage so that when we're about to run the','line_number':400,'multiline':False]
['text':' computation everything is ready.','line_number':401,'multiline':False]
['text':' Let's now create some inputs and run our computation with them:','line_number':403,'multiline':False]
['text':' This will be the input A','line_number':404,'multiline':False]
['text':' This will be the input B','line_number':405,'multiline':False]
['text':' This will be used for the result','line_number':406,'multiline':False]
['text':' Now let's invoke our codegen to perform the computation on our data. We','line_number':408,'multiline':False]
['text':' need to provide as many arguments as how many placeholders and tensors we','line_number':409,'multiline':False]
['text':' passed at the codegen construction time. A position in these lists would','line_number':410,'multiline':False]
['text':' define how real data arrays from the latter call (these arguments are','line_number':411,'multiline':False]
['text':' referred to as 'CallArg's in our codebase) correspond to symbols','line_number':412,'multiline':False]
['text':' (placeholders and tensors) used in the tensor expressions we constructed','line_number':413,'multiline':False]
['text':' (these are referred to as 'BufferArg').','line_number':414,'multiline':False]
['text':' Thus, we will provide three arguments: data_A, data_B, and data_X. data_A','line_number':415,'multiline':False]
['text':' contains data for the placeholder A, data_B - for the placeholder B, and','line_number':416,'multiline':False]
['text':' data_X would be used for contents of tensor X.','line_number':417,'multiline':False]
['text':' Let's print one of the elements from each array to verify that the','line_number':420,'multiline':False]
['text':' computation did happen:','line_number':421,'multiline':False]
['text':' Prints:','line_number':425,'multiline':False]
['text':' A[10] = 3','line_number':426,'multiline':False]
['text':' B[10] = 5','line_number':427,'multiline':False]
['text':' X[10] = A[10] + B[10] = 8','line_number':428,'multiline':False]
['text':' This section requires a LLVM-enabled PyTorch build, so we have to use a','line_number':433,'multiline':False]
['text':' guard:','line_number':434,'multiline':False]
['text':' Often we would like to convert a TorchScript IR to TE rather than','line_number':437,'multiline':False]
['text':' construct TE IR from scratch.  NNC provides an API to perform such','line_number':438,'multiline':False]
['text':' lowering: it takes a TorchScript graph and returns an object that can be','line_number':439,'multiline':False]
['text':' used to invoke the generated kernel.','line_number':440,'multiline':False]
['text':' This API is currently used by the TorchScript JIT fuser and can also be','line_number':441,'multiline':False]
['text':' used ahead of time to pre-compile parts of a model.','line_number':442,'multiline':False]
['text':'','line_number':443,'multiline':False]
['text':' To get familiar with this API let's first start with defining a simple','line_number':444,'multiline':False]
['text':' TorchScript graph:','line_number':445,'multiline':False]
['text':' This graph defines a simple computation of A*A*B + B where A and B are','line_number':457,'multiline':False]
['text':' input 5x3 tensors.','line_number':458,'multiline':False]
['text':' To lower this TorchScript graph to TE, we just need to create a','line_number':460,'multiline':False]
['text':' TensorExprKernel object. In its constructor it constructs the','line_number':461,'multiline':False]
['text':' corresponding TE IR and compiles it for the given backend (in this','line_number':462,'multiline':False]
['text':' example for CPU using LLVM compiler).','line_number':463,'multiline':False]
['text':' We can retrieve the generated TE stmt from the kernel object:','line_number':466,'multiline':False]
['text':' Prints:','line_number':470,'multiline':False]
['text':' TE Stmt constructed from TorchScript:','line_number':471,'multiline':False]
['text':' {','line_number':472,'multiline':False]
['text':'   for (const auto v : c10::irange(5)) {','line_number':473,'multiline':False]
['text':'     for (const auto _tail_tail : c10::irange(3)) {','line_number':474,'multiline':False]
['text':'       aten_add[_tail_tail + 3 * v] = (tA[_tail_tail + 3 * v]) *','line_number':475,'multiline':False]
['text':'       ((tA[_tail_tail + 3 * v]) * (tB[_tail_tail + 3 * v])) +','line_number':476,'multiline':False]
['text':'       (tB[_tail_tail + 3 * v]);','line_number':477,'multiline':False]
['text':'     }','line_number':478,'multiline':False]
['text':'   }','line_number':479,'multiline':False]
['text':' }','line_number':480,'multiline':False]
['text':' We can also examine generated LLVM IR and assembly code:','line_number':482,'multiline':False]
['text':' Prints:','line_number':486,'multiline':False]
['text':' Generated LLVM IR:','line_number':487,'multiline':False]
['text':'   %9 = bitcast float* %2 to <8 x float>*','line_number':488,'multiline':False]
['text':'   %10 = load <8 x float>, <8 x float>* %9 ...','line_number':489,'multiline':False]
['text':'   %11 = bitcast float* %5 to <8 x float>*','line_number':490,'multiline':False]
['text':'   %12 = load <8 x float>, <8 x float>* %11 ...','line_number':491,'multiline':False]
['text':'   %13 = fmul <8 x float> %10, %12','line_number':492,'multiline':False]
['text':'   %14 = fmul <8 x float> %10, %13','line_number':493,'multiline':False]
['text':' Prints:','line_number':498,'multiline':False]
['text':' Generated assembly:','line_number':499,'multiline':False]
['text':'         vmulps  %ymm1, %ymm0, %ymm2','line_number':500,'multiline':False]
['text':'         vfmadd213ps     %ymm1, %ymm0, %ymm2','line_number':501,'multiline':False]
['text':'         vmovups %ymm2, (%rax)','line_number':502,'multiline':False]
['text':'         vmovss  32(%rcx), %xmm0','line_number':503,'multiline':False]
['text':'         vmovss  32(%rdx), %xmm1','line_number':504,'multiline':False]
['text':'         vmulss  %xmm1, %xmm0, %xmm2','line_number':505,'multiline':False]
['text':' We can also execute the generated kernel:','line_number':507,'multiline':False]
['text':' Let's print one of the elements from the result tensor to verify that the','line_number':519,'multiline':False]
['text':' computation did happen and was correct:','line_number':520,'multiline':False]
['text':' Prints:','line_number':522,'multiline':False]
['text':' R[2][2] = 15','line_number':523,'multiline':False]
['text':' [ CPUFloatType{} ]','line_number':524,'multiline':False]
