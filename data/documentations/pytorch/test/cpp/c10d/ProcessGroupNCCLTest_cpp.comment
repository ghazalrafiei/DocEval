['text':' overwrite ','line_number':55,'multiline':True]
['text':' Each device has a single tensor to perf the NCCL op','line_number':85,'multiline':False]
['text':' Allocate a stream per device.','line_number':102,'multiline':False]
['text':'','line_number':103,'multiline':False]
['text':' The "current stream" is set globally per device in THC, so we','line_number':104,'multiline':False]
['text':' can't make two tensors on the same device use different streams','line_number':105,'multiline':False]
['text':' and pass this along to the collective (since it uses the THC','line_number':106,'multiline':False]
['text':' getters to retrieve the current stream).','line_number':107,'multiline':False]
['text':'','line_number':108,'multiline':False]
['text':' For the duration of this function, make THC use our streams','line_number':126,'multiline':False]
['text':' Copy inputs to outputs','line_number':129,'multiline':False]
['text':' For the duration of this function, make THC use our streams','line_number':157,'multiline':False]
['text':' Copy inputs to outputs','line_number':160,'multiline':False]
['text':' Launches sleep on every CUDA device','line_number':171,'multiline':False]
['text':' Launches value initialization for every tensor','line_number':180,'multiline':False]
['text':' Get the indices of all non-zero elements in the dense tensor','line_number':190,'multiline':False]
['text':' Get the unique row indices of the non-zero elements','line_number':191,'multiline':False]
['text':'dim=','line_number':193,'multiline':True]
['text':'index=','line_number':193,'multiline':True]
['text':'dim=','line_number':195,'multiline':True]
['text':' get the values at the non-zero indices','line_number':195,'multiline':False]
['text':' Launches value initialization for every sparse tensor','line_number':201,'multiline':False]
['text':' Convert the dense tensor to a sparse tensor in COO row format','line_number':207,'multiline':False]
['text':' For the duration of this function, make THC use our streams','line_number':226,'multiline':False]
['text':' Make sure enabling profile does not make any issue. Note, in single','line_number':233,'multiline':False]
['text':' process multi-device mode we do not expect any events be populated for','line_number':234,'multiline':False]
['text':' collective operations, since profiling for that mode is not supported.','line_number':235,'multiline':False]
['text':' For the duration of this function, make THC use our streams','line_number':253,'multiline':False]
['text':' For the duration of this function, make THC use our streams','line_number':268,'multiline':False]
['text':' For the duration of this function, make THC use our streams','line_number':287,'multiline':False]
['text':' For the duration of this function, make THC use our streams','line_number':306,'multiline':False]
['text':' For the duration of this function, make THC use our streams','line_number':324,'multiline':False]
['text':' contains at least one element otherwise wouldn't run.','line_number':329,'multiline':False]
['text':' this is a flattened allgather, hence one rank contributes','line_number':330,'multiline':False]
['text':' only 1 tensor, regardless of number of devices','line_number':331,'multiline':False]
['text':' For the duration of this function, make THC use our streams','line_number':354,'multiline':False]
['text':' Launch value initialization for every tensor','line_number':360,'multiline':False]
['text':' For the duration of this function, make THC use our streams','line_number':385,'multiline':False]
['text':' Wait for work to finish','line_number':411,'multiline':False]
['text':' Validation','line_number':414,'multiline':False]
['text':' Wait for work to finish','line_number':432,'multiline':False]
['text':' validate the work output is same as tensor','line_number':437,'multiline':False]
['text':' Validation','line_number':439,'multiline':False]
['text':' Add one since we are seeding with an additional 1 to prevent empty tensors','line_number':441,'multiline':False]
['text':' validate the tensor is sparse','line_number':447,'multiline':False]
['text':' validate indices are expected size','line_number':453,'multiline':False]
['text':' row indices','line_number':457,'multiline':False]
['text':' coordinate indices','line_number':460,'multiline':False]
['text':' validate all tensor values are expected value','line_number':464,'multiline':False]
['text':' expect the input and output tensors should be the same','line_number':471,'multiline':False]
['text':' Wait for work to finish','line_number':483,'multiline':False]
['text':' validate the work output is same as tensor','line_number':488,'multiline':False]
['text':' Validation','line_number':490,'multiline':False]
['text':' Add one since we are seeding with an additional 1 to prevent empty tensors','line_number':492,'multiline':False]
['text':' validate the tensor is sparse','line_number':498,'multiline':False]
['text':' validate indices are expected size','line_number':504,'multiline':False]
['text':' row indices','line_number':508,'multiline':False]
['text':' coordinate indices','line_number':511,'multiline':False]
['text':' validate all tensor values are expected value','line_number':515,'multiline':False]
['text':' expect the input and output tensors should be the same','line_number':522,'multiline':False]
['text':' try every permutation of root rank and root tensor','line_number':534,'multiline':False]
['text':' wait for work to complete','line_number':539,'multiline':False]
['text':' Check results','line_number':542,'multiline':False]
['text':' try every permutation of root rank and root tensor','line_number':561,'multiline':False]
['text':' wait for work to complete','line_number':566,'multiline':False]
['text':' Validation','line_number':569,'multiline':False]
['text':' Wait for work to finish','line_number':589,'multiline':False]
['text':' Validation','line_number':592,'multiline':False]
['text':' device index','line_number':594,'multiline':False]
['text':' rank index','line_number':596,'multiline':False]
['text':' Wait for work to finish','line_number':613,'multiline':False]
['text':' Validation','line_number':615,'multiline':False]
['text':' Rank index','line_number':621,'multiline':False]
['text':' expected is i // input.numel() <- rank, and each rank contributed rank *','line_number':623,'multiline':False]
['text':' num_gpu','line_number':624,'multiline':False]
['text':' Wait for work to finish','line_number':634,'multiline':False]
['text':' Validation','line_number':636,'multiline':False]
['text':' Rank index','line_number':642,'multiline':False]
['text':' expected is i * input.numel() <- rank, and each rank contributed rank *','line_number':644,'multiline':False]
['text':' num_gpu','line_number':645,'multiline':False]
['text':' Wait for work to finish','line_number':656,'multiline':False]
['text':' Validation','line_number':662,'multiline':False]
['text':' device index','line_number':664,'multiline':False]
['text':' simulate world_size > 1 here via threads.','line_number':680,'multiline':False]
['text':' Catch error relating to health check failure','line_number':685,'multiline':False]
['text':' unused ','line_number':713,'multiline':True]
['text':' unused ','line_number':714,'multiline':True]
['text':' timeout ','line_number':715,'multiline':True]
['text':' unused ','line_number':720,'multiline':True]
['text':' unused ','line_number':721,'multiline':True]
['text':' timeout ','line_number':722,'multiline':True]
['text':' unused ','line_number':727,'multiline':True]
['text':' unused ','line_number':728,'multiline':True]
['text':' Note: ProcessGroupNCCLTest doesn't support multiprocess testing. So we','line_number':729,'multiline':False]
['text':' simulate world_size > 1 here via threads.','line_number':730,'multiline':False]
['text':' Use WORLD_SIZE and RANK environmental variables to do multi-node','line_number':757,'multiline':False]
['text':' distributed testing','line_number':758,'multiline':False]
['text':' Reset TORCH_NCCL_BLOCKING_WAIT environment variable after each run.','line_number':770,'multiline':False]
['text':' Skip tests if CUDA is not available.','line_number':775,'multiline':False]
['text':' Steal the broadcast test and issue it for both of our groups.','line_number':912,'multiline':False]
['text':' This ensures consistent full collective communication.  TODO:','line_number':913,'multiline':False]
['text':' maybe refactor the guts rather than copy-pasta, but it may not be','line_number':914,'multiline':False]
['text':' worth it.','line_number':915,'multiline':False]
['text':' try every permutation of root rank and root tensor','line_number':918,'multiline':False]
['text':' Check results','line_number':924,'multiline':False]
['text':' Now that we've run full operations on both the original and split process','line_number':938,'multiline':False]
['text':' group, ensure we saw exactly as many splits as we expected: 0 in the','line_number':939,'multiline':False]
['text':' original process group, and one per device in the second.','line_number':940,'multiline':False]
