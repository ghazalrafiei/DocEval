['text':' NOLINT','line_number':32,'multiline':False]
['text':' NOLINT','line_number':36,'multiline':False]
['text':' Tests go in torch::jit','line_number':38,'multiline':False]
['text':'device=','line_number':50,'multiline':True]
['text':'extra_files=','line_number':51,'multiline':True]
['text':' namespace','line_number':54,'multiline':False]
['text':' Manually create some data with Flatbuffer header.','line_number':57,'multiline':False]
['text':' Loading module from it should throw an exception.','line_number':62,'multiline':False]
['text':' Check guard at parse_and_initialize_mobile_module_for_jit.','line_number':63,'multiline':False]
['text':' Check guard at parse_and_initialize_mobile_module.','line_number':67,'multiline':False]
['text':' NOLINT (use =delete in gtest)','line_number':151,'multiline':False]
['text':' test invoking a method with default parameter','line_number':153,'multiline':False]
['text':' inner method call with default parameter (gets inlined)','line_number':158,'multiline':False]
['text':' simple method call','line_number':165,'multiline':False]
['text':' (keep linter happy)','line_number':177,'multiline':False]
['text':' !defined(FB_XPLAT_BUILD)','line_number':219,'multiline':False]
['text':'use_flatbuffer=','line_number':239,'multiline':True]
['text':' load it twice using the same stream','line_number':247,'multiline':False]
['text':' Test if flatbuffer does not require any explicit key entries mapping in the','line_number':253,'multiline':False]
['text':' extra file map.','line_number':254,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-magic-numbers,modernize-use-emplace)','line_number':285,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-magic-numbers,modernize-use-emplace)','line_number':327,'multiline':False]
['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':465,'multiline':False]
['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':477,'multiline':False]
['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':501,'multiline':False]
['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':513,'multiline':False]
['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':569,'multiline':False]
['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':581,'multiline':False]
['text':' Check to see if it is a custom class.','line_number':612,'multiline':False]
['text':' If it's not a custom class, assume it's another namespace','line_number':617,'multiline':False]
['text':' NOLINTNEXTLINE(performance-move-const-arg)','line_number':618,'multiline':False]
['text':' namespace','line_number':649,'multiline':False]
['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':697,'multiline':False]
['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':705,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-magic-numbers,modernize-use-emplace)','line_number':722,'multiline':False]
['text':' save m in training mode to make sure that mobile eval() will correctly','line_number':727,'multiline':False]
['text':' change back to eval mode','line_number':728,'multiline':False]
['text':' a more stable matrix','line_number':995,'multiline':False]
['text':' namespace','line_number':1000,'multiline':False]
['text':' Test with different number of specified arguments.','line_number':1004,'multiline':False]
['text':' Arguments not specified take default value.','line_number':1005,'multiline':False]
['text':'  bytecode with one specified argument:','line_number':1010,'multiline':False]
['text':'  (6,','line_number':1011,'multiline':False]
['text':'      ('__torch__.m.forward',','line_number':1012,'multiline':False]
['text':'          (('instructions',','line_number':1013,'multiline':False]
['text':'              (('STOREN', 1, 2),','line_number':1014,'multiline':False]
['text':'                  ('DROPR', 1, 0),','line_number':1015,'multiline':False]
['text':'                  ('MOVE', 2, 0),','line_number':1016,'multiline':False]
['text':'                  ('OP', 0, 0),','line_number':1017,'multiline':False]
['text':'                  ('RET', 0, 0))),','line_number':1018,'multiline':False]
['text':'              ('operators', (('aten::linalg_pinv', '', 1),)),','line_number':1019,'multiline':False]
['text':'              ('constants', (False, 1e-15)), # default constants are not','line_number':1020,'multiline':False]
['text':'              used','line_number':1021,'multiline':False]
['text':'              ('types', ()),','line_number':1022,'multiline':False]
['text':'              ('register_size', 2)),','line_number':1023,'multiline':False]
['text':'          (('arguments',','line_number':1024,'multiline':False]
['text':'              ((('name', 'self'), ('type', '__torch__.m'), ('default_value',','line_number':1025,'multiline':False]
['text':'              None)),','line_number':1026,'multiline':False]
['text':'                  (('name', 'input'), ('type', 'Tensor'), ('default_value',','line_number':1027,'multiline':False]
['text':'                  None)))),','line_number':1028,'multiline':False]
['text':'              ('returns',','line_number':1029,'multiline':False]
['text':'                  ((('name', ''), ('type', 'Tensor'), ('default_value',','line_number':1030,'multiline':False]
['text':'                  None)),)))))','line_number':1031,'multiline':False]
['text':'  bytecode with 2 specified argument:','line_number':1033,'multiline':False]
['text':'  (6,','line_number':1034,'multiline':False]
['text':'      ('__torch__.m.forward',','line_number':1035,'multiline':False]
['text':'          (('instructions',','line_number':1036,'multiline':False]
['text':'              (('STOREN', 1, 2),','line_number':1037,'multiline':False]
['text':'                  ('DROPR', 1, 0),','line_number':1038,'multiline':False]
['text':'                  ('MOVE', 2, 0),','line_number':1039,'multiline':False]
['text':'                  ('LOADC', 1, 0), # added LOADC for specified argument','line_number':1040,'multiline':False]
['text':'                  ('OP', 0, 0),','line_number':1041,'multiline':False]
['text':'                  ('RET', 0, 0))),','line_number':1042,'multiline':False]
['text':'              ('operators', (('aten::linalg_pinv', '', 2),)),','line_number':1043,'multiline':False]
['text':'              ('constants', (False, 1e-05)), # updated constant table','line_number':1044,'multiline':False]
['text':'              ('types', ()),','line_number':1045,'multiline':False]
['text':'              ('register_size', 2)),','line_number':1046,'multiline':False]
['text':'          (('arguments',','line_number':1047,'multiline':False]
['text':'              ((('name', 'self'), ('type', '__torch__.m'), ('default_value',','line_number':1048,'multiline':False]
['text':'              None)),','line_number':1049,'multiline':False]
['text':'                  (('name', 'input'), ('type', 'Tensor'), ('default_value',','line_number':1050,'multiline':False]
['text':'                  None)))),','line_number':1051,'multiline':False]
['text':'              ('returns',','line_number':1052,'multiline':False]
['text':'                  ((('name', ''), ('type', 'Tensor'), ('default_value',','line_number':1053,'multiline':False]
['text':'                  None)),)))))','line_number':1054,'multiline':False]
['text':'  bytecode with 3 specified arguments:','line_number':1056,'multiline':False]
['text':'  (6,','line_number':1057,'multiline':False]
['text':'      ('__torch__.m.forward',','line_number':1058,'multiline':False]
['text':'          (('instructions',','line_number':1059,'multiline':False]
['text':'              (('STOREN', 1, 2),','line_number':1060,'multiline':False]
['text':'                  ('DROPR', 1, 0),','line_number':1061,'multiline':False]
['text':'                  ('MOVE', 2, 0),','line_number':1062,'multiline':False]
['text':'                  ('LOADC', 1, 0),','line_number':1063,'multiline':False]
['text':'                  ('LOADC', 0, 0),','line_number':1064,'multiline':False]
['text':'                  ('OP', 0, 0),','line_number':1065,'multiline':False]
['text':'                  ('RET', 0, 0))),','line_number':1066,'multiline':False]
['text':'              ('operators', (('aten::linalg_pinv', '', 3),)),','line_number':1067,'multiline':False]
['text':'              ('constants', (True, 1e-05)),','line_number':1068,'multiline':False]
['text':'              ('types', ()),','line_number':1069,'multiline':False]
['text':'              ('register_size', 2)),','line_number':1070,'multiline':False]
['text':'          (('arguments',','line_number':1071,'multiline':False]
['text':'              ((('name', 'self'), ('type', '__torch__.m'), ('default_value',','line_number':1072,'multiline':False]
['text':'              None)),','line_number':1073,'multiline':False]
['text':'                  (('name', 'input'), ('type', 'Tensor'), ('default_value',','line_number':1074,'multiline':False]
['text':'                  None)))),','line_number':1075,'multiline':False]
['text':'              ('returns',','line_number':1076,'multiline':False]
['text':'                  ((('name', ''), ('type', 'Tensor'), ('default_value',','line_number':1077,'multiline':False]
['text':'                  None)),)))))','line_number':1078,'multiline':False]
['text':' The second argument is specified, but the value is the same as the default','line_number':1082,'multiline':False]
['text':' value. It's treated as "not specified" since the value can be fetched from','line_number':1083,'multiline':False]
['text':' schema.','line_number':1084,'multiline':False]
['text':' a more stable matrix','line_number':1122,'multiline':False]
['text':' Test with different number of specified arguments + out arg.','line_number':1130,'multiline':False]
['text':' Arguments not specified take default value.','line_number':1131,'multiline':False]
['text':' !defined(FB_XPLAT_BUILD)','line_number':1163,'multiline':False]
['text':' __getattr__','line_number':1173,'multiline':False]
['text':' __setattr__','line_number':1176,'multiline':False]
['text':' namespace','line_number':1181,'multiline':False]
['text':' Create 3 methods:','line_number':1184,'multiline':False]
['text':'','line_number':1185,'multiline':False]
['text':' 1. forward() returns a tensor with dtype=torch.int64 (4)','line_number':1186,'multiline':False]
['text':' 2. forward2() returns a tensor with dtype=torch.float32 (6)','line_number':1187,'multiline':False]
['text':' 3. forward3() returns a tensor with dtype=torch.float32 but','line_number':1188,'multiline':False]
['text':'    the dtype is inferred by the input tensor's dtype','line_number':1189,'multiline':False]
['text':'','line_number':1190,'multiline':False]
['text':' If caching works correctly, then the result from the full-jit','line_number':1191,'multiline':False]
['text':' module and the lite module will be the same. Otherwise, it','line_number':1192,'multiline':False]
['text':' will be different if we don't correctly ignore the cache','line_number':1193,'multiline':False]
['text':' entry for an operator that has a different number of','line_number':1194,'multiline':False]
['text':' arguments.','line_number':1195,'multiline':False]
['text':' if the variables read are wrong type the conversion will raise exception','line_number':1255,'multiline':False]
['text':' NOLINT (use =delete in gtest)','line_number':1263,'multiline':False]
['text':' test invoking a method with default parameter','line_number':1265,'multiline':False]
['text':' inner method call with default parameter (gets inlined)','line_number':1270,'multiline':False]
['text':' simple method call','line_number':1277,'multiline':False]
['text':' Make a copy of the data so we can use the existing API, which takes','line_number':1306,'multiline':False]
['text':' ownership. The `data` param might point into the middle of a buffer, so we','line_number':1307,'multiline':False]
['text':' can't safely take ownership of it directly.','line_number':1308,'multiline':False]
['text':' @nolint CLANGTIDY cppcoreguidelines-no-malloc','line_number':1309,'multiline':False]
['text':'use_fatbuffer=','line_number':1330,'multiline':True]
['text':' NOLINT (use =delete in gtest)','line_number':1357,'multiline':False]
['text':' test invoking a method with default parameter','line_number':1359,'multiline':False]
['text':' inner method call with default parameter (gets inlined)','line_number':1364,'multiline':False]
['text':' simple method call','line_number':1371,'multiline':False]
['text':' (keep linter happy)','line_number':1383,'multiline':False]
['text':' The following test run in fbcode only','line_number':1410,'multiline':False]
['text':'
  (('__torch__.MyModule.forward',
    (('instructions',
      (('STOREN', 1, 3),
       ('DROPR', 1, 0),
       ('LOAD', 2, 0),
       ('LOAD', 3, 0),
       ('OP', 0, 0),
       ('LOAD', 2, 0),
       ('LOAD', 3, 0),
       ('OP', 1, 0),
       ('MOVE', 2, 0),
       ('MOVE', 3, 0),
       ('OP', 2, 0),
       ('TUPLE_CONSTRUCT', 3, 0),
       ('RET', 0, 0))),
     ('operators',
      (('aten::div', 'Tensor'),
       ('aten::div', 'Tensor'),
       ('aten::div', 'Tensor'))),
     ('constants', ()),
     ('types', ()),
     ('register_size', 3))),)

  ','line_number':1415,'multiline':True]
['text':' 3 operators will use upgrader','line_number':1447,'multiline':False]
['text':'
  (('__torch__.MyModule.forward',
    (('instructions',
      (('STOREN', 1, 4),
       ('DROPR', 1, 0),
       ('MOVE', 2, 0),
       ('MOVE', 3, 0),
       ('MOVE', 4, 0),
       ('OP', 0, 0),
       ('RET', 0, 0))),
     ('operators', (('aten::div', 'out'),)),
     ('constants', ()),
     ('types', ()),
     ('register_size', 4))),)
  ','line_number':1463,'multiline':True]
['text':' One operator will use upgrader','line_number':1486,'multiline':False]
['text':' The out argument will be overwritten with the output','line_number':1496,'multiline':False]
['text':'
  (('__torch__.MyModule.forward',
    (('instructions',
      (('STOREN', 1, 3),
       ('DROPR', 1, 0),
       ('MOVE', 2, 0),
       ('MOVE', 3, 0),
       ('OP', 0, 0),
       ('RET', 0, 0))),
     ('operators', (('aten::div_', 'Tensor'),)),
     ('constants', ()),
     ('types', ()),
     ('register_size', 3))),)
  ','line_number':1505,'multiline':True]
['text':' One operator will use upgrader','line_number':1527,'multiline':False]
['text':' The out argument will be overwritten with the output','line_number':1535,'multiline':False]
['text':'
  (('__torch__.MyModuleFloat.forward',
    (('instructions',
    (('STOREN', 1, 3),
    ('DROPR', 1, 0),
    ('MOVE', 2, 0),
    ('MOVE', 3, 0),
    ('OP', 0, 0),
    ('RET', 0, 0))),
    ('operators', (('aten::div', 'Scalar'),)),
    ('constants', ()),
    ('types', ()),
    ('register_size', 3))),)
  ','line_number':1544,'multiline':True]
['text':' One operator will use upgrader','line_number':1567,'multiline':False]
['text':' The out argument will be overwritten with the output','line_number':1575,'multiline':False]
['text':'
  (('__torch__.MyModuleFloat.forward',
    (('instructions',
      (('STOREN', 1, 3),
      ('DROPR', 1, 0),
      ('MOVE', 2, 0),
      ('OP', 0, 0),
      ('MOVE', 3, 0),
      ('OP', 1, 0),
      ('RET', 0, 0))),
    ('operators', (('aten::reciprocal', ''), ('aten::mul', 'Scalar'))),
    ('constants', ()),
    ('types', ()),
    ('register_size', 3))),)
  ','line_number':1584,'multiline':True]
['text':' No operator will use upgrader','line_number':1607,'multiline':False]
['text':' The out argument will be overwritten with the output','line_number':1614,'multiline':False]
['text':'
  (('__torch__.MyModuleInt.forward',
  (('instructions',
    (('STOREN', 1, 3),
     ('DROPR', 1, 0),
     ('MOVE', 2, 0),
     ('OP', 0, 0),
     ('MOVE', 3, 0),
     ('OP', 1, 0),
     ('RET', 0, 0))),
   ('operators', (('aten::reciprocal', ''), ('aten::mul', 'Scalar'))),
   ('constants', ()),
   ('types', ()),
   ('register_size', 3))),)
  ','line_number':1623,'multiline':True]
['text':' No operator will use upgrader','line_number':1646,'multiline':False]
['text':' The out argument will be overwritten with the output','line_number':1654,'multiline':False]
['text':'
  (('__torch__.MyModule.forward',
    (('instructions',
      (('STOREN', 1, 5),
      ('DROPR', 1, 0),
      ('LOAD', 2, 0),
      ('LOAD', 3, 0),
      ('OP', 0, 0),
      ('MOVE', 2, 0),
      ('LOAD', 4, 0),
      ('OP', 1, 0),
      ('LOAD', 3, 0),
      ('MOVE', 4, 0),
      ('OP', 2, 0),
      ('MOVE', 3, 0),
      ('MOVE', 5, 0),
      ('OP', 3, 0),
      ('TUPLE_CONSTRUCT', 4, 0),
      ('RET', 0, 0))),
    ('operators',
      (('aten::div', ''),
      ('aten::div', 'float'),
      ('aten::div', ''),
      ('aten::div', 'int'))),
    ('constants', ()),
    ('types', ()),
    ('register_size', 5))),)
  ','line_number':1663,'multiline':True]
['text':' No operator will use upgrader','line_number':1698,'multiline':False]
['text':' auto actual_output = output.toTensor();','line_number':1706,'multiline':False]
['text':'
  (('__torch__.MyModuleInt.forward',
    (('instructions',
      (('STOREN', 1, 3),
      ('DROPR', 1, 0),
      ('MOVE', 2, 0),
      ('MOVE', 3, 0),
      ('OP', 0, 0),
      ('RET', 0, 0))),
    ('operators', (('aten::div', 'Scalar'),)),
    ('constants', ()),
    ('types', ()),
    ('register_size', 3))),)
  ','line_number':1717,'multiline':True]
['text':' One operator will use upgrader','line_number':1739,'multiline':False]
['text':' The out argument will be overwritten with the output','line_number':1747,'multiline':False]
['text':'
  (('__torch__.MyModuleFloat.forward',
    (('instructions',
      (('STOREN', 1, 3),
      ('DROPR', 1, 0),
      ('MOVE', 2, 0),
      ('MOVE', 3, 0),
      ('OP', 0, 0),
      ('RET', 0, 0))),
    ('operators', (('aten::div_', 'Scalar'),)),
    ('constants', ()),
    ('types', ()),
    ('register_size', 3))),)
  ','line_number':1756,'multiline':True]
['text':' One operator will use upgrader','line_number':1779,'multiline':False]
['text':' The out argument will be overwritten with the output','line_number':1787,'multiline':False]
['text':'
  (('__torch__.MyModuleInt.forward',
    (('instructions',
      (('STOREN', 1, 3),
       ('DROPR', 1, 0),
       ('MOVE', 2, 0),
       ('MOVE', 3, 0),
       ('OP', 0, 0),
       ('RET', 0, 0))),
     ('operators', (('aten::div_', 'Scalar'),)),
     ('constants', ()),
     ('types', ()),
     ('register_size', 3))),)
  ','line_number':1796,'multiline':True]
['text':' One operator will use upgrader','line_number':1819,'multiline':False]
['text':' The out argument will be overwritten with the output','line_number':1827,'multiline':False]
['text':' !defined(FB_XPLAT_BUILD)','line_number':1831,'multiline':False]
['text':'','line_number':1833,'multiline':False]
['text':' Tests that need access to internal flatbuffers types/functions.','line_number':1834,'multiline':False]
['text':' Do not add any other tests after this section.','line_number':1835,'multiline':False]
['text':'','line_number':1836,'multiline':False]
['text':' namespace jit','line_number':1838,'multiline':False]
['text':' namespace torch','line_number':1839,'multiline':False]
['text':'*
 * An Allocator that can only deallocate (using delete []), counting
 * the number of times that it has been asked to deallocate.
 ','line_number':1843,'multiline':True]
['text':'*
   * *deallocate_call_count will be incremented whenever deallocate() is called.
   ','line_number':1849,'multiline':True]
['text':'size','line_number':1855,'multiline':True]
['text':'/ Provides access to DetachedBuffer::destroy().','line_number':1872,'multiline':False]
['text':'/ Returns a UniqueDetachedBuffer that wraps the provided DetachedBuffer.','line_number':1874,'multiline':False]
['text':'/ A copy of similar code in flatbuffer_serializer.cpp.','line_number':1875,'multiline':False]
['text':' Use a custom Allocator to watch the lifecycle of a','line_number':1883,'multiline':False]
['text':' flatbuffers::DetachedBuffer.','line_number':1884,'multiline':False]
['text':' Data for the buffer. TestAllocator will free it with `delete []`.','line_number':1888,'multiline':False]
['text':' An internal buffer on the stack that owns the data.','line_number':1892,'multiline':False]
['text':'own_allocator=','line_number':1894,'multiline':True]
['text':' Mimic the code inside save_mobile_module_to_bytes by transferring ownership','line_number':1898,'multiline':False]
['text':' to a heap object.','line_number':1899,'multiline':False]
['text':' The data should not have been deleted yet.','line_number':1901,'multiline':False]
['text':' The new object points to the data.','line_number':1903,'multiline':False]
['text':' The old object points to nothing.','line_number':1906,'multiline':False]
['text':' @lint-ignore CLANGTIDY bugprone-use-after-move','line_number':1907,'multiline':False]
['text':' @lint-ignore CLANGTIDY bugprone-use-after-move','line_number':1909,'multiline':False]
['text':' The top-level torch::jit::DetachedBuffer.','line_number':1912,'multiline':False]
['text':' The unique_ptr that owns the torch::jit::DetachedBuffer and its contents.','line_number':1918,'multiline':False]
['text':' The data should not have been deleted yet.','line_number':1925,'multiline':False]
['text':' Now that the unique_ptr is out of scope, the data should have been deleted.','line_number':1929,'multiline':False]
['text':' a torch::jit::DetachedBuffer with a null internal owner.','line_number':1934,'multiline':False]
['text':' A unique_ptr that owns the torch::jit::DetachedBuffer and its contents.','line_number':1938,'multiline':False]
['text':' The DetachedBuffer should have been destroyed when the UniqueDetachedBuffer','line_number':1946,'multiline':False]
['text':' went out of scope. If we didn't crash or get any ASAN warnings, we should','line_number':1947,'multiline':False]
['text':' be good.','line_number':1948,'multiline':False]
['text':'','line_number':1951,'multiline':False]
['text':' Do not add tests here unless they require flatbuffers types. See comment at','line_number':1952,'multiline':False]
['text':' the beginning of this section.','line_number':1953,'multiline':False]
['text':'','line_number':1954,'multiline':False]
['text':' namespace jit','line_number':1956,'multiline':False]
['text':' namespace torch','line_number':1957,'multiline':False]
