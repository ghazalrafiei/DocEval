['text':' NOLINT','line_number':25,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)','line_number':33,'multiline':False]
['text':' dummy chunk data reader with 3 chunks and 35 examples in total. Each chunk','line_number':63,'multiline':False]
['text':' contains 10, 5, 20 examples respectively.','line_number':64,'multiline':False]
['text':'/ Read an entire chunk.','line_number':71,'multiline':False]
['text':' NOLINTNEXTLINE(bugprone-fold-init-type)','line_number':76,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-magic-numbers,cppcoreguidelines-avoid-c-arrays)','line_number':93,'multiline':False]
['text':'epoch_size=','line_number':169,'multiline':True]
['text':' NOLINT','line_number':185,'multiline':False]
['text':' NOLINT','line_number':192,'multiline':False]
['text':' NOLINT','line_number':203,'multiline':False]
['text':' Let's say the sequence number matches for the batch one, then it should','line_number':214,'multiline':False]
['text':' return immediately.','line_number':215,'multiline':False]
['text':' Now it should call the getter until it gets the next value.','line_number':220,'multiline':False]
['text':' The next three should come in order.','line_number':224,'multiline':False]
['text':' New value doesn't matter. In fact, it shouldn't be accessed.','line_number':226,'multiline':False]
['text':' The index doesn't change.','line_number':228,'multiline':False]
['text':'epoch_size=','line_number':414,'multiline':True]
['text':'epoch_size=','line_number':423,'multiline':True]
['text':'epoch_size=','line_number':432,'multiline':True]
['text':'dim=','line_number':472,'multiline':True]
['text':'dim=','line_number':473,'multiline':True]
['text':'dim=','line_number':476,'multiline':True]
['text':'dim=','line_number':477,'multiline':True]
['text':'dim=','line_number':485,'multiline':True]
['text':'dim=','line_number':488,'multiline':True]
['text':' Template classes cannot be nested in functions.','line_number':491,'multiline':False]
['text':' Works for zero (one implicit) channels','line_number':553,'multiline':False]
['text':' (1 - 0.5) / 0.1 = 5','line_number':556,'multiline':False]
['text':' Works for one explicit channel','line_number':560,'multiline':False]
['text':' Works for two channels with different moments','line_number':567,'multiline':False]
['text':'dim=','line_number':574,'multiline':True]
['text':'start=','line_number':574,'multiline':True]
['text':'end=','line_number':574,'multiline':True]
['text':'dim=','line_number':578,'multiline':True]
['text':'start=','line_number':578,'multiline':True]
['text':' Works for three channels with one moment value','line_number':582,'multiline':False]
['text':' Works for three channels with different moments','line_number':590,'multiline':False]
['text':'dim=','line_number':597,'multiline':True]
['text':'start=','line_number':597,'multiline':True]
['text':'end=','line_number':597,'multiline':True]
['text':'dim=','line_number':601,'multiline':True]
['text':'start=','line_number':601,'multiline':True]
['text':'end=','line_number':601,'multiline':True]
['text':'dim=','line_number':605,'multiline':True]
['text':'start=','line_number':605,'multiline':True]
['text':' First test: push batch and the pop in thread.','line_number':665,'multiline':False]
['text':' Second test: attempt to pop batch (and block), then push.','line_number':674,'multiline':False]
['text':' pop_result() will only attempt to pop if there was a push_job() batch.','line_number':705,'multiline':False]
['text':' unused ','line_number':744,'multiline':True]
['text':' NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)','line_number':753,'multiline':False]
['text':' This test will only compile if we really are not making any copies.','line_number':762,'multiline':False]
['text':' There is otherwise no logic to test and because it is not deterministic','line_number':763,'multiline':False]
['text':' how many and when worker threads access the shareddataset, we don't have','line_number':764,'multiline':False]
['text':' any additional assertions here.','line_number':765,'multiline':False]
['text':' exhaust ','line_number':775,'multiline':True]
['text':' This will not compile if a copy is made.','line_number':780,'multiline':False]
['text':' NOLINTNEXTLINE(bugprone-argument-comment)','line_number':1131,'multiline':False]
['text':'batch_size=','line_number':1132,'multiline':True]
['text':' NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)','line_number':1150,'multiline':False]
['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':1186,'multiline':False]
['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':1196,'multiline':False]
['text':' stackoverflow.com/questions/24465533/implementing-boostbarrier-in-c11','line_number':1294,'multiline':False]
['text':' On the OrderingTest: This test is intended to verify that the','line_number':1311,'multiline':False]
['text':' `enforce_ordering` option of the dataloader works correctly. The reason this','line_number':1312,'multiline':False]
['text':' flag exists is because when the dataloader has multiple workers (threads)','line_number':1313,'multiline':False]
['text':' enabled and this flag is not set, the order in which worker threads finish','line_number':1314,'multiline':False]
['text':' loading their respective batch and push it back to the dataloader's main','line_number':1315,'multiline':False]
['text':' thread (for outside consumption) is not deterministic. Imagine the sampler is','line_number':1316,'multiline':False]
['text':' a SequentialSampler with indices 0, 1, 2, 3. With batch size 1, each index','line_number':1317,'multiline':False]
['text':' will be a single "job". Inside the dataloader, worker threads block until a','line_number':1318,'multiline':False]
['text':' job is available. It is not deterministic which worker thread wakes up batch','line_number':1319,'multiline':False]
['text':' to dequeue a particular batch. Further, some worker threads may take longer','line_number':1320,'multiline':False]
['text':' than others to read the data for their index. As such, it could be that','line_number':1321,'multiline':False]
['text':' worker thread 2 finishes before all other threads and returns its batch to','line_number':1322,'multiline':False]
['text':' the main thread. In that case, the dataloader iterator would return the datum','line_number':1323,'multiline':False]
['text':' at index 2 batch, and afterwards the datum from whatever thread finishes','line_number':1324,'multiline':False]
['text':' next. As such, the user may see data from indices 2, 0, 3, 1. On another run','line_number':1325,'multiline':False]
['text':' of the same dataloader on the same data, threads may be scheduled differently','line_number':1326,'multiline':False]
['text':' and return in order 0, 2, 3, 1. To force this ordering to deterministically','line_number':1327,'multiline':False]
['text':' be 0, 1, 2, 3, the `enforce_ordering` flag can be set to true. In that case,','line_number':1328,'multiline':False]
['text':' the dataloader will use a *sequencer* internally which keeps track of which','line_number':1329,'multiline':False]
['text':' datum is expected next, and buffers any other results until that next','line_number':1330,'multiline':False]
['text':' expected value arrives. For example, workers 1, 2, 3 may finish before worker','line_number':1331,'multiline':False]
['text':' 0. If `enforce_ordering` is true, the sequencer will internally buffer the','line_number':1332,'multiline':False]
['text':' results from 1, 2, 3 until worker 0 finishes. Only then does the dataloader','line_number':1333,'multiline':False]
['text':' return the datum from worker 0 to the user (and then datum 1 the next time,','line_number':1334,'multiline':False]
['text':' then 2 and so on).','line_number':1335,'multiline':False]
['text':'','line_number':1336,'multiline':False]
['text':' The way the test works is that we start','line_number':1337,'multiline':False]
['text':' `kNumberOfWorkers` workers in the dataloader, which each get an index from a','line_number':1338,'multiline':False]
['text':' `SequentialSampler` in the range `0...kNumberOfWorkers-1`. Each worker thread','line_number':1339,'multiline':False]
['text':' has a copy of the dataset, and thus `get_batch()` is called on the','line_number':1340,'multiline':False]
['text':' thread-local copy in each worker. We want to simulate out-of-order completion','line_number':1341,'multiline':False]
['text':' of these threads. For this, we batch set a barrier in the `get_batch()`','line_number':1342,'multiline':False]
['text':' method to make sure every worker has some index to fetch assigned. Further,','line_number':1343,'multiline':False]
['text':' each worker thread has a unique ID in `0...kNumberOfWorkers-1`.','line_number':1344,'multiline':False]
['text':' There is a hard-coded ordering, `kOrderInWhichWorkersReturnTheirBatch`, in','line_number':1345,'multiline':False]
['text':' which we want the worker threads to return. For this, an iterator into this','line_number':1346,'multiline':False]
['text':' order is maintained. When the dereferenced iterator (the current order index)','line_number':1347,'multiline':False]
['text':' matches the thread ID of a worker, it knows it can now return its index as','line_number':1348,'multiline':False]
['text':' well as progress the iterator. Inside the dataloader, the sequencer should','line_number':1349,'multiline':False]
['text':' buffer these indices such that they are ultimately returned in order.','line_number':1350,'multiline':False]
['text':' namespace','line_number':1357,'multiline':False]
['text':' This copy constructor will be called when we copy the dataset into a','line_number':1362,'multiline':False]
['text':' particular thread.','line_number':1363,'multiline':False]
['text':' Wait for all threads to get an index batch and arrive here.','line_number':1379,'multiline':False]
['text':' namespace ordering_test','line_number':1398,'multiline':False]
['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':1460,'multiline':False]
['text':'count=','line_number':1595,'multiline':True]
['text':' Notice that the `get_batch()` of the dataset returns a vector<Example>, but','line_number':1617,'multiline':False]
['text':' the `Stack` collation stacks the tensors into one.','line_number':1618,'multiline':False]
['text':' This test tests the core function for iterate through a chunk dataset. It','line_number':1630,'multiline':False]
['text':' contains test cases with different parameter combination. (For example,','line_number':1631,'multiline':False]
['text':' different prefetch count, batch size and data loader worker count). It','line_number':1632,'multiline':False]
['text':' verifies the return batches size and content when the order is deterministic.','line_number':1633,'multiline':False]
['text':' different prefetch count for testing.','line_number':1635,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-c-arrays)','line_number':1636,'multiline':False]
['text':' different batch size for testing.','line_number':1639,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-c-arrays)','line_number':1640,'multiline':False]
['text':' test with/without worker threads','line_number':1643,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-c-arrays)','line_number':1644,'multiline':False]
['text':' test functionality across epoch boundary','line_number':1651,'multiline':False]
['text':' Suppress unused variable warning','line_number':1675,'multiline':False]
['text':' When prefetch_count is equal to 1 and no worker thread, the batch','line_number':1684,'multiline':False]
['text':' order is deterministic. So we can verify elements in each batch.','line_number':1685,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-c-arrays)','line_number':1797,'multiline':False]
['text':' before we start, the index should be 0.','line_number':1863,'multiline':False]
['text':' sum([0, 35))','line_number':1871,'multiline':False]
['text':' 3 chunks, and when exhausted the value is already incremented.','line_number':1872,'multiline':False]
['text':' this will make the preloaders to wait till the `get_batch()` calls.','line_number':1879,'multiline':False]
['text':' simply creates the iterator but no iteration. chunk preloaders are waiting','line_number':1906,'multiline':False]
['text':' to fill the batch buffer but it is not draining. Still we need to exit','line_number':1907,'multiline':False]
['text':' cleanly.','line_number':1908,'multiline':False]
['text':' Test ChunkDataset save function.','line_number':1912,'multiline':False]
['text':' Note [save/load ChunkDataset as ChunkSampler]:','line_number':1913,'multiline':False]
['text':' The chunk sampler inside ChunkDataset is used in a separate thread pool other','line_number':1914,'multiline':False]
['text':' than the main thread. Thus it is very hard to accurately estimate its status','line_number':1915,'multiline':False]
['text':' when ChunkDataset::save/ChunkDataset::load is called. For the pure purpose of','line_number':1916,'multiline':False]
['text':' testing, we utilize the implementation fact that the file format for sampler','line_number':1917,'multiline':False]
['text':' serialization is the same as ChunkDataset serialization, and manually control','line_number':1918,'multiline':False]
['text':' the chunk sampler by calling the sampler's save/load method for value','line_number':1919,'multiline':False]
['text':' validation. This is only for testing the specific save/load functionality. In','line_number':1920,'multiline':False]
['text':' real user case, the user should still use matching ChunkDataset::save and','line_number':1921,'multiline':False]
['text':' ChunkDataset::load method.','line_number':1922,'multiline':False]
['text':' tested save_intervals','line_number':1951,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-c-arrays)','line_number':1952,'multiline':False]
['text':'cache size','line_number':1972,'multiline':True]
['text':' Suppress unused variable warning','line_number':1979,'multiline':False]
['text':' See Note [save/load ChunkDataset as ChunkSampler]','line_number':1988,'multiline':False]
['text':' Verify save logic. For ChunkDataset, the chunk data is stored in a','line_number':1991,'multiline':False]
['text':' cache inside the dataset. One pool of threads are constantly','line_number':1992,'multiline':False]
['text':' writing to the cache, and a different pool of thread are constantly','line_number':1993,'multiline':False]
['text':' reading from the cache. Due to the nature of asynchronization, at','line_number':1994,'multiline':False]
['text':' the time of get_batch(), which chunk is written to the cache is not','line_number':1995,'multiline':False]
['text':' fully deterministic.','line_number':1996,'multiline':False]
['text':' But we can still calculate a restricted window on the expected','line_number':1997,'multiline':False]
['text':' output, hence verify the logic. In this test, the cache size is','line_number':1998,'multiline':False]
['text':' configured to be the same as chunk size and batch size. So the','line_number':1999,'multiline':False]
['text':' chunk data is written to the cache one by one. Only the current','line_number':2000,'multiline':False]
['text':' batch is retrieved, the next chunk is written. Now in iteration 0,','line_number':2001,'multiline':False]
['text':' after the first batch is retrieved, when we save the dataset','line_number':2002,'multiline':False]
['text':' statues, there are three possible scenarios for the writer thread:','line_number':2003,'multiline':False]
['text':' 1. it hasn't started loading the next chunk data yet, so the','line_number':2004,'multiline':False]
['text':' sequential sampler index is still 0;','line_number':2005,'multiline':False]
['text':' 2. it started to load the second chunk, so the sequential sampler','line_number':2006,'multiline':False]
['text':' index is at 1;','line_number':2007,'multiline':False]
['text':' 3. it finished loading the second chunk, and start to load the','line_number':2008,'multiline':False]
['text':' third chunk, because the cache is still fully occupied by the data','line_number':2009,'multiline':False]
['text':' from the second chunk, it is waiting to write to the cache. At this','line_number':2010,'multiline':False]
['text':' point, the sampler index is at 2.','line_number':2011,'multiline':False]
['text':' So now we have a window of [0, 2], which is what we expected the','line_number':2012,'multiline':False]
['text':' sampler to save the index from. Now noted for sequential sampler,','line_number':2013,'multiline':False]
['text':' it advances to the next index automatically in the call next(). So','line_number':2014,'multiline':False]
['text':' when save the index, it saves the next index in stead of the','line_number':2015,'multiline':False]
['text':' current one. In other word, after getting the first index from','line_number':2016,'multiline':False]
['text':' sequential sampler, it already moves to the second index. So when','line_number':2017,'multiline':False]
['text':' we save it, it is the second index we save. As a result,','line_number':2018,'multiline':False]
['text':' we need to advance the window by one. Now we have the expected','line_number':2019,'multiline':False]
['text':' window of [1, 3].','line_number':2020,'multiline':False]
['text':' This analysis applies to all scenarios. So extend it to a more','line_number':2021,'multiline':False]
['text':' general case: the expected saved index should falling into the','line_number':2022,'multiline':False]
['text':' range of [iteration, iteration + 3], which is the validation','line_number':2023,'multiline':False]
['text':' below.','line_number':2024,'multiline':False]
['text':' Test ChunkDataset load function.','line_number':2034,'multiline':False]
['text':' Configure sampler to skip 2 chunks','line_number':2047,'multiline':False]
['text':' See Note [save/load ChunkDataset as ChunkSampler]','line_number':2052,'multiline':False]
['text':' test functionality across epoch boundary. The first epoch should be','line_number':2056,'multiline':False]
['text':' affected by the checkpoint, but the second should start normally.','line_number':2057,'multiline':False]
['text':'cache size','line_number':2072,'multiline':True]
['text':' For the first epoch, the returned batch should be returned from the','line_number':2082,'multiline':False]
['text':' third chunk, because the check point skipped the first two chunks. But','line_number':2083,'multiline':False]
['text':' for the next epoch, it should start from the first batch.','line_number':2084,'multiline':False]
['text':' See Note [save/load ChunkDataset as ChunkSampler]','line_number':2106,'multiline':False]
['text':' Repeatedly sample every 5 indices.','line_number':2127,'multiline':False]
['text':' Returns the next batch of indices.','line_number':2136,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-c-arrays)','line_number':2179,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-c-arrays)','line_number':2181,'multiline':False]
['text':' construct expected result','line_number':2219,'multiline':False]
['text':' Suppress unused variable warning','line_number':2224,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-magic-numbers,clang-analyzer-security.insecureAPI.rand)','line_number':2252,'multiline':False]
['text':' custom preprocessing policy - sort the data ascendingly','line_number':2266,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-c-arrays)','line_number':2274,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-c-arrays)','line_number':2276,'multiline':False]
