['text':' Owner(s): ["module: onnx"]','line_number':1,'multiline':False]
['text':' type: ignore[import]','line_number':14,'multiline':False]
['text':' type: ignore[import]','line_number':15,'multiline':False]
['text':' type: ignore[import]','line_number':19,'multiline':False]
['text':' type: ignore[import]','line_number':32,'multiline':False]
['text':' TODO(justinchuby): Replicate torch's type casting policy','line_number':87,'multiline':False]
['text':' in the exporter for type promotion support','line_number':88,'multiline':False]
['text':' Non-tensor optional kwargs are always folded into constant and','line_number':102,'multiline':False]
['text':' removed from input list in Dynamo-traced graph, if its value is not provided','line_number':103,'multiline':False]
['text':' to tracer. So for a function like','line_number':104,'multiline':False]
['text':'   def func(x, b=1.0)','line_number':105,'multiline':False]
['text':' here. E.g., if you first Dynamo-trace the model with arguments (x,),','line_number':106,'multiline':False]
['text':' and then call the traced graph with arguments (x, b=2.0), it will complain','line_number':107,'multiline':False]
['text':' somewhere that model is called with extra args because the modified','line_number':108,'multiline':False]
['text':' function is traced into','line_number':109,'multiline':False]
['text':'   def forward(self, x : torch.Tensor):','line_number':110,'multiline':False]
['text':'     add = x + 1.0;  x = None','line_number':111,'multiline':False]
['text':'     relu = add.relu()','line_number':112,'multiline':False]
['text':'     return (add, relu)','line_number':113,'multiline':False]
['text':' To summarize, in order to be traced as graph input, the value of optional kwarg','line_number':114,'multiline':False]
['text':' must be provided. Otherwise, they are treated as in-graph constants in Dynamo.','line_number':115,'multiline':False]
['text':' Tensor optional kwargs are an exception. It is always traced as input.','line_number':116,'multiline':False]
['text':' It is unclear if this behavior is intended or not. But in general it is bad','line_number':117,'multiline':False]
['text':' practice to set mutable default values.','line_number':118,'multiline':False]
['text':' `DynamoOptimizeExporter` applies a workaround by binding args and kwargs to','line_number':119,'multiline':False]
['text':' model signature and fill in the default values of unprovided optional arguments.','line_number':120,'multiline':False]
['text':' Test without providing optional kwarg.','line_number':128,'multiline':False]
['text':' Test with only positional args.','line_number':130,'multiline':False]
['text':' Test while specifying optional kwarg.','line_number':134,'multiline':False]
['text':' TODO: add boolean tests when SymBool is supported','line_number':144,'multiline':False]
['text':' to infer types','line_number':145,'multiline':False]
['text':' test on different non-tensor input - xfail','line_number':197,'multiline':False]
['text':' This produces op as `torch.ops.aten.log_sigmoid_forward`, instead of the more','line_number':278,'multiline':False]
['text':' conventional `torch.ops.aten.log_sigmoid`.','line_number':279,'multiline':False]
['text':' TODO(bowbao): Note [training vs eval in dynamo_export]','line_number':293,'multiline':False]
['text':' So we are effectively exporting all models in traning mode by','line_number':294,'multiline':False]
['text':' default. But for the sake of this export we are only interested in eval mode.','line_number':295,'multiline':False]
['text':' The question is, should we call `model.eval()` in `dynamo_export`?','line_number':296,'multiline':False]
['text':' This particular test fails 'functionalization' in training mode.','line_number':297,'multiline':False]
['text':' So we are explicitly calling `model.eval()` for any model that contains','line_number':298,'multiline':False]
['text':' batch norm.','line_number':299,'multiline':False]
['text':' Ref: https://github.com/pytorch/pytorch/issues/99662#issuecomment-1528178221','line_number':300,'multiline':False]
['text':' TODO(bowbao): see Note [training vs eval in dynamo_export]','line_number':315,'multiline':False]
['text':' problematic user code for dynamo','line_number':421,'multiline':False]
['text':' NOTE:The test was meant to test the empty bounding box case, but it is not','line_number':567,'multiline':False]
['text':' supported. When we have vision model examples, we will have a better test case','line_number':568,'multiline':False]
['text':' to demonstrate in FX and FX exporter.','line_number':569,'multiline':False]
['text':' y = torch.empty(0)','line_number':577,'multiline':False]
['text':' additional_test_inputs=[((y,),)],  # TODO: Without `additional_test_inputs` arg, dynamic shape cannot be verified','line_number':581,'multiline':False]
['text':' Has static shape for dynamic_shapes=True due to 0/1 specialization','line_number':582,'multiline':False]
['text':' Repro from llama. Emits `torch.ops.aten._local_scalar_dense`.','line_number':613,'multiline':False]
['text':' Model','line_number':661,'multiline':False]
['text':' Encoded inputs','line_number':681,'multiline':False]
['text':' Another encoded inputs to test dynamic shapes','line_number':684,'multiline':False]
['text':' Assuming x is a tensor on the CPU, move it to the desired device using device_put()','line_number':712,'multiline':False]
['text':' Create the toy model.','line_number':749,'multiline':False]
['text':' Dump state_dict to a file to simulate how HuggingFace model is initialized.','line_number':757,'multiline':False]
['text':' The file will be loaded via .load_state_dict(...)','line_number':758,'multiline':False]
['text':' NOTE: FakeTensorMode disallows symbolic shape of fx graph','line_number':765,'multiline':False]
['text':' The following coed block does several things.','line_number':766,'multiline':False]
['text':'  1. Create a model whose parameters and buffers are all FakeTensor's.','line_number':767,'multiline':False]
['text':'  2. Convert nn.Module into ONNX model without initializers.','line_number':768,'multiline':False]
['text':'  3. Record the file paths to find real initializers.','line_number':769,'multiline':False]
['text':' Toy model with parameters and buffers as FakeTensor's.','line_number':771,'multiline':False]
['text':' Toy inputs as FakeTensor's.','line_number':774,'multiline':False]
['text':' Export ONNX model without initializers while ctx.paths records','line_number':776,'multiline':False]
['text':' all files that contains real initializers.','line_number':777,'multiline':False]
['text':' Tasks done by the following block.','line_number':796,'multiline':False]
['text':'  1. Iterate through all tensors stored in ctx.paths (the file content is loaded torch.load)','line_number':797,'multiline':False]
['text':'  2. If a tensor's name matches a "onnx_model"'s input name, an initializer is created and saved to','line_number':798,'multiline':False]
['text':'     a seperated folder.','line_number':799,'multiline':False]
['text':'  3. A new ONNX model is saved into file with the initializers saved in the previous step.','line_number':800,'multiline':False]
['text':'  4. ORT executes the new ONNX model and compares the results with the original GPT model.','line_number':801,'multiline':False]
['text':' Model saved to tmp_folder/onnx_model_location','line_number':803,'multiline':False]
['text':' Initializers are saved to tmp_folder/onnx_initializer_location/*.onnx','line_number':804,'multiline':False]
['text':' TODO: We are using the internal `save_model_with_external_data` instead of public','line_number':807,'multiline':False]
['text':' `ONNXProgram.save` because we need to rename ONNX initializers before saving.','line_number':808,'multiline':False]
['text':' This is only needed/allowed because we are using `fx_tracer=FXSymbolicTracer`,','line_number':809,'multiline':False]
['text':' which is not an official FX tracer.','line_number':810,'multiline':False]
['text':' Generate random inputs.','line_number':819,'multiline':False]
['text':' Original outputs.','line_number':822,'multiline':False]
['text':' ORT outputs.','line_number':826,'multiline':False]
['text':' Drop Parameters and buffers added by fx_serialization.save_model_with_external_data','line_number':829,'multiline':False]
['text':' Create the toy model with real weight.','line_number':995,'multiline':False]
['text':' concrete (non-fake) state_dict','line_number':997,'multiline':False]
['text':' Dump state_dict to a file to simulate how HuggingFace model is initialized.','line_number':1009,'multiline':False]
['text':' The file will be loaded via .load_state_dict(...)','line_number':1010,'multiline':False]
['text':' Export the model with fake inputs and parameters','line_number':1020,'multiline':False]
['text':' Generate random inputs.','line_number':1061,'multiline':False]
['text':' Original outputs.','line_number':1064,'multiline':False]
['text':' model_with_state_dict=real_model is used to create non-fake weights','line_number':1065,'multiline':False]
['text':' ORT outputs.','line_number':1069,'multiline':False]
['text':' model_with_state_dict=real_model is used to create non-fake weights','line_number':1070,'multiline':False]
