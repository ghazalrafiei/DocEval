['text':' Owner(s): ["module: onnx"]','line_number':1,'multiline':False]
['text':' Modify this section ##########################################################','line_number':49,'multiline':False]
['text':' NOTE: Modify this section as more ops are supported. The list should be sorted','line_number':50,'multiline':False]
['text':' alphabetically.','line_number':51,'multiline':False]
['text':'','line_number':52,'multiline':False]
['text':' For example, to add a test for torch.ceil:','line_number':53,'multiline':False]
['text':' 1.  Add "ceil" to TESTED_OPS then run pytest.','line_number':54,'multiline':False]
['text':' 2.  If the test fails, fix the error or add a new entry to EXPECTED_SKIPS_OR_FAILS.','line_number':55,'multiline':False]
['text':' TODO: Directly modify DecorateInfo in each OpInfo in ob_db when all ops are enabled.','line_number':57,'multiline':False]
['text':' Ops to be tested for numerical consistency between onnx and pytorch','line_number':58,'multiline':False]
['text':' "col2im", extra opinfo needed','line_number':92,'multiline':False]
['text':' "copy",  copy is not in OPS_DB','line_number':95,'multiline':False]
['text':' "detach",  detach is not in OP-TEST-DB','line_number':100,'multiline':False]
['text':' "empty",  non-deterministic','line_number':103,'multiline':False]
['text':' "empty_like",  non-deterministic','line_number':104,'multiline':False]
['text':' "empty_strided",  empty_strided is not in OPS_DB','line_number':105,'multiline':False]
['text':' aten::cat is invoked instead','line_number':120,'multiline':False]
['text':' "new_empty",  non-deterministic','line_number':126,'multiline':False]
['text':' "new_empty_strided",  non-deterministic','line_number':127,'multiline':False]
['text':' "nn.functional.conv2d",  AssertionError: The values for attribute 'shape' do not match in float32','line_number':139,'multiline':False]
['text':' "nn.functional.conv3d",  extra opinfo needed','line_number':140,'multiline':False]
['text':' "nn.functional.convolution",  extra opinfo needed','line_number':141,'multiline':False]
['text':' "nn.functional.scaled_dot_product_attention"  non-deterministic','line_number':153,'multiline':False]
['text':' aten::cat is invoked instead','line_number':164,'multiline':False]
['text':' NOTE: For ATen signature modifications that will break ONNX export,','line_number':176,'multiline':False]
['text':' use **xfail_torchlib_forward_compatibility** and **skip_torchlib_forward_compatibility** instead of xfail or skip','line_number':177,'multiline':False]
['text':' to make the signal apparent for maintainers.','line_number':178,'multiline':False]
['text':' fmt: off','line_number':231,'multiline':False]
['text':' Turn off black formatting to keep the list compact','line_number':232,'multiline':False]
['text':' Expected failures for onnx export.','line_number':234,'multiline':False]
['text':' The list should be sorted alphabetically by op name.','line_number':235,'multiline':False]
['text':' Q: When should I use fixme vs vs skip vs xfail?','line_number':236,'multiline':False]
['text':' A: Prefer xfail over skip when possible.','line_number':237,'multiline':False]
['text':'     2a. If a test is now failing because of xpass, because some previous errors','line_number':238,'multiline':False]
['text':'     are now fixed, removed the corresponding xfail.','line_number':239,'multiline':False]
['text':'     2b. If a test is not failing consistently, use skip.','line_number':240,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/111454','line_number':384,'multiline':False]
['text':' fmt: on','line_number':540,'multiline':False]
['text':' xfail can't only use dtypes to catch all cases','line_number':544,'multiline':False]
['text':' ONNX has not include_self parameter and default is include_self=True mode','line_number':690,'multiline':False]
['text':' END OF SECTION TO MODIFY #####################################################','line_number':701,'multiline':False]
['text':' Assert all ops in OPINFO_FUNCTION_MAPPING are in the OPS_DB','line_number':707,'multiline':False]
['text':' Linear search on ops_test_data.SKIP_XFAIL_SUBTESTS. That's fine because the list is small.','line_number':730,'multiline':False]
['text':' NOTE: If model_type is None, the test is decorator_meta is meant to skip/xfail all model types.','line_number':731,'multiline':False]
['text':' xfail/skip the whole test of the model type without matcher','line_number':742,'multiline':False]
['text':' device is provided by instantiate_device_type_tests, but we only want to run in cpu.','line_number':753,'multiline':False]
['text':' Provide the repr to subtest because tensors are not serializable in parallel test runs','line_number':764,'multiline':False]
['text':' Relax atol and rtol for float32 based on empirical results','line_number':782,'multiline':False]
['text':' Run the test','line_number':794,'multiline':False]
['text':' TODO(titaiwang): refactor this','line_number':873,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/105338','line_number':874,'multiline':False]
['text':' The name needs to match the parameterized_class name.','line_number':877,'multiline':False]
