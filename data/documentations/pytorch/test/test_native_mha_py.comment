['text':' Owner(s): ["module: nn"]','line_number':1,'multiline':False]
['text':' dim_per_head = 12 does not divide evenly by CPU vectorization length of 8','line_number':22,'multiline':False]
['text':' Make sure CUDA can handle small input sizes','line_number':24,'multiline':False]
['text':' dim_per_head = 6 does not divide evenly by CUDA vectorization length of 4,','line_number':26,'multiline':False]
['text':' causes alignment issues','line_number':27,'multiline':False]
['text':' We have to use inference_mode here because q/k/v are','line_number':46,'multiline':False]
['text':' all views of the same Tensor, which autograd doesn't','line_number':47,'multiline':False]
['text':' like. This is fine because this function is only','line_number':48,'multiline':False]
['text':' exposed to Python for purposes of writing this test.','line_number':49,'multiline':False]
['text':' mask_type = 1 => src_key_padding_mask, mask_type = 0 => src_mask','line_number':181,'multiline':False]
['text':' PyTorch implementation returns non-zero junk in the padding','line_number':236,'multiline':False]
['text':' locations; overwrite it so that the comparison works out.','line_number':237,'multiline':False]
['text':' Zero the last row of each TxT weight matrix','line_number':243,'multiline':False]
['text':' High rtol seems necessary for','line_number':258,'multiline':False]
['text':' test_native_multihead_attention_cpu_float32 on Windows,','line_number':259,'multiline':False]
['text':' otherwise 2e-4 would likely be fine.','line_number':260,'multiline':False]
