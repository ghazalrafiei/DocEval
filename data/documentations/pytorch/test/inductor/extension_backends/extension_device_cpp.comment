['text':' register guard','line_number':18,'multiline':False]
['text':' namespace at::detail','line_number':24,'multiline':False]
['text':' basic dummy add function','line_number':26,'multiline':False]
['text':' Since this custom device is just for testing, not bothering to implement kernels.','line_number':29,'multiline':False]
['text':' basic dummy mul function','line_number':33,'multiline':False]
['text':' Since this custom device is just for testing, not bothering to implement kernels.','line_number':36,'multiline':False]
['text':' basic dummy eq function: Only support CPU','line_number':40,'multiline':False]
['text':' Some dummy asserts for the basic use case: inputs are the same size / dtype, all contiguous.','line_number':50,'multiline':False]
['text':' Since this custom device is just for testing, not bothering to implement kernels.','line_number':61,'multiline':False]
['text':' A dummy allocator for our custom device, that secretly uses the CPU','line_number':66,'multiline':False]
['text':' Register our dummy allocator','line_number':86,'multiline':False]
['text':' basic dummy copy_() function, so we can copy from the custom device to/from CPU','line_number':104,'multiline':False]
['text':' Some dummy asserts for the basic use case: inputs are the same size / dtype, all contiguous.','line_number':109,'multiline':False]
['text':' This macro does the heavy lifting.','line_number':141,'multiline':False]
['text':' With TORCH_LIBRARY_IMPL, you can register custom kernels for your backend.','line_number':142,'multiline':False]
['text':' For open registration, we're registering all of our kernels to the PrivateUse1 dispatch key.','line_number':143,'multiline':False]
['text':' Later in this file, we map a custom device to the PrivateUse1 device type,','line_number':144,'multiline':False]
['text':' which allows user code that puts a tensor on your custom_device to eventually get plumbed','line_number':145,'multiline':False]
['text':' into the kernels registered here.','line_number':146,'multiline':False]
['text':'','line_number':147,'multiline':False]
['text':' This macro registers your kernels to the PyTorch Dispatcher.','line_number':148,'multiline':False]
['text':' More details on the dispatcher can be found at http://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/.','line_number':149,'multiline':False]
['text':' This basic implementation doesn't bother dealing with different device indices','line_number':160,'multiline':False]
['text':' (e.g. custom_device:0 vs. custom_device:1).','line_number':161,'multiline':False]
['text':' We could do that by letting the user pass in a device index in our exposed device function.','line_number':162,'multiline':False]
['text':' Note that if you do that, you'll also need to register a device guard to core.','line_number':163,'multiline':False]
['text':' See `c10/core/impl/DeviceGuardImplInterface.h:C10_REGISTER_GUARD_IMPL`.','line_number':164,'multiline':False]
['text':' Constructors','line_number':180,'multiline':False]
['text':' this is used to register generator','line_number':188,'multiline':False]
['text':' Here, we're exposing a custom device object that corresponds to our custom backend.','line_number':197,'multiline':False]
['text':' We do this using pybind: exposing an "extension_name.custom_device()" function in python,','line_number':198,'multiline':False]
['text':' that's implemented in C++.','line_number':199,'multiline':False]
['text':' The implementation in this file maps directly to the `PrivateUse1` device type.','line_number':200,'multiline':False]
