['text':' Owner(s): ["module: dynamo"]','line_number':1,'multiline':False]
['text':' from numpy._utils import _pep440','line_number':14,'multiline':False]
['text':' from hypothesis import given, settings','line_number':18,'multiline':False]
['text':' from hypothesis.strategies import sampled_from','line_number':19,'multiline':False]
['text':' from hypothesis.extra import numpy as hynp','line_number':20,'multiline':False]
['text':'    assert_array_equal, suppress_warnings, _gen_alignment_data,','line_number':50,'multiline':False]
['text':'    assert_warns,','line_number':51,'multiline':False]
['text':' This compares scalarmath against ufuncs.','line_number':95,'multiline':False]
['text':' list of types','line_number':105,'multiline':False]
['text':' It was comparing the type numbers, but the new ufunc','line_number':114,'multiline':False]
['text':' function-finding mechanism finds the lowest function','line_number':115,'multiline':False]
['text':' to which both inputs can be cast - which produces 'l'','line_number':116,'multiline':False]
['text':' when you do 'q' + 'b'.  The old function finding mechanism','line_number':117,'multiline':False]
['text':' skipped ahead based on the first argument, but that','line_number':118,'multiline':False]
['text':' does not produce properly symmetric results...','line_number':119,'multiline':False]
['text':' freezes under torch.Dynamo (loop unrolling, huh)','line_number':133,'multiline':False]
['text':' test leak of scalar objects','line_number':135,'multiline':False]
['text':' a leak would show up in valgrind as still-reachable of ~2.6MB','line_number':136,'multiline':False]
['text':' test alignments offsets for simd instructions','line_number':143,'multiline':False]
['text':' alignments for vz + 2 * (vs - 1) + 1','line_number':144,'multiline':False]
['text':' skip true divide for ints','line_number':163,'multiline':False]
['text':' (reason="pytorch does not have .view")','line_number':176,'multiline':False]
['text':' check data that is not aligned to element size','line_number':178,'multiline':False]
['text':' i.e doubles are aligned to 4 bytes on i386','line_number':179,'multiline':False]
['text':' (reason="Value-based casting: (2)**(-2) -> 0 in pytorch.")','line_number':208,'multiline':False]
['text':' Note that the combination of uint64 with a signed integer','line_number':210,'multiline':False]
['text':' has common type np.float64. The other combinations should all','line_number':211,'multiline':False]
['text':' raise a ValueError for integer ** negative integer.','line_number':212,'multiline':False]
['text':' 1 ** -1 possible special case','line_number':215,'multiline':False]
['text':' -1 ** -1 possible special case','line_number':225,'multiline':False]
['text':' 2 ** -1 perhaps generic','line_number':235,'multiline':False]
['text':' modular power is not implemented, so ensure it errors','line_number':269,'multiline':False]
['text':' noqa: F841','line_number':273,'multiline':False]
['text':' note that 3-operand power only dispatches on the first argument','line_number':275,'multiline':False]
['text':' dt = np.typecodes["AllInteger"] + np.typecodes["Float"]','line_number':294,'multiline':False]
['text':' test that float results are exact for small integers. This also','line_number':312,'multiline':False]
['text':' holds for the same integers scaled by powers of two.','line_number':313,'multiline':False]
['text':' convert exact integer results from Python to float so that','line_number':322,'multiline':False]
['text':' signed zero can be used, it is checked.','line_number':323,'multiline':False]
['text':' use list comprehension so a_ and b_ are scalars','line_number':333,'multiline':False]
['text':' gh-6127','line_number':339,'multiline':False]
['text':' dt = np.typecodes["Float"]','line_number':340,'multiline':False]
['text':' Equal assertion should hold when fmod is used','line_number':350,'multiline':False]
['text':' FIXME: make xfail','line_number':360,'multiline':False]
['text':' Check nans, inf','line_number':370,'multiline':False]
['text':'     with suppress_warnings() as sup:','line_number':371,'multiline':False]
['text':'         sup.filter(RuntimeWarning, "invalid value encountered in remainder")','line_number':372,'multiline':False]
['text':'         sup.filter(RuntimeWarning, "divide by zero encountered in remainder")','line_number':373,'multiline':False]
['text':'         sup.filter(RuntimeWarning, "divide by zero encountered in floor_divide")','line_number':374,'multiline':False]
['text':'         sup.filter(RuntimeWarning, "divide by zero encountered in divmod")','line_number':375,'multiline':False]
['text':'         sup.filter(RuntimeWarning, "invalid value encountered in divmod")','line_number':376,'multiline':False]
['text':' MSVC 2008 returns NaN here, so disable the check.','line_number':384,'multiline':False]
['text':' rem = operator.mod(fone, finf)','line_number':385,'multiline':False]
['text':' assert_(rem == fone, 'dt: %s' % dt)','line_number':386,'multiline':False]
['text':' tupled (numerator, denominator, expected)','line_number':416,'multiline':False]
['text':' for testing as expected == numerator/denominator','line_number':417,'multiline':False]
['text':' check real and imag parts separately to avoid comparison','line_number':433,'multiline':False]
['text':' in array context, which does not account for signed zeros','line_number':434,'multiline':False]
['text':' tupled (numerator, denominator, expected)','line_number':440,'multiline':False]
['text':' for testing as expected == numerator/denominator','line_number':441,'multiline':False]
['text':' trigger branch: real(fabs(denom)) > imag(fabs(denom))','line_number':444,'multiline':False]
['text':' followed by else condition as neither are == 0','line_number':445,'multiline':False]
['text':' trigger branch: real(fabs(denom)) > imag(fabs(denom))','line_number':448,'multiline':False]
['text':' followed by if condition as both are == 0','line_number':449,'multiline':False]
['text':' is performed in test_zero_division(), so this is skipped','line_number':450,'multiline':False]
['text':' trigger else if branch: real(fabs(denom)) < imag(fabs(denom))','line_number':452,'multiline':False]
['text':' check real and imag parts separately to avoid comparison','line_number':460,'multiline':False]
['text':' in array context, which does not account for signed zeros','line_number':461,'multiline':False]
['text':' NB: this test assumes that the default fp type is float64','line_number':468,'multiline':False]
['text':' (reason="pytorch does not emit this warning.")','line_number':476,'multiline':False]
['text':' All integer','line_number':503,'multiline':False]
['text':' Signed integers and floats','line_number':518,'multiline':False]
['text':' Unsigned integers','line_number':539,'multiline':False]
['text':' unsigned vs signed','line_number':545,'multiline':False]
['text':' Scalars should just return False and not give a warnings.','line_number':561,'multiline':False]
['text':' The comparisons are flagged by pep8, ignore that.','line_number':562,'multiline':False]
['text':' class TestRepr:','line_number':570,'multiline':False]
['text':'    def test_repr(self):','line_number':571,'multiline':False]
['text':'        for t in types:','line_number':572,'multiline':False]
['text':'            val = t(1197346475.0137341)','line_number':573,'multiline':False]
['text':'            val_repr = repr(val)','line_number':574,'multiline':False]
['text':'            val2 = eval(val_repr)','line_number':575,'multiline':False]
['text':'            assert_equal( val, val2 )','line_number':576,'multiline':False]
['text':' (reason="can delegate repr to pytorch")','line_number':579,'multiline':False]
['text':' could add some more types to the list below','line_number':586,'multiline':False]
['text':' Values from https://en.wikipedia.org/wiki/IEEE_754','line_number':588,'multiline':False]
['text':' long double test cannot work, because eval goes through a python','line_number':607,'multiline':False]
['text':' float','line_number':608,'multiline':False]
['text':' Test that basic sequences get repeated when multiplied with','line_number':616,'multiline':False]
['text':' numpy integers. And errors are raised when multiplied with others.','line_number':617,'multiline':False]
['text':' Some of this behaviour may be controversial and could be open for','line_number':618,'multiline':False]
['text':' change.','line_number':619,'multiline':False]
['text':' can't default-construct void scalars','line_number':623,'multiline':False]
['text':' Test that an array-like which does not know how to be multiplied','line_number':647,'multiline':False]
['text':' does not attempt sequence repeat (raise TypeError).','line_number':648,'multiline':False]
['text':' See also gh-7428.','line_number':649,'multiline':False]
['text':' Test for simple ArrayLike above and memoryviews (original report)','line_number':657,'multiline':False]
['text':' XXX: TypeError from numpy, RuntimeError from torch','line_number':668,'multiline':False]
['text':' with suppress_warnings() as sup:','line_number':673,'multiline':False]
['text':'     sup.filter(RuntimeWarning)','line_number':674,'multiline':False]
['text':' XXX: TypeError from numpy','line_number':688,'multiline':False]
['text':' RuntimeError from torch','line_number':689,'multiline':False]
['text':'        with suppress_warnings() as sup:','line_number':693,'multiline':False]
['text':'            sup.filter(RuntimeWarning)','line_number':694,'multiline':False]
['text':' assert_equal() checks zero signedness','line_number':707,'multiline':False]
['text':'      with suppress_warnings() as sup:','line_number':716,'multiline':False]
['text':'          sup.filter(UserWarning)','line_number':717,'multiline':False]
['text':' gh-2449','line_number':739,'multiline':False]
['text':' sign bit is preserved','line_number':749,'multiline':False]
['text':' FIXME: make xfail','line_number':753,'multiline':False]
['text':' Result on scalars should be the same as on arrays','line_number':759,'multiline':False]
['text':' Cast back to Python, in case the NumPy scalar has less precision','line_number':780,'multiline':False]
['text':' If Python distinguishes different NaNs we do so too (gh-18833)','line_number':789,'multiline':False]
['text':' Test some complex valued hashes specifically:','line_number':794,'multiline':False]
['text':' (reason="pytorch does not warn on overflow")','line_number':813,'multiline':False]
['text':' The minimum signed integer can "overflow" for some additional operations','line_number':846,'multiline':False]
['text':' (reason="pytorch does not warn on overflow")','line_number':855,'multiline':False]
['text':' does not warn','line_number':863,'multiline':False]
['text':' (reason="pytorch raises RuntimeError on division by zero")','line_number':865,'multiline':False]
['text':' Note __op__ and __rop__ may be identical here:','line_number':887,'multiline':False]
['text':' inheritance has to override, or this is correctly lost:','line_number':932,'multiline':False]
['text':' inherited','line_number':935,'multiline':False]
['text':' Two independent subclasses do not really define an order.  This could','line_number':937,'multiline':False]
['text':' be attempted, but we do not since Python's `int` does neither:','line_number':938,'multiline':False]
['text':' inherited','line_number':940,'multiline':False]
['text':' @np._no_nep50_warning()','line_number':945,'multiline':False]
['text':' Check that deferring is indicated using `__array_ufunc__`:','line_number':953,'multiline':False]
['text':' Just like normally, we should never presume we can modify the float.','line_number':960,'multiline':False]
['text':' module is not support for complex.  Do not test.','line_number':965,'multiline':False]
['text':' When no deferring is indicated, subclasses are handled normally.','line_number':970,'multiline':False]
['text':' Check for float32, as a float subclass float64 may behave differently','line_number':973,'multiline':False]
