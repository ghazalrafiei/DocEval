['text':' Owner(s): ["module: serialization"]','line_number':1,'multiline':False]
['text':' These tests were all copied from `test/test_torch.py` at some point, so see','line_number':32,'multiline':False]
['text':' the actual blame, see this revision','line_number':33,'multiline':False]
['text':' https://github.com/pytorch/pytorch/blame/9a2691f2fc948b9792686085b493c61793c2de30/test/test_torch.py','line_number':34,'multiline':False]
['text':' Python 2's StringIO.StringIO has no fileno attribute.','line_number':57,'multiline':False]
['text':' This is used to test that.','line_number':58,'multiline':False]
['text':' 0-3','line_number':88,'multiline':False]
['text':' 4','line_number':89,'multiline':False]
['text':' 5','line_number':90,'multiline':False]
['text':' 6','line_number':91,'multiline':False]
['text':' 7','line_number':94,'multiline':False]
['text':' 8','line_number':95,'multiline':False]
['text':' I have to do it in this roundabout fashion, because there's no','line_number':111,'multiline':False]
['text':' way to slice storages','line_number':112,'multiline':False]
['text':' check that serializing the same storage view object unpickles','line_number':116,'multiline':False]
['text':' it as one object not two (and vice versa)','line_number':117,'multiline':False]
['text':' Test serialization with a real file','line_number':156,'multiline':False]
['text':' test non-ascii encoding of bytes arrays/strings','line_number':167,'multiline':False]
['text':' The following bytes are produced by serializing','line_number':168,'multiline':False]
['text':'   [b'\xc5\xbc\xc4\x85\xc4\x85\xc3\xb3\xc5\xbc\xc4\x85\xc5\xbc', torch.zeros(1, dtype=torch.float), 2]','line_number':169,'multiline':False]
['text':' in Python 2.7.12 and PyTorch 0.4.1, where the first element contains','line_number':170,'multiline':False]
['text':' bytes of some utf-8 characters (i.e., `utf8_str.encode('utf-8')`).','line_number':171,'multiline':False]
['text':' Test serialization (load and save) with a filelike object','line_number':200,'multiline':False]
['text':' If this check is False for all Python versions (i.e. the fix','line_number':222,'multiline':False]
['text':' has been backported), this test and torch.serialization._is_zipfile','line_number':223,'multiline':False]
['text':' can be deleted','line_number':224,'multiline':False]
['text':' Test serialization with gzip file','line_number':231,'multiline':False]
['text':' test some old tensor serialization mechanism','line_number':443,'multiline':False]
['text':' Setup: create a serialized file object with a 'cuda:0' restore location','line_number':534,'multiline':False]
['text':' The following was generated by saving a torch.randn(2, device='cuda') tensor.','line_number':535,'multiline':False]
['text':' Reset between save and load','line_number':563,'multiline':False]
['text':' Test edge cases where filelike objects are missing attributes.','line_number':584,'multiline':False]
['text':' The Python io docs suggests that these attributes should really exist','line_number':585,'multiline':False]
['text':' and throw io.UnsupportedOperation, but that isn't always the case.','line_number':586,'multiline':False]
['text':' This one should call python read multiple times','line_number':601,'multiline':False]
['text':' For maximum effiency, when reading a file-like object,','line_number':608,'multiline':False]
['text':' ensure the C API calls readinto instead of read.','line_number':609,'multiline':False]
['text':' Try to serialize to buffers that does not have write method','line_number':621,'multiline':False]
['text':' Or have a malfrormed one, and make sure it does not cause an abort','line_number':622,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/87997','line_number':623,'multiline':False]
['text':' Tries to serialize str into tensor','line_number':626,'multiline':False]
['text':' Tries to serialize str into tensor with write property','line_number':631,'multiline':False]
['text':' Tries to serialize str into tensor with wrong callable write property','line_number':636,'multiline':False]
['text':' Tries to serialize list into CharStorage','line_number':641,'multiline':False]
['text':' Tries to serialize ndarray into ndarray','line_number':645,'multiline':False]
['text':' Generated using:','line_number':650,'multiline':False]
['text':'','line_number':651,'multiline':False]
['text':' t = torch.zeros(2);','line_number':652,'multiline':False]
['text':' s1 = t.storage()[:1]','line_number':653,'multiline':False]
['text':' s2 = t.storage()[1:]','line_number':654,'multiline':False]
['text':' torch.save((s1, s2), 'foo.ser')','line_number':655,'multiline':False]
['text':'','line_number':656,'multiline':False]
['text':' with PyTorch 0.3.1','line_number':657,'multiline':False]
['text':' This Pickle contains a Python 2 module with Unicode data and the','line_number':679,'multiline':False]
['text':' loading should fail if the user explicitly specifies ascii encoding!','line_number':680,'multiline':False]
['text':' This Pickle contains some Unicode data!','line_number':685,'multiline':False]
['text':' unique_key is necessary because on Python 2.7, if a warning passed to','line_number':811,'multiline':False]
['text':' the warning module is the same, it is not raised again.','line_number':812,'multiline':False]
['text':' First check that the checkpoint can be loaded without warning about unsafe loads','line_number':831,'multiline':False]
['text':' Replace the module with different source','line_number':839,'multiline':False]
['text':' Ensure large zip64 serialization works properly','line_number':940,'multiline':False]
['text':' Run GC to clear up as much memory as possible before running this test','line_number':942,'multiline':False]
['text':' check method is not bound','line_number':985,'multiline':False]
['text':' Must be less than 1MB','line_number':986,'multiline':False]
['text':' Unsafe load should work','line_number':1014,'multiline':False]
['text':' Safe load should assert','line_number':1017,'multiline':False]
['text':' Unsafe load should work','line_number':1029,'multiline':False]
['text':' We don't support serializing `ZeroTensor` as it is not public','line_number':1043,'multiline':False]
['text':' facing yet.','line_number':1044,'multiline':False]
['text':' If in future, `ZeroTensor` serialization is supported, this test','line_number':1045,'multiline':False]
['text':' should start failing!','line_number':1046,'multiline':False]
['text':' Unsafe load should work','line_number':1053,'multiline':False]
['text':' NOTE: `torch.save` fails before we hit the TORCH_CHECK in `getTensoMetadata`','line_number':1056,'multiline':False]
['text':'       as nullptr storage is disabled.','line_number':1057,'multiline':False]
['text':' clean out hidden state','line_number':1065,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':1079,'multiline':False]
['text':'','line_number':1080,'multiline':False]
['text':' import torch','line_number':1081,'multiline':False]
['text':'','line_number':1082,'multiline':False]
['text':' lstm = torch.nn.LSTM(3, 3)','line_number':1083,'multiline':False]
['text':' inputs = [torch.randn(1, 3) for _ in range(5)]','line_number':1084,'multiline':False]
['text':'','line_number':1085,'multiline':False]
['text':' inputs = torch.cat(inputs).view(len(inputs), 1, -1)','line_number':1086,'multiline':False]
['text':' hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))','line_number':1087,'multiline':False]
['text':'','line_number':1088,'multiline':False]
['text':' torch.save(lstm.state_dict(), "lstm.LE.pt", _disable_byteorder_record=True)','line_number':1089,'multiline':False]
['text':' torch.save(lstm.state_dict(), "lstm.LE.BOM.pt")','line_number':1090,'multiline':False]
['text':'','line_number':1091,'multiline':False]
['text':' print(lstm.state_dict())','line_number':1092,'multiline':False]
['text':'','line_number':1093,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':1094,'multiline':False]
['text':'','line_number':1095,'multiline':False]
['text':' import torch','line_number':1096,'multiline':False]
['text':'','line_number':1097,'multiline':False]
['text':' lstm = torch.nn.LSTM(3, 3)','line_number':1098,'multiline':False]
['text':' lstm.load_state_dict(torch.load("lstm.LE.BOM.pt"), strict=True)','line_number':1099,'multiline':False]
['text':'','line_number':1100,'multiline':False]
['text':' torch.save(lstm.state_dict(), "lstm.BE.pt", _disable_byteorder_record=True)','line_number':1101,'multiline':False]
['text':' torch.save(lstm.state_dict(), "lstm.BE.BOM.pt")','line_number':1102,'multiline':False]
['text':'','line_number':1103,'multiline':False]
['text':' print(lstm.state_dict())','line_number':1104,'multiline':False]
['text':'','line_number':1105,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':1106,'multiline':False]
['text':'','line_number':1107,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':1108,'multiline':False]
['text':' data = file.read()','line_number':1109,'multiline':False]
['text':' file.close()','line_number':1110,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':1111,'multiline':False]
['text':'','line_number':1112,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':1113,'multiline':False]
['text':'','line_number':1114,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':1433,'multiline':False]
['text':'','line_number':1434,'multiline':False]
['text':' import torch','line_number':1435,'multiline':False]
['text':'','line_number':1436,'multiline':False]
['text':' x = torch.randn(2,2, dtype=torch.double)','line_number':1437,'multiline':False]
['text':'','line_number':1438,'multiline':False]
['text':' torch.save(x, "tensor.double.LE.pt", _disable_byteorder_record=True)','line_number':1439,'multiline':False]
['text':' torch.save(x, "tensor.double.LE.BOM.pt")','line_number':1440,'multiline':False]
['text':'','line_number':1441,'multiline':False]
['text':' print(x)','line_number':1442,'multiline':False]
['text':'','line_number':1443,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':1444,'multiline':False]
['text':'','line_number':1445,'multiline':False]
['text':' import torch','line_number':1446,'multiline':False]
['text':'','line_number':1447,'multiline':False]
['text':' x = torch.load('tensor.double.LE.BOM.pt')','line_number':1448,'multiline':False]
['text':'','line_number':1449,'multiline':False]
['text':' torch.save(x, 'tensor.double.BE.pt', _disable_byteorder_record=True)','line_number':1450,'multiline':False]
['text':' torch.save(x, 'tensor.double.BE.BOM.pt')','line_number':1451,'multiline':False]
['text':'','line_number':1452,'multiline':False]
['text':' print(x)','line_number':1453,'multiline':False]
['text':'','line_number':1454,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':1455,'multiline':False]
['text':'','line_number':1456,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':1457,'multiline':False]
['text':' data = file.read()','line_number':1458,'multiline':False]
['text':' file.close()','line_number':1459,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':1460,'multiline':False]
['text':'','line_number':1461,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':1462,'multiline':False]
['text':'','line_number':1463,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':1636,'multiline':False]
['text':'','line_number':1637,'multiline':False]
['text':' import torch','line_number':1638,'multiline':False]
['text':'','line_number':1639,'multiline':False]
['text':' x = torch.randn(2,2, dtype=torch.float)','line_number':1640,'multiline':False]
['text':'','line_number':1641,'multiline':False]
['text':' torch.save(x, "tensor.float.LE.pt", _disable_byteorder_record=True)','line_number':1642,'multiline':False]
['text':' torch.save(x, "tensor.float.LE.BOM.pt")','line_number':1643,'multiline':False]
['text':'','line_number':1644,'multiline':False]
['text':' print(x)','line_number':1645,'multiline':False]
['text':'','line_number':1646,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':1647,'multiline':False]
['text':'','line_number':1648,'multiline':False]
['text':' import torch','line_number':1649,'multiline':False]
['text':'','line_number':1650,'multiline':False]
['text':' x = torch.load('tensor.float.LE.BOM.pt')','line_number':1651,'multiline':False]
['text':'','line_number':1652,'multiline':False]
['text':' torch.save(x, 'tensor.float.BE.pt', _disable_byteorder_record=True)','line_number':1653,'multiline':False]
['text':' torch.save(x, 'tensor.float.BE.BOM.pt')','line_number':1654,'multiline':False]
['text':'','line_number':1655,'multiline':False]
['text':' print(x)','line_number':1656,'multiline':False]
['text':'','line_number':1657,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':1658,'multiline':False]
['text':'','line_number':1659,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':1660,'multiline':False]
['text':' data = file.read()','line_number':1661,'multiline':False]
['text':' file.close()','line_number':1662,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':1663,'multiline':False]
['text':'','line_number':1664,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':1665,'multiline':False]
['text':'','line_number':1666,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':1835,'multiline':False]
['text':'','line_number':1836,'multiline':False]
['text':' import torch','line_number':1837,'multiline':False]
['text':'','line_number':1838,'multiline':False]
['text':' x = torch.randn(2,2, dtype=torch.half)','line_number':1839,'multiline':False]
['text':'','line_number':1840,'multiline':False]
['text':' torch.save(x, "tensor.half.LE.pt", _disable_byteorder_record=True)','line_number':1841,'multiline':False]
['text':' torch.save(x, "tensor.half.LE.BOM.pt")','line_number':1842,'multiline':False]
['text':'','line_number':1843,'multiline':False]
['text':' print(x)','line_number':1844,'multiline':False]
['text':'','line_number':1845,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':1846,'multiline':False]
['text':'','line_number':1847,'multiline':False]
['text':' import torch','line_number':1848,'multiline':False]
['text':'','line_number':1849,'multiline':False]
['text':' x = torch.load('tensor.half.LE.BOM.pt')','line_number':1850,'multiline':False]
['text':'','line_number':1851,'multiline':False]
['text':' torch.save(x, 'tensor.half.BE.pt', _disable_byteorder_record=True)','line_number':1852,'multiline':False]
['text':' torch.save(x, 'tensor.half.BE.BOM.pt')','line_number':1853,'multiline':False]
['text':'','line_number':1854,'multiline':False]
['text':' print(x)','line_number':1855,'multiline':False]
['text':'','line_number':1856,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':1857,'multiline':False]
['text':'','line_number':1858,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':1859,'multiline':False]
['text':' data = file.read()','line_number':1860,'multiline':False]
['text':' file.close()','line_number':1861,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':1862,'multiline':False]
['text':'','line_number':1863,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':1864,'multiline':False]
['text':'','line_number':1865,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':2034,'multiline':False]
['text':'','line_number':2035,'multiline':False]
['text':' import torch','line_number':2036,'multiline':False]
['text':'','line_number':2037,'multiline':False]
['text':' x = torch.randint(-4294967295, 4294967295, [4, 4], dtype=torch.long)','line_number':2038,'multiline':False]
['text':'','line_number':2039,'multiline':False]
['text':' torch.save(x, "tensor.long.LE.pt", _disable_byteorder_record=True)','line_number':2040,'multiline':False]
['text':' torch.save(x, "tensor.long.LE.BOM.pt")','line_number':2041,'multiline':False]
['text':'','line_number':2042,'multiline':False]
['text':' print(x)','line_number':2043,'multiline':False]
['text':'','line_number':2044,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':2045,'multiline':False]
['text':'','line_number':2046,'multiline':False]
['text':' import torch','line_number':2047,'multiline':False]
['text':'','line_number':2048,'multiline':False]
['text':' x = torch.load('tensor.long.LE.BOM.pt')','line_number':2049,'multiline':False]
['text':'','line_number':2050,'multiline':False]
['text':' torch.save(x, 'tensor.long.BE.pt', _disable_byteorder_record=True)','line_number':2051,'multiline':False]
['text':' torch.save(x, 'tensor.long.BE.BOM.pt')','line_number':2052,'multiline':False]
['text':'','line_number':2053,'multiline':False]
['text':' print(x)','line_number':2054,'multiline':False]
['text':'','line_number':2055,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':2056,'multiline':False]
['text':'','line_number':2057,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':2058,'multiline':False]
['text':' data = file.read()','line_number':2059,'multiline':False]
['text':' file.close()','line_number':2060,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':2061,'multiline':False]
['text':'','line_number':2062,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':2063,'multiline':False]
['text':'','line_number':2064,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':2257,'multiline':False]
['text':'','line_number':2258,'multiline':False]
['text':' import torch','line_number':2259,'multiline':False]
['text':'','line_number':2260,'multiline':False]
['text':' x = torch.randint(-2147483648, 2147483648, [4, 4], dtype=torch.int)','line_number':2261,'multiline':False]
['text':'','line_number':2262,'multiline':False]
['text':' torch.save(x, "tensor.int.LE.pt", _disable_byteorder_record=True)','line_number':2263,'multiline':False]
['text':' torch.save(x, "tensor.int.LE.BOM.pt")','line_number':2264,'multiline':False]
['text':'','line_number':2265,'multiline':False]
['text':' print(x)','line_number':2266,'multiline':False]
['text':'','line_number':2267,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':2268,'multiline':False]
['text':'','line_number':2269,'multiline':False]
['text':' import torch','line_number':2270,'multiline':False]
['text':'','line_number':2271,'multiline':False]
['text':' x = torch.load('tensor.int.LE.BOM.pt')','line_number':2272,'multiline':False]
['text':'','line_number':2273,'multiline':False]
['text':' torch.save(x, 'tensor.int.BE.pt', _disable_byteorder_record=True)','line_number':2274,'multiline':False]
['text':' torch.save(x, 'tensor.int.BE.BOM.pt')','line_number':2275,'multiline':False]
['text':'','line_number':2276,'multiline':False]
['text':' print(x)','line_number':2277,'multiline':False]
['text':'','line_number':2278,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':2279,'multiline':False]
['text':'','line_number':2280,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':2281,'multiline':False]
['text':' data = file.read()','line_number':2282,'multiline':False]
['text':' file.close()','line_number':2283,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':2284,'multiline':False]
['text':'','line_number':2285,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':2286,'multiline':False]
['text':'','line_number':2287,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':2464,'multiline':False]
['text':'','line_number':2465,'multiline':False]
['text':' import torch','line_number':2466,'multiline':False]
['text':'','line_number':2467,'multiline':False]
['text':' x = torch.randint(-32768, 32768, [4, 4], dtype=torch.int16)','line_number':2468,'multiline':False]
['text':'','line_number':2469,'multiline':False]
['text':' torch.save(x, "tensor.int16.LE.pt", _disable_byteorder_record=True)','line_number':2470,'multiline':False]
['text':' torch.save(x, "tensor.int16.LE.BOM.pt")','line_number':2471,'multiline':False]
['text':'','line_number':2472,'multiline':False]
['text':' print(x)','line_number':2473,'multiline':False]
['text':'','line_number':2474,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':2475,'multiline':False]
['text':'','line_number':2476,'multiline':False]
['text':' import torch','line_number':2477,'multiline':False]
['text':'','line_number':2478,'multiline':False]
['text':' x = torch.load('tensor.int16.LE.BOM.pt')','line_number':2479,'multiline':False]
['text':'','line_number':2480,'multiline':False]
['text':' torch.save(x, 'tensor.int16.BE.pt', _disable_byteorder_record=True)','line_number':2481,'multiline':False]
['text':' torch.save(x, 'tensor.int16.BE.BOM.pt')','line_number':2482,'multiline':False]
['text':'','line_number':2483,'multiline':False]
['text':' print(x)','line_number':2484,'multiline':False]
['text':'','line_number':2485,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':2486,'multiline':False]
['text':'','line_number':2487,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':2488,'multiline':False]
['text':' data = file.read()','line_number':2489,'multiline':False]
['text':' file.close()','line_number':2490,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':2491,'multiline':False]
['text':'','line_number':2492,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':2493,'multiline':False]
['text':'','line_number':2494,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':2667,'multiline':False]
['text':'','line_number':2668,'multiline':False]
['text':' import torch','line_number':2669,'multiline':False]
['text':'','line_number':2670,'multiline':False]
['text':' x = torch.randint(-128, 128, [4, 4], dtype=torch.int8)','line_number':2671,'multiline':False]
['text':'','line_number':2672,'multiline':False]
['text':' torch.save(x, "tensor.int8.LE.pt", _disable_byteorder_record=True)','line_number':2673,'multiline':False]
['text':' torch.save(x, "tensor.int8.LE.BOM.pt")','line_number':2674,'multiline':False]
['text':'','line_number':2675,'multiline':False]
['text':' print(x)','line_number':2676,'multiline':False]
['text':'','line_number':2677,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':2678,'multiline':False]
['text':'','line_number':2679,'multiline':False]
['text':' import torch','line_number':2680,'multiline':False]
['text':'','line_number':2681,'multiline':False]
['text':' x = torch.load('tensor.int8.LE.BOM.pt')','line_number':2682,'multiline':False]
['text':'','line_number':2683,'multiline':False]
['text':' torch.save(x, 'tensor.int8.BE.pt', _disable_byteorder_record=True)','line_number':2684,'multiline':False]
['text':' torch.save(x, 'tensor.int8.BE.BOM.pt')','line_number':2685,'multiline':False]
['text':'','line_number':2686,'multiline':False]
['text':' print(x)','line_number':2687,'multiline':False]
['text':'','line_number':2688,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':2689,'multiline':False]
['text':'','line_number':2690,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':2691,'multiline':False]
['text':' data = file.read()','line_number':2692,'multiline':False]
['text':' file.close()','line_number':2693,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':2694,'multiline':False]
['text':'','line_number':2695,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':2696,'multiline':False]
['text':'','line_number':2697,'multiline':False]
['text':' 1-byte types are same on BE and LE','line_number':2847,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':2860,'multiline':False]
['text':'','line_number':2861,'multiline':False]
['text':' import torch','line_number':2862,'multiline':False]
['text':'','line_number':2863,'multiline':False]
['text':' x = torch.randint(0, 256, [4, 4], dtype=torch.uint8)','line_number':2864,'multiline':False]
['text':'','line_number':2865,'multiline':False]
['text':' torch.save(x, "tensor.uint8.LE.pt", _disable_byteorder_record=True)','line_number':2866,'multiline':False]
['text':' torch.save(x, "tensor.uint8.LE.BOM.pt")','line_number':2867,'multiline':False]
['text':'','line_number':2868,'multiline':False]
['text':' print(x)','line_number':2869,'multiline':False]
['text':'','line_number':2870,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':2871,'multiline':False]
['text':'','line_number':2872,'multiline':False]
['text':' import torch','line_number':2873,'multiline':False]
['text':'','line_number':2874,'multiline':False]
['text':' x = torch.load('tensor.uint8.LE.BOM.pt')','line_number':2875,'multiline':False]
['text':'','line_number':2876,'multiline':False]
['text':' torch.save(x, 'tensor.uint8.BE.pt', _disable_byteorder_record=True)','line_number':2877,'multiline':False]
['text':' torch.save(x, 'tensor.uint8.BE.BOM.pt')','line_number':2878,'multiline':False]
['text':'','line_number':2879,'multiline':False]
['text':' print(x)','line_number':2880,'multiline':False]
['text':'','line_number':2881,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':2882,'multiline':False]
['text':'','line_number':2883,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':2884,'multiline':False]
['text':' data = file.read()','line_number':2885,'multiline':False]
['text':' file.close()','line_number':2886,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':2887,'multiline':False]
['text':'','line_number':2888,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':2889,'multiline':False]
['text':'','line_number':2890,'multiline':False]
['text':' 1-byte types are same on BE and LE','line_number':3042,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':3055,'multiline':False]
['text':'','line_number':3056,'multiline':False]
['text':' import torch','line_number':3057,'multiline':False]
['text':'','line_number':3058,'multiline':False]
['text':' x = torch.randint(0, 2, [4, 4], dtype=torch.bool)','line_number':3059,'multiline':False]
['text':'','line_number':3060,'multiline':False]
['text':' torch.save(x, "tensor.bool.LE.pt", _disable_byteorder_record=True)','line_number':3061,'multiline':False]
['text':' torch.save(x, "tensor.bool.LE.BOM.pt")','line_number':3062,'multiline':False]
['text':'','line_number':3063,'multiline':False]
['text':' print(x)','line_number':3064,'multiline':False]
['text':'','line_number':3065,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':3066,'multiline':False]
['text':'','line_number':3067,'multiline':False]
['text':' import torch','line_number':3068,'multiline':False]
['text':'','line_number':3069,'multiline':False]
['text':' x = torch.load('tensor.bool.LE.BOM.pt')','line_number':3070,'multiline':False]
['text':'','line_number':3071,'multiline':False]
['text':' torch.save(x, 'tensor.bool.BE.pt', _disable_byteorder_record=True)','line_number':3072,'multiline':False]
['text':' torch.save(x, 'tensor.bool.BE.BOM.pt')','line_number':3073,'multiline':False]
['text':'','line_number':3074,'multiline':False]
['text':' print(x)','line_number':3075,'multiline':False]
['text':'','line_number':3076,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':3077,'multiline':False]
['text':'','line_number':3078,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':3079,'multiline':False]
['text':' data = file.read()','line_number':3080,'multiline':False]
['text':' file.close()','line_number':3081,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':3082,'multiline':False]
['text':'','line_number':3083,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':3084,'multiline':False]
['text':'','line_number':3085,'multiline':False]
['text':' 1-byte types are same on BE and LE','line_number':3237,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':3250,'multiline':False]
['text':'','line_number':3251,'multiline':False]
['text':' import torch','line_number':3252,'multiline':False]
['text':'','line_number':3253,'multiline':False]
['text':' x = torch.randn(2,2, dtype=torch.bfloat16)','line_number':3254,'multiline':False]
['text':'','line_number':3255,'multiline':False]
['text':' torch.save(x, "tensor.bfloat16.LE.pt", _disable_byteorder_record=True)','line_number':3256,'multiline':False]
['text':' torch.save(x, "tensor.bfloat16.LE.BOM.pt")','line_number':3257,'multiline':False]
['text':'','line_number':3258,'multiline':False]
['text':' print(x)','line_number':3259,'multiline':False]
['text':'','line_number':3260,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':3261,'multiline':False]
['text':'','line_number':3262,'multiline':False]
['text':' import torch','line_number':3263,'multiline':False]
['text':'','line_number':3264,'multiline':False]
['text':' x = torch.load('tensor.bfloat16.LE.BOM.pt')','line_number':3265,'multiline':False]
['text':'','line_number':3266,'multiline':False]
['text':' torch.save(x, 'tensor.bfloat16.BE.pt', _disable_byteorder_record=True)','line_number':3267,'multiline':False]
['text':' torch.save(x, 'tensor.bfloat16.BE.BOM.pt')','line_number':3268,'multiline':False]
['text':'','line_number':3269,'multiline':False]
['text':' print(x)','line_number':3270,'multiline':False]
['text':'','line_number':3271,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':3272,'multiline':False]
['text':'','line_number':3273,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':3274,'multiline':False]
['text':' data = file.read()','line_number':3275,'multiline':False]
['text':' file.close()','line_number':3276,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':3277,'multiline':False]
['text':'','line_number':3278,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':3279,'multiline':False]
['text':'','line_number':3280,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':3452,'multiline':False]
['text':'','line_number':3453,'multiline':False]
['text':' import torch','line_number':3454,'multiline':False]
['text':'','line_number':3455,'multiline':False]
['text':' x = torch.randn(2,2, dtype=torch.cdouble)','line_number':3456,'multiline':False]
['text':'','line_number':3457,'multiline':False]
['text':' torch.save(x, "tensor.cdouble.LE.pt", _disable_byteorder_record=True)','line_number':3458,'multiline':False]
['text':' torch.save(x, "tensor.cdouble.LE.BOM.pt")','line_number':3459,'multiline':False]
['text':'','line_number':3460,'multiline':False]
['text':' print(x)','line_number':3461,'multiline':False]
['text':'','line_number':3462,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':3463,'multiline':False]
['text':'','line_number':3464,'multiline':False]
['text':' import torch','line_number':3465,'multiline':False]
['text':'','line_number':3466,'multiline':False]
['text':' x = torch.load('tensor.cdouble.LE.BOM.pt')','line_number':3467,'multiline':False]
['text':'','line_number':3468,'multiline':False]
['text':' torch.save(x, 'tensor.cdouble.BE.pt', _disable_byteorder_record=True)','line_number':3469,'multiline':False]
['text':' torch.save(x, 'tensor.cdouble.BE.BOM.pt')','line_number':3470,'multiline':False]
['text':'','line_number':3471,'multiline':False]
['text':' print(x)','line_number':3472,'multiline':False]
['text':'','line_number':3473,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':3474,'multiline':False]
['text':'','line_number':3475,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':3476,'multiline':False]
['text':' data = file.read()','line_number':3477,'multiline':False]
['text':' file.close()','line_number':3478,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':3479,'multiline':False]
['text':'','line_number':3480,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':3481,'multiline':False]
['text':'','line_number':3482,'multiline':False]
['text':' 1. Generated on LE system using following commands:','line_number':3661,'multiline':False]
['text':'','line_number':3662,'multiline':False]
['text':' import torch','line_number':3663,'multiline':False]
['text':'','line_number':3664,'multiline':False]
['text':' x = torch.randn(2,2, dtype=torch.cfloat)','line_number':3665,'multiline':False]
['text':'','line_number':3666,'multiline':False]
['text':' torch.save(x, "tensor.cfloat.LE.pt", _disable_byteorder_record=True)','line_number':3667,'multiline':False]
['text':' torch.save(x, "tensor.cfloat.LE.BOM.pt")','line_number':3668,'multiline':False]
['text':'','line_number':3669,'multiline':False]
['text':' print(x)','line_number':3670,'multiline':False]
['text':'','line_number':3671,'multiline':False]
['text':' 2. After that it is resaved on BE system with following commands:','line_number':3672,'multiline':False]
['text':'','line_number':3673,'multiline':False]
['text':' import torch','line_number':3674,'multiline':False]
['text':'','line_number':3675,'multiline':False]
['text':' x = torch.load('tensor.cfloat.LE.BOM.pt')','line_number':3676,'multiline':False]
['text':'','line_number':3677,'multiline':False]
['text':' torch.save(x, 'tensor.cfloat.BE.pt', _disable_byteorder_record=True)','line_number':3678,'multiline':False]
['text':' torch.save(x, 'tensor.cfloat.BE.BOM.pt')','line_number':3679,'multiline':False]
['text':'','line_number':3680,'multiline':False]
['text':' print(x)','line_number':3681,'multiline':False]
['text':'','line_number':3682,'multiline':False]
['text':' Following commands and a bit of manual work were used to produce python bytes from resulting files:','line_number':3683,'multiline':False]
['text':'','line_number':3684,'multiline':False]
['text':' file = open('filename', 'rb')','line_number':3685,'multiline':False]
['text':' data = file.read()','line_number':3686,'multiline':False]
['text':' file.close()','line_number':3687,'multiline':False]
['text':' print("\n".join(textwrap.wrap(str(data), 80)))','line_number':3688,'multiline':False]
['text':'','line_number':3689,'multiline':False]
['text':' BOM in this context is used as Byte Order Mark.','line_number':3690,'multiline':False]
['text':'','line_number':3691,'multiline':False]
['text':' make sure mmap where tensors' location tags are not CPU does not crash','line_number':3938,'multiline':False]
['text':' zipfile will first be mmap-ed on CPU and storages are extracted using','line_number':3939,'multiline':False]
['text':' overall_storage[start_offset:end_offset] before running','line_number':3940,'multiline':False]
['text':' _{device}_deserialize, which moves the storage to device','line_number':3941,'multiline':False]
['text':' Check that views are actually views','line_number':3961,'multiline':False]
['text':' The wrapping tensor (TestSubclass) is just a meta tensor, so it','line_number':3977,'multiline':False]
['text':' doesn't hold any memory (meta tensor is generally the preferred type','line_number':3978,'multiline':False]
['text':' of tensor you want to make a subclass from)...','line_number':3979,'multiline':False]
['text':' ...the real tensor is held as an element on the tensor.','line_number':3981,'multiline':False]
['text':' The wrapping tensor (TestSubclass) is just a meta tensor, so it','line_number':3995,'multiline':False]
['text':' doesn't hold any memory (meta tensor is generally the preferred type','line_number':3996,'multiline':False]
['text':' of tensor you want to make a subclass from)...','line_number':3997,'multiline':False]
['text':' ...the real tensor is held as an element on the tensor.','line_number':3999,'multiline':False]
['text':' Ensures it runs fine','line_number':4077,'multiline':False]
['text':' Ensures it runs fine','line_number':4086,'multiline':False]
['text':' Note that tensor.data_ptr() == 0 here','line_number':4087,'multiline':False]
