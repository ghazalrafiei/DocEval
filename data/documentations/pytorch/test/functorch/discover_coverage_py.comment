['text':' Importing these files make modifications to the op_db that we need','line_number':12,'multiline':False]
['text':' noqa: F401','line_number':13,'multiline':False]
['text':' noqa: F401','line_number':14,'multiline':False]
['text':' torch.abs, Tensor.abs, Tensor.abs_ are all considered to be different','line_number':27,'multiline':False]
['text':' APIs eitehr begin with 4 spaces or ".. autofunction::"','line_number':36,'multiline':False]
['text':' filter out in-place','line_number':93,'multiline':False]
['text':' Deduplicates torch.abs and Tensor.abs','line_number':100,'multiline':False]
['text':' NB: there are no dunder methods bcs we don't document those','line_number':119,'multiline':False]
['text':' quantization','line_number':129,'multiline':False]
['text':' is_cpu, etc. It doesn't make sense to have OpInfos for these','line_number':133,'multiline':False]
['text':' e.g. nn.functional.softmax','line_number':141,'multiline':False]
['text':' Maps function -> [OpInfo]','line_number':153,'multiline':False]
['text':' These are either not real "operators", factory functions','line_number':187,'multiline':False]
['text':' that trivially work, or not-documented ops.','line_number':188,'multiline':False]
['text':' is namespace','line_number':227,'multiline':False]
['text':' Now, sort by priority','line_number':237,'multiline':False]
['text':' Ignore this, this is heavily inflated','line_number':248,'multiline':False]
['text':' get all operators that are not in the denylist','line_number':255,'multiline':False]
['text':' get subset of all operators','line_number':259,'multiline':False]
['text':' Assume the rest are skips','line_number':316,'multiline':False]
['text':' Removes "torch."','line_number':354,'multiline':False]
['text':' print("List of OpInfos we need:")','line_number':409,'multiline':False]
['text':' for key in untested_overridable_outplace_ops.keys():','line_number':410,'multiline':False]
['text':'     print(key)','line_number':411,'multiline':False]
['text':' print("-" * 80)','line_number':412,'multiline':False]
['text':' print("")','line_number':413,'multiline':False]
['text':' - number that support autograd','line_number':449,'multiline':False]
['text':' - number that support forward_ad (in pytorch core)','line_number':450,'multiline':False]
['text':' - number that support functorch.jvp','line_number':451,'multiline':False]
['text':' result = get_skipped_or_xfailed_ops_for('test_vmap_exhaustive')','line_number':483,'multiline':False]
['text':' result = get_skipped_or_xfailed_ops_for('test_op_has_batch_rule')','line_number':484,'multiline':False]
['text':' result = get_skipped_or_xfailed_ops_for('test_vjp')','line_number':485,'multiline':False]
['text':' result = get_skipped_or_xfailed_ops_for('test_vmapvjp')','line_number':486,'multiline':False]
['text':' result = get_skipped_or_xfailed_ops_for('test_vmapvjp_has_batch_rule')','line_number':487,'multiline':False]
['text':' import pdb; pdb.set_trace()','line_number':488,'multiline':False]
['text':' for op in method_only_ops:','line_number':495,'multiline':False]
['text':'     print(f'    {op},')','line_number':496,'multiline':False]
['text':' print("top ops not covered by opinfo: ")','line_number':503,'multiline':False]
['text':' top_ops_not_covered_by_opinfo = get_top_ops_not_covered_by_opinfo(200, 50)','line_number':504,'multiline':False]
['text':' for op in top_ops_not_covered_by_opinfo:','line_number':505,'multiline':False]
['text':'     print(f'{op}, {top_ops.usage_count[op]}')','line_number':506,'multiline':False]
['text':' print("top ops not covered by opinfo: ")','line_number':508,'multiline':False]
['text':' top_ops_not_covered_by_opinfo = get_top_ops_not_covered_by_opinfo(220, 92)','line_number':509,'multiline':False]
['text':' for op in top_ops_not_covered_by_opinfo:','line_number':510,'multiline':False]
['text':'    print(f'{op}, {top_ops.usage_count[op]}')','line_number':511,'multiline':False]
['text':' print("top ops not covered by opinfo: ")','line_number':513,'multiline':False]
['text':' top_ops_not_covered_by_opinfo = get_top_ops_not_covered_by_opinfo(999, 999)','line_number':514,'multiline':False]
['text':' for op in top_ops_not_covered_by_opinfo:','line_number':515,'multiline':False]
['text':'     print(f'{op}, {top_ops.usage_count[op]}')','line_number':516,'multiline':False]
['text':' testing problems','line_number':531,'multiline':False]
['text':' randomness','line_number':533,'multiline':False]
['text':' Allowed exemptions','line_number':536,'multiline':False]
['text':' randomness','line_number':538,'multiline':False]
['text':' randomness','line_number':539,'multiline':False]
['text':' number output','line_number':540,'multiline':False]
['text':' dynamic','line_number':541,'multiline':False]
['text':' dynamic','line_number':542,'multiline':False]
['text':' dynamic','line_number':543,'multiline':False]
['text':' dynamic (backward)','line_number':544,'multiline':False]
['text':' norm with nuc is not commonly used; we support the other cases.','line_number':545,'multiline':False]
['text':' There isn't a bug, it is just nondeterministic so we can't test it.','line_number':546,'multiline':False]
['text':' We support everything except the sparse option.','line_number':547,'multiline':False]
['text':' We don't care about these yet','line_number':564,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':599,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':600,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':601,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':602,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':603,'multiline':False]
['text':' randomness','line_number':607,'multiline':False]
['text':' randomness','line_number':608,'multiline':False]
['text':' number output','line_number':609,'multiline':False]
['text':' dynamic','line_number':610,'multiline':False]
['text':' dynamic','line_number':611,'multiline':False]
['text':' dynamic','line_number':612,'multiline':False]
['text':' dynamic (backward)','line_number':613,'multiline':False]
['text':' norm with nuc is not commonly used; we support the other cases.','line_number':614,'multiline':False]
['text':' There isn't a bug, it is just nondeterministic so we can't test it.','line_number':615,'multiline':False]
['text':' We support everything except the sparse option.','line_number':616,'multiline':False]
['text':' randomness','line_number':617,'multiline':False]
['text':' randomness','line_number':618,'multiline':False]
['text':' randomness','line_number':619,'multiline':False]
['text':' randomness','line_number':620,'multiline':False]
['text':' randomness','line_number':621,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':625,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':626,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':627,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':628,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':629,'multiline':False]
['text':' we have support (see OpInfo), testing artifact','line_number':723,'multiline':False]
['text':' exception: we dont even support double backward for this','line_number':726,'multiline':False]
['text':' this isn't differentiable','line_number':728,'multiline':False]
['text':' not differentiable','line_number':729,'multiline':False]
['text':' dynamic (backward)','line_number':739,'multiline':False]
['text':' testing problem','line_number':740,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':741,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':742,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':743,'multiline':False]
['text':' not actually problem, randomness testing artifact','line_number':744,'multiline':False]
['text':' Not a problem.','line_number':745,'multiline':False]
['text':' It's just that the max_norm testing mutates inputs...','line_number':746,'multiline':False]
['text':' (we have our own functorch variant of the OpInfo without max_norm)','line_number':747,'multiline':False]
['text':' sanity checks','line_number':843,'multiline':False]
['text':' pprint.pprint(result)','line_number':845,'multiline':False]
['text':' result = opset.query(Operator.supports_vmapjvp, (Support.NO, Support.UNKNOWN))','line_number':850,'multiline':False]
['text':' pprint.pprint(result)','line_number':851,'multiline':False]
['text':' result = opset.query(Operator.supports_jvp, (Support.NO, Support.UNKNOWN))','line_number':852,'multiline':False]
['text':' pprint.pprint(result)','line_number':853,'multiline':False]
['text':' kresult = opset.query(Operator.supports_jvpvjp, (Support.NO, Support.UNKNOWN))','line_number':854,'multiline':False]
['text':' kpprint.pprint(result)','line_number':855,'multiline':False]
['text':' result = opset.query(Operator.supports_vmapjvp, (Support.NO, Support.UNKNOWN))','line_number':856,'multiline':False]
['text':' pprint.pprint(result)','line_number':857,'multiline':False]
['text':' result = opset.query(Operator.supports_fast_vmapjvp, (Support.NO, Support.UNKNOWN))','line_number':858,'multiline':False]
['text':' pprint.pprint(result)','line_number':859,'multiline':False]
['text':' pprint.pprint(result)','line_number':860,'multiline':False]
['text':' result = opset.query(Operator.supports_vmap, (Support.NO, Support.UNKNOWN))','line_number':866,'multiline':False]
['text':' pprint.pprint(result)','line_number':867,'multiline':False]
['text':' result = opset.query(Operator.supports_jvpvjp, (Support.NO, Support.UNKNOWN))','line_number':868,'multiline':False]
['text':' pprint.pprint(result)','line_number':869,'multiline':False]
['text':' result = opset.query(Operator.supports_fast_vmapjvp, (Support.NO, Support.UNKNOWN))','line_number':882,'multiline':False]
['text':' pprint.pprint(result)','line_number':883,'multiline':False]
['text':' pprint.pprint(result)','line_number':884,'multiline':False]
['text':' print("=" * 30 + " Top 160 Summary " + "=" * 30)','line_number':887,'multiline':False]
['text':' opset = OperatorSet.from_top160()','line_number':888,'multiline':False]
['text':' result = opset.query(Operator.supports_jvpvjp, (Support.NO, Support.UNKNOWN))','line_number':889,'multiline':False]
['text':' pprint.pprint(result)','line_number':890,'multiline':False]
['text':' print(opset.summary())','line_number':891,'multiline':False]
['text':' Print list of everything in order','line_number':893,'multiline':False]
['text':' all_ops = get_top_ops(999999, 999999, with_counts=True)','line_number':894,'multiline':False]
['text':' for op, count in all_ops:','line_number':895,'multiline':False]
['text':'     print(f'{op}, {count}')','line_number':896,'multiline':False]
