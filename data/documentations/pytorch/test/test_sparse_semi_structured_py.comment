['text':' Owner(s): ["module: sparse"]','line_number':1,'multiline':False]
['text':' check if cslt is available for now using this:','line_number':45,'multiline':False]
['text':' TODO when we add cusparselt as a backend, we can update this to be use torch.cusparselt.is_available()','line_number':46,'multiline':False]
['text':' To prevent zeros except where mask applied.','line_number':84,'multiline':False]
['text':' To prevent zeros except where mask below applied.','line_number':114,'multiline':False]
['text':' set masked weight','line_number':156,'multiline':False]
['text':' test that sparse_compile_result and dense_result are numerically close','line_number':166,'multiline':False]
['text':' assert sparse and sparse_compile have the same strides,','line_number':168,'multiline':False]
['text':' as meta registrations may return contiguous tensors when the output is transposed','line_number':169,'multiline':False]
['text':' https://github.com/pytorch/pytorch/pull/114477','line_number':170,'multiline':False]
['text':' for cuSPARSELt v0.4.0 there is a bug where although there are 5 alg_ids, we run into an error','line_number':265,'multiline':False]
['text':' when setting using the last one (4)','line_number':266,'multiline':False]
['text':' in cuSPARSELt v0.5.0 there are only 4 alg_ids total, so we should remove the +1 here when we update.','line_number':267,'multiline':False]
['text':' Currently we don't support int matmul on GPU, so evaluate on CPU and copy over','line_number':307,'multiline':False]
['text':' This should fail','line_number':309,'multiline':False]
['text':' Currently we don't support int matmul on GPU, so evaluate on CPU and copy over','line_number':337,'multiline':False]
['text':' padding with int8 throws an error because transposing B yields a contiguous output','line_number':339,'multiline':False]
['text':' and row-row 2:4 sparse @ dense with NN is not supported by cuSPARSELt or CUTLASS.','line_number':340,'multiline':False]
['text':' test transpose','line_number':349,'multiline':False]
['text':' NOTE: CUTLASS and cuSPARSELt have slightly different int8 behavior.','line_number':350,'multiline':False]
['text':' CUTLASS will output to an int32 tensor while cuSPARSELt will output to a int8 tensor','line_number':351,'multiline':False]
['text':' test transpose','line_number':356,'multiline':False]
['text':' Currently we don't support int matmul on GPU, so evaluate on CPU and copy over','line_number':393,'multiline':False]
['text':' set masked weight','line_number':434,'multiline':False]
['text':' set masked weight','line_number':468,'multiline':False]
['text':' SiLU not supported for integer inputs','line_number':563,'multiline':False]
['text':' The torch.ops.aten._to_sparse_semi_structured operator','line_number':582,'multiline':False]
['text':' uses CUTLASS to perform conversion from given dense','line_number':583,'multiline':False]
['text':' matrix to the pair of corresponding sparse and metadata','line_number':584,'multiline':False]
['text':' matrices, with the later used here as a reference to','line_number':585,'multiline':False]
['text':' compare the metadata matrix produced by conversion','line_number':586,'multiline':False]
['text':' performed by SparseSemiStructuredTensor class','line_number':587,'multiline':False]
['text':' constructor against.','line_number':588,'multiline':False]
