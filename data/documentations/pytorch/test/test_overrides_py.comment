['text':' Owner(s): ["module: __torch_function__"]','line_number':1,'multiline':False]
['text':' The functions below simulate the pure-python torch functions in the','line_number':30,'multiline':False]
['text':' torch.functional namespace. We use examples local to this file rather','line_number':31,'multiline':False]
['text':' than any of the real examples implemented in Python since in the','line_number':32,'multiline':False]
['text':' future those examples might get reimplemented in C++ for speed. This','line_number':33,'multiline':False]
['text':' fake torch function allows us to verify that the dispatch rules work','line_number':34,'multiline':False]
['text':' the same for a torch function implemented in C++ or Python.','line_number':35,'multiline':False]
['text':' HANDLED_FUNCTIONS_DIAGONAL is a dispatch table that','line_number':63,'multiline':False]
['text':' DiagonalTensor.__torch_function__ uses to determine which override','line_number':64,'multiline':False]
['text':' function to call for a given torch API function.  The keys of the','line_number':65,'multiline':False]
['text':' dictionary are function names in the torch API and the values are','line_number':66,'multiline':False]
['text':' function implementations. Implementations are added to','line_number':67,'multiline':False]
['text':' HANDLED_FUNCTION_DIAGONAL by decorating a python function with','line_number':68,'multiline':False]
['text':' implements_diagonal. See the overrides immediately below the defintion','line_number':69,'multiline':False]
['text':' of DiagonalTensor for usage examples.','line_number':70,'multiline':False]
['text':' This is defined as a class attribute so that SubDiagonalTensor','line_number':124,'multiline':False]
['text':' below which subclasses DiagonalTensor can re-use DiagonalTensor's','line_number':125,'multiline':False]
['text':' __torch_function__ implementation.','line_number':126,'multiline':False]
['text':' The dispatch table for SubTensor's __torch_function__ implementation.','line_number':187,'multiline':False]
['text':' The dispatch table for SubDiagonalTensor's __torch_function__ implementation.','line_number':252,'multiline':False]
['text':' The dispatch table for SubDiagonalTensor's __torch_function__ implementation.','line_number':299,'multiline':False]
['text':' Note: _triggered wrapper','line_number':303,'multiline':False]
['text':' Dict that wraps the implementations from get_testing_overrides into another','line_number':304,'multiline':False]
['text':' function with a _triggered slot/flag. The triggered flag is set when the','line_number':305,'multiline':False]
['text':' implementation is called.','line_number':306,'multiline':False]
['text':' test/test_cpp_api_parity.py monkeypatches torch.nn to have a new','line_number':331,'multiline':False]
['text':' function sample_functional.  Depending on what order you run pytest','line_number':332,'multiline':False]
['text':' collection, this may trigger the error here.  This is a hack to fix','line_number':333,'multiline':False]
['text':' the problem.  A more proper fix is to make the "not tested" check','line_number':334,'multiline':False]
['text':' a test on its own, and to make sure the monkeypatch is only installed','line_number':335,'multiline':False]
['text':' for the span of the relevant test (and deleted afterwards)','line_number':336,'multiline':False]
['text':' decorate the overrides with implements_tensor_like if it's not a','line_number':351,'multiline':False]
['text':' torch.Tensor method','line_number':352,'multiline':False]
['text':' See note: "_triggered wrapper"','line_number':354,'multiline':False]
['text':' In this case _torch_function_ should override TensorLike objects','line_number':376,'multiline':False]
['text':' only DiagonalTensor so should always get DiagonalTensor result','line_number':402,'multiline':False]
['text':' tensor and DiagonalTensor, always return DiagonalTensor result','line_number':404,'multiline':False]
['text':' only SubTensor so should always get SubTensor result','line_number':407,'multiline':False]
['text':' tensor and SubTensor so should always get SubTensor result','line_number':409,'multiline':False]
['text':' DiagonalTensor and SubTensor are unrelated classes so the result','line_number':412,'multiline':False]
['text':' depends on which argument appears first','line_number':413,'multiline':False]
['text':' SubDiagonalTensor should take precedence over DiagonalTensor','line_number':416,'multiline':False]
['text':' but should behave otherwise the same as DiagonalTensor','line_number':417,'multiline':False]
['text':' DiagonalTensor has a valid override and SubDiagonal has an','line_number':444,'multiline':False]
['text':' override that returns NotImplemented so we should call the','line_number':445,'multiline':False]
['text':' DiagonalTensor implementation, returning -1','line_number':446,'multiline':False]
['text':' SubTensor has an implementation that returns NotImplemented as','line_number':454,'multiline':False]
['text':' well so it should behave exactly like SubDiagonalTensor in the','line_number':455,'multiline':False]
['text':' test above','line_number':456,'multiline':False]
['text':' div between SubTensor and SubDiagonalTensor should raise','line_number':463,'multiline':False]
['text':' TypeError since both have an implementation that','line_number':464,'multiline':False]
['text':' explicitly returns NotImplemented','line_number':465,'multiline':False]
['text':' none of DiagonalTensor, SubdiagonalTensor, or SubTensor have a','line_number':475,'multiline':False]
['text':' mul or a baz implementation so all ops should raise TypeError','line_number':476,'multiline':False]
['text':' Check that leaf subclass is kept regardless of order','line_number':538,'multiline':False]
['text':' Check indexing subclass is kept','line_number':543,'multiline':False]
['text':' Check case for subclass of subclass.','line_number':546,'multiline':False]
['text':' Make sure unrelated class trees are not merged.','line_number':555,'multiline':False]
['text':' https://github.com/szagoruyko/pytorchviz/issues/65','line_number':562,'multiline':False]
['text':' Previously, Tensor-like objects that did not subclass from Tensor','line_number':572,'multiline':False]
['text':' did not get wrapped into unary tuples before being passed into','line_number':573,'multiline':False]
['text':' handle_torch_function, in contradiction with how Tensor-likes','line_number':574,'multiline':False]
['text':' were handled','line_number':575,'multiline':False]
['text':'','line_number':576,'multiline':False]
['text':' NB: this asserts that the arguments get normalized into a tuple','line_number':577,'multiline':False]
['text':' before entering the torch function handler; it could go the','line_number':578,'multiline':False]
['text':' other way but beware https://github.com/pytorch/pytorch/issues/76037','line_number':579,'multiline':False]
['text':' If func corresponds to a torch.Tensor method or property.','line_number':612,'multiline':False]
['text':' Generate an instance by using SubTensor,','line_number':614,'multiline':False]
['text':' Otherwise, TensorLike.','line_number':618,'multiline':False]
['text':' FIXME The following code does not support kwonly args without defaults.','line_number':622,'multiline':False]
['text':' The fix is easy, as one just needs to save these args when generating the variable','line_number':623,'multiline':False]
['text':' annotated_args. The problem is that, if one does so, one finds a number','line_number':624,'multiline':False]
['text':' of functions that have problematic signatures in native_functions.yaml.','line_number':625,'multiline':False]
['text':' Fixing these would be BC breaking, so hence this terrible hack','line_number':626,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/67008','line_number':627,'multiline':False]
['text':' Guess valid input to aten function based on type of argument','line_number':636,'multiline':False]
['text':' TODO: generate actual SymbolicInt','line_number':670,'multiline':False]
['text':' Guess valid input to aten function based on type of argument','line_number':679,'multiline':False]
['text':' See "Note: properties and __get__"','line_number':684,'multiline':False]
['text':' Remove annotations from argspec','line_number':696,'multiline':False]
['text':' ret is None for certain protocols, e.g., `__weakref__` and `__setitem__`','line_number':713,'multiline':False]
['text':' This is currently the best check but doesn't work for, for example,','line_number':714,'multiline':False]
['text':' Tensor.__add__ because it redirects to Tensor.add.','line_number':715,'multiline':False]
['text':' See note "_triggered wrapper"','line_number':716,'multiline':False]
['text':' Note: properties and __get__','line_number':728,'multiline':False]
['text':' __get__ is part of the descriptor protocol.','line_number':729,'multiline':False]
['text':' https://docs.python.org/3/howto/descriptor.html','line_number':730,'multiline':False]
['text':' This is used for properties of the form','line_number':731,'multiline':False]
['text':' torch.Tensor.<property>, with the method __get__','line_number':732,'multiline':False]
['text':' In this case we get the property name in two ways:','line_number':733,'multiline':False]
['text':' This case for properties defined in C.','line_number':735,'multiline':False]
['text':' This one for properties defined in Python.','line_number':742,'multiline':False]
['text':' Unfortunately I couldn't find a way to unify these two cases','line_number':746,'multiline':False]
['text':' and there is no way for general descriptors.','line_number':747,'multiline':False]
['text':' If it's a method','line_number':775,'multiline':False]
['text':' Don't append self to args if classmethod/staticmethod','line_number':778,'multiline':False]
['text':' Otherwise append self to args','line_number':781,'multiline':False]
['text':' Find an instance of this class in the arguments','line_number':803,'multiline':False]
['text':' unwrap inputs if necessary','line_number':861,'multiline':False]
['text':' wrap inputs if necessary','line_number':868,'multiline':False]
['text':' in the old einsum interface, `operands` is a list','line_number':883,'multiline':False]
['text':' These attributes (and the functions below) may change','line_number':908,'multiline':False]
['text':' if the gradcheck implementation changes. It's best to','line_number':909,'multiline':False]
['text':' aim for attributes that may be commonly present on other','line_number':910,'multiline':False]
['text':' Tensor-likes.','line_number':911,'multiline':False]
['text':' Regression test for gh-54457','line_number':1079,'multiline':False]
['text':' Regression test for gh-55868','line_number':1089,'multiline':False]
['text':' Regression test for gh-64687','line_number':1097,'multiline':False]
['text':' Function that handles torch_function on the python side','line_number':1135,'multiline':False]
['text':' Function that handles torch_function in C++','line_number':1139,'multiline':False]
['text':' NB: factory functions get overridden too!','line_number':1156,'multiline':False]
['text':' python side','line_number':1161,'multiline':False]
['text':' add hits the torch function again!','line_number':1368,'multiline':False]
['text':' This failed because the parser thinks the function is called to()','line_number':1372,'multiline':False]
['text':' but it's actually called _parse_to()','line_number':1373,'multiline':False]
['text':' This failed because improper use of has_torch_function when','line_number':1391,'multiline':False]
['text':' is_tensor_like should have been used instead, inside the','line_number':1392,'multiline':False]
['text':' broadcasting logic called by distributions (Bernoulli doesn't','line_number':1393,'multiline':False]
['text':' matter per se)','line_number':1394,'multiline':False]
['text':' Default tensor subclass implementation disables torch function;','line_number':1412,'multiline':False]
['text':' when we redispatch to mode we must not treat the objects as','line_number':1413,'multiline':False]
['text':' eligible','line_number':1414,'multiline':False]
['text':' The first time we call, the mode sees an active type that','line_number':1424,'multiline':False]
['text':' it doesn't know how to deal with.  The second time, we're','line_number':1425,'multiline':False]
['text':' instructed to treat it "as if it were a tensor", and so','line_number':1426,'multiline':False]
['text':' we keep going.  I'm not entirely clear if the subclasses','line_number':1427,'multiline':False]
['text':' disappearing from types is the correct way to do it.','line_number':1428,'multiline':False]
['text':' If the hash function was returning the same value, this would','line_number':1531,'multiline':False]
['text':' fail inside `Tensor.__eq__`.','line_number':1532,'multiline':False]
['text':' If __hash__ was going through torch_function, the implementation above would','line_number':1533,'multiline':False]
['text':' be wrong as it would compute the hash on a temporary Tensor thus not ensuring','line_number':1534,'multiline':False]
['text':' the uniqueness of the hash that we rely on for Tensors.','line_number':1535,'multiline':False]
