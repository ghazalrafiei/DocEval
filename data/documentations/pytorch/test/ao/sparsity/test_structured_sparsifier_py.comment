['text':' Owner(s): ["module: unknown"]','line_number':1,'multiline':False]
['text':' make sure both models run','line_number':135,'multiline':False]
['text':' make sure lowest saliency rows are pruned','line_number':139,'multiline':False]
['text':' Check mask exists','line_number':168,'multiline':False]
['text':' Check parametrization exists and is correct','line_number':170,'multiline':False]
['text':' Assume that this is the 1st/only parametrization','line_number':173,'multiline':False]
['text':' Can instantiate the model with configs','line_number':221,'multiline':False]
['text':' without and with bias','line_number':249,'multiline':False]
['text':' Pruning step','line_number':363,'multiline':False]
['text':' linear(bias) -> linear(no bias)','line_number':415,'multiline':False]
['text':' linear(bias) -> linear(bias)','line_number':425,'multiline':False]
['text':' linear(no bias) -> linear(bias)','line_number':434,'multiline':False]
['text':' test version with nn.Modules','line_number':466,'multiline':False]
['text':' test functional version','line_number':474,'multiline':False]
['text':' Fusion step','line_number':500,'multiline':False]
['text':' TODO This rtol is a little high, need to double check if something specific is causing this to fail','line_number':508,'multiline':False]
['text':' only time this should be equal is when all layers have padding and we can't prune','line_number':515,'multiline':False]
['text':' all within sequential blocks','line_number':520,'multiline':False]
['text':' prune across sequential blocks','line_number':527,'multiline':False]
['text':' Conv2d with Bias and no Activation','line_number':551,'multiline':False]
['text':' conv2d(bias) -> conv2d(bias)','line_number':553,'multiline':False]
['text':' conv2d(no bias) -> conv2d(bias)','line_number':562,'multiline':False]
['text':' conv2d(bias) -> conv2d(no bias)','line_number':572,'multiline':False]
['text':' Conv2d with Activation and no Bias','line_number':596,'multiline':False]
['text':' conv2d(no bias) -> activation -> conv2d(no bias)','line_number':599,'multiline':False]
['text':' conv2d(bias) -> activation -> conv2d(bias)','line_number':607,'multiline':False]
['text':' conv2d(bias) -> activation -> conv2d(no bias)','line_number':616,'multiline':False]
['text':' conv2d(no bias) -> activation -> conv2d(bias)','line_number':625,'multiline':False]
['text':' Conv2d with Padded layers after Bias layers','line_number':647,'multiline':False]
['text':' conv(padded, bias) -> conv(padded, bias)','line_number':650,'multiline':False]
['text':' conv(no bias, no pad) -> conv(padded, bias)','line_number':658,'multiline':False]
['text':' conv(padded, bias) -> conv ( no bias ,no pad)','line_number':666,'multiline':False]
['text':' conv(pad, bias) -> conv(no pad, bias)','line_number':673,'multiline':False]
['text':' conv(no pad, bias) -> conv(pad, bias)','line_number':680,'multiline':False]
['text':' Conv2d with Pooling layers','line_number':702,'multiline':False]
['text':' We cannot compare y_expected == y_pruned, as the 0 elements mess up the numerics','line_number':789,'multiline':False]
['text':' Instead we check that the weights of the new LSTM are a subset of the weights of','line_number':790,'multiline':False]
['text':' the old LSTM','line_number':791,'multiline':False]
['text':' assert we haven't deleted any keys','line_number':795,'multiline':False]
['text':' We cannot check that y_expected == y_pruned as usual because','line_number':827,'multiline':False]
['text':' zeros vs. missing elements yield different numerical results.','line_number':828,'multiline':False]
['text':' Instead that we check that the pruned elements are the first half of the results','line_number':829,'multiline':False]
['text':' since we are using a BottomHalfLSTMPruner','line_number':830,'multiline':False]
['text':' also check that output of linear is the same shape, this means we've resized','line_number':834,'multiline':False]
['text':' linear columns correctly.','line_number':835,'multiline':False]
['text':' We cannot compare y_expected == y_pruned, as the 0 elements mess up the numerics','line_number':872,'multiline':False]
['text':' Instead we check that the weights of the new LSTM are a subset of the weights of','line_number':873,'multiline':False]
['text':' the old LSTM','line_number':874,'multiline':False]
['text':' assert we haven't deleted any keys','line_number':878,'multiline':False]
['text':' We cannot check that y_expected == y_pruned as usual because','line_number':910,'multiline':False]
['text':' zeros vs. missing elements yield different numerical results.','line_number':911,'multiline':False]
['text':' Instead that we check that the pruned elements are the first half of the results','line_number':912,'multiline':False]
['text':' since we are using a BottomHalfLSTMPruner','line_number':913,'multiline':False]
['text':' also check that output of linear is the same shape, this means we've resized','line_number':917,'multiline':False]
['text':' linear columns correctly.','line_number':918,'multiline':False]
['text':' Manually set the filter weights for demonstration purposes','line_number':930,'multiline':False]
['text':' Weight weights for each filter','line_number':936,'multiline':False]
['text':' broadcasting','line_number':937,'multiline':False]
['text':' Second Convolutional Layer','line_number':940,'multiline':False]
['text':' compute the distance matrix using torch.cdist','line_number':957,'multiline':False]
['text':' test pruning with one layer of conv2d','line_number':978,'multiline':False]
['text':' fusion step','line_number':989,'multiline':False]
['text':' assert shapes','line_number':993,'multiline':False]
['text':' assert value','line_number':998,'multiline':False]
['text':' the second setting','line_number':1002,'multiline':False]
['text':' Get the masks for the two least-norm filters','line_number':1013,'multiline':False]
['text':' Check if either of the least-norm filters is not pruned','line_number':1016,'multiline':False]
['text':' fusion step','line_number':1019,'multiline':False]
['text':' assert shapes','line_number':1022,'multiline':False]
['text':' assert values','line_number':1028,'multiline':False]
