['text':' Owner(s): ["module: tests"]','line_number':1,'multiline':False]
['text':' TODO: replace with make_tensor','line_number':29,'multiline':False]
['text':' work around torch.randn not being implemented for bfloat16','line_number':35,'multiline':False]
['text':' Use extremal values','line_number':43,'multiline':False]
['text':' TODO: replace with make_tensor','line_number':59,'multiline':False]
['text':' Wrap negative dims','line_number':81,'multiline':False]
['text':'##########################################################################','line_number':96,'multiline':False]
['text':' ReductionOpInfo unit tests','line_number':97,'multiline':False]
['text':'##########################################################################','line_number':98,'multiline':False]
['text':' TODO(@heitorschueroff) combine cases with and without keepdim once','line_number':112,'multiline':False]
['text':' there's support for a @parametrize decorator.','line_number':113,'multiline':False]
['text':' TODO(@heitorschueroff) Update these to use the nan_policy kwarg once','line_number':227,'multiline':False]
['text':' it is added to reduction operators.','line_number':228,'multiline':False]
['text':' Reducing along empty slice should return identity','line_number':290,'multiline':False]
['text':' Reducing along empty slice should return NaN','line_number':294,'multiline':False]
['text':' Reducing along empty slice should raise an error','line_number':298,'multiline':False]
['text':' ref reductions throw RuntimeError for this','line_number':300,'multiline':False]
['text':' NumPy does not support BFloat16 so we don't test that against reference','line_number':358,'multiline':False]
['text':' implementations. We also don't compare dtypes or test for different','line_number':359,'multiline':False]
['text':' keepdim because we already have other tests covering those.','line_number':360,'multiline':False]
['text':' The test_reference_testing in test_ops.py only uses the samples from','line_number':361,'multiline':False]
['text':' sample_inputs_func which do not test as exhaustively as these tests.','line_number':362,'multiline':False]
['text':'##########################################################################','line_number':427,'multiline':False]
['text':' TODO: Legacy tests - port to ReductionOpInfo','line_number':428,'multiline':False]
['text':'##########################################################################','line_number':429,'multiline':False]
['text':' check that out is actually inplace','line_number':499,'multiline':False]
['text':' check integral inputs is promoted to floating point','line_number':505,'multiline':False]
['text':' logcumsumexp is a more precise way to compute than ``log(cumsum(exp(a)))``','line_number':515,'multiline':False]
['text':' and faster than ``[log(sum(exp(a[:i]))) for i in range(a.shape[0])]``','line_number':516,'multiline':False]
['text':' the for-loop above should produce similar precision as logcumsumexp (it's just slower),','line_number':517,'multiline':False]
['text':' so it can be used as the expected values to check our computation','line_number':518,'multiline':False]
['text':' using logsumexp from scipy because by the time of writing this test code,','line_number':520,'multiline':False]
['text':' torch.logsumexp has not been implemented for complex numbers','line_number':521,'multiline':False]
['text':' if the expected is not given, then revert to scipy's logsumexp','line_number':547,'multiline':False]
['text':' move the imaginary values to (0, 2 * pi)','line_number':553,'multiline':False]
['text':' zeroing the imaginary part of the element if the real part is -inf','line_number':557,'multiline':False]
['text':' as the imaginary part cannot be determined exactly and it does not','line_number':558,'multiline':False]
['text':' really matter if we take the exp of the output','line_number':559,'multiline':False]
['text':' randomly specified values','line_number':565,'multiline':False]
['text':' in this case, scipy.logsumexp should be enough','line_number':566,'multiline':False]
['text':' test with some non-normal values','line_number':570,'multiline':False]
['text':' handle special case involving infinites and nans','line_number':574,'multiline':False]
['text':' here we don't use scipy.logsumexp as it gives confusing answer on','line_number':575,'multiline':False]
['text':' some inf cases','line_number':576,'multiline':False]
['text':' see here:','line_number':577,'multiline':False]
['text':' scipy's logsumexp gives (inf + 0.7853982j) here, unclear why','line_number':595,'multiline':False]
['text':' the imaginary part thanks to some weird behaviour of log(inf + infj)','line_number':596,'multiline':False]
['text':' windows give strange results on the second-to-last results where it gives inf + pi/4 j','line_number':600,'multiline':False]
['text':' instead of inf + nan j','line_number':601,'multiline':False]
['text':' To use parallel branches we'll need to compare on tensors','line_number':624,'multiline':False]
['text':' that are relatively large. Even if this is run on a single','line_number':625,'multiline':False]
['text':' core machine these tests will still give you signal on','line_number':626,'multiline':False]
['text':' the correctness','line_number':627,'multiline':False]
['text':' 0s and 1s','line_number':631,'multiline':False]
['text':' Parallelisim is only used if numel is','line_number':633,'multiline':False]
['text':' larger than grainsize defined in Parallel.h','line_number':634,'multiline':False]
['text':' TODO: kill map2_ (and similar) uses and update to compare with NumPy','line_number':650,'multiline':False]
['text':' only works on CPU since this uses map2_, which is only supported on CPU','line_number':651,'multiline':False]
['text':' Two tensors','line_number':653,'multiline':False]
['text':' TODO: kill this ane replace with common creation ops','line_number':728,'multiline':False]
['text':' TODO: refactor this to use comparators from common_utils','line_number':780,'multiline':False]
['text':' TODO: update this and tests that use it to use the device argument properly','line_number':788,'multiline':False]
['text':' we have no control over NumPy warnings...','line_number':796,'multiline':False]
['text':' If the optional desired output type is given, the input','line_number':874,'multiline':False]
['text':' is internally cast.','line_number':875,'multiline':False]
['text':' TODO: update this and tests that use it to handle device properly','line_number':879,'multiline':False]
['text':' 'out' is favored over dtype, check error','line_number':892,'multiline':False]
['text':' test mixed int/float/complex','line_number':910,'multiline':False]
['text':' Pre-calculated results.','line_number':952,'multiline':False]
['text':' The indices are the position of the last appearance of the mode element.','line_number':954,'multiline':False]
['text':' Test use of result tensor','line_number':963,'multiline':False]
['text':' Test non-default dim','line_number':970,'multiline':False]
['text':' input unchanged','line_number':975,'multiline':False]
['text':' Set the value of each interval to the mode "v"','line_number':983,'multiline':False]
['text':' Check whether the returned indices correspond to the returned values','line_number':989,'multiline':False]
['text':' Check whether the returned values are the mode','line_number':991,'multiline':False]
['text':' i should be less than (d - 2) / 2','line_number':997,'multiline':False]
['text':' Mode only in the middle.','line_number':1000,'multiline':False]
['text':' Mode in discontiguous parts of the input.','line_number':1002,'multiline':False]
['text':' More than one line of (65535) thread blocks','line_number':1005,'multiline':False]
['text':' Max slice size (2048)','line_number':1008,'multiline':False]
['text':' Naive kernel for big slice sizes (> 2048)','line_number':1011,'multiline':False]
['text':' mode only supports CPU and CUDA device type','line_number':1040,'multiline':False]
['text':' CPU Input Tensor','line_number':1067,'multiline':False]
['text':' TODO: make work on CUDA, too','line_number':1080,'multiline':False]
['text':' TODO: this should be a generic opinfo test','line_number':1108,'multiline':False]
['text':' non contiguous','line_number':1146,'multiline':False]
['text':' indices','line_number':1156,'multiline':False]
['text':' nan','line_number':1171,'multiline':False]
['text':' TODO: bincount isn't a classic reduction -- maybe this test suite is','line_number':1231,'multiline':False]
['text':'   reductions and summary ops?','line_number':1232,'multiline':False]
['text':' negative input throws','line_number':1234,'multiline':False]
['text':' n-d input, with n > 1 throws','line_number':1237,'multiline':False]
['text':' floating input type throws','line_number':1240,'multiline':False]
['text':' minlength < 0 throws','line_number':1243,'multiline':False]
['text':' n-d weights, with n > 1 throws','line_number':1248,'multiline':False]
['text':' input and weights dim mismatch','line_number':1252,'multiline':False]
['text':' 1-d input with no elements and default minlength','line_number':1256,'multiline':False]
['text':' 1-d input with no elements and specified minlength','line_number':1259,'multiline':False]
['text':' test tensor method without weights','line_number':1263,'multiline':False]
['text':' test avoiding overflow for uint8 (#76979)','line_number':1269,'multiline':False]
['text':' test minlength functionality','line_number':1273,'multiline':False]
['text':' test weights','line_number':1279,'multiline':False]
['text':' test non-contiguous inputs and weights','line_number':1290,'multiline':False]
['text':' inputs are non-contiguous but weights are contiguous','line_number':1296,'multiline':False]
['text':' inputs and weights are non-contiguous','line_number':1298,'multiline':False]
['text':' weights are non-contiguous but inputs are contiguous','line_number':1302,'multiline':False]
['text':' test bincount on non-contiguous slices','line_number':1306,'multiline':False]
['text':' test large number of bins - global memory use','line_number':1313,'multiline':False]
['text':' test large input size','line_number':1319,'multiline':False]
['text':' TODO: how many var stability tests are there?','line_number':1325,'multiline':False]
['text':' Stability for inner dim','line_number':1329,'multiline':False]
['text':' General stability','line_number':1332,'multiline':False]
['text':' Stability for outer dimensions','line_number':1335,'multiline':False]
['text':' xc is a channels last tensor','line_number':1358,'multiline':False]
['text':' xc is not memory dense, but looks like channels last','line_number':1360,'multiline':False]
['text':' Check all combinations: fp16 input - fp16 output, fp16 input - fp32','line_number':1419,'multiline':False]
['text':' output, fp32 input - fp16 output, fp32 input - fp32 output','line_number':1420,'multiline':False]
['text':' TODO: consider refactoring with bincount test','line_number':1483,'multiline':False]
['text':' simple 1d boundary and 3d input value','line_number':1488,'multiline':False]
['text':' simple float 1d boundary and 1d input with output int32 type','line_number':1498,'multiline':False]
['text':' multiple dimension input with 0 elements','line_number':1506,'multiline':False]
['text':' nan input','line_number':1513,'multiline':False]
['text':' type promotion and non contiguous tensors','line_number':1522,'multiline':False]
['text':' All tensors in XLA is contiguous even doing permute, no warning msg will be generate in XLA','line_number':1531,'multiline':False]
['text':' scalar type','line_number':1534,'multiline':False]
['text':' invalid input dimensions','line_number':1544,'multiline':False]
['text':' incompatiable output tensor's dtype','line_number':1556,'multiline':False]
['text':' invalid side argument','line_number':1567,'multiline':False]
['text':' invalid sorter argument, wrong size','line_number':1571,'multiline':False]
['text':' invalid sorter argument, is not dtype long','line_number':1577,'multiline':False]
['text':' invalid sorter value, out of bound (>= innermost size)','line_number':1583,'multiline':False]
['text':' invalid sorter value, out of bound (< 0)','line_number':1587,'multiline':False]
['text':' scalar type bfloat16','line_number':1591,'multiline':False]
['text':' noncontiguous','line_number':1610,'multiline':False]
['text':' dim','line_number':1611,'multiline':False]
['text':' Randomly scale the values','line_number':1616,'multiline':False]
['text':' Test 0-d to 3-d tensors.','line_number':1636,'multiline':False]
['text':' Generate Input.','line_number':1642,'multiline':False]
['text':' Default `dims=None` case','line_number':1646,'multiline':False]
['text':' With `dims: tuple of ints` case','line_number':1650,'multiline':False]
['text':' On Windows CI, the current version of `numpy` promotes all lower integers','line_number':1669,'multiline':False]
['text':' dtypes to int32 while `torch` promotes them to int64. Hence we skip on checking','line_number':1670,'multiline':False]
['text':' the exact dtype.','line_number':1671,'multiline':False]
['text':' Reference : https://dr.pytorch.org/api/view-log-full?build_id=122051580','line_number':1672,'multiline':False]
['text':' PR : https://github.com/pytorch/pytorch/pull/38628#issuecomment-655905370','line_number':1673,'multiline':False]
['text':' TODO: Investigate why the output is not close to numpy.','line_number':1680,'multiline':False]
['text':' Default values','line_number':1688,'multiline':False]
['text':' Case: All Ones','line_number':1730,'multiline':False]
['text':' Case: With single `nan` present.','line_number':1735,'multiline':False]
['text':' Case: Randomly Generated Tensors','line_number':1741,'multiline':False]
['text':' Generate Input.','line_number':1746,'multiline':False]
['text':' Verify indices returned by max and min.','line_number':1768,'multiline':False]
['text':' Argmax','line_number':1777,'multiline':False]
['text':' Non-contiguous input','line_number':1781,'multiline':False]
['text':' Verify indices returned by max.','line_number':1784,'multiline':False]
['text':' Argmin','line_number':1789,'multiline':False]
['text':' Non-contiguous input','line_number':1793,'multiline':False]
['text':' Verify indices returned by min.','line_number':1796,'multiline':False]
['text':' Case: Sample from issue: https://github.com/pytorch/pytorch/issues/41998','line_number':1801,'multiline':False]
['text':' Case: Sample from issue: https://github.com/pytorch/pytorch/issues/41998','line_number':1807,'multiline':False]
['text':' Note [all, any uint8 compatibility]: However for compatibility reason,','line_number':1815,'multiline':False]
['text':' for `uint8`, they return Tensor of same dtype `uint8`.','line_number':1816,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/pull/47878#issuecomment-747108561','line_number':1817,'multiline':False]
['text':' This test will fail once the functions return bool output','line_number':1860,'multiline':False]
['text':' for uint8 input.','line_number':1861,'multiline':False]
['text':' TODO: part of this test covers torch.norm, with should be covered by test_linalg','line_number':1924,'multiline':False]
['text':' TODO: update this test to comapre against NumPy','line_number':1937,'multiline':False]
['text':' TODO: update this test to compare against NumPy','line_number':1953,'multiline':False]
['text':' Large, not-nice input','line_number':1956,'multiline':False]
['text':' TODO: update this to compare against NumPy instead of CPU','line_number':1962,'multiline':False]
['text':' TODO: update this to compare against NumPy instead of CPU','line_number':1972,'multiline':False]
['text':' TODO: make this test generic using OpInfos','line_number':1992,'multiline':False]
['text':' tests half to float promotion','line_number':2003,'multiline':False]
['text':' Assert for illegal dtype would not be raised on XLA','line_number':2009,'multiline':False]
['text':' This won't test for 256bit instructions, since we usually','line_number':2068,'multiline':False]
['text':' only work on 1 cacheline (512bit) at a time and these','line_number':2069,'multiline':False]
['text':' examples aren't big enough to trigger that.','line_number':2070,'multiline':False]
['text':' Mean not supported for Int types','line_number':2079,'multiline':False]
['text':' prod is not supported for float16 & bfloat16 on CPU','line_number':2098,'multiline':False]
['text':' TODO: torch.min does not support the same operation as argmin','line_number':2110,'multiline':False]
['text':' for the same case, should we enable it?','line_number':2111,'multiline':False]
['text':' test that non-contiguous tensors work','line_number':2134,'multiline':False]
['text':' test that non-contiguous tensors work','line_number':2165,'multiline':False]
['text':' general case','line_number':2193,'multiline':False]
['text':' check 1-d behavior','line_number':2198,'multiline':False]
['text':' check reducing of a singleton dimension','line_number':2204,'multiline':False]
['text':' check reducing with output kwargs','line_number':2211,'multiline':False]
['text':' Test reduction when there is a 32bit-indexing split','line_number':2233,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/37583','line_number':2234,'multiline':False]
['text':' 1D case: sum','line_number':2243,'multiline':False]
['text':' 1D case: argmax','line_number':2261,'multiline':False]
['text':' 2D case: sum','line_number':2278,'multiline':False]
['text':' 2D case: max/argmax','line_number':2295,'multiline':False]
['text':' 2D case: min/argmin','line_number':2316,'multiline':False]
['text':' vec 4','line_number':2351,'multiline':False]
['text':' vec 2','line_number':2353,'multiline':False]
['text':' vec 1','line_number':2357,'multiline':False]
['text':' Regression test for gh-32863','line_number':2364,'multiline':False]
['text':' See: https://github.com/pytorch/pytorch/issues/38922','line_number':2374,'multiline':False]
['text':' Generate random 0-3D sizes','line_number':2392,'multiline':False]
['text':' Create random input tensor','line_number':2395,'multiline':False]
['text':' We can only test agains numpy for odd reductions because numpy','line_number':2403,'multiline':False]
['text':' returns the mean of the two medians and torch returns the lower','line_number':2404,'multiline':False]
['text':' We can only test agains numpy for odd reductions because numpy','line_number':2414,'multiline':False]
['text':' returns the mean of the two medians and torch returns the lower','line_number':2415,'multiline':False]
['text':' Generate random 0-3D sizes','line_number':2421,'multiline':False]
['text':' Create random input tensor with nan values','line_number':2424,'multiline':False]
['text':' We can only test agains numpy for odd reductions because numpy','line_number':2438,'multiline':False]
['text':' returns the mean of the two medians and torch returns the lower','line_number':2439,'multiline':False]
['text':' We can only test agains numpy for odd reductions because numpy','line_number':2451,'multiline':False]
['text':' returns the mean of the two medians and torch returns the lower','line_number':2452,'multiline':False]
['text':' Indices are not deterministic here so can only check values','line_number':2483,'multiline':False]
['text':' Discontiguous and strided tensors','line_number':2489,'multiline':False]
['text':' Generate some random test cases','line_number':2510,'multiline':False]
['text':' Add corner cases','line_number':2516,'multiline':False]
['text':' Enumerate all input combinations','line_number':2522,'multiline':False]
['text':' Make some random elements NaN','line_number':2526,'multiline':False]
['text':' Compute quantile along every dimension and flattened tensor','line_number':2536,'multiline':False]
['text':' Test out variation','line_number':2545,'multiline':False]
['text':' dim','line_number':2715,'multiline':False]
['text':' correction','line_number':2717,'multiline':False]
['text':' keepdim','line_number':2719,'multiline':False]
['text':' Negative correction','line_number':2722,'multiline':False]
['text':' NumPy default is not compatible with torch.std (gh-50010)','line_number':2731,'multiline':False]
['text':' inf vs. nan results are sensitive to machine precision,','line_number':2737,'multiline':False]
['text':' just treat them as equivalent','line_number':2738,'multiline':False]
['text':' dim','line_number':2749,'multiline':False]
['text':' correction','line_number':2751,'multiline':False]
['text':' keepdim','line_number':2753,'multiline':False]
['text':' Negative correction','line_number':2756,'multiline':False]
['text':' NumPy default is incompatible with torch.std (gh-50010)','line_number':2765,'multiline':False]
['text':' inf vs. nan results are sensitive to machine precision,','line_number':2771,'multiline':False]
['text':' just treat them as equivalent','line_number':2772,'multiline':False]
['text':' dim','line_number':2783,'multiline':False]
['text':' correction','line_number':2785,'multiline':False]
['text':' keepdim','line_number':2787,'multiline':False]
['text':' Negative correction','line_number':2790,'multiline':False]
['text':' dim','line_number':2814,'multiline':False]
['text':' correction','line_number':2816,'multiline':False]
['text':' keepdim','line_number':2818,'multiline':False]
['text':' Negative correction','line_number':2821,'multiline':False]
['text':' negative nbins throws','line_number':2874,'multiline':False]
['text':' empty tensor','line_number':2877,'multiline':False]
['text':' without nbins','line_number':2882,'multiline':False]
['text':' tensor with the same element','line_number':2889,'multiline':False]
['text':' no element falls between [min, max]','line_number':2894,'multiline':False]
['text':' element falls below min + integral bin size and','line_number':2900,'multiline':False]
['text':' non-integral bin size','line_number':2907,'multiline':False]
['text':' double input','line_number':2914,'multiline':False]
['text':' mixed input','line_number':2921,'multiline':False]
['text':' scalar input and 1 bin -- should return a 1-dimensional tensor, not a scalar.','line_number':2929,'multiline':False]
['text':' tensors with inf; min, max not provided -- should throw a RuntimeError','line_number':2936,'multiline':False]
['text':' tensors with inf; min, max provided','line_number':2941,'multiline':False]
['text':' tensor with nan; min, max not provided -- should throw a RuntimeError','line_number':2950,'multiline':False]
['text':' tensor with nan; min, max provided -- nan is ignored','line_number':2953,'multiline':False]
['text':' tensors with min > max -- should throw a RuntimeError','line_number':2958,'multiline':False]
['text':' test against numpy.histogram()','line_number':2963,'multiline':False]
['text':' NB: Numpy returns a int64 tensor, like normal people...','line_number':2972,'multiline':False]
['text':' Test bins arg','line_number':2978,'multiline':False]
['text':' Test truncated range','line_number':2981,'multiline':False]
['text':' Wrapper around numpy.histogram performing conversions between torch tensors and numpy arrays.','line_number':3017,'multiline':False]
['text':' Doesn't pass a 'range' kwarg unless necessary because the override of histogram with Tensor bins doesn't accept one','line_number':3023,'multiline':False]
['text':' Calls numpy.histogram again, passing torch's actual_bin_edges as the bins argument','line_number':3040,'multiline':False]
['text':' Test passing non-contiguous output tensors','line_number':3047,'multiline':False]
['text':' Doesn't pass a 'range' kwarg unless necessary because the override of histogram with Tensor bins doesn't accept one','line_number':3053,'multiline':False]
['text':' Tests passing just the bin_ct','line_number':3079,'multiline':False]
['text':' Tests with caller-specified histogram range','line_number':3082,'multiline':False]
['text':' Tests with range min=max','line_number':3086,'multiline':False]
['text':' Tests with caller-specified bin edges','line_number':3090,'multiline':False]
['text':' Necessary because msort always produces contiguous output','line_number':3093,'multiline':False]
['text':' Tests with input tensor in which all elements are equal','line_number':3100,'multiline':False]
['text':' Tests with input equal to bin_edges','line_number':3106,'multiline':False]
['text':' Tests values of default args','line_number':3114,'multiline':False]
['text':' Wrapper around numpy.histogram performing conversions between torch tensors and numpy arrays.','line_number':3135,'multiline':False]
['text':' numpy.histogramdd accepts only (N, D) shapes','line_number':3139,'multiline':False]
['text':' numpy.histogramdd throws an error for D=0','line_number':3145,'multiline':False]
['text':' numpy.histogramdd expects range to be specified as a sequence of D (lower, upper) tuples','line_number':3149,'multiline':False]
['text':' Calls numpy.histogram again, passing torch's actual_bin_edges as the bins argument','line_number':3173,'multiline':False]
['text':' Tests passing a single bin count','line_number':3207,'multiline':False]
['text':' Tests passing a bin count for each dimension','line_number':3211,'multiline':False]
['text':' Tests with caller-specified histogram range','line_number':3215,'multiline':False]
['text':' Tests with range min=max','line_number':3220,'multiline':False]
['text':' Tests with caller-specified bin edges','line_number':3225,'multiline':False]
['text':' Necessary because msort always produces contiguous output','line_number':3228,'multiline':False]
['text':' Tests to ensure that reduction functions employing comparison operators are usable when there','line_number':3302,'multiline':False]
['text':' exists a zero dimension (i.e. when the tensors are empty) in the tensor. These tests specifically','line_number':3303,'multiline':False]
['text':' cater to functions where specifying the `dim` parameter is necessary.','line_number':3304,'multiline':False]
['text':' Check if reduction happens along the specified dim with and without keepdim. Check with','line_number':3318,'multiline':False]
['text':' numpy to maintain compatibility with numpy functions.','line_number':3319,'multiline':False]
['text':' Check if function raises error on specified zero'd dimension as reduction dim.','line_number':3339,'multiline':False]
['text':' Tests to ensure that reduction of zero-dim tensors (i.e. empty tensors) using comparison operators','line_number':3342,'multiline':False]
['text':' raises an error if no `dim` parameter is specified. This exists separately from tests in','line_number':3343,'multiline':False]
['text':' test_tensot_compare_ops_empty because not specifying a `dim` parameter in the former tests does','line_number':3344,'multiline':False]
['text':' not throw errors. Also, checking the return type of argmax requires supplying a different dtype','line_number':3345,'multiline':False]
['text':' argument than that for the input tensor. There is also variantion in numpy testing.','line_number':3346,'multiline':False]
['text':' keepdim variant does not exist for numpy','line_number':3370,'multiline':False]
['text':' Check if function raises error on specified zero'd dimension as reduction dim.','line_number':3376,'multiline':False]
['text':' Tests to ensure that reduction of zero-dim tensors (i.e. empty tensors) using math operators works when a','line_number':3381,'multiline':False]
['text':' non-zero dim is specified for the reduction and throws an error when the dim specified is 0. Although','line_number':3382,'multiline':False]
['text':' there is some repetition with test_tensor_compare_ops_optional_dim_empty and test_tensor_compare_ops_empty,','line_number':3383,'multiline':False]
['text':' these tests are kept separate since tests for math operators also require checking for correctness of the','line_number':3384,'multiline':False]
['text':' returned data using allclose() or isinf() which does not exists in the former tests.','line_number':3385,'multiline':False]
['text':' Check if reduction happens along the specified dimension.','line_number':3403,'multiline':False]
['text':' The scipy function does not work for reduction the zero dimension','line_number':3431,'multiline':False]
['text':' logsumexp throws a type error when not specifying dim so test separately.','line_number':3443,'multiline':False]
['text':' Tests to ensure that any() and all() functions work with zero-dim tensors. Kept separate from','line_number':3448,'multiline':False]
['text':' other tests for checking reduction with zero-dim tensors because these tests have significantly','line_number':3449,'multiline':False]
['text':' different testing behaviour than that used for the former tests.','line_number':3450,'multiline':False]
['text':' Refer: [all, any uint8 compatibility]','line_number':3456,'multiline':False]
['text':' output of all/any is bool irrespective of input dtype','line_number':3460,'multiline':False]
['text':' any','line_number':3464,'multiline':False]
['text':' all','line_number':3471,'multiline':False]
['text':' TODO: can these be merged with their respective OpInfos?','line_number':3478,'multiline':False]
['text':' `identity` is mapped to numpy reduction `initial` argument','line_number':3524,'multiline':False]
['text':' Workaround https://github.com/pytorch/pytorch/issues/66556','line_number':3528,'multiline':False]
['text':' transform numpy scalars to numpy.ndarray instances','line_number':3529,'multiline':False]
['text':' mean_cuda is not implemented for ComplexHalf','line_number':3546,'multiline':False]
