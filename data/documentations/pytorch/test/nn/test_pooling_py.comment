['text':' Owner(s): ["module: nn"]','line_number':1,'multiline':False]
['text':' Because unfold does not support 3D sliding window we will split tensor to multiple tensors and calculate sum','line_number':36,'multiline':False]
['text':' sum_pool2d assumes tensor in (1, 1, n, m) view, so unsqueeze two times','line_number':39,'multiline':False]
['text':' Regression test for gh-36977','line_number':97,'multiline':False]
['text':' Regression test for gh-36977','line_number':109,'multiline':False]
['text':' Regression test for gh-36977','line_number':123,'multiline':False]
['text':' 0x0x3fffffffffffffff * 2 * 2 = 0xfffffffffffffffc = -4 as int64_t','line_number':153,'multiline':False]
['text':' Tensor::numel() return int64_t, so following check that negative allocs are correctly handled','line_number':154,'multiline':False]
['text':' Test 1D','line_number':352,'multiline':False]
['text':' Test list / tuple passed as argument to max_unpool1d','line_number':356,'multiline':False]
['text':' Test 2D','line_number':363,'multiline':False]
['text':' Test 3D','line_number':369,'multiline':False]
['text':' The tests are used to verify the functions raises errors for backward propagation','line_number':396,'multiline':False]
['text':' when output_size = 0, in adaptive_{avg, max}_pool and its variants.','line_number':397,'multiline':False]
['text':' These tests are explicitly written because ErrorInputs does not support backward calls','line_number':398,'multiline':False]
['text':' Issue: https://github.com/pytorch/pytorch/issues/78868','line_number':399,'multiline':False]
['text':' 1D is supposed to be okay with 0 numel() inputs so dont test','line_number':495,'multiline':False]
['text':' error raising for that case.','line_number':496,'multiline':False]
['text':' Some tests are failing in trunk https://github.com/pytorch/pytorch/issues/103854','line_number':552,'multiline':False]
['text':' NOTE: CUDA tests need to be run in a subprocess because they cause device asserts','line_number':595,'multiline':False]
['text':' test with empty non-batch input','line_number':679,'multiline':False]
['text':' Checks output shape against expected for 1D, 2D and 3D','line_number':687,'multiline':False]
['text':' Test case from issue https://github.com/pytorch/pytorch/issues/45357','line_number':700,'multiline':False]
['text':' TODO: fix on XLA','line_number':705,'multiline':False]
['text':' make sure it doesn't crash','line_number':718,'multiline':False]
['text':' make sure it doesn't crash','line_number':741,'multiline':False]
['text':' Runtime Error not raised for meta','line_number':748,'multiline':False]
['text':' ROCm 16GB MI25 hits OOM error. Clear caching allocator prior to running large subtest.','line_number':798,'multiline':False]
['text':' Pooling args: (kernel_size, stride, padding, dilation, return_indices, ceil_mode)','line_number':817,'multiline':False]
['text':' FIXME For now compare against max_pool1d with indices','line_number':828,'multiline':False]
['text':' Non-contiguous test','line_number':846,'multiline':False]
['text':' test for max_pool1d','line_number':871,'multiline':False]
['text':' assertEqual implicitly compares shape for tensors','line_number':1032,'multiline':False]
['text':' Tests crazy strides for feature dim of size 1','line_number':1143,'multiline':False]
['text':' Should not crash','line_number':1155,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/52822','line_number':1164,'multiline':False]
['text':' max_pool3d_cpu is not implemented for half','line_number':1172,'multiline':False]
['text':' x has to have batch_size 1 to test contiguous checks','line_number':1183,'multiline':False]
['text':' increase the stride in dimension 0. the tensor is still contiguous because size[0] is 1','line_number':1188,'multiline':False]
['text':' noqa: UP032','line_number':1218,'multiline':False]
['text':' FIXME(#105716): Test fails when using f-string','line_number':1220,'multiline':False]
['text':' noqa: UP032','line_number':1221,'multiline':False]
['text':' Check forward','line_number':1228,'multiline':False]
['text':' Make sure backward works','line_number':1239,'multiline':False]
['text':' Make sure backward after changing indices will result in an error','line_number':1245,'multiline':False]
['text':' Make sure -Infinity is handled correctly','line_number':1249,'multiline':False]
['text':' TODO: Fails on XLA','line_number':1328,'multiline':False]
['text':' RuntimeError: Unrecognized tensor type ID: Meta','line_number':1352,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/52427','line_number':1370,'multiline':False]
['text':' Raises -> RuntimeError: TensorAccessor expected 4 dims but tensor has 3','line_number':1371,'multiline':False]
['text':' on CUDA in gradcheck','line_number':1372,'multiline':False]
['text':' Incorrect kernel_size','line_number':1378,'multiline':False]
['text':' Incorrect output_size','line_number':1388,'multiline':False]
['text':' RuntimeError: Unrecognized tensor type ID: Meta','line_number':1391,'multiline':False]
['text':' Incorrect kernel_size','line_number':1413,'multiline':False]
['text':' Incorrect output_size','line_number':1425,'multiline':False]
['text':' TODO: Fails on XLA','line_number':1430,'multiline':False]
['text':' TODO: RuntimeError message different on XLA','line_number':1445,'multiline':False]
['text':' 16777217 is the smallest integer not expressible in float32','line_number':1468,'multiline':False]
['text':' check if the output shape was still computed correctly','line_number':1472,'multiline':False]
['text':' asserts test finishes normally without raising errors','line_number':1482,'multiline':False]
['text':' New implementation without indices supports empty tensors','line_number':1498,'multiline':False]
['text':' TODO(Heitor) change once with_indices code is updated','line_number':1499,'multiline':False]
['text':' use a configuration that gives zero outputs only','line_number':1502,'multiline':False]
['text':' when doing a correct floor division by the stride','line_number':1503,'multiline':False]
['text':' some implementations do not support dilation','line_number':1510,'multiline':False]
['text':' previous CUDA routine of this backward calculates kernel launch grid size','line_number':1523,'multiline':False]
['text':' with last two dimensions interchanged, so the tailing along the longer dim','line_number':1524,'multiline':False]
['text':' get ignored. Here we test whether every position gets gradient.','line_number':1525,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/81409','line_number':1534,'multiline':False]
