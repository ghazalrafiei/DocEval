['text':' Owner(s): ["module: nn"]','line_number':1,'multiline':False]
['text':' Backward pre hook can affect subsequent gradient computation','line_number':283,'multiline':False]
['text':' 1. test forward pre hook','line_number':324,'multiline':False]
['text':' forward-pre: bias' = bias * 2','line_number':334,'multiline':False]
['text':' So, out = x + bias * 2','line_number':335,'multiline':False]
['text':' 2. test forward pre and forward hooks','line_number':341,'multiline':False]
['text':' forward-pre: bias' = bias * 2','line_number':355,'multiline':False]
['text':' forward: out = x + bias'','line_number':356,'multiline':False]
['text':' forward-post: out = out + bias'','line_number':357,'multiline':False]
['text':' So, out = x + bias * 4','line_number':358,'multiline':False]
['text':' 3. test nn.Module member method as forward-post hook','line_number':364,'multiline':False]
['text':' forward: out = x + bias','line_number':372,'multiline':False]
['text':' forward-post: out = out + bias','line_number':373,'multiline':False]
['text':' So, out = x + bias * 2','line_number':374,'multiline':False]
['text':' test forward pre and forward hooks','line_number':380,'multiline':False]
['text':' forward-pre: bias' = bias * 2','line_number':394,'multiline':False]
['text':' forward: out = x + bias'','line_number':395,'multiline':False]
['text':' forward-post: out = out + bias'','line_number':396,'multiline':False]
['text':' So, out = x + bias * 4','line_number':397,'multiline':False]
['text':' forward-pre: bias' = bias * 2','line_number':403,'multiline':False]
['text':' forward: out = x + bias'','line_number':404,'multiline':False]
['text':' So, out = x + bias * 2','line_number':405,'multiline':False]
['text':' forward: out = x + bias','line_number':414,'multiline':False]
['text':' So, out = x + bias','line_number':415,'multiline':False]
['text':' make sure always_called forward hook runs when model.forward raises RuntimeError','line_number':457,'multiline':False]
['text':' make sure that always_called forward hook does not run twice if there is no error','line_number':462,'multiline':False]
['text':' make sure always_called forward hook runs when forward pre hook raises RuntimeError','line_number':466,'multiline':False]
['text':' make sure always_called hook runs when another always_called forward hook raises an error','line_number':474,'multiline':False]
['text':' error raised should not be error of the forced hook','line_number':479,'multiline':False]
['text':' make sure that always called forward hooks are properly removed','line_number':484,'multiline':False]
['text':' make sure that always called forward hook is not run twice if it fails while running','line_number':489,'multiline':False]
['text':' make sure global forward hook runs when forward pre hook raises RuntimeError','line_number':499,'multiline':False]
['text':' make sure forced global forward hook is properly removed','line_number':504,'multiline':False]
['text':' Test to verify that backward hook raises warning','line_number':512,'multiline':False]
['text':' if result is not a Tensor or tuple of Tensors.','line_number':513,'multiline':False]
['text':' Test with module instance method as hook','line_number':605,'multiline':False]
['text':' Test that hooks registered on a submodule are also called','line_number':638,'multiline':False]
['text':' appropriately, i.e. with the submodule as module argument in','line_number':639,'multiline':False]
['text':' my_pre_load_hook_with_module.','line_number':640,'multiline':False]
['text':' Hook must be called even if it is wrapped','line_number':688,'multiline':False]
['text':' Ensure that the hook modified missing_keys and unexpected_keys','line_number':691,'multiline':False]
['text':' When called with strict=True, the error raised should mention the','line_number':696,'multiline':False]
['text':' missing and unexpected keys the hook added.','line_number':697,'multiline':False]
['text':' Removing the hook via handle.remove() should cause it not to','line_number':701,'multiline':False]
['text':' fire anymore.','line_number':702,'multiline':False]
['text':' Hook did not run so it should not have added any keys','line_number':704,'multiline':False]
['text':' hook_called should not have been incremented','line_number':708,'multiline':False]
['text':' load state_dict with strict=True should not throw.','line_number':718,'multiline':False]
['text':' explicitly ensure that the post hook clearned out incompatible_keys','line_number':720,'multiline':False]
['text':' Simulate an older model that did not have this attr','line_number':734,'multiline':False]
['text':' Save and load, and ensure that load_state_dict works (without proper','line_number':736,'multiline':False]
['text':' BC we would run into errors because this attribute would be expected).','line_number':737,'multiline':False]
['text':' In particular, Softmax runs into the issue described here:','line_number':738,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/77280','line_number':739,'multiline':False]
['text':' Note that torch.save / torch.load is not recommended to save/load','line_number':741,'multiline':False]
['text':' modules.','line_number':742,'multiline':False]
['text':' Ensure hooks can be registered and called.','line_number':748,'multiline':False]
['text':' make sure hook register is successful','line_number':925,'multiline':False]
['text':' make sure hook removal is successful','line_number':933,'multiline':False]
['text':' make sure hook register is successful','line_number':960,'multiline':False]
['text':' make sure hook removal is successful','line_number':968,'multiline':False]
['text':' backward_pre_hook expects callback with only `module` and `grad_output`','line_number':1064,'multiline':False]
['text':' as arguments.','line_number':1065,'multiline':False]
['text':' Test to make sure that the grad_outputs','line_number':1140,'multiline':False]
['text':' updated by full_backward_pre_hook are received by','line_number':1141,'multiline':False]
['text':' the full_backward_hook','line_number':1142,'multiline':False]
['text':' Ensure that requires grad is properly propagated','line_number':1209,'multiline':False]
['text':' If the inputs were requiring gradients, this would be','line_number':1231,'multiline':False]
['text':' a valid return','line_number':1232,'multiline':False]
['text':' This should run and trigger the hook properly','line_number':1241,'multiline':False]
['text':' No inplace should work','line_number':1305,'multiline':False]
['text':' Input inplace error should throw an error','line_number':1309,'multiline':False]
['text':' Input inplace error should throw an error if we try to re-use the view after they have','line_number':1314,'multiline':False]
['text':' been modified','line_number':1315,'multiline':False]
['text':' Any operation involving the view will fail here','line_number':1321,'multiline':False]
['text':' Output inplace error should throw an error','line_number':1324,'multiline':False]
['text':' Check invalid input container','line_number':1337,'multiline':False]
['text':' Check invalid output container','line_number':1348,'multiline':False]
['text':' Check invalid output from different Nodes','line_number':1359,'multiline':False]
['text':' Check invalid forward with multiple Nodes','line_number':1370,'multiline':False]
['text':' Make module with multiple operations in forward','line_number':1382,'multiline':False]
['text':' And different size for input and outputs','line_number':1383,'multiline':False]
