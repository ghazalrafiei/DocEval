['text':' Owner(s): ["module: dynamo"]','line_number':1,'multiline':False]
['text':' flake8: noqa','line_number':2,'multiline':False]
['text':' Defines all the kernels for tests','line_number':37,'multiline':False]
['text':' noqa: F403','line_number':38,'multiline':False]
['text':' dynamo decomposes this to avoid a graph break when','line_number':109,'multiline':False]
['text':' the value kwarg is populated','line_number':110,'multiline':False]
['text':' dynamo same() util doesn't support deque so just return a list','line_number':289,'multiline':False]
['text':' avg_pool2d is an odd one with __self__ set','line_number':346,'multiline':False]
['text':' This is common in sme huggingface models','line_number':625,'multiline':False]
['text':' being a LOAD_CONST in the bytecode','line_number':673,'multiline':False]
['text':' this is roughly the pattern found in einops.unpack()','line_number':859,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/103602','line_number':1040,'multiline':False]
['text':' dynamo should recompile for all inputs in static shapes mode','line_number':1089,'multiline':False]
['text':' dynamo should recompile for items 0, 1, 2, 6 in dynamic shapes mode','line_number':1091,'multiline':False]
['text':' # This is to test the new syntax for pattern matching','line_number':1154,'multiline':False]
['text':' # ("match ... case ...") added on python 3.10.','line_number':1155,'multiline':False]
['text':' # Uncomment these test cases if you run on 3.10+','line_number':1156,'multiline':False]
['text':' @make_test','line_number':1157,'multiline':False]
['text':' def test_match_sequence(a):','line_number':1158,'multiline':False]
['text':'     point = (5, 8)','line_number':1159,'multiline':False]
['text':'     match point:','line_number':1160,'multiline':False]
['text':'         case (0, 0):','line_number':1161,'multiline':False]
['text':'             return a','line_number':1162,'multiline':False]
['text':'         case (0, y):','line_number':1163,'multiline':False]
['text':'             return a - y','line_number':1164,'multiline':False]
['text':'         case (x, 0):','line_number':1165,'multiline':False]
['text':'             return a + x','line_number':1166,'multiline':False]
['text':'         case (x, y):','line_number':1167,'multiline':False]
['text':'             return a + x - y','line_number':1168,'multiline':False]
['text':' @make_test','line_number':1170,'multiline':False]
['text':' def test_match_mapping_and_match_keys(x):','line_number':1171,'multiline':False]
['text':'     param = {"a": 0.5}','line_number':1172,'multiline':False]
['text':'     match param:','line_number':1173,'multiline':False]
['text':'         case {"a": param}:','line_number':1174,'multiline':False]
['text':'             return x * param','line_number':1175,'multiline':False]
['text':'         case {"b": param}:','line_number':1176,'multiline':False]
['text':'             return x / param','line_number':1177,'multiline':False]
['text':' No recompile! Tensor and udf_mul guarded','line_number':1403,'multiline':False]
['text':' Recompile! Tensor size changed','line_number':1408,'multiline':False]
['text':' Recompile! func id changed','line_number':1415,'multiline':False]
['text':' start over','line_number':1425,'multiline':False]
['text':' Recompile! Different kwarg keys','line_number':1430,'multiline':False]
['text':' Recompile! Different arg keys','line_number':1436,'multiline':False]
['text':' Recompile! input is no longer a functools partial','line_number':1442,'multiline':False]
['text':' Should not have recompiled','line_number':1487,'multiline':False]
['text':' Should not have recompiled','line_number':1503,'multiline':False]
['text':' Force no inlining','line_number':1528,'multiline':False]
['text':' Define shared triton constants here.','line_number':1583,'multiline':False]
['text':' the inner func mutates += 1 each call','line_number':1607,'multiline':False]
['text':' Calling compiled_func twice does not recompile','line_number':1610,'multiline':False]
['text':' But with a change to the guarded default tensor, we do recompile','line_number':1614,'multiline':False]
['text':' the inner func mutates += 1 each call','line_number':1647,'multiline':False]
['text':' Calling compiled_func twice does not recompile','line_number':1650,'multiline':False]
['text':' But with a change to the guarded default tensor, we do recompile','line_number':1654,'multiline':False]
['text':' No need to assert anything, the goal is to make sure dynamo does','line_number':1709,'multiline':False]
['text':' not crash','line_number':1710,'multiline':False]
['text':' Test higher order function with mutation','line_number':1723,'multiline':False]
['text':' Make sure it is modified','line_number':1739,'multiline':False]
['text':' Test higher order function without mutation','line_number':1742,'multiline':False]
['text':' Make sure it is NOT modified','line_number':1757,'multiline':False]
['text':' Make sure t2 was not modified','line_number':1792,'multiline':False]
['text':' Make sure t2 was not modified','line_number':1796,'multiline':False]
['text':' Make sure t2 was not modified','line_number':1800,'multiline':False]
['text':' normal mutation only','line_number':1832,'multiline':False]
['text':' triton kernel mutation only','line_number':1843,'multiline':False]
['text':' normal mutation + triton kernel mutation','line_number':1862,'multiline':False]
['text':' TODO(oulgen): NYI - Support this','line_number':1959,'multiline':False]
['text':' self.assertEqual(t * t, compiled_func(t))','line_number':1960,'multiline':False]
['text':' These two asserts are not optimal since it requires original aten','line_number':1991,'multiline':False]
['text':' to be in the metadata, so there might be false negatives','line_number':1992,'multiline':False]
['text':' The following checks that there are only the tensor output is in','line_number':1995,'multiline':False]
['text':' the compiled graph','line_number':1996,'multiline':False]
['text':' Make sure we emitted two kernels here','line_number':2066,'multiline':False]
['text':' Make sure this does not crash','line_number':2104,'multiline':False]
['text':' Triton kernels capture global constants by their parse time value','line_number':2239,'multiline':False]
['text':' not runtime value','line_number':2240,'multiline':False]
['text':' If the behavior of triton kernels change, this test will fail','line_number':2243,'multiline':False]
['text':' reset back','line_number':2253,'multiline':False]
['text':' No Dynamo -- Make sure triton kernel works','line_number':2371,'multiline':False]
['text':' No Dynamo -- Make sure triton kernel works (with positional BLOCK_SIZE)','line_number':2373,'multiline':False]
['text':' With Dynamo','line_number':2377,'multiline':False]
['text':' With simple kernel','line_number':2381,'multiline':False]
['text':' With lambda kernel','line_number':2384,'multiline':False]
['text':' With lambda kernel (with positional BLOCK_SIZE)','line_number':2387,'multiline':False]
['text':' With user defined function kernel','line_number':2390,'multiline':False]
['text':' Check default dict assignment','line_number':2419,'multiline':False]
['text':' Check that dataclass methods can be inlined','line_number':2421,'multiline':False]
['text':' Check that normal assignment works','line_number':2424,'multiline':False]
['text':' Check default int assignment','line_number':2427,'multiline':False]
['text':' Check that the default members are properly initialized','line_number':2430,'multiline':False]
['text':' Change dataclass','line_number':2434,'multiline':False]
['text':' Return dataclaass as well to check reconstruction','line_number':2438,'multiline':False]
['text':' (int, 1.0), # fails due to a >= 0 comparison in sym_int','line_number':2497,'multiline':False]
['text':' , bool, complex]: no casting for sym_bool, no sym_complex','line_number':2498,'multiline':False]
['text':' Cannot handle non single-elem','line_number':2512,'multiline':False]
['text':' The real tensor values are recovered when graph breaking.','line_number':2562,'multiline':False]
['text':' Hence we recover the invariant.','line_number':2563,'multiline':False]
['text':' Test aliased','line_number':2660,'multiline':False]
['text':' Recompiles','line_number':2662,'multiline':False]
['text':' Tensor method','line_number':2673,'multiline':False]
['text':' torch function','line_number':2674,'multiline':False]
['text':' Test aliased','line_number':2682,'multiline':False]
['text':' Recompiles','line_number':2684,'multiline':False]
['text':' If nopython, should raise UserError','line_number':2706,'multiline':False]
['text':' Should cause fallback if allow graph break','line_number':2710,'multiline':False]
