['text':' Owner(s): ["module: ProxyTensor"]','line_number':1,'multiline':False]
['text':' TODO: consider all_gather the local tensors for better debugging','line_number':122,'multiline':False]
['text':' WARNING: if any of your inputs are index tensors, DO NOT use this','line_number':141,'multiline':False]
['text':' function','line_number':142,'multiline':False]
['text':' We expect to see matmul in the trace - it should NOT be decomposed into mm.','line_number':154,'multiline':False]
['text':' Also, torch.ones() doesn't show up in the trace.','line_number':155,'multiline':False]
['text':' This is annoying but expected: ones() never dispatches to the Autograd dispatch key,','line_number':156,'multiline':False]
['text':' so our mode never sees it - it goes directly to the BackendSelect key.','line_number':157,'multiline':False]
['text':' Test that make_fx(pre_dispatch=True) clears caches properly.','line_number':159,'multiline':False]
['text':' get_isolated_graphmodule uses make_fx internally that shouldn't be traced','line_number':227,'multiline':False]
['text':' by the outer make_fx call','line_number':228,'multiline':False]
['text':' When factory functions are used, they should not be traced','line_number':232,'multiline':False]
['text':' by the outer make_fx call','line_number':233,'multiline':False]
['text':' Verify nested make_fx calls don't make factory functions to be leaked','line_number':255,'multiline':False]
['text':' into the outer graph. Verify that `make_fx`` itself does not leak its execution.','line_number':256,'multiline':False]
['text':' Verify that the `forward`` function of a graph module produced as a','line_number':268,'multiline':False]
['text':' side effect of an interior `make_fx` is still traced','line_number':269,'multiline':False]
['text':' `gm.forward`` is still traced','line_number':274,'multiline':False]
['text':' Verify interaction with non-ProxyTensor modes','line_number':282,'multiline':False]
['text':' Verify interaction with another tensor subclass','line_number':303,'multiline':False]
['text':' This case currently doesn't work and should raise an error','line_number':304,'multiline':False]
['text':' See: https://github.com/pytorch/pytorch/pull/81764#issuecomment-1200472068','line_number':305,'multiline':False]
['text':' this fails, sigmoid is traced with LoggingTensor','line_number':322,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/97541','line_number':325,'multiline':False]
['text':' When new_zeros() decomposes into torch.zero(), we expect ProxyTensorMode','line_number':346,'multiline':False]
['text':' to still be (re-entrantly) enabled, so that the `torch.zero()` call','line_number':347,'multiline':False]
['text':' returns a ProxyTensor.','line_number':348,'multiline':False]
['text':' An old version of this test called the module directly.  This works','line_number':381,'multiline':False]
['text':' for tracing_mode == "real", but for fake tensors, we also have to','line_number':382,'multiline':False]
['text':' ensure that the parameters and buffers get wrapped in fake tensors','line_number':383,'multiline':False]
['text':' because free fake tensors are not supported.  Fortunately functional_call','line_number':384,'multiline':False]
['text':' does precisely this for us.','line_number':385,'multiline':False]
['text':' I could have done this with the functional API, but there is','line_number':390,'multiline':False]
['text':' plenty of exercising this; I want to show mutating API still','line_number':391,'multiline':False]
['text':' works','line_number':392,'multiline':False]
['text':' default behavior should trace factory functions','line_number':437,'multiline':False]
['text':' In case we mutated shared state in the g graph!','line_number':497,'multiline':False]
['text':' fx may change the order of parameters in list, so using set() to compare','line_number':579,'multiline':False]
['text':' noqa: B902','line_number':601,'multiline':False]
['text':' fx may change the order of parameters in list, so using set() to compare','line_number':639,'multiline':False]
['text':' also there is a numerical difference in results so changing atol from 1e-08 to 1e-03','line_number':640,'multiline':False]
['text':' Tests the issue brought up here https://github.com/pytorch/pytorch/pull/86917#issuecomment-1283155344','line_number':736,'multiline':False]
['text':' Smoke tests','line_number':766,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/99356','line_number':802,'multiline':False]
['text':' NB: this should not have a detach call','line_number':850,'multiline':False]
['text':' TODO: Need to test the guards themselves specifically as well','line_number':883,'multiline':False]
['text':' Operator where meta and cpu disagree on strides','line_number':907,'multiline':False]
['text':' input mismatch is caught (indicates guard problem)','line_number':924,'multiline':False]
['text':' Catch the incorrect meta','line_number':930,'multiline':False]
['text':' this isn't really a proxy tensor test, but it's the most convenient','line_number':993,'multiline':False]
['text':' way to get a fake tensor with symbolic sizes','line_number':994,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/108195','line_number':1002,'multiline':False]
['text':' noqa: B950','line_number':1029,'multiline':False]
['text':' noqa: B950','line_number':1042,'multiline':False]
['text':' Extracted from wave2vec2','line_number':1065,'multiline':False]
['text':' NB: this specializes, which is fine, the point is to make sure the','line_number':1123,'multiline':False]
['text':' dtype inference is correct','line_number':1124,'multiline':False]
['text':' noqa: B950','line_number':1143,'multiline':False]
['text':' from moco','line_number':1148,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/101939','line_number':1149,'multiline':False]
['text':' noqa: B950','line_number':1162,'multiline':False]
['text':' noqa: B950','line_number':1218,'multiline':False]
['text':' noqa: B950','line_number':1297,'multiline':False]
['text':' refines i0 = s0','line_number':1309,'multiline':False]
['text':' noqa: B950','line_number':1321,'multiline':False]
['text':' refines i0 = i1','line_number':1327,'multiline':False]
['text':' refines i0 = s0','line_number':1328,'multiline':False]
['text':' noqa: B950','line_number':1342,'multiline':False]
['text':' tolist not directly supported atm','line_number':1346,'multiline':False]
['text':' noqa: B950','line_number':1371,'multiline':False]
['text':' I think I messed up writing this test case originally, I think','line_number':1449,'multiline':False]
['text':' I'm supposed to hit an error case, but the code here works in both','line_number':1450,'multiline':False]
['text':' eager and tracing','line_number':1451,'multiline':False]
['text':' Checks if the input expr has been updated even though the constraint','line_number':1488,'multiline':False]
['text':' happened afterwards','line_number':1489,'multiline':False]
['text':' noqa: B950','line_number':1535,'multiline':False]
['text':' noqa: B950','line_number':1536,'multiline':False]
['text':' noqa: B950','line_number':1539,'multiline':False]
['text':' noqa: B950','line_number':1540,'multiline':False]
['text':' NB: Numbers are carefully chosen to avoid duck shaping from applying','line_number':1596,'multiline':False]
['text':' unknown','line_number':1663,'multiline':False]
['text':' empty','line_number':1666,'multiline':False]
['text':' flaky','line_number':1671,'multiline':False]
['text':' flaky, probably just a precision issue','line_number':1676,'multiline':False]
['text':' data-dependent control flow','line_number':1678,'multiline':False]
['text':' Seems like it's creating a sparse tensor that isn't captured by tensor.is_sparse','line_number':1688,'multiline':False]
['text':' proxy tensor doesn't support sparse correctly right now','line_number':1692,'multiline':False]
['text':' segfaults','line_number':1694,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':1697,'multiline':False]
['text':' ASAN failures due to divide by 0','line_number':1702,'multiline':False]
['text':' aten.frexp.Tensor - couldn't find symbolic meta function/decomposition','line_number':1710,'multiline':False]
['text':' aten.geqrf.default - couldn't find symbolic meta function/decomposition','line_number':1711,'multiline':False]
['text':' Could not run 'aten::histc' with arguments from the 'Meta' backend. This could be because...','line_number':1712,'multiline':False]
['text':' Could not run 'aten::histogram.bin_ct' with arguments from the 'Meta' backend. This c...','line_number':1713,'multiline':False]
['text':' aten._histogramdd_bin_edges.default - couldn't find symbolic meta function/decomposition','line_number':1714,'multiline':False]
['text':' aten.isin.Tensor_Tensor - couldn't find symbolic meta function/decomposition','line_number':1715,'multiline':False]
['text':' aten.kthvalue.default - couldn't find symbolic meta function/decomposition','line_number':1716,'multiline':False]
['text':' Could not run 'aten::equal' with arguments from the 'Meta' backend.','line_number':1717,'multiline':False]
['text':' aten.size.default - couldn't find symbolic meta function/decomposition','line_number':1718,'multiline':False]
['text':' aten.new_empty.default - couldn't find symbolic meta function/decom...','line_number':1719,'multiline':False]
['text':' aten.size.default - couldn't find symbolic meta function/decomposition','line_number':1720,'multiline':False]
['text':' aten._ctc_loss.Tensor - couldn't find symbolic meta function/decomposition','line_number':1721,'multiline':False]
['text':' argument 'size' must be tuple of ints, but found element of t...','line_number':1722,'multiline':False]
['text':' argument 'size' must be tuple of ints, but found element of t...','line_number':1723,'multiline':False]
['text':' aten.upsample_linear1d.vec - couldn't find symbolic meta function/dec...','line_number':1724,'multiline':False]
['text':' aten.upsample_trilinear3d.vec - couldn't find symbolic meta functi...','line_number':1725,'multiline':False]
['text':' aten.pixel_unshuffle.default - couldn't find symbolic meta function/deco...','line_number':1726,'multiline':False]
['text':' Could not run 'aten::equal' with arguments from the 'Meta' backend.','line_number':1727,'multiline':False]
['text':' aten.clone.default - couldn't find symbolic meta function/decomposition','line_number':1728,'multiline':False]
['text':' aten.unique_consecutive.default - couldn't find symbolic meta function/decomposition','line_number':1729,'multiline':False]
['text':' aten._unique2.default - couldn't find symbolic meta function/decomposition','line_number':1730,'multiline':False]
['text':' AssertionError: False != True - https://github.com/pytorch/pytorch/issues/113905','line_number':1732,'multiline':False]
['text':' Expected a value of type 'List[int]' for argument 'kernel_size' but...','line_number':1739,'multiline':False]
['text':' many complex operators incorrect striding, metadata','line_number':1741,'multiline':False]
['text':' Segfault??','line_number':1760,'multiline':False]
['text':' aten.i0.default - couldn't find symbolic meta function/decomposition','line_number':1766,'multiline':False]
['text':' Cannot call numel() on tensor with symbolic sizes/strides','line_number':1769,'multiline':False]
['text':' Cannot call numel() on tensor with symbolic sizes/strides','line_number':1770,'multiline':False]
['text':' Cannot call numel() on tensor with symbolic sizes/strides','line_number':1771,'multiline':False]
['text':' bugs','line_number':1775,'multiline':False]
['text':' base given to float_power_ has dtype Float but the operation's result requires dtype Double','line_number':1776,'multiline':False]
['text':' decomp not implemented','line_number':1777,'multiline':False]
['text':' SymIntArrayRef expected to contain only concrete','line_number':1836,'multiline':False]
['text':' Copies inputs to inplace operations to avoid inplace modifications','line_number':1848,'multiline':False]
['text':'   to leaves requiring gradient','line_number':1849,'multiline':False]
['text':' Limit ourselves to first 100 inputs so symbolic tracing tests don't take too long','line_number':1861,'multiline':False]
