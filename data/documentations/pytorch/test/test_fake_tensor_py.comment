['text':' Owner(s): ["module: meta tensors"]','line_number':1,'multiline':False]
['text':' doesnt error','line_number':49,'multiline':False]
['text':' TODO: tensor() errors','line_number':161,'multiline':False]
['text':' Test torch.full returns tensor with correct dtype','line_number':219,'multiline':False]
['text':' no error','line_number':282,'multiline':False]
['text':' does not fail','line_number':324,'multiline':False]
['text':' intentionally bad inputs','line_number':352,'multiline':False]
['text':' argument `cx` can be None','line_number':487,'multiline':False]
['text':' Ensure CUDA (non-cuDNN) impl succeeds with fake tensors.','line_number':499,'multiline':False]
['text':' t2.size(0) is still dynamic, even though we didn't pass DYNAMIC here','line_number':551,'multiline':False]
['text':' It's not obvious that the invocation above makes it dynamic but it','line_number':573,'multiline':False]
['text':' does!','line_number':574,'multiline':False]
['text':' This behavior was originally unintentional but we see people','line_number':650,'multiline':False]
['text':' relying on it','line_number':651,'multiline':False]
['text':' This used to segfault, now it does not, but it still raises an','line_number':1028,'multiline':False]
['text':' error','line_number':1029,'multiline':False]
['text':' at::_embedding_bag has no op info,','line_number':1043,'multiline':False]
['text':' and returns extra tensors that at::embedding bag throws away','line_number':1044,'multiline':False]
['text':' mode = max','line_number':1051,'multiline':False]
['text':' We expect the cross ref to succed for the first output to fail','line_number':1106,'multiline':False]
['text':' for the rng state, see Note [Seed and Offset]','line_number':1107,'multiline':False]
['text':' Convert nn.Module to GraphModule so that FakeTensorProp runs.','line_number':1177,'multiline':False]
['text':' The following block runs FakeTensorProp on graph_module w/to the same FakeTensorMode','line_number':1179,'multiline':False]
['text':'','line_number':1180,'multiline':False]
['text':' TODO(wschin): there should be an API to run FakeTensorProp for GraphModule','line_number':1181,'multiline':False]
['text':' with parameters and buffers.','line_number':1182,'multiline':False]
['text':' This case uses the **same** fake tensor mode to','line_number':1199,'multiline':False]
['text':'  1. create fake parameters and fake buffers, and','line_number':1200,'multiline':False]
['text':'  2. run FakeTensorProp','line_number':1201,'multiline':False]
['text':' The result should be correct.','line_number':1202,'multiline':False]
['text':' This case uses the **different** fake tensor modes to','line_number':1206,'multiline':False]
['text':'  1. create fake parameters and fake buffers, and','line_number':1207,'multiline':False]
['text':'  2. run FakeTensorProp','line_number':1208,'multiline':False]
['text':' The following code should fail.','line_number':1209,'multiline':False]
['text':' AssertionError: tensor's device must be `meta`, got cpu instead','line_number':1214,'multiline':False]
['text':' Mimic huggingface's `forward` methods which have several optional arguments.','line_number':1227,'multiline':False]
['text':' For example, GPT accepts forward(self, input_ids, None, attention_mask, ...).','line_number':1228,'multiline':False]
['text':' To apply FakeTensorProp, its from_real_tensor(...) needs to accept None.','line_number':1229,'multiline':False]
