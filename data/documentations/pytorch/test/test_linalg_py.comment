['text':' Owner(s): ["module: linear algebra"]','line_number':1,'multiline':False]
['text':' Protects against includes accidentally setting the default dtype','line_number':37,'multiline':False]
['text':' scalar x scalar','line_number':71,'multiline':False]
['text':' scalar x empty','line_number':72,'multiline':False]
['text':' scalar x 1D','line_number':73,'multiline':False]
['text':' scalar x 3D','line_number':74,'multiline':False]
['text':' empty x empty','line_number':76,'multiline':False]
['text':' empty x 2D','line_number':77,'multiline':False]
['text':' 1D x 1D','line_number':79,'multiline':False]
['text':' 1D x 3D','line_number':80,'multiline':False]
['text':' 1D x 3D empty','line_number':81,'multiline':False]
['text':' 2D x 2D','line_number':83,'multiline':False]
['text':' 2D x 3D','line_number':84,'multiline':False]
['text':' 4D x 4D','line_number':85,'multiline':False]
['text':' Test error message','line_number':87,'multiline':False]
['text':' Tests torch.outer, and its alias, torch.ger, vs. NumPy','line_number':93,'multiline':False]
['text':' test out variant','line_number':114,'multiline':False]
['text':' test 0 strided tensor','line_number':127,'multiline':False]
['text':' Singular values are None when lapack_driver='gelsy' in SciPy','line_number':211,'multiline':False]
['text':' SciPy and NumPy operate only on non-batched input and','line_number':218,'multiline':False]
['text':' return an empty array with shape (0,) if rank(a) != n','line_number':219,'multiline':False]
['text':' in PyTorch the batched inputs are supported and','line_number':220,'multiline':False]
['text':' matrices in the batched input can have different ranks','line_number':221,'multiline':False]
['text':' we compute residuals only if all matrices have rank == n','line_number':222,'multiline':False]
['text':' see https://github.com/pytorch/pytorch/issues/56483','line_number':223,'multiline':False]
['text':' residuals are not always computed (and have non-zero shape)','line_number':236,'multiline':False]
['text':' singular_values are not always computed (and have non-zero shape)','line_number':242,'multiline':False]
['text':' SciPy provides 3 driver options: gelsd, gelss, gelsy','line_number':249,'multiline':False]
['text':' NumPy uses only gelsd routine','line_number':258,'multiline':False]
['text':' cases m < n are only supported on CPU and for cuSOLVER path on CUDA','line_number':267,'multiline':False]
['text':' we generate matrices with singular values sampled from a normal distribution,','line_number':272,'multiline':False]
['text':' that is why we use `cond=1.0`, the mean to cut roughly half of all','line_number':273,'multiline':False]
['text':' the singular values and compare whether torch.linalg.lstsq agrees with','line_number':274,'multiline':False]
['text':' SciPy and NumPy.','line_number':275,'multiline':False]
['text':' if rcond is True then set value for it based on the used algorithm','line_number':276,'multiline':False]
['text':' rcond == -1 or any other negative value forces LAPACK to use machine precision tolerance','line_number':277,'multiline':False]
['text':' keep the rcond value if it is None or -1, set the driver specific value if it is True','line_number':281,'multiline':False]
['text':' SVD based algorithm; set to zero roughly half of all the singular values','line_number':284,'multiline':False]
['text':' driver == 'gelsy'','line_number':287,'multiline':False]
['text':' QR based algorithm; setting the value too high might lead to non-unique solutions and flaky tests','line_number':288,'multiline':False]
['text':' so we skip this case','line_number':289,'multiline':False]
['text':' specifying rcond value has no effect for gels driver so no need to run the tests again','line_number':292,'multiline':False]
['text':' Only checks gelsd, gelss, gelsy drivers','line_number':305,'multiline':False]
['text':' Only checks gelsd driver','line_number':308,'multiline':False]
['text':' gels driver is not checked by comparing to NumPy or SciPy implementation','line_number':311,'multiline':False]
['text':' because NumPy and SciPy do not implement this driver','line_number':312,'multiline':False]
['text':' the case when a single matrix is batch-broadcasted over the rhs','line_number':329,'multiline':False]
['text':' cases with broadcastable shapes','line_number':335,'multiline':False]
['text':' rhs are vectors, not matrices in this test','line_number':341,'multiline':False]
['text':' unsqueeze for b because `check_correctness` checks against','line_number':343,'multiline':False]
['text':' a.pinverse() @ b, which requires b to be a matrix','line_number':344,'multiline':False]
['text':' rhs are vectors, not matrices in this test','line_number':351,'multiline':False]
['text':' check empty inputs','line_number':359,'multiline':False]
['text':' empty batches','line_number':360,'multiline':False]
['text':' empty a and b','line_number':367,'multiline':False]
['text':' empty a and b','line_number':374,'multiline':False]
['text':' empty a but not b','line_number':381,'multiline':False]
['text':' empty a and b','line_number':389,'multiline':False]
['text':' only CPU since CUDA does not support overdetermined systems','line_number':391,'multiline':False]
['text':' if on cpu','line_number':436,'multiline':False]
['text':' cuSOLVER path supports underdetermined systems','line_number':441,'multiline':False]
['text':' For fp32 individual entries in matrices can differ between PyTorch and NumPy','line_number':465,'multiline':False]
['text':' Let's compare the norms of matrices instead','line_number':466,'multiline':False]
['text':' axis is specified to calculate matrix norm for batched input','line_number':468,'multiline':False]
['text':' Compare the norms with standard tolerances','line_number':471,'multiline':False]
['text':' and individual values with a higher tolerance','line_number':473,'multiline':False]
['text':' check the out= variant','line_number':484,'multiline':False]
['text':' check the upper= variant','line_number':492,'multiline':False]
['text':' cholesky requires the input to be a square matrix or batch of square matrices','line_number':503,'multiline':False]
['text':' cholesky requires the input to be at least 2 dimensional tensor','line_number':513,'multiline':False]
['text':' if the input matrix is not positive definite, an error should be raised','line_number':521,'multiline':False]
['text':' Now A is not positive definite','line_number':523,'multiline':False]
['text':' if at least one matrix in the batch is singular, an error should be raised','line_number':529,'multiline':False]
['text':' Now A[4] is not positive definite','line_number':533,'multiline':False]
['text':' if out tensor with wrong shape is passed a warning is given','line_number':537,'multiline':False]
['text':' Trigger warning','line_number':541,'multiline':False]
['text':' Check warning occurs','line_number':543,'multiline':False]
['text':' dtypes should be safely castable','line_number':547,'multiline':False]
['text':' device should match','line_number':552,'multiline':False]
['text':' NOTE: old_cholesky* tests were moved here from test_torch.py and test_autograd.py','line_number':559,'multiline':False]
['text':' Correctness check','line_number':571,'multiline':False]
['text':' Upper triangular check','line_number':573,'multiline':False]
['text':' Correctness check','line_number':576,'multiline':False]
['text':' Lower triangular check','line_number':578,'multiline':False]
['text':' default Case','line_number':610,'multiline':False]
['text':' test Upper Triangular','line_number':615,'multiline':False]
['text':' test Lower Triangular','line_number':620,'multiline':False]
['text':' Test for issue','line_number':637,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/57032','line_number':638,'multiline':False]
['text':' torch.cholesky with upper=True for batched CUDA inputs was wrong','line_number':639,'multiline':False]
['text':' it was using the lower triangular part instead of the upper one','line_number':640,'multiline':False]
['text':' fill the lower triangular part with zero','line_number':649,'multiline':False]
['text':' For fp32 individual entries in matrices can differ between PyTorch and NumPy','line_number':668,'multiline':False]
['text':' Let's compare the norms of matrices instead','line_number':669,'multiline':False]
['text':' axis is specified to calculate matrix norm for batched input','line_number':671,'multiline':False]
['text':' Compare the norms with standard tolerances','line_number':674,'multiline':False]
['text':' and individual values with a higher tolerance','line_number':676,'multiline':False]
['text':' if the input matrix is not positive definite, info with positive integer is returned','line_number':691,'multiline':False]
['text':' Now A is singular','line_number':693,'multiline':False]
['text':' if at least one matrix in the batch is not positive definite,','line_number':699,'multiline':False]
['text':' batched info with positive integer for the corresponding matrix is returned','line_number':700,'multiline':False]
['text':' Now A[3] is singular','line_number':704,'multiline':False]
['text':' Test out variant','line_number':733,'multiline':False]
['text':' test transpose','line_number':744,'multiline':False]
['text':' test 0 strided tensor','line_number':748,'multiline':False]
['text':' test scalar','line_number':752,'multiline':False]
['text':' test nans and infs are not propagated to the output when beta == 0','line_number':756,'multiline':False]
['text':' when beta is zero','line_number':785,'multiline':False]
['text':' when beta is not zero','line_number':787,'multiline':False]
['text':' when beta is zero','line_number':800,'multiline':False]
['text':' when beta is not zero','line_number':802,'multiline':False]
['text':' don't use @dtypes decorator to avoid generating ~1700 tests per device','line_number':816,'multiline':False]
['text':' Tests migrated from test_torch.py','line_number':829,'multiline':False]
['text':' 1) test the shape of the result tensor when there is empty input tensor','line_number':830,'multiline':False]
['text':' 2) test the Runtime Exception when there is scalar input tensor','line_number':831,'multiline':False]
['text':' Tests torch.det and its alias, torch.linalg.det, vs. NumPy','line_number':853,'multiline':False]
['text':' NOTE: det requires a 2D+ tensor','line_number':874,'multiline':False]
['text':' sign of eigenvectors is not unique and therefore absolute values are compared','line_number':891,'multiline':False]
['text':' additionally we can multiply the eigenvector with a phase factor e^{i\phi} and then compare the values','line_number':893,'multiline':False]
['text':' let's choose the convention that the first element of the eigenvectors from torch and numpy be the same','line_number':894,'multiline':False]
['text':' for real inputs, this phase factor is plus or minus one','line_number':895,'multiline':False]
['text':' check the out= variant','line_number':901,'multiline':False]
['text':' check lower case uplo','line_number':922,'multiline':False]
['text':' use non-symmetric input to check whether uplo argument is working as intended','line_number':923,'multiline':False]
['text':' eigh requires a square matrix','line_number':940,'multiline':False]
['text':' eigh requires 'uplo' parameter to be 'U' or 'L'','line_number':945,'multiline':False]
['text':' if non-empty out tensor with wrong shape is passed a warning is given','line_number':953,'multiline':False]
['text':' Trigger warning','line_number':959,'multiline':False]
['text':' Check warning occurs','line_number':961,'multiline':False]
['text':' dtypes should be safely castable','line_number':966,'multiline':False]
['text':' device should match','line_number':977,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/94772, https://github.com/pytorch/pytorch/issues/105359','line_number':993,'multiline':False]
['text':' This test crashes with `cusolver error: CUSOLVER_STATUS_EXECUTION_FAILED` on cuda 11.8,','line_number':994,'multiline':False]
['text':' but passes on cuda 12.1 update 1 or later.','line_number':995,'multiline':False]
['text':' Matrix input a is too ill-conditioned.','line_number':1003,'multiline':False]
['text':' We'll just compare the first two singular values/eigenvalues. They are 1.0e5 and 511.0','line_number':1004,'multiline':False]
['text':' The precision override with tolerance of 1.0 makes sense since ill-conditioned inputs are hard to converge','line_number':1005,'multiline':False]
['text':' to exact values.','line_number':1006,'multiline':False]
['text':' check the out= variant','line_number':1023,'multiline':False]
['text':' eigvalsh requires a square matrix','line_number':1039,'multiline':False]
['text':' eigvalsh requires 'uplo' parameter to be 'U' or 'L'','line_number':1044,'multiline':False]
['text':' if non-empty out tensor with wrong shape is passed a warning is given','line_number':1052,'multiline':False]
['text':' Trigger warning','line_number':1056,'multiline':False]
['text':' Check warning occurs','line_number':1058,'multiline':False]
['text':' dtypes should be safely castable','line_number':1062,'multiline':False]
['text':' device should match','line_number':1067,'multiline':False]
['text':' check the out= variant','line_number':1085,'multiline':False]
['text':' NumPy doesn't work if the first argument is empty','line_number':1105,'multiline':False]
['text':' if non-empty out tensor with wrong shape is passed a warning is given','line_number':1115,'multiline':False]
['text':' Trigger warning','line_number':1120,'multiline':False]
['text':' Check warning occurs','line_number':1122,'multiline':False]
['text':' dtypes should match','line_number':1126,'multiline':False]
['text':' This test confirms that torch.linalg.norm's dtype argument works','line_number':1131,'multiline':False]
['text':' as expected, according to the function's documentation','line_number':1132,'multiline':False]
['text':' In these orders we are computing the 10-th power and 10-th root of numbers.','line_number':1159,'multiline':False]
['text':' We avoid them for half-precision types as it makes the tests above too badly conditioned','line_number':1160,'multiline':False]
['text':' We need torch.svdvals','line_number':1182,'multiline':False]
['text':' We need LAPACK or equivalent','line_number':1186,'multiline':False]
['text':' This test confirms torch.linalg.norm bfloat16 and half get right result.','line_number':1192,'multiline':False]
['text':' This test compares torch.linalg.vector_norm's output with','line_number':1212,'multiline':False]
['text':' torch.linalg.norm given a flattened tensor','line_number':1213,'multiline':False]
['text':' The operation does not have an identity.','line_number':1240,'multiline':False]
['text':' input size, dim, error, error message','line_number':1281,'multiline':False]
['text':' vector_norm should accept a tuple or a list for dim arg','line_number':1293,'multiline':False]
['text':' This test compares torch.linalg.norm and numpy.linalg.norm to ensure that','line_number':1301,'multiline':False]
['text':' their vector norm results match','line_number':1302,'multiline':False]
['text':' input size, p settings, dim','line_number':1320,'multiline':False]
['text':' This test compares torch.linalg.norm, torch.linalg.matrix_norm and numpy.linalg.norm to','line_number':1338,'multiline':False]
['text':' ensure that their matrix norm results match.','line_number':1339,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/54082','line_number':1340,'multiline':False]
['text':' input size, dim','line_number':1362,'multiline':False]
['text':' We need torch.svdvals','line_number':1374,'multiline':False]
['text':' We need LAPACK or equivalent','line_number':1377,'multiline':False]
['text':' smoke check that profiler returned some events','line_number':1392,'multiline':False]
['text':' test that there was no explicit copy','line_number':1394,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/53739','line_number':1400,'multiline':False]
['text':' test out= variant','line_number':1412,'multiline':False]
['text':' test empty batch sizes','line_number':1425,'multiline':False]
['text':' test non-square input','line_number':1432,'multiline':False]
['text':' test for singular input','line_number':1439,'multiline':False]
['text':' make 'a' singular','line_number':1441,'multiline':False]
['text':' Numpy may fail to converge for some BLAS backends (although this is very rare)','line_number':1446,'multiline':False]
['text':' See the discussion in https://github.com/pytorch/pytorch/issues/67675','line_number':1447,'multiline':False]
['text':' test for 0x0 matrices. NumPy doesn't work for such input, we return 0','line_number':1450,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/53739','line_number':1460,'multiline':False]
['text':' cond expects the input to be at least 2-dimensional','line_number':1468,'multiline':False]
['text':' for some norm types cond expects the input to be square','line_number':1474,'multiline':False]
['text':' if non-empty out tensor with wrong shape is passed a warning is given','line_number':1481,'multiline':False]
['text':' Trigger warning','line_number':1487,'multiline':False]
['text':' Check warning occurs','line_number':1489,'multiline':False]
['text':' dtypes should be safely castable','line_number':1493,'multiline':False]
['text':' device should match','line_number':1499,'multiline':False]
['text':' for batched input if at least one matrix in the batch is not invertible,','line_number':1507,'multiline':False]
['text':' we can't get the result for all other (possibly) invertible matrices in the batch without an explicit for loop.','line_number':1508,'multiline':False]
['text':' this should change when at::inverse works with silent errors','line_number':1509,'multiline':False]
['text':' NumPy works fine in this case because it's possible to silence the error and get the inverse matrix results','line_number':1510,'multiline':False]
['text':' possibly filled with NANs','line_number':1511,'multiline':False]
['text':' now a[1] is singular','line_number':1516,'multiline':False]
['text':' check invalid norm type','line_number':1521,'multiline':False]
['text':' This test calls torch.linalg.norm and numpy.linalg.norm with illegal arguments','line_number':1527,'multiline':False]
['text':' to ensure that they both throw errors','line_number':1528,'multiline':False]
['text':' input size, p settings, dim, error type, error regex','line_number':1547,'multiline':False]
['text':' Test complex number inputs for linalg.norm','line_number':1567,'multiline':False]
['text':' Test supported ords','line_number':1579,'multiline':False]
['text':' vector norm','line_number':1581,'multiline':False]
['text':' matrix norm','line_number':1596,'multiline':False]
['text':' Test that linal.vector_norm gives the same result as numpy when inputs','line_number':1611,'multiline':False]
['text':' contain extreme values (inf, -inf, nan)','line_number':1612,'multiline':False]
['text':' Test only inputs for which torch.linalg.matrix_norm diverges from torch.linalg.norm','line_number':1632,'multiline':False]
['text':' Test dim=None behavior','line_number':1644,'multiline':False]
['text':' Test that linal.norm gives the same result as numpy when inputs','line_number':1649,'multiline':False]
['text':' contain extreme values (inf, -inf, nan)','line_number':1650,'multiline':False]
['text':' matrix_ords 'nuc', 2, -2 are skipped currently','line_number':1657,'multiline':False]
['text':' See issue https://github.com/pytorch/pytorch/issues/71911','line_number':1658,'multiline':False]
['text':' TODO: Remove this function once the broken cases are fixed','line_number':1675,'multiline':False]
['text':' These cases are broken because of an issue with svd','line_number':1680,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/43567','line_number':1681,'multiline':False]
['text':' These cases are broken because of another issue with svd','line_number':1684,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/52633','line_number':1685,'multiline':False]
['text':' Test degenerate shape results match numpy for linalg.norm vector norms','line_number':1701,'multiline':False]
['text':' input size, dim','line_number':1722,'multiline':False]
['text':' Test degenerate shape results match numpy for linalg.norm matrix norms','line_number':1735,'multiline':False]
['text':' input size, p settings that cause error, dim','line_number':1763,'multiline':False]
['text':' slow path','line_number':1782,'multiline':False]
['text':' fast 0-norm','line_number':1787,'multiline':False]
['text':' fast 1-norm','line_number':1792,'multiline':False]
['text':' fast 2-norm','line_number':1797,'multiline':False]
['text':' fast 3-norm','line_number':1802,'multiline':False]
['text':' NumPy computes only in float64 and complex128 precisions','line_number':1809,'multiline':False]
['text':' for float32 or complex64 results might be very different from float64 or complex128','line_number':1810,'multiline':False]
['text':' for symmetric real-valued inputs eigenvalues and eigenvectors have imaginary part equal to zero','line_number':1817,'multiline':False]
['text':' unlike NumPy the result is not cast to float32 or float64 dtype in this case','line_number':1818,'multiline':False]
['text':' compare with NumPy','line_number':1825,'multiline':False]
['text':' the eigenvalues are not necessarily ordered','line_number':1826,'multiline':False]
['text':' so order of NumPy and PyTorch can be different','line_number':1827,'multiline':False]
['text':' sort NumPy output','line_number':1830,'multiline':False]
['text':' sort PyTorch output','line_number':1834,'multiline':False]
['text':' torch.argsort doesn't work with complex inputs, NumPy sorting on CPU is used instead','line_number':1835,'multiline':False]
['text':' RuntimeError: _th_sort not supported on CUDAType for ComplexDouble','line_number':1836,'multiline':False]
['text':' RuntimeError: "sorting_kernel_method_name" not implemented for 'ComplexDouble'','line_number':1837,'multiline':False]
['text':' Empty matrix','line_number':1847,'multiline':False]
['text':' Single matrix','line_number':1848,'multiline':False]
['text':' Zero batch dimension tensors','line_number':1849,'multiline':False]
['text':' 3-dim tensors','line_number':1850,'multiline':False]
['text':' 4-dim tensors','line_number':1851,'multiline':False]
['text':' for symmetric real-valued inputs eigenvalues and eigenvectors have imaginary part equal to zero','line_number':1864,'multiline':False]
['text':' compare with CPU','line_number':1873,'multiline':False]
['text':' Empty matrix','line_number':1878,'multiline':False]
['text':' Single matrix','line_number':1879,'multiline':False]
['text':' Zero batch dimension tensors','line_number':1880,'multiline':False]
['text':' 3-dim tensors','line_number':1881,'multiline':False]
['text':' 4-dim tensors','line_number':1882,'multiline':False]
['text':' For CUDA inputs only matrices of size larger than 2048x2048 actually call MAGMA library','line_number':1892,'multiline':False]
['text':' check correctness using eigendecomposition identity','line_number':1896,'multiline':False]
['text':' eig requires the input to be at least 2 dimensional tensor','line_number':1903,'multiline':False]
['text':' eig requires a square matrix','line_number':1908,'multiline':False]
['text':' if out tensor with floating dtype is passed for complex output an error is thrown','line_number':1913,'multiline':False]
['text':' The characteristic equation is p(λ) = λ^2 − 2λ + 5 = 0, with roots λ = 1±2i','line_number':1915,'multiline':False]
['text':' dtypes should be safely castable','line_number':1926,'multiline':False]
['text':' if non-empty out tensor with wrong shape is passed a warning is given','line_number':1937,'multiline':False]
['text':' Trigger warning','line_number':1942,'multiline':False]
['text':' Check warning occurs','line_number':1944,'multiline':False]
['text':' device should match','line_number':1949,'multiline':False]
['text':' NumPy computes only in float64 and complex128 precisions','line_number':1975,'multiline':False]
['text':' for float32 or complex64 results might be very different from float64 or complex128','line_number':1976,'multiline':False]
['text':' for symmetric real-valued inputs eigenvalues and eigenvectors have imaginary part equal to zero','line_number':1983,'multiline':False]
['text':' unlike NumPy the result is not cast to float32 or float64 dtype in this case','line_number':1984,'multiline':False]
['text':' compare with NumPy','line_number':1991,'multiline':False]
['text':' the eigenvalues are not necessarily ordered','line_number':1992,'multiline':False]
['text':' so order of NumPy and PyTorch can be different','line_number':1993,'multiline':False]
['text':' sort NumPy output','line_number':1996,'multiline':False]
['text':' sort PyTorch output','line_number':2000,'multiline':False]
['text':' torch.argsort doesn't work with complex inputs, NumPy sorting on CPU is used instead','line_number':2001,'multiline':False]
['text':' RuntimeError: _th_sort not supported on CUDAType for ComplexDouble','line_number':2002,'multiline':False]
['text':' RuntimeError: "sorting_kernel_method_name" not implemented for 'ComplexDouble'','line_number':2003,'multiline':False]
['text':' Empty matrix','line_number':2010,'multiline':False]
['text':' Single matrix','line_number':2011,'multiline':False]
['text':' Zero batch dimension tensors','line_number':2012,'multiline':False]
['text':' 3-dim tensors','line_number':2013,'multiline':False]
['text':' 4-dim tensors','line_number':2014,'multiline':False]
['text':' for symmetric real-valued inputs eigenvalues and eigenvectors have imaginary part equal to zero','line_number':2027,'multiline':False]
['text':' compare with CPU','line_number':2036,'multiline':False]
['text':' check out= variant','line_number':2040,'multiline':False]
['text':' check non-contiguous out','line_number':2049,'multiline':False]
['text':' Empty matrix','line_number':2057,'multiline':False]
['text':' Single matrix','line_number':2058,'multiline':False]
['text':' Zero batch dimension tensors','line_number':2059,'multiline':False]
['text':' 3-dim tensors','line_number':2060,'multiline':False]
['text':' 4-dim tensors','line_number':2061,'multiline':False]
['text':' eig requires the input to be at least 2 dimensional tensor','line_number':2070,'multiline':False]
['text':' eig requires a square matrix','line_number':2075,'multiline':False]
['text':' if out tensor with floating dtype is passed for complex output an error is thrown','line_number':2080,'multiline':False]
['text':' The characteristic equation is p(λ) = λ^2 − 2λ + 5 = 0, with roots λ = 1±2i','line_number':2082,'multiline':False]
['text':' dtypes should be safely castable','line_number':2088,'multiline':False]
['text':' if non-empty out tensor with wrong shape is passed a warning is given','line_number':2094,'multiline':False]
['text':' Trigger warning','line_number':2097,'multiline':False]
['text':' Check warning occurs','line_number':2099,'multiline':False]
['text':' device should match','line_number':2103,'multiline':False]
['text':' 'nuc' norm uses SVD, and thus its precsion is much lower than other norms.','line_number':2116,'multiline':False]
['text':' test_svd takes @precisionOverride({torch.float: 1e-4, torch.cfloat: 2e-4}),','line_number':2117,'multiline':False]
['text':' and here we are doing the same thing for nuc norm.','line_number':2118,'multiline':False]
['text':' full reduction','line_number':2141,'multiline':False]
['text':' one dimension','line_number':2149,'multiline':False]
['text':' matrix norm','line_number':2160,'multiline':False]
['text':' zero dimensions','line_number':2169,'multiline':False]
['text':' larger tensor sanity check','line_number':2178,'multiline':False]
['text':' matrix norm with non-square >2-D tensors, all combinations of reduction dims','line_number':2183,'multiline':False]
['text':' Test that torch.norm with p=+/-inf propagates NaN','line_number':2197,'multiline':False]
['text':' vector norm','line_number':2214,'multiline':False]
['text':' matrix norm','line_number':2224,'multiline':False]
['text':' Ensure torch.norm with p='fro' and p=2 give the same results for mutually supported input combinations','line_number':2234,'multiline':False]
['text':' Try full reduction','line_number':2256,'multiline':False]
['text':' Try all possible 1-D reductions','line_number':2259,'multiline':False]
['text':' Try all possible 2-D reductions','line_number':2269,'multiline':False]
['text':' too many cpu <==> device copies','line_number':2286,'multiline':False]
['text':' 2d, inner dimensions C','line_number':2306,'multiline':False]
['text':' 2d, inner dimensions Fortran','line_number':2310,'multiline':False]
['text':' 2d, inner dimensions non-contiguous','line_number':2314,'multiline':False]
['text':' 2d, all dimensions non-contiguous','line_number':2318,'multiline':False]
['text':' 3d, inner dimensions C','line_number':2324,'multiline':False]
['text':' 3d, inner dimensions Fortran','line_number':2328,'multiline':False]
['text':' 3d, inner dimensions non-contiguous','line_number':2332,'multiline':False]
['text':' 3d, all dimensions non-contiguous','line_number':2336,'multiline':False]
['text':' 4d, inner dimensions C','line_number':2342,'multiline':False]
['text':' 4d, inner dimensions Fortran','line_number':2346,'multiline':False]
['text':' 4d, inner dimensions non-contiguous','line_number':2350,'multiline':False]
['text':' 4d, all dimensions non-contiguous','line_number':2354,'multiline':False]
['text':' check if u, s, v is a SVD','line_number':2393,'multiline':False]
['text':' check if svd_lowrank produces same singular values as torch.svd','line_number':2398,'multiline':False]
['text':' actual_rank is known only for dense inputs','line_number':2406,'multiline':False]
['text':'','line_number':2407,'multiline':False]
['text':' check if pairs (u, U) and (v, V) span the same','line_number':2408,'multiline':False]
['text':' subspaces, respectively','line_number':2409,'multiline':False]
['text':' noqa: B020','line_number':2416,'multiline':False]
['text':' dense input','line_number':2423,'multiline':False]
['text':' sparse input','line_number':2429,'multiline':False]
['text':' jitting support','line_number':2434,'multiline':False]
['text':' tests linalg.svd, svd, linalg.svdvals','line_number':2445,'multiline':False]
['text':' only test cases below and skip otherwise:','line_number':2465,'multiline':False]
['text':' - backend == 'cusolver' (driver can be anything)','line_number':2466,'multiline':False]
['text':' - backend != 'cusolver' (driver should only be None)','line_number':2467,'multiline':False]
['text':' MAGMA backend doesn't work in this case','line_number':2514,'multiline':False]
['text':' test for https://github.com/pytorch/pytorch/issues/61949','line_number':2519,'multiline':False]
['text':' the problem was that tensors of incorrect size were allocated and then narrowed','line_number':2520,'multiline':False]
['text':' the following should run without errors','line_number':2524,'multiline':False]
['text':' Stacked output','line_number':2559,'multiline':False]
['text':' Actual output','line_number':2560,'multiline':False]
['text':' Equality check','line_number':2561,'multiline':False]
['text':' Correctness check','line_number':2563,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/42695','line_number':2602,'multiline':False]
['text':' test against numpy.linalg.solve','line_number':2606,'multiline':False]
['text':' no broadcasting','line_number':2608,'multiline':False]
['text':' broadcasting b','line_number':2609,'multiline':False]
['text':' broadcasting A','line_number':2610,'multiline':False]
['text':' broadcasting A & b','line_number':2611,'multiline':False]
['text':' dtypes should be safely castable','line_number':2617,'multiline':False]
['text':' device should match','line_number':2624,'multiline':False]
['text':' if out tensor with wrong shape is passed a warning is given','line_number':2631,'multiline':False]
['text':' Trigger warning','line_number':2634,'multiline':False]
['text':' Check warning occurs','line_number':2636,'multiline':False]
['text':' Compare against NumPy output','line_number':2667,'multiline':False]
['text':' NumPy uses 'gesv' LAPACK routine solving the equation A A_inv = I','line_number':2668,'multiline':False]
['text':' But in PyTorch 'gertf' + 'getrs' is used. As such, there may be some element-wise differences','line_number':2669,'multiline':False]
['text':' Additional correctness tests, check matrix*matrix_inverse == identity','line_number':2673,'multiline':False]
['text':' check the out= variant','line_number':2678,'multiline':False]
['text':' prepare the expected out tensor','line_number':2679,'multiline':False]
['text':' batched matrices: 3+ dimensional tensors, check matrix_inverse same as single-inverse for each matrix','line_number':2687,'multiline':False]
['text':' use `p` instead of -1, so that the test works for empty input as well','line_number':2690,'multiline':False]
['text':' single-inverse is done using cuSOLVER, while batched inverse is done using MAGMA','line_number':2695,'multiline':False]
['text':' individual values can be significantly different for fp32, hence rather high rtol is used','line_number':2696,'multiline':False]
['text':' the important thing is that torch_inverse passes above checks with identity','line_number':2697,'multiline':False]
['text':' helper function for testing torch.linalg.inv_ex','line_number':2702,'multiline':False]
['text':' test non-contiguous input','line_number':2717,'multiline':False]
['text':' if the input matrix is not invertible, info with positive integer is returned','line_number':2739,'multiline':False]
['text':' Now A is singular','line_number':2741,'multiline':False]
['text':' if at least one matrix in the batch is not positive definite,','line_number':2748,'multiline':False]
['text':' batched info with positive integer for the corresponding matrix is returned','line_number':2749,'multiline':False]
['text':' Now A[3] is singular','line_number':2753,'multiline':False]
['text':' Compare against NumPy output','line_number':2776,'multiline':False]
['text':' TODO: XLA doesn't raise exception','line_number':2786,'multiline':False]
['text':' inverse expects batches of square matrices as input','line_number':2789,'multiline':False]
['text':' if input is not invertible, RuntimeError is raised mentioning the first non-invertible batch','line_number':2793,'multiline':False]
['text':' TODO: XLA doesn't raise exception','line_number':2806,'multiline':False]
['text':' Test batched inverse of singular matrices reports errors without crashing (gh-51930)','line_number':2809,'multiline':False]
['text':' Testing against definition for pseudo-inverses','line_number':2824,'multiline':False]
['text':' Check out= variant','line_number':2836,'multiline':False]
['text':' Check against NumPy output','line_number':2843,'multiline':False]
['text':' Test float rcond, and specific value for each matrix','line_number':2844,'multiline':False]
['text':' Test different types of rcond tensor','line_number':2846,'multiline':False]
['text':' Test broadcasting of rcond','line_number':2849,'multiline':False]
['text':' square matrices','line_number':2860,'multiline':False]
['text':' fat matrices','line_number':2861,'multiline':False]
['text':' thin matrices','line_number':2862,'multiline':False]
['text':' zero numel matrices','line_number':2863,'multiline':False]
['text':' Check hermitian = True','line_number':2869,'multiline':False]
['text':' square matrices','line_number':2870,'multiline':False]
['text':' zero numel square matrices','line_number':2871,'multiline':False]
['text':' pinv requires at least 2D tensor','line_number':2881,'multiline':False]
['text':' if non-empty out tensor with wrong shape is passed a warning is given','line_number':2886,'multiline':False]
['text':' Trigger warning','line_number':2890,'multiline':False]
['text':' Check warning occurs','line_number':2892,'multiline':False]
['text':' dtypes of out and input should be safely castable','line_number':2896,'multiline':False]
['text':' device of out and input should match','line_number':2902,'multiline':False]
['text':' device of rcond and input should match','line_number':2908,'multiline':False]
['text':' rcond can't be complex','line_number':2914,'multiline':False]
['text':' atol can't be complex','line_number':2919,'multiline':False]
['text':' rtol can't be complex','line_number':2924,'multiline':False]
['text':' inv expects batches of square matrices as input','line_number':2933,'multiline':False]
['text':' inv requires the input to be at least 2 dimensional tensor','line_number':2938,'multiline':False]
['text':' if input is not invertible, RuntimeError is raised mentioning the first non-invertible batch','line_number':2943,'multiline':False]
['text':' dtypes should match','line_number':2953,'multiline':False]
['text':' device should match','line_number':2959,'multiline':False]
['text':' if out tensor with wrong shape is passed a warning is given','line_number':2966,'multiline':False]
['text':' Trigger warning','line_number':2970,'multiline':False]
['text':' Check warning occurs','line_number':2972,'multiline':False]
['text':' if out tensor in batched column major format but with wrong a warning is given','line_number':2976,'multiline':False]
['text':' Trigger warning','line_number':2983,'multiline':False]
['text':' Check warning occurs','line_number':2985,'multiline':False]
['text':' Correctness test','line_number':3007,'multiline':False]
['text':' Check against NumPy','line_number':3016,'multiline':False]
['text':' test against numpy.linalg.solve','line_number':3040,'multiline':False]
['text':' broadcasting with 0 batch dim','line_number':3041,'multiline':False]
['text':' broadcasting with 0 batch dim','line_number':3042,'multiline':False]
['text':' broadcasting B','line_number':3043,'multiline':False]
['text':' broadcasting A','line_number':3044,'multiline':False]
['text':' broadcasting A & B','line_number':3045,'multiline':False]
['text':' check the out= variant','line_number':3059,'multiline':False]
['text':' Check for empty inputs. NumPy does not work for these cases.','line_number':3074,'multiline':False]
['text':' tensorsolve expects the input that can be reshaped to a square matrix','line_number':3084,'multiline':False]
['text':' if non-empty out tensor with wrong shape is passed a warning is given','line_number':3091,'multiline':False]
['text':' Trigger warning','line_number':3095,'multiline':False]
['text':' Check warning occurs','line_number':3097,'multiline':False]
['text':' dtypes should be safely castable','line_number':3101,'multiline':False]
['text':' device should match','line_number':3106,'multiline':False]
['text':' check the out= variant','line_number':3126,'multiline':False]
['text':' compare to NumPy output','line_number':3132,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/53739','line_number':3143,'multiline':False]
['text':' Check for empty inputs. NumPy does not work for these cases.','line_number':3149,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/53739','line_number':3154,'multiline':False]
['text':' tensorinv requires the input to satisfy','line_number':3161,'multiline':False]
['text':' prod(a.shape[ind:]) == prod(a.shape[:ind])','line_number':3162,'multiline':False]
['text':' if non-empty out tensor with wrong shape is passed a warning is given','line_number':3173,'multiline':False]
['text':' Trigger warning','line_number':3177,'multiline':False]
['text':' Check warning occurs','line_number':3179,'multiline':False]
['text':' dtypes should be safely castable','line_number':3183,'multiline':False]
['text':' device should match','line_number':3188,'multiline':False]
['text':' test for invalid shape','line_number':3195,'multiline':False]
['text':' test for invalid ind','line_number':3199,'multiline':False]
['text':' test for invalid out tensor','line_number':3203,'multiline':False]
['text':' Now `a` is singular','line_number':3215,'multiline':False]
['text':' test for non-invertible input','line_number':3220,'multiline':False]
['text':' Compare with numpy','line_number':3226,'multiline':False]
['text':' Test out variant','line_number':3237,'multiline':False]
['text':' Empty','line_number':3242,'multiline':False]
['text':' Contiguous','line_number':3247,'multiline':False]
['text':' 0 strided','line_number':3252,'multiline':False]
['text':' 2 strided','line_number':3256,'multiline':False]
['text':' check against NumPy','line_number':3318,'multiline':False]
['text':' hermitian flag for NumPy was added in 1.14.0','line_number':3325,'multiline':False]
['text':' check out= variant','line_number':3332,'multiline':False]
['text':' Check against NumPy output','line_number':3350,'multiline':False]
['text':' Test float tol, and specific value for each matrix','line_number':3351,'multiline':False]
['text':' Test different types of tol tensor','line_number':3353,'multiline':False]
['text':' Test broadcasting of tol','line_number':3356,'multiline':False]
['text':' creates a matrix with singular values rank=n and singular values in range [2/3, 3/2]','line_number':3379,'multiline':False]
['text':' the singular values are 1 + 1/2, 1 - 1/3, 1 + 1/4, 1 - 1/5, ...','line_number':3380,'multiline':False]
['text':' test float and tensor variants','line_number':3384,'multiline':False]
['text':' using rtol (relative tolerance) takes into account the largest singular value (1.5 in this case)','line_number':3386,'multiline':False]
['text':' there are 2 singular values above 1.5*0.81 = 1.215','line_number':3388,'multiline':False]
['text':' atol is used directly to compare with singular values','line_number':3390,'multiline':False]
['text':' there are 7 singular values above 0.81','line_number':3392,'multiline':False]
['text':' when both are specified the maximum tolerance is used','line_number':3394,'multiline':False]
['text':' there are 2 singular values above max(0.81, 1.5*0.81)','line_number':3396,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/75391','line_number':3400,'multiline':False]
['text':' NumPy doesn't work for input with no elements','line_number':3405,'multiline':False]
['text':' dtypes should be safely castable','line_number':3440,'multiline':False]
['text':' device should match','line_number':3446,'multiline':False]
['text':' if out tensor with wrong shape is passed a warning is given','line_number':3453,'multiline':False]
['text':' Trigger warning','line_number':3456,'multiline':False]
['text':' Check warning occurs','line_number':3458,'multiline':False]
['text':' This tests only the cases where torch.chain_matmul differs from torch.linalg.multi_dot which this is an "alias" for.','line_number':3478,'multiline':False]
['text':' chain_matmul accepts a single input tensor while multi_dot does not','line_number':3480,'multiline':False]
['text':' chain_matmul expects all tensors to be 2D whereas multi_dot allows the first and last tensors to','line_number':3486,'multiline':False]
['text':' be either 1D or 2D','line_number':3487,'multiline':False]
['text':' test for inputs with empty dimensions','line_number':3501,'multiline':False]
['text':' test variable output shapes','line_number':3511,'multiline':False]
['text':' test multiple input tensors','line_number':3518,'multiline':False]
['text':' test large tensors','line_number':3522,'multiline':False]
['text':' Check0: Q[-2:] = (m, n_columns), R[-2:] = (n_columns, n)','line_number':3563,'multiline':False]
['text':' Check1: A = QR','line_number':3574,'multiline':False]
['text':' Check2: A = QR (with out)','line_number':3577,'multiline':False]
['text':' Check3: Q == Q_out, R == R_out','line_number':3584,'multiline':False]
['text':' Check4: Q^{T}Q = I, triu(R) = R','line_number':3588,'multiline':False]
['text':' Empty Tensors','line_number':3593,'multiline':False]
['text':' Batched empty Tensors','line_number':3594,'multiline':False]
['text':' Single matrix','line_number':3595,'multiline':False]
['text':' 3-dim Tensors','line_number':3596,'multiline':False]
['text':' 4-dim Tensors','line_number':3597,'multiline':False]
['text':' empty','line_number':3611,'multiline':False]
['text':' empty','line_number':3612,'multiline':False]
['text':'','line_number':3622,'multiline':False]
['text':' for mode='r' we need a special logic because numpy returns only r','line_number':3623,'multiline':False]
['text':' check that q is empty','line_number':3626,'multiline':False]
['text':' check r','line_number':3630,'multiline':False]
['text':' torch.linalg.qr(mode='r') returns only 'r' and discards 'q', but','line_number':3637,'multiline':False]
['text':' without 'q' you cannot compute the backward pass. Check that','line_number':3638,'multiline':False]
['text':' linalg_qr_backward complains cleanly in that case.','line_number':3639,'multiline':False]
['text':' empty tensor','line_number':3642,'multiline':False]
['text':'','line_number':3647,'multiline':False]
['text':' for mode='r' we need a special logic because numpy returns only r','line_number':3687,'multiline':False]
['text':' check that q is empty','line_number':3690,'multiline':False]
['text':' check r','line_number':3694,'multiline':False]
['text':' Check that the other variations for opt_einsum work too','line_number':3715,'multiline':False]
['text':' Test cases from https://gist.github.com/rockt/15ee013889d65342088e9260a377dc8f','line_number':3731,'multiline':False]
['text':' Vector operations','line_number':3744,'multiline':False]
['text':' sum','line_number':3745,'multiline':False]
['text':' dot','line_number':3746,'multiline':False]
['text':' vector element-wisem mul','line_number':3747,'multiline':False]
['text':' outer','line_number':3748,'multiline':False]
['text':' Matrix operations','line_number':3750,'multiline':False]
['text':' transpose','line_number':3751,'multiline':False]
['text':' row sum','line_number':3752,'multiline':False]
['text':' col sum','line_number':3753,'multiline':False]
['text':' matrix element-wise mul','line_number':3754,'multiline':False]
['text':' matrix vector multiplication','line_number':3755,'multiline':False]
['text':' matmul','line_number':3756,'multiline':False]
['text':' matrix outer product','line_number':3757,'multiline':False]
['text':' Tensor operations','line_number':3759,'multiline':False]
['text':' batch matmul','line_number':3760,'multiline':False]
['text':' tensor matrix contraction','line_number':3761,'multiline':False]
['text':' tensor matrix contraction','line_number':3762,'multiline':False]
['text':' tensor tensor contraction','line_number':3763,'multiline':False]
['text':' tensor matrix contraction with double indices','line_number':3764,'multiline':False]
['text':' tensor matrix contraction with double indices','line_number':3765,'multiline':False]
['text':' non contiguous','line_number':3766,'multiline':False]
['text':' non contiguous with double indices','line_number':3767,'multiline':False]
['text':' Test diagonals','line_number':3769,'multiline':False]
['text':' trace','line_number':3770,'multiline':False]
['text':' diagonal','line_number':3771,'multiline':False]
['text':' non-contiguous trace','line_number':3772,'multiline':False]
['text':' Test ellipsis','line_number':3775,'multiline':False]
['text':' torch.bilinear with noncontiguous tensors','line_number':3783,'multiline':False]
['text':' with strided tensors','line_number':3789,'multiline':False]
['text':' test multiple inputs','line_number':3792,'multiline':False]
['text':' torch.bilinear with noncontiguous tensors','line_number':3815,'multiline':False]
['text':' how many tests to generate','line_number':3834,'multiline':False]
['text':' how many labels available','line_number':3835,'multiline':False]
['text':' min and max number of operands per test','line_number':3836,'multiline':False]
['text':' min and max number of dimensions per operand','line_number':3837,'multiline':False]
['text':' min and max size of each dimension','line_number':3838,'multiline':False]
['text':' max number of dimensions for the output','line_number':3839,'multiline':False]
['text':' controls if labels can be repeated for diagonals','line_number':3840,'multiline':False]
['text':' probability of including ellipsis in operand','line_number':3841,'multiline':False]
['text':' probability of turning some dim sizes 1 for broadcasting','line_number':3842,'multiline':False]
['text':' Select a subset of labels for this test and give them random sizes','line_number':3856,'multiline':False]
['text':' create random input operands','line_number':3867,'multiline':False]
['text':' turn some dimensions to size 1 for testing broadcasting','line_number':3875,'multiline':False]
['text':' include ellipsis if not all dimensions were assigned a label already','line_number':3883,'multiline':False]
['text':' again, turn some dimensions to size 1 for broadcasting','line_number':3888,'multiline':False]
['text':' NumPy has a bug with the sublist format so for now we compare PyTorch sublist','line_number':3898,'multiline':False]
['text':' implementation against the equation format implementation of NumPy','line_number':3899,'multiline':False]
['text':' see https://github.com/numpy/numpy/issues/10926','line_number':3900,'multiline':False]
['text':' test equation format','line_number':3903,'multiline':False]
['text':' test sublist format','line_number':3907,'multiline':False]
['text':' generate an explicit output','line_number':3911,'multiline':False]
['text':' test equation format with explicit output','line_number':3919,'multiline':False]
['text':' test sublist format with explicit output','line_number':3923,'multiline':False]
['text':' Test equation variantions','line_number':3936,'multiline':False]
['text':' Test tensors with 0 size dimensions','line_number':3948,'multiline':False]
['text':' Test broadcasting','line_number':3954,'multiline':False]
['text':' Test ellipsis broadcasting','line_number':3958,'multiline':False]
['text':' expand means that we generate a batch of matrices with a stride of zero in the batch dimension','line_number':4008,'multiline':False]
['text':' We just expand on the batch size','line_number':4011,'multiline':False]
['text':' If expand_a or expand_b, we'll expand them to the correct size later','line_number':4018,'multiline':False]
['text':' A = L from PLU','line_number':4027,'multiline':False]
['text':' A = U from PLU','line_number':4030,'multiline':False]
['text':' B may be expanded','line_number':4065,'multiline':False]
['text':' Tolerances dictated by widest acceptable range on CPU before failure','line_number':4071,'multiline':False]
['text':' This exercises the API + BLAS CPU + batched cuBLAS','line_number':4078,'multiline':False]
['text':' Magma needed for the PLU decomposition','line_number':4090,'multiline':False]
['text':' Exercises magma and cublas','line_number':4095,'multiline':False]
['text':' create positive definite matrix','line_number':4143,'multiline':False]
['text':' Stacked output','line_number':4182,'multiline':False]
['text':' Actual output','line_number':4185,'multiline':False]
['text':' Equality check','line_number':4186,'multiline':False]
['text':' test empty input','line_number':4206,'multiline':False]
['text':' test zero batch case','line_number':4212,'multiline':False]
['text':' test batched A case','line_number':4226,'multiline':False]
['text':' test batched b case','line_number':4239,'multiline':False]
['text':' test against scipy.linalg.solve_triangular','line_number':4279,'multiline':False]
['text':' no broadcasting','line_number':4280,'multiline':False]
['text':' broadcasting b','line_number':4281,'multiline':False]
['text':' broadcasting A','line_number':4282,'multiline':False]
['text':' broadcasting A & b','line_number':4283,'multiline':False]
['text':' dtypes should be safely castable','line_number':4289,'multiline':False]
['text':' device should match','line_number':4302,'multiline':False]
['text':' Trigger the WARN_ONCE deprecation error','line_number':4314,'multiline':False]
['text':' if out tensor with wrong shape is passed a warning is given','line_number':4317,'multiline':False]
['text':' Trigger warning','line_number':4321,'multiline':False]
['text':' Check warning occurs','line_number':4323,'multiline':False]
['text':' Scale the atol with the size of the matrix','line_number':4333,'multiline':False]
['text':' test x @ y','line_number':4341,'multiline':False]
['text':' test out','line_number':4347,'multiline':False]
['text':' Integer matmul just supported on CPU','line_number':4379,'multiline':False]
['text':' Integer matmul just supported on CPU','line_number':4389,'multiline':False]
['text':' Integer matmul just supported on CPU','line_number':4399,'multiline':False]
['text':' 4GB should do, but we run tests in parallel in CI, so let's be generous','line_number':4409,'multiline':False]
['text':' Should not create an intermediary tensor of size [1024, 1024, 65536] (256GB of memory) and OOM','line_number':4416,'multiline':False]
['text':' 4GB should do, but we run tests in parallel in CI, so let's be generous','line_number':4419,'multiline':False]
['text':' Should not create an intermediary tensor of size [1024, 1024, 65536] (256GB of memory) and OOM','line_number':4426,'multiline':False]
['text':' test for broadcastable inputs','line_number':4454,'multiline':False]
['text':' big enough to exercise vectorized path','line_number':4483,'multiline':False]
['text':' collapse non-dim dimensions.','line_number':4488,'multiline':False]
['text':' clip','line_number':4491,'multiline':False]
['text':' renormalize','line_number':4495,'multiline':False]
['text':' note that the axis fed to torch.renorm is different (2~=1)','line_number':4499,'multiline':False]
['text':' Q is of size m x m','line_number':4527,'multiline':False]
['text':' if tau is all zeros then the implicit matrix Q is the identity matrix','line_number':4548,'multiline':False]
['text':' so the actual result should be C_right in this case','line_number':4549,'multiline':False]
['text':' input1 size, input2 size, input3 size, error regex','line_number':4564,'multiline':False]
['text':' mm, addmm','line_number':4592,'multiline':False]
['text':' mv, addmv','line_number':4606,'multiline':False]
['text':' bmm, baddbmm','line_number':4617,'multiline':False]
['text':' Issue #33467','line_number':4629,'multiline':False]
['text':' Issue #33467','line_number':4630,'multiline':False]
['text':' addbmm','line_number':4632,'multiline':False]
['text':' matmul','line_number':4639,'multiline':False]
['text':' dot','line_number':4648,'multiline':False]
['text':' common case','line_number':4660,'multiline':False]
['text':' Ntrans_B has ld >> rows','line_number':4665,'multiline':False]
['text':' trans_A has ld >> rows','line_number':4670,'multiline':False]
['text':' large tensor dim > 65535','line_number':4675,'multiline':False]
['text':' This test is disabled on CUDA 9 due to:','line_number':4687,'multiline':False]
['text':' See: https://github.com/pytorch/pytorch/issues/31006','line_number':4688,'multiline':False]
['text':' TODO (@zasdfgbnm): this causes the following error on test','line_number':4690,'multiline':False]
['text':' TestTorchDeviceTypeXLA.test_blas_alpha_beta_empty_xla_bfloat16:','line_number':4691,'multiline':False]
['text':'','line_number':4692,'multiline':False]
['text':'   RuntimeError: _th_equal not supported on CPUType for BFloat16','line_number':4693,'multiline':False]
['text':' ensure beta is respected','line_number':4695,'multiline':False]
['text':' torch.addmm','line_number':4712,'multiline':False]
['text':' These functions should work correctly with NaN filled outputs,','line_number':4723,'multiline':False]
['text':' but need special handling, see [NOTE: cpu_zero]','line_number':4724,'multiline':False]
['text':' torch.mv','line_number':4730,'multiline':False]
['text':' torch.mm','line_number':4737,'multiline':False]
['text':' torch.bmm','line_number':4742,'multiline':False]
['text':' not supported by CUBLAS','line_number':4748,'multiline':False]
['text':' This would previously fail if the allocated output had NaNs, see:','line_number':4750,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/31663 and [NOTE: cpu_zero]','line_number':4751,'multiline':False]
['text':' full reduction','line_number':4763,'multiline':False]
['text':' torch.linalg.qr does not work correctly for zero batch dimension tensors','line_number':4802,'multiline':False]
['text':' see https://github.com/pytorch/pytorch/issues/50576','line_number':4803,'multiline':False]
['text':' if tau is empty and A is not the result should be a matrix with ones on the diagonal','line_number':4809,'multiline':False]
['text':' Empty matrix','line_number':4823,'multiline':False]
['text':' Single matrix','line_number':4824,'multiline':False]
['text':' Zero batch dimension tensors','line_number':4825,'multiline':False]
['text':' 3-dim tensors','line_number':4826,'multiline':False]
['text':' 4-dim tensors','line_number':4827,'multiline':False]
['text':' input1 size, input2 size, error regex','line_number':4835,'multiline':False]
['text':' if out tensor with wrong shape is passed a warning is given','line_number':4846,'multiline':False]
['text':' Trigger warning','line_number':4851,'multiline':False]
['text':' Check warning occurs','line_number':4853,'multiline':False]
['text':' dtypes should be safely castable','line_number':4857,'multiline':False]
['text':' device of out and input should match','line_number':4866,'multiline':False]
['text':' device of tau and input should match','line_number':4872,'multiline':False]
['text':' Tests torch.lu','line_number':4883,'multiline':False]
['text':'       torch.linalg.lu_factor','line_number':4884,'multiline':False]
['text':'       torch.linalg.lu_factor_ex','line_number':4885,'multiline':False]
['text':'       torch.lu_unpack','line_number':4886,'multiline':False]
['text':'       torch.linalg.lu_solve','line_number':4887,'multiline':False]
['text':'       torch.linalg.solve','line_number':4888,'multiline':False]
['text':' It may or may not throw as the LU decomposition without pivoting','line_number':4897,'multiline':False]
['text':' may still succeed for singular matrices','line_number':4898,'multiline':False]
['text':' Vector case when left = False is not allowed','line_number':4924,'multiline':False]
['text':' Test linalg.lu_solve. It does not support vectors as rhs','line_number':4933,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/74045#issuecomment-1112304913','line_number':4934,'multiline':False]
['text':' Test linalg.solve','line_number':4944,'multiline':False]
['text':' Non pivoting just implemented for CUDA','line_number':4956,'multiline':False]
['text':' Just do one of them on singular matrices','line_number':4962,'multiline':False]
['text':' Reproducer of a magma bug,','line_number':4967,'multiline':False]
['text':' see https://bitbucket.org/icl/magma/issues/13/getrf_batched-kernel-produces-nans-on','line_number':4968,'multiline':False]
['text':' This is also a bug in cuSOLVER < 11.3','line_number':4969,'multiline':False]
['text':' Info should be positive for rank deficient matrices','line_number':4975,'multiline':False]
['text':' Error checking, no pivoting variant on CPU','line_number':4980,'multiline':False]
['text':' Shapes to exercise all the paths','line_number':5009,'multiline':False]
['text':' Square tests','line_number':5033,'multiline':False]
['text':' This should run without issues','line_number':5038,'multiline':False]
['text':' Rectangular tests','line_number':5054,'multiline':False]
['text':' This should run without issues','line_number':5059,'multiline':False]
['text':' Rectangular tests','line_number':5071,'multiline':False]
['text':' This should run without issues','line_number':5076,'multiline':False]
['text':' check that onces flags are unset, Nones are returned','line_number':5098,'multiline':False]
['text':' Check convergence','line_number':5136,'multiline':False]
['text':' Check B-orthogonality','line_number':5139,'multiline':False]
['text':' Check block equation','line_number':5143,'multiline':False]
['text':' check dense input','line_number':5156,'multiline':False]
['text':' skip tests that are known to fail with the basic','line_number':5165,'multiline':False]
['text':' LOBPCG method due to calling cholesky on singular','line_number':5166,'multiline':False]
['text':' input','line_number':5167,'multiline':False]
['text':' classical eigenvalue problem, smallest eigenvalues','line_number':5173,'multiline':False]
['text':' classical eigenvalue problem, largest eigenvalues','line_number':5182,'multiline':False]
['text':' generalized eigenvalue problem, smallest eigenvalues','line_number':5188,'multiline':False]
['text':' generalized eigenvalue problem, largest eigenvalues','line_number':5192,'multiline':False]
['text':' check sparse input','line_number':5197,'multiline':False]
['text':' skip tests that are known to fail with the basic LOBCG','line_number':5204,'multiline':False]
['text':' method due to insufficient accuracy','line_number':5205,'multiline':False]
['text':' classical eigenvalue problem, smallest eigenvalues','line_number':5214,'multiline':False]
['text':' classical eigenvalue problem, largest eigenvalues','line_number':5219,'multiline':False]
['text':' generalized eigenvalue problem, smallest eigenvalues','line_number':5224,'multiline':False]
['text':' generalized eigenvalue problem, largest eigenvalues','line_number':5228,'multiline':False]
['text':' size of the square matrix','line_number':5273,'multiline':False]
['text':' the number of requested eigenpairs','line_number':5274,'multiline':False]
['text':' tol for scipy lobpcg will be choosed so that the number of','line_number':5289,'multiline':False]
['text':' iterations will be equal or very close to pytorch lobpcg','line_number':5290,'multiline':False]
['text':' (that is around 170-180)','line_number':5291,'multiline':False]
['text':' Standard eigenvalue problem','line_number':5293,'multiline':False]
['text':' std','line_number':5304,'multiline':False]
['text':' std','line_number':5305,'multiline':False]
['text':' Generalized eigenvalue problem','line_number':5309,'multiline':False]
['text':' general','line_number':5324,'multiline':False]
['text':' general','line_number':5325,'multiline':False]
['text':' Timings','line_number':5329,'multiline':False]
['text':' Handling of very small tolerence','line_number':5369,'multiline':False]
['text':' have to use torch.randn(...).to(bfloat16) instead of','line_number':5462,'multiline':False]
['text':' torch.randn(..., dtype=bfloat16). randn does not support','line_number':5463,'multiline':False]
['text':' bfloat16 yet.','line_number':5464,'multiline':False]
['text':' "*0.2" to reduce errors for low precision','line_number':5465,'multiline':False]
['text':' to reduce errors for low precision','line_number':5472,'multiline':False]
['text':' 0d','line_number':5475,'multiline':False]
['text':' to reduce errors for low precision','line_number':5476,'multiline':False]
['text':' 1d','line_number':5477,'multiline':False]
['text':' this initialization reduces errors for low precision for broadcasted matrices','line_number':5479,'multiline':False]
['text':' by making sure that intermediate and result values are exactly representable','line_number':5480,'multiline':False]
['text':' in low precision type','line_number':5481,'multiline':False]
['text':' 2d','line_number':5483,'multiline':False]
['text':' Test beta=0, t=nan','line_number':5489,'multiline':False]
['text':' tests (o, s)*(s).  o is output size, s is summed size.','line_number':5498,'multiline':False]
['text':' vector-shaped bias and beta=1 result in epilogue fusion in CUDA','line_number':5530,'multiline':False]
['text':' Test 0-strided','line_number':5534,'multiline':False]
['text':' Test beta=0, M=nan','line_number':5540,'multiline':False]
['text':' Test transpose','line_number':5546,'multiline':False]
['text':' use vector V instead of matrix M for epilogue fusion in CUDA (doesn't depend on t1)','line_number':5559,'multiline':False]
['text':' just check for no overflow on ROCM','line_number':5616,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/45724','line_number':5663,'multiline':False]
['text':' Checking out variant','line_number':5703,'multiline':False]
['text':' NOTE: We're just exercising terrible failures here.','line_number':5710,'multiline':False]
['text':' Scales and zeros for the same q-group should be contiguous, so we can','line_number':5812,'multiline':False]
['text':' load as a 32-bit word','line_number':5813,'multiline':False]
['text':' bfloat16 doesn't have sufficient precision to pass this test','line_number':5907,'multiline':False]
['text':' helper function','line_number':5913,'multiline':False]
['text':' contiguous case','line_number':5927,'multiline':False]
['text':' non contiguous case 1','line_number':5935,'multiline':False]
['text':' non contiguous case 2','line_number':5943,'multiline':False]
['text':' non contiguous case 3','line_number':5951,'multiline':False]
['text':' test with zero stride','line_number':5959,'multiline':False]
['text':' explicitly exercise the _out variant in torch.mm().','line_number':5967,'multiline':False]
['text':' contiguous case','line_number':5968,'multiline':False]
['text':' explicitly exercise the _out variant in torch.mm().','line_number':5977,'multiline':False]
['text':' non contiguous case 3','line_number':5978,'multiline':False]
['text':' test broadcasting','line_number':6039,'multiline':False]
['text':' Tests strided view case with stride smaller than corresponding dimension size','line_number':6053,'multiline':False]
['text':' noqa: E731','line_number':6059,'multiline':False]
['text':' noqa: E731','line_number':6060,'multiline':False]
['text':' noqa: E731','line_number':6063,'multiline':False]
['text':' cuBLAS does not guarantee BFloat16 support on SM < 53.','line_number':6072,'multiline':False]
['text':' So on PyTorch, we consider BFloat16 support on SM < 53 as','line_number':6073,'multiline':False]
['text':' undefined bahavior','line_number':6074,'multiline':False]
['text':' transposed tensors','line_number':6098,'multiline':False]
['text':' broadcasting tensors','line_number':6105,'multiline':False]
['text':' zero-sized tensors','line_number':6112,'multiline':False]
['text':' check that mixed arguments are rejected','line_number':6132,'multiline':False]
['text':' cuBLAS does not guarantee BFloat16 support on SM < 53.','line_number':6184,'multiline':False]
['text':' So on PyTorch, we consider BFloat16 support on SM < 53 as','line_number':6185,'multiline':False]
['text':' undefined bahavior','line_number':6186,'multiline':False]
['text':' 43 vs 43.75','line_number':6195,'multiline':False]
['text':' transposed tensors','line_number':6213,'multiline':False]
['text':' broadcasting tensors','line_number':6225,'multiline':False]
['text':' zero-sized tensors','line_number':6236,'multiline':False]
['text':' cuBLAS does not guarantee BFloat16 support on SM < 53.','line_number':6257,'multiline':False]
['text':' So on PyTorch, we consider BFloat16 support on SM < 53 as','line_number':6258,'multiline':False]
['text':' undefined bahavior','line_number':6259,'multiline':False]
['text':' transposed tensors','line_number':6283,'multiline':False]
['text':' broadcasting tensors','line_number':6294,'multiline':False]
['text':' zero-sized tensors','line_number':6304,'multiline':False]
['text':' Testing against definition for pseudo-inverses','line_number':6327,'multiline':False]
['text':' square matrices','line_number':6338,'multiline':False]
['text':' fat matrices','line_number':6339,'multiline':False]
['text':' thin matrices','line_number':6340,'multiline':False]
['text':' zero numel matrices','line_number':6341,'multiline':False]
['text':' Test inverse and pseudo-inverse for invertible matrix','line_number':6345,'multiline':False]
['text':' test linear combination','line_number':6395,'multiline':False]
['text':' check `out=` version','line_number':6404,'multiline':False]
['text':' Regression test for https://github.com/pytorch/pytorch/issues/94124','line_number':6427,'multiline':False]
['text':' this tests https://github.com/pytorch/pytorch/issues/80948','line_number':6437,'multiline':False]
['text':' check 1x1 matrices','line_number':6461,'multiline':False]
['text':' Check small batches','line_number':6475,'multiline':False]
['text':' Check large batches','line_number':6482,'multiline':False]
['text':' check zero matrix','line_number':6494,'multiline':False]
['text':' deg 1','line_number':6517,'multiline':False]
['text':' deg 2','line_number':6518,'multiline':False]
['text':' deg 4','line_number':6519,'multiline':False]
['text':' deg 8','line_number':6520,'multiline':False]
['text':' deg 12','line_number':6521,'multiline':False]
['text':' deg 18','line_number':6522,'multiline':False]
['text':' if torch.double','line_number':6524,'multiline':False]
['text':' deg 1','line_number':6526,'multiline':False]
['text':' deg 2','line_number':6527,'multiline':False]
['text':' deg 4','line_number':6528,'multiline':False]
['text':' deg 8','line_number':6529,'multiline':False]
['text':' deg 12','line_number':6530,'multiline':False]
['text':' deg 18','line_number':6531,'multiline':False]
['text':' generate input','line_number':6534,'multiline':False]
['text':' test simple analytic whatever norm generated','line_number':6544,'multiline':False]
['text':' generate norms to test different degree expansions','line_number':6555,'multiline':False]
['text':' matrices to equal norm','line_number':6561,'multiline':False]
['text':' single matrix','line_number':6575,'multiline':False]
['text':' small batch of matrices','line_number':6583,'multiline':False]
['text':' large batch of matrices','line_number':6591,'multiline':False]
['text':' small batch of matrices','line_number':6622,'multiline':False]
['text':' large batch of matrices','line_number':6628,'multiline':False]
['text':' deg 1','line_number':6682,'multiline':False]
['text':' deg 2','line_number':6683,'multiline':False]
['text':' deg 4','line_number':6684,'multiline':False]
['text':' deg 8','line_number':6685,'multiline':False]
['text':' deg 12','line_number':6686,'multiline':False]
['text':' deg 18','line_number':6687,'multiline':False]
['text':' if torch.double','line_number':6689,'multiline':False]
['text':' deg 1','line_number':6691,'multiline':False]
['text':' deg 2','line_number':6692,'multiline':False]
['text':' deg 4','line_number':6693,'multiline':False]
['text':' deg 8','line_number':6694,'multiline':False]
['text':' deg 12','line_number':6695,'multiline':False]
['text':' deg 18','line_number':6696,'multiline':False]
['text':' generate norms to test different degree expansions','line_number':6699,'multiline':False]
['text':' single matrix','line_number':6715,'multiline':False]
['text':' small batch of matrices','line_number':6721,'multiline':False]
['text':' large batch of matrices','line_number':6727,'multiline':False]
['text':' mat_chars denotes matrix characteristics','line_number':6742,'multiline':False]
['text':' possible values are: hermitian, hermitian_psd, hermitian_pd, singular, non_singular','line_number':6743,'multiline':False]
['text':' test out=variant','line_number':6769,'multiline':False]
['text':' slogdet requires the input to be a square matrix or batch of square matrices','line_number':6789,'multiline':False]
['text':' slogdet requires the input to be at least 2 dimensional tensor','line_number':6794,'multiline':False]
['text':' if non-empty out tensor with wrong shape is passed a warning is given','line_number':6803,'multiline':False]
['text':' Trigger warning','line_number':6809,'multiline':False]
['text':' Check warning occurs','line_number':6811,'multiline':False]
['text':' device should match','line_number':6815,'multiline':False]
['text':' FIXME One of the backends of lu_factor fails in windows. I haven't investigated which or why','line_number':6823,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/75225','line_number':6824,'multiline':False]
['text':' Test det','line_number':6842,'multiline':False]
['text':' Test slogdet','line_number':6846,'multiline':False]
['text':' Compare the overall value rather than individual parts because of','line_number':6847,'multiline':False]
['text':' precision issues when det is near zero.','line_number':6848,'multiline':False]
['text':' Test logdet','line_number':6854,'multiline':False]
['text':' Compare logdet against our own pytorch slogdet because they should','line_number':6855,'multiline':False]
['text':' be consistent, while it may behave slightly differently with other','line_number':6856,'multiline':False]
['text':' slogdet implementations when det is near zero due to precision','line_number':6857,'multiline':False]
['text':' issues.','line_number':6858,'multiline':False]
['text':' Testing bug in #34061 (https://github.com/pytorch/pytorch/issues/34061)','line_number':6867,'multiline':False]
['text':' skip singular','line_number':6881,'multiline':False]
['text':' dim 0','line_number':6896,'multiline':False]
['text':' dim 1','line_number':6900,'multiline':False]
['text':' dim 0','line_number':6908,'multiline':False]
['text':' dim 1','line_number':6912,'multiline':False]
['text':' dim 0','line_number':6926,'multiline':False]
['text':' dim 1','line_number':6932,'multiline':False]
['text':' For matrices with values i.i.d. with 0 mean, unit variance, and','line_number':6940,'multiline':False]
['text':' subexponential tail, we have:','line_number':6941,'multiline':False]
['text':'   E[log det(A^2)] \approx log((n-1)!)','line_number':6942,'multiline':False]
['text':'','line_number':6943,'multiline':False]
['text':' Notice:','line_number':6944,'multiline':False]
['text':'   log Var[det(A)] = log E[det(A^2)] >= E[log det(A^2)]','line_number':6945,'multiline':False]
['text':'','line_number':6946,'multiline':False]
['text':' So:','line_number':6947,'multiline':False]
['text':'   stddev[det(A)] >= sqrt( (n-1)! )','line_number':6948,'multiline':False]
['text':'','line_number':6949,'multiline':False]
['text':' We use this as an intuitive guideline to scale random generated','line_number':6950,'multiline':False]
['text':' matrices so our closeness tests can work more robustly:','line_number':6951,'multiline':False]
['text':'   scale by sqrt( (n-1)! )^(-1/n) = ( (n-1)! )^(-1/(2n))','line_number':6952,'multiline':False]
['text':'','line_number':6953,'multiline':False]
['text':' source: https://arxiv.org/pdf/1112.0752.pdf','line_number':6954,'multiline':False]
['text':' TODO: technically we need subexponential distn for this to hold,','line_number':6956,'multiline':False]
['text':'       but we mostly use gaussian entries below. Consider switching','line_number':6957,'multiline':False]
['text':'       to Chi-sq if this turns out not stable enough, since Chi-sq','line_number':6958,'multiline':False]
['text':'       is easy enough to sample from.','line_number':6959,'multiline':False]
['text':' symmetric psd','line_number':6966,'multiline':False]
['text':' symmetric pd','line_number':6968,'multiline':False]
['text':' symmetric','line_number':6971,'multiline':False]
['text':' non-contiguous','line_number':6977,'multiline':False]
['text':' det = 0','line_number':6979,'multiline':False]
['text':' Small values to test numerical stability. Note that we don't scale','line_number':6990,'multiline':False]
['text':' this matrix.','line_number':6991,'multiline':False]
['text':' mat_chars denotes matrix characteristics','line_number':7004,'multiline':False]
['text':' possible values are: sym, sym_psd, sym_pd, sing, non_sym','line_number':7005,'multiline':False]
['text':' Scaling adapted from `get_random_mat_scale` in _test_det_logdet_slogdet','line_number':7023,'multiline':False]
['text':' check the out= variant','line_number':7070,'multiline':False]
['text':' There are two code paths currently for the out= variant','line_number':7074,'multiline':False]
['text':' 1. When 'out' tensor is in Fortran (column-major) memory format','line_number':7075,'multiline':False]
['text':' then the fast route is taken and the storage is reused directly in the computations','line_number':7076,'multiline':False]
['text':' 2. When 'out' tensor is not in Fortran format then a temporary tensor is allocated internally','line_number':7077,'multiline':False]
['text':' and the result is copied from the temporary tensor to 'out' tensor','line_number':7078,'multiline':False]
['text':' This test checks the first code path','line_number':7080,'multiline':False]
['text':' This test checks the second code path','line_number':7089,'multiline':False]
['text':' cholesky_inverse requires the input to be at least 2 dimensional tensor','line_number':7100,'multiline':False]
['text':' cholesky_inverse requires a square matrix','line_number':7105,'multiline':False]
['text':' if non-empty out tensor with wrong shape is passed a warning is given','line_number':7110,'multiline':False]
['text':' Trigger warning','line_number':7114,'multiline':False]
['text':' Check warning occurs','line_number':7116,'multiline':False]
['text':' dtypes should be safely castable','line_number':7120,'multiline':False]
['text':' device should match','line_number':7125,'multiline':False]
['text':' cholesky_inverse raises an error for invalid inputs on CPU','line_number':7132,'multiline':False]
['text':' for example if at least one diagonal element is zero','line_number':7133,'multiline':False]
['text':' cholesky_inverse on GPU does not raise an error for this case','line_number':7139,'multiline':False]
['text':' select full dimensionality','line_number':7145,'multiline':False]
['text':' select actual dimensions for ops:','line_number':7153,'multiline':False]
['text':' larger: full ndims, individual sizes may be reduced','line_number':7154,'multiline':False]
['text':' smaller: possibly reduced ndims, sizes may be reduced','line_number':7155,'multiline':False]
['text':' no reduced singleton dimension','line_number':7161,'multiline':False]
['text':' larger may have reduced singleton dimension','line_number':7164,'multiline':False]
['text':' smaller may have reduced singleton dimension','line_number':7167,'multiline':False]
['text':' test torch.matmul function as well','line_number':7264,'multiline':False]
['text':' test torch.matmul with out','line_number':7267,'multiline':False]
['text':' compare to bmm','line_number':7272,'multiline':False]
['text':' Stacked output','line_number':7318,'multiline':False]
['text':' Actual output','line_number':7319,'multiline':False]
['text':' Equality check','line_number':7320,'multiline':False]
['text':' Tests tensors with 0 elements','line_number':7327,'multiline':False]
['text':' test against numpy.linalg.solve','line_number':7368,'multiline':False]
['text':' no broadcasting','line_number':7369,'multiline':False]
['text':' broadcasting b','line_number':7370,'multiline':False]
['text':' broadcasting A','line_number':7371,'multiline':False]
['text':' broadcasting A & b','line_number':7372,'multiline':False]
['text':' this tests https://github.com/pytorch/pytorch/issues/36921','line_number':7377,'multiline':False]
['text':' actual rank is known only for dense input','line_number':7423,'multiline':False]
['text':' noqa: B020','line_number':7430,'multiline':False]
['text':' sparse input','line_number':7446,'multiline':False]
['text':' jitting support','line_number':7453,'multiline':False]
['text':' Ensure that nuclear_norm's out variant gives the same result as the non-out','line_number':7458,'multiline':False]
['text':' input size, dim','line_number':7465,'multiline':False]
['text':' numpy.linalg.qr with mode = 'raw' computes the same operation as torch.geqrf','line_number':7491,'multiline':False]
['text':' so this test compares against that function','line_number':7492,'multiline':False]
['text':' numpy.linalg.qr doesn't work with batched input','line_number':7495,'multiline':False]
['text':' numpy.linalg.qr returns transposed result','line_number':7508,'multiline':False]
['text':' FIXME: these are just a selection of LAPACK functions -- we need a general strategy here.','line_number':7520,'multiline':False]
['text':' The LAPACK functions themselves generally do NOT work with zero sized dimensions, although','line_number':7521,'multiline':False]
['text':' numpy/sci often has a direct wrapper (e.g. lu_factor) and a wrapper that "does the right thing"','line_number':7522,'multiline':False]
['text':' (e.g. lu).  We often name our functions identically to the lapack function, so it will take work','line_number':7523,'multiline':False]
['text':' to name / migrate-to better wrappers.','line_number':7524,'multiline':False]
['text':' inverse, pinverse','line_number':7529,'multiline':False]
['text':' det, logdet, slogdet','line_number':7535,'multiline':False]
['text':' This test is designed only for inputs with 1x1 block diagonal matrix D.','line_number':7585,'multiline':False]
['text':' That is for positive definite input matrices, the pivots tensor is always > 0.','line_number':7586,'multiline':False]
['text':' If negative pivots are encountered, it means that the input matrix is not positive definite.','line_number':7587,'multiline':False]
['text':' And matrix D is a 2x2 block diagonal matrix.','line_number':7588,'multiline':False]
['text':' Construct a 1x1 block diagonal matrix D from factors.','line_number':7591,'multiline':False]
['text':' Now test against SciPy implementation','line_number':7603,'multiline':False]
['text':' hermitian=True for complex inputs on CUDA is supported only with MAGMA 2.5.4+','line_number':7629,'multiline':False]
['text':' verify A @ X == B','line_number':7656,'multiline':False]
['text':' hermitian=True is not supported on CUDA yet','line_number':7660,'multiline':False]
['text':' The main purpose of this test is to make sure these "backend" calls work normally without raising exceptions.','line_number':7674,'multiline':False]
['text':' Although linalg preferred flags doesn't affect CPU currently,','line_number':7684,'multiline':False]
['text':' we set this to make sure the flag can switch back to default normally.','line_number':7685,'multiline':False]
['text':' fix https://github.com/pytorch/pytorch/issues/95125','line_number':7698,'multiline':False]
['text':' and https://github.com/pytorch/pytorch/issues/83863','line_number':7699,'multiline':False]
['text':' for bf16 accumulation in gemm ref path','line_number':7700,'multiline':False]
['text':' test matmul','line_number':7712,'multiline':False]
['text':' test bmm','line_number':7723,'multiline':False]
['text':' test baddbmm','line_number':7728,'multiline':False]
['text':' test mv/addmv','line_number':7734,'multiline':False]
['text':' test dot','line_number':7744,'multiline':False]
