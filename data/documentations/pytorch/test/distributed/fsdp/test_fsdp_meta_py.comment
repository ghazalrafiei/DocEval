['text':' Owner(s): ["oncall: distributed"]','line_number':1,'multiline':False]
['text':' For torchdistX init, we don't need to call reset_params, as','line_number':48,'multiline':False]
['text':' deferred_init(model).materialize() is equivalent to model().','line_number':49,'multiline':False]
['text':' Assume that a module has `reset_parameters()` iff it has directly','line_number':52,'multiline':False]
['text':' managed parameters or buffers','line_number':53,'multiline':False]
['text':' Use an initialization method that depends on shape','line_number':69,'multiline':False]
['text':' Use an initialization method that depends on shape','line_number':80,'multiline':False]
['text':' Create model on meta device and wrap with FSDP.','line_number':154,'multiline':False]
['text':' Test to make sure it is the same model parameters as regular FSDP','line_number':165,'multiline':False]
['text':' approach.','line_number':166,'multiline':False]
['text':' Test that meta init works if all submodules are contained in only a','line_number':180,'multiline':False]
['text':' single FSDP unit.','line_number':181,'multiline':False]
['text':' Run a forward + backward pass + optimizer step','line_number':190,'multiline':False]
['text':' Non FSDP modules will still be initialized because they bubble up','line_number':265,'multiline':False]
['text':' to be part of a larger FSDP unit.','line_number':266,'multiline':False]
['text':' Init and reset parameters before wrapping so that reset_params','line_number':270,'multiline':False]
['text':' matches up with meta device's initialization.','line_number':271,'multiline':False]
['text':' Compare it before training','line_number':280,'multiline':False]
['text':' TODO: `module.to_empty()` is not generally correct for meta','line_number':401,'multiline':False]
['text':' device initialization.','line_number':402,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/90465','line_number':403,'multiline':False]
['text':' Wrap `lin1` and the top level `model` to create nested FSDP instances','line_number':408,'multiline':False]
['text':' where each instance has parameters','line_number':409,'multiline':False]
