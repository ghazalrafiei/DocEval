['text':' Owner(s): ["module: inductor"]','line_number':1,'multiline':False]
['text':' for some reason importing functional collectives after dynamo breaks collectives handling!','line_number':10,'multiline':False]
['text':' NOTE: custom cost model to show that the compute reordering algorithm is working','line_number':35,'multiline':False]
['text':' Collective kernels','line_number':36,'multiline':False]
['text':' High-arithmetic-intensity compute kernels','line_number':44,'multiline':False]
['text':' All other kernels','line_number':47,'multiline':False]
['text':' hack: no matter whether we have 2 or 3 or 4 gpus, just run on 2','line_number':66,'multiline':False]
['text':' works around issue with skipif<2 and workers with unpredictable #s gpu','line_number':67,'multiline':False]
['text':' TODO: somehow inductor bg compile threads are causing hangs at exit with distributed work dtor','line_number':73,'multiline':False]
['text':' NOTE: notice that `_wait_tensor` is delayed until right before first use','line_number':95,'multiline':False]
['text':' TODO: somehow inductor bg compile threads are causing hangs at exit with distributed work dtor','line_number':106,'multiline':False]
['text':' NOTE: notice that `dist.all_reduce` is raised above relu and matmul','line_number':128,'multiline':False]
['text':' TODO: somehow inductor bg compile threads are causing hangs at exit with distributed work dtor','line_number':139,'multiline':False]
['text':' NOTE: notice that `dist.all_reduce` is raised above relu and matmul,','line_number':162,'multiline':False]
['text':' and `_wait_tensor` is delayed until right before first use','line_number':163,'multiline':False]
['text':' TODO: somehow inductor bg compile threads are causing hangs at exit with distributed work dtor','line_number':174,'multiline':False]
['text':' NOTE: after scheduling the first all_reduce:','line_number':199,'multiline':False]
['text':' 1. we first schedule the ops (c and d) that ARE required for second all_reduce but DO NOT depend on first all_reduce.','line_number':200,'multiline':False]
['text':' 2. then, we schedule the ops (g) that ARE NOT required for second all_reduce and DO NOT depend on first all_reduce.','line_number':201,'multiline':False]
['text':' 3. then, we schedule the ops (f) that ARE required for second all_reduce and DO depend on first all_reduce.','line_number':202,'multiline':False]
['text':' and then, we schedule the second all_reduce. And then schedule all ops that depend on second all_reduce.','line_number':203,'multiline':False]
['text':' TODO: somehow inductor bg compile threads are causing hangs at exit with distributed work dtor','line_number':226,'multiline':False]
['text':' NOTE: after scheduling the first all_reduce:','line_number':256,'multiline':False]
['text':' 1. we first schedule the ops (c and d) that ARE required for second all_reduce but DO NOT depend on first all_reduce.','line_number':257,'multiline':False]
['text':' 2. then, we schedule the ops (g) that ARE NOT required for second all_reduce and DO NOT depend on first all_reduce.','line_number':258,'multiline':False]
['text':' 3. then, we schedule the ops (f) that ARE required for second all_reduce and DO depend on first all_reduce.','line_number':259,'multiline':False]
['text':' and then, we schedule the second all_reduce. And then schedule all ops that depend on second all_reduce.','line_number':260,'multiline':False]
