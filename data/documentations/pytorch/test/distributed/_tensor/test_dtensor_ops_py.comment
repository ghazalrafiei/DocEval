['text':' Copyright (c) Meta Platforms, Inc. and affiliates','line_number':1,'multiline':False]
['text':' Owner(s): ["oncall: distributed"]','line_number':2,'multiline':False]
['text':' rewrite common size variables to sth can be sharded evenly','line_number':31,'multiline':False]
['text':' we can enable uneven shards later, but need to adjust more on','line_number':32,'multiline':False]
['text':' sample inputs (i.e. view/reshape need to adjust shape size as well)','line_number':33,'multiline':False]
['text':' Copied from functorch','line_number':40,'multiline':False]
['text':' This decorator doesn't modify fn in any way','line_number':81,'multiline':False]
['text':' Re-generate this failed list, turn on dry_run of the below func','line_number':88,'multiline':False]
['text':' check_dtensor_func(self, test, op, dry_run=True), then run sth','line_number':89,'multiline':False]
['text':' like python test/distributed/_tensor/test_dtensor_ops.py > failed.expect','line_number':90,'multiline':False]
['text':' these sometimes pass and sometimes fail','line_number':92,'multiline':False]
['text':' we need to remove many of them from list once op','line_number':93,'multiline':False]
['text':' get full support with varying sharding specs','line_number':94,'multiline':False]
['text':' ops inside this might even fail without dtensor','line_number':491,'multiline':False]
['text':' tests, as we rescale op db common test size factor (i.e. L, M, S)','line_number':492,'multiline':False]
['text':' which triggered the original function run failures with input','line_number':493,'multiline':False]
['text':' generation becomes wrong, we skip them for now but should enable later.','line_number':494,'multiline':False]
['text':' TODO: need to clean this list and remove all cases','line_number':495,'multiline':False]
['text':' TODO: fix the following ops','line_number':526,'multiline':False]
['text':' Add a list of ops that are currently failing BW pass','line_number':531,'multiline':False]
['text':' corresponds to the transpose ops 'H' and 'T'','line_number':533,'multiline':False]
['text':' DEVICE_TYPE = "cuda" if torch.cuda.is_available() and torch.cuda.device_count() >= OP_DB_WORLD_SIZE else "cpu"','line_number':545,'multiline':False]
['text':' TODO: debug cuda illegal memory access issue and re-enable cuda tests','line_number':546,'multiline':False]
['text':' only allow float dytpe for now, we can relax this constraint','line_number':555,'multiline':False]
['text':' when feel necessary later (i.e when adding quantization support).','line_number':556,'multiline':False]
['text':' test each op with dist tensor inputs and normal inputs','line_number':564,'multiline':False]
['text':' we need to figure out a way to test the out variant, out variant testing','line_number':572,'multiline':False]
['text':' is tricky, as we need to pre allocate the dtensor out, some of them rely','line_number':573,'multiline':False]
['text':' on sharding placements to be pre-known (i.e. mm.out)','line_number':574,'multiline':False]
['text':' if isinstance(expected, torch.Tensor) and op.supports_out:','line_number':575,'multiline':False]
['text':'     func(*args, **kwargs, out=expected)','line_number':576,'multiline':False]
['text':' concat the result on corresponding dim for ops like','line_number':608,'multiline':False]
['text':' split, so that we can call backward on a single tensor','line_number':609,'multiline':False]
['text':' TODO: also handle cases where func raise an exception','line_number':616,'multiline':False]
['text':' Suppress warnings, this doesn't matter for test_meta.py','line_number':624,'multiline':False]
['text':' but it does matter if you want to use this decorator','line_number':625,'multiline':False]
['text':' for cross-ref testing, as some tests may be looking at','line_number':626,'multiline':False]
['text':' errors','line_number':627,'multiline':False]
['text':' for every comb of sharding choices, we test if it works','line_number':630,'multiline':False]
['text':' Only attempt if we managed to convert all tensors to DTensor','line_number':632,'multiline':False]
['text':' (if any of them failed, we're in a mixed tensor situation and','line_number':633,'multiline':False]
['text':' this is not allowed in DTensor)','line_number':634,'multiline':False]
['text':' Handle special cases first if there's any','line_number':636,'multiline':False]
['text':' Suppress warnings, this doesn't matter for test_meta.py','line_number':637,'multiline':False]
['text':' but it does matter if you want to use this decorator','line_number':638,'multiline':False]
['text':' for cross-ref testing, as some tests may be looking at','line_number':639,'multiline':False]
['text':' errors','line_number':640,'multiline':False]
['text':' we need to skip tests containing tensors of zero elements for now.','line_number':643,'multiline':False]
['text':' see issue: https://github.com/pytorch/tau/issues/470','line_number':644,'multiline':False]
['text':' TODO remove this once issue above fixed.','line_number':645,'multiline':False]
['text':' redistribute/all_gather the results to compare with normal output','line_number':653,'multiline':False]
['text':' TODO(anj): Remove this guard exception after gaining more confidence.','line_number':664,'multiline':False]
['text':' only instantiate tests for DEVICE_TYPE alone (i.e. either CPU or GPU)','line_number':695,'multiline':False]
['text':' NB: CPU dtensor ops test frequently timeout https://github.com/pytorch/pytorch/issues/98816','line_number':700,'multiline':False]
['text':' so running it only on CUDA','line_number':701,'multiline':False]
