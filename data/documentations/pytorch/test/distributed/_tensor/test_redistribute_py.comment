['text':' Copyright (c) Meta Platforms, Inc. and affiliates','line_number':1,'multiline':False]
['text':' Owner(s): ["oncall: distributed"]','line_number':2,'multiline':False]
['text':' 1) test shard -> replicate forward','line_number':21,'multiline':False]
['text':' 2) test shard -> replicate backward:','line_number':44,'multiline':False]
['text':' should give gradient as shard','line_number':45,'multiline':False]
['text':' 1) test replicate -> replicate forward','line_number':59,'multiline':False]
['text':' 2) test replicate -> replicate backward:','line_number':65,'multiline':False]
['text':' should give gradient as replicate','line_number':66,'multiline':False]
['text':' 1) test replicate -> shard forward','line_number':88,'multiline':False]
['text':' make local tensor as the element of the corresponding chunked list','line_number':96,'multiline':False]
['text':' 2) test replicate -> shard backward:','line_number':104,'multiline':False]
['text':' should give gradient as replicate','line_number':105,'multiline':False]
['text':' Although we don't allow user to reshard to produce a partial','line_number':114,'multiline':False]
['text':' placement (i.e. user can't reshard to partial), we do allow','line_number':115,'multiline':False]
['text':' replicate to partial internally, and also partial to replicate','line_number':116,'multiline':False]
['text':' backward should work as expected','line_number':117,'multiline':False]
['text':' test partial -> replicate, which trigger all_reduce','line_number':122,'multiline':False]
['text':' test backward to have replicate grad on partial','line_number':131,'multiline':False]
['text':' 1) test replicate -> partial forward','line_number':144,'multiline':False]
['text':' test it successfully zero out the contents on other ranks','line_number':153,'multiline':False]
['text':' replicate to partial on sub groups','line_number':158,'multiline':False]
['text':' 1) test replicate -> partial on 2d-mesh subgroups','line_number':164,'multiline':False]
['text':' test partial to shard, trigger reduce_scatter','line_number':216,'multiline':False]
['text':' these should be entirely ignored','line_number':254,'multiline':False]
['text':' because distribute_tensor is expected to override shards in ranks != 0','line_number':255,'multiline':False]
['text':' if partial, temporarily make it Replicated, then replace replicated with partial afterwards','line_number':265,'multiline':False]
['text':' create a new DTensor reinterpreting some of the replicated entires as "Partial"','line_number':270,'multiline':False]
['text':' redistribute on target outputs','line_number':276,'multiline':False]
['text':' replicate and then get first shard','line_number':279,'multiline':False]
