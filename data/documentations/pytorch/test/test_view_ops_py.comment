['text':' Owner(s): ["module: tests"]','line_number':1,'multiline':False]
['text':' TODO: replace this with make_tensor() in common_utils.py','line_number':21,'multiline':False]
['text':' work around torch.randn not being implemented for bfloat16','line_number':27,'multiline':False]
['text':' Use extremal values','line_number':35,'multiline':False]
['text':' TODO: replace this with make_tensor() in common_utils.py','line_number':51,'multiline':False]
['text':' TODO: refactor tests to avoid this function','line_number':58,'multiline':False]
['text':' Converts half/bfloat16 dtype to float when device is cpu','line_number':59,'multiline':False]
['text':' TODO: replace this with make_tensor() in common_utils.py','line_number':65,'multiline':False]
['text':' Returns a tensor of the requested shape, dtype, and device','line_number':66,'multiline':False]
['text':' Requesting a half CPU tensor returns a float CPU tensor with','line_number':67,'multiline':False]
['text':' values representable by a half.','line_number':68,'multiline':False]
['text':' Initialization uses randint for non-float types and randn for float types.','line_number':69,'multiline':False]
['text':' Returns a tensor filled with ones','line_number':71,'multiline':False]
['text':' Returns a tensor with random integer values','line_number':75,'multiline':False]
['text':' generate negative values also','line_number':79,'multiline':False]
['text':' Populates the CPU tensor with floats representable as half/bfloat16','line_number':82,'multiline':False]
['text':' Default: returns a tensor with random float values','line_number':88,'multiline':False]
['text':' Tests ops and indexing to ensure they return views (and new tensors) as','line_number':91,'multiline':False]
['text':' appropriate.','line_number':92,'multiline':False]
['text':' Note: only validates storage on native device types','line_number':102,'multiline':False]
['text':' because some accelerators, like XLA, do not expose storage','line_number':103,'multiline':False]
['text':' Returns true if v1 and v2 are views of the same base','line_number':110,'multiline':False]
['text':' Performs transpose if contiguous=True, else returns the input tensor as is','line_number':116,'multiline':False]
['text':' NumPy's dtype view requires contiguous input if target','line_number':199,'multiline':False]
['text':' dtype is a different size','line_number':200,'multiline':False]
['text':' Test that requires_grad is dropped for floating point casts,','line_number':209,'multiline':False]
['text':' because view(dtype) does not support backward yet','line_number':210,'multiline':False]
['text':' TODO: Remove this when autograd support is added','line_number':211,'multiline':False]
['text':' Test the extra error checks that happen when the view dtype','line_number':217,'multiline':False]
['text':' has a greater element size than the original dtype','line_number':218,'multiline':False]
['text':' RuntimeError since in this case the last dim of input would not be of size 2','line_number':274,'multiline':False]
['text':' RuntimeError since in this case the last dim of input would not have stride 1','line_number':276,'multiline':False]
['text':' RuntimeError since in this case the stride of non-last dim of input would not be of size 2','line_number':280,'multiline':False]
['text':' tensor with zero elements','line_number':287,'multiline':False]
['text':' torch.Size([0])','line_number':288,'multiline':False]
['text':' zero dimension tensor','line_number':293,'multiline':False]
['text':' torch.Size([0, 2])','line_number':299,'multiline':False]
['text':' tensor with zero elements','line_number':318,'multiline':False]
['text':' tensor with zero dim','line_number':324,'multiline':False]
['text':' for the case of contiguous_input, t=u','line_number':392,'multiline':False]
['text':' for the case of non contiguous_input, the base still remains','line_number':393,'multiline':False]
['text':' t since we are performing a view operation to make the input non-contiguous','line_number':394,'multiline':False]
['text':' ensure storage offset is being correctly set','line_number':405,'multiline':False]
['text':' Lazy hasn't implemented unbind yet.','line_number':478,'multiline':False]
['text':' TODO: opinfo this or move to unbind's test suite','line_number':490,'multiline':False]
['text':' check that it works with only one gradient provided (#9977)','line_number':497,'multiline':False]
['text':' Check with gradcheck','line_number':506,'multiline':False]
['text':' TODO: Fix this test for LTC. There is an interaction with dynamic shapes here that is broken,','line_number':510,'multiline':False]
['text':' causing asserts to trigger.','line_number':511,'multiline':False]
['text':' Check that forward will **not** resize storage because it may','line_number':661,'multiline':False]
['text':' cause NaN in output and fail numerical Jacobian check consequently','line_number':662,'multiline':False]
['text':' test','line_number':677,'multiline':False]
['text':' test crazy stride at dim with size 1 case','line_number':680,'multiline':False]
['text':' test expand case','line_number':683,'multiline':False]
['text':' test non-expand overlapping case','line_number':688,'multiline':False]
['text':' test transpose case','line_number':692,'multiline':False]
['text':' test "getting things outside the input" case','line_number':695,'multiline':False]
['text':' should be all zeros','line_number':697,'multiline':False]
['text':' test select on expanded input case','line_number':700,'multiline':False]
['text':' self.is_view_of reports false positives for lazy','line_number':726,'multiline':False]
['text':' self.is_view_of reports false positives for lazy','line_number':754,'multiline':False]
['text':' This test use as_strided to construct a tensor with overlapping memory,','line_number':764,'multiline':False]
['text':' which is not handled by the functionalization pass.','line_number':765,'multiline':False]
['text':' zero-dimensional tensor','line_number':780,'multiline':False]
['text':' stride[i] = stride[i + 1] * size[i + 1] is satisfied for 3 groups:','line_number':791,'multiline':False]
['text':'               [--1--|---2---|-3-] [--1--|----2---|-3-]','line_number':794,'multiline':False]
['text':' flatten returns the original object if start_dim=end_dim','line_number':822,'multiline':False]
['text':' Randomly change values in output','line_number':898,'multiline':False]
['text':' and verify that original is changed','line_number':899,'multiline':False]
['text':' as well.','line_number':900,'multiline':False]
['text':' Testing that the generated view_copy kernel and its derivative are implemented correctly','line_number':913,'multiline':False]
['text':' view_copy ops don't preserve view relationship','line_number':920,'multiline':False]
['text':' forward and backward give the same shape + result','line_number':927,'multiline':False]
['text':' Testing that the output of a view_copy kernel (by default) is contiguous.','line_number':931,'multiline':False]
['text':' Continuous Tensor -> View','line_number':961,'multiline':False]
['text':' Non-continuous Tensor -> Copy','line_number':968,'multiline':False]
['text':' Test that flatten returns 1-dim tensor when given a 0-dim tensor','line_number':977,'multiline':False]
['text':' Test both float tensor and quantized tensor','line_number':998,'multiline':False]
['text':' TODO: this should be refactored into the view ops test suite','line_number':1029,'multiline':False]
['text':' should be viewable -- i.e. data_ptr is the same.','line_number':1033,'multiline':False]
['text':' match NumPy semantics -- don't infer the size of dimension with a degree of freedom','line_number':1036,'multiline':False]
['text':' test double expand','line_number':1052,'multiline':False]
['text':' test non-contiguous','line_number':1055,'multiline':False]
['text':' make sure it's compatible with unsqueeze','line_number':1060,'multiline':False]
['text':' test -1 as target size','line_number':1066,'multiline':False]
['text':' test expanding empty to empty','line_number':1070,'multiline':False]
['text':' TODO: this should be refactored into the view ops test suite','line_number':1073,'multiline':False]
['text':' TODO: this should be refactored into the view ops test suite','line_number':1078,'multiline':False]
['text':' .data_ptr() on meta tensors is always 0 so they are equal regardless of the reshape','line_number':1088,'multiline':False]
['text':' TODO: fix these once we have multi-dimensional empty tensors','line_number':1102,'multiline':False]
['text':' Test that flatten returns 1-dim tensor when given a 0-dim tensor','line_number':1113,'multiline':False]
['text':' Test both float tensor and quantized tensor','line_number':1127,'multiline':False]
['text':' out of bounds index','line_number':1162,'multiline':False]
['text':' invalid start and end','line_number':1166,'multiline':False]
['text':' TODO: update to work on CUDA, too','line_number':1170,'multiline':False]
['text':' TODO: update to work on CUDA, too','line_number':1183,'multiline':False]
['text':' TODO: make work on CUDA, too','line_number':1195,'multiline':False]
['text':' Test 0D tensors','line_number':1198,'multiline':False]
['text':' Test 1D tensors','line_number':1204,'multiline':False]
['text':' Test 2D tensors','line_number':1210,'multiline':False]
['text':' Test 3D tensor','line_number':1216,'multiline':False]
['text':' Variable sections split','line_number':1237,'multiline':False]
['text':' Invalid chunk sizes','line_number':1273,'multiline':False]
['text':' TODO: make work on CUDA, too','line_number':1280,'multiline':False]
['text':' unit test for special case transposed copy (see ATen/native/Copy.cpp for details)','line_number':1297,'multiline':False]
['text':' TODO: is resize best put in test_view_ops?','line_number':1351,'multiline':False]
['text':' Invalid `source` and `destination` dimension','line_number':1384,'multiline':False]
['text':' Move dim to same position','line_number':1419,'multiline':False]
['text':' Generate Input.','line_number':1436,'multiline':False]
['text':' Compare sequence input','line_number':1442,'multiline':False]
['text':' TODO: are these view ops?','line_number':1452,'multiline':False]
['text':' TODO: OpInfo this','line_number':1459,'multiline':False]
['text':' 0-dim','line_number':1461,'multiline':False]
['text':' 1-dim','line_number':1467,'multiline':False]
['text':' 2,3,4-dim','line_number':1473,'multiline':False]
['text':' Skip BFloat16 since numpy does not support it','line_number':1555,'multiline':False]
['text':' s0.dim() <= s1.dim(), reverse s0 and s1 to compare trailing dimension','line_number':1559,'multiline':False]
['text':' test size inference with empty tensors','line_number':1601,'multiline':False]
['text':' test view when tensor is not contiguous in every dimension, but only','line_number':1615,'multiline':False]
['text':' contiguous dimensions are touched.','line_number':1616,'multiline':False]
['text':' size:                      [   4,    2,    3,    9,    6,    2,    1,    5]','line_number':1618,'multiline':False]
['text':' stride:                    [3840, 1620,    1,    3,   54,   27,  324,  324]','line_number':1619,'multiline':False]
['text':' contiguous dim chunks:     [__________, ____, ____, __________, ____, ____]','line_number':1620,'multiline':False]
['text':' merging 1 to chunk after:  [__________, ____, ____, __________, __________]','line_number':1621,'multiline':False]
['text':' [4, 2] => [8, 1]','line_number':1623,'multiline':False]
['text':' [3] => [3]','line_number':1624,'multiline':False]
['text':' [9] => [3, 3]','line_number':1625,'multiline':False]
['text':' [6, 2] => [4, 1, 3]','line_number':1626,'multiline':False]
['text':' [1, 5] => [5]','line_number':1627,'multiline':False]
['text':' [4, 2] => [2, 4]','line_number':1630,'multiline':False]
['text':' [3] => [3]','line_number':1631,'multiline':False]
['text':' [9] => [1, 9]','line_number':1632,'multiline':False]
['text':' [6, 2] => [2, 2, 3]','line_number':1633,'multiline':False]
['text':' [1, 5] => [5, 1]','line_number':1634,'multiline':False]
['text':' adding size 1 dims','line_number':1637,'multiline':False]
['text':' invalid views','line_number':1641,'multiline':False]
['text':' crossing [4, 2], [3]','line_number':1643,'multiline':False]
['text':' crossing [6, 2], [1, 5]','line_number':1645,'multiline':False]
['text':' crossing [9], [6, 2]','line_number':1647,'multiline':False]
['text':' view with stride 0 dims','line_number':1650,'multiline':False]
['text':' all dims are contiguous','line_number':1651,'multiline':False]
['text':' Cases where the tensor can be returned as a view.','line_number':1664,'multiline':False]
['text':' Cases where the tensor must be copied (transpose makes it non-contiguous forcing','line_number':1669,'multiline':False]
['text':' the copy).','line_number':1670,'multiline':False]
['text':' change the stride in dimension 0. the tensor is still contiguous because size[0] is 1','line_number':1680,'multiline':False]
['text':' Skip BFloat16 since numpy does not support it','line_number':1685,'multiline':False]
['text':' Run tests on transposed input if it has at least 2 dims','line_number':1698,'multiline':False]
['text':' Skip BFloat16 since numpy does not support it','line_number':1716,'multiline':False]
['text':' Run tests on transposed input if it has at least 2 dims','line_number':1741,'multiline':False]
['text':' input size, sections or indices, dim, error type, error message, numpy error type','line_number':1764,'multiline':False]
['text':' addtional tests for tensor_split with tensor_indices_or_sections','line_number':1784,'multiline':False]
['text':' This is the test. If crow_indices is not a view op it'll','line_number':1839,'multiline':False]
['text':' trigger an internal assert due to use count greater than 1','line_number':1840,'multiline':False]
['text':' in debug build.','line_number':1841,'multiline':False]
