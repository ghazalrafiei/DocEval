['text':' Owner(s): ["module: custom-operators"]','line_number':1,'multiline':False]
['text':' noqa: F403','line_number':3,'multiline':False]
['text':' noqa: F403','line_number':4,'multiline':False]
['text':' noqa: F403','line_number':22,'multiline':False]
['text':' Should not raise','line_number':67,'multiline':False]
['text':' Should not raise','line_number':76,'multiline':False]
['text':' Should not raise','line_number':85,'multiline':False]
['text':' Emulate AutoDispatchBelowADInplaceOrView, which is not bound into python','line_number':135,'multiline':False]
['text':' Emulate AutoDispatchBelowADInplaceOrView, which is not bound into python','line_number':200,'multiline':False]
['text':' I'm not sure why this is necessary','line_number':291,'multiline':False]
['text':' Triggers the CustomOp autograd NYI error','line_number':350,'multiline':False]
['text':' Should not raise','line_number':379,'multiline':False]
['text':' Should not raise','line_number':393,'multiline':False]
['text':' function schmea validation goes through torchgen, so this is just a','line_number':453,'multiline':False]
['text':' basic test.','line_number':454,'multiline':False]
['text':' Tests for the older custom_op API','line_number':487,'multiline':False]
['text':' kwonly-arg works','line_number':551,'multiline':False]
['text':' Tests for the older custom_op API','line_number':558,'multiline':False]
['text':' Sequence[int] gets automagically turned into int[] in the schema.','line_number':715,'multiline':False]
['text':' This test checks that we actually do support arbitrary sequence types.','line_number':716,'multiline':False]
['text':' Dispatcher will normalize the sequence type into a List','line_number':737,'multiline':False]
['text':' Not comprehensive (it doesn't need to be), just a check that our mechanism works','line_number':748,'multiline':False]
['text':' int[N] in Dispatcher is a bit wild, so we don't try to support it.','line_number':758,'multiline':False]
['text':' We could theoretically support this, but the syntax for suporting','line_number':766,'multiline':False]
['text':' int[] is Sequence[int]','line_number':767,'multiline':False]
['text':' All of these should already be tested by PyTorch codegen','line_number':783,'multiline':False]
['text':' (we share the same mechanism), but here's a sanity check.','line_number':784,'multiline':False]
['text':' We can't define an op multiple times,','line_number':838,'multiline':False]
['text':' noqa: F811','line_number':842,'multiline':False]
['text':' Unless we delete the original op.','line_number':845,'multiline':False]
['text':' Smoke test','line_number':848,'multiline':False]
['text':' noqa: F811','line_number':850,'multiline':False]
['text':' noqa: F811','line_number':857,'multiline':False]
['text':' Shouldn't raise, because we are in no_grad','line_number':903,'multiline':False]
['text':' Smoke test: should not raise error','line_number':931,'multiline':False]
['text':' Not supported by this API: we can either support them in the future','line_number':936,'multiline':False]
['text':' or provide some other CustomOp.def_* function. This depends on how','line_number':937,'multiline':False]
['text':' common the use cases are.','line_number':938,'multiline':False]
['text':' More serious tests are in our CustomOp opinfo db,','line_number':1394,'multiline':False]
['text':' this one is just a sanity check.','line_number':1395,'multiline':False]
['text':' We've updated to attempt to use unbacked symints even for fake','line_number':1455,'multiline':False]
['text':' tracing','line_number':1456,'multiline':False]
['text':' noqa: B950','line_number':1475,'multiline':False]
['text':' pre-existing problem: torch.compile(dynamic=True) will, by default,','line_number':1497,'multiline':False]
['text':' graph break on data-dependent operations. Eventually we'll make it so','line_number':1498,'multiline':False]
['text':' that it never graph breaks on data-dependent operations.','line_number':1499,'multiline':False]
