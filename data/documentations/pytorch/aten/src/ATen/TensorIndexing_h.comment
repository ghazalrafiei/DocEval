['text':' `at::indexing::TensorIndex` is used for converting C++ tensor indices such as','line_number':86,'multiline':False]
['text':' `{None, "...", Ellipsis, 0, true, Slice(1, None, 2), torch::tensor({1, 2})}`','line_number':87,'multiline':False]
['text':' into its equivalent `std::vector<TensorIndex>`, so that further tensor','line_number':88,'multiline':False]
['text':' indexing operations can be performed using the supplied indices.','line_number':89,'multiline':False]
['text':'','line_number':90,'multiline':False]
['text':' There is one-to-one correspondence between Python and C++ tensor index types:','line_number':91,'multiline':False]
['text':' Python                  | C++','line_number':92,'multiline':False]
['text':' -----------------------------------------------------','line_number':93,'multiline':False]
['text':' `None`                  | `at::indexing::None`','line_number':94,'multiline':False]
['text':' `Ellipsis`              | `at::indexing::Ellipsis`','line_number':95,'multiline':False]
['text':' `...`                   | `"..."`','line_number':96,'multiline':False]
['text':' `123`                   | `123`','line_number':97,'multiline':False]
['text':' `True` / `False`        | `true` / `false`','line_number':98,'multiline':False]
['text':' `:`                     | `Slice()` / `Slice(None, None)`','line_number':99,'multiline':False]
['text':' `::`                    | `Slice()` / `Slice(None, None, None)`','line_number':100,'multiline':False]
['text':' `1:`                    | `Slice(1, None)`','line_number':101,'multiline':False]
['text':' `1::`                   | `Slice(1, None, None)`','line_number':102,'multiline':False]
['text':' `:3`                    | `Slice(None, 3)`','line_number':103,'multiline':False]
['text':' `:3:`                   | `Slice(None, 3, None)`','line_number':104,'multiline':False]
['text':' `::2`                   | `Slice(None, None, 2)`','line_number':105,'multiline':False]
['text':' `1:3`                   | `Slice(1, 3)`','line_number':106,'multiline':False]
['text':' `1::2`                  | `Slice(1, None, 2)`','line_number':107,'multiline':False]
['text':' `:3:2`                  | `Slice(None, 3, 2)`','line_number':108,'multiline':False]
['text':' `1:3:2`                 | `Slice(1, 3, 2)`','line_number':109,'multiline':False]
['text':' `torch.tensor([1, 2])`) | `torch::tensor({1, 2})`','line_number':110,'multiline':False]
['text':' Case 1: `at::indexing::None`','line_number':112,'multiline':False]
['text':' Case 2: "..." / `at::indexing::Ellipsis`','line_number':115,'multiline':False]
['text':' Case 3: (Sym) Integer value','line_number':126,'multiline':False]
['text':' Case 4: Boolean value','line_number':132,'multiline':False]
['text':' Case 5: Slice represented in `at::indexing::Slice` form','line_number':138,'multiline':False]
['text':' Case 6: Tensor value','line_number':142,'multiline':False]
['text':' TODO: implement negative step','line_number':211,'multiline':False]
['text':' See NOTE [nested tensor size for indexing]','line_number':214,'multiline':False]
['text':' Skip this optimization if we are tracing, as the trace may be polymorphic','line_number':216,'multiline':False]
['text':' over the shape of the `self` tensor, and we still want to record','line_number':217,'multiline':False]
['text':' the slice.','line_number':218,'multiline':False]
['text':'self_device','line_number':236,'multiline':True]
['text':' See NOTE [nested tensor size for indexing]','line_number':238,'multiline':False]
['text':' if the index is negative, do not normalize it because that would fix the','line_number':259,'multiline':False]
['text':' index on the current tensor size in the tracer. aten::select also works on','line_number':260,'multiline':False]
['text':' negative indices','line_number':261,'multiline':False]
['text':' booleans add a dimension of size 1. true indexes this dimension as if 0:,','line_number':268,'multiline':False]
['text':' false as empty.','line_number':269,'multiline':False]
['text':' booleans add a dimension of size 1. true indexes this dimension as if 0:,','line_number':280,'multiline':False]
['text':' false as empty.','line_number':281,'multiline':False]
['text':' TODO: check scalarType','line_number':310,'multiline':False]
['text':'self','line_number':317,'multiline':True]
['text':' NOTE: Why do we mirror instead of replace the `count_specified_dimensions`','line_number':327,'multiline':False]
['text':' function in torch/csrc/autograd/python_variable_indexing.cpp? It's because','line_number':328,'multiline':False]
['text':' `count_specified_dimensions` is on the hot path of Python tensor multi-dim','line_number':329,'multiline':False]
['text':' indexing (i.e. it's called by `applySlicing` which is called by','line_number':330,'multiline':False]
['text':' `THPVariable_getitem` / `THPVariable_setitem` when handling indexing of more','line_number':331,'multiline':False]
['text':' than one dimension). If we were to merge the Python/C++','line_number':332,'multiline':False]
['text':' `count_specified_dimensions` function, on the Python side we would have to','line_number':333,'multiline':False]
['text':' construct a `std::vector` container to be consumed by the C++','line_number':334,'multiline':False]
['text':' `count_specified_dimensions` function, which adds 100s of nanoseconds','line_number':335,'multiline':False]
['text':' overhead and is undesirable.','line_number':336,'multiline':False]
['text':' Count the number of indexed dimensions (everything but ellipsis and None)','line_number':339,'multiline':False]
['text':' namespace impl','line_number':355,'multiline':False]
['text':' NOTE: Many functions below are only for consumption from Python indexing','line_number':357,'multiline':False]
['text':' implementation, they include:','line_number':358,'multiline':False]
['text':'','line_number':359,'multiline':False]
['text':' - `Tensor scalarToTensor(...)`','line_number':360,'multiline':False]
['text':' - `IntArrayRef slicePrefix1sSize(...)`','line_number':361,'multiline':False]
['text':' - `void copy_to(...)`','line_number':362,'multiline':False]
['text':' - `Tensor handleDimInMultiDimIndexing(...)`','line_number':363,'multiline':False]
['text':' - `Tensor dispatch_index(...)`','line_number':364,'multiline':False]
['text':' - `Tensor dispatch_index_put_(...)`','line_number':365,'multiline':False]
['text':' - `Tensor get_item(...)`','line_number':366,'multiline':False]
['text':' - `void set_item(...)`','line_number':367,'multiline':False]
['text':'','line_number':368,'multiline':False]
['text':' The rest of the functions are in `at::indexing::impl` namespace, signifying','line_number':369,'multiline':False]
['text':' that they shouldn't be used from Python indexing implementation.','line_number':370,'multiline':False]
['text':' To match numpy semantics:','line_number':383,'multiline':False]
['text':' As a special case for backwards compatibility,','line_number':384,'multiline':False]
['text':' strip away unit dimensions from the left of 'src'','line_number':385,'multiline':False]
['text':' Unbacked SymInt has different behavior, but this is sound because','line_number':389,'multiline':False]
['text':' failing to slice will only ever cause an error, not divergent','line_number':390,'multiline':False]
['text':' behavior','line_number':391,'multiline':False]
['text':' A shortcut to avoid generating hard-coded constant sizes during tracing.','line_number':403,'multiline':False]
['text':' This is not a perfect solution: when src & dst have different shapes,','line_number':404,'multiline':False]
['text':' constants will still appear. Users can workaround that case by','line_number':405,'multiline':False]
['text':' dst[index..] = src.reshape(..)','line_number':406,'multiline':False]
['text':' See NOTE [ Setting `disable_slice_optimization` when calling C++ tensor','line_number':418,'multiline':False]
['text':' indexing functions from Python ]','line_number':419,'multiline':False]
['text':'disable_slice_optimization=','line_number':446,'multiline':True]
['text':'includeBool=','line_number':471,'multiline':True]
['text':' This mirrors `applySlicing` in','line_number':506,'multiline':False]
['text':' torch/csrc/autograd/python_variable_indexing.cpp','line_number':507,'multiline':False]
['text':' See NOTE [nested tensor size for indexing]','line_number':518,'multiline':False]
['text':' See NOTE [nested tensor size for indexing]','line_number':529,'multiline':False]
['text':'prev_dim_result=','line_number':534,'multiline':True]
['text':'original_tensor=','line_number':535,'multiline':True]
['text':'index=','line_number':536,'multiline':True]
['text':'dim=','line_number':537,'multiline':True]
['text':'specified_dims_ptr=','line_number':538,'multiline':True]
['text':'real_dim=','line_number':539,'multiline':True]
['text':'outIndices=','line_number':540,'multiline':True]
['text':'disable_slice_optimization=','line_number':541,'multiline':True]
['text':'original_tensor_device=','line_number':542,'multiline':True]
['text':'prev_dim_result_sizes=','line_number':543,'multiline':True]
['text':' namespace impl','line_number':547,'multiline':False]
['text':' NOTE [ Setting `disable_slice_optimization` when calling C++ tensor indexing','line_number':563,'multiline':False]
['text':' functions from Python ]','line_number':564,'multiline':False]
['text':'','line_number':565,'multiline':False]
['text':' Question: When should we set `disable_slice_optimization` to `true` when','line_number':566,'multiline':False]
['text':' calling C++ tensor indexing functions from Python indexing code?','line_number':567,'multiline':False]
['text':'','line_number':568,'multiline':False]
['text':' Answer: What "slice optimization" means: when we have a slicing expression','line_number':569,'multiline':False]
['text':' like `x[0:5, 0]`, where the sliced tensor was of size 5 in dimension 0, we','line_number':570,'multiline':False]
['text':' would skip dispatching the actual slice call as an optimization. However,','line_number':571,'multiline':False]
['text':' here are the cases where we DON'T want this optimization:','line_number':572,'multiline':False]
['text':'','line_number':573,'multiline':False]
['text':' 1. When we are doing 1-D slicing (e.g. `tensor[:]`).','line_number':574,'multiline':False]
['text':'    Reason: we always return a shallow copy for expressions such as','line_number':575,'multiline':False]
['text':'    `tensor[:]` / `tensor[...]` / `tensor[:, :]`. (Note that for `tensor[:,','line_number':576,'multiline':False]
['text':'    :]`, we return an alias of `tensor` by doing the following:','line_number':577,'multiline':False]
['text':'    ```','line_number':578,'multiline':False]
['text':'    Tensor sliced = impl::applySlicing(self, indices, tensorIndices,','line_number':579,'multiline':False]
['text':'    disable_slice_optimization, self_device, self_sizes); if','line_number':580,'multiline':False]
['text':'    (tensorIndices.empty()) {','line_number':581,'multiline':False]
['text':'      if (sliced.is_same(self)) {','line_number':582,'multiline':False]
['text':'        // ensure we return a shallow copy for things like x[...]','line_number':583,'multiline':False]
['text':'        sliced = at::alias(sliced);','line_number':584,'multiline':False]
['text':'      }','line_number':585,'multiline':False]
['text':'      return sliced;','line_number':586,'multiline':False]
['text':'    }','line_number':587,'multiline':False]
['text':'    ```)','line_number':588,'multiline':False]
['text':' 2. When we are doing JIT tracing.','line_number':589,'multiline':False]
['text':'    Reason: JIT tracing needs the `self.slice(...)` call to properly trace the','line_number':590,'multiline':False]
['text':'    slice operation.','line_number':591,'multiline':False]
['text':' This mirrors `THPVariable_getitem` in','line_number':593,'multiline':False]
['text':' torch/csrc/autograd/python_variable_indexing.cpp See NOTE [ Setting','line_number':594,'multiline':False]
['text':' `disable_slice_optimization` when calling C++ tensor indexing functions from','line_number':595,'multiline':False]
['text':' Python ]','line_number':596,'multiline':False]
['text':' NOTE [nested tensor size for indexing]','line_number':602,'multiline':False]
['text':' nested tensor does not have a size (yet) so for now we represent its size','line_number':603,'multiline':False]
['text':' as null may need to be changed after we reach a better solution for nested','line_number':604,'multiline':False]
['text':' tensor size','line_number':605,'multiline':False]
['text':' handle simple types: integers, slices, none, ellipsis, bool','line_number':610,'multiline':False]
['text':'disable_slice_optimization=','line_number':623,'multiline':True]
['text':' ensure we return a shallow copy for things like x[...]','line_number':649,'multiline':False]
['text':' indexing by tensors ("advanced" indexing)','line_number':655,'multiline':False]
['text':' This mirrors `THPVariable_setitem` in','line_number':659,'multiline':False]
['text':' torch/csrc/autograd/python_variable_indexing.cpp for "the assigned value is a','line_number':660,'multiline':False]
['text':' Tensor" case See NOTE [ Setting `disable_slice_optimization` when calling C++','line_number':661,'multiline':False]
['text':' tensor indexing functions from Python ]','line_number':662,'multiline':False]
['text':' handle simple types: integers, slices, ellipsis, bool','line_number':671,'multiline':False]
['text':' do nothing for false (technically we should check the size, but we','line_number':675,'multiline':False]
['text':' don't have real 0-sized shapes.','line_number':676,'multiline':False]
['text':'disable_slice_optimization=','line_number':698,'multiline':True]
['text':' namespace at::indexing','line_number':731,'multiline':False]
