['text':' We assume this in a few other places in the codebase,','line_number':12,'multiline':False]
['text':' but there isn't a centralized definition.','line_number':13,'multiline':False]
['text':' The valid vmap levels range from [0, 64). This effectively means that we','line_number':16,'multiline':False]
['text':' support a maximum of 64 nested vmaps.','line_number':17,'multiline':False]
['text':' Store this number of elements of BatchDims on the stack. Most people will','line_number':20,'multiline':False]
['text':' probably use <= 5 nested vmaps, but adjust this number as necessary.','line_number':21,'multiline':False]
['text':' a BatchDim represents a "private" dimension on a Tensor created inside of','line_number':24,'multiline':False]
['text':' vmap. It is a (level, dim) tuple, with the `dim` indicating which dimension','line_number':25,'multiline':False]
['text':' is being vmap'ed over and the `level` being an identifier for which vmap','line_number':26,'multiline':False]
['text':' said dimension was created inside. The `dim` corresponds to a "physical','line_number':27,'multiline':False]
['text':' dim" - it is a dimension index on the underlying physical tensor that is','line_number':28,'multiline':False]
['text':' being vmapped over.','line_number':29,'multiline':False]
['text':' A BatchedTensorImpl holds an underlying Tensor and a list of BatchDim','line_number':47,'multiline':False]
['text':' NB: We use the term "BatchedTensor" to mean a Tensor that is backed with a','line_number':48,'multiline':False]
['text':' BatchedTensorImpl.','line_number':49,'multiline':False]
['text':'','line_number':50,'multiline':False]
['text':' The batch dimensions are treated as being "private"; they are not','line_number':51,'multiline':False]
['text':' user-visible. For example, in the following Tensor,','line_number':52,'multiline':False]
['text':'    bt = BatchedTensorImpl(ones(2, 3, 5, 7), [(lvl=1, dim=0), (lvl=2, dim=1)])','line_number':53,'multiline':False]
['text':' dimensions 0 and 1 are batch dimensions.','line_number':54,'multiline':False]
['text':'','line_number':55,'multiline':False]
['text':' bt.sizes() returns (5, 7); bt.sum(0) performs a reduction over the (public)','line_number':56,'multiline':False]
['text':' dim 0, which is equivalent to dim 3 in the underlying ones(2, 3, 5, 7)','line_number':57,'multiline':False]
['text':' tensor.','line_number':58,'multiline':False]
['text':' Returns a reference to BatchDims that represent which dimensions of this','line_number':62,'multiline':False]
['text':' tensor are private.','line_number':63,'multiline':False]
['text':' BatchedTensorImpl wraps a Tensor','line_number':68,'multiline':False]
['text':' Given a public dimension index, return the dimension index in the','line_number':73,'multiline':False]
['text':' underlying value() tensor. For example, if we have','line_number':74,'multiline':False]
['text':'    bt = BatchedTensorImpl(ones(2, 3, 5, 7), [(lvl=1, dim=0), (lvl=2,','line_number':75,'multiline':False]
['text':'    dim=2)])','line_number':76,'multiline':False]
['text':' bt.actualDim(0) -> 1','line_number':77,'multiline':False]
['text':' bt.actualDim(1) -> 3','line_number':78,'multiline':False]
['text':' bt.actualDim(2) -> Error','line_number':79,'multiline':False]
['text':' We have to override this because we opted into CustomStrides','line_number':82,'multiline':False]
['text':' Override a bunch of methods inherited from TensorImpl to return error','line_number':84,'multiline':False]
['text':' messages.','line_number':85,'multiline':False]
['text':' see NOTE: [BatchedTensorImpl levels invariant]','line_number':95,'multiline':False]
['text':' Note: [BatchedTensorImpl levels invariant]','line_number':101,'multiline':False]
['text':' There is an invariant that the BatchDims must be stored in increasing','line_number':102,'multiline':False]
['text':' `level` order. That is, for i < j, bdims_[i].level must be less than','line_number':103,'multiline':False]
['text':' bdims_[j].level.','line_number':104,'multiline':False]
['text':' NB: We use the term "BatchedTensor" to mean a Tensor that is backed with a','line_number':108,'multiline':False]
['text':' BatchedTensorImpl.','line_number':109,'multiline':False]
['text':' It is unsafe to call this on a Tensor that is not backed by a','line_number':114,'multiline':False]
['text':' BatchedTensorImpl. Please use `maybeGetBatchedImpl` whenever possible.','line_number':115,'multiline':False]
['text':' Returns a bitset. If bit i is set, then that means dim i is a batchdim.','line_number':127,'multiline':False]
['text':' Creates a bitset for all of the levels present in `bdims`','line_number':137,'multiline':False]
['text':' Use this to construct a BatchedTensor from a regular Tensor','line_number':151,'multiline':False]
['text':' Adds a batch dim to `tensor`, returning a BatchedTensor','line_number':154,'multiline':False]
['text':' Checks if an inplace operation on self and other is "vmap compatible".','line_number':157,'multiline':False]
['text':' See NOTE: [vmap-incompatible in-place operations] for the definition of this.','line_number':158,'multiline':False]
['text':' namespace at','line_number':161,'multiline':False]
