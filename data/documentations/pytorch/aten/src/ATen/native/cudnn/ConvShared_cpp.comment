['text':' NOTE [cuDNN API version]','line_number':28,'multiline':False]
['text':'','line_number':29,'multiline':False]
['text':' ConvPlaceholders.cpp contains placeholder implementation of cudnn','line_number':30,'multiline':False]
['text':' convolution when cudnn is not enabled. These operators only raises','line_number':31,'multiline':False]
['text':' errors, and do no real computation. These operators are implemented','line_number':32,'multiline':False]
['text':' using currnet operators.','line_number':33,'multiline':False]
['text':'','line_number':34,'multiline':False]
['text':' cuDNN v7 and v8 have different API. ConvShared.{cpp, h} contains','line_number':35,'multiline':False]
['text':' code shared by v7 and v8. Conv_v7.cpp contains implementation of','line_number':36,'multiline':False]
['text':' convolution using cuDNN v7 API. Conv_v8.cpp contains implementation','line_number':37,'multiline':False]
['text':' with v8 API.','line_number':38,'multiline':False]
['text':'','line_number':39,'multiline':False]
['text':' NOTE [ Convolution design ]','line_number':40,'multiline':False]
['text':'','line_number':41,'multiline':False]
['text':' cuDNN convolutions does not handle bias. Bias is handled outside.','line_number':42,'multiline':False]
['text':'','line_number':43,'multiline':False]
['text':' The general strategy:','line_number':44,'multiline':False]
['text':'','line_number':45,'multiline':False]
['text':'    - cudnn_convolution (Tensor)','line_number':46,'multiline':False]
['text':'      Entry points for clients','line_number':47,'multiline':False]
['text':'','line_number':48,'multiline':False]
['text':'    - cudnn_convolution_forward (TensorArg)','line_number':49,'multiline':False]
['text':'      Entry point, which may be reused between regular','line_number':50,'multiline':False]
['text':'      convolution and transposed convolution.','line_number':51,'multiline':False]
['text':'','line_number':52,'multiline':False]
['text':'    - raw_cudnn_convolution_forward_out (Tensor)','line_number':53,'multiline':False]
['text':'      Function that has different implementation on Conv_v7.cpp','line_number':54,'multiline':False]
['text':'      and Conv_v8.cpp','line_number':55,'multiline':False]
['text':'','line_number':56,'multiline':False]
['text':' The raw API directly invokes CuDNN and are implemeted differently','line_number':57,'multiline':False]
['text':' on cuDNN v7 and cuDNN v8','line_number':58,'multiline':False]
['text':'','line_number':59,'multiline':False]
['text':' There are a few reasons this should never be directly exposed','line_number':60,'multiline':False]
['text':' via ATen:','line_number':61,'multiline':False]
['text':'','line_number':62,'multiline':False]
['text':'    - It takes output as a parameter (this should be computed!)','line_number':63,'multiline':False]
['text':'    - It doesn't do input checking','line_number':64,'multiline':False]
['text':'    - It doesn't resize output (it is assumed to be correctly sized)','line_number':65,'multiline':False]
['text':'','line_number':66,'multiline':False]
['text':' Where does argument checking happen?  Here's the division of','line_number':67,'multiline':False]
['text':' responsibility:','line_number':68,'multiline':False]
['text':'  - Things that happen in at::Tensor','line_number':69,'multiline':False]
['text':'    - TensorArg allocation','line_number':70,'multiline':False]
['text':'  - Things that happen in TensorArg','line_number':71,'multiline':False]
['text':'    - Check arguments (type, GPU, shape)','line_number':72,'multiline':False]
['text':' ---------------------------------------------------------------------','line_number':76,'multiline':False]
['text':'','line_number':77,'multiline':False]
['text':' ConvolutionParams','line_number':78,'multiline':False]
['text':'','line_number':79,'multiline':False]
['text':' ---------------------------------------------------------------------','line_number':80,'multiline':False]
['text':' NB: This can't be a constructor, because then ConvolutionParams','line_number':96,'multiline':False]
['text':' would not be a POD anymore.','line_number':97,'multiline':False]
['text':' TODO: Use TensorGeometry here instead of the entire Tensor, which we','line_number':98,'multiline':False]
['text':' don't actually need.  (OTOH: We can always pass in','line_number':99,'multiline':False]
['text':' grad_input/grad_output, so this is not very pressing)','line_number':100,'multiline':False]
['text':' ASSERT(weight.dim() == input.dim())','line_number':111,'multiline':False]
['text':' ASSERT(padding.size() == stride.size())','line_number':118,'multiline':False]
['text':' ASSERT(padding.size() == dilation.size())','line_number':119,'multiline':False]
['text':' In principle, we shouldn't parametrize by groups for legacy','line_number':125,'multiline':False]
['text':' CuDNN, but it doesn't seem worth the effort to actually do this.','line_number':126,'multiline':False]
['text':' ---------------------------------------------------------------------','line_number':174,'multiline':False]
['text':'','line_number':175,'multiline':False]
['text':' Convolution forward / Transposed convolution backward','line_number':176,'multiline':False]
['text':'','line_number':177,'multiline':False]
['text':' ---------------------------------------------------------------------','line_number':178,'multiline':False]
['text':' Avoid ambiguity of "output" when this is being used as backwards','line_number':199,'multiline':False]
['text':' NB: output_padding not needed here, as there is no ambiguity to','line_number':226,'multiline':False]
['text':' resolve','line_number':227,'multiline':False]
['text':' ---------------------------------------------------------------------','line_number':240,'multiline':False]
['text':'','line_number':241,'multiline':False]
['text':' Convolution backward / Transposed convolution forward','line_number':242,'multiline':False]
['text':'','line_number':243,'multiline':False]
['text':' ---------------------------------------------------------------------','line_number':244,'multiline':False]
['text':' NOTE [ Backward vs transpose convolutions ]','line_number':246,'multiline':False]
['text':'','line_number':247,'multiline':False]
['text':' Backward and transpose are algorithmically equivalent, but they','line_number':248,'multiline':False]
['text':' compute their geometry differently.  In a backwards, you knew what','line_number':249,'multiline':False]
['text':' the original size of the input tensor was, so you can cache that','line_number':250,'multiline':False]
['text':' geometry and fill it directly.  In transposed convolution, it is','line_number':251,'multiline':False]
['text':' more conventional to not explicitly specify the output (previously','line_number':252,'multiline':False]
['text':' input) size, and compute it.  This, however, leaves a degree of','line_number':253,'multiline':False]
['text':' freedom; this degree of freedom is resolved using the','line_number':254,'multiline':False]
['text':' output_padding parameter.  Both of these interfaces are equivalent,','line_number':255,'multiline':False]
['text':' but they are differently convenient depending on the use case.','line_number':256,'multiline':False]
['text':' Avoid "grad_input" when this is being used as transposed convolution','line_number':271,'multiline':False]
['text':' ---------------------------------------------------------------------','line_number':323,'multiline':False]
['text':'','line_number':324,'multiline':False]
['text':' Convolution backward (weight)','line_number':325,'multiline':False]
['text':'','line_number':326,'multiline':False]
['text':' ---------------------------------------------------------------------','line_number':327,'multiline':False]
['text':' For uniformity with everything else, although it seems grad_weight','line_number':348,'multiline':False]
['text':' would be unambiguous too.','line_number':349,'multiline':False]
['text':' FuseFrozenConvAddRelu performs some tensor shape checking','line_number':443,'multiline':False]
['text':' use output_t as z to satisfy CUDNN API','line_number':469,'multiline':False]
['text':' alpha','line_number':470,'multiline':False]
['text':' benchmark','line_number':476,'multiline':False]
['text':' deterministic','line_number':477,'multiline':False]
['text':' allow_tf32','line_number':478,'multiline':False]
['text':' AT_CUDNN_CONV_BIAS_RELU_FALLBACK','line_number':480,'multiline':False]
['text':' use output_t as z to satisfy CUDNN API','line_number':485,'multiline':False]
['text':' alpha','line_number':486,'multiline':False]
['text':' benchmark','line_number':492,'multiline':False]
['text':' deterministic','line_number':493,'multiline':False]
['text':' allow_tf32','line_number':494,'multiline':False]
['text':' FuseFrozenConvAddRelu performs some tensor shape checking','line_number':520,'multiline':False]
['text':' deterministic','line_number':555,'multiline':False]
['text':' allow_tf32','line_number':556,'multiline':False]
['text':' AT_CUDNN_CONV_BIAS_RELU_FALLBACK','line_number':558,'multiline':False]
['text':' deterministic','line_number':571,'multiline':False]
['text':' allow_tf32','line_number':572,'multiline':False]
['text':' AT_CUDNN_CONV_BIAS_RELU_FALLBACK','line_number':574,'multiline':False]
['text':' AT_CUDNN_ENABLED','line_number':584,'multiline':False]
