['text':' for the definition of AT_CUDNN_ENABLED','line_number':3,'multiline':False]
['text':' TODO: remove duplicate code in Conv_v7.cpp','line_number':51,'multiline':False]
['text':' alignment are in bytes','line_number':57,'multiline':False]
['text':' Workaround for cudnn error handling deficiency, that results in a crash on Ubuntu-22+','line_number':70,'multiline':False]
['text':' if `libnvrtc.so` is not found on the system, which strictly speaking is not necessary','line_number':71,'multiline':False]
['text':' for usecases below','line_number':72,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/97041','line_number':73,'multiline':False]
['text':' TODO: check under which conditions this is OK','line_number':132,'multiline':False]
['text':' No op here because it is assumed to be a forward conv op','line_number':150,'multiline':False]
['text':' TODO: does it make sense to have this in the key? but alpha is a graph-level param...','line_number':156,'multiline':False]
['text':' roughly corresponds to 2GiB assuming 200KiB per ExecutionPlan','line_number':185,'multiline':False]
['text':' 0 is used to indicate no limit','line_number':186,'multiline':False]
['text':' negative values are used to indicate no caching','line_number':187,'multiline':False]
['text':' no mutexes here as caches are now thread local for v8, can also return a pointer','line_number':212,'multiline':False]
['text':' to the Execution Plan if we know it will not be invalidated by another thread','line_number':213,'multiline':False]
['text':' update most recently accessed','line_number':228,'multiline':False]
['text':' iterator was invalidated by the erase, so we grab it again','line_number':234,'multiline':False]
['text':' need to perform eviction','line_number':255,'multiline':False]
['text':' dummy iterator','line_number':271,'multiline':False]
['text':' @eqy: use thread local caches as cuDNN Execution Plans are not guaranteed to be thread safe across all engines','line_number':277,'multiline':False]
['text':' see Limitations in https://docs.nvidia.com/deeplearning/cudnn/release-notes/index.html','line_number':278,'multiline':False]
['text':' namespace','line_number':282,'multiline':False]
['text':' need computation to be done in FLOAT type regardless of reduced precision input','line_number':328,'multiline':False]
['text':' virtual output of conv','line_number':347,'multiline':False]
['text':' another virtual output (of add)','line_number':356,'multiline':False]
['text':' another virtual output (of add bias)','line_number':365,'multiline':False]
['text':' final output is in original datatype','line_number':371,'multiline':False]
['text':' Method for engine config generator based on heuristics','line_number':384,'multiline':False]
['text':'&desc,','line_number':385,'multiline':True]
['text':' Method for engine config generator based on fallback list','line_number':395,'multiline':False]
['text':' clear CUDA error','line_number':461,'multiline':False]
['text':' We don't care about getting the best ordering of algos if we're roing to run all of them','line_number':480,'multiline':False]
['text':' We only get configs from this stage to avoid building unnecessary plans that are never executed','line_number':537,'multiline':False]
['text':' clear CUDA error','line_number':568,'multiline':False]
['text':' clear CUDA error','line_number':582,'multiline':False]
['text':' clear CUDA error','line_number':603,'multiline':False]
['text':' clear CUDA error','line_number':624,'multiline':False]
['text':' TODO: is this thread safe if cache is updated? is pointer stale?','line_number':636,'multiline':False]
['text':' clear CUDA error','line_number':643,'multiline':False]
['text':' extra data needed for errata filter','line_number':647,'multiline':False]
['text':' heuristic configs','line_number':648,'multiline':False]
['text':' fallback configs','line_number':655,'multiline':False]
['text':' Replicate v7 behavior: clear cached blocks as benchmark incurs','line_number':668,'multiline':False]
['text':' significant memory consumptiont that is not needed after this step','line_number':669,'multiline':False]
['text':' clear CUDA error','line_number':689,'multiline':False]
['text':' extra data needed for errata filter','line_number':693,'multiline':False]
['text':' heuristic configs','line_number':694,'multiline':False]
['text':' fallback configs','line_number':701,'multiline':False]
['text':' at::native','line_number':801,'multiline':False]
['text':' HAS_CUDNN_V8','line_number':803,'multiline':False]
['text':' AT_CUDNN_ENABLED','line_number':804,'multiline':False]
