['text':' optional ','line_number':66,'multiline':True]
['text':' optional ','line_number':67,'multiline':True]
['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':73,'multiline':False]
['text':' repeated check so expanded weights can call native_group_norm directly but','line_number':79,'multiline':False]
['text':' save mean and variance from forward','line_number':80,'multiline':False]
['text':' dtype ','line_number':94,'multiline':True]
['text':' layout ','line_number':95,'multiline':True]
['text':' device ','line_number':96,'multiline':True]
['text':' pin_memory ','line_number':97,'multiline':True]
['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':118,'multiline':False]
['text':' dtype ','line_number':141,'multiline':True]
['text':' layout ','line_number':142,'multiline':True]
['text':' device ','line_number':143,'multiline':True]
['text':' pin_memory ','line_number':144,'multiline':True]
['text':' dtype ','line_number':150,'multiline':True]
['text':' layout ','line_number':151,'multiline':True]
['text':' device ','line_number':152,'multiline':True]
['text':' pin_memory ','line_number':153,'multiline':True]
['text':' dtype ','line_number':159,'multiline':True]
['text':' layout ','line_number':160,'multiline':True]
['text':' device ','line_number':161,'multiline':True]
['text':' pin_memory ','line_number':162,'multiline':True]
['text':' optional ','line_number':185,'multiline':True]
['text':' optional ','line_number':186,'multiline':True]
['text':' cudnn_enabled, deprecated ','line_number':188,'multiline':True]
['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':189,'multiline':False]
['text':' Ported from pytorch/xla repo','line_number':218,'multiline':False]
['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':228,'multiline':False]
['text':'weight=','line_number':238,'multiline':True]
['text':'bias=','line_number':239,'multiline':True]
['text':'running_mean=','line_number':240,'multiline':True]
['text':'running_var=','line_number':241,'multiline':True]
['text':'training=','line_number':242,'multiline':True]
['text':'momentum=','line_number':243,'multiline':True]
['text':' convert mean/std to have the same dtype as input.','line_number':257,'multiline':False]
['text':' This follows the same behavior as the CPU and CUDA kernels.','line_number':258,'multiline':False]
['text':' namespace native','line_number':263,'multiline':False]
['text':' namespace at','line_number':264,'multiline':False]
