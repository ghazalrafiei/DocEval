['text':' for now, this branch executes for dtype == ScalarType::QUInt8','line_number':39,'multiline':False]
['text':' additional cases will be added when quantization support for other dtypes becomes available','line_number':40,'multiline':False]
['text':'min=','line_number':46,'multiline':True]
['text':'max=','line_number':47,'multiline':True]
['text':'qmin=','line_number':48,'multiline':True]
['text':'qmax=','line_number':49,'multiline':True]
['text':'preserve_sparsity=','line_number':50,'multiline':True]
['text':'force_scale_power_of_two=','line_number':51,'multiline':True]
['text':'reduce_range=','line_number':52,'multiline':True]
['text':' TODO: To support all features of MemoryFormat::Preserve we need to add','line_number':195,'multiline':False]
['text':' _empty_affine_quantized_strided function and use it similarly to','line_number':196,'multiline':False]
['text':' Tensor clone(const Tensor& src, c10::optional<c10::MemoryFormat>','line_number':197,'multiline':False]
['text':' optional_memory_format) if (self.is_non_overlapping_and_dense()) ->','line_number':198,'multiline':False]
['text':' _empty_affine_quantized_strided','line_number':199,'multiline':False]
['text':' Delegate to virtual equalTo method. This will ensure different concrete','line_number':238,'multiline':False]
['text':' Quantizers can have specific logic for comparison','line_number':239,'multiline':False]
['text':' Sizes and element types must be the same','line_number':246,'multiline':False]
['text':' Data must be the same','line_number':254,'multiline':False]
['text':' Calculate the quantization params for the activation tensor ','line_number':263,'multiline':True]
['text':'min=','line_number':277,'multiline':True]
['text':'max=','line_number':278,'multiline':True]
['text':'qmin=','line_number':279,'multiline':True]
['text':'qmax=','line_number':280,'multiline':True]
['text':'preserve_sparsity=','line_number':281,'multiline':True]
['text':'force_scale_power_of_two=','line_number':282,'multiline':True]
['text':'reduce_range=','line_number':283,'multiline':True]
['text':' NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)','line_number':297,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)','line_number':301,'multiline':False]
['text':' TODO add FBGEMM kernel','line_number':308,'multiline':False]
['text':' #ifdef USE_FBGEMM','line_number':309,'multiline':False]
['text':' #endif','line_number':310,'multiline':False]
['text':' remainder loop','line_number':312,'multiline':False]
['text':'
  Helper function to find the best min/max for a tensor to calculate qparams.
  It uses a greedy approach to nudge the min and max and calculate the l2 norm
  and tries to minimize the quant error by doing `torch.norm(x-fake_quant(x,s,z))`
  Returns the optimized xmax and xmin value of the tensor.
','line_number':322,'multiline':True]
['text':' NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)','line_number':346,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)','line_number':360,'multiline':False]
['text':' move left','line_number':363,'multiline':False]
['text':' move right','line_number':366,'multiline':False]
['text':' found a local optima','line_number':370,'multiline':False]
['text':' namespace native','line_number':390,'multiline':False]
['text':' namespace at','line_number':391,'multiline':False]
