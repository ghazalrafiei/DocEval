['text':' out variant of LinearPackedParamsBase::apply','line_number':16,'multiline':False]
['text':'input','line_number':18,'multiline':True]
['text':'output_scale','line_number':19,'multiline':True]
['text':'output_zero_point','line_number':20,'multiline':True]
['text':'input','line_number':29,'multiline':True]
['text':'output_scale','line_number':30,'multiline':True]
['text':'output_zero_point','line_number':31,'multiline':True]
['text':' Corresponding pattern (the ops with `*` are part of the pattern that','line_number':39,'multiline':False]
['text':' represents the computation of quantized::linear_with_input_q_dq_qweight_dq_output_fp32):','line_number':40,'multiline':False]
['text':' input -> q* -> dq* -> linear* ->','line_number':41,'multiline':False]
['text':'         qweight -> dq* /','line_number':42,'multiline':False]
['text':'','line_number':43,'multiline':False]
['text':' After fusion:','line_number':44,'multiline':False]
['text':' input -> quantized::linear_with_input_q_dq_qweight_dq_output_fp32* ->','line_number':45,'multiline':False]
['text':'         qweight /','line_number':46,'multiline':False]
['text':'','line_number':47,'multiline':False]
['text':' Additional Note: the weight is packed as well','line_number':48,'multiline':False]
['text':' Params:','line_number':49,'multiline':False]
['text':'    X: float32 Tensor, will be quantized to quint8 in the op','line_number':50,'multiline':False]
['text':'    W_prepack: packed qint8 quantized weight and bias','line_number':51,'multiline':False]
['text':' Returns:','line_number':52,'multiline':False]
['text':'    Y: float32 Tensor','line_number':53,'multiline':False]
['text':' Corresponding pattern (the ops with `*` are part of the pattern that','line_number':64,'multiline':False]
['text':' represents the computation of quantized::linear_with_input_q_dq_qweight_dq_relu_output_fp32):','line_number':65,'multiline':False]
['text':' input -> q* -> dq* -> linear* -> relu* ->','line_number':66,'multiline':False]
['text':'         qweight -> dq* /','line_number':67,'multiline':False]
['text':'','line_number':68,'multiline':False]
['text':' After fusion:','line_number':69,'multiline':False]
['text':' input -> quantized::linear_with_input_q_dq_qweight_dq_relu_output_fp32* ->','line_number':70,'multiline':False]
['text':'         qweight /','line_number':71,'multiline':False]
['text':'','line_number':72,'multiline':False]
['text':' Additional Note: the weight is packed as well','line_number':73,'multiline':False]
['text':' Params:','line_number':74,'multiline':False]
['text':'    input: float32 Tensor, will be quantized to quint8 in the op','line_number':75,'multiline':False]
['text':' Returns:','line_number':76,'multiline':False]
['text':'    float32 Tensor','line_number':77,'multiline':False]
['text':' input ','line_number':96,'multiline':True]
['text':' reduce_range ','line_number':98,'multiline':True]
['text':' input ','line_number':105,'multiline':True]
['text':' reduce_range ','line_number':107,'multiline':True]
['text':'bias','line_number':118,'multiline':True]
