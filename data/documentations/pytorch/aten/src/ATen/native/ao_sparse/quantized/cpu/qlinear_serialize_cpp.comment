['text':'*
  - Wrap a vector in a Tensor, copying data into its own data pointer.
  - The type of vec is T& (not vector<T>&) so this works with any vector-like
    datastructure which has .data() and .size()
 ','line_number':16,'multiline':True]
['text':'*
 * Adapted from Fbgemm BCSRMatrix::pack, but with zero points, without tiling,
 * and without determining row_offsets
 * https://github.com/pytorch/FBGEMM/blob/9d7c48a65419d0350f9e9e72f31e05bfe37e85a4/src/FbgemmSparseDense.cc#L84
 ','line_number':31,'multiline':True]
['text':' is the whole block zero?','line_number':55,'multiline':False]
['text':' break if already found a non-zero element or','line_number':58,'multiline':False]
['text':' out of bounds','line_number':59,'multiline':False]
['text':' within bound?','line_number':67,'multiline':False]
['text':' zero fill','line_number':82,'multiline':False]
['text':' USE_FBGEMM','line_number':99,'multiline':False]
['text':' namespace','line_number':100,'multiline':False]
['text':' Get weights, row indices, and col indices in untiled form;','line_number':105,'multiline':False]
['text':' unpack the tiled bcsr then pack it in untiled form','line_number':106,'multiline':False]
['text':' Add 128 to each weight value. This serialization format is best for','line_number':123,'multiline':False]
['text':' minimizing memory footprint for QNNPack','line_number':124,'multiline':False]
['text':' Narrowing from int32_t to int8_t; this is okay because qint8 zero','line_number':143,'multiline':False]
['text':' points are restricted to fit in bounds of int_8','line_number':144,'multiline':False]
['text':' Row block indices','line_number':148,'multiline':False]
['text':' Col block indices','line_number':150,'multiline':False]
['text':' USE_FBGEMM','line_number':156,'multiline':False]
['text':' Don't go to the end because of padding','line_number':185,'multiline':False]
['text':' Subtract 128 from each zero point, to reverse addition done during','line_number':188,'multiline':False]
['text':' prepacking','line_number':189,'multiline':False]
['text':' Don't go to the end because of padding','line_number':193,'multiline':False]
['text':' Cast from uint8_t range to int8_t','line_number':206,'multiline':False]
['text':' Cast from uint16_t range to int16_t','line_number':214,'multiline':False]
['text':' Cast from uint32_t range to int32_t','line_number':222,'multiline':False]
['text':' USE_PYTORCH_QNNPACK','line_number':246,'multiline':False]
['text':' namespace sparse','line_number':248,'multiline':False]
['text':' namespace ao','line_number':249,'multiline':False]
