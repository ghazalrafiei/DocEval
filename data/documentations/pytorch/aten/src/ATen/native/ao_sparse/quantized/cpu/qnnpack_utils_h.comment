['text':' TODO: Refacto QnnpackUtils.h so as to separate code','line_number':7,'multiline':False]
['text':' needed for quantized op from the generic qnnpack specific','line_number':8,'multiline':False]
['text':' quantization utilities.','line_number':9,'multiline':False]
['text':' block sparsity size across output_features ','line_number':19,'multiline':True]
['text':' block sparsity size across input_features ','line_number':19,'multiline':True]
['text':' Separate copy of bias exist so that we can fill in zeros when','line_number':22,'multiline':False]
['text':' optional bias does not exist. This is to compy with qnnpack operator that','line_number':23,'multiline':False]
['text':' expects bias to be present.','line_number':24,'multiline':False]
['text':' In case bias is present bias_ is just a reference to orig_bias_','line_number':25,'multiline':False]
['text':' Deserialized Tensors are stored to maintain the lifetime of underlying','line_number':37,'multiline':False]
['text':' BCSR data.','line_number':38,'multiline':False]
['text':' These are left empty if PackedLinearWeightQnnp is created via prepacking','line_number':39,'multiline':False]
['text':' rather than deserializing.','line_number':40,'multiline':False]
['text':' namespace ao::sparse','line_number':90,'multiline':False]
['text':' USE_PYTORCH_QNNPACK','line_number':92,'multiline':False]
