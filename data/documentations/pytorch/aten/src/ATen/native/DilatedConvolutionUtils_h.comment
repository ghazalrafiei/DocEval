['text':' namespace','line_number':34,'multiline':False]
['text':' calculate the rear part of output tensor sizes','line_number':36,'multiline':False]
['text':' calculate the sizes of output tensor','line_number':56,'multiline':False]
['text':'
  slow_conv_dilated_shape_check - check user-input to dilated convolution
  forward and backward functions.
','line_number':73,'multiline':True]
['text':'
    When the following tensors are defined:

    bias, grad_weight, grad_output

    then these are assumed to be contiguous without checking
    because of these tensors are made contiguous by calling
    .contiguous() method or by resizing of zero-sized tensors in
    forward/backward functions.

    When grad_weight is defined then it is assumed without
    checking to have the same shape as weight, see backward
    functions.
   ','line_number':87,'multiline':True]
['text':' Check size arguments','line_number':101,'multiline':False]
['text':' check input','line_number':140,'multiline':False]
['text':' input dim has to be dim + 1 if not batched','line_number':146,'multiline':False]
['text':' check output sizes','line_number':154,'multiline':False]
['text':' check weight','line_number':164,'multiline':False]
['text':' check bias when present','line_number':183,'multiline':False]
['text':' check grad_output when present','line_number':193,'multiline':False]
['text':' namespace at::native::internal','line_number':229,'multiline':False]
