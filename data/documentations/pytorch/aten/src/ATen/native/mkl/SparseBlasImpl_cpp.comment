['text':'
  Get row-major or column-major matrix.

  Args:
  * `tensor` - 2D strided Tensor.
  * `row_major` - controls the memory layout.
','line_number':48,'multiline':True]
['text':' ILP64 is a 64-bit API version of MKL','line_number':82,'multiline':False]
['text':' Indices tensor must have ScalarType::Long type','line_number':83,'multiline':False]
['text':' LP64 is a 32-bit API version of MKL','line_number':91,'multiline':False]
['text':' Indices tensor must have ScalarType::Int type','line_number':92,'multiline':False]
['text':'
  Resizes `input` tensor and fills it with the data from MKL.
','line_number':111,'multiline':True]
['text':' Resize input using nnz information from MKL','line_number':130,'multiline':False]
['text':' NB: When nnz is zero it is possible that input_values.data_ptr<scalar_t> is','line_number':138,'multiline':False]
['text':' a nullptr, if input was created via empty. As such we need to check that','line_number':139,'multiline':False]
['text':' nnz is not zero to avoid passing nullptr to std::memcpy. We will apply','line_number':140,'multiline':False]
['text':' the same precautions to crow_indices.data_ptr<MKL_INT>.','line_number':141,'multiline':False]
['text':'','line_number':142,'multiline':False]
['text':' Otherwise ASAN will complain.','line_number':143,'multiline':False]
['text':' MKL Sparse Inspector-Executor doesn't have a way to provide external','line_number':146,'multiline':False]
['text':' buffers So we have to copy the memory allocated by MKL','line_number':147,'multiline':False]
['text':'
  Computes a sparse matrix-dense matrix product defined as
  C <- alpha*(A*B) + beta*C

  Args:
  * `A` - Sparse Tensor storing m x k matrix.
  * `B` - Dense Tensor storing k x n matrix.
  * `C` - [in] Dense Tensor storing matrix of size m x n.
          [out] result of the operation.
','line_number':161,'multiline':True]
['text':' MKL requires same storage layout of matrices','line_number':188,'multiline':False]
['text':'
  Computes a sparse matrix-sparse matrix product with dense result defined as
  C <- alpha*(A*B) + beta*C

  Args:
  * `A` - Sparse Tensor storing m x k matrix.
  * `B` - Sparse Tensor storing k x n matrix.
  * `C` - [in] Dense Tensor storing matrix of size m x n.
          [out] result of the operation.
','line_number':231,'multiline':True]
['text':' MKL function computes C <- A*B','line_number':253,'multiline':False]
['text':' So we need a temporary matrix to store the result','line_number':254,'multiline':False]
['text':' and then add it to C','line_number':255,'multiline':False]
['text':' If beta is zero NaN and Inf should not be propagated to the result','line_number':273,'multiline':False]
['text':'
  Computes a sparse matrix-sparse matrix product defined as
  C <- alpha*(A*B) + beta*C

  Args:
  * `mat1` - Sparse CSR Tensor storing m x k matrix A.
  * `mat2` - Sparse CSR Tensor storing k x n matrix B.
  * `result` - [in] Sparse CSR Tensor storing matrix C of size m x n.
               [out] result of the operation.
','line_number':283,'multiline':True]
['text':' Compute beta*result because MKL doesn't do it','line_number':305,'multiline':False]
['text':' If beta is zero NaN and Inf should not be propagated to the result','line_number':306,'multiline':False]
['text':' MKL doesn't work with empty matrices','line_number':313,'multiline':False]
['text':' MKL doesn't have an interface to compute alpha*(A*B) + beta*C at once','line_number':318,'multiline':False]
['text':' copy the data from MKL, otherwise computed result will be destroyed','line_number':337,'multiline':False]
['text':' together with `mkl_result`','line_number':338,'multiline':False]
['text':' anonymous namespace','line_number':346,'multiline':False]
['text':'
  Computes a matrix-matrix product defined as
  C <- alpha*(A*B) + beta*C

  Args:
  * `mat1` - Tensor storing m x k matrix A.
  * `mat2` - Tensor storing k x n matrix B.
  * `result` - [in] Tensor storing matrix C of size m x n.
               [out] result of the operation.
','line_number':348,'multiline':True]
['text':' Layout checks are nested mat1, mat2, result','line_number':371,'multiline':False]
['text':' Conditions are ordered strided, csr, csc, bsr, bsc.','line_number':372,'multiline':False]
['text':' Valid combinations terminate in a return','line_number':373,'multiline':False]
['text':' Invalid combinations are omitted and will fall though to the TORCH check','line_number':374,'multiline':False]
['text':' generating an informative error message','line_number':375,'multiline':False]
['text':' TODO: Add native CSC support via cuSPARSE if supported.','line_number':379,'multiline':False]
['text':' TODO: CSR @ CSC kernel would be very fast due to format alignment','line_number':425,'multiline':False]
['text':' TODO: CSR @ CSC kernel would be very fast due to format alignment','line_number':430,'multiline':False]
['text':' TODO: avoid csc->csr conversion with native csc support','line_number':439,'multiline':False]
['text':' TODO: avoid csc->csr conversion with native csc support','line_number':446,'multiline':False]
['text':' TODO avoid csc->csr','line_number':461,'multiline':False]
['text':'
  Computes a sparse matrix-dense vector product defined as
  y <- alpha*op(A)*x + beta*y

  Args:
  * `mat` - Tensor storing sparse m x n matrix A.
  * `vec` - Tensor storing dense vector x of size n.
  * `result` - [in] Tensor storing dense vector y of size m.
               [out] result of the operation.
','line_number':492,'multiline':True]
['text':' MKL doesn't work with empty matrices','line_number':557,'multiline':False]
['text':' Modify `result` tensor in-place to swap indices tensors with 32-bit (or','line_number':569,'multiline':False]
['text':' 64-bit) variants','line_number':570,'multiline':False]
['text':' Note that the order the order of mat1 and mat2 arguments is swapped','line_number':585,'multiline':False]
['text':' because MKL computes alpha*mat1 + mat2 while PyTorch needs mat1 +','line_number':586,'multiline':False]
['text':' alpha*mat2','line_number':587,'multiline':False]
['text':' now copy data from `result_desc` to `result`','line_number':596,'multiline':False]
['text':' If A has no nnz, then A is singular and we can't solve.','line_number':625,'multiline':False]
['text':'dim=','line_number':637,'multiline':True]
['text':'dim=','line_number':638,'multiline':True]
['text':' MKL has a bug for inputs with unmaterialized diagonal indices.','line_number':644,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/88890 and','line_number':645,'multiline':False]
['text':' the comments within.','line_number':646,'multiline':False]
['text':' MKL requires same storage layout of matrices','line_number':654,'multiline':False]
['text':' namespace mkl','line_number':706,'multiline':False]
['text':' namespace impl','line_number':707,'multiline':False]
['text':' namespace sparse','line_number':708,'multiline':False]
['text':' namespace native','line_number':709,'multiline':False]
['text':' namespace at','line_number':710,'multiline':False]
