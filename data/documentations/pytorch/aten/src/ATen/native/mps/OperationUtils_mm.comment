['text':'  Copyright Â© 2022 Apple Inc.','line_number':1,'multiline':False]
['text':'*
 * Computes distance from lowest to highest element offset in given tensor.
 ','line_number':31,'multiline':True]
['text':' #issue 104398441 sortWithTensor and argsortWithTensor has support of','line_number':86,'multiline':False]
['text':' Int32, Half and Float32 types. These utilities are to help cast to these','line_number':87,'multiline':False]
['text':' types.','line_number':88,'multiline':False]
['text':' #issue 104398441 sortWithTensor and argsortWithTensor has support of','line_number':106,'multiline':False]
['text':' Int32, Half and Float32 types. These utilities are to help cast from these','line_number':107,'multiline':False]
['text':' types.','line_number':108,'multiline':False]
['text':' This is an intentional fallthrough supporting Double for Scalar','line_number':127,'multiline':False]
['text':' types as they are casted to Float32 currently.','line_number':128,'multiline':False]
['text':' use short_name to avoid getting extra long cached graph keys with ops such as cat_out(), etc.','line_number':160,'multiline':False]
['text':' The key format per tensor would look like ":Float32[1,1,1,10]:"','line_number':260,'multiline':False]
['text':' if tensor is a scalar','line_number':265,'multiline':False]
['text':' Get shape and data type','line_number':311,'multiline':False]
['text':' Initialize data','line_number':315,'multiline':False]
['text':' extract the pointer to MTLBuffer from the Tensor's storage','line_number':343,'multiline':False]
['text':' a view tensor could be contiguous (e.g., slice ops) or non-contiguous (e.g., transpose())','line_number':346,'multiline':False]
['text':' use "_tensor" from Placeholder to retain view's output during its usage in other ops','line_number':349,'multiline':False]
['text':' if we cannot gather, we make the tensor contiguous implicitly, and keep','line_number':352,'multiline':False]
['text':' it in placeholder to be able to retrieve it when we return from constructor','line_number':353,'multiline':False]
['text':' tensor.numel() could be zero, but tensor is valid as long as the buffer size is non-zero.','line_number':359,'multiline':False]
['text':' if buffer size is zero in here, it's not a user error. It could be a missing check for','line_number':360,'multiline':False]
['text':' tensor.numel() == 0 in our internal implementations of ops.','line_number':361,'multiline':False]
['text':' create empty NDArray','line_number':390,'multiline':False]
['text':' Scalar pools are only supported on devices with unified memory','line_number':425,'multiline':False]
['text':' Copied and modified from aten/stc/ATen/ScalarOps.h','line_number':447,'multiline':False]
['text':' as MPS doesn't support float64 tensor.','line_number':448,'multiline':False]
['text':' this is meant to suppress the availability warning on castTensor','line_number':489,'multiline':False]
['text':' we pass ScalarType instead of MPSDataType to handle MPSDataTypeBoolean's availability too','line_number':490,'multiline':False]
['text':' for interval-based signpost tracing, we begin the interval here to be able','line_number':532,'multiline':False]
['text':' to measure the time it takes to compile the graphs (if graph newly created),','line_number':533,'multiline':False]
['text':' and also the time potentially spent on gather/scatter of graph's input tensors','line_number':534,'multiline':False]
['text':' namespace at::native::mps','line_number':551,'multiline':False]
