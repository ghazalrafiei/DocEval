['text':' namespace at::native','line_number':76,'multiline':False]
['text':' AT_MKLDNN_EBABLED','line_number':78,'multiline':False]
['text':' RNN_RELU; RNN_TANH','line_number':125,'multiline':False]
['text':' mkldnn memory descriptors','line_number':131,'multiline':False]
['text':' logical size described as ldigo','line_number':144,'multiline':False]
['text':' MKLDNN GRU gate order is different from PyTorch's which requires gates shuffle','line_number':182,'multiline':False]
['text':' (let rt,zt,nt be reset, update, new gates respectively)','line_number':183,'multiline':False]
['text':'','line_number':184,'multiline':False]
['text':'   MKLDNN GRU weight_ih/weight_hh gates order: (zt, rt, nt)','line_number':185,'multiline':False]
['text':'   PyTorch GRU weight_ih/weight_hh gates order: (rt, zt, nt)','line_number':186,'multiline':False]
['text':'','line_number':187,'multiline':False]
['text':' MKLDNN GRU bias has 4 gates instead of 3','line_number':188,'multiline':False]
['text':'  (PyTorch GRU bias)     (MKLDNN GRU bias)','line_number':189,'multiline':False]
['text':'','line_number':190,'multiline':False]
['text':'  bias_ih    bias_hh          bias','line_number':191,'multiline':False]
['text':'  +-----+    +-----+       +---------+','line_number':192,'multiline':False]
['text':'  | rt1 |    | rt2 |       | zt1+zt2 |','line_number':193,'multiline':False]
['text':'  |-----|    |-----|       |---------|','line_number':194,'multiline':False]
['text':'  | zt1 |    | zt2 |       | rt1+rt2 |','line_number':195,'multiline':False]
['text':'  |-----|    |-----|       |---------|','line_number':196,'multiline':False]
['text':'  | nt1 |    | nt2 |       |   nt1   |','line_number':197,'multiline':False]
['text':'  +-----+    +-----+       |---------|','line_number':198,'multiline':False]
['text':'                           |   nt2   |','line_number':199,'multiline':False]
['text':'                           +---------+','line_number':200,'multiline':False]
['text':'','line_number':201,'multiline':False]
['text':'gates','line_number':205,'multiline':True]
['text':'gates','line_number':206,'multiline':True]
['text':'output_channels','line_number':213,'multiline':True]
['text':'output_channels','line_number':214,'multiline':True]
['text':'output_channels','line_number':215,'multiline':True]
['text':'is_single_direction','line_number':246,'multiline':True]
['text':' Packed weight will be mkldnn layout while bias won't be packed','line_number':255,'multiline':False]
['text':' per layer input size','line_number':260,'multiline':False]
['text':'is_single_direction','line_number':340,'multiline':True]
['text':' per layer input size','line_number':350,'multiline':False]
['text':' Create diff_* ATen tensor and corresponding ideep tensor as fp32','line_number':375,'multiline':False]
['text':' Convert grad_y, grad_hy, grad_cy to fp32 in non-fp32 backward','line_number':403,'multiline':False]
['text':' MKLDNN RNN integration notes:','line_number':442,'multiline':False]
['text':' I. Memory Formats','line_number':443,'multiline':False]
['text':'   a. mkldnn will use plain formats for input, hx/cx, output, hy/cy','line_number':444,'multiline':False]
['text':'      and possibly use blocked formats for weights depending shape info.','line_number':445,'multiline':False]
['text':'   b. All mkldnn memorys are created (in plain format) as views on ATen tensor,','line_number':446,'multiline':False]
['text':'      the weight reorder(if any) is handed automatically inside ideep (mkldnn bridge)','line_number':447,'multiline':False]
['text':'','line_number':448,'multiline':False]
['text':' II. MKLDNN Primitive Mapping','line_number':449,'multiline':False]
['text':'   a. mkldnn rnn primitive doesn't support training with dropout or padded input sequence.','line_number':450,'multiline':False]
['text':'   b. here break a single RNN module into { num_layers * num_directions } mkldnn rnn primitives','line_number':451,'multiline':False]
['text':'      for future need to cover these feature gaps.','line_number':452,'multiline':False]
['text':'','line_number':453,'multiline':False]
['text':'TODO: a. training with dropout','line_number':454,'multiline':False]
['text':'   b. padded sequence input support','line_number':455,'multiline':False]
['text':'','line_number':456,'multiline':False]
['text':' bias won't be packed','line_number':493,'multiline':False]
['text':'output_channels','line_number':503,'multiline':True]
['text':'train=','line_number':505,'multiline':True]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':517,'multiline':False]
['text':'// MKLDNN dispatch for the generic RNN ops (at::lstm, at::gru, ...)','line_number':518,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':519,'multiline':False]
['text':' Helpers for working with different hidden types.','line_number':523,'multiline':False]
['text':'batch_sizes','line_number':551,'multiline':True]
['text':' anonymous namespace','line_number':566,'multiline':False]
['text':' namespace at::native','line_number':570,'multiline':False]
['text':' AT_MKLDNN_EBABLED','line_number':572,'multiline':False]
