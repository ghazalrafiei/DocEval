['text':' TODO: use is_integeral/is_same to check the scalar_t and simplify the implementation','line_number':32,'multiline':False]
['text':' currently it does not work','line_number':33,'multiline':False]
['text':' Pass I: init out lane','line_number':86,'multiline':False]
['text':' Pass II: compute local max','line_number':98,'multiline':False]
['text':' true = all ones, false = all zeros','line_number':112,'multiline':False]
['text':' std::is_same<scalar_t, at::BFloat16> || std::is_same<scalar_t, at::Half>','line_number':136,'multiline':False]
['text':' Pass I: init out lane','line_number':159,'multiline':False]
['text':' Pass II: compute local max','line_number':171,'multiline':False]
['text':' true = all ones, false = all zeros','line_number':190,'multiline':False]
['text':' out_vec.store(out + d2);','line_number':203,'multiline':False]
['text':' Convert max values from float to bfloat16/half','line_number':220,'multiline':False]
['text':' treat batch size and channels as one dimension','line_number':268,'multiline':False]
['text':'','line_number':269,'multiline':False]
['text':' MaxPool2d:','line_number':270,'multiline':False]
['text':'   ndim == 3: CHW','line_number':271,'multiline':False]
['text':'   ndim == 4: NCHW','line_number':272,'multiline':False]
['text':'','line_number':273,'multiline':False]
['text':' MaxPool3d:','line_number':274,'multiline':False]
['text':'   ndim == 4: CDHW','line_number':275,'multiline':False]
['text':'   ndim == 5: NCDHW','line_number':276,'multiline':False]
['text':' parallel on dim N, C','line_number':291,'multiline':False]
['text':' compute local max','line_number':313,'multiline':False]
['text':' set output to local max and store location of max','line_number':335,'multiline':False]
['text':' MaxPool2d: NHWC','line_number':366,'multiline':False]
['text':' MaxPool3d: NDHWC','line_number':367,'multiline':False]
['text':' for the convience of vectorization, use integer of the same size of scalar_t,','line_number':409,'multiline':False]
['text':'   e.g. int32_t for float, int64_t for double','line_number':410,'multiline':False]
['text':' need to make sure doesn't overflow','line_number':411,'multiline':False]
['text':' parallel on dim N, {D}, H, W','line_number':414,'multiline':False]
['text':' temp buffer holding index with integer_t','line_number':424,'multiline':False]
['text':' temp buffer holding max value with opmath_t','line_number':427,'multiline':False]
['text':' convert indice data type','line_number':453,'multiline':False]
['text':' move on to next output index','line_number':456,'multiline':False]
['text':' treat batch size and channels as one dimension','line_number':483,'multiline':False]
['text':'','line_number':484,'multiline':False]
['text':' MaxPool2d:','line_number':485,'multiline':False]
['text':'   ndim == 3: CHW','line_number':486,'multiline':False]
['text':'   ndim == 4: NCHW','line_number':487,'multiline':False]
['text':'','line_number':488,'multiline':False]
['text':' MaxPool3d:','line_number':489,'multiline':False]
['text':'   ndim == 4: CDHW','line_number':490,'multiline':False]
['text':'   ndim == 5: NCDHW','line_number':491,'multiline':False]
['text':' parallel on dim of N, C','line_number':507,'multiline':False]
['text':' retrieve position of max','line_number':517,'multiline':False]
['text':' update gradient','line_number':521,'multiline':False]
['text':' MaxPool2d: NHWC','line_number':556,'multiline':False]
['text':' MaxPool3d: NDHWC','line_number':557,'multiline':False]
['text':' parallel on dim N','line_number':567,'multiline':False]
['text':' TODO: gcc vectorization','line_number':579,'multiline':False]
['text':'is 3d','line_number':608,'multiline':True]
['text':' align with cuda:','line_number':633,'multiline':False]
['text':' work around buggy behavior of suggest_memory_format here where','line_number':634,'multiline':False]
['text':' suggested format of unsqueezed tensor is contiguous while it is','line_number':635,'multiline':False]
['text':' really only contiguous in ChannelsLast3d','line_number':636,'multiline':False]
['text':'is 3d','line_number':647,'multiline':True]
['text':'is 3d','line_number':658,'multiline':True]
['text':'is 3d','line_number':682,'multiline':True]
['text':'is 3d','line_number':688,'multiline':True]
['text':' align with cuda:','line_number':703,'multiline':False]
['text':' work around buggy behavior of suggest_memory_format here where','line_number':704,'multiline':False]
['text':' suggested format of unsqueezed tensor is contiguous while it is','line_number':705,'multiline':False]
['text':' really only contiguous in ChannelsLast3d','line_number':706,'multiline':False]
['text':'is_3d','line_number':715,'multiline':True]
['text':'is_3d','line_number':724,'multiline':True]
['text':'is_3d','line_number':730,'multiline':True]
['text':' anonymous namespace','line_number':739,'multiline':False]
['text':' at::native','line_number':745,'multiline':False]
