['text':' TODO: this file could benefit from a global renaming of its functions /','line_number':26,'multiline':False]
['text':' classes and terms, as well as from adding more comments. In particular:','line_number':27,'multiline':False]
['text':' - It's not obvious that despite their names (and the file name), all these','line_number':28,'multiline':False]
['text':'   kernels don't just do upsampling: they do general interpolation, i.e. they','line_number':29,'multiline':False]
['text':'   also all support downscaling.','line_number':30,'multiline':False]
['text':' - the term "horizontal" or "within dims" or "contiguous dim" refers to the','line_number':31,'multiline':False]
['text':'   last dimension.','line_number':32,'multiline':False]
['text':'   It's not specific to 2D images and applies to 3D (and 1D??) inputs as well.','line_number':33,'multiline':False]
['text':'   Similarly "vertical" or "across dims" refers to all dims that aren't the','line_number':34,'multiline':False]
['text':'   last one. In other kernels these are also referred to as "zero-stride" and','line_number':35,'multiline':False]
['text':'   "non-zero-stride" - we should unify all this.','line_number':36,'multiline':False]
['text':' - the terms "zero-stride" and "non-zero strides" refer to the weights and','line_number':37,'multiline':False]
['text':'   indices, not to the contiguity of input or output','line_number':38,'multiline':False]
['text':' - It's not always clear which kernel is vectorized and which one isn't.','line_number':39,'multiline':False]
['text':' - The functions like _use_vectorized_kernel_cond() should be renamed and','line_number':40,'multiline':False]
['text':'   their description updated, because they're not the only "fork" in the','line_number':41,'multiline':False]
['text':'   code-path where a choice is made between a vectorized kernel vs a','line_number':42,'multiline':False]
['text':'   non-vectorized one. See e.g. upsample_bilinear2d_kernel_impl() where we','line_number':43,'multiline':False]
['text':'   already make a similar check, before the one in','line_number':44,'multiline':False]
['text':'   _use_vectorized_kernel_cond().','line_number':45,'multiline':False]
['text':' - It's not always clear which code is part of a "separable interpolation"','line_number':46,'multiline':False]
['text':'   code-path.','line_number':47,'multiline':False]
['text':' - Some names need to be more specific. For example','line_number':48,'multiline':False]
['text':'   "cpu_upsample_generic_aa()" looks like a super generic name, but the function','line_number':49,'multiline':False]
['text':'   is instead fairly specific - we need to make that clearer.','line_number':50,'multiline':False]
['text':' - Some functions have a "aa" suffix but it doesn't mean that they only','line_number':51,'multiline':False]
['text':'   support antialias. Some of them also support antialias=False now.','line_number':52,'multiline':False]
['text':' - Various comments are outdated. Case in point: the one just below about the','line_number':53,'multiline':False]
['text':'   `Interpolate` struct being used for cpu_upsample_linear:','line_number':54,'multiline':False]
['text':'   cpu_upsample_linear doesn't exist anymore, and these structs are used for','line_number':55,'multiline':False]
['text':'   various modes, *not* just linear.','line_number':56,'multiline':False]
['text':' - It'd be useful to document how interpolation works in general, and in particular state explicitly:','line_number':57,'multiline':False]
['text':'   - that the weights and indices across a given dimension are the same for','line_number':58,'multiline':False]
['text':'     all pixels (hence the benefit of pre-computing them)','line_number':59,'multiline':False]
['text':'   - that it can be "separated", i.e. we can do the horizontal pass and the','line_number':60,'multiline':False]
['text':'     vertical pass independently (and that some kernels are written this way,','line_number':61,'multiline':False]
['text':'     while some aren't.)','line_number':62,'multiline':False]
['text':' - we can probably remove the template over index_t, because it's always','line_number':63,'multiline':False]
['text':'   hard-coded as int64_t','line_number':64,'multiline':False]
['text':' Helper structs and methods for cpu_upsample_linear','line_number':67,'multiline':False]
['text':'','line_number':68,'multiline':False]
['text':' Interpolation methods that used below are separable, and as such we can compute the interpolation','line_number':69,'multiline':False]
['text':' independently per dimension in a recursive way. Please, refer to #10482 for more context.','line_number':70,'multiline':False]
['text':'','line_number':71,'multiline':False]
['text':' Interpolation structure to compute output value in n-dimensional case.','line_number':72,'multiline':False]
['text':' - recursively compute interpolated output for each dimension','line_number':73,'multiline':False]
['text':' - we rely a lot on compiler's code optimization such that implemented operations','line_number':74,'multiline':False]
['text':'   can be automatically factorized and vectorized using SSE and AVX2','line_number':75,'multiline':False]
['text':' There is an unexpected 2x slowdown for upsample_trilinear3d channels_first','line_number':126,'multiline':False]
['text':' for both 1 and 6 threads. We have to specialize this case as below:','line_number':127,'multiline':False]
['text':' Once the issue is fixed we can keep generic implementation and remove:','line_number':128,'multiline':False]
['text':' struct Interpolate<n, scalar_t, index_t, 2> and','line_number':129,'multiline':False]
['text':' struct Interpolate<1, scalar_t, index_t, 2>','line_number':130,'multiline':False]
['text':' Helper class to recursively check if all input strides corresponding to interpolated dimensions','line_number':232,'multiline':False]
['text':' are equal zero except on a single dimension.','line_number':233,'multiline':False]
['text':'','line_number':234,'multiline':False]
['text':' Inputs: array of strides of size N, non_zero_stride_dim which can be -1, 0, 1, 2, ...','line_number':235,'multiline':False]
['text':'   if non_zero_stride_dim, we check that all strides are equal zero, otherwise','line_number':236,'multiline':False]
['text':'   4 strides corresponding to the strides for index_0, weight_0, index_1 and weight_1 for non_zero_stride_dim','line_number':237,'multiline':False]
['text':'   dimension should be non zero.','line_number':238,'multiline':False]
['text':'','line_number':239,'multiline':False]
['text':' Unit check of the recursion is to verify whether 4 strides for one interpolated dimension are either zero,','line_number':240,'multiline':False]
['text':' see method is_zero_stride, or (sizeof(index_t), sizeof(scalar_t), sizeof(index_t), sizeof(scalar_t)), see','line_number':241,'multiline':False]
['text':' method is_contiguous_stride.','line_number':242,'multiline':False]
['text':'','line_number':243,'multiline':False]
['text':' In practice, we have the following cases:','line_number':244,'multiline':False]
['text':' - for ND, float32, channel first, strides are','line_number':245,'multiline':False]
['text':'         dimN-1,              dim1,           dim0','line_number':246,'multiline':False]
['text':'         i0, w0, i1, w1, ..., i0, w0, i1, w1, i0, w0, i1, w1','line_number':247,'multiline':False]
['text':' strides=(0,  0,  0,  0, ...,  0,  0,  0,  0,  4,  4,  4,  4)','line_number':248,'multiline':False]
['text':'','line_number':249,'multiline':False]
['text':' if size dim0 is 1 then its strides are 0 and dim1 strides are equal 4','line_number':250,'multiline':False]
['text':'','line_number':251,'multiline':False]
['text':' - for ND, float32, channel last, strides are','line_number':252,'multiline':False]
['text':'         dimN-1,         dimN-2,             dim0','line_number':253,'multiline':False]
['text':'         i0, w0, i1, w1, i0, w0, i1, w1, ... i0, w0, i1, w1','line_number':254,'multiline':False]
['text':' strides=(0,  0,  0,  0,  0,  0,  0,  0, ..., 0,  0,  0,  0)','line_number':255,'multiline':False]
['text':'','line_number':256,'multiline':False]
['text':' Using these methods we can hint the compiler to factorize constant indices and weights','line_number':257,'multiline':False]
['text':' in cpu_upsample_linear method','line_number':258,'multiline':False]
['text':' N is dim index: N -> dim0, N-1 -> dim1, ...','line_number':262,'multiline':False]
['text':' non_zero_stride_dim should be out_dims - dim','line_number':263,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':264,'multiline':False]
['text':'strides','line_number':279,'multiline':True]
['text':' Helper method to compute interpolation for nearest, linear, cubic modes','line_number':289,'multiline':False]
['text':' index stride is constant for the given dimension','line_number':308,'multiline':False]
['text':' See Note [ Weights computation for uint8_t and multiplication trick ]','line_number':324,'multiline':False]
['text':' index stride is constant for the given dimension','line_number':328,'multiline':False]
['text':' Intermediate computations are using integer type','line_number':344,'multiline':False]
['text':' accounts for the +0.5 part','line_number':345,'multiline':False]
['text':' index stride is constant for the given dimension','line_number':364,'multiline':False]
['text':' See Note [ Weights computation for uint8_t and multiplication trick ]','line_number':388,'multiline':False]
['text':' index stride is constant for the given dimension','line_number':391,'multiline':False]
['text':' Here we are implementing data interpolation within the same line (vs between the lines)','line_number':396,'multiline':False]
['text':' output[x, y] = input[xmin[x], y] * W[x] + input[xmin[x] + 1, y] * W[x + 1] + ... + input[xmin[x] + xsize, y] * W[x + xsize]','line_number':397,'multiline':False]
['text':' Intermediate computations are using integer type','line_number':411,'multiline':False]
['text':' accounts for the +0.5 part','line_number':412,'multiline':False]
['text':' Generic upsampling computation method using TensorIterator for Nd case.','line_number':423,'multiline':False]
['text':' Supports: nearest, linear, cubic modes with interp_size template argument: 1, 2, 4','line_number':424,'multiline':False]
['text':'','line_number':425,'multiline':False]
['text':' Single loop function for 1d, 2d and 3d cases and modes','line_number':426,'multiline':False]
['text':' For N dimensions, output value up to Di dimension can be computed as','line_number':427,'multiline':False]
['text':'','line_number':428,'multiline':False]
['text':' output_i[a] = interpolate(output_{i+1}[a], w_{i+1}[a], output_{i+1}[a+1], w_{i+1}[a+1], ...)','line_number':429,'multiline':False]
['text':' with','line_number':430,'multiline':False]
['text':' output_DN[a] = interpolate(input_DN[a], w_DN[a], input_DN[a+1], w_DN[a+1], ...)','line_number':431,'multiline':False]
['text':' and i - dimension index and a - linear index for spatial coordinates','line_number':432,'multiline':False]
['text':'','line_number':433,'multiline':False]
['text':' The recursive call is implemented with InterpLinear struct using template for','line_number':434,'multiline':False]
['text':' the loop unrolling on compile time.','line_number':435,'multiline':False]
['text':' special-cases to let the compiler apply compile-time input-specific optimizations','line_number':440,'multiline':False]
['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':442,'multiline':False]
['text':' contiguous channels-first case','line_number':444,'multiline':False]
['text':' contiguous channels-last case','line_number':448,'multiline':False]
['text':' fallback','line_number':451,'multiline':False]
['text':' upsample nearest 2d','line_number':540,'multiline':False]
['text':' upsample nearest 3d','line_number':543,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':609,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':659,'multiline':False]
['text':' upsample nearest 2d','line_number':713,'multiline':False]
['text':' upsample nearest 3d','line_number':716,'multiline':False]
['text':' Helper structs to use with upsample_generic_Nd_kernel_impl','line_number':726,'multiline':False]
['text':' align_corners_delta is 0.5 for uint8 and align_corners=true and antialias=false','line_number':751,'multiline':False]
['text':'                     is 0.0 otherwise','line_number':752,'multiline':False]
['text':' There are rare cases when due to precision xsize can be larger than max_interp_size by one.','line_number':761,'multiline':False]
['text':' We have to clip the value','line_number':762,'multiline':False]
['text':' Note [ Support for antialias=False as a subcase of antilias=True ]','line_number':786,'multiline':False]
['text':' This function was originally written with the hard assumption that','line_number':787,'multiline':False]
['text':' antialias=True (hence the aa in the name). It was later extended to support','line_number':788,'multiline':False]
['text':' antialias=False. The only difference between aa and no-aa is in how the','line_number':789,'multiline':False]
['text':' weights and indices are computed (and their number). In aa their number is','line_number':790,'multiline':False]
['text':' variable but with no-aa, they're fixed to interp_size. The same "filters"','line_number':791,'multiline':False]
['text':' can be used otherwise. HOWEVER, support for antialias=False here may not be','line_number':792,'multiline':False]
['text':' optimally optimized: the code assumes an arbitrary number of weights and','line_number':793,'multiline':False]
['text':' indices, but this can be optimized further when aa=False since we know','line_number':794,'multiline':False]
['text':' their actual dimensions.','line_number':795,'multiline':False]
['text':' Bounds approach as in PIL: xmin/xmax','line_number':818,'multiline':False]
['text':' Weights','line_number':827,'multiline':False]
['text':' Weights indices','line_number':835,'multiline':False]
['text':'
  NOTE [ Weights computation for uint8_t and multiplication trick ]
  When the input/output dtype is uint8_t, we still compute the interpolation
  weights as double, but then convert them to int16 via some conversion logic
  detailed below. This allows us to compute all interpolation operation (sum of
  multiplications) as ints instead of floats. The result is converted back into
  uint8 in basic_loop_aa_horizontal<uint8_t> (and vertical)

  In essence the idea is to avoid a multiplication between a float (the
  weight) and an int (the pixel value) and instead run a multpilication between
  2 ints:

  ```py
  COEF_PREC = 16

  def mul(a:float, b:int) -> Tuple[float, int]:
    # return a * b, round(a * b)
    actual = a * b

    assert a > 0  # I'm lazy
    int_a = floor(0.5 + a * (1 << COEF_PREC))
    with_trick = ((int_a * b) + (1 << (COEF_PREC - 1))) >> COEF_PREC

    return actual, with_trick  # round(actual) == with_trick!!
  ```

  Here's how it works:
  N == COEFF_PREC
  1 << N == 2**N
  floor(0.5 + x) == round(x)

  So the operation is something like

  int_a = round(a * 2**N)  -- let's just say it's `a * 2**N` for simplicity

  res = ((int_a * b) + (1 << (N - 1))) >> N
      = ((a * 2**N * b + 2**(N - 1)) / 2**N
      = a * b + 0.5
      = round(a * b)
      = what we wanted
  ','line_number':872,'multiline':True]
['text':' Rescale float weights to int16 and compute weights precision','line_number':929,'multiline':False]
['text':' Rescale float values to int16','line_number':940,'multiline':False]
['text':' We should respect int32 alignment as we will load int16 data as int32','line_number':945,'multiline':False]
['text':' See ImagingResampleHorizontalConvolution8u4x, mmk0 = _mm256_set1_epi32(*(int32_t*)&k[x]);','line_number':946,'multiline':False]
['text':' compute aligned_interp_size = nearest pair value to interp_size','line_number':947,'multiline':False]
['text':' assert that we wont go out of bounds','line_number':951,'multiline':False]
['text':' This structure implements outdated and buggy method to compute indices','line_number':967,'multiline':False]
['text':' for nearest neighbours interpolation','line_number':968,'multiline':False]
['text':' We keep this structure for BC and consider as deprecated.','line_number':969,'multiline':False]
['text':' See HelperInterpNearestExact as replacement','line_number':970,'multiline':False]
['text':' Defines weights for consistency, but not used','line_number':984,'multiline':False]
['text':' Compute nearest mode indices and weights for each interpolated dimension','line_number':989,'multiline':False]
['text':' indices_weights = {','line_number':990,'multiline':False]
['text':'      {indices_0, 1.0, },  // dim -n','line_number':991,'multiline':False]
['text':'      {indices_0, 1.0, },  // dim -(n-1)','line_number':992,'multiline':False]
['text':'      ...','line_number':993,'multiline':False]
['text':'      {indices_0, 1.0, },  // dim -1','line_number':994,'multiline':False]
['text':' }','line_number':995,'multiline':False]
['text':' Indices and weights are reshaped as (1, 1, ..., N, ..., 1, 1) to','line_number':996,'multiline':False]
['text':' fit input/output tensors.','line_number':997,'multiline':False]
['text':' Indices are already containing the strides to optimize the computations','line_number':998,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1006,'multiline':False]
['text':' Indices are computed as following:','line_number':1019,'multiline':False]
['text':' scale = 1.0 * isize / osize','line_number':1020,'multiline':False]
['text':' index_f32 = (output_index) * scale','line_number':1021,'multiline':False]
['text':' input_index = floor(index_f32)','line_number':1022,'multiline':False]
['text':' Same as OpenCV INTER_NEAREST','line_number':1023,'multiline':False]
['text':'align_corners=','line_number':1027,'multiline':True]
['text':'cubic=','line_number':1027,'multiline':True]
['text':' Compute nearest mode indices and weights for each interpolated dimension','line_number':1040,'multiline':False]
['text':' indices_weights = {','line_number':1041,'multiline':False]
['text':'      {indices_0, 1.0, },  // dim -n','line_number':1042,'multiline':False]
['text':'      {indices_0, 1.0, },  // dim -(n-1)','line_number':1043,'multiline':False]
['text':'      ...','line_number':1044,'multiline':False]
['text':'      {indices_0, 1.0, },  // dim -1','line_number':1045,'multiline':False]
['text':' }','line_number':1046,'multiline':False]
['text':' Indices and weights are reshaped as (1, 1, ..., N, ..., 1, 1) to','line_number':1047,'multiline':False]
['text':' fit input/output tensors.','line_number':1048,'multiline':False]
['text':' Indices are already containing the strides to optimize the computations','line_number':1049,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1057,'multiline':False]
['text':' Indices should be computed as following:','line_number':1069,'multiline':False]
['text':' scale = 1.0 * isize / osize','line_number':1070,'multiline':False]
['text':' index_f32 = (output_index + 0.5) * scale - 0.5','line_number':1071,'multiline':False]
['text':' input_index = round(index_f32)','line_number':1072,'multiline':False]
['text':' Same as Pillow and Scikit-Image/Scipy ndi.zoom','line_number':1073,'multiline':False]
['text':'align_corners=','line_number':1078,'multiline':True]
['text':'cubic=','line_number':1078,'multiline':True]
['text':' Compute indices and weights for each interpolated dimension','line_number':1092,'multiline':False]
['text':' indices_weights = {','line_number':1093,'multiline':False]
['text':'      {indices_0, weights_0, indices_1, weights_1},  // dim -n','line_number':1094,'multiline':False]
['text':'      {indices_0, weights_0, indices_1, weights_1},  // dim -(n-1)','line_number':1095,'multiline':False]
['text':'      ...','line_number':1096,'multiline':False]
['text':'      {indices_0, weights_0, indices_1, weights_1},  // dim -1','line_number':1097,'multiline':False]
['text':' }','line_number':1098,'multiline':False]
['text':' Indices and weights are reshaped as (1, 1, ..., N, ..., 1, 1) to','line_number':1099,'multiline':False]
['text':' fit input/output tensors.','line_number':1100,'multiline':False]
['text':' Indices are already containing the strides to optimize the computations','line_number':1101,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1107,'multiline':False]
['text':' put stride into indices','line_number':1128,'multiline':False]
['text':' index values correspond to input indices (0, 1, 2, 3, ...)','line_number':1129,'multiline':False]
['text':' when multiplied by input stride, maximum possible value','line_number':1130,'multiline':False]
['text':' input_size[dim-1] * input_size[dim-2] * ... for the given dimension.','line_number':1131,'multiline':False]
['text':' taken from','line_number':1140,'multiline':False]
['text':' https://github.com/python-pillow/Pillow/blob/6812205f18ca4ef54372e87e1a13ce4a859434df/','line_number':1141,'multiline':False]
['text':' src/libImaging/Resample.c#L20-L29','line_number':1142,'multiline':False]
['text':'antialias=','line_number':1185,'multiline':True]
['text':'align_corners_delta=','line_number':1186,'multiline':True]
['text':' Compute indices and weights for each interpolated dimension','line_number':1216,'multiline':False]
['text':' indices_weights = {','line_number':1217,'multiline':False]
['text':'      {indices_0, weights_0, indices_1, weights_1, ..., indices_3, weights_3},  // dim -n','line_number':1218,'multiline':False]
['text':'      {indices_0, weights_0, indices_1, weights_1, ..., indices_3, weights_3},  // dim -(n-1)','line_number':1219,'multiline':False]
['text':'      ...','line_number':1220,'multiline':False]
['text':'      {indices_0, weights_0, indices_1, weights_1, ..., indices_3, weights_3},  // dim -1','line_number':1221,'multiline':False]
['text':' }','line_number':1222,'multiline':False]
['text':' Indices and weights are reshaped as (1, 1, ..., N, ..., 1, 1) to','line_number':1223,'multiline':False]
['text':' fit input/output tensors.','line_number':1224,'multiline':False]
['text':' Indices are already containing the strides to optimize the computations','line_number':1225,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1231,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-c-arrays,modernize-avoid-c-arrays)','line_number':1243,'multiline':False]
['text':'cubic=','line_number':1251,'multiline':True]
['text':' taken from','line_number':1268,'multiline':False]
['text':' https://github.com/python-pillow/Pillow/blob/6812205f18ca4ef54372e87e1a13ce4a859434df/','line_number':1269,'multiline':False]
['text':' src/libImaging/Resample.c#L46-L62','line_number':1270,'multiline':False]
['text':' https://en.wikipedia.org/wiki/Bicubic_interpolation#Bicubic_convolution_algorithm','line_number':1273,'multiline':False]
['text':' a = -0.5 was proposed by R. Keys in "Cubic convolution interpolation for digital image processing"','line_number':1274,'multiline':False]
['text':' We are using -0.5 for bicubic, antialiasing=true (compatibility with PIL)','line_number':1275,'multiline':False]
['text':' and using -0.75 for bicubic, antialiasing=false (compatibility with Opencv)','line_number':1276,'multiline':False]
['text':'antialias=','line_number':1322,'multiline':True]
['text':'align_corners_delta','line_number':1323,'multiline':True]
['text':' We have to use the -0.75 constant when aa is False so that this uint8','line_number':1342,'multiline':False]
['text':' path is as close as possible to float results.','line_number':1343,'multiline':False]
['text':' Generic upsampling interpolation kernel for N-d case.','line_number':1352,'multiline':False]
['text':' Input is assumed to be like NCHW, NCL, NCKHW - interpolated spatial dimension','line_number':1353,'multiline':False]
['text':' are those from the end up to batch size N and number of channels C.','line_number':1354,'multiline':False]
['text':'','line_number':1355,'multiline':False]
['text':' Internally, it uses TensorIterator to optimize the computations.','line_number':1356,'multiline':False]
['text':' - out_ndims is the number of interpolated dims: 1, 2, 3','line_number':1357,'multiline':False]
['text':' - scale_type is template type for scales, typically c10::optional<double>','line_number':1358,'multiline':False]
['text':' - template<typename> class F is one of the above structs to compute indices and weights','line_number':1359,'multiline':False]
['text':' input can be NCHW, NCL or NCKHW','line_number':1368,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1384,'multiline':False]
['text':' nearest also supports uint8 tensor, but we have to use float','line_number':1390,'multiline':False]
['text':' with compute_indices_weights','line_number':1391,'multiline':False]
['text':' NOLINTNEXTLINE(performance-inefficient-vector-operation)','line_number':1396,'multiline':False]
['text':' Nearest also supports uint8 tensor, so need to handle it separately','line_number':1421,'multiline':False]
['text':' MSVC can not catch constexpr int interp_size here','line_number':1424,'multiline':False]
['text':' Strides are : X 0 | 8 8 8 0 8  (Channels first)','line_number':1443,'multiline':False]
['text':' Strides are : X X | 0 0 0 0 0  (Channels last)','line_number':1444,'multiline':False]
['text':' upsampling data within a contiguous dimension (aka horizontal resampling)','line_number':1445,'multiline':False]
['text':' channels last case','line_number':1448,'multiline':False]
['text':' Strides are : X Y | 0 0 0 0 0 (Channels first)','line_number':1456,'multiline':False]
['text':' Strides are : X X | 0 0 0 0 0 (Channels last)','line_number':1457,'multiline':False]
['text':' upsampling data between contiguous dimensions (aka vertical resampling)','line_number':1458,'multiline':False]
['text':' input can be NCHW, NCL or NCKHW','line_number':1482,'multiline':False]
['text':' This is a special branch to provide uint8 dtype support for bilinear and bicubic modes only','line_number':1504,'multiline':False]
['text':' Generic separable upsampling interpolation kernel for N-d case with anti-aliasing.','line_number':1540,'multiline':False]
['text':' It also supports antialias=False iff','line_number':1541,'multiline':False]
['text':' (dtype == uint8 and mode in ("bilinear", "bicubic")): this is used as','line_number':1542,'multiline':False]
['text':' fallback in these settings when AVX isn't supported.','line_number':1543,'multiline':False]
['text':' Precompute the number of single dim resize method invocations','line_number':1564,'multiline':False]
['text':' to avoid copying temporary buffer to output','line_number':1565,'multiline':False]
['text':' upsampling data within the contiguous dimension (aka horizontal resampling)','line_number':1574,'multiline':False]
['text':' upsampling data between contiguous dimensions (aka vertical resampling)','line_number':1595,'multiline':False]
['text':' This condition is used to know whether we should dispatch to a vectorized','line_number':1638,'multiline':False]
['text':' kernel, or to the more general upsample_generic_Nd_kernel_impl(). For now,','line_number':1639,'multiline':False]
['text':' the vectorized kernels are only optimized for channels_last and when C >= 4','line_number':1640,'multiline':False]
['text':' (shape = NCHW). For a very wide range of use-cases (typically image or mask','line_number':1641,'multiline':False]
['text':' resizing where we have C < 4), using upsample_generic_Nd_kernel_impl() is','line_number':1642,'multiline':False]
['text':' actually faster. On top of that, benchmarks showed that this also depends on','line_number':1643,'multiline':False]
['text':' the *output* size (output_H + output_W), for both upsampling and','line_number':1644,'multiline':False]
['text':' downsampling. The current 128 threshold was determined through benchmarks.','line_number':1645,'multiline':False]
['text':' Similar to _use_vectorized_kernel_cond_2d() but for 3d resampling (e.g. videos)','line_number':1650,'multiline':False]
['text':' Note that unlike the 2d case, this is not subject to small output size','line_number':1651,'multiline':False]
['text':' overhead - hence the absence of the 128 threshold in the condition.','line_number':1652,'multiline':False]
['text':' See note above about _use_vectorized_kernel_cond_2d(output, input). The extra cond is present','line_number':1740,'multiline':False]
['text':' because benchmarks showed that with only 1 thread, images (C == 3) were','line_number':1741,'multiline':False]
['text':' slightly faster with the vectorized kernel than with the generic one.','line_number':1742,'multiline':False]
['text':' That's not the case for masks though (C == 1), which strongly benefit from','line_number':1743,'multiline':False]
['text':' using the generic kernel.','line_number':1744,'multiline':False]
['text':'antialias=','line_number':1767,'multiline':True]
['text':'antialias=','line_number':1771,'multiline':True]
['text':' CPU_CAPABILITY_AVX2','line_number':1773,'multiline':False]
['text':'antialias=','line_number':1776,'multiline':True]
['text':' CPU_CAPABILITY_AVX2','line_number':1777,'multiline':False]
['text':'antialias=','line_number':1794,'multiline':True]
['text':'antialias=','line_number':1798,'multiline':True]
['text':' CPU_CAPABILITY_AVX2','line_number':1800,'multiline':False]
['text':'antialias=','line_number':1803,'multiline':True]
['text':' CPU_CAPABILITY_AVX2','line_number':1804,'multiline':False]
['text':'antialias=','line_number':1836,'multiline':True]
['text':'antialias=','line_number':1840,'multiline':True]
['text':' CPU_CAPABILITY_AVX2','line_number':1842,'multiline':False]
['text':'antialias=','line_number':1845,'multiline':True]
['text':' CPU_CAPABILITY_AVX2','line_number':1846,'multiline':False]
['text':'antialias=','line_number':1865,'multiline':True]
['text':'antialias=','line_number':1869,'multiline':True]
['text':' CPU_CAPABILITY_AVX2','line_number':1871,'multiline':False]
['text':'antialias=','line_number':1874,'multiline':True]
['text':' CPU_CAPABILITY_AVX2','line_number':1875,'multiline':False]
['text':' treat nbatch and channels as one dimension','line_number':1899,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1934,'multiline':False]
['text':'antialias=','line_number':1952,'multiline':True]
['text':'align_corners_delta=','line_number':1953,'multiline':True]
['text':'antialias=','line_number':1966,'multiline':True]
['text':'align_corners_delta=','line_number':1967,'multiline':True]
['text':' upsample bilinear 2d','line_number':1985,'multiline':False]
['text':' anonymous namespace','line_number':2023,'multiline':False]
['text':' namespace at::native','line_number':2041,'multiline':False]
