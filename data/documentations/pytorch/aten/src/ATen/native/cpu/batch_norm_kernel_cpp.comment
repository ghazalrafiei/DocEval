['text':' optional ','line_number':33,'multiline':True]
['text':' optional ','line_number':33,'multiline':True]
['text':'/ Collect the linear and constant terms regarding the input.','line_number':45,'multiline':False]
['text':'/ output(n, c, h, w)','line_number':46,'multiline':False]
['text':'/     = (input(n, c, h, w) - mean(c)) / sqrt(var(c) + eps) * weight(c)','line_number':47,'multiline':False]
['text':'/         + bias(c)','line_number':48,'multiline':False]
['text':'/     = input(n, c, h, w) * inv_var(c) * weight(c)','line_number':49,'multiline':False]
['text':'/         - mean(c) * inv_var(c) * weight(c) + bias(c),','line_number':50,'multiline':False]
['text':'/ where inv_var(c) = 1 / sqrt(var(c) + eps).','line_number':51,'multiline':False]
['text':'/ So the linear term, alpha(c) = inv_var(c) * weight(c),','line_number':52,'multiline':False]
['text':'/   the constant term beta(c) = bias(c) - mean(c) * inv_var(c) * weight(c)','line_number':53,'multiline':False]
['text':'/ Note that this is only a good idea if (input_size >> c), in degenerate','line_number':54,'multiline':False]
['text':'/ cases where image_size == 1 && batch_size == 1, it is slow.','line_number':55,'multiline':False]
['text':'/ A fast path for CPU inference and training forward when all tensors are contiguous.','line_number':72,'multiline':False]
['text':' Apply the linear terms to the input,','line_number':96,'multiline':False]
['text':' output(n, c, h, w) = input(n, c, h, w) * alpha(c) + beta(c)','line_number':97,'multiline':False]
['text':' move on to next index','line_number':119,'multiline':False]
['text':' Apply the linear terms to the input,','line_number':148,'multiline':False]
['text':' output(n, c, h, w) = input(n, c, h, w) * alpha(c) + beta(c)','line_number':149,'multiline':False]
['text':' vectorize on channel dimension, for normal batch_norm input size,','line_number':155,'multiline':False]
['text':' alpha/beta should fit in L1 cache, otherwise consider blocking.','line_number':156,'multiline':False]
['text':' keep acc_type as opmath_type will use float type when scalar_t==float','line_number':180,'multiline':False]
['text':' while acc_type uses double for float.','line_number':181,'multiline':False]
['text':' parallel dim reduce on 'channel'','line_number':192,'multiline':False]
['text':' compute mean per input','line_number':195,'multiline':False]
['text':' compute variance per input','line_number':206,'multiline':False]
['text':' keep acc_type as opmath_type will use float type when scalar_t==float','line_number':226,'multiline':False]
['text':' while acc_type uses double for float.','line_number':227,'multiline':False]
['text':' Typical vertical reduce from shape of {NHW, C} to {C}.','line_number':236,'multiline':False]
['text':' Apply two path parallel reduction:','line_number':237,'multiline':False]
['text':' First path: allocate an immediate buffer of size {max_threads, C}, parallel along dim0,','line_number':238,'multiline':False]
['text':'    {NHW, C} => {max_threads, C}','line_number':239,'multiline':False]
['text':'','line_number':240,'multiline':False]
['text':' Second path: parallel along dim1 of the immediate buffer,','line_number':241,'multiline':False]
['text':'    {max_threads, C} => {C}','line_number':242,'multiline':False]
['text':'','line_number':243,'multiline':False]
['text':' Normal size of C should fit in L1, otherwise consider blocking on C.','line_number':244,'multiline':False]
['text':'','line_number':245,'multiline':False]
['text':' compute mean per input','line_number':250,'multiline':False]
['text':' compute variance per input, reuse the immediate buffer','line_number':278,'multiline':False]
['text':' keep acc_type as opmath_type will use float type when scalar_t==float','line_number':315,'multiline':False]
['text':' while acc_type uses double for float.','line_number':316,'multiline':False]
['text':' parallel dim reduce on 'channel'','line_number':339,'multiline':False]
['text':' reduce over grad_output in feature plane','line_number':353,'multiline':False]
['text':' compute 1) sum; 2) dot product of Q(X) and dY.','line_number':354,'multiline':False]
['text':' fuse into a single loop to reuse dY','line_number':355,'multiline':False]
['text':'','line_number':356,'multiline':False]
['text':' Scalar math:','line_number':386,'multiline':False]
['text':' for (const auto j : c10::irange(image_size)) {','line_number':387,'multiline':False]
['text':'   scalar_t dx = (x_ptr[j] - mean) * k;','line_number':388,'multiline':False]
['text':'   dx_ptr[j] = (dy_ptr[j] - grad_mean - dx) * invstd * w;','line_number':389,'multiline':False]
['text':' }','line_number':390,'multiline':False]
['text':' evaluation mode','line_number':401,'multiline':False]
['text':' Scalar math:','line_number':406,'multiline':False]
['text':' for (const auto j : c10::irange(image_size)) {','line_number':407,'multiline':False]
['text':'   dx_ptr[j] = dy_ptr[j] * invstd * w;','line_number':408,'multiline':False]
['text':' }','line_number':409,'multiline':False]
['text':' keep acc_type as opmath_type will use float type when scalar_t==float','line_number':438,'multiline':False]
['text':' while acc_type uses double for float.','line_number':439,'multiline':False]
['text':' Typical vertical reduce from shape of {NHW, C} to {C}.','line_number':475,'multiline':False]
['text':' Apply two path parallel reduction:','line_number':476,'multiline':False]
['text':' First path: allocate an immediate buffer of size {2, max_threads, C}, parallel along dim0,','line_number':477,'multiline':False]
['text':'    sum = buffer[0], dotp = buffer[2]','line_number':478,'multiline':False]
['text':'','line_number':479,'multiline':False]
['text':' Second path: parallel along dim1 of the immediate buffer.','line_number':480,'multiline':False]
['text':'','line_number':481,'multiline':False]
['text':' compute sum and dotp per feature plain,','line_number':487,'multiline':False]
['text':' fuse into a single loop to reuse grad_output in L1.','line_number':488,'multiline':False]
['text':' store the final result of sum and dotp in the 1st lane of immediate buffer,','line_number':518,'multiline':False]
['text':' so that we won't need to allocate anther buffer to store the temp values.','line_number':519,'multiline':False]
['text':' 0 * n_channel + ','line_number':524,'multiline':True]
['text':' 0 * n_channel + ','line_number':530,'multiline':True]
['text':' compute grad_input','line_number':534,'multiline':False]
['text':' evaluation mode','line_number':570,'multiline':False]
['text':' grad_weight = dotp * invstd','line_number':592,'multiline':False]
['text':' grad_bias = sum','line_number':601,'multiline':False]
['text':'/ bfloat16/Half kernels','line_number':611,'multiline':False]
['text':' use float as acc type','line_number':624,'multiline':False]
['text':' move on to next index','line_number':671,'multiline':False]
['text':' TODO: use fast version','line_number':768,'multiline':False]
['text':' TODO: use fast version','line_number':791,'multiline':False]
['text':' parallel dim reduce on 'channel'','line_number':936,'multiline':False]
['text':' compute 1) sum; 2) dot product of Q(X) and dY.','line_number':950,'multiline':False]
['text':' TODO: use fast version','line_number':976,'multiline':False]
['text':' evaluation mode','line_number':995,'multiline':False]
['text':' use float as acc type','line_number':1057,'multiline':False]
['text':' store the final result of sum and dotp in the 1st lane of immediate buffer,','line_number':1126,'multiline':False]
['text':' so that we won't need to allocate anther buffer to store the temp values.','line_number':1127,'multiline':False]
['text':' 0 * n_channel + ','line_number':1132,'multiline':True]
['text':' 0 * n_channel + ','line_number':1138,'multiline':True]
['text':' compute grad_input','line_number':1142,'multiline':False]
['text':' evaluation mode','line_number':1190,'multiline':False]
['text':' NC11 is also channels last','line_number':1250,'multiline':False]
['text':' NC11 is also channels last','line_number':1275,'multiline':False]
['text':' NC11 is also channels last','line_number':1297,'multiline':False]
['text':' anonymous namespace','line_number':1315,'multiline':False]
['text':' namespace at::native','line_number':1321,'multiline':False]
