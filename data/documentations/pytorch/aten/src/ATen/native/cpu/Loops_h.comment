['text':' This file provides two functions to help write elementwise kernels:','line_number':3,'multiline':False]
['text':'','line_number':4,'multiline':False]
['text':'   cpu_kernel(TensorIterator iter, <lambda>)','line_number':5,'multiline':False]
['text':'   cpu_kernel_vec(TensorIterator iter, <lambda>, <vec_lambda>)','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':' Both functions may generate vectorized code. The cpu_kernel implementation','line_number':8,'multiline':False]
['text':' relies on the compiler's auto-vectorization. The cpu_kernel_vec','line_number':9,'multiline':False]
['text':' implementation uses x86 SIMD intrinsics when available. These functions','line_number':10,'multiline':False]
['text':' are only intended to be used in the ATen/native/cpu subdirectory, since files','line_number':11,'multiline':False]
['text':' in other directories are not compiled with AVX/AVX2 enabled. See README.md','line_number':12,'multiline':False]
['text':' for more details.','line_number':13,'multiline':False]
['text':'','line_number':14,'multiline':False]
['text':' For example, to write a multiplication kernel for float:','line_number':15,'multiline':False]
['text':'','line_number':16,'multiline':False]
['text':'   cpu_kernel(iter, [](float a, float b) { return a * b; });','line_number':17,'multiline':False]
['text':'','line_number':18,'multiline':False]
['text':' Or you may write:','line_number':19,'multiline':False]
['text':'','line_number':20,'multiline':False]
['text':'   cpu_kernel_vec(iter,','line_number':21,'multiline':False]
['text':'     [](float a, float b) { return a * b; },','line_number':22,'multiline':False]
['text':'     [](Vectorized<float> a, Vectorized<float> b) { return a * b; });','line_number':23,'multiline':False]
['text':'','line_number':24,'multiline':False]
['text':' See BinaryOpsKernel.cpp for the complete implementation','line_number':25,'multiline':False]
['text':'','line_number':26,'multiline':False]
['text':'','line_number':27,'multiline':False]
['text':' Basic loop operation (one output, N inputs). May be auto-vectorized','line_number':111,'multiline':False]
['text':' by the compiler. Supports inputs and outputs of different types.','line_number':112,'multiline':False]
['text':' Copying strides to temporary array helps auto vectorization in older GCC','line_number':119,'multiline':False]
['text':' versions.','line_number':120,'multiline':False]
['text':' the recursive variadic template for iterating over the returned tuple','line_number':129,'multiline':False]
['text':' Base case for the above recursive template','line_number':143,'multiline':False]
['text':' Loop operation for `cpu_kernel_multiple_outputs`.','line_number':163,'multiline':False]
['text':' 1. Use `c10::guts::apply` to make dynamic method invocation','line_number':164,'multiline':False]
['text':'    for the lambda passed in `cpu_kernel_multiple_outputs`.','line_number':165,'multiline':False]
['text':' 2. Iterate over the members of the returned tuple, set the corresponding','line_number':166,'multiline':False]
['text':'    output tensor by the tuple member in `handle_tuple_outputs` function.','line_number':167,'multiline':False]
['text':' Copying strides to temporary array helps auto vectorization in older GCC','line_number':177,'multiline':False]
['text':' versions.','line_number':178,'multiline':False]
['text':' Explicitly vectorized loop implementation. All inputs and outputs must be','line_number':193,'multiline':False]
['text':' the same type and contiguous with one exception: a single input may be','line_number':194,'multiline':False]
['text':' a scalar (stride 0). It's position is indicated by the argument `S`. If `S`','line_number':195,'multiline':False]
['text':' is 0, then there are no scalar inputs.','line_number':196,'multiline':False]
['text':'strides','line_number':232,'multiline':True]
['text':' this could be extended to work with void return types','line_number':306,'multiline':False]
['text':' dynamic casting not currently supported on CPU','line_number':309,'multiline':False]
['text':' basic loop can handle 1d slices with arbitrary strides, and 1d slices is all that','line_number':313,'multiline':False]
['text':' iter.for_each is ever sending to the loop lambda','line_number':314,'multiline':False]
['text':' This function helps write elementwise kernels that requires multiple outputs.','line_number':320,'multiline':False]
['text':' It follows the similar structure of cpu_kernel.','line_number':321,'multiline':False]
['text':' Instead of `basic_loop` function, a new `multiple_outputs_loop` function is','line_number':322,'multiline':False]
['text':' manipulated to handle multiple return values.','line_number':323,'multiline':False]
['text':' For now `needs_dynamic_casting` check is not added as the passed lambda (`func_t`)','line_number':324,'multiline':False]
['text':' of `multiple_outputs_loop` returns `std::tuple` instead of `scalar_t`.','line_number':325,'multiline':False]
['text':' The `gpu_kernel_multiple_outputs` is also implemented without this check,','line_number':326,'multiline':False]
['text':' We could extend `needs_dynamic_casting` to support both `std::tuple` and','line_number':327,'multiline':False]
['text':' `thrust::tuple` in the future.','line_number':328,'multiline':False]
['text':' this could be extended to work with void return types','line_number':343,'multiline':False]
['text':' dynamic casting not currently supported on CPU, but some kernels (like Fill)','line_number':346,'multiline':False]
['text':' explicitly dynamic_cast, so we give the opt-out of checking.','line_number':347,'multiline':False]
['text':' dynamic casting not currently supported on CPU','line_number':362,'multiline':False]
['text':' this could be extended to work with void return types','line_number':379,'multiline':False]
['text':' dynamic casting not currently supported on CPU','line_number':382,'multiline':False]
['text':' namespace at::native::<anonymous>','line_number':394,'multiline':False]
