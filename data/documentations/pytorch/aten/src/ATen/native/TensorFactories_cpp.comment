['text':' namespace','line_number':127,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ arange ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':132,'multiline':False]
['text':'start=','line_number':139,'multiline':True]
['text':'step=','line_number':148,'multiline':True]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':159,'multiline':False]
['text':' bool inputs are considered integral','line_number':163,'multiline':False]
['text':'step=','line_number':175,'multiline':True]
['text':'start=','line_number':179,'multiline':True]
['text':'step=','line_number':179,'multiline':True]
['text':'step=','line_number':183,'multiline':True]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ complex / polar ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':190,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ empty ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':253,'multiline':False]
['text':' See Note [Enabling Deterministic Operations]','line_number':257,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':272,'multiline':False]
['text':' size is logical; aka, the output size you'll get from the operation overall','line_number':290,'multiline':False]
['text':'','line_number':291,'multiline':False]
['text':' physical_layout follows NCHW/NHWC convention:','line_number':292,'multiline':False]
['text':' contiguous is [0,1,2,3], channels last is [0,2,3,1]','line_number':293,'multiline':False]
['text':'','line_number':294,'multiline':False]
['text':' this means if i is physical index, physical_layout[i] is logical index;','line_number':295,'multiline':False]
['text':' e.g., to find what is innermost physical dim (3), query NHWC[3] == 1','line_number':296,'multiline':False]
['text':' (aka it is channels)','line_number':297,'multiline':False]
['text':' do a contiguous allocation','line_number':314,'multiline':False]
['text':' permute the strides (inverse permutation!  This is why this is','line_number':317,'multiline':False]
['text':' empty_permute*d*, not empty_permute; it's not an empty + permute)','line_number':318,'multiline':False]
['text':' See Note [Enabling Deterministic Operations]','line_number':329,'multiline':False]
['text':' Preferably, this argument would not be accepted by _out, but the code','line_number':339,'multiline':False]
['text':' generator requires the out and non-out overloads to match exactly','line_number':340,'multiline':False]
['text':' See Note [Enabling Deterministic Operations]','line_number':350,'multiline':False]
['text':' Temporary type cast operators. These are needed to trace type-casts now since','line_number':357,'multiline':False]
['text':' Type's are not supported in the IR. Instead, we call down to these','line_number':358,'multiline':False]
['text':' specialized operators for each datatype.','line_number':359,'multiline':False]
['text':' TODO: remove when we have Type support in the IR','line_number':360,'multiline':False]
['text':' Some scalar types in CAST_OP have no declarations, they may be unused in Pytorch.','line_number':369,'multiline':False]
['text':' But we keep them and ignore the warning here until verified in the future.','line_number':370,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':385,'multiline':False]
['text':' If input tensor is not dense and non-overlapping but strided, we will infer an output strides','line_number':406,'multiline':False]
['text':' which keeps the layout permutation of the input tensor.','line_number':407,'multiline':False]
['text':' See Note [Explicit nullopt MemoryFormat argument]','line_number':409,'multiline':False]
['text':' See Note [Explicit nullopt MemoryFormat argument]','line_number':412,'multiline':False]
['text':' See Note [Explicit nullopt MemoryFormat argument]','line_number':416,'multiline':False]
['text':' never propagate Conjugate, Negative, and ZeroTensor dispatch key','line_number':424,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':438,'multiline':False]
['text':' TODO: To support all features of MemoryFormat::Preserve we need to add','line_number':459,'multiline':False]
['text':' _empty_affine_quantized_strided function and use it similarly to','line_number':460,'multiline':False]
['text':' Tensor clone(const Tensor& src, c10::optional<c10::MemoryFormat> optional_memory_format)','line_number':461,'multiline':False]
['text':' if (self.is_non_overlapping_and_dense()) -> _empty_affine_quantized_strided','line_number':462,'multiline':False]
['text':' Note [Explicit nullopt MemoryFormat argument]','line_number':468,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':469,'multiline':False]
['text':' Some functions which we call default the OPTIONAL MemoryFormat','line_number':470,'multiline':False]
['text':' argument to something that's not nullopt.  If we pass the','line_number':471,'multiline':False]
['text':' MemoryFormat via TensorOptions, we must explicitly disable this','line_number':472,'multiline':False]
['text':' defaulting process, by explicitly passing nullopt for the MemoryFormat','line_number':473,'multiline':False]
['text':' argument.  When codegen is adjusted so we can delete this argument from','line_number':474,'multiline':False]
['text':' the method signature, the argument will just disappear entirely.','line_number':475,'multiline':False]
['text':'','line_number':476,'multiline':False]
['text':' BTW, there are a few places where the optional MemoryFormat is None,','line_number':477,'multiline':False]
['text':' but I still pass in nullopt for robustness.','line_number':478,'multiline':False]
['text':' We could check if dtype is still quantized?  But then should we shift/scale','line_number':480,'multiline':False]
['text':' the q_zero_point / q_scale or not?','line_number':481,'multiline':False]
['text':' See Note [Explicit nullopt MemoryFormat argument]','line_number':491,'multiline':False]
['text':' Copy the tensors with channels to avoid accidental overrides','line_number':494,'multiline':False]
['text':' See Note [Explicit nullopt MemoryFormat argument]','line_number':501,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':532,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ eye ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':538,'multiline':False]
['text':' the default value of `m` equals to `n`','line_number':545,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':554,'multiline':False]
['text':' to be resized','line_number':557,'multiline':False]
['text':' the default value of `m` equals to `n`','line_number':562,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ full ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':587,'multiline':False]
['text':' Performs dtype inference for full','line_number':591,'multiline':False]
['text':' anonymous namespace','line_number':614,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':621,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':647,'multiline':False]
['text':' anonymous namespace','line_number':688,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ linspace ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':690,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':700,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ logspace ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':748,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':759,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ones ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':810,'multiline':False]
['text':'fill_value=','line_number':817,'multiline':True]
['text':'fill_value=','line_number':821,'multiline':True]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':842,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ scalar_tensor ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':848,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':855,'multiline':False]
['text':' This is a fast track to skip device dispatch for making scalar tensor on CPU.','line_number':859,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/29915 for more detailed perf','line_number':860,'multiline':False]
['text':' difference.','line_number':861,'multiline':False]
['text':' In the future when we remove the overhead of device dispatch, we'll happily','line_number':862,'multiline':False]
['text':' revert this to following:','line_number':863,'multiline':False]
['text':'   auto result = at::empty({}, options);','line_number':864,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ rand ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':874,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':889,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':912,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ randint ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':919,'multiline':False]
['text':' generator','line_number':926,'multiline':True]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':960,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1000,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1016,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ randn ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1023,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1038,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1060,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1080,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ randperm ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1087,'multiline':False]
['text':' NOLINTNEXTLINE(clang-analyzer-security.insecureAPI.rand)','line_number':1106,'multiline':False]
['text':' namespace','line_number':1113,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1132,'multiline':False]
['text':' See Note [Acquire lock when using random generators]','line_number':1149,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ range ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1158,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1168,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ triangle ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1185,'multiline':False]
['text':' create an empty Tensor with correct size','line_number':1198,'multiline':False]
['text':' The following three approaches result in very little performance','line_number':1201,'multiline':False]
['text':' differences. Hence, the 2nd option is taken for simpler code, and to return','line_number':1202,'multiline':False]
['text':' contiguous tensors. Refer to #14904 for more details.','line_number':1203,'multiline':False]
['text':'','line_number':1204,'multiline':False]
['text':' 1. sequential RAM access: fill row coordinates first, then columns. This','line_number':1205,'multiline':False]
['text':'    results in two for-loop and more arithmetic operations.','line_number':1206,'multiline':False]
['text':'','line_number':1207,'multiline':False]
['text':' 2. interleaved RAM access: fill in index coordinates one by one, which','line_number':1208,'multiline':False]
['text':'    jumps between the two output Tensor rows in every iteration.','line_number':1209,'multiline':False]
['text':'','line_number':1210,'multiline':False]
['text':' 3. sequential RAM + transpose: create an n X 2 Tensor, fill the Tensor','line_number':1211,'multiline':False]
['text':'    sequentially, and then transpose it.','line_number':1212,'multiline':False]
['text':' fill the Tensor with correct values','line_number':1214,'multiline':False]
['text':' move to the next column and check if (r, c) is still in bound','line_number':1223,'multiline':False]
['text':' NOTE: not necessary to check if r is less than row here, because i','line_number':1228,'multiline':False]
['text':' and tril_size provide the guarantee','line_number':1229,'multiline':False]
['text':' create an empty Tensor with correct size','line_number':1248,'multiline':False]
['text':' fill the Tensor with correct values','line_number':1252,'multiline':False]
['text':' not typing std::max with scalar_t as it could be an unsigned type','line_number':1255,'multiline':False]
['text':' NOTE: no need to check if the returned value of std::max overflows','line_number':1256,'multiline':False]
['text':' index_t, as i and triu_size act as a guard.','line_number':1257,'multiline':False]
['text':' move to the next column and check if (r, c) is still in bound','line_number':1263,'multiline':False]
['text':' not typing std::max with scalar_t as it could be an unsigned type','line_number':1267,'multiline':False]
['text':' NOTE: not necessary to check if c is less than col or overflows here,','line_number':1268,'multiline':False]
['text':' because i and triu_size act as a guard.','line_number':1269,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ zeros ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1278,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1285,'multiline':False]
['text':' TODO: I think this branch should be dead, but we don't have an easy','line_number':1325,'multiline':False]
['text':' way to cover all sparse kernels with zeros_sparse_out, so retain this','line_number':1326,'multiline':False]
['text':' for now','line_number':1327,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1343,'multiline':False]
['text':' Prefer values passed in explicitly, but default to value from self.','line_number':1345,'multiline':False]
['text':' to be resized','line_number':1352,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~ bartlett_window ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1381,'multiline':False]
['text':'periodic=','line_number':1389,'multiline':True]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1399,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~ blackman_window ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1420,'multiline':False]
['text':'periodic=','line_number':1428,'multiline':True]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1438,'multiline':False]
['text':' from https://en.wikipedia.org/wiki/Window_function#Blackman_window','line_number':1452,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ hamming_window ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1460,'multiline':False]
['text':'periodic=','line_number':1468,'multiline':True]
['text':'alpha=','line_number':1481,'multiline':True]
['text':'beta=','line_number':1497,'multiline':True]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1509,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ hann_window ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1528,'multiline':False]
['text':'periodic=','line_number':1535,'multiline':True]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1545,'multiline':False]
['text':'alpha=','line_number':1550,'multiline':True]
['text':'beta=','line_number':1550,'multiline':True]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ kaiser_window ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1553,'multiline':False]
['text':'periodic=','line_number':1562,'multiline':True]
['text':'beta=','line_number':1563,'multiline':True]
['text':'beta=','line_number':1575,'multiline':True]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1586,'multiline':False]
['text':' short-circuit for `meta`.','line_number':1591,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~ vandermonde_matrix ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1612,'multiline':False]
['text':' Acquires n, defaulting to size if not provided','line_number':1618,'multiline':False]
['text':' Note: result is long if x is an integer tensor (like int8) because','line_number':1625,'multiline':False]
['text':' cumprod promotes integer tensors to long','line_number':1626,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ tensor ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1643,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1670,'multiline':False]
['text':'allocator=','line_number':1683,'multiline':True]
['text':'resizable=','line_number':1684,'multiline':True]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ clone ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1691,'multiline':False]
['text':' Copy all strides, this is marginally faster than calling empty_like','line_number':1699,'multiline':False]
['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~ named tensor overloads ~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':1716,'multiline':False]
['text':' In the short term, these exist.','line_number':1717,'multiline':False]
['text':' In the long term, we should move DimnameList into TensorOptions to avoid','line_number':1718,'multiline':False]
['text':' having these overloads.','line_number':1719,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1729,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1747,'multiline':False]
['text':'fill_value=','line_number':1750,'multiline':True]
['text':'fill_value=','line_number':1760,'multiline':True]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1781,'multiline':False]
['text':' See [Note: hacky wrapper removal for TensorOptions]','line_number':1806,'multiline':False]
['text':' namespace native','line_number':1816,'multiline':False]
['text':' namespace at','line_number':1817,'multiline':False]
