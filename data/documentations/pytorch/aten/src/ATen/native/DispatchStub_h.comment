['text':' Implements instruction set specific function dispatch.','line_number':9,'multiline':False]
['text':'','line_number':10,'multiline':False]
['text':' Kernels that may make use of specialized instruction sets (e.g. AVX2) are','line_number':11,'multiline':False]
['text':' compiled multiple times with different compiler flags (e.g. -mavx2). A','line_number':12,'multiline':False]
['text':' DispatchStub contains a table of function pointers for a kernel. At runtime,','line_number':13,'multiline':False]
['text':' the fastest available kernel is chosen based on the features reported by','line_number':14,'multiline':False]
['text':' cpuinfo.','line_number':15,'multiline':False]
['text':'','line_number':16,'multiline':False]
['text':' Example:','line_number':17,'multiline':False]
['text':'','line_number':18,'multiline':False]
['text':' In native/MyKernel.h:','line_number':19,'multiline':False]
['text':'   using fn_type = void(*)(const Tensor& x);','line_number':20,'multiline':False]
['text':'   DECLARE_DISPATCH(fn_type, stub);','line_number':21,'multiline':False]
['text':'','line_number':22,'multiline':False]
['text':' In native/MyKernel.cpp','line_number':23,'multiline':False]
['text':'   DEFINE_DISPATCH(stub);','line_number':24,'multiline':False]
['text':'','line_number':25,'multiline':False]
['text':' In native/cpu/MyKernel.cpp:','line_number':26,'multiline':False]
['text':'   namespace {','line_number':27,'multiline':False]
['text':'     // use anonymous namespace so that different cpu versions won't conflict','line_number':28,'multiline':False]
['text':'     void kernel(const Tensor& x) { ... }','line_number':29,'multiline':False]
['text':'   }','line_number':30,'multiline':False]
['text':'   REGISTER_DISPATCH(stub, &kernel);','line_number':31,'multiline':False]
['text':'','line_number':32,'multiline':False]
['text':' To call:','line_number':33,'multiline':False]
['text':'   stub(kCPU, tensor);','line_number':34,'multiline':False]
['text':'','line_number':35,'multiline':False]
['text':' TODO: CPU instruction set selection should be folded into whatever','line_number':36,'multiline':False]
['text':' the main dispatch mechanism is.','line_number':37,'multiline':False]
['text':' ignore warnings about DispatchStub::DEFAULT, AVX, AVX2 defined elsewhere','line_number':39,'multiline':False]
['text':'*
 * The sole purpose of this class is to outline methods that don't need to be
 * specialized or otherwise inlined and duplicated (by the compiler due to
 * template expansion), since it causes size bloat if there are a significant
 * number of specialization of the DispatchStub<> class.
 ','line_number':63,'multiline':True]
['text':'*
   * The CPU Dispatch actual method is chosen in decreasing order of preference by
   * DispatchStubImpl::choose_cpu_impl() in case none is found by
   * DispatchStubImpl::get_call_ptr() in cpu_dispatch_ptr.
   ','line_number':87,'multiline':True]
['text':' Fixing dispatch error in Windows debug builds.','line_number':108,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/22681 for more details.','line_number':109,'multiline':False]
['text':' TODO: make this point at hip_dispatch_ptr','line_number':212,'multiline':False]
['text':' anonymous namespace','line_number':224,'multiline':False]
['text':' Compiler will complain if you put things like std::tuple<Tensor, Tensor> in','line_number':225,'multiline':False]
['text':' the `fn` argument of DECLARE_DISPATCH. Some possible workarounds, e.g.,','line_number':226,'multiline':False]
['text':' adding parentheses and using helper struct to get rid of the parentheses, do','line_number':227,'multiline':False]
['text':' not work with MSVC. So do a `using`-declaration if you need to pass in such','line_number':228,'multiline':False]
['text':' `fn`, e.g., grid_sampler_2d_backward_cpu_kernel in GridSampleKernel.h.','line_number':229,'multiline':False]
['text':' Macro to register the same kernel for all CPU arch types. This is useful','line_number':267,'multiline':False]
['text':' if a kernel does not benefit from being recompiled across different arch types.','line_number':268,'multiline':False]
['text':' NB: This macro must be used in an actual 'cu' file; if you try using','line_number':291,'multiline':False]
['text':' it from a 'cpp' file it will not work!','line_number':292,'multiline':False]
['text':' TODO: cut this over to HIP dispatch once we stop pretending that CUDA','line_number':296,'multiline':False]
['text':' is HIP in the PyTorch HIPify build.','line_number':297,'multiline':False]
['text':' #define REGISTER_DISPATCH(name, fn) REGISTER_HIP_DISPATCH(name, fn)','line_number':299,'multiline':False]
['text':' NB: this macro must be used from a 'mm' file in order to dispatch a MPS kernel','line_number':301,'multiline':False]
['text':' REGISTER_DISPATCH now dispatches an AVX512 kernel to nullptr but registers other dispatches.','line_number':304,'multiline':False]
['text':' ALSO_REGISTER_AVX512_DISPATCH should be used for ensuring AVX512 dispatch, among others.','line_number':305,'multiline':False]
['text':' namespace at::native','line_number':313,'multiline':False]
