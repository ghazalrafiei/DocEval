['text':' References:','line_number':16,'multiline':False]
['text':' https://devblogs.nvidia.com/cuda-pro-tip-increase-performance-with-vectorized-memory-access/','line_number':17,'multiline':False]
['text':' What does the `static_unroll` do?','line_number':23,'multiline':False]
['text':'','line_number':24,'multiline':False]
['text':' We want to do something like:','line_number':25,'multiline':False]
['text':'','line_number':26,'multiline':False]
['text':'    using args_t = typename traits::ArgsTuple;','line_number':27,'multiline':False]
['text':'    args_t args;','line_number':28,'multiline':False]
['text':'    #pragma unroll','line_number':29,'multiline':False]
['text':'    for (int i = 0; i < traits::arity; i++) {','line_number':30,'multiline':False]
['text':'      std::get<i>(args) = ....','line_number':31,'multiline':False]
['text':'    }','line_number':32,'multiline':False]
['text':'','line_number':33,'multiline':False]
['text':' but unfortunately the above code does not work because','line_number':34,'multiline':False]
['text':' the template argument has to be a compile time constant','line_number':35,'multiline':False]
['text':' so `static_unroll` is created to simulate `#pragma unroll`','line_number':36,'multiline':False]
['text':' using template metaprogramming.','line_number':37,'multiline':False]
['text':' helper structs to be used with static_unroll to load arguments','line_number':54,'multiline':False]
['text':' one by one','line_number':55,'multiline':False]
['text':' `data` hold the data_ptr for tensors [output, input0, input1, ...], so we','line_number':62,'multiline':False]
['text':' need a +1 offset to get the input','line_number':63,'multiline':False]
['text':' `data` hold the data_ptr for tensors [output, input0, input1, ...], so we','line_number':75,'multiline':False]
['text':' need a +1 offset to get the input','line_number':76,'multiline':False]
['text':' namespace detail','line_number':94,'multiline':False]
['text':' aligned vector generates vectorized load/store on CUDA','line_number':158,'multiline':False]
['text':' See NOTE [Loading boolean values]','line_number':173,'multiline':False]
['text':' Assumption:','line_number':184,'multiline':False]
['text':' all tensors are contiguous, that is: stride == sizeof(type) for all tensors','line_number':185,'multiline':False]
['text':' Assumption:','line_number':236,'multiline':False]
['text':' all tensors are contiguous, that is: stride == sizeof(type) for all tensors','line_number':237,'multiline':False]
['text':' Note:','line_number':238,'multiline':False]
['text':' Functions in vectorized policy does not do boundary check. It assumes the whole block','line_number':239,'multiline':False]
['text':' has its job to do. So the reminders should be handled by the caller manually.','line_number':240,'multiline':False]
['text':' vec_size: number of scalars, can be 1, 2, or 4.','line_number':241,'multiline':False]
['text':'multi_outputs_unroll struct members and check_inbounds and load methods are copypasted from unroll struct','line_number':295,'multiline':False]
['text':'we don't use inheritance because of compiler bug in cuda 10.2+','line_number':296,'multiline':False]
['text':' namespace policies','line_number':344,'multiline':False]
['text':' This is only used in host, but we will wrap this into some templates','line_number':346,'multiline':False]
['text':' which is C10_HOST_DEVICE, so we have to make this C10_HOST_DEVICE','line_number':347,'multiline':False]
['text':' in order to compile','line_number':348,'multiline':False]
['text':' `pointers` hold the data_ptr for tensors [output, input0, input1, ...], so we','line_number':367,'multiline':False]
['text':' need a +1 offset to get the input','line_number':368,'multiline':False]
['text':' We need to get the type for each argument of `func_t`, this can only','line_number':379,'multiline':False]
['text':' be done at compile time.','line_number':380,'multiline':False]
['text':' namespace at::native::memory','line_number':385,'multiline':False]
