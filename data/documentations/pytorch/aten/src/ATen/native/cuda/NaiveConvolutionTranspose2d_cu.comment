['text':' Force batch','line_number':190,'multiline':False]
['text':' Batch size + input planes','line_number':202,'multiline':False]
['text':' Create temporary columns','line_number':205,'multiline':False]
['text':' Define a buffer of ones, for bias accumulation','line_number':209,'multiline':False]
['text':' Helpers','line_number':216,'multiline':False]
['text':' For each elt in batch, do:','line_number':220,'multiline':False]
['text':' Matrix mulitply per output:','line_number':222,'multiline':False]
['text':' M,N,K are dims of matrix A and B','line_number':226,'multiline':False]
['text':' (see http://docs.nvidia.com/cuda/cublas/#cublas-lt-t-gt-gemm)','line_number':227,'multiline':False]
['text':' Do GEMM (note: this is a bit confusing because gemm assumes','line_number':232,'multiline':False]
['text':' column-major matrices)','line_number':233,'multiline':False]
['text':' Unpack columns back into input:','line_number':249,'multiline':False]
['text':' Do Bias after:','line_number':268,'multiline':False]
['text':' M,N,K are dims of matrix A and B','line_number':269,'multiline':False]
['text':' (see http://docs.nvidia.com/cuda/cublas/#cublas-lt-t-gt-gemm)','line_number':270,'multiline':False]
['text':' Do GEMM (note: this is a bit confusing because gemm assumes','line_number':275,'multiline':False]
['text':' column-major matrices)','line_number':276,'multiline':False]
['text':' Resize output','line_number':295,'multiline':False]
['text':' end of dispatch','line_number':300,'multiline':False]
['text':' Force batch','line_number':387,'multiline':False]
['text':' Batch size + input planes','line_number':401,'multiline':False]
['text':' Resize output','line_number':404,'multiline':False]
['text':' Create temporary columns','line_number':407,'multiline':False]
['text':' Helpers','line_number':416,'multiline':False]
['text':' For each elt in batch, do:','line_number':420,'multiline':False]
['text':' Matrix mulitply per sample:','line_number':422,'multiline':False]
['text':' M,N,K are dims of matrix A and B','line_number':446,'multiline':False]
['text':' (see http://docs.nvidia.com/cuda/cublas/#cublas-lt-t-gt-gemm)','line_number':447,'multiline':False]
['text':' Do GEMM (note: this is a bit confusing because gemm assumes','line_number':452,'multiline':False]
['text':' column-major matrices)','line_number':453,'multiline':False]
['text':' Resize output','line_number':472,'multiline':False]
['text':' end of dispatch','line_number':478,'multiline':False]
['text':' Force batch','line_number':580,'multiline':False]
['text':' Batch size + input planes','line_number':594,'multiline':False]
['text':' Create temporary columns','line_number':597,'multiline':False]
['text':' Helpers','line_number':606,'multiline':False]
['text':' For each elt in batch, do:','line_number':612,'multiline':False]
['text':' Matrix mulitply per output:','line_number':614,'multiline':False]
['text':' Do Weight:','line_number':617,'multiline':False]
['text':' Matrix mulitply per output:','line_number':619,'multiline':False]
['text':' Extract columns:','line_number':623,'multiline':False]
['text':' M,N,K are dims of matrix A and B','line_number':643,'multiline':False]
['text':' (see http://docs.nvidia.com/cuda/cublas/#cublas-lt-t-gt-gemm)','line_number':644,'multiline':False]
['text':' n_input_plane','line_number':646,'multiline':False]
['text':' Do GEMM (note: this is a bit confusing because gemm assumes','line_number':649,'multiline':False]
['text':' column-major matrices)','line_number':650,'multiline':False]
['text':' Resize','line_number':674,'multiline':False]
['text':' end of dispatch','line_number':679,'multiline':False]
['text':' namespace','line_number':681,'multiline':False]
['text':' namespace at::native','line_number':833,'multiline':False]
