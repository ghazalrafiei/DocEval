['text':' Execute a pre-planned transform','line_number':37,'multiline':False]
['text':' NOTE [ cuFFT Embedded Strides ]','line_number':90,'multiline':False]
['text':'','line_number':91,'multiline':False]
['text':' cuFFT supports a subset of arbitrary strides via their "advanced data layout"','line_number':92,'multiline':False]
['text':' option (http://docs.nvidia.com/cuda/cufft/index.html#advanced-data-layout).','line_number':93,'multiline':False]
['text':' Specifically, these are tensors that can be viewed as subtensors resulted','line_number':94,'multiline':False]
['text':' from slicing a larger contiguous tensors. For such input tensors, let the','line_number':95,'multiline':False]
['text':' sizes of the enclosing tensor be `inembed`, and we can have in 3d case:','line_number':96,'multiline':False]
['text':'','line_number':97,'multiline':False]
['text':'     input[x, y, z] = input[((x * inembed[1] + y) * inembed[2] + z)]','line_number':98,'multiline':False]
['text':'','line_number':99,'multiline':False]
['text':' Above is the simplified formula ignoring the batch dimension. In fact, the','line_number':100,'multiline':False]
['text':' last dimension of the enclosing tensor doesn't have to be contiguous, i.e.,','line_number':101,'multiline':False]
['text':' it can be greater than 1. Then one can set the base stride for the enclosing','line_number':102,'multiline':False]
['text':' tensor with `istride`. Then we have','line_number':103,'multiline':False]
['text':'','line_number':104,'multiline':False]
['text':'     input[x, y, z] = input[((x * inembed[1] + y) * inembed[2] + z) * istride]','line_number':105,'multiline':False]
['text':'','line_number':106,'multiline':False]
['text':' For example, consider','line_number':107,'multiline':False]
['text':'','line_number':108,'multiline':False]
['text':'     enclosing = torch.zeros(6, 8, 10)  # contiguous','line_number':109,'multiline':False]
['text':'     input = enclosing[:4, 2:6, 6:]','line_number':110,'multiline':False]
['text':'     input.size()                       # [ 4,  4,  4]','line_number':111,'multiline':False]
['text':'     input.stride()                     # [80, 10,  1]','line_number':112,'multiline':False]
['text':'     # inembed = [6, 8, 10]','line_number':113,'multiline':False]
['text':'     input[2, 1, 3] = input[((2 * 8) + 1) * 10 + 3]   # using above formula','line_number':114,'multiline':False]
['text':'                    = input[173]','line_number':115,'multiline':False]
['text':'                    = input[2 * 80 + 1 * 10 + 1 * 3]  # using strides directly','line_number':116,'multiline':False]
['text':'','line_number':117,'multiline':False]
['text':' Generally, the embedded strides can be computed as','line_number':118,'multiline':False]
['text':'','line_number':119,'multiline':False]
['text':'     embed[i] = stride[i - 1] / stride[i].','line_number':120,'multiline':False]
['text':'','line_number':121,'multiline':False]
['text':' Note that the value of embed[0] isn't used to compute indices and doesn't','line_number':122,'multiline':False]
['text':' matter.','line_number':123,'multiline':False]
['text':'','line_number':124,'multiline':False]
['text':' Contrary to advanced data layout, simple layout means that *embeds have','line_number':125,'multiline':False]
['text':' unit-strides. In particular, unit-stride refers to that the input and output','line_number':126,'multiline':False]
['text':' tensors being contiguous, and that the strides at the innermost signal','line_number':127,'multiline':False]
['text':' dimension being unit (1) w.r.t. the corresponding data type.','line_number':128,'multiline':False]
['text':' The cuFFT plan cache','line_number':130,'multiline':False]
['text':' unique_ptr for nullability and to avoid reference invalidation on vector resize','line_number':131,'multiline':False]
['text':' namespace at::native::detail','line_number':187,'multiline':False]
['text':' "Large" here means a prime factor not special-cased by cuFFT','line_number':192,'multiline':False]
['text':' Ref: https://docs.nvidia.com/cuda/cufft/index.html#accuracy-and-performance','line_number':193,'multiline':False]
['text':' Execute a general fft operation (can be c2c, onesided r2c or onesided c2r)','line_number':209,'multiline':False]
['text':' Permute dimensions so batch dimensions come first, and in stride order','line_number':216,'multiline':False]
['text':' This maximizes data locality when collapsing to a single batch dimension','line_number':217,'multiline':False]
['text':' Collapse batch dimensions into a single dimension','line_number':233,'multiline':False]
['text':' Create the transform plan (either from cache or locally)','line_number':259,'multiline':False]
['text':' Workaround for gh-63152, gh-58724','line_number':268,'multiline':False]
['text':' Bluestein plans in CUDA 11.1 (cufft 10.3) cannot be re-used','line_number':269,'multiline':False]
['text':' Bluestein's algorithm is only used when a size has large prime factors,','line_number':270,'multiline':False]
['text':' sizes with only small prime factors can still be cached','line_number':271,'multiline':False]
['text':' Only cache plans for transforms with small prime factors','line_number':275,'multiline':False]
['text':' check again after acquiring the lock','line_number':285,'multiline':False]
['text':' prepare cufft for execution','line_number':301,'multiline':False]
['text':' execute transform plan','line_number':306,'multiline':False]
['text':' workaround for corner case where a primary context exists but is not','line_number':311,'multiline':False]
['text':' the current context','line_number':312,'multiline':False]
['text':' !defined(USE_ROCM) ','line_number':317,'multiline':True]
['text':' Inplace reshaping to original batch shape and inverting the dimension permutation','line_number':320,'multiline':False]
['text':' Calculates the normalization constant and applies it in-place to self','line_number':333,'multiline':False]
['text':' sizes is the sizes of a twosided tensor and dims are all transformed dims','line_number':334,'multiline':False]
['text':' namespace (anonymous)','line_number':360,'multiline':False]
['text':' Use the optimized path to perform single R2C or C2R if transformation dim is supported by cuFFT','line_number':362,'multiline':False]
['text':' For performance reason, when dim starts with (0, 1), do not use the optimized path.','line_number':364,'multiline':False]
['text':' n-dimensional real to complex FFT','line_number':374,'multiline':False]
['text':' CuFFT requires real input to be over-aligned, as if it were complex','line_number':387,'multiline':False]
['text':'forward=','line_number':399,'multiline':True]
['text':' First do the R2C transform on the last dimension','line_number':401,'multiline':False]
['text':'forward=','line_number':404,'multiline':True]
['text':' Then any remaining C2C transforms','line_number':410,'multiline':False]
['text':' Resort dimensions every time as _exec_fft re-strides the output','line_number':415,'multiline':False]
['text':' Intermediate results are always onesided','line_number':423,'multiline':False]
['text':'forward=','line_number':424,'multiline':True]
['text':' Only need to normalize the onesided slice since data in the other half is overwritten','line_number':429,'multiline':False]
['text':'onesided=','line_number':446,'multiline':True]
['text':' n-dimensional complex to real IFFT','line_number':461,'multiline':False]
['text':' Complex to real FFTs may overwrite the input buffer, so must always clone (gh-34551)','line_number':472,'multiline':False]
['text':'forward=','line_number':474,'multiline':True]
['text':' First complete any C2C transforms','line_number':476,'multiline':False]
['text':'forward=','line_number':481,'multiline':True]
['text':' Complex to real FFTs may overwrite the input buffer, so must always clone (gh-34551)','line_number':483,'multiline':False]
['text':' Finally, do a 1D C2R transform','line_number':487,'multiline':False]
['text':' TODO: could transform up to 2 other dims in the same cuFFT operation','line_number':488,'multiline':False]
['text':'forward=','line_number':489,'multiline':True]
['text':' n-dimensional complex to complex FFT/IFFT','line_number':501,'multiline':False]
['text':' Perform any number of C2C transforms','line_number':511,'multiline':False]
['text':' Sort dimensions every time as _exec_fft re-strides the output','line_number':515,'multiline':False]
['text':' at::native','line_number':548,'multiline':False]
