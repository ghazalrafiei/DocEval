['text':'we could make it dependent on dtype, but that would lead to different results between float and low-p types','line_number':37,'multiline':False]
['text':' aligned vector generates vectorized load/store on CUDA (copy-pasted from MemoryAccess.cuh)','line_number':39,'multiline':False]
['text':' Checks alignment of buffers for using vectorized loads / stores','line_number':45,'multiline':False]
['text':'correction=','line_number':70,'multiline':True]
['text':'take_sqrt=','line_number':70,'multiline':True]
['text':'identity_element=','line_number':80,'multiline':True]
['text':'proper division is slow, this is less accurate but noticeably faster','line_number':129,'multiline':False]
['text':'NB we don't use --use_fast_math, but this is emulation, 1./count goes to intrinsic, `* coef` is multiplication, instead of slow fp division','line_number':143,'multiline':False]
['text':'X points to the row to read','line_number':161,'multiline':False]
['text':'no tail, we check that N is multiple of vec_size','line_number':169,'multiline':False]
['text':' intra-warp reduction','line_number':177,'multiline':False]
['text':' threadIdx.x == 0 has correct values for each warp','line_number':183,'multiline':False]
['text':' inter-warp reductions','line_number':184,'multiline':False]
['text':' upper half of warps write to shared','line_number':189,'multiline':False]
['text':' lower half merges','line_number':197,'multiline':False]
['text':'if we made smem WelfordDataLN type, there would be bank conflicts,','line_number':230,'multiline':False]
['text':'as one thread would have to write 3 consecutive floats','line_number':231,'multiline':False]
['text':' No tail, N is guaranteed to be multiple of vec size','line_number':248,'multiline':False]
['text':' Computation is performed in T_ACC, X is cast to T_ACC and result is implicitly cast to T','line_number':253,'multiline':False]
['text':'N','line_number':287,'multiline':True]
['text':'eps','line_number':288,'multiline':True]
['text':'X','line_number':289,'multiline':True]
['text':'gamma','line_number':290,'multiline':True]
['text':'beta','line_number':291,'multiline':True]
['text':'mean','line_number':292,'multiline':True]
['text':'rstd','line_number':293,'multiline':True]
['text':'Y','line_number':294,'multiline':True]
['text':'to avoid windows SFINAE errors','line_number':298,'multiline':False]
['text':'vectorized reads don't improve perf, so use regular unrolling','line_number':332,'multiline':False]
['text':' This implementation gets called when input buffers (dY, X, gamma and dX) are aligned','line_number':393,'multiline':False]
['text':' to vec_size * sizeof(T). Compared to the unvectorized implementation, it is about 10%','line_number':394,'multiline':False]
['text':' faster measuread at PT operator level, with cases seeing a 2X speedup (where N >> M).','line_number':395,'multiline':False]
['text':' There are no noticeable regressions on the rest of the sizes.','line_number':396,'multiline':False]
['text':' Tail Loop','line_number':448,'multiline':False]
['text':' Reduction in Shared Memory','line_number':457,'multiline':False]
['text':' Tail Loop','line_number':496,'multiline':False]
['text':' Main loop','line_number':570,'multiline':False]
['text':' Volta and newer architectures allow lane divergence within a warp.','line_number':581,'multiline':False]
['text':' Remainder loop','line_number':596,'multiline':False]
['text':' This kernel uses a block of (C10_WARP_SIZE x C10_WARP_SIZE) and','line_number':609,'multiline':False]
['text':' gets called when M; N divide by 32. We can use warp shuffles','line_number':610,'multiline':False]
['text':' for the final reduction step. This removes 4 shmem loads and','line_number':611,'multiline':False]
['text':' stores with their corresponding __syncthreads()','line_number':612,'multiline':False]
['text':' This greatly reduces bank conflicts at the expense of a little','line_number':614,'multiline':False]
['text':' extra shared memory. It does not impact occupancy','line_number':615,'multiline':False]
['text':' Load transposed so that a warp holds an entire column','line_number':624,'multiline':False]
['text':' Main Loop','line_number':672,'multiline':False]
['text':' Remainder loop','line_number':688,'multiline':False]
['text':' Do the final reduction in shared memory','line_number':701,'multiline':False]
['text':'constexpr int alignment = 16; //currently unused to make sure float and half results are bw accurate','line_number':741,'multiline':False]
['text':' assumes input, gamma and beta are of proper shape, this was checked in _check_layer_norm_inputs','line_number':764,'multiline':False]
['text':' assumes all tensors are contiguous','line_number':765,'multiline':False]
['text':' check if can take fast path - all tensors are properly aligned, N is less than 2^24 (to use float count),','line_number':775,'multiline':False]
['text':' N is multiple of vec_size (so that all rows are aligned if tensor is aligned)','line_number':776,'multiline':False]
['text':' buf has at least blockDim.x * blockDim.y * blockDim.y + (blockDim.y - 1)*(blockDim.x/blockDim.y) elements','line_number':920,'multiline':False]
['text':' compute partial sums from strided inputs','line_number':923,'multiline':False]
['text':' do this to increase number of loads in flight','line_number':924,'multiline':False]
['text':' inter-warp reductions','line_number':930,'multiline':False]
['text':' sum within each warp','line_number':931,'multiline':False]
['text':' sum all warps','line_number':943,'multiline':False]
['text':' sum partial gradients for gamma and beta','line_number':976,'multiline':False]
['text':' each warp does sequential reductions until reduced part_size is num_warps','line_number':981,'multiline':False]
['text':' inter-warp reductions','line_number':995,'multiline':False]
['text':' top half write to shared memory','line_number':998,'multiline':False]
['text':' bottom half sums','line_number':1005,'multiline':False]
['text':' write out fully summed gradients','line_number':1014,'multiline':False]
['text':' Optimization for ROCm MI100','line_number':1046,'multiline':False]
['text':' intra-warp reductions','line_number':1064,'multiline':False]
['text':' inter-warp reductions','line_number':1069,'multiline':False]
['text':' upper half of warps write to shared','line_number':1074,'multiline':False]
['text':' lower half merges','line_number':1081,'multiline':False]
['text':' all threads now have the two sums over l','line_number':1099,'multiline':False]
['text':' prevent race where buf is written again before reads are done','line_number':1124,'multiline':False]
['text':' Optimization for ROCm','line_number':1164,'multiline':False]
['text':' For small batch size, do colwise reduce directly.','line_number':1214,'multiline':False]
['text':' For small batch size, do colwise reduce directly.','line_number':1229,'multiline':False]
['text':' Optimization for ROCm','line_number':1251,'multiline':False]
['text':' This implementation relies on warp primitives and requires that M and N divide','line_number':1265,'multiline':False]
['text':' exactly to warp size.','line_number':1266,'multiline':False]
['text':' If M and N divide by warp_size, we can use warp shuffles for the final reduction.','line_number':1270,'multiline':False]
['text':' That requires transposing values in shared memory, so we apply a padding to','line_number':1271,'multiline':False]
['text':' reduce bank conflicts.','line_number':1272,'multiline':False]
['text':' namespace','line_number':1329,'multiline':False]
['text':' optional ','line_number':1334,'multiline':True]
['text':' optional ','line_number':1335,'multiline':True]
['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':1337,'multiline':False]
['text':' dtype ','line_number':1354,'multiline':True]
['text':' layout ','line_number':1355,'multiline':True]
['text':' device ','line_number':1356,'multiline':True]
['text':' pin_memory ','line_number':1357,'multiline':True]
['text':'is_cuda=','line_number':1359,'multiline':True]
['text':' Calling the kernel for M==0 gives a CUDA error','line_number':1362,'multiline':False]
['text':' See: https://github.com/pytorch/pytorch/pull/28614','line_number':1363,'multiline':False]
['text':' optional ','line_number':1390,'multiline':True]
['text':' optional ','line_number':1391,'multiline':True]
['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':1393,'multiline':False]
['text':' dtype ','line_number':1414,'multiline':True]
['text':' layout ','line_number':1415,'multiline':True]
['text':' device ','line_number':1416,'multiline':True]
['text':' pin_memory ','line_number':1417,'multiline':True]
['text':' dtype ','line_number':1423,'multiline':True]
['text':' layout ','line_number':1424,'multiline':True]
['text':' device ','line_number':1425,'multiline':True]
['text':' pin_memory ','line_number':1426,'multiline':True]
['text':' dtype ','line_number':1430,'multiline':True]
['text':' layout ','line_number':1431,'multiline':True]
['text':' device ','line_number':1432,'multiline':True]
['text':' pin_memory ','line_number':1433,'multiline':True]
['text':' dtype ','line_number':1439,'multiline':True]
['text':' layout ','line_number':1440,'multiline':True]
['text':' device ','line_number':1441,'multiline':True]
['text':' pin_memory ','line_number':1442,'multiline':True]
['text':' dtype ','line_number':1446,'multiline':True]
['text':' layout ','line_number':1447,'multiline':True]
['text':' device ','line_number':1448,'multiline':True]
['text':' pin_memory ','line_number':1449,'multiline':True]
['text':' namespace at::native','line_number':1462,'multiline':False]
