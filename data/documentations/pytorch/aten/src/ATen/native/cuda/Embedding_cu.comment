['text':' OK to pass as int, we don't expect 2 billion+ samples in one shot','line_number':52,'multiline':False]
['text':' OK to make int, we don't expect 2 billion+ embedding row size','line_number':61,'multiline':False]
['text':' feature_dim','line_number':63,'multiline':False]
['text':' Entire block cooperates to load a batch of 1024 indices to process','line_number':67,'multiline':False]
['text':' Loop over the batch of <= 1024 loaded indices in chunks of blockDim.y = 32','line_number':75,'multiline':False]
['text':' This does double duty:  it makes sure indices_batch is ready, and it makes sure match-group','line_number':78,'multiline':False]
['text':' leaders are done with their accumulates before other warps start loading again.','line_number':79,'multiline':False]
['text':' This warp's target row in grad_weight','line_number':86,'multiline':False]
['text':' All warps load their smem segments with incoming grad data','line_number':88,'multiline':False]
['text':' To ensure determinism, we can't just have each warp add its grad data to its dst_row.','line_number':94,'multiline':False]
['text':' We need to check if any other warps pulled grad data targeting dst_row.','line_number':95,'multiline':False]
['text':' If so, we elect the first warp in each matching group as the leader.','line_number':96,'multiline':False]
['text':' Each leader warp serializes the accumulates targeting dst_row in shared memory,','line_number':97,'multiline':False]
['text':' then finishes by adding the accumulated buffer to dst_row in grad_weight.','line_number':98,'multiline':False]
['text':' Per-warp exit condition, safe with ballot_sync','line_number':99,'multiline':False]
['text':' Nominate lowest-indexed warp as the leader','line_number':112,'multiline':False]
['text':' Each warp is responsible for an input into the LookupTable.','line_number':142,'multiline':False]
['text':' If the preceding input has the same as this input, then the warp','line_number':143,'multiline':False]
['text':' exits immediately. The warp also processes subsequent inputs with the','line_number':144,'multiline':False]
['text':' same value.','line_number':145,'multiline':False]
['text':'','line_number':146,'multiline':False]
['text':' Input Warp','line_number':147,'multiline':False]
['text':' 1     <warp 1>','line_number':148,'multiline':False]
['text':' 1     <warp 1> (<warp 2> exits without doing any work)','line_number':149,'multiline':False]
['text':' 5     <warp 3>','line_number':150,'multiline':False]
['text':' 8     <warp 4>','line_number':151,'multiline':False]
['text':' Number of values proceessed by each thread (grain size)','line_number':153,'multiline':False]
['text':' Calculate norms of the rows of weight_ptr given by idx_ptr and capture them in norms ','line_number':195,'multiline':True]
['text':' Some casting hacks since dynamic shared memory and templates don't work together:','line_number':206,'multiline':False]
['text':' now we renormalize the blocks that need it','line_number':232,'multiline':False]
['text':' anonymous namespace','line_number':241,'multiline':False]
['text':', 0, nbits','line_number':304,'multiline':True]
['text':' Compute an increasing sequence per unique item in sortedIndices:','line_number':313,'multiline':False]
['text':' sorted: 2 5 5 5 7 7 8 9 9','line_number':314,'multiline':False]
['text':'  count: 1 1 2 3 1 2 1 1 2','line_number':315,'multiline':False]
['text':' Take the maximum of each count per unique key in reverse:','line_number':325,'multiline':False]
['text':' sorted: 2 5 5 5 7 7 8 9 9','line_number':326,'multiline':False]
['text':'  count: 1 3 3 3 2 2 1 2 2','line_number':327,'multiline':False]
['text':' namespace at::native','line_number':395,'multiline':False]
