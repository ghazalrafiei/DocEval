['text':' ========================= Volta Traits ===========================','line_number':37,'multiline':False]
['text':' Volta will always dequantize after the global memory load.','line_number':38,'multiline':False]
['text':' This will instantiate any HMMA tensorcore kernels for Volta.','line_number':39,'multiline':False]
['text':' Note that volta does not have native bfloat support so weights and activations will be casted to fp16','line_number':40,'multiline':False]
['text':' and compute will happen in fp16 then will be converted for bf16 output.','line_number':41,'multiline':False]
['text':' ======================= Turing Traits ==============================','line_number':67,'multiline':False]
['text':' Note that turing does not have native bfloat support so weights and activations will be casted to fp16','line_number':68,'multiline':False]
['text':' and compute will happen in fp16 then will be converted for bf16 output.','line_number':69,'multiline':False]
['text':' ======================= Ampere Traits ==============================','line_number':95,'multiline':False]
['text':' namespace kernel','line_number':121,'multiline':False]
['text':' namespace gemm','line_number':122,'multiline':False]
['text':' namespace cutlass','line_number':123,'multiline':False]
