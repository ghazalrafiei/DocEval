['text':' Sort the input data. The original indices of the data are stored in','line_number':40,'multiline':False]
['text':' sort_buffer_ptr','line_number':41,'multiline':False]
['text':' Count # of unique elements via an inner product between adjacent elements.','line_number':44,'multiline':False]
['text':' Add 1 if two neighboring element are not equal.','line_number':45,'multiline':False]
['text':' Count frequency of each element','line_number':56,'multiline':False]
['text':' Find index of maximum count','line_number':71,'multiline':False]
['text':' Find first index within which it occurs','line_number':75,'multiline':False]
['text':' Translate to original non-sorted index','line_number':78,'multiline':False]
['text':' For bool, we can skip finding the unique elements since there','line_number':102,'multiline':False]
['text':' are only two possible values.','line_number':103,'multiline':False]
['text':' See NOTE [Loading boolean values]','line_number':105,'multiline':False]
['text':' Find first index within which it occurs','line_number':121,'multiline':False]
['text':' Because the input is contiguous, we want to get a reference to the','line_number':139,'multiline':False]
['text':' location of the buffer at the innermost dimension that we are going','line_number':140,'multiline':False]
['text':' to calculate the mode for --> we do this by manually doing the stride','line_number':141,'multiline':False]
['text':' calculations to get an offset','line_number':142,'multiline':False]
['text':'','line_number':143,'multiline':False]
['text':' Yes, mutating self is a code smell, but we clone self before','line_number':144,'multiline':False]
['text':' entering the bowels of this implementation.','line_number':145,'multiline':False]
['text':'','line_number':146,'multiline':False]
['text':' See [Note: CUDA torch.mode clones self]','line_number':147,'multiline':False]
['text':' Place mode, index in output','line_number':163,'multiline':False]
['text':'memcpy_and_sync will synchronize results','line_number':176,'multiline':False]
['text':' Because we have transposed the Tensor, the data for the dimension we are','line_number':188,'multiline':False]
['text':' mode'ing along is always in the innermost dimension','line_number':189,'multiline':False]
['text':' Set-up TensorInfo structs for passing to kernel','line_number':228,'multiline':False]
['text':' The number of blocks is the number of slices that we need to calculate','line_number':232,'multiline':False]
['text':' the mode for. Each block is responsible for computing a single mode','line_number':233,'multiline':False]
['text':' The blocksize is two elements per thread, rounded up to the nearest power','line_number':237,'multiline':False]
['text':' of 2','line_number':238,'multiline':False]
['text':' Tradeoff between compilation time and the number of specializations.','line_number':241,'multiline':False]
['text':' Ideally we would have one handle_fused_mode for each power of 2','line_number':242,'multiline':False]
['text':' Position will store the dimension values we are processing','line_number':283,'multiline':False]
['text':' namespace at::native','line_number':290,'multiline':False]
