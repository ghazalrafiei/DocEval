['text':' A transform is mixed type if the parameters are higher precision than the input','line_number':42,'multiline':False]
['text':' Helper to convert 1d tensors to an nd tensor that broadcasts with input','line_number':132,'multiline':False]
['text':' All elements go into the channel dimension','line_number':133,'multiline':False]
['text':' NOTE: Epsilon is only used for InvStd, not Var. The value here is ignored.','line_number':299,'multiline':False]
['text':' For some reason this isn't an actual operator but it exists anyway...','line_number':330,'multiline':False]
['text':'dims=','line_number':331,'multiline':True]
['text':'unbiased=','line_number':332,'multiline':True]
['text':'keepdim=','line_number':332,'multiline':True]
['text':'non_blocking=','line_number':445,'multiline':True]
['text':'is_cuda=','line_number':457,'multiline':True]
['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':493,'multiline':False]
['text':' Fused reducion & elementwise kernel','line_number':502,'multiline':False]
['text':' NOTE: native_batch_norm always returns save_mean and save_invstd to be reused in backward.','line_number':523,'multiline':False]
['text':' However, this is also called from cudnn_batch_norm in eval mode which doesn't give','line_number':524,'multiline':False]
['text':' save_mean and save_invstd, so it needs recalculated.','line_number':525,'multiline':False]
['text':'is_cuda=','line_number':526,'multiline':True]
['text':' NOTE: sum_dy and sum_dy_xmy are defined, as train implies needs_reduction','line_number':559,'multiline':False]
['text':'is_cuda=','line_number':573,'multiline':True]
['text':' FIXME: Epsilon parameter isn't required, we don't take the reciprocal','line_number':602,'multiline':False]
['text':' FIXME: Epsilon parameter isn't required, we don't take the reciprocal','line_number':609,'multiline':False]
['text':' accepting input(self) here to determine template data types, since running_mean/running_var are optional','line_number':614,'multiline':False]
['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':616,'multiline':False]
['text':' optional ','line_number':629,'multiline':True]
['text':' optional ','line_number':629,'multiline':True]
['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':630,'multiline':False]
['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':648,'multiline':False]
['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':685,'multiline':False]
['text':'is_cuda=','line_number':726,'multiline':True]
['text':' namespace at::native','line_number':739,'multiline':False]
