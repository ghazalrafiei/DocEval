['text':' The kernels are templated on an opaque, self-aligned type of the correct','line_number':103,'multiline':False]
['text':' size to avoid redundant kernels for different types of the same size.','line_number':104,'multiline':False]
['text':' See note [Writing Nondeterministic Operations]','line_number':223,'multiline':False]
['text':' Nondeterministic when index contains duplicate entries','line_number':224,'multiline':False]
['text':' this kernel will not be called when torch.use_deterministic_algorithms(True)','line_number':225,'multiline':False]
['text':' OffsetCalculator needs the sizes and strides reveresed','line_number':279,'multiline':False]
['text':' Cannot use `OpaqueType`, as we need the actual type for `fastSpecializedgpuAtomicAdd`','line_number':308,'multiline':False]
['text':' Cannot use `OpaqueType`, as Tensor::data_ptr<OpaqueType<N>> is not implemented','line_number':333,'multiline':False]
['text':' Convert exclusive sum to inclusive sum','line_number':351,'multiline':False]
['text':' anonymous namespace','line_number':356,'multiline':False]
['text':' Use a prefix sum to determine the output locations of the masked elements','line_number':365,'multiline':False]
['text':' Asynchronously check that the number of `1` elements present in the mask','line_number':372,'multiline':False]
['text':' must be <= the number of elements available in `src`.','line_number':373,'multiline':False]
['text':' We are getting elements from `src` based on an offset from','line_number':378,'multiline':False]
['text':' `maskPrefixSum`, so that should be made contiguous too','line_number':379,'multiline':False]
['text':'signed_strides=','line_number':423,'multiline':True]
['text':' offsets can be negative here, but it's fine','line_number':427,'multiline':False]
['text':' namespace at::native','line_number':463,'multiline':False]
