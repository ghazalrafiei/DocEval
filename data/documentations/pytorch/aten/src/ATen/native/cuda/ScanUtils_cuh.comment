['text':' we want to keep the ratio between the x-threads and y-threads about the same as','line_number':29,'multiline':False]
['text':' the ratio between the row_size and num_rows, but the total number of threads in','line_number':30,'multiline':False]
['text':' a block should be about 512','line_number':31,'multiline':False]
['text':' 9 is from log2(512)','line_number':33,'multiline':False]
['text':' I found that in having larger log_num_threads_x can give significant speed up in some cases,','line_number':35,'multiline':False]
['text':' but detrimental in another case, so just keep the lower bound to be log2(16) == 4 to make it','line_number':36,'multiline':False]
['text':' similar to the previous implementation','line_number':37,'multiline':False]
['text':' Keeping the upper bound to be log2(512) == 9 as the maximum number of threads in a block.','line_number':38,'multiline':False]
['text':' Perform an inclusive scan along the innermost dimension of a tensor.
 *
 * - num_rows is the size of the flattened outer dimensions;
 * - row_size is the size of the innermost dimension;
 *
 * The outer dimensions of the tensor are considered as a single dimension, i.e. the tensor is
 * considered as having 'num_rows' rows of size 'row_size'.
 * Each thread block processes one or more sets of contiguous rows (processing multiple rows
 * per thread block is quicker than processing a single row, especially for short rows).
 ','line_number':50,'multiline':True]
['text':' dynamic memory allocation for vbuf and ibuf','line_number':65,'multiline':False]
['text':' the size is num_threads * 2','line_number':67,'multiline':False]
['text':' Perform scan on one block at a time, keeping track of the total value of','line_number':83,'multiline':False]
['text':' all blocks processed so far.','line_number':84,'multiline':False]
['text':' Load data into shared memory (two values per thread).','line_number':86,'multiline':False]
['text':' No need to set the index here as the value in init will never be selected','line_number':95,'multiline':False]
['text':' No need to set the index here as the value in init will never be selected','line_number':103,'multiline':False]
['text':' Add the total value of all previous blocks to the first value of this block.','line_number':106,'multiline':False]
['text':' Parallel reduction with Sklansky method. The diagram can be seen on this paper:','line_number':113,'multiline':False]
['text':' https://research.nvidia.com/publication/single-pass-parallel-prefix-scan-decoupled-look-back','line_number':114,'multiline':False]
['text':' Write back to output.','line_number':125,'multiline':False]
['text':' Perform an inclusive scan along an outer dimension of a tensor.
 *
 * - num_orows is the size of the flattened outer dimensions;
 * - num_irows is the size of the flattened inner dimensions;
 * - row_size is the size of the dimension along which to compute the variance;
 *
 * The dimensions to the outside and inside of the specified dimension are considered as flattened.
 * Thread blocks with the same blockIdx.y process an "outer row" (i.e. an element of the flattened
 * outer dimensions, which contains several "inner rows").
 * Each thread processes a single inner row at a time.
 ','line_number':143,'multiline':True]
['text':' Treat all outer dimensions (i.e. dim_ < dim) as one.','line_number':195,'multiline':False]
['text':' Treat all inner dimensions (i.e. dim > dimension) as one.','line_number':198,'multiline':False]
['text':'for performance reasons, cuda kernels use uint32_t for loops over irows, orows and row,','line_number':200,'multiline':False]
['text':'make sure that input is not bigger than supported by uint32_t','line_number':201,'multiline':False]
['text':' Treat all outer dimensions as a single dimension.','line_number':221,'multiline':False]
['text':' assuming max_num_threads per block is 512','line_number':225,'multiline':False]
['text':'int64_t dim) {','line_number':242,'multiline':False]
['text':' TODO: The implementation of `tensor_kernel_scan_outer_dim` and','line_number':254,'multiline':False]
['text':' `tensor_kernel_scan_innermost_dim` is similar to','line_number':255,'multiline':False]
['text':' `tensor_kernel_scan_outer_dim_with_indices`','line_number':256,'multiline':False]
['text':' `tensor_kernel_scan_outer_dim_with_indices` and should be refactored to','line_number':257,'multiline':False]
['text':' remove the duplication.','line_number':258,'multiline':False]
['text':' Perform an inclusive scan along an outer dimension of a tensor.
 *
 * - num_orows is the size of the flattened outer dimensions;
 * - num_irows is the size of the flattened inner dimensions;
 * - row_size is the size of the dimension along which to scan;
 *
 * The dimensions to the outside and inside of the specified dimension are considered as flattened.
 * Thread blocks with the same blockIdx.y process an "outer row" (i.e. an element of the flattened
 * outer dimensions, which contains several "inner rows").
 * Each thread processes a single inner row at a time.
 ','line_number':260,'multiline':True]
['text':' Perform an inclusive scan along the innermost dimension of a tensor.
 *
 * - num_rows is the size of the flattened outer dimensions;
 * - row_size is the size of the innermost dimension;
 *
 * The outer dimensions of the tensor are considered as a single dimension, i.e. the tensor is
 * considered as having 'num_rows' rows of size 'row_size'.
 * Each thread block processes one or more sets of contiguous rows (processing multiple rows
 * per thread block is quicker than processing a single row, especially for short rows).
 ','line_number':293,'multiline':True]
['text':' Perform scan on one block at a time, keeping track of the total value of','line_number':319,'multiline':False]
['text':' all blocks processed so far.','line_number':320,'multiline':False]
['text':' Load data into shared memory (two values per thread).','line_number':322,'multiline':False]
['text':' Add the total value of all previous blocks to the first value of this block.','line_number':338,'multiline':False]
['text':' Parallel reduction with Sklansky method. The diagram can be seen on this paper:','line_number':345,'multiline':False]
['text':' https://research.nvidia.com/publication/single-pass-parallel-prefix-scan-decoupled-look-back','line_number':346,'multiline':False]
['text':' s = 2 ^ m','line_number':349,'multiline':False]
['text':' a = (threadIdx.x / s) * (2 * s) + s','line_number':350,'multiline':False]
['text':' Write back to output.','line_number':358,'multiline':False]
['text':' Treat all outer dimensions (i.e. dim_ < dim) as one.','line_number':396,'multiline':False]
['text':' Treat all inner dimensions (i.e. dim > dimension) as one.','line_number':399,'multiline':False]
['text':' Treat all outer dimensions as a single dimension.','line_number':420,'multiline':False]
['text':' assuming max_num_threads per block is 512','line_number':424,'multiline':False]
['text':' namespace at::native','line_number':459,'multiline':False]
