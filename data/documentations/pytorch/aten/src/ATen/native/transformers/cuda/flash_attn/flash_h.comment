['text':'*****************************************************************************
 * Copyright (c) 2023, Tri Dao.
 *****************************************************************************','line_number':1,'multiline':True]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':19,'multiline':False]
['text':' The QKV matrices.','line_number':23,'multiline':False]
['text':' The stride between rows of the Q, K and V matrices.','line_number':28,'multiline':False]
['text':' The number of heads.','line_number':39,'multiline':False]
['text':' In the case of multi-query and grouped-query attention (MQA/GQA), nheads_k could be','line_number':41,'multiline':False]
['text':' different from nheads (query).','line_number':42,'multiline':False]
['text':' precompute h / h_k,','line_number':43,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':46,'multiline':False]
['text':' The O matrix (output).','line_number':50,'multiline':False]
['text':' The stride between rows of O.','line_number':54,'multiline':False]
['text':' The pointer to the P matrix.','line_number':59,'multiline':False]
['text':' The pointer to the softmax sum.','line_number':62,'multiline':False]
['text':' The dimensions.','line_number':66,'multiline':False]
['text':' The scaling factors for the kernel.','line_number':69,'multiline':False]
['text':' array of length b+1 holding starting offset of each sequence.','line_number':73,'multiline':False]
['text':' If provided, the actual length of each k sequence.','line_number':77,'multiline':False]
['text':' The K_new and V_new matrices.','line_number':82,'multiline':False]
['text':' The stride between rows of the Q, K and V matrices.','line_number':86,'multiline':False]
['text':' The cos and sin matrices for rotary embedding.','line_number':94,'multiline':False]
['text':' The indices to index into the KV cache.','line_number':98,'multiline':False]
['text':' The dropout probability (probability of keeping an activation).','line_number':101,'multiline':False]
['text':' uint32_t p_dropout_in_uint;','line_number':103,'multiline':False]
['text':' uint16_t p_dropout_in_uint16_t;','line_number':104,'multiline':False]
['text':' Scale factor of 1 / (1 - p_dropout).','line_number':107,'multiline':False]
['text':' Local window size','line_number':111,'multiline':False]
['text':' Random state.','line_number':114,'multiline':False]
['text':' If is_seqlens_k_cumulative, then seqlen_k is cu_seqlens_k[bidb + 1] - cu_seqlens_k[bidb].','line_number':122,'multiline':False]
['text':' Otherwise it's cu_seqlens_k[bidb], i.e., we use cu_seqlens_k to store the sequence lengths of K.','line_number':123,'multiline':False]
['text':' For split-KV version','line_number':128,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':131,'multiline':False]
['text':' The dO and dQKV matrices.','line_number':135,'multiline':False]
['text':' To accumulate dQ','line_number':141,'multiline':False]
['text':' // To accumulate dK and dV in case we're splitting the bwd along seqlen_q','line_number':146,'multiline':False]
['text':' dimension void *__restrict__ dk_accum_ptr; void *__restrict__','line_number':147,'multiline':False]
['text':' dv_accum_ptr;','line_number':148,'multiline':False]
['text':' The stride between rows of the dO, dQ, dK and dV matrices.','line_number':150,'multiline':False]
['text':' TD [2022-04-16]: We're using 32-bit indexing to save registers.','line_number':151,'multiline':False]
['text':' The code probably won't work for arrays larger than 2GB.','line_number':152,'multiline':False]
['text':' The pointer to the softmax d sum.','line_number':166,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':170,'multiline':False]
['text':' namespace pytorch_flash','line_number':178,'multiline':False]
