['text':'*****************************************************************************
 * Copyright (c) 2023, Tri Dao.
 *****************************************************************************','line_number':1,'multiline':True]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':26,'multiline':False]
['text':'zero_init=','line_number':32,'multiline':True]
['text':'zero_init=','line_number':38,'multiline':True]
['text':' Reshape acc_o from (MMA=4, MMA_M, MMA_K) to (nrow=(2, MMA_M), ncol=(2, MMA_K))','line_number':39,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':59,'multiline':False]
['text':' Reshape tOrP from (8, MMA_M, MMA_N) to (8, MMA_M * MMA_N)','line_number':65,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':76,'multiline':False]
['text':' Shared memory.','line_number':85,'multiline':False]
['text':' The thread index.','line_number':88,'multiline':False]
['text':'Varlen=','line_number':97,'multiline':True]
['text':' if (threadIdx.x == 0 && blockIdx.y == 0 && blockIdx.z == 0) {','line_number':105,'multiline':False]
['text':'     printf("m_block = %d, n_block_max = %d\n", m_block, n_block_max);','line_number':106,'multiline':False]
['text':' }','line_number':107,'multiline':False]
['text':' We exit early and write 0 to gO and gLSE. This also covers the case where actual_seqlen_k == 0.','line_number':109,'multiline':False]
['text':' Otherwise we might read OOB elements from gK and gV.','line_number':110,'multiline':False]
['text':' Save seed and offset for backward. If we don't have this here, the 0-th thread block might','line_number':112,'multiline':False]
['text':' exit early and no one saves the rng state.','line_number':113,'multiline':False]
['text':' Construct identity layout for sO','line_number':135,'multiline':False]
['text':' (BLK_M,BLK_K) -> (blk_m,blk_k)','line_number':136,'multiline':False]
['text':' Repeat the partitioning with identity layouts','line_number':137,'multiline':False]
['text':' Clear_OOB_K must be false since we don't want to write zeros to gmem','line_number':144,'multiline':False]
['text':'Clear_OOB_MN=','line_number':145,'multiline':True]
['text':'Clear_OOB_K=','line_number':145,'multiline':True]
['text':' if (tidx == 0) { printf("m_block = %d, n_block_min = %d, n_block_max = %d\n", m_block, n_block_min, n_block_max); }','line_number':155,'multiline':False]
['text':' We iterate over the blocks in reverse order. This is because the last block is the only one','line_number':157,'multiline':False]
['text':' that needs masking when we read K and V from global memory. Moreover, iterating in reverse','line_number':158,'multiline':False]
['text':' might save us 1 register (we just need n_block instead of both n_block and n_block_max).','line_number':159,'multiline':False]
['text':' We move K and V to the last block.','line_number':163,'multiline':False]
['text':' Careful we're using the same smem for sQ and sK | sV if Share_Q_K_smem;','line_number':186,'multiline':False]
['text':' (KCPY, KCPY_N, KCPY_K)','line_number':200,'multiline':False]
['text':' (VCPY, VCPY_N, VCPY_K)','line_number':202,'multiline':False]
['text':' (MMA,MMA_M,MMA_K)','line_number':208,'multiline':False]
['text':' (MMA,MMA_N,MMA_K)','line_number':209,'multiline':False]
['text':' (MMA, MMA_K,MMA_N)','line_number':210,'multiline':False]
['text':' MMA, MMA_M, MMA_K','line_number':212,'multiline':False]
['text':'','line_number':214,'multiline':False]
['text':' Copy Atom retiling','line_number':215,'multiline':False]
['text':'','line_number':216,'multiline':False]
['text':' if (cute::thread0()) {smem_thr_copy_Q.print_all();}','line_number':220,'multiline':False]
['text':' if (cute::thread0()) {print(tSsQ.layout()); printf("\n");}','line_number':222,'multiline':False]
['text':' TODO: this might need to change if we change the mma instruction in SM70','line_number':232,'multiline':False]
['text':'','line_number':236,'multiline':False]
['text':' PREDICATES','line_number':237,'multiline':False]
['text':'','line_number':238,'multiline':False]
['text':' // Allocate predicate tensors for m and n','line_number':240,'multiline':False]
['text':' Tensor tQpQ = make_tensor<bool>(make_shape(size<1>(tQsQ), size<2>(tQsQ)), Stride<_1,_0>{});','line_number':241,'multiline':False]
['text':' Tensor tKVpKV = make_tensor<bool>(make_shape(size<1>(tKsK), size<2>(tKsK)), Stride<_1,_0>{});','line_number':242,'multiline':False]
['text':' Construct identity layout for sQ and sK','line_number':244,'multiline':False]
['text':' (BLK_M,BLK_K) -> (blk_m,blk_k)','line_number':245,'multiline':False]
['text':' (BLK_N,BLK_K) -> (blk_n,blk_k)','line_number':246,'multiline':False]
['text':' Tensor tScQ = thr_mma.partition_A(cQ);                           // (MMA,MMA_M,MMA_K)','line_number':247,'multiline':False]
['text':' if (cute::thread0()) {','line_number':248,'multiline':False]
['text':'     print(tScQ.layout()); printf("\n");','line_number':249,'multiline':False]
['text':'     for (int i = 0; i < size(tScQ); ++i) {','line_number':250,'multiline':False]
['text':'         printf("%d ", get<0>(tScQ(i)));','line_number':251,'multiline':False]
['text':'     }','line_number':252,'multiline':False]
['text':'     printf("\n");','line_number':253,'multiline':False]
['text':'     for (int i = 0; i < size(tScQ); ++i) {','line_number':254,'multiline':False]
['text':'         printf("%d ", get<1>(tScQ(i)));','line_number':255,'multiline':False]
['text':'     }','line_number':256,'multiline':False]
['text':'     printf("\n");','line_number':257,'multiline':False]
['text':' }','line_number':258,'multiline':False]
['text':' Repeat the partitioning with identity layouts','line_number':260,'multiline':False]
['text':' (ACPY,ACPY_M,ACPY_K) -> (blk_m,blk_k)','line_number':261,'multiline':False]
['text':' (BCPY,BCPY_N,BCPY_K) -> (blk_n,blk_k)','line_number':262,'multiline':False]
['text':' Allocate predicate tensors for k','line_number':264,'multiline':False]
['text':' Set predicates for k bounds','line_number':268,'multiline':False]
['text':' Prologue','line_number':276,'multiline':False]
['text':' We don't need to clear the sQ smem tiles since we'll only write out the valid outputs','line_number':279,'multiline':False]
['text':' // Copy rmem to smem','line_number':284,'multiline':False]
['text':' // copy(tQrQ, tQsQ);','line_number':285,'multiline':False]
['text':' pytorch_flash::cp_async_wait<0>();','line_number':286,'multiline':False]
['text':' __syncthreads();','line_number':287,'multiline':False]
['text':' // if (cute::thread(1, 0)) { print(tQsQ); }','line_number':288,'multiline':False]
['text':' // Tensor sQNoSwizzle = make_tensor(make_smem_ptr(reinterpret_cast<Element *>(smem_)), typename Kernel_traits::SmemLayoutQNoSwizzle{});','line_number':289,'multiline':False]
['text':' // if (cute::thread0()) { print(sQNoSwizzle); }','line_number':290,'multiline':False]
['text':' M','line_number':296,'multiline':False]
['text':' We don't need to clear the sK smem tiles since we'll mask out the scores anyway.','line_number':302,'multiline':False]
['text':' if (threadIdx.x == 0 && blockIdx.y == 0 && blockIdx.z < 2) { print(tKgK); }','line_number':306,'multiline':False]
['text':' __syncthreads();','line_number':307,'multiline':False]
['text':' M','line_number':313,'multiline':False]
['text':' For performance reason, we separate out two kinds of iterations:','line_number':328,'multiline':False]
['text':' those that need masking on S, and those that don't.','line_number':329,'multiline':False]
['text':' We need masking on S for the very last block when K and V has length not multiple of kBlockN.','line_number':330,'multiline':False]
['text':' We also need masking on S if it's causal, for the last ceil_div(kBlockM, kBlockN) blocks.','line_number':331,'multiline':False]
['text':' We will have at least 1 "masking" iteration.','line_number':332,'multiline':False]
['text':' If not even_N, then seqlen_k might end in the middle of a block. In that case we need to','line_number':334,'multiline':False]
['text':' mask 2 blocks (e.g. when kBlockM == kBlockN), not just 1.','line_number':335,'multiline':False]
['text':' (MMA=4, MMA_M, MMA_N)','line_number':341,'multiline':False]
['text':' Advance gV','line_number':346,'multiline':False]
['text':'Is_even_MN=','line_number':349,'multiline':True]
['text':' Clear the smem tiles to account for predicated off loads','line_number':351,'multiline':False]
['text':'Clear_OOB_MN=','line_number':352,'multiline':True]
['text':'A_in_regs=','line_number':358,'multiline':True]
['text':' if (cute::thread0()) { print(acc_s); }','line_number':362,'multiline':False]
['text':' Reshape acc_s from (MMA=4, MMA_M, MMA_N) to (nrow=(2, MMA_M), ncol=(2, MMA_N))','line_number':364,'multiline':False]
['text':' if (cute::thread0()) { print_tensor(scores); }','line_number':366,'multiline':False]
['text':' We don't put the masking before the matmul S = Q K^T because we don't clear sK','line_number':367,'multiline':False]
['text':' for rows outside actual_seqlen_k. So those rows could have Inf / NaN, and the matmul','line_number':368,'multiline':False]
['text':' can produce Inf / NaN.','line_number':369,'multiline':False]
['text':' Tensor caccS = make_identity_tensor(Shape<Int<kBlockM>, Int<kBlockN>>{});    // (BLK_M,BLK_N) -> (blk_m,blk_n)','line_number':373,'multiline':False]
['text':' Tensor taccScS = thr_mma.partition_C(caccS);                           // (MMA,MMA_M,MMA_N)','line_number':374,'multiline':False]
['text':' static_assert(decltype(size<0>(taccScS))::value == 4);','line_number':375,'multiline':False]
['text':' // Convert to ((2, 2), MMA_M, MMA_N) then take only the row indices.','line_number':376,'multiline':False]
['text':' Tensor idx_row = logical_divide(taccScS, Shape<_2>{})(make_coord(0, _), _, 0);','line_number':377,'multiline':False]
['text':' Tensor idx_rowcol = make_tensor(taccScS.data(), pytorch_flash::convert_layout_acc_rowcol(taccScS.layout()));','line_number':378,'multiline':False]
['text':' pytorch_flash::apply_mask_causal_w_idx(scores, idx_rowcol, n_block * kBlockN, binfo.actual_seqlen_k,','line_number':379,'multiline':False]
['text':'                               m_block * kBlockM);','line_number':380,'multiline':False]
['text':' Idk why it's get<1> and not get<0> of the stride.','line_number':381,'multiline':False]
['text':' if (cute::thread0()) { print(idx_row.layout()); print(stride<1>(idx_row)); printf("stride = %d \n", get<1>(stride<1>(idx_row))); }','line_number':382,'multiline':False]
['text':' I can't get the stride from idx_row','line_number':383,'multiline':False]
['text':'HasWSLeft=','line_number':384,'multiline':True]
['text':' m_block * kBlockM + get<0>(idx_row(0)),','line_number':386,'multiline':False]
['text':' m_block * kBlockM + (tidx / 32) * 16, kNWarps * 16','line_number':390,'multiline':False]
['text':' m_block * kBlockM + (tidx / 32) * (kBlockM / kNWarps), 16','line_number':391,'multiline':False]
['text':' if (cute::thread0()) { print_tensor(scores); }','line_number':393,'multiline':False]
['text':' Advance gK','line_number':399,'multiline':False]
['text':'Is_even_MN=','line_number':401,'multiline':True]
['text':' This cp_async_fence needs to be in the if block, otherwise the synchronization','line_number':402,'multiline':False]
['text':' isn't right and we get race conditions.','line_number':403,'multiline':False]
['text':' TODO: when we have key_padding_mask we'll need to Check_inf','line_number':407,'multiline':False]
['text':'Is_first=','line_number':409,'multiline':True]
['text':'Check_inf=','line_number':409,'multiline':True]
['text':'Is_first=','line_number':410,'multiline':True]
['text':'Check_inf=','line_number':410,'multiline':True]
['text':' Convert scores from fp32 to fp16/bf16','line_number':412,'multiline':False]
['text':' Reshape rP from (nrow=(2, MMA_M), ncol=(2, MMA_N)) to ((2, 2, 2), MMA_M, MMA_N / 2)','line_number':414,'multiline':False]
['text':' if using m16n8k16 or ((2, 2, 1), MMA_M, MMA_N) if using m16n8k8.','line_number':415,'multiline':False]
['text':'encode_dropout_in_sign_bit=','line_number':422,'multiline':True]
['text':' if (cute::thread0()) { print(tOrP); }','line_number':433,'multiline':False]
['text':' if (cute::thread0()) { print(scores); }','line_number':436,'multiline':False]
['text':' This check is at the end of the loop since we always have at least 1 iteration','line_number':438,'multiline':False]
['text':' These are the iterations where we don't need masking on S','line_number':445,'multiline':False]
['text':' (MMA=4, MMA_M, MMA_N)','line_number':447,'multiline':False]
['text':' Advance gV','line_number':451,'multiline':False]
['text':'Is_even_MN=','line_number':453,'multiline':True]
['text':'A_in_regs=','line_number':456,'multiline':True]
['text':' Advance gK','line_number':464,'multiline':False]
['text':'Is_even_MN=','line_number':466,'multiline':True]
['text':' This cp_async_fence needs to be in the if block, otherwise the synchronization','line_number':467,'multiline':False]
['text':' isn't right and we get race conditions.','line_number':468,'multiline':False]
['text':' Reshape acc_s from (MMA=4, MMA_M, MMA_N) to (nrow=(2, MMA_M), ncol=(2, MMA_N))','line_number':472,'multiline':False]
['text':'Is_first=','line_number':482,'multiline':True]
['text':'Check_inf=','line_number':482,'multiline':True]
['text':' Reshape rP from (nrow=(2, MMA_M), ncol=(2, MMA_N)) to ((2, 2, 2), MMA_M, MMA_N / 2)','line_number':485,'multiline':False]
['text':' if using m16n8k16 or ((2, 2, 1), MMA_M, MMA_N) if using m16n8k8.','line_number':486,'multiline':False]
['text':'encode_dropout_in_sign_bit=','line_number':493,'multiline':True]
['text':' Epilogue','line_number':508,'multiline':False]
['text':' Reshape acc_o from (MMA=4, MMA_M, MMA_K) to (nrow=(2, MMA_M), ncol=(2, MMA_K))','line_number':510,'multiline':False]
['text':' if (cute::thread0()) { print(acc_o_rowcol); }','line_number':523,'multiline':False]
['text':' Convert acc_o from fp32 to fp16/bf16','line_number':525,'multiline':False]
['text':' (SMEM_M,SMEM_N)','line_number':527,'multiline':False]
['text':' Partition sO to match the accumulator partitioning','line_number':528,'multiline':False]
['text':' ((Atom,AtomNum), MMA_M, MMA_N)','line_number':531,'multiline':False]
['text':' ((Atom,AtomNum),PIPE_M,PIPE_N)','line_number':532,'multiline':False]
['text':' sO has the same size as sQ, so we don't need to sync here.','line_number':534,'multiline':False]
['text':' ((Atom,AtomNum),ATOM_M,ATOM_N)','line_number':550,'multiline':False]
['text':' (BLK_M,BLK_K) -> (blk_m,blk_k)','line_number':558,'multiline':False]
['text':' (MMA,MMA_M,MMA_K)','line_number':559,'multiline':False]
['text':' Convert to ((2, 2), MMA_M, MMA_K) then take only the row indices.','line_number':561,'multiline':False]
['text':' MMA_M','line_number':563,'multiline':False]
['text':' Construct identity layout for sO','line_number':572,'multiline':False]
['text':' (BLK_M,BLK_K) -> (blk_m,blk_k)','line_number':573,'multiline':False]
['text':' Repeat the partitioning with identity layouts','line_number':574,'multiline':False]
['text':' (ACPY,ACPY_M,ACPY_K) -> (blk_m,blk_k)','line_number':575,'multiline':False]
['text':' Clear_OOB_K must be false since we don't want to write zeros to gmem','line_number':581,'multiline':False]
['text':'Clear_OOB_MN=','line_number':582,'multiline':True]
['text':'Clear_OOB_K=','line_number':582,'multiline':True]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':587,'multiline':False]
['text':' Shared memory.','line_number':596,'multiline':False]
['text':' The thread index.','line_number':599,'multiline':False]
['text':'Varlen=','line_number':614,'multiline':True]
['text':' if (threadIdx.x == 0 && blockIdx.y == 0 && blockIdx.z == 0) { printf("Is_even_MN = %d, is_cumulativ = %d, seqlen_k_cache = %d, actual_seqlen_k = %d\n", Is_even_MN, params.is_seqlens_k_cumulative, binfo.seqlen_k_cache, binfo.actual_seqlen_k); }','line_number':615,'multiline':False]
['text':' if (threadIdx.x == 0 && blockIdx.y == 1 && blockIdx.z == 0) { printf("params.knew_ptr = %p, seqlen_k_cache + seqlen_knew = %d\n", params.knew_ptr, binfo.seqlen_k_cache + (params.knew_ptr == nullptr ? 0 : params.seqlen_knew)); }','line_number':616,'multiline':False]
['text':' This also covers the case where n_block_max <= 0','line_number':628,'multiline':False]
['text':' We exit early and write 0 to gOaccum and -inf to gLSEaccum.','line_number':629,'multiline':False]
['text':' Otherwise we might read OOB elements from gK and gV,','line_number':630,'multiline':False]
['text':' or get wrong results when we combine gOaccum from different blocks.','line_number':631,'multiline':False]
['text':' Construct identity layout for sO','line_number':648,'multiline':False]
['text':' (BLK_M,BLK_K) -> (blk_m,blk_k)','line_number':649,'multiline':False]
['text':' Repeat the partitioning with identity layouts','line_number':650,'multiline':False]
['text':' Clear_OOB_K must be false since we don't want to write zeros to gmem','line_number':657,'multiline':False]
['text':'Clear_OOB_MN=','line_number':658,'multiline':True]
['text':'Clear_OOB_K=','line_number':658,'multiline':True]
['text':' We iterate over the blocks in reverse order. This is because the last block is the only one','line_number':669,'multiline':False]
['text':' that needs masking when we read K and V from global memory. Moreover, iterating in reverse','line_number':670,'multiline':False]
['text':' might save us 1 register (we just need n_block instead of both n_block and n_block_max).','line_number':671,'multiline':False]
['text':' We move K and V to the last block.','line_number':675,'multiline':False]
['text':' if (threadIdx.x == 0 && blockIdx.y == 0 && blockIdx.z == 0) { printf("k_ptr = %p, row_offset_k = %d, gK_ptr = %p\n", params.k_ptr, row_offset_k, gK.data()); }','line_number':688,'multiline':False]
['text':' (KCPY, KCPY_N, KCPY_K)','line_number':705,'multiline':False]
['text':' (VCPY, VCPY_N, VCPY_K)','line_number':707,'multiline':False]
['text':' (MMA,MMA_M,MMA_K)','line_number':712,'multiline':False]
['text':' (MMA,MMA_N,MMA_K)','line_number':713,'multiline':False]
['text':' (MMA, MMA_K,MMA_N)','line_number':714,'multiline':False]
['text':' MMA, MMA_M, MMA_K','line_number':716,'multiline':False]
['text':'','line_number':718,'multiline':False]
['text':' Copy Atom retiling','line_number':719,'multiline':False]
['text':'','line_number':720,'multiline':False]
['text':' TODO: this might need to change if we change the mma instruction in SM70','line_number':734,'multiline':False]
['text':'','line_number':738,'multiline':False]
['text':' PREDICATES','line_number':739,'multiline':False]
['text':'','line_number':740,'multiline':False]
['text':' // Allocate predicate tensors for m and n','line_number':742,'multiline':False]
['text':' Tensor tQpQ = make_tensor<bool>(make_shape(size<1>(tQsQ), size<2>(tQsQ)), Stride<_1,_0>{});','line_number':743,'multiline':False]
['text':' Tensor tKVpKV = make_tensor<bool>(make_shape(size<1>(tKsK), size<2>(tKsK)), Stride<_1,_0>{});','line_number':744,'multiline':False]
['text':' Construct identity layout for sQ and sK','line_number':746,'multiline':False]
['text':' (BLK_M,BLK_K) -> (blk_m,blk_k)','line_number':747,'multiline':False]
['text':' (BLK_N,BLK_K) -> (blk_n,blk_k)','line_number':748,'multiline':False]
['text':' Repeat the partitioning with identity layouts','line_number':750,'multiline':False]
['text':' (ACPY,ACPY_M,ACPY_K) -> (blk_m,blk_k)','line_number':751,'multiline':False]
['text':' (BCPY,BCPY_N,BCPY_K) -> (blk_n,blk_k)','line_number':752,'multiline':False]
['text':' Allocate predicate tensors for k','line_number':754,'multiline':False]
['text':' Set predicates for k bounds','line_number':758,'multiline':False]
['text':' Prologue','line_number':766,'multiline':False]
['text':' Copy from Knew to K, optionally apply rotary embedding.','line_number':768,'multiline':False]
['text':' Even if we have MQA / GQA, all threadblocks responsible for the same KV head are writing to','line_number':774,'multiline':False]
['text':' gmem. Technically it's a race condition, but they all write the same content anyway, and it's safe.','line_number':775,'multiline':False]
['text':' We want to do this so that all threadblocks can proceed right after they finish writing the KV cache.','line_number':776,'multiline':False]
['text':' if (cute::thread(0, 0)) { printf("rotary_cos_ptr = %p, gCos.data() = %p, tRgCos.data() = %p, rotary_dim = %d\n", params.rotary_cos_ptr, gCos.data(), tRgCos.data(), params.rotary_dim); }','line_number':794,'multiline':False]
['text':' if (cute::thread(8, 0)) { print_tensor(gCos); }','line_number':795,'multiline':False]
['text':' if (cute::thread(0, 0)) { print_tensor(tRgCos); }','line_number':796,'multiline':False]
['text':' Subtract seqlen_k_cache * row stride so that conceptually gK and gKnew "line up". When we access them,','line_number':802,'multiline':False]
['text':' e.g. if gK has 128 rows and gKnew has 64 rows, we access gK[:128] and gKNew[128:128 + 64].','line_number':803,'multiline':False]
['text':' This maps to accessing the first 64 rows of knew_ptr.','line_number':804,'multiline':False]
['text':' if (threadIdx.x == 0 && blockIdx.y == 0 && blockIdx.z == 0) { printf("knew_ptr = %p, row_offset_knew = %d, gKnew_ptr = %p\n", params.knew_ptr, row_offset_knew, gKnew.data()); }','line_number':809,'multiline':False]
['text':' (KCPY, KCPY_N, KCPY_K)','line_number':814,'multiline':False]
['text':' (VCPY, VCPY_N, VCPY_K)','line_number':815,'multiline':False]
['text':' Don't clear OOB_K because we're writing to global memory','line_number':830,'multiline':False]
['text':'Clear_OOB_K=','line_number':831,'multiline':True]
['text':' Don't clear OOB_K because we're writing to global memory','line_number':838,'multiline':False]
['text':'Clear_OOB_K=','line_number':839,'multiline':True]
['text':' Need this before we can read in K again, so that we'll see the updated K values.','line_number':851,'multiline':False]
['text':' Read Q from gmem to smem, optionally apply rotary embedding.','line_number':859,'multiline':False]
['text':' We don't need to clear the sQ smem tiles since we'll only write out the valid outputs','line_number':862,'multiline':False]
['text':' If not causal, all the queries get the same the cos/sin, taken at location seqlen_k_cache.','line_number':867,'multiline':False]
['text':' We do this by setting the row stride of gCos / gSin to 0.','line_number':868,'multiline':False]
['text':' We don't need to clear the sK smem tiles since we'll mask out the scores anyway.','line_number':899,'multiline':False]
['text':' pytorch_flash::cp_async_wait<0>();','line_number':904,'multiline':False]
['text':' __syncthreads();','line_number':905,'multiline':False]
['text':' if (tidx == 0 && blockIdx.y == 0 && blockIdx.z == 0) { print(tKsK); }','line_number':906,'multiline':False]
['text':' __syncthreads();','line_number':907,'multiline':False]
['text':' For performance reason, we separate out two kinds of iterations:','line_number':911,'multiline':False]
['text':' those that need masking on S, and those that don't.','line_number':912,'multiline':False]
['text':' We need masking on S for the very last block when K and V has length not multiple of kBlockN.','line_number':913,'multiline':False]
['text':' We also need masking on S if it's causal, for the last ceil_div(kBlockM, kBlockN) blocks.','line_number':914,'multiline':False]
['text':' We will have at least 1 "masking" iteration.','line_number':915,'multiline':False]
['text':' If not even_N, then seqlen_k might end in the middle of a block. In that case we need to','line_number':917,'multiline':False]
['text':' mask 2 blocks (e.g. when kBlockM == kBlockN), not just 1.','line_number':918,'multiline':False]
['text':' (MMA=4, MMA_M, MMA_N)','line_number':924,'multiline':False]
['text':' Advance gV','line_number':929,'multiline':False]
['text':'Is_even_MN=','line_number':932,'multiline':True]
['text':' Clear the smem tiles to account for predicated off loads','line_number':934,'multiline':False]
['text':'Clear_OOB_MN=','line_number':935,'multiline':True]
['text':' if (cute::thread0()) { print(acc_s); }','line_number':945,'multiline':False]
['text':' Reshape acc_s from (MMA=4, MMA_M, MMA_N) to (nrow=(2, MMA_M), ncol=(2, MMA_N))','line_number':947,'multiline':False]
['text':' if (cute::thread0()) { print(scores); }','line_number':949,'multiline':False]
['text':' We don't put the masking before the matmul S = Q K^T because we don't clear sK','line_number':950,'multiline':False]
['text':' for rows outside actual_seqlen_k. So those rows could have Inf / NaN, and the matmul','line_number':951,'multiline':False]
['text':' can produce Inf / NaN.','line_number':952,'multiline':False]
['text':' if (tidx == 0 && blockIdx.y == 0 && blockIdx.z == 0) { print(tVsV); }','line_number':965,'multiline':False]
['text':' __syncthreads();','line_number':966,'multiline':False]
['text':' Advance gK','line_number':969,'multiline':False]
['text':'Is_even_MN=','line_number':971,'multiline':True]
['text':' This cp_async_fence needs to be in the if block, otherwise the synchronization','line_number':972,'multiline':False]
['text':' isn't right and we get race conditions.','line_number':973,'multiline':False]
['text':' We have key_padding_mask so we'll need to Check_inf','line_number':977,'multiline':False]
['text':'Is_first=','line_number':979,'multiline':True]
['text':'Check_inf=','line_number':979,'multiline':True]
['text':'Is_first=','line_number':980,'multiline':True]
['text':'Check_inf=','line_number':980,'multiline':True]
['text':' if (cute::thread0()) { print(scores_max); print(scores_sum); print(scores); }','line_number':981,'multiline':False]
['text':' Convert scores from fp32 to fp16/bf16','line_number':983,'multiline':False]
['text':' Reshape rP from (nrow=(2, MMA_M), ncol=(2, MMA_N)) to ((2, 2, 2), MMA_M, MMA_N / 2)','line_number':985,'multiline':False]
['text':' if using m16n8k16 or ((2, 2, 1), MMA_M, MMA_N) if using m16n8k8.','line_number':986,'multiline':False]
['text':' if (cute::thread0()) { print(scores); }','line_number':990,'multiline':False]
['text':' This check is at the end of the loop since we always have at least 1 iteration','line_number':992,'multiline':False]
['text':' These are the iterations where we don't need masking on S','line_number':999,'multiline':False]
['text':' (MMA=4, MMA_M, MMA_N)','line_number':1001,'multiline':False]
['text':' Advance gV','line_number':1005,'multiline':False]
['text':'Is_even_MN=','line_number':1007,'multiline':True]
['text':' Advance gK','line_number':1018,'multiline':False]
['text':'Is_even_MN=','line_number':1020,'multiline':True]
['text':' This cp_async_fence needs to be in the if block, otherwise the synchronization','line_number':1021,'multiline':False]
['text':' isn't right and we get race conditions.','line_number':1022,'multiline':False]
['text':' Reshape acc_s from (MMA=4, MMA_M, MMA_N) to (nrow=(2, MMA_M), ncol=(2, MMA_N))','line_number':1026,'multiline':False]
['text':'Is_first=','line_number':1036,'multiline':True]
['text':'Check_inf=','line_number':1036,'multiline':True]
['text':' Reshape rP from (nrow=(2, MMA_M), ncol=(2, MMA_N)) to ((2, 2, 2), MMA_M, MMA_N / 2)','line_number':1039,'multiline':False]
['text':' if using m16n8k16 or ((2, 2, 1), MMA_M, MMA_N) if using m16n8k8.','line_number':1040,'multiline':False]
['text':' Epilogue','line_number':1046,'multiline':False]
['text':' Reshape acc_o from (MMA=4, MMA_M, MMA_K) to (nrow=(2, MMA_M), ncol=(2, MMA_K))','line_number':1048,'multiline':False]
['text':' if (cute::thread0()) { print(acc_o_rowcol); }','line_number':1050,'multiline':False]
['text':' if (cute::thread0()) { print(lse); }','line_number':1061,'multiline':False]
['text':' if (cute::thread0()) { print(acc_o_rowcol); }','line_number':1062,'multiline':False]
['text':' (SMEM_M,SMEM_N)','line_number':1064,'multiline':False]
['text':' Partition sO to match the accumulator partitioning','line_number':1065,'multiline':False]
['text':' ((Atom,AtomNum), MMA_M, MMA_N)','line_number':1074,'multiline':False]
['text':' ((Atom,AtomNum),PIPE_M,PIPE_N)','line_number':1075,'multiline':False]
['text':' sOaccum is larger than sQ, so we need to syncthreads here','line_number':1077,'multiline':False]
['text':' TODO: allocate enough smem for sOaccum','line_number':1078,'multiline':False]
['text':' if (tidx == 0) { printf("row_offset_o = %d, bidh = %d, gOaccum = %p\n", row_offset_o, bidh, gOaccum.data()); }','line_number':1094,'multiline':False]
['text':' ((Atom,AtomNum),ATOM_M,ATOM_N)','line_number':1098,'multiline':False]
['text':' (BLK_M,BLK_K) -> (blk_m,blk_k)','line_number':1106,'multiline':False]
['text':' (MMA,MMA_M,MMA_K)','line_number':1107,'multiline':False]
['text':' Convert to ((2, 2), MMA_M, MMA_K) then take only the row indices.','line_number':1109,'multiline':False]
['text':' MMA_M','line_number':1111,'multiline':False]
['text':' Construct identity layout for sO','line_number':1120,'multiline':False]
['text':' (BLK_M,BLK_K) -> (blk_m,blk_k)','line_number':1121,'multiline':False]
['text':' Repeat the partitioning with identity layouts','line_number':1122,'multiline':False]
['text':' (ACPY,ACPY_M,ACPY_K) -> (blk_m,blk_k)','line_number':1123,'multiline':False]
['text':' Clear_OOB_K must be false since we don't want to write zeros to gmem','line_number':1129,'multiline':False]
['text':'Clear_OOB_MN=','line_number':1130,'multiline':True]
['text':'Clear_OOB_K=','line_number':1130,'multiline':True]
['text':' __syncthreads();','line_number':1133,'multiline':False]
['text':' if (cute::thread0()) { print(tOgOaccum); }','line_number':1134,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':1137,'multiline':False]
['text':' The block index for the batch.','line_number':1142,'multiline':False]
['text':' The block index for the head.','line_number':1144,'multiline':False]
['text':' We want the fwd and bwd to generate the same dropout pattern (RNG), without restricting','line_number':1147,'multiline':False]
['text':' them to have the same number of threads or have to traverse the attention matrix','line_number':1148,'multiline':False]
['text':' in the same order.','line_number':1149,'multiline':False]
['text':' In the Philox RNG, we use the offset to store the batch, head, and the lane id','line_number':1150,'multiline':False]
['text':' (within a warp). We use the subsequence to store the location of the 16 x 32 blocks within','line_number':1151,'multiline':False]
['text':' the attention matrix. This way, as long as we have the batch, head, and the location of','line_number':1152,'multiline':False]
['text':' the 16 x 32 block within the attention matrix, we can generate the exact same dropout pattern.','line_number':1153,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':1158,'multiline':False]
['text':' The block index for the batch.','line_number':1163,'multiline':False]
['text':' The block index for the head.','line_number':1165,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':1172,'multiline':False]
['text':' Shared memory.','line_number':1187,'multiline':False]
['text':' kBlockM + 1 instead of kBlockM to reduce bank conflicts.','line_number':1188,'multiline':False]
['text':' The thread and block index.','line_number':1191,'multiline':False]
['text':' Read the LSE values from gmem and store them in shared memory, then tranpose them.','line_number':1203,'multiline':False]
['text':' if (bidx == 0 && tidx < 32) { printf("tidx = %d, row = %d, col = %d, lse = %f\n", tidx, row, col, lse); }','line_number':1211,'multiline':False]
['text':' if (bidx == 1 && tidx < 32) { printf("tidx = %d, row_offset_lse = %d, lse = %f\n", tidx, row_offset_lse, lse_accum(0)); }','line_number':1213,'multiline':False]
['text':' To make sure that kMaxSplits is within 1 warp: we decide how many elements within kMaxSplits','line_number':1217,'multiline':False]
['text':' each thread should hold. If kMaxSplits = 16, then each thread holds 2 elements (128 threads,','line_number':1218,'multiline':False]
['text':' kBlockM rows, so each time we load we can load 128 / kBlockM rows).','line_number':1219,'multiline':False]
['text':' constexpr int kThreadsPerSplit = kMaxSplits / kRowsPerLoadTranspose;','line_number':1220,'multiline':False]
['text':' static_assert(kThreadsPerSplit <= 32);','line_number':1221,'multiline':False]
['text':' if (bidx == 0 && tidx < 32) { printf("tidx = %d, row = %d, col = %d, lse = %f\n", tidx, row, col, lse_accum(l)); }','line_number':1229,'multiline':False]
['text':' Compute the logsumexp of the LSE along the split dimension.','line_number':1232,'multiline':False]
['text':' In case all local LSEs are -inf','line_number':1238,'multiline':False]
['text':' For the case where all local lse == -INFINITY, we want to set lse_logsum to INFINITY. Otherwise','line_number':1244,'multiline':False]
['text':' lse_logsum is log(0.0) = -INFINITY and we get NaN when we do lse_accum(l) - lse_logsum.','line_number':1245,'multiline':False]
['text':' if (bidx == 0 && tidx < 32) { printf("tidx = %d, lse = %f, lse_max = %f, lse_logsum = %f\n", tidx, lse_accum(0), lse_max, lse_logsum); }','line_number':1247,'multiline':False]
['text':' Store the scales exp(lse - lse_logsum) in shared memory.','line_number':1249,'multiline':False]
['text':' Val layout, 4 vals per store','line_number':1267,'multiline':False]
['text':' Predicates','line_number':1275,'multiline':False]
['text':' Repeat the partitioning with identity layouts','line_number':1277,'multiline':False]
['text':' Load Oaccum in then scale and accumulate to O','line_number':1284,'multiline':False]
['text':'Is_even_MN=','line_number':1286,'multiline':True]
['text':' if (cute::thread0()) { printf("lse_scale = %f, %f\n", sLSE[split][0], sLSE[split][1]); print(tOrOaccum); }','line_number':1300,'multiline':False]
['text':' if (cute::thread0()) { print_tensor(tOrO); }','line_number':1304,'multiline':False]
['text':' Write to gO','line_number':1307,'multiline':False]
['text':' The index to the rows of Q','line_number':1314,'multiline':False]
['text':' TODO: Should check if this is using vectorized store, but it seems pretty fast','line_number':1324,'multiline':False]
['text':' if (bidx == 0 && tidx == 0) { printf("tidx = %d, idx = %d, batch_idx = %d, head_idx = %d, row = %d, col = %d\n", tidx, idx, batch_idx, head_idx, row, col); print(rO(_, m, k)); print(gO); }','line_number':1326,'multiline':False]
['text':' reinterpret_cast<uint64_t *>(o_ptr)[col / 4] = recast<uint64_t>(rO)(0, m, k);','line_number':1327,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////////////////////////','line_number':1334,'multiline':False]
['text':' namespace flash','line_number':1336,'multiline':False]
