['text':'  Copyright Â© 2022 Apple Inc.','line_number':1,'multiline':False]
['text':' this implementation is based on CUDACachingAllocator.','line_number':16,'multiline':False]
['text':' It utilizes Metal Heaps to improve the performance with buffer allocation.','line_number':17,'multiline':False]
['text':' Do not include this header. Use MPSAllocatorInterface.h instead.','line_number':18,'multiline':False]
['text':' TODO: Unify the logic with CUDACachingAllocator and remove redundant code.','line_number':19,'multiline':False]
['text':' largest "small" allocation is 1 MiB','line_number':22,'multiline':False]
['text':' allocations between 1 and 10 MiB may use kLargeHeap','line_number':23,'multiline':False]
['text':' round up large allocations to 2 MiB','line_number':24,'multiline':False]
['text':' "small" allocations are packed in 8 MiB heaps','line_number':25,'multiline':False]
['text':' "large" allocations may be packed in 32 MiB heaps','line_number':26,'multiline':False]
['text':' "extra large" allocations on Discrete devices may be packed in 128 MiB heaps','line_number':27,'multiline':False]
['text':' "extra large" allocations on Unified devices may be packed in 1 GiB heaps','line_number':28,'multiline':False]
['text':' largest "scalar" allocation','line_number':29,'multiline':False]
['text':' buffer pools could be customized with a combination of usage flags','line_number':31,'multiline':False]
['text':' small heaps have sizes of kSmallHeap, and large ones kLargeHeap','line_number':34,'multiline':False]
['text':' shared pools allocated on devices with unified memory; otherwise, private between host/device','line_number':35,'multiline':False]
['text':' managed storage mode','line_number':36,'multiline':False]
['text':' enables Automatic Hazard Tracking for the resources allocated on the pool','line_number':37,'multiline':False]
['text':' used to import CPU scalar values to GPU and use them in MPS Stream','line_number':38,'multiline':False]
['text':' debug verbosity flags','line_number':40,'multiline':False]
['text':' print generic profiling data for total system memory usage','line_number':43,'multiline':False]
['text':' print buffer allocations','line_number':44,'multiline':False]
['text':' print buffer recycling','line_number':45,'multiline':False]
['text':' print buffer releases','line_number':46,'multiline':False]
['text':' only log large buffer pool transactions','line_number':47,'multiline':False]
['text':' stores the pointer to CPU mapping of a Shared MTLBuffer','line_number':54,'multiline':False]
['text':' size after alignment','line_number':55,'multiline':False]
['text':' requested size (before alignment)','line_number':56,'multiline':False]
['text':' buffer shape is used for retrieving base of views in cached graphs','line_number':57,'multiline':False]
['text':' counter to candidate least recently used buffers for garbage collection','line_number':62,'multiline':False]
['text':' counter to assign unique ids to buffer blocks','line_number':65,'multiline':False]
['text':' Metal events used to sync GPU/CPU operations on the shared-storage buffers','line_number':67,'multiline':False]
['text':' true if we exceed the low watermark limit. In this case','line_number':96,'multiline':False]
['text':' we apply strategies to relieve the pressure before allocation.','line_number':97,'multiline':False]
['text':' true if we're allocating on a unified memory device','line_number':99,'multiline':False]
['text':' indicates if we split this heap to sub-allocate 'several' buffers (otherwise single buffer)','line_number':109,'multiline':False]
['text':' counter to assign unique ids to heap blocks','line_number':111,'multiline':False]
['text':' TODO: check the caching performance of write-combined mode','line_number':119,'multiline':False]
['text':' this automatically handles Metal buffer access synchronizations at the','line_number':153,'multiline':False]
['text':' cost of slightly lower performance.','line_number':154,'multiline':False]
['text':' returns the retainCount before releasing the buffer','line_number':189,'multiline':False]
['text':' returns the retainCount before releasing the heap','line_number':198,'multiline':False]
['text':' assert if heap isn't empty','line_number':201,'multiline':False]
['text':' usage flags to customize the pool for various purposes (see UsageFlags enum)','line_number':227,'multiline':False]
['text':' total number of buffers in the pool','line_number':229,'multiline':False]
['text':' total allocations size on this pool','line_number':231,'multiline':False]
['text':' total memory available in the pool','line_number':233,'multiline':False]
['text':' list of heaps ordered by their "available" (not total) memory size','line_number':235,'multiline':False]
['text':' list of only "available" buffers in the pool (i.e., buffers not in-use)','line_number':237,'multiline':False]
['text':' list of buffers that are in a state of "limbo" where they've already been freed','line_number':239,'multiline':False]
['text':' from PyTorch-side, but were not returned to pool due to still being','line_number':240,'multiline':False]
['text':' in-use by command buffers with retainCount > 1. In this state, the buffer is','line_number':241,'multiline':False]
['text':' neither ready to be recycled, nor could be returned to pool as available.','line_number':242,'multiline':False]
['text':' These buffers will be returned to pool once the command buffer's','line_number':243,'multiline':False]
['text':' completionHandler callbacks are called.','line_number':244,'multiline':False]
['text':' list of heaps pending size update','line_number':246,'multiline':False]
['text':' interface exposed to at::Allocator','line_number':262,'multiline':False]
['text':' frees a buffer and returns it into buffer pool','line_number':264,'multiline':False]
['text':' releases all the cached buffers and their associated heaps','line_number':266,'multiline':False]
['text':' free inactive buffers that are pending to be freed','line_number':268,'multiline':False]
['text':' returns true if buffer was allocated from the shared pool','line_number':270,'multiline':False]
['text':' get the requested unaligned size of an MTLBuffer','line_number':272,'multiline':False]
['text':' set the shape of a base tensor from a view tensor','line_number':274,'multiline':False]
['text':' retrieve the shape of a base tensor from a view tensor','line_number':276,'multiline':False]
['text':' get the unique ID of the buffer','line_number':278,'multiline':False]
['text':' allocate a buffer from a specialized pool to import CPU scalars into GPU','line_number':280,'multiline':False]
['text':' returns a CPU-mapping of the input buffer and its retainCount,','line_number':282,'multiline':False]
['text':' if only it has Shared storage-mode and allocated on MPSAllocator','line_number':283,'multiline':False]
['text':' records events for a list of MTLBuffers (list is used to lock the mutex once)','line_number':285,'multiline':False]
['text':' returns true if records any event (given if passed buffers exist and are shared-storage)','line_number':286,'multiline':False]
['text':' waits for the event to signal the completion of GPU execution','line_number':288,'multiline':False]
['text':' on the passed shared buffers (list is used to lock the mutex once)','line_number':289,'multiline':False]
['text':' returns true if actually waited on any event','line_number':290,'multiline':False]
['text':' this indicates how far (in Megabytes) the current total allocations are from the','line_number':292,'multiline':False]
['text':' low watermark limit which is used to detect if we're under memory pressure','line_number':293,'multiline':False]
['text':' This returns zero if we've reached the low watermark limit','line_number':294,'multiline':False]
['text':' (see m_low_watermark_ratio for description)','line_number':296,'multiline':False]
['text':' (see m_high_watermark_ratio for description)','line_number':298,'multiline':False]
['text':' (see m_low_watermark_limit for description)','line_number':300,'multiline':False]
['text':' (see m_max_total_allowed_size for description)','line_number':302,'multiline':False]
['text':' (see m_total_allocated_memory for description)','line_number':304,'multiline':False]
['text':' (see m_current_allocated_memory for description)','line_number':306,'multiline':False]
['text':' total GPU memory allocated in the process by Metal driver; including','line_number':308,'multiline':False]
['text':' implicit allocations from MPS/MPSGraph frameworks and MPSHeapAllocatorImpl.','line_number':309,'multiline':False]
['text':' (see enum DebugVerbosity for description)','line_number':311,'multiline':False]
['text':' returns the device that we allocate from','line_number':313,'multiline':False]
['text':' TODO: make a common function to do size unit conversions in PyTorch.','line_number':316,'multiline':False]
['text':' (see m_high_watermark_ratio for description)','line_number':320,'multiline':False]
['text':' we set the allowed upper bound to twice the size of recommendedMaxWorkingSetSize.','line_number':322,'multiline':False]
['text':' (see m_low_watermark_ratio for description)','line_number':324,'multiline':False]
['text':' on unified memory, we could allocate beyond the recommendedMaxWorkingSetSize','line_number':325,'multiline':False]
['text':' allocated buffers by device pointer','line_number':331,'multiline':False]
['text':' using a container for pools to simplify iterating them','line_number':333,'multiline':False]
['text':' total memory allocated by HeapAllocator (including blocks in pools)','line_number':335,'multiline':False]
['text':' currently active memory allocations in use (i.e., blocks not in pools)','line_number':337,'multiline':False]
['text':' max buffer size allowed by Metal','line_number':339,'multiline':False]
['text':' maximum total size allowed to be allocated','line_number':341,'multiline':False]
['text':' high watermark ratio is a hard limit for the total allowed allocations','line_number':343,'multiline':False]
['text':' 0. : disables high watermark limit (may cause system failure if system-wide OOM occurs)','line_number':344,'multiline':False]
['text':' 1. : recommended maximum allocation size (i.e., device.recommendedMaxWorkingSetSize)','line_number':345,'multiline':False]
['text':' >1.: allows limits beyond the device.recommendedMaxWorkingSetSize','line_number':346,'multiline':False]
['text':' e.g., value 0.95 means we allocate up to 95% of recommended maximum','line_number':347,'multiline':False]
['text':' allocation size; beyond that, the allocations would fail with OOM error.','line_number':348,'multiline':False]
['text':' low watermark ratio is a soft limit to attempt limiting memory allocations up to the lower watermark','line_number':350,'multiline':False]
['text':' level by garbage collection or committing command buffers more frequently (a.k.a, adaptive commit).','line_number':351,'multiline':False]
['text':' Value between 0 to m_high_watermark_ratio (setting 0.0 disables adaptive commit and garbage collection)','line_number':352,'multiline':False]
['text':' e.g., value 0.9 means we 'attempt' to limit allocations up to 90% of recommended maximum','line_number':353,'multiline':False]
['text':' allocation size.','line_number':354,'multiline':False]
['text':' low watermark size limit (in Bytes) at the time we initialize the allocator','line_number':356,'multiline':False]
['text':' use "PYTORCH_DEBUG_MPS_ALLOCATOR" env-var to set debug verbosity','line_number':358,'multiline':False]
['text':' default MPS stream','line_number':360,'multiline':False]
['text':' we hold a reference to MPSEventPool so it could get destroyed after MPSAllocator','line_number':362,'multiline':False]
['text':' returns true if the container heap is also released','line_number':373,'multiline':False]
['text':' free unused cached blocks to reclaim GPU memory if memory pressure is high','line_number':378,'multiline':False]
['text':' returns the suitable buffer pool type for the usage or','line_number':380,'multiline':False]
['text':' requested/allocated sizes','line_number':381,'multiline':False]
['text':' returns the aligned allocation size that is optimized','line_number':383,'multiline':False]
['text':' for the buffers to get reused frequently','line_number':384,'multiline':False]
['text':' maximum size of device memory available for allocation in current process','line_number':386,'multiline':False]
['text':' Note: the recommendedMaxWorkingSetSize is typically 75% of the total system memory.','line_number':387,'multiline':False]
['text':' there are implicit allocations from MPS backend, so we need to query the 'device' for','line_number':389,'multiline':False]
['text':' total allocated size instead of manually tracking in MPSAllocator','line_number':390,'multiline':False]
['text':' namespace at::mps::HeapAllocator','line_number':401,'multiline':False]
