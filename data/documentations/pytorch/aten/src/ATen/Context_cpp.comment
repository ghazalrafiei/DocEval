['text':' USE_FBGEMM','line_number':15,'multiline':False]
['text':' TODO: This could be bad juju if someone calls globalContext() in the','line_number':21,'multiline':False]
['text':' destructor of an object with static lifetime.','line_number':22,'multiline':False]
['text':' NB: This method is *purely* whether or not a user requested','line_number':28,'multiline':False]
['text':' that CuDNN was enabled, it doesn't actually say anything about','line_number':29,'multiline':False]
['text':' whether or not CuDNN is actually usable.','line_number':30,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-c-arrays,modernize-avoid-c-arrays)','line_number':128,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-c-arrays,modernize-avoid-c-arrays)','line_number':130,'multiline':False]
['text':' If using CUDA 10.2 or greater, need to make sure CuBLAS workspace config','line_number':135,'multiline':False]
['text':' is set to deterministic setting','line_number':136,'multiline':False]
['text':' TODO: consider if CuDNN field needs to also be set for potential future CuDNN ops like multi-headed attention','line_number':204,'multiline':False]
['text':' X86 is enabled if and only if fbgemm is available.
       * It combines goodness of fbgemm and onednn by dispatching.
       * If onednn not available, always dispatch to fbgemm.
       * Make it default qengine for X86 CPU platforms.
      ','line_number':307,'multiline':True]
['text':' Engines are listed in priority order: later one wins','line_number':332,'multiline':False]
['text':' By default we prefer FBGEMM if we're running on server side','line_number':333,'multiline':False]
['text':' QNNPACK on server side has some issue, so we disable it by default.','line_number':334,'multiline':False]
['text':' C10_MOBILE','line_number':340,'multiline':False]
['text':' C10_MOBILE','line_number':345,'multiline':False]
['text':' The X86 qengine is available if and only if FBGEMM is available','line_number':354,'multiline':False]
['text':' override_allow_tf32_flag = true','line_number':396,'multiline':False]
['text':'    means the allow_tf32 flags are overrided and tf32 is force disabled','line_number':397,'multiline':False]
['text':' override_allow_tf32_flag = false','line_number':398,'multiline':False]
['text':'    means the original allow_tf32 flags are followed','line_number':399,'multiline':False]
['text':' Ops can query this flag to know they are in the backward pass.','line_number':420,'multiline':False]
['text':' This information can be used, for example, to select implementations','line_number':421,'multiline':False]
['text':' with different numerical or performance characteristics.','line_number':422,'multiline':False]
['text':' See https://pytorch.org/docs/stable/notes/numerical_accuracy.html for details.','line_number':423,'multiline':False]
['text':' Setting the priority high to make sure no other allocator gets used instead of this.','line_number':451,'multiline':False]
['text':'priority','line_number':453,'multiline':True]
['text':' Setting the priority high to make sure no other allocator gets used instead of this.','line_number':460,'multiline':False]
['text':'priority','line_number':461,'multiline':True]
['text':' namespace at','line_number':464,'multiline':False]
