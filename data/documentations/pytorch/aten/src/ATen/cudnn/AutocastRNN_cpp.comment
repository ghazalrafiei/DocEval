['text':' pulls in AT_CUDNN_ENABLED() as defined by cmake','line_number':5,'multiline':False]
['text':'*******************************************************************************
Autocast wrapper for CuDNN RNNs (the weight reflattening needs special attention)
*******************************************************************************','line_number':15,'multiline':True]
['text':' To be registered for the "_cudnn_rnn(...)" schema.','line_number':19,'multiline':False]
['text':' _cudnn_rnn is autograd-exposed (test_autocast_cudnn_rnn in test_cuda.py includes a test to confirm)','line_number':20,'multiline':False]
['text':' weight_stride0 is the number of weight tensors per layer and direction, as seen by model.parameters().','line_number':44,'multiline':False]
['text':' If bias is enabled, there are 4 such tensors (ih and hh weights, ih and hh biases).','line_number':45,'multiline':False]
['text':' If bias is not enabled, there are 2 (ih and hh weights).','line_number':46,'multiline':False]
['text':' This organization holds for all rnn types (RNN, GRU, and LSTM). If LSTM with projections is','line_number':47,'multiline':False]
['text':' used, additional hr weight is added.','line_number':48,'multiline':False]
['text':' There's an implicit contract here with native/cudnn/RNN.cpp:_cudnn_impl, which calls at:_cudnn_rnn.','line_number':62,'multiline':False]
['text':' Code here assumes if _cudnn_impl passes weight_buf_opt containing a defined tensor, that tensor','line_number':63,'multiline':False]
['text':' is valid flat storage of the weights in their incoming dtype.','line_number':64,'multiline':False]
['text':' weight_buf is valid.  Only change it if it's eligible and not already FP16.','line_number':69,'multiline':False]
['text':' weight_buf is not valid.  Only create it if other weights are eligible and not already FP16.','line_number':71,'multiline':False]
['text':' Casts weight tensors to FP16 and ensures all weights for all layers are views into a large flat buffer,','line_number':74,'multiline':False]
['text':' with the right locations and layouts expected by cudnn.','line_number':75,'multiline':False]
['text':' This is (and should be) autograd-exposed.','line_number':76,'multiline':False]
['text':'flat_buf_datatype=','line_number':92,'multiline':True]
['text':' could just hardcode CUDNN_DATA_HALF','line_number':92,'multiline':False]
['text':'flat_buf_options=','line_number':93,'multiline':True]
['text':'set_orig_weights_to_flat_buf=','line_number':94,'multiline':True]
['text':'allow_type_change=','line_number':95,'multiline':True]
['text':'include_bias=','line_number':96,'multiline':True]
['text':' AT_CUDNN_ENABLED()','line_number':115,'multiline':False]
['text':' never reached, placates the compiler','line_number':117,'multiline':False]
['text':' AT_CUDNN_ENABLED()','line_number':118,'multiline':False]
['text':' anonymous namespace','line_number':126,'multiline':False]
['text':' namespace autocast','line_number':128,'multiline':False]
['text':' namespace at','line_number':129,'multiline':False]
