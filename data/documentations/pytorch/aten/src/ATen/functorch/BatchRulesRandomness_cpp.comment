['text':' Copyright (c) Facebook, Inc. and its affiliates.','line_number':1,'multiline':False]
['text':' All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' This source code is licensed under the BSD-style license found in the','line_number':4,'multiline':False]
['text':' LICENSE file in the root directory of this source tree.','line_number':5,'multiline':False]
['text':' This file contains batching rules for random operations. These are different','line_number':13,'multiline':False]
['text':' from our regular batching rules: regular batching rules get registered to the','line_number':14,'multiline':False]
['text':' FuncTorchBatched key, but batching rules for random operations get','line_number':15,'multiline':False]
['text':' registered to FuncTorchVmapMode. This is because we need to interpose on','line_number':16,'multiline':False]
['text':' random operations even if they're not on a BatchedTensor.','line_number':17,'multiline':False]
['text':' batching should make this just work out...','line_number':56,'multiline':False]
['text':' compute max logical rank','line_number':84,'multiline':False]
['text':' If the dimensions aren't aligned, we need to line them up.','line_number':92,'multiline':False]
['text':' Tensor[B, 3] + Tensor[2, 5, 3] -> Tensor[B, 1, 1, 3] + Tensor[2, 5, 3]','line_number':93,'multiline':False]
['text':' Note that only tensors that have a batch dim need to be modified.','line_number':94,'multiline':False]
['text':' Tensor[B, 2, 3, 5] + Tensor[5] -> no changes needed','line_number':95,'multiline':False]
['text':' batching should make this just work out...','line_number':105,'multiline':False]
['text':' since this is done in a loop, need to pass by reference for generator to update','line_number':123,'multiline':False]
['text':' if we are in eval mode, we don't use about randomness','line_number':199,'multiline':False]
['text':' if tensor is unbatched, add batch dim before','line_number':205,'multiline':False]
['text':' calling dropout.','line_number':206,'multiline':False]
['text':' repeated code from the CPU kernel since the CUDA one doesn't call bernoulli_ explicitly','line_number':219,'multiline':False]
['text':' Check for probability of zero to avoid divide by zero and NaN results','line_number':221,'multiline':False]
['text':' 1D cases: S -> BS -> multinomial(BS)','line_number':243,'multiline':False]
['text':'           BS -> multinomial(BS)','line_number':244,'multiline':False]
['text':'','line_number':245,'multiline':False]
['text':' 2D cases: MS -> BMS -> (BM)S -> multinomial((BM)S) -> (BM)S -> BMS','line_number':246,'multiline':False]
['text':'           BMS -> (BM)S -> multinomial((BM)S) -> (BM)S -> BMS','line_number':247,'multiline':False]
['text':' check_randomness eliminates error randomness','line_number':262,'multiline':False]
['text':' check_randomness eliminates same randomness with batched input','line_number':263,'multiline':False]
['text':' Must be same randomness with unbatched input','line_number':264,'multiline':False]
['text':' 1D case: S -> multinomial(S) -> S','line_number':265,'multiline':False]
['text':' 2D case: MS -> multinomial(MS) -> MS','line_number':266,'multiline':False]
['text':' needs special casing because cuda version doesn't call bernoulli','line_number':479,'multiline':False]
['text':' namespace at::functorch','line_number':508,'multiline':False]
