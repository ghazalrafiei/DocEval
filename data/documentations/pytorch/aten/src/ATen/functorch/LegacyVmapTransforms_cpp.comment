['text':' Copyright (c) Facebook, Inc. and its affiliates.','line_number':1,'multiline':False]
['text':' All rights reserved.','line_number':2,'multiline':False]
['text':'','line_number':3,'multiline':False]
['text':' This source code is licensed under the BSD-style license found in the','line_number':4,'multiline':False]
['text':' LICENSE file in the root directory of this source tree.','line_number':5,'multiline':False]
['text':' Takes a BatchedTensorImpl, permutes all of the batch dims to the front,','line_number':16,'multiline':False]
['text':' and then returns a physical version of the Tensor.','line_number':17,'multiline':False]
['text':'physical','line_number':51,'multiline':True]
['text':' NB: fmap doesn't have a SmallVector variant, so we don't use it here.','line_number':56,'multiline':False]
['text':' The algorithm is as follows:','line_number':112,'multiline':False]
['text':' 1. Figure out what all of the collective levels in `logical_tensors` is.','line_number':113,'multiline':False]
['text':' 2. Move all batch dims to the front of the tensors and add extra dims','line_number':114,'multiline':False]
['text':'    of size 1. At this point, every tensor will have a dimension for','line_number':115,'multiline':False]
['text':'    each of the collective levels.','line_number':116,'multiline':False]
['text':' 3. Compute the batch_sizes.','line_number':117,'multiline':False]
['text':' 4. Expand each physical tensor so that they have output batch size equal','line_number':118,'multiline':False]
['text':'    to `batch_sizes`','line_number':119,'multiline':False]
['text':' Figure out the batch size first','line_number':125,'multiline':False]
['text':' Unsqueeze dim 0, expand it to the correct shape','line_number':145,'multiline':False]
['text':' Figure out the batch size first','line_number':177,'multiline':False]
['text':' figure out the example ndim','line_number':190,'multiline':False]
['text':' Unsqueeze dim 0, expand it to the correct shape','line_number':200,'multiline':False]
['text':' namespace at','line_number':231,'multiline':False]
