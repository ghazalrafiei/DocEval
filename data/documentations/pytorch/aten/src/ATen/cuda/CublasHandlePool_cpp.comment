['text':' this is because of something dumb in the ordering of','line_number':26,'multiline':False]
['text':' destruction. Sometimes atexit, the cuda context (or something)','line_number':27,'multiline':False]
['text':' would already be destroyed by the time this gets destroyed. It','line_number':28,'multiline':False]
['text':' happens in fbcode setting. @colesbury and @soumith decided to not destroy','line_number':29,'multiline':False]
['text':' the handle as a workaround.','line_number':30,'multiline':False]
['text':'   - Comments of @soumith copied from cuDNN handle pool implementation','line_number':31,'multiline':False]
['text':' namespace','line_number':40,'multiline':False]
['text':' :4096:2:16:8 default, 32MiB for Hopper ','line_number':50,'multiline':True]
['text':' Thread local PoolWindows are lazily-initialized','line_number':92,'multiline':False]
['text':' to avoid initialization issues that caused hangs on Windows.','line_number':93,'multiline':False]
['text':' See: https://github.com/pytorch/pytorch/pull/22405','line_number':94,'multiline':False]
['text':' This thread local unique_ptrs will be destroyed when the thread terminates,','line_number':95,'multiline':False]
['text':' releasing its reserved handles back to the pool.','line_number':96,'multiline':False]
['text':' Use a leaky singleton for the pool following standard practice around','line_number':98,'multiline':False]
['text':' singletons: https://isocpp.org/wiki/faq/ctors#construct-on-first-use-v2','line_number':99,'multiline':False]
['text':' Leak the memory.','line_number':102,'multiline':False]
['text':' cuBLAS should not need an explicitly allocated workspace after CUDA 12.2','line_number':111,'multiline':False]
['text':' to avoid increasing memory usage during graph captures','line_number':112,'multiline':False]
['text':' original issue: https://github.com/pytorch/pytorch/pull/83461','line_number':113,'multiline':False]
['text':' On CUDA >= 11, and architecture >= Ampere, cuBLAS can use TF32 to speedup','line_number':123,'multiline':False]
['text':' FP32 data type calculations based on the value of the allow_tf32 flag.','line_number':124,'multiline':False]
['text':' To enable TF32, set the math mode of the handle to CUBLAS_TF32_TENSOR_OP_MATH.','line_number':125,'multiline':False]
['text':' namespace at::cuda','line_number':144,'multiline':False]
