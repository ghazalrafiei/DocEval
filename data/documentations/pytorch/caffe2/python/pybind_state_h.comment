['text':' Temporary solution for numpy < 1.7 versions: old macro, no promises.','line_number':30,'multiline':False]
['text':' You're strongly advised to upgrade to >= 1.7.','line_number':31,'multiline':False]
['text':' Forward declaring PyArrayObject for safety','line_number':39,'multiline':False]
['text':' USE_NUMPY','line_number':41,'multiline':False]
['text':' Add methods common to both CPU and GPU mode.','line_number':48,'multiline':False]
['text':' Expose Workspace, Net, Blob','line_number':50,'multiline':False]
['text':' Get current workspace','line_number':53,'multiline':False]
['text':' Get workspace by name. Returns nullptr if none exists by name.','line_number':56,'multiline':False]
['text':' Checks whether the data with type `dtype` needs to be copied in the context','line_number':95,'multiline':False]
['text':' of `tensor`','line_number':96,'multiline':False]
['text':' USE_NUMPY','line_number':103,'multiline':False]
['text':' cleanup on failure','line_number':139,'multiline':False]
['text':' TODO: use CUDAGuard here instead of context and employ explicit sync','line_number':151,'multiline':False]
['text':' copy','line_number':152,'multiline':False]
['text':' USE_NUMPY','line_number':160,'multiline':False]
['text':' numpy requires long int as its dims.','line_number':191,'multiline':False]
['text':' Now, copy the data to the tensor.','line_number':203,'multiline':False]
['text':' string','line_number':219,'multiline':False]
['text':' USE_NUMPY','line_number':253,'multiline':False]
['text':' namespace python_detail','line_number':283,'multiline':False]
['text':' TODO: Remove template?','line_number':285,'multiline':False]
['text':' to use the `_a` literal for arguments','line_number':321,'multiline':False]
['text':' Rethrow exception to preserve python exception type.','line_number':340,'multiline':False]
['text':' Acquire GIL for call to Python runtime.','line_number':350,'multiline':False]
['text':' Allow CPU tensors in addition to operator context's tensors','line_number':360,'multiline':False]
['text':' copy wrapper','line_number':368,'multiline':False]
['text':' Python op is always used with CPUContext only and treats inputs and','line_number':381,'multiline':False]
['text':' outputs as CPU tensors, CUDA version of PythonOp is implemented','line_number':382,'multiline':False]
['text':' through GPUFallbackOp that copies input CUDA blobs to CPU and copies','line_number':383,'multiline':False]
['text':' outputs from CUDA to CPU.','line_number':384,'multiline':False]
['text':' GPUFallbackOp also allows keeping some of the output blobs on CPU','line_number':385,'multiline':False]
['text':' by specifying their indices explicitly in template parameters.','line_number':386,'multiline':False]
['text':' PythonDLPack op allows working CPU blobs only through DLPack tensors.','line_number':388,'multiline':False]
['text':' We don't have use cases of CUDA version yet, but if there is such use','line_number':389,'multiline':False]
['text':' case, we can use GPUFallbackOp to enable it.','line_number':390,'multiline':False]
['text':' Rethrow exception to preserve python exception type.','line_number':414,'multiline':False]
['text':' since it may trigger python interpreter when refcount reaches zero','line_number':423,'multiline':False]
['text':' namespace python','line_number':466,'multiline':False]
['text':' namespace caffe2','line_number':467,'multiline':False]
