['text':' Utility class for other loading tests, don't add test functions here','line_number':28,'multiline':False]
['text':' Inherit from this test instead. If you add a test here,','line_number':29,'multiline':False]
['text':' each derived class will inherit it as well and cause test duplication','line_number':30,'multiline':False]
['text':' Saves the blobs to a local db.','line_number':60,'multiline':False]
['text':' Reset the workspace so that anything we load is surely loaded','line_number':69,'multiline':False]
['text':' from the serialized proto.','line_number':70,'multiline':False]
['text':' Load using device option stored in the proto, i.e.','line_number':101,'multiline':False]
['text':' src_device_option','line_number':102,'multiline':False]
['text':' Load again, but this time load into dst_device_option.','line_number':104,'multiline':False]
['text':' Load back to the src_device_option to see if both paths are able','line_number':106,'multiline':False]
['text':' to reallocate memory.','line_number':107,'multiline':False]
['text':' Reset the workspace, and load directly into the dst_device_option.','line_number':109,'multiline':False]
['text':' Test load all which loads all blobs in the db into the workspace.','line_number':113,'multiline':False]
['text':' Load again making sure that overwrite functionality works.','line_number':116,'multiline':False]
['text':' Load again with different device.','line_number':118,'multiline':False]
['text':' Saves the blobs to a local db.','line_number':139,'multiline':False]
['text':' Saves the blobs to a local db.','line_number':165,'multiline':False]
['text':' Saves the blobs to a local db.','line_number':243,'multiline':False]
['text':' moved here per @cxj's suggestion','line_number':284,'multiline':False]
['text':' load 'x' into 'blob_x'','line_number':286,'multiline':False]
['text':' we should have 'blob_a/b/c/' and 'blob_x' now','line_number':298,'multiline':False]
['text':' we should have 'blob_a/b/c/' and 'blob_x/y/z' now','line_number':314,'multiline':False]
['text':' Saves the blobs to a local db.','line_number':560,'multiline':False]
['text':' This is the default value of the --caffe2_tensor_chunk_size flag from','line_number':589,'multiline':False]
['text':' core/blob_serialization.cc','line_number':590,'multiline':False]
['text':'','line_number':591,'multiline':False]
['text':' Test with just slightly more than this to ensure that 2 chunks are','line_number':592,'multiline':False]
['text':' used.','line_number':593,'multiline':False]
['text':' Saves the blobs to a local db.','line_number':616,'multiline':False]
['text':' We explicitly set a chunk_size of 10 for int16_data','line_number':644,'multiline':False]
['text':' uint16_data should match the .*16_data pattern, and get a size of 20','line_number':648,'multiline':False]
['text':' float16_data should also match the .*16_data pattern, and get a size','line_number':652,'multiline':False]
['text':' of 20.  The explicitly float16_data rule came after the .*16_data','line_number':653,'multiline':False]
['text':' pattern, so it has lower precedence and will be ignored.','line_number':654,'multiline':False]
['text':' int64_data will get the default chunk_size of 40','line_number':658,'multiline':False]
['text':' Saves the blobs to a local db.','line_number':675,'multiline':False]
['text':' Create 2 blobs with the same float data','line_number':698,'multiline':False]
['text':' Serialize the data, using bfloat16 serialization for one of the blobs','line_number':704,'multiline':False]
['text':' As long as fbgemm was available for us to perform bfloat16 conversion,','line_number':723,'multiline':False]
['text':' the serialized data for float1 should be almost half the size of float2','line_number':724,'multiline':False]
['text':' float2 should be exactly the same as the input data','line_number':736,'multiline':False]
['text':' float2 should be close-ish to the input data','line_number':738,'multiline':False]
['text':' Create some blobs to test with','line_number':744,'multiline':False]
['text':' Estimate the serialized size of the data.','line_number':755,'multiline':False]
['text':' Request bfloat16 serialization for one of the float blobs, just to','line_number':756,'multiline':False]
['text':' exercise size estimation when using this option.','line_number':757,'multiline':False]
['text':' Note that the output blob list will include our output blob names.','line_number':781,'multiline':False]
['text':' The estimation code applies a fixed 40 byte per-chunk overhead to','line_number':791,'multiline':False]
['text':' account for the extra space required for other fixed TensorProto','line_number':792,'multiline':False]
['text':' message fields.','line_number':793,'multiline':False]
['text':' Our serialization options request to split float1 into 500-element','line_number':809,'multiline':False]
['text':' chunks when saving it.  If fbgemm is available then the float1 blob','line_number':810,'multiline':False]
['text':' will be serialized using 2 bytes per element instead of 4 bytes.','line_number':811,'multiline':False]
['text':' Now actually save the blobs so we can compare our estimates','line_number':821,'multiline':False]
['text':' to how big the serialized data actually is.','line_number':822,'multiline':False]
['text':' For sanity checking, ensure that our estimates aren't','line_number':842,'multiline':False]
['text':' extremely far off','line_number':843,'multiline':False]
['text':' Don't check the blob_names blob.  It is a string tensor, and we','line_number':853,'multiline':False]
['text':' can't estimate string tensor sizes very well without knowing the','line_number':854,'multiline':False]
['text':' individual string lengths.  (Currently it requires 102 bytes to','line_number':855,'multiline':False]
['text':' save, but we estimate 360).','line_number':856,'multiline':False]
['text':' Check that we are within 100 bytes, or within 25%','line_number':859,'multiline':False]
['text':' We are generally quite close for tensors with fixed-width fields','line_number':860,'multiline':False]
['text':' (like float), but a little farther off for tensors that use varint','line_number':861,'multiline':False]
['text':' encoding.','line_number':862,'multiline':False]
