['text':'# @package attention','line_number':1,'multiline':False]
['text':' Module caffe2.python.attention','line_number':2,'multiline':False]
['text':' We have to manually scope due to our internal/external blob','line_number':16,'multiline':False]
['text':' relationships.','line_number':17,'multiline':False]
['text':' c_i = \sum_j w_{ij}\textbf{s}_j','line_number':21,'multiline':False]
['text':' [batch_size, encoder_output_dim, 1]','line_number':29,'multiline':False]
['text':' [batch_size, encoder_output_dim]','line_number':35,'multiline':False]
['text':' Calculate a softmax over the passed in attention energy logits','line_number':47,'multiline':False]
['text':' [batch_size, encoder_length, 1]','line_number':61,'multiline':False]
['text':' e_{ij} = \textbf{v}^T tanh \alpha(\textbf{h}_{i-1}, \textbf{s}_j)','line_number':72,'multiline':False]
['text':' [encoder_length, batch_size, encoder_output_dim]','line_number':79,'multiline':False]
['text':' [encoder_length, batch_size, 1]','line_number':85,'multiline':False]
['text':' [batch_size, encoder_length, 1]','line_number':96,'multiline':False]
['text':' \textbf{W}^\alpha used in the context of \alpha_{sum}(a,b)','line_number':106,'multiline':False]
['text':' Implement RecAtt due to section 4.1 in http://arxiv.org/abs/1601.03317','line_number':131,'multiline':False]
['text':' [1, batch_size, encoder_output_dim]','line_number':160,'multiline':False]
['text':' [encoder_length, batch_size, encoder_output_dim]','line_number':168,'multiline':False]
['text':' [batch_size, encoder_length, 1]','line_number':184,'multiline':False]
['text':' [batch_size, encoder_output_dim, 1]','line_number':192,'multiline':False]
['text':' [encoder_length, batch_size, encoder_output_dim]','line_number':224,'multiline':False]
['text':' [batch_size, encoder_length, 1]','line_number':239,'multiline':False]
['text':' [batch_size, encoder_output_dim, 1]','line_number':247,'multiline':False]
['text':' [batch_size, encoder_output_dim, encoder_length]','line_number':263,'multiline':False]
['text':' [1, batch_size, decoder_state_dim]','line_number':265,'multiline':False]
['text':' [batch_size, decoder_state_dim]','line_number':283,'multiline':False]
['text':' [batch_size, decoder_state_dim, 1]','line_number':290,'multiline':False]
['text':' [batch_size, encoder_output_dim, 1]','line_number':297,'multiline':False]
['text':' [batch_size, encoder_length, 1]','line_number':307,'multiline':False]
['text':' [batch_size, encoder_output_dim, 1]','line_number':315,'multiline':False]
['text':' [encoder_length, batch_size, encoder_output_dim]','line_number':348,'multiline':False]
['text':' [batch_size, encoder_length]','line_number':354,'multiline':False]
['text':' [encoder_length, batch_size]','line_number':360,'multiline':False]
['text':' [encoder_length, batch_size, encoder_output_dim]','line_number':367,'multiline':False]
['text':' [encoder_length, batch_size, encoder_output_dim]','line_number':375,'multiline':False]
['text':' [batch_size, encoder_length, 1]','line_number':381,'multiline':False]
['text':' [batch_size, encoder_length, 1]','line_number':389,'multiline':False]
['text':' [batch_size, encoder_output_dim, 1]','line_number':397,'multiline':False]
['text':' [batch_size, encoder_length]','line_number':406,'multiline':False]
