['text':' Sanity check we didn't overwrite anything','line_number':90,'multiline':False]
['text':' Make an identically-sized empty destination dataset','line_number':94,'multiline':False]
['text':' Make an identically-sized empty destination dataset','line_number':127,'multiline':False]
['text':' executed once','line_number':159,'multiline':False]
['text':' executed once per thread','line_number':164,'multiline':False]
['text':' executed on each iteration','line_number':167,'multiline':False]
['text':' executed once per thread','line_number':170,'multiline':False]
['text':' executed once','line_number':175,'multiline':False]
['text':' Read full data set from original reader','line_number':182,'multiline':False]
['text':' Read with a count-limited reader','line_number':190,'multiline':False]
['text':' Make source dataset','line_number':206,'multiline':False]
['text':' Make an identically-sized empty destination Dataset','line_number':209,'multiline':False]
['text':' Read without limiter','line_number':221,'multiline':False]
['text':' WorkspaceType.GLOBAL is required because we are fetching','line_number':222,'multiline':False]
['text':' reader.data_finished() after the TaskGroup finishes.','line_number':223,'multiline':False]
['text':' Do a fuzzy match (expected_read_len +/- expected_read_len_threshold)','line_number':235,'multiline':False]
['text':' to eliminate flakiness for time-limited tests','line_number':236,'multiline':False]
['text':' No iter count specified, should read all records.','line_number':251,'multiline':False]
['text':' Zero iter count specified, should read 0 records.','line_number':262,'multiline':False]
['text':' Read with limit smaller than size of dataset','line_number':273,'multiline':False]
['text':' Read with limit larger than size of dataset','line_number':284,'multiline':False]
['text':' No duration specified, should read all records.','line_number':295,'multiline':False]
['text':' Read with insufficient time limit','line_number':306,'multiline':False]
['text':' Because the time limit check happens before the delay + read op,','line_number':312,'multiline':False]
['text':' subtract a little bit of time to ensure we don't get in an extra read','line_number':313,'multiline':False]
['text':' NOTE: `expected_read_len_threshold` was added because this test case','line_number':316,'multiline':False]
['text':' has significant execution variation under stress. Under stress, we may','line_number':317,'multiline':False]
['text':' read strictly less than the expected # of samples; anywhere from','line_number':318,'multiline':False]
['text':' [0,N] where N = expected_read_len.','line_number':319,'multiline':False]
['text':' Hence we set expected_read_len to N/2, plus or minus N/2.','line_number':320,'multiline':False]
['text':' Read with ample time limit','line_number':331,'multiline':False]
['text':' NOTE: we don't use `expected_read_len_threshold` because the duration,','line_number':332,'multiline':False]
['text':' read_delay, and # threads should be more than sufficient','line_number':333,'multiline':False]
['text':' In case any test method fails, clean up temp paths.','line_number':349,'multiline':False]
['text':' Remove file.','line_number':356,'multiline':False]
['text':' Remove dir recursively.','line_number':358,'multiline':False]
['text':' Make a temp path as db_path.','line_number':361,'multiline':False]
['text':' Read data for the first time.','line_number':388,'multiline':False]
['text':' Read data from cache.','line_number':398,'multiline':False]
['text':' We removed cache so we expect to receive data from original reader.','line_number':410,'multiline':False]
['text':' Build a cache DB file.','line_number':428,'multiline':False]
['text':' Read data from cache DB file.','line_number':437,'multiline':False]
