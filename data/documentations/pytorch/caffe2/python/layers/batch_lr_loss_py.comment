['text':'# @package batch_lr_loss','line_number':1,'multiline':False]
['text':' Module caffe2.python.layers.batch_lr_loss','line_number':2,'multiline':False]
['text':' iter = 0: lr = 1;','line_number':170,'multiline':False]
['text':' iter = 1e6; lr = 0.5^0.1  = 0.93','line_number':171,'multiline':False]
['text':' iter = 1e9; lr = 1e-3^0.1 = 0.50','line_number':172,'multiline':False]
['text':' numerically stable log-softmax with crossentropy','line_number':182,'multiline':False]
['text':' mandatory cast to float32','line_number':184,'multiline':False]
['text':' self.input_record.label.field_type().base is np.float32 but','line_number':185,'multiline':False]
['text':' label type is actually int','line_number':186,'multiline':False]
['text':' focal loss = (y(1-p) + p(1-y))^gamma * original LR loss','line_number':215,'multiline':False]
['text':' y(1-p) + p(1-y) = y + p - 2 * yp','line_number':216,'multiline':False]
['text':' fuse with JSD','line_number':255,'multiline':False]
['text':' mean (0.5 * exp(-s) * loss + 0.5 * penalty * s)','line_number':271,'multiline':False]
['text':' enforce less than 88 to avoid OverflowError','line_number':284,'multiline':False]
