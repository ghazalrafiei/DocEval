['text':' Note(jiayq): we are yet to find out why Travis gives out an error in gloo','line_number':33,'multiline':False]
['text':' like:','line_number':34,'multiline':False]
['text':' RuntimeError: [enforce fail at /home/travis/build/caffe2/caffe2/third_party/gloo/gloo/transport/tcp/device.cc:113] ifa != nullptr. Unable to find interface for: [127.0.1.1]','line_number':35,'multiline':False]
['text':' See for example https://travis-ci.org/caffe2/caffe2/jobs/262433866','line_number':36,'multiline':False]
['text':' As a result, we will check if this is travis, and if yes, disable it.','line_number':37,'multiline':False]
['text':' For testing explicit sync','line_number':57,'multiline':False]
['text':' Light test for LR names','line_number':87,'multiline':False]
['text':' Each run has same input, independent of number of gpus','line_number':93,'multiline':False]
['text':' Test AddBlobSync','line_number':123,'multiline':False]
['text':' Queue for assertion errors on subprocesses','line_number':132,'multiline':False]
['text':' Capture any exception thrown by the subprocess','line_number':135,'multiline':False]
['text':' Start N processes in the background','line_number':148,'multiline':False]
['text':' Test complete, join background processes','line_number':158,'multiline':False]
['text':' Raise exception if we find any.','line_number':164,'multiline':False]
['text':' Note that the following is executed ALSO after','line_number':165,'multiline':False]
['text':' the last process was joined, so if ANY exception','line_number':166,'multiline':False]
['text':' was raised, it will be re-raised here.','line_number':167,'multiline':False]
['text':' Add a duplicate param init to ensure it does not cause issues','line_number':215,'multiline':False]
['text':' Only gpu_1 params should be returned (gpu_1 is the first gpu)','line_number':236,'multiline':False]
['text':' Append the net and param_init_net of the other model','line_number':272,'multiline':False]
['text':' Just create and run net and confirm no exception is thrown','line_number':299,'multiline':False]
['text':' Set network timeout to 2 seconds, and add a 3 seconds','line_number':385,'multiline':False]
['text':' sleep for 1 host.  Make sure there is no timeout on the','line_number':386,'multiline':False]
['text':' second RunNet.','line_number':387,'multiline':False]
['text':' assert that the transformer is called for both train and test cases','line_number':435,'multiline':False]
['text':' dBias','line_number':498,'multiline':False]
['text':' Sum dBias values over all devices to find the average gradient','line_number':499,'multiline':False]
['text':' dGamma','line_number':513,'multiline':False]
['text':' Sum dGamma values over all devices to find the average gradient','line_number':514,'multiline':False]
['text':' dX','line_number':526,'multiline':False]
['text':' Verify that the gradients calculated over multiple devices are the','line_number':609,'multiline':False]
['text':' same as the gradients calculated over one device. These values should','line_number':610,'multiline':False]
['text':' be equivalent because combine_spatial_bn sums values over all devices','line_number':611,'multiline':False]
['text':' Scalar and Bias gradients should be the same across devices','line_number':625,'multiline':False]
['text':' Expected tanh_grad should be the combined tanh_grad vectors','line_number':634,'multiline':False]
['text':' across the devices','line_number':635,'multiline':False]
['text':' We are generating random data','line_number':694,'multiline':False]
['text':' Get values calculated without combine_spatial_bn','line_number':699,'multiline':False]
['text':' Get values calculated over multiple devices with combine_spatial_bn true','line_number':713,'multiline':False]
['text':' Check to see if the combined values are equivalent','line_number':731,'multiline':False]
['text':' A silly loss function','line_number':780,'multiline':False]
['text':' Change all initialization to be ConstantFills so that','line_number':826,'multiline':False]
['text':' the everything is deterministic','line_number':827,'multiline':False]
['text':' Each run has same input, independent of number of gpus','line_number':832,'multiline':False]
['text':' Update the vecs','line_number':981,'multiline':False]
['text':' Each run has same input, independent of number of gpus','line_number':998,'multiline':False]
['text':' Force vecs to be same on all runs','line_number':1025,'multiline':False]
['text':' Sanity check to see the vecs were updated','line_number':1049,'multiline':False]
['text':' Each run has same input, independent of number of gpus','line_number':1122,'multiline':False]
['text':' Check initial momentum params are zeros','line_number':1175,'multiline':False]
['text':' Run the algorithm for one iteration to have non-zero params.','line_number':1185,'multiline':False]
['text':' Save iteration momentum and post local update params','line_number':1188,'multiline':False]
['text':' Compute block gradients.','line_number':1199,'multiline':False]
['text':' Check momentum update step','line_number':1216,'multiline':False]
['text':' Check params update step','line_number':1225,'multiline':False]
['text':' Update the vecs','line_number':1346,'multiline':False]
['text':' Each run has same input, independent of number of gpus','line_number':1351,'multiline':False]
['text':' Force vecs to be same on all runs','line_number':1371,'multiline':False]
['text':' print (len(idx), len(grad_slice))','line_number':1401,'multiline':False]
