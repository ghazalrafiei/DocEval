['text':' check iteration counters have the same value by default','line_number':151,'multiline':False]
['text':' YellowFin: An automatic tuner for momentum SGD','line_number':322,'multiline':False]
['text':' (https://arxiv.org/abs/1706.03471)','line_number':323,'multiline':False]
['text':' First tune based on dynamic range','line_number':351,'multiline':False]
['text':' a hack to create an object with __dict__','line_number':406,'multiline':False]
['text':' Check same optimizer share the same learning rate.','line_number':637,'multiline':False]
['text':' Check different instance of the same optimizer has a different lr.','line_number':649,'multiline':False]
['text':' Check different optimizer type case','line_number':662,'multiline':False]
['text':' Check the proto that all weights are decayed and not non-weights','line_number':698,'multiline':False]
['text':' are decayed.','line_number':699,'multiline':False]
['text':' use the following optimizer if none specified in param_info','line_number':741,'multiline':False]
['text':' Check the proto that all weights are decayed and not non-weights','line_number':752,'multiline':False]
['text':' are decayed.','line_number':753,'multiline':False]
['text':' Check the learning rate for each parameter','line_number':762,'multiline':False]
