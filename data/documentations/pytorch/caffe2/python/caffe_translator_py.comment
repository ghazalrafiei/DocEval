['text':'# @package caffe_translator','line_number':1,'multiline':False]
['text':' Module caffe2.python.caffe_translator','line_number':2,'multiline':False]
['text':' noqa','line_number':8,'multiline':False]
['text':' all stages in rule.stages should be in, otherwise it's not a match.','line_number':29,'multiline':False]
['text':' none of the stage in rule.stages should be in, otherwise it's not a match.','line_number':32,'multiline':False]
['text':' If none of the nonmatch happens, return True.','line_number':35,'multiline':False]
['text':' check exclude rules: if any exclusion is met, we shouldn't include.','line_number':42,'multiline':False]
['text':' check include rules: if any inclusion is met, we should include.','line_number':45,'multiline':False]
['text':' Get dimensions with legacy pad','line_number':58,'multiline':False]
['text':' Running with the legacy pad argument removed','line_number':125,'multiline':False]
['text':' compare the dimensions and adjust pad argument when necessary','line_number':126,'multiline':False]
['text':' remove legacy pad arg','line_number':142,'multiline':False]
['text':' use a new name to avoid the interference with inplace','line_number':149,'multiline':False]
['text':' reset output name','line_number':154,'multiline':False]
['text':' Get dimensions with legacy pad','line_number':173,'multiline':False]
['text':' getting input dimension from first layer','line_number':190,'multiline':False]
['text':' Get pretrained one','line_number':250,'multiline':False]
['text':' No pretrained layer for the given layer name. We'll just pass','line_number':266,'multiline':False]
['text':' no parameter blobs.','line_number':267,'multiline':False]
['text':' print 'No pretrained layer for layer', layer.name','line_number':268,'multiline':False]
['text':'###############################################################################','line_number':323,'multiline':False]
['text':' Common translators for layers.','line_number':324,'multiline':False]
['text':'###############################################################################','line_number':325,'multiline':False]
['text':' A function used in convolution, pooling and deconvolution to deal with','line_number':343,'multiline':False]
['text':' conv pool specific parameters.','line_number':344,'multiline':False]
['text':' This catches the case of a PoolingParameter, in which case we are','line_number':357,'multiline':False]
['text':' having non-repeating pad, stride and kernel.','line_number':358,'multiline':False]
['text':' Get stride','line_number':362,'multiline':False]
['text':' Get pad','line_number':368,'multiline':False]
['text':' Get kernel','line_number':379,'multiline':False]
['text':' weight','line_number':410,'multiline':False]
['text':' bias','line_number':413,'multiline':False]
['text':' weight','line_number':429,'multiline':False]
['text':' bias','line_number':432,'multiline':False]
['text':' Group convolution option','line_number':438,'multiline':False]
['text':' Get dilation - not tested. If you have a model and this checks out,','line_number':441,'multiline':False]
['text':' please provide a test and uncomment this.','line_number':442,'multiline':False]
['text':' In the Facebook port of Caffe, a torch_pooling field was added to','line_number':520,'multiline':False]
['text':' map the pooling computation of Torch. Essentially, it uses','line_number':521,'multiline':False]
['text':'   floor((height + 2 * padding - kernel) / stride) + 1','line_number':522,'multiline':False]
['text':' instead of','line_number':523,'multiline':False]
['text':'   ceil((height + 2 * padding - kernel) / stride) + 1','line_number':524,'multiline':False]
['text':' which is Caffe's version.','line_number':525,'multiline':False]
['text':' Torch pooling is actually the same as Caffe2 pooling, so we don't','line_number':526,'multiline':False]
['text':' need to do anything.','line_number':527,'multiline':False]
['text':' We might be using an historic Caffe protobuf that does not have axis','line_number':594,'multiline':False]
['text':' and transpose arguments, so we will silently pass.','line_number':595,'multiline':False]
['text':' To provide the old-style 4-dimensional blob (1, 1, dim_output, dim_input)','line_number':600,'multiline':False]
['text':' case, we always explicitly reshape the pretrained blob.','line_number':601,'multiline':False]
['text':' IntelCaffe and NVCaffe uses fused BN+Scale,','line_number':719,'multiline':False]
['text':' three blobs for BN and two blobs for Scale,','line_number':720,'multiline':False]
['text':' so that the total number of blobs becomes five (including scale and bias).','line_number':721,'multiline':False]
['text':' TODO(jiayq): if we have a protobuf that uses this, lift this constraint','line_number':744,'multiline':False]
['text':' and verify that we can correctly translate.','line_number':745,'multiline':False]
['text':' the scale parameter is in pretrained blobs','line_number':759,'multiline':False]
['text':' No bias-term in Scale layer','line_number':772,'multiline':False]
['text':' Caffe Scale layer supports a bias term such that it computes','line_number':775,'multiline':False]
['text':' (scale_param * X + bias), whereas Caffe2 Mul op doesn't.','line_number':776,'multiline':False]
['text':' Include a separate Add op for the bias followed by Mul.','line_number':777,'multiline':False]
['text':' TODO(jiayq): find a protobuf that uses this and verify.','line_number':798,'multiline':False]
['text':' This could be a Reshape op, but dim size is not known here.','line_number':824,'multiline':False]
['text':' Only used for gradient computation','line_number':845,'multiline':False]
['text':' We can't figure out the number of dims to reduce from positive axis','line_number':880,'multiline':False]
['text':' for back reduction since the shape info is not known here.','line_number':881,'multiline':False]
['text':' Assume there is one input and one output','line_number':923,'multiline':False]
