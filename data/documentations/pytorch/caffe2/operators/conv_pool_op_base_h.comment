['text':' This macro is here just to allow us to experiment with padding values that','line_number':15,'multiline':False]
['text':' determines, when we have an odd number of pads, which side gets the one','line_number':16,'multiline':False]
['text':' additional pad value, the head side, or the tail side. Setting it to false','line_number':17,'multiline':False]
['text':' will enable the TensorFlow behavior, and setting it to true will enable','line_number':18,'multiline':False]
['text':' a behavior more consistent with Caffe and CuDNN.','line_number':19,'multiline':False]
['text':' This only affects the case when you set legacy pad to VALID or SAME. The','line_number':20,'multiline':False]
['text':' behavior inherits from the early designs of Google's CNN implementation,','line_number':21,'multiline':False]
['text':' where padding values are implicitly calculated instead of explicitly','line_number':22,'multiline':False]
['text':' specified. This is still the case with TensorFlow. Many frameworks have','line_number':23,'multiline':False]
['text':' followed a slightly different approach of explicitly giving padding values,','line_number':24,'multiline':False]
['text':' in which case the value of this constant value does not matter.','line_number':25,'multiline':False]
['text':' For the padding, they should either be the legacy padding strategy','line_number':54,'multiline':False]
['text':' (VALID or SAME), or an explicit, non-negative value.','line_number':55,'multiline':False]
['text':' Get old arguments values.','line_number':64,'multiline':False]
['text':' Fill default values.','line_number':117,'multiline':False]
['text':' Check kernel only if we are doing conv or pooling. The reason is that a','line_number':151,'multiline':False]
['text':' few other ops, like PadImage, are also using this base class. We really','line_number':152,'multiline':False]
['text':' need to clean this up.','line_number':153,'multiline':False]
['text':' Returns the input image dimensions for the current storage order type.','line_number':173,'multiline':False]
['text':' Returns the size of the input image for the current storage type.','line_number':189,'multiline':False]
['text':' Gets the output size. The output channel is manually provided since','line_number':213,'multiline':False]
['text':' it may not be identical to the input channels.','line_number':214,'multiline':False]
['text':' This function can be used in the forward functions to obtain the output','line_number':215,'multiline':False]
['text':' sizes.','line_number':216,'multiline':False]
['text':' Note(jiayq): the templatization of this function is mainly to help','line_number':217,'multiline':False]
['text':' implementations that do not use first-class Tensor objects, such as the','line_number':218,'multiline':False]
['text':' MKL operator. One can still call this function with dummy','line_number':219,'multiline':False]
['text':' Tensor objects in order to obtain the sizes.','line_number':220,'multiline':False]
['text':' Helper function that is also called from OperatorSchema. Modified','line_number':258,'multiline':False]
['text':' kernel parameters and output output_dims and channel_first.','line_number':259,'multiline':False]
['text':' ComputePads could be used in backward functions to figure out the padding','line_number':338,'multiline':False]
['text':' values for the given input.','line_number':339,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':345,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':379,'multiline':False]
['text':' If the helper bias multiplier is not image size, reshape and fill it','line_number':402,'multiline':False]
['text':' with one.','line_number':403,'multiline':False]
['text':' VLOG(2) << "Running NHWC";','line_number':421,'multiline':False]
['text':' VLOG(2) << "Running NCHW";','line_number':424,'multiline':False]
['text':' The actual function that does the computation, if the different','line_number':431,'multiline':False]
['text':' storage order leads to different implementations.','line_number':432,'multiline':False]
['text':' 3D convolution','line_number':466,'multiline':False]
['text':' 2D convolution','line_number':487,'multiline':False]
['text':' 1D convolution','line_number':505,'multiline':False]
['text':' grouping is NOT properly handled yet','line_number':531,'multiline':False]
['text':' We will just use the direct padding head and tail values, but we','line_number':683,'multiline':False]
['text':' will verify that they are non-negative.','line_number':684,'multiline':False]
['text':' This is in order to adapt Caffe's pooling padding case. In this case,','line_number':711,'multiline':False]
['text':' we will only use pad_head and will compute pad_tail to match the','line_number':712,'multiline':False]
['text':' old caffe pooling strategy. Also see caffe2_legacy.proto for more','line_number':713,'multiline':False]
['text':' details.','line_number':714,'multiline':False]
['text':' Here, notice that caffe casts UP while caffe2 casts DOWN for the','line_number':716,'multiline':False]
['text':' output size computation.','line_number':717,'multiline':False]
['text':' If we have padding, caffe also ensures that the last pooling starts','line_number':720,'multiline':False]
['text':' strictly inside the image (instead of at the padding); otherwise clip','line_number':721,'multiline':False]
['text':' the last.','line_number':722,'multiline':False]
['text':' Now, compare the output size with the standard Caffe2 output size.','line_number':726,'multiline':False]
['text':' The','line_number':727,'multiline':False]
['text':' caffe2 standard output size should always be no larger than the','line_number':728,'multiline':False]
['text':' output','line_number':729,'multiline':False]
['text':' size of caffe.','line_number':730,'multiline':False]
['text':' We will just use the direct padding head and tail values, but we','line_number':762,'multiline':False]
['text':' will verify that they are non-negative.','line_number':763,'multiline':False]
['text':' This is in order to adapt Caffe's pooling padding case. In this case,','line_number':790,'multiline':False]
['text':' we will only use pad_head and will compute pad_tail to match the','line_number':791,'multiline':False]
['text':' old caffe pooling strategy. Also see caffe2_legacy.proto for more','line_number':792,'multiline':False]
['text':' details.','line_number':793,'multiline':False]
['text':' Here, notice that caffe casts UP while caffe2 casts DOWN for the','line_number':795,'multiline':False]
['text':' output size computation.','line_number':796,'multiline':False]
['text':' If we have padding, caffe also ensures that the last pooling starts','line_number':799,'multiline':False]
['text':' strictly inside the image (instead of at the padding); otherwise clip','line_number':800,'multiline':False]
['text':' the last.','line_number':801,'multiline':False]
['text':' Now, compare the output size with the standard Caffe2 output size.','line_number':805,'multiline':False]
['text':' The','line_number':806,'multiline':False]
['text':' caffe2 standard output size should always be no larger than the','line_number':807,'multiline':False]
['text':' output','line_number':808,'multiline':False]
['text':' size of caffe.','line_number':809,'multiline':False]
['text':' Accessors for 2D conv params.','line_number':829,'multiline':False]
['text':' namespace caffe2','line_number':907,'multiline':False]
['text':' CAFFE2_OPERATORS_CONV_POOL_OP_BASE_H_','line_number':909,'multiline':False]
