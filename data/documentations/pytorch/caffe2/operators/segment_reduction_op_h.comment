['text':' blocks ','line_number':28,'multiline':True]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':36,'multiline':False]
['text':' Range reducer ops: leverage that input segment is continuous and allow','line_number':37,'multiline':False]
['text':' reducer functors to do something special','line_number':38,'multiline':False]
['text':' Note: for now there are no real use cases for it yet :)','line_number':39,'multiline':False]
['text':' Also, doesn't support additional arguments for now','line_number':40,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':41,'multiline':False]
['text':'*
 * Base implementation for segment reduction op that leverages continuity of the
 * data
 *
 * Assumes that segments are sorted and there are no skip indices
 ','line_number':43,'multiline':True]
['text':' Assume the segments are sorted and there are no gaps','line_number':92,'multiline':False]
['text':' check correctness of the next segment','line_number':106,'multiline':False]
['text':' TODO(azzolini): avoid using input/output if not used by a particular op','line_number':135,'multiline':False]
['text':' Assume the segments are sorted and there are no gaps','line_number':162,'multiline':False]
['text':' repeat the check from forward op','line_number':164,'multiline':False]
['text':' check correctness of the next segment','line_number':183,'multiline':False]
['text':' no gradient on segment_ids!','line_number':247,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':253,'multiline':False]
['text':' Incremental reducer ops: assume that reducer consumes pieces of data one by','line_number':254,'multiline':False]
['text':' one. Also, supports additional arguments passed to reducer, e.g. scalers for','line_number':255,'multiline':False]
['text':' weighted sum.','line_number':256,'multiline':False]
['text':'','line_number':257,'multiline':False]
['text':' Note: in current implementation additional inputs are considered auxiliary','line_number':258,'multiline':False]
['text':' constants and have limitations:','line_number':259,'multiline':False]
['text':' - there is no gradient computation for auxiliary inputs','line_number':260,'multiline':False]
['text':' - auxiliary inputs aren't affected by fused embedding lookup in operations','line_number':261,'multiline':False]
['text':' like sparse_sorted_segment','line_number':262,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':263,'multiline':False]
['text':'*
 * @brief Simple non-segmented reduction over the first few dimensions of the
 * tensor
 *
 * Inputs:
 *   0: DATA - input embedding to do lookups in
 *   1..P: AUX_ARG_<I> - optional additional arguments to be passed to the
 *                       reducer
 *
 * Args:
 *   num_reduce_dim (default 1) - the number of dims in front of the tensor to
 *                                reduce
 *
 * Output:
 *   Tensor without the first `num_dim` dimensions of DATA
 ','line_number':265,'multiline':True]
['text':' If more complicated fixed size logic becomes necessary, it can be moved','line_number':298,'multiline':False]
['text':' to the reducer class','line_number':299,'multiline':False]
['text':' If more complicated fixed size logic becomes necessary, it can be moved','line_number':369,'multiline':False]
['text':' to the reducer class','line_number':370,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':382,'multiline':False]
['text':'no grad','line_number':388,'multiline':True]
['text':' Have utility function generating these names?','line_number':470,'multiline':False]
['text':' FIXME: pass in num_reduce_dims?!','line_number':484,'multiline':False]
['text':' no gradient on auxiliary inputs for now','line_number':492,'multiline':False]
['text':' Have utility function generating these names?','line_number':537,'multiline':False]
['text':' FIXME: pass in num_reduce_dims?!','line_number':551,'multiline':False]
['text':' no gradient on auxiliary inputs for now','line_number':559,'multiline':False]
['text':'*
 * @brief Segment reduction op with optional fused embedding lookup
 *
 * Base implementation for SortedSegmentXXX and SparseSortedSegmentXXX depending
 * on SparseFused static argument.
 *
 * Inputs:
 *   0: DATA - input embedding to do lookups in
 *   1..P: AUX_ARG_<I> - optional additional arguments to be passed to the
 *                       reducer, should have the same first dimension as
 *                       SEGMENT_IDS (e.g. scalars in WeightedSum)
 *   # if SparseFused == true:
 *   P+1: INDICES - 1-D vector with indices to look up in DATA. Should have the
 *                  same dimension as SEGMENT_IDS
 *   # P+1 if SparseFused == false:
 *   P+1 or P+2: SEGMENT_IDS - sorted segment ids 1-D vector
 *
 * Output:
 *   Tensor with first dimension of K, where K is the max segment id + 1. Rest
 *   of dimensions are decided by reducer but usually are the same size as extra
 *   dimensions of DATA
 ','line_number':566,'multiline':True]
['text':' type doesn't matter','line_number':605,'multiline':False]
['text':' If more complicated fixed size logic becomes necessary, it can be moved','line_number':612,'multiline':False]
['text':' to the reducer class','line_number':613,'multiline':False]
['text':' static if','line_number':629,'multiline':False]
['text':' It would probably look nicer with varargs templates but it's too much','line_number':642,'multiline':False]
['text':' metaprogramming','line_number':643,'multiline':False]
['text':' Assume the segments are sorted and there are no gaps','line_number':678,'multiline':False]
['text':' static if','line_number':686,'multiline':False]
['text':' check correctness of the next segment','line_number':702,'multiline':False]
['text':' Gradient actually doesn't depend on whether sparse lookup is fused or not','line_number':724,'multiline':False]
['text':' If more complicated fixed size logic becomes necessary, it can be moved','line_number':732,'multiline':False]
['text':' to the reducer class','line_number':733,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':748,'multiline':False]
['text':'no grad','line_number':758,'multiline':True]
['text':' Assume the segments are sorted and there are no gaps','line_number':778,'multiline':False]
['text':' repeat the check from forward op','line_number':780,'multiline':False]
['text':' check correctness of the next segment','line_number':798,'multiline':False]
['text':' Input layout:','line_number':809,'multiline':False]
['text':'   orig_arg1, orig_arg2, ..., orig_argN, SEGMENT_GRADS, SEGMENT_IDS','line_number':810,'multiline':False]
['text':' orig_argXs represent original op's inputs and will be passed to the reducer','line_number':811,'multiline':False]
['text':' directly','line_number':812,'multiline':False]
['text':' base implementation of sorted/unsorted sparse/non-sparse gradient computation','line_number':821,'multiline':False]
['text':' no gradient on segment_ids or auxiliary inputs for now','line_number':845,'multiline':False]
['text':'Sorted','line_number':896,'multiline':True]
['text':'SparseFused','line_number':897,'multiline':True]
['text':' TODO(dzhulgakov): we're registering the same class twice here,','line_number':947,'multiline':False]
['text':' consider avoiding op duplication here','line_number':948,'multiline':False]
['text':'Sorted','line_number':955,'multiline':True]
['text':'SparseFused','line_number':956,'multiline':True]
['text':'*
 * @brief Unsorted segment reduction op with optional fused embedding lookup
 *
 * Base implementation for UnsortedSegmentXXX and UnsparseSortedSegmentXXX
 * depending on SparseFused static argument.
 *
 * Unlike the sorted version it allows to have "gaps" in segment ids.
 *
 * Inputs:
 *   0: DATA - input embedding to do lookups in
 *   1..P: AUX_ARG_<I> - optional additional arguments to be passed to the
 *                       reducer, should have the same first dimension as
 *                       SEGMENT_IDS (e.g. scalars in WeightedSum)
 *   # if SparseFused == true:
 *   P+1: INDICES - 1-D vector with indices to look up in DATA. Should have the
 *                  same dimension as SEGMENT_IDS
 *   # P+1 if SparseFused == false:
 *   P+1 or P+2: SEGMENT_IDS - unsorted segment ids 1-D vector
 *
 * Args:
 *   num_segments - allows to override the dimension of the output. If not set
 *                  it would be inferred from segment_ids tensor.
 *
 *
 * Output:
 *   Tensor with first dimension of K, where K is the max segment id + 1. Rest
 *   of dimensions are decided by reducer but usually are the same size as extra
 *   dimensions of DATA
 ','line_number':959,'multiline':True]
['text':' type doesn't matter','line_number':1009,'multiline':False]
['text':' If more complicated fixed size logic becomes necessary, it can be moved','line_number':1016,'multiline':False]
['text':' to the reducer class','line_number':1017,'multiline':False]
['text':' static if','line_number':1033,'multiline':False]
['text':' It would probably look nicer with varargs templates but it's too much','line_number':1046,'multiline':False]
['text':' metaprogramming','line_number':1047,'multiline':False]
['text':' determine the number of segments','line_number':1068,'multiline':False]
['text':' static if','line_number':1103,'multiline':False]
['text':' call reducers destructors (if there is any)','line_number':1121,'multiline':False]
['text':' member field to reuse memory','line_number':1135,'multiline':False]
['text':' Gradient actually doesn't depend on whether sparse lookup is fused or not','line_number':1140,'multiline':False]
['text':' If more complicated fixed size logic becomes necessary, it can be moved','line_number':1148,'multiline':False]
['text':' to the reducer class','line_number':1149,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':1164,'multiline':False]
['text':'no grad','line_number':1174,'multiline':True]
['text':' call reducers destructors (if there is any)','line_number':1220,'multiline':False]
['text':' Input layout:','line_number':1225,'multiline':False]
['text':'   orig_arg1, orig_arg2, ..., orig_argN, SEGMENT_GRADS, SEGMENT_IDS','line_number':1226,'multiline':False]
['text':' orig_argXs represent original op's inputs and will be passed to the reducer','line_number':1227,'multiline':False]
['text':' directly','line_number':1228,'multiline':False]
['text':' member field to reuse memory','line_number':1237,'multiline':False]
['text':'Sorted','line_number':1294,'multiline':True]
['text':'SparseFused','line_number':1295,'multiline':True]
['text':' TODO(dzhulgakov): we're registering the same class twice here,','line_number':1346,'multiline':False]
['text':' consider avoiding op duplication here','line_number':1347,'multiline':False]
['text':'Sorted','line_number':1354,'multiline':True]
['text':'SparseFused','line_number':1355,'multiline':True]
['text':'*
 * @brief Segment reduction op with optional fused embedding lookup
 *
 * Base implementation for LengthsXXX and SparseLengthsXXX depending
 * on SparseFused static argument.
 *
 * Inputs:
 *   0: DATA - input embedding to do lookups in
 *   1..P: AUX_ARG_<I> - optional additional arguments to be passed to the
 *                       reducer, should have the same first dimension as
 *                       LENGTHS (e.g. scalars in WeightedSum)
 *   # if SparseFused == true:
 *   P+1: INDICES - 1-D vector with indices to look up in DATA. Should have the
 *                  same dimension as LENGTHS
 *   # P+1 if SparseFused == false:
 *   P+1 or P+2: LENGTHS - lengths on indices vector
 *
 * Output:
 *   Tensor with first dimension of K, where K = len(LENGTHS). Rest
 *   of dimensions are decided by reducer but usually are the same size as extra
 *   dimensions of DATA
 ','line_number':1358,'multiline':True]
['text':' TODO(dzhulgakov): for now it's implemented with incremental reducers because','line_number':1380,'multiline':False]
['text':' of fused sparse support. But using "lengths" representation actually implies','line_number':1381,'multiline':False]
['text':' continuous segments and thus range reducers can be used for non-sparse','line_number':1382,'multiline':False]
['text':' version.','line_number':1383,'multiline':False]
['text':' type doesn't matter','line_number':1402,'multiline':False]
['text':' If more complicated fixed size logic becomes necessary, it can be moved','line_number':1409,'multiline':False]
['text':' to the reducer class','line_number':1410,'multiline':False]
['text':' Either first dim the data or how much we pull in indexies from it','line_number':1423,'multiline':False]
['text':' static if','line_number':1428,'multiline':False]
['text':' static if','line_number':1471,'multiline':False]
['text':'
 * Some notice:
 * 1. Gradient actually doesn't depend on whether sparse lookup is fused or not
 * 2. INDICES are not used in CPU version, but they are needed in async CUDA
 *    version. So we register 3 input version for CPU as gradient op for
 *    GPU/CPU convert. We then register 2 input version for CPU for backward
 *    compatibility with older nets.
 ','line_number':1517,'multiline':True]
['text':' If more complicated fixed size logic becomes necessary, it can be moved','line_number':1537,'multiline':False]
['text':' to the reducer class','line_number':1538,'multiline':False]
['text':'no grad','line_number':1569,'multiline':True]
['text':' Input layout:','line_number':1602,'multiline':False]
['text':'   orig_arg1, orig_arg2, ..., orig_argN, SEGMENT_GRADS, LENGTHS, INDICES','line_number':1603,'multiline':False]
['text':' orig_argXs represent original op's inputs and will be passed to the reducer','line_number':1604,'multiline':False]
['text':' directly','line_number':1605,'multiline':False]
['text':' Version of gradient that requires the main input and thus needs to receive','line_number':1615,'multiline':False]
['text':' length, indices and other stuff','line_number':1616,'multiline':False]
['text':' type doesn't matter','line_number':1635,'multiline':False]
['text':' If more complicated fixed size logic becomes necessary, it can be moved','line_number':1642,'multiline':False]
['text':' to the reducer class','line_number':1643,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':1662,'multiline':False]
['text':' Either first dim the data or how much we pull in indexies from it','line_number':1670,'multiline':False]
['text':' static if','line_number':1673,'multiline':False]
['text':' No range checking, should've been verified in forward pass','line_number':1700,'multiline':False]
['text':' static if','line_number':1701,'multiline':False]
['text':' Input layout:','line_number':1718,'multiline':False]
['text':'   orig_arg1, orig_arg2, ..., orig_argN, SEGMENT_GRADS, LENGTHS,','line_number':1719,'multiline':False]
['text':'      DATA_INPUT, [INDICES]','line_number':1720,'multiline':False]
['text':' orig_argXs represent original op's inputs and will be passed to the reducer','line_number':1721,'multiline':False]
['text':' directly','line_number':1722,'multiline':False]
['text':' Version of gradient that requires the main input as well as the output of the','line_number':1733,'multiline':False]
['text':' forward op.','line_number':1734,'multiline':False]
['text':' If more complicated fixed size logic becomes necessary, it can be moved','line_number':1743,'multiline':False]
['text':' to the reducer class.','line_number':1744,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':1764,'multiline':False]
['text':' No range checking, should've been verified in forward pass','line_number':1797,'multiline':False]
['text':' Input layout:','line_number':1811,'multiline':False]
['text':'   orig_arg1, orig_arg2, ..., orig_argN, FORWARD_OUTPUT, SEGMENT_GRADS,','line_number':1812,'multiline':False]
['text':'      LENGTHS, DATA_INPUT','line_number':1813,'multiline':False]
['text':' orig_argXs represent original op's inputs and will be passed to the reducer','line_number':1814,'multiline':False]
['text':' directly','line_number':1815,'multiline':False]
['text':' base implementation of sparse/non-sparse gradient computation','line_number':1826,'multiline':False]
['text':' Hacky: using Input as Indices, remove this after we have specialized','line_number':1864,'multiline':False]
['text':' cuda LengthsIndicesInGradientSumGradient','line_number':1865,'multiline':False]
['text':'SparseFused','line_number':1963,'multiline':True]
['text':' TODO(dzhulgakov): we're registering the same class twice here,','line_number':2035,'multiline':False]
['text':' consider avoiding op duplication here','line_number':2036,'multiline':False]
['text':' Note: registering 2 input version for now because of naming in the macro,','line_number':2037,'multiline':False]
['text':' will register 3 input version alone','line_number':2038,'multiline':False]
['text':' INDICES are not used in CPU version, but they are needed in async CUDA
   *    version. So we register 3 input version for CPU as gradient op for
   *    GPU/CPU convert. We then register 2 input version for CPU for backward
   *    compatibility with older nets.
   ','line_number':2039,'multiline':True]
['text':'GradientNeedIndices','line_number':2049,'multiline':True]
['text':' Will return 3 input version. This is aligning new CPU/GPU nets.','line_number':2056,'multiline':False]
['text':'SparseFused','line_number':2061,'multiline':True]
['text':' namespace caffe2','line_number':2064,'multiline':False]
['text':' CAFFE2_OPERATORS_SEGMENT_REDUCTION_OP_H_','line_number':2066,'multiline':False]
