['text':'*
 * Copyright (c) 2016-present, Facebook, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 ','line_number':1,'multiline':True]
['text':' #define DNNLOWP_MEASURE_TIME_BREAKDOWN','line_number':23,'multiline':False]
['text':' These should all be false if we're not broadcasting.','line_number':68,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':97,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':99,'multiline':False]
['text':' How far to increment A pointer each itr','line_number':101,'multiline':False]
['text':' How far to increment B pointer each itr','line_number':102,'multiline':False]
['text':' How far to increment Y pointer each itr','line_number':103,'multiline':False]
['text':' vector-vector','line_number':105,'multiline':False]
['text':' matrix-matrix with batches','line_number':129,'multiline':False]
['text':' [B1..., M, K] * [B2..., K, N] -> [B..., M, N]','line_number':130,'multiline':False]
['text':' In the event that A or B are one-dimensional, the trailing or leading','line_number':131,'multiline':False]
['text':' 1 is not added to the output tensor's size.','line_number':132,'multiline':False]
['text':' First step: partition the tensors into inner and outer blocks.','line_number':134,'multiline':False]
['text':' Ignoring the last two dimensions of A and B, ensure that one of the','line_number':135,'multiline':False]
['text':' tensors' dimensions is a suffix of the other. For example,','line_number':136,'multiline':False]
['text':' [4, x, x] is a suffix of [2, 3, 4, x, x]. In this example, the','line_number':137,'multiline':False]
['text':' dimensions of size 2 and 3 will be broadcasted, so we partition into','line_number':138,'multiline':False]
['text':' 2*3=6 individual instances of batched GEMM with A and B \in [4, x, x].','line_number':139,'multiline':False]
['text':' Standard M, N, and K parameters respecting GEMM API and transpose','line_number':157,'multiline':False]
['text':' flags','line_number':158,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':159,'multiline':False]
['text':' Calculate output tensor shapes [B..., (M), (N)]','line_number':186,'multiline':False]
['text':' Batch dimensions will be broadcasted out to those of the longer tensor','line_number':187,'multiline':False]
['text':' A or B. Either M or N are optional if A or B, respectively are 1-D.','line_number':188,'multiline':False]
['text':' Calculate strides. Continuing our example above,','line_number':206,'multiline':False]
['text':'   [4, M, K] * [2, 3, 4, K, N] = [2, 3, 4, M, N]','line_number':207,'multiline':False]
['text':' We calculate this as follows:','line_number':208,'multiline':False]
['text':'   1) Treat the outer batch dimensions as flattened, i.e. view the B','line_number':209,'multiline':False]
['text':'      tensor here as [6, 4, K, N] and Y as [6, 4, M, N]. The same rea-','line_number':210,'multiline':False]
['text':'      soning is analogous for the case where # dims A >= # dims B.','line_number':211,'multiline':False]
['text':'   2) Perform this operation:','line_number':212,'multiline':False]
['text':'        for i in range(6):','line_number':213,'multiline':False]
['text':'          Y[i, :, :, :] = BatchMatMul(A, B[i, :, :, :])','line_number':214,'multiline':False]
['text':' How far to increment A pointer each itr','line_number':215,'multiline':False]
['text':' How far to increment B pointer each itr','line_number':216,'multiline':False]
['text':' How far to increment Y pointer each itr','line_number':217,'multiline':False]
['text':' How many "inner batches" we have. That is, the product of sizes for','line_number':218,'multiline':False]
['text':' the slices excluding M, K, and N, for their respective matrices.','line_number':219,'multiline':False]
['text':' Mutually exclusive since otherwise we would've taken the vector-vector','line_number':250,'multiline':False]
['text':' path above','line_number':251,'multiline':False]
['text':' Allocate output tensor','line_number':258,'multiline':False]
['text':' Optimize case num_sub_batches == 1 where we can combine batched gemms','line_number':261,'multiline':False]
['text':' into a single gemm','line_number':262,'multiline':False]
['text':' Zero batch dimension indicates no elements','line_number':271,'multiline':False]
['text':' Choose quantization for X','line_number':281,'multiline':False]
['text':' Quantize B','line_number':295,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-use-emplace)','line_number':302,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':311,'multiline':False]
['text':' weight ','line_number':319,'multiline':True]
['text':' B_qparams_[i] is computed for unsigned type.','line_number':321,'multiline':False]
['text':' Adjust for the fact that B will actually use signed.','line_number':322,'multiline':False]
['text':'pmat','line_number':339,'multiline':True]
['text':'groups','line_number':340,'multiline':True]
['text':' Pre-compute column_offset','line_number':342,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':343,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':347,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':352,'multiline':False]
['text':' for each input in the batch','line_number':359,'multiline':False]
['text':' Bq_packed_.empty()','line_number':360,'multiline':False]
['text':' to measure quantization error, run ref impl.','line_number':374,'multiline':False]
['text':' slow path','line_number':380,'multiline':False]
['text':' fast path','line_number':413,'multiline':False]
['text':' Only when input and output are float, we don't need input to be','line_number':418,'multiline':False]
['text':' quantized.','line_number':419,'multiline':False]
['text':' buffer for packed matrix','line_number':459,'multiline':False]
['text':' group','line_number':460,'multiline':False]
['text':' FUSE_RELU ','line_number':465,'multiline':True]
['text':' bias','line_number':473,'multiline':False]
['text':' ncols per quant group','line_number':474,'multiline':False]
['text':' thread_id','line_number':483,'multiline':False]
['text':' num_threads','line_number':484,'multiline':False]
['text':' for each input in batch','line_number':485,'multiline':False]
['text':' dequantize_output','line_number':490,'multiline':False]
['text':' Both input and output are float','line_number':494,'multiline':False]
['text':' buffer for packed matrix','line_number':521,'multiline':False]
['text':' groups','line_number':524,'multiline':False]
['text':' FUSE_RELU','line_number':529,'multiline':True]
['text':' bias','line_number':537,'multiline':False]
['text':' ncols per quant group','line_number':538,'multiline':False]
['text':' thread_id','line_number':547,'multiline':False]
['text':' num_threads','line_number':548,'multiline':False]
['text':' for each input in batch','line_number':549,'multiline':False]
['text':' Input quantized and output float','line_number':552,'multiline':False]
['text':' buffer for packed matrix','line_number':581,'multiline':False]
['text':' group','line_number':582,'multiline':False]
['text':' FUSE_RELU','line_number':587,'multiline':True]
['text':' bias','line_number':595,'multiline':False]
['text':' ncols per quant group','line_number':596,'multiline':False]
['text':' thread_id','line_number':605,'multiline':False]
['text':' num_threads','line_number':606,'multiline':False]
['text':' for each input in batch','line_number':607,'multiline':False]
['text':' dequantize_output','line_number':610,'multiline':False]
['text':' slow path','line_number':623,'multiline':False]
['text':' Quantize inputs','line_number':624,'multiline':False]
['text':' Y_q = (scale_A * scale_B) / scale_Y * Y_int32','line_number':641,'multiline':False]
['text':' Y_int32 = (A_q - zero_point_A * 1_A) * (B_q - zero_point_B * 1_B),','line_number':642,'multiline':False]
['text':'           where 1_A is a matrix with all 1s and same size as A','line_number':643,'multiline':False]
['text':' Y_int32 = A_q * B_q','line_number':644,'multiline':False]
['text':'           - zero_point_A * 1_A * B - zero_point_B * A * 1_B','line_number':645,'multiline':False]
['text':'           + zero_point_A * zero_point_B * 1_A * 1_B','line_number':646,'multiline':False]
['text':' zero_point_A * 1_A * B : a matrix with (i, j) is the sum of jth','line_number':647,'multiline':False]
['text':'                          column of B. This is computed by','line_number':648,'multiline':False]
['text':'                          column_offsets in the code.','line_number':649,'multiline':False]
['text':' zero_point_B * A * 1_B : a matrix with (i, j) is the sum of ith row','line_number':650,'multiline':False]
['text':'                          of A. This is computed by row_offset in the','line_number':651,'multiline':False]
['text':'                          code.','line_number':652,'multiline':False]
['text':' zero_point_A * zero_point_B * 1_A * 1_B : a matrix with all elements','line_number':653,'multiline':False]
['text':'                          are zero_point_A * zero_point_B *','line_number':654,'multiline':False]
['text':'                          num_of_cols_of_A. This is computed by','line_number':655,'multiline':False]
['text':'                          const_offset in the code.','line_number':656,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':663,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':667,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':672,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':680,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':684,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':689,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':696,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':700,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':706,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':712,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':718,'multiline':False]
['text':' for each output col','line_number':727,'multiline':False]
['text':' for each output row','line_number':728,'multiline':False]
['text':' Requantization','line_number':730,'multiline':False]
['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':731,'multiline':False]
['text':' for each batch','line_number':737,'multiline':False]
['text':' namespace caffe2','line_number':760,'multiline':False]
