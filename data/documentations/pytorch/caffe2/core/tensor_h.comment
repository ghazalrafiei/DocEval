['text':'*
 * @brief Tensor class holds a shared pointer to the implementation TensorImpl,
 * redirects API calls to TensorImpl;
 * Copying of Tensor results in sharing the same underlying implementation
 * object
 *
 * NB: See TensorImpl for documentation on these methods.
 ','line_number':29,'multiline':True]
['text':'*
   * @brief Creates a tensor of the given device type.
   *
   * Note that the actual data allocation is not going to be carried out until
   * you resize the tensor and then call mutable_data().
   ','line_number':76,'multiline':True]
['text':'*
   * @brief Creates a tensor of the given dimension.
   *
   * Note that the actual data allocation is not going to be carried out until
   * the first time mutable_data() is called.
   ','line_number':88,'multiline':True]
['text':' TODO: here, we create a Storage','line_number':95,'multiline':False]
['text':' and immediately discard it in Resize() since','line_number':96,'multiline':False]
['text':' reset_tensor will be true and FreeMemory will be called,','line_number':97,'multiline':False]
['text':' we might want to avoid creating Storage twice?','line_number':98,'multiline':False]
['text':' we want to preserve index information','line_number':102,'multiline':False]
['text':' TODO: remove?','line_number':107,'multiline':False]
['text':'*
   * @brief: Create a Tensor of at::DeviceType `type` and initialize it with
   * src Tensor
   ','line_number':112,'multiline':True]
['text':'*
   * @brief Mutual conversion with at::Tensor
   *
   * The tensor will share the same instance (data, strides, sizes, etc) but
   * a different subset of APIs would be available
   ','line_number':120,'multiline':True]
['text':'*
   * Clone self as a Tensor that share the same Storage,
   * that is, both Tensors are views on the same Storage.
   * If we change the sizes or strides of one Tensor, it
   * does not affect the other Tensor that it shares Storage
   * with.
   * A similar yet different usage is `Tensor x = y;`, this
   * will make x and y pointing to the same Tensor and resizing
   * one of them will resize the other as well.
   *
   * TODO: Deduplicate this with THTensor_(newWithTensor)
   * (exposed in ATen as at::alias but not otherwise available)
   ','line_number':145,'multiline':True]
['text':' set_storage already sets data_type_ of TensorImpl','line_number':167,'multiline':False]
['text':'*
   * @brief Copies the data from a source tensor, with a context provided to
   * carry out the underlying memcpy operation.  This method respects
   * caffe2_keep_on_shrink.
   *
   * After CopyFrom, this function guarantees that the destination tensor will
   * have the same initialization state and dtype as src.  This function
   * preserves the DeviceType of the source tensor (so, e.g., if you allocate
   * a tensor on CPU and then CopyFrom a CUDA tensor, that will to a
   * CUDA-to-CPU transfer).
   *
   * 'async' parameter triggers async copy for CUDA tensors
   ','line_number':182,'multiline':True]
['text':'*
   * @brief Extend the outer-most dimension of this tensor
   *        to dimension of `num`.
   ','line_number':197,'multiline':True]
['text':'*
   * @brief Shrinks the outer-most dimension to given size, keeping the data.
   *
   * This method guarantees that no re-allocations are carried out, which means
   * that the extra capacity after the end of the shrunk tensor is maintained.
   * Notably, this function does NOT respect caffe2_keep_on_shrink.
   ','line_number':211,'multiline':True]
['text':'*
   * Resize the tensor like the source tensor. Note that this is just a
   * sugar wrapper that essentially calls Resize(src_tensor.dims()).
   * This method respects caffe2_keep_on_shrink.
   ','line_number':247,'multiline':True]
['text':'*
   * A utility function to print the debug string for the tensor. Note that this
   * is very slow since it involves quite some string operations, so do not use
   * it in your performance-critical code.
   ','line_number':273,'multiline':True]
['text':' To be deprecated','line_number':289,'multiline':False]
['text':'*
   * @brief Shares the data with an externally managed pointer.
   *
   * This is similar to ShareData() but the source is a pointer with an advanced
   * deleter option. In default, no deletion takes place, and one needs to make
   * sure that the external memory is deallocated only after the tensor finishes
   * using it. If a Deleter object is passed in, when this tensor is reallocated
   * or freed, the deleter function is going to be called.
   ','line_number':294,'multiline':True]
['text':'*
   * Returns a raw void* pointer of the underlying storage. mutable_data()
   * or raw_mutable_data() must have been called prior to this function call.
   ','line_number':349,'multiline':True]
['text':'*
   * Returns a mutable raw pointer of the underlying storage. This can only be
   * used when you know for sure that the underlying storage of the tensor is
   * already created via an earlier raw_mutable_data(meta) call or a
   * mutable_data<T>() call.
   *
   * If the existing data does not match the desired type, it will be deleted
   * and a new storage will be created.
   ','line_number':366,'multiline':True]
['text':'*
   * Returns the number of dimensions of the data.
   ','line_number':389,'multiline':True]
['text':'*
   * (To be deprecated) Returns the number of dimensions of the data.
   ','line_number':396,'multiline':True]
['text':'*
   * (To be deprecated) Returns the size (i.e. the number of items) of the
   * tensor.
   ','line_number':403,'multiline':True]
['text':'*
   * Returns the number of items of the tensor.
   ','line_number':411,'multiline':True]
['text':'*
   * Return the number of bytes each item takes in the tensor.
   ','line_number':418,'multiline':True]
['text':'*
   * Returns the total number of bytes of the storage.
   *
   * This is equivalent to calling size() * itemsize().
   ','line_number':425,'multiline':True]
['text':'*
   * Returns the 'canonical' version of a (usually)  user-specified axis,
   * allowing for negative indexing (e.g., -1 for the last axis).
   *
   * @param axis_index the axis index.
   *        If 0 <= index < dim(), return index.
   *        If -ndim <= index <= -1, return (dim() - (-index)),
   *        e.g., the last axis index (dim() - 1) if index == -1,
   *        the second to last if index == -2, etc.
   *        Dies on out of range index.
   ','line_number':462,'multiline':True]
['text':'*
   * Checks if the tensor content is of the given data type.
   ','line_number':490,'multiline':True]
['text':'*
   * Returns the TypeMeta object associated with the current data type.
   ','line_number':498,'multiline':True]
['text':'*
   * (To be deprecated) Returns the TypeMeta object associated with the current
   * data type.
   ','line_number':505,'multiline':True]
['text':'*
   * Returns the i-th dimension of the tensor in int.
   *
   * This function returns an int value instead of int64_t, which depending on
   * the typedef could be int64. If you want int64 dim values, make sure you
   * call dim() instead.
   ','line_number':513,'multiline':True]
['text':' Avoid TensorImpl::size() because it is a virtual call that','line_number':526,'multiline':False]
['text':' supports out-of-range indexing like Python.','line_number':527,'multiline':False]
['text':' To be deprecated','line_number':537,'multiline':False]
['text':'*
 * Reinitialize a Tensor to given dims and options if necessary, note that
 * this will not do anything if the
 * Tensor already has correct size and data type
 ','line_number':559,'multiline':True]
['text':' TODO: the following logic can be merged into regular Tensor class methods','line_number':577,'multiline':False]
['text':' after MKLMemory starts to implement Tensor interface','line_number':578,'multiline':False]
['text':' Type call registry','line_number':580,'multiline':False]
['text':' Shape call registry','line_number':585,'multiline':False]
['text':' resize helper function','line_number':591,'multiline':False]
['text':' Tensor factory function','line_number':597,'multiline':False]
['text':'*
 * @brief Creates a CPU tensor, and fills its contents with the given values.
 * Values are copied in
 ','line_number':600,'multiline':True]
['text':' TODO: can be unified with at::from_blob when Tensor is merged and string','line_number':604,'multiline':False]
['text':' types are supported','line_number':605,'multiline':False]
['text':' One most likely doesn't want to print int64-number of items for visual','line_number':644,'multiline':False]
['text':' inspection, so we cast down to int here.','line_number':645,'multiline':False]
['text':' We do not add a comma after the last item.','line_number':653,'multiline':False]
['text':' Log to console.','line_number':660,'multiline':False]
['text':' namespace caffe2','line_number':666,'multiline':False]
['text':' namespace c10','line_number':673,'multiline':False]
['text':' CAFFE2_CORE_TENSOR_H_','line_number':674,'multiline':False]
