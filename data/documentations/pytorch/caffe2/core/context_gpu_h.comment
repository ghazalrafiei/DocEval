['text':' Since we are using the macro CAFFE2_USE_CUDNN, we will need to include this','line_number':17,'multiline':False]
['text':' file after common.h is included.','line_number':18,'multiline':False]
['text':' CAFFE2_USE_CUDNN','line_number':21,'multiline':False]
['text':'*
 * Gets the current memory pool type used by Caffe2.
 *
 * The memory pool is set up during caffe2's global initialization time.
 ','line_number':36,'multiline':True]
['text':'*
 * A struct to host thread-local cuda objects.
 *
 * In Caffe2, each thread has its own non-default cuda stream as well as
 * related objects such as cublas and curand handles. This is achieved by
 * having the ThreadLocalCUDAObjects wrapper that takes care of allocating
 * and deallocating these objects at the thread scope. This class is solely
 * used inside CUDAContext and should not be used externally.
 *
 * This class manages the mapping from logical stream ID (int stream_id
 * passed around in Caffe2) and CUDAStream objects.  We intend to eventually
 * deprecate the logical stream ID interface, but not for now.
 ','line_number':43,'multiline':True]
['text':' Record current stream id for the current thread.','line_number':66,'multiline':False]
['text':' This is the new API we're trying to migrate use cases to and get rid of','line_number':67,'multiline':False]
['text':' explicit stream id passing. For now it's invoked in','line_number':68,'multiline':False]
['text':' CUDAContext::SwitchToDevice','line_number':69,'multiline':False]
['text':' TODO: use current device id from thread local instead of passing gpu in','line_number':71,'multiline':False]
['text':' Retrieves the CUDAStream corresponding to a logical stream ID, ensuring','line_number':77,'multiline':False]
['text':' that it exists in cuda_streams_ if it has not been allocated yet.','line_number':78,'multiline':False]
['text':' NB: This streams are not guaranteed to be unique; we'll','line_number':82,'multiline':False]
['text':' wrap around once we run out of streams in the pool.','line_number':83,'multiline':False]
['text':' high priority ','line_number':84,'multiline':True]
['text':' Uses the logical stream id from the thread local to pick the stream','line_number':89,'multiline':False]
['text':' We're going to migrate all usages to this case API instead of passing the','line_number':90,'multiline':False]
['text':' stream id directly','line_number':91,'multiline':False]
['text':' Uses the logical stream id from the thread local to pick the stream','line_number':100,'multiline':False]
['text':' We're going to migrate all usages to this case API instead of passing the','line_number':101,'multiline':False]
['text':' stream id directly','line_number':102,'multiline':False]
['text':' Default construct in the map if it doesn't exist, and return a mutable','line_number':109,'multiline':False]
['text':' reference to it.','line_number':110,'multiline':False]
['text':' The default is CUBLAS_POINTER_MODE_HOST. You can override','line_number':114,'multiline':False]
['text':' it after obtaining the cublas handle, but do that with','line_number':115,'multiline':False]
['text':' caution.','line_number':116,'multiline':False]
['text':' Uses the logical stream id from the thread local to pick the stream','line_number':124,'multiline':False]
['text':' We're going to migrate all usages to this case API instead of passing the','line_number':125,'multiline':False]
['text':' stream id directly','line_number':126,'multiline':False]
['text':' CAFFE2_USE_CUDNN','line_number':140,'multiline':False]
['text':' this is because of something dumb in the ordering of','line_number':152,'multiline':False]
['text':' destruction. Sometimes at exit, the cuda context would already','line_number':153,'multiline':False]
['text':' be destroyed by the time this gets destroyed. This happens on','line_number':154,'multiline':False]
['text':' windows with cuda 11 and cuda 12.','line_number':155,'multiline':False]
['text':' _WIN32','line_number':159,'multiline':False]
['text':' CAFFE2_USE_CUDNN','line_number':162,'multiline':False]
['text':' WARNING: mapping from logical stream ID to c10::cuda::CUDAStream','line_number':164,'multiline':False]
['text':' is NOT bijective; multiple logical stream IDs may map to the','line_number':165,'multiline':False]
['text':' same underlying stream ID.','line_number':166,'multiline':False]
['text':' CAFFE2_USE_CUDNN','line_number':171,'multiline':False]
['text':' The default cuda context constructor.','line_number':176,'multiline':False]
['text':' void SwitchToDevice()','line_number':189,'multiline':False]
['text':' Note on current use cases:','line_number':201,'multiline':False]
['text':' FinishDeviceComputation must be called on the same cpu thread as','line_number':202,'multiline':False]
['text':' SwitchToDevice()','line_number':203,'multiline':False]
['text':' CAFFE2_USE_CUDNN','line_number':232,'multiline':False]
['text':' Get a mutex to lock out cudaMalloc / cudaFree calls when','line_number':251,'multiline':False]
['text':' NCCL kernels are being launched. Should remove threat of','line_number':252,'multiline':False]
['text':' deadlocks','line_number':253,'multiline':False]
['text':' Functions to query memory stats. Only available if flag','line_number':256,'multiline':False]
['text':' --caffe2_gpu_memory_tracking is enabled.','line_number':257,'multiline':False]
['text':' By default CUDA operators have async device parts','line_number':310,'multiline':False]
['text':' ignore and clear the error if not ready','line_number':323,'multiline':False]
['text':' Reraise error','line_number':326,'multiline':False]
['text':' namespace caffe2','line_number':352,'multiline':False]
['text':' CAFFE2_CORE_CONTEXT_GPU_H_','line_number':354,'multiline':False]
