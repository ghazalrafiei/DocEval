['text':' shim for torch.cuda.Event when running on cpu','line_number':57,'multiline':False]
['text':' CUDA events for timing','line_number':84,'multiline':False]
['text':' XXX: Use if need to print something','line_number':102,'multiline':False]
['text':' print(modeldef.forward.graph_for(*modeldef.inputs))','line_number':103,'multiline':False]
['text':' Output for OSS','line_number':170,'multiline':False]
['text':' print the AI-PEP format json string for each model','line_number':177,'multiline':False]
['text':' Output for AI-PEP','line_number':180,'multiline':False]
['text':' Replace the value of info_fwd and info_bwd to None','line_number':204,'multiline':False]
['text':' groups help control which test group you want to run','line_number':235,'multiline':False]
['text':' if you only want to run one/two benchmark, run it with','line_number':236,'multiline':False]
['text':' e.g: python -m fastrnns.bench --rnns jit and --group rnns','line_number':237,'multiline':False]
['text':' TODO: Maybe add a separate section for the layernorm/dropout lstms','line_number':320,'multiline':False]
['text':' 'cudnn_layernorm', jit_layernorm', 'jit_layernom_decom',','line_number':321,'multiline':False]
['text':' 'jit', 'jit_dropout', 'cudnn_dropout'','line_number':322,'multiline':False]
['text':' noqa: E731,F811','line_number':326,'multiline':False]
