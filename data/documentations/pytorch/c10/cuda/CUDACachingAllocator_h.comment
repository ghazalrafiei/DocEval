['text':' Caching allocator will execute every registered callback if it unable to find','line_number':18,'multiline':False]
['text':' block inside of already allocated area.','line_number':19,'multiline':False]
['text':' TODO: Turn this into an honest to goodness class. I briefly attempted to do','line_number':32,'multiline':False]
['text':' this, but it was a bit irritating to figure out how to also correctly','line_number':33,'multiline':False]
['text':' apply pimpl pattern so I didn't have to leak any internal implementation','line_number':34,'multiline':False]
['text':' details in the header (CUDACachingAllocator could be made a pimpl, but','line_number':35,'multiline':False]
['text':' you also need to appropriately define a class which is a subclass','line_number':36,'multiline':False]
['text':' of Allocator. Not impossible, but required a bit more surgery than','line_number':37,'multiline':False]
['text':' I wanted to do at the time.)','line_number':38,'multiline':False]
['text':'','line_number':39,'multiline':False]
['text':' Why is this using a namespace rather than old-style THCCachingAllocator_','line_number':40,'multiline':False]
['text':' prefix?  Mostly because it made the HIPify rules easier to write; _ is','line_number':41,'multiline':False]
['text':' not counted as a word boundary, so you would otherwise have to list each','line_number':42,'multiline':False]
['text':' of these functions.','line_number':43,'multiline':False]
['text':' remember to update this whenever a new stat type is added','line_number':60,'multiline':False]
['text':' Struct containing memory allocator summary statistics for a device.','line_number':65,'multiline':False]
['text':' COUNT: allocations requested by client code','line_number':67,'multiline':False]
['text':' COUNT: number of allocated segments from cudaMalloc().','line_number':69,'multiline':False]
['text':' COUNT: number of active memory blocks (allocated or used by stream)','line_number':71,'multiline':False]
['text':' COUNT: number of inactive, split memory blocks (unallocated but can't be','line_number':73,'multiline':False]
['text':' released via cudaFree)','line_number':74,'multiline':False]
['text':' SUM: bytes allocated by this memory alocator','line_number':77,'multiline':False]
['text':' SUM: bytes reserved by this memory allocator (both free and used)','line_number':79,'multiline':False]
['text':' SUM: bytes within active memory blocks','line_number':81,'multiline':False]
['text':' SUM: bytes within inactive, split memory blocks','line_number':83,'multiline':False]
['text':' SUM: bytes requested by client code','line_number':85,'multiline':False]
['text':' COUNT: total number of failed calls to CUDA malloc necessitating cache','line_number':88,'multiline':False]
['text':' flushes.','line_number':89,'multiline':False]
['text':' COUNT: total number of OOMs (i.e. failed calls to CUDA after cache flush)','line_number':92,'multiline':False]
['text':' COUNT: total number of oversize blocks allocated from pool','line_number':95,'multiline':False]
['text':' COUNT: total number of oversize blocks requiring malloc','line_number':98,'multiline':False]
['text':' SIZE: maximum block size that is allowed to be split.','line_number':101,'multiline':False]
['text':' Struct containing info of an allocation block (i.e. a fractional part of a','line_number':107,'multiline':False]
['text':' cudaMalloc)..','line_number':108,'multiline':False]
['text':' per-watcher context','line_number':116,'multiline':False]
['text':' Struct containing info of a memory segment (i.e. one contiguous cudaMalloc).','line_number':119,'multiline':False]
['text':' unrounded, actually requested size','line_number':124,'multiline':False]
['text':' API made to the caching allocator for new memory','line_number':146,'multiline':False]
['text':' API call made to the caching allocator to free memory','line_number':147,'multiline':False]
['text':' The allocator might have to delay a free because','line_number':148,'multiline':False]
['text':' it is still in use on another stream via record_stream','line_number':149,'multiline':False]
['text':' This event is generated when a free actually completes.','line_number':150,'multiline':False]
['text':' a call to cudaMalloc to get more memory from the OS','line_number':151,'multiline':False]
['text':' a call to cudaFree to return memory to the OS (e.g. to','line_number':152,'multiline':False]
['text':' defragment or empty_caches)','line_number':153,'multiline':False]
['text':' a call to cuMemMap (used with expandable_segments)','line_number':154,'multiline':False]
['text':' unmap part of a segment (used with expandable segments)','line_number':155,'multiline':False]
['text':' a call to snapshot, used to correlate memory snapshots to trace','line_number':156,'multiline':False]
['text':' events','line_number':157,'multiline':False]
['text':' the allocator threw an OutOfMemoryError (addr_ is the amount of free','line_number':158,'multiline':False]
['text':' bytes reported by cuda)','line_number':159,'multiline':False]
['text':' for OOM, this is the amount of free bytes reported by cuda','line_number':179,'multiline':False]
['text':' returns the pointers freed in the pool','line_number':191,'multiline':False]
['text':' and the pointers allocated. Note: a pointer','line_number':192,'multiline':False]
['text':' may appear in both freed and allocated','line_number':193,'multiline':False]
['text':' only keep stacks for active allocations','line_number':201,'multiline':False]
['text':' additionally keep stacks for allocations in the trace history','line_number':202,'multiline':False]
['text':' additionally record stacks for when something is freed','line_number':203,'multiline':False]
['text':' Size pretty-printer','line_number':206,'multiline':False]
['text':' returns true if the allocated blocks are equal to expected live allocations','line_number':239,'multiline':False]
['text':' Attached AllocatorTraceTracker callbacks will be called while the','line_number':265,'multiline':False]
['text':' per-device allocator lock is held. Any additional locks taken from within','line_number':266,'multiline':False]
['text':' the callback must be proven to always have the lock order that never','line_number':267,'multiline':False]
['text':' triggers a deadlock. In particular, Python's GIL may be held when','line_number':268,'multiline':False]
['text':' calling the allocator so it is unsafe to try to acquire the GIL in this','line_number':269,'multiline':False]
['text':' callback.','line_number':270,'multiline':False]
['text':' memory not allocated from cudaMalloc cannot be copied','line_number':275,'multiline':False]
['text':' across devices using cudaMemcpyAsync if peer to peer access is disabled.','line_number':276,'multiline':False]
['text':' instead it requires cudaMemcpyAsyncPeer','line_number':277,'multiline':False]
['text':'  with P2P Enabled, all combinations work','line_number':278,'multiline':False]
['text':'  with P2P Disabled:','line_number':279,'multiline':False]
['text':'                       cudaMalloc cudaMallocAsync/cuMemMap','line_number':280,'multiline':False]
['text':' cudaMemcpyAsyncPeer   works      works','line_number':281,'multiline':False]
['text':' cudaMemcpyAsync       works      error','line_number':282,'multiline':False]
['text':' This function performs chooses to use the Peer version of','line_number':284,'multiline':False]
['text':' memcpy if required based on where the allocated put dst/src.','line_number':285,'multiline':False]
['text':' Allocator object, statically initialized','line_number':303,'multiline':False]
['text':' See BackendInitializer in CUDACachingAllocator.cpp.','line_number':304,'multiline':False]
['text':' Atomic loads on x86 are just normal loads,','line_number':305,'multiline':False]
['text':' (atomic stores are different), so reading this value','line_number':306,'multiline':False]
['text':' is no different than loading a pointer.','line_number':307,'multiline':False]
['text':' Called directly by clients.','line_number':314,'multiline':False]
['text':' CUDAGraph interactions','line_number':379,'multiline':False]
['text':' Not part of CUDA_ALLOCATOR_BACKEND_INTERFACE','line_number':423,'multiline':False]
['text':' namespace CUDACachingAllocator','line_number':448,'multiline':False]
['text':' namespace cuda','line_number':449,'multiline':False]
['text':' namespace c10','line_number':450,'multiline':False]
