['text':' A PyHandleCache represents a cached pointer from a C++ object to','line_number':11,'multiline':False]
['text':' a Python object that represents that object analogously in Python.','line_number':12,'multiline':False]
['text':' Upon a cache hit, the relevant object can be retrieved after a test','line_number':13,'multiline':False]
['text':' and then a memory load.  Two conditions must hold to be able to use this','line_number':14,'multiline':False]
['text':' class:','line_number':15,'multiline':False]
['text':'','line_number':16,'multiline':False]
['text':'  - This must truly be a cache; e.g., the caller must be able to produce','line_number':17,'multiline':False]
['text':'    the object some other way if the cache hit misses.','line_number':18,'multiline':False]
['text':'','line_number':19,'multiline':False]
['text':'  - This must truly be a handle; e.g., the Python object referenced by','line_number':20,'multiline':False]
['text':'    this class must have static lifetime.  This means we don't have to','line_number':21,'multiline':False]
['text':'    maintain strong ownership or deallocate the object when the C++ object','line_number':22,'multiline':False]
['text':'    dies.  Static lifetime is a good idea in conjunction with the cache,','line_number':23,'multiline':False]
['text':'    since if you are producing a fresh object on miss you won't be','line_number':24,'multiline':False]
['text':'    maintaining object identity.  If you need bidirectional ownership,','line_number':25,'multiline':False]
['text':'    you will want to factor out the pattern in TensorImpl with','line_number':26,'multiline':False]
['text':'    resurrection.','line_number':27,'multiline':False]
['text':'','line_number':28,'multiline':False]
['text':' This cache is expected to not improve perf under torchdeploy, as one','line_number':29,'multiline':False]
['text':' interpreter will fill up the cache, and all the interpreters will be','line_number':30,'multiline':False]
['text':' unable to use the slot.  A potential improvement is to have multiple','line_number':31,'multiline':False]
['text':' slots (one per interpreter), which will work in deployment scenarios','line_number':32,'multiline':False]
['text':' where there a stable, fixed number of interpreters.  You can also store','line_number':33,'multiline':False]
['text':' the relevant state in the Python library, rather than in the non-Python','line_number':34,'multiline':False]
['text':' library (although in many cases, this is not convenient, as there may','line_number':35,'multiline':False]
['text':' not be a way to conveniently index based on the object.)','line_number':36,'multiline':False]
['text':' Attempt to fetch the pointer from the cache, if the PyInterpreter','line_number':41,'multiline':False]
['text':' matches.  If it doesn't exist, or the cache entry is not valid,','line_number':42,'multiline':False]
['text':' use slow_accessor to get the real pointer value and return that','line_number':43,'multiline':False]
['text':' (possibly writing it to the cache, if the cache entry is','line_number':44,'multiline':False]
['text':' available.)','line_number':45,'multiline':False]
['text':' Note [Memory ordering on Python interpreter tag]','line_number':49,'multiline':False]
['text':' attempt to claim this cache entry with the specified interpreter tag','line_number':57,'multiline':False]
['text':' This shouldn't be possible, as you should be GIL protected','line_number':62,'multiline':False]
['text':' namespace c10','line_number':75,'multiline':False]
