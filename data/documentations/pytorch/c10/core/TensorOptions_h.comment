['text':'/ A class to encapsulate construction axes of an Tensor.  TensorOptions was','line_number':45,'multiline':False]
['text':'/ designed to support the Python style API for specifying construction options','line_number':46,'multiline':False]
['text':'/ on factory functions, e.g.,','line_number':47,'multiline':False]
['text':'/','line_number':48,'multiline':False]
['text':'/     torch.zeros(2, 3, dtype=torch.int32)','line_number':49,'multiline':False]
['text':'/','line_number':50,'multiline':False]
['text':'/ Because C++ doesn't natively support keyword arguments, there must be','line_number':51,'multiline':False]
['text':'/ another way of specifying keyword-like arguments.  TensorOptions is a','line_number':52,'multiline':False]
['text':'/ builder class which can be used to construct this "dictionary" of keyword','line_number':53,'multiline':False]
['text':'/ arguments: functions which support TensorOptions conventionally take this','line_number':54,'multiline':False]
['text':'/ argument optionally as their last argument.','line_number':55,'multiline':False]
['text':'/','line_number':56,'multiline':False]
['text':'/ WARNING: In PyTorch, there are `torch::` variants of factory functions,','line_number':57,'multiline':False]
['text':'/ e.g., torch::zeros for at::zeros.  These return Variables (while the','line_number':58,'multiline':False]
['text':'/ stock ATen functions return plain Tensors).  If you mix these functions','line_number':59,'multiline':False]
['text':'/ up, you WILL BE SAD.','line_number':60,'multiline':False]
['text':'/','line_number':61,'multiline':False]
['text':'/ Rather than use the constructor of this class directly, you should prefer to','line_number':62,'multiline':False]
['text':'/ use the constructor functions, and then chain setter methods on top of them.','line_number':63,'multiline':False]
['text':'/','line_number':64,'multiline':False]
['text':'/     at::device(at::kCUDA).dtype(kInt)','line_number':65,'multiline':False]
['text':'/     at::dtype(at::kInt)','line_number':66,'multiline':False]
['text':'/','line_number':67,'multiline':False]
['text':'/ Additionally, anywhere a TensorOptions is expected, you can directly','line_number':68,'multiline':False]
['text':'/ pass at::kCUDA / at::kInt, and it will implicitly convert to a','line_number':69,'multiline':False]
['text':'/ TensorOptions.','line_number':70,'multiline':False]
['text':'/','line_number':71,'multiline':False]
['text':'/ Here are some recommended ways to create a 2x2 tensor of zeros','line_number':72,'multiline':False]
['text':'/ with certain properties.  These all *implicitly* make use of','line_number':73,'multiline':False]
['text':'/ TensorOptions, even if they don't mention the class explicitly:','line_number':74,'multiline':False]
['text':'/','line_number':75,'multiline':False]
['text':'/     at::zeros({2,2}, at::kCUDA);','line_number':76,'multiline':False]
['text':'/     at::zeros({2,2}, at::kLong);','line_number':77,'multiline':False]
['text':'/     at::zeros({2,2}, at::device(at::kCUDA).dtype(at::kLong()));','line_number':78,'multiline':False]
['text':'/     at::zeros({2,2}, at::device({at::kCUDA, 1})); // place on device 1','line_number':79,'multiline':False]
['text':'/     at::zeros({2,2}, at::requires_grad());','line_number':80,'multiline':False]
['text':'/','line_number':81,'multiline':False]
['text':'/ NOTE [ TensorOptions Constructors ]','line_number':83,'multiline':False]
['text':'/','line_number':84,'multiline':False]
['text':'/ TensorOptions is like a dictionary with entries from the set:','line_number':85,'multiline':False]
['text':'/ {requires_grad, device, dtype, layout}, where each entry may be','line_number':86,'multiline':False]
['text':'/ unspecified (i.e., is optional). It is used to specify the properties of','line_number':87,'multiline':False]
['text':'/ tensors in many places both in C++ internal and API, e.g., tensor factory','line_number':88,'multiline':False]
['text':'/ methods like `at::empty({10}, options)`, tensor conversions like','line_number':89,'multiline':False]
['text':'/ `tensor.to(...)`, etc.','line_number':90,'multiline':False]
['text':'/','line_number':91,'multiline':False]
['text':'/ To provide a simple API that is consistent with Python, where one can do','line_number':92,'multiline':False]
['text':'/ `torch.empty(sizes, X)` with `X` being a `torch.device`, `torch.dtype`, or a','line_number':93,'multiline':False]
['text':'/ `torch.layout`, we want TensorOptions to be implicitly convertible from','line_number':94,'multiline':False]
['text':'/ `ScalarType dtype`, `Layout layout` and `Device device`. Therefore, we have','line_number':95,'multiline':False]
['text':'/ three implicit constructors from each of these three types.','line_number':96,'multiline':False]
['text':'/','line_number':97,'multiline':False]
['text':'/ This is sufficient for `ScalarType` and `Layout` as they are simple Enum','line_number':98,'multiline':False]
['text':'/ classes. However, `Device` is an ordinary class with implicit constructors','line_number':99,'multiline':False]
['text':'/ `Device(DeviceType, DeviceIndex = -1)` and `Device(std::string)` to be','line_number':100,'multiline':False]
['text':'/ consistent with Python API, where strings are treated as equivalent with a','line_number':101,'multiline':False]
['text':'/ `torch.device` object (e.g., "cuda:1" can be passed to everywhere a','line_number':102,'multiline':False]
['text':'/ `torch.device("cuda:1")` is accepted). To support the syntax','line_number':103,'multiline':False]
['text':'/ `at::empty({10}, {kCUDA, 1})` and `tensor.to(kCUDA)`, we need to make sure','line_number':104,'multiline':False]
['text':'/ that `TensorOptions` is implicitly constructible with any arguments that a','line_number':105,'multiline':False]
['text':'/ `Device` can constructed from. So we have,','line_number':106,'multiline':False]
['text':'/','line_number':107,'multiline':False]
['text':'/    /* implicit */ TensorOptions(T&& device) : TensorOptions() {','line_number':108,'multiline':False]
['text':'/      this->set_device(device);','line_number':109,'multiline':False]
['text':'/    }','line_number':110,'multiline':False]
['text':'/','line_number':111,'multiline':False]
['text':'/    template <typename... Args,','line_number':112,'multiline':False]
['text':'/             typename = std::enable_if_t<std::is_constructible<Device,','line_number':113,'multiline':False]
['text':'/             Args&&...>::value>>','line_number':114,'multiline':False]
['text':'/    /* implicit */  TensorOptions(Args&&... args)','line_number':115,'multiline':False]
['text':'/     : TensorOptions(Device(std::forward<Args>(args)...)) {}','line_number':116,'multiline':False]
['text':'/','line_number':117,'multiline':False]
['text':'/','line_number':118,'multiline':False]
['text':'/ But this will be problematic. Consider this: `TensorOptions({kCUDA, 1})`.','line_number':119,'multiline':False]
['text':'/ Compiler will complain about ambiguity between the copy constructor and the','line_number':120,'multiline':False]
['text':'/ `Device` constructor because `{kCUDA, 1}` can be converted to both a','line_number':121,'multiline':False]
['text':'/ `TensorOption` and a `Device`.','line_number':122,'multiline':False]
['text':'/','line_number':123,'multiline':False]
['text':'/ To get around this, we templatize the `Device` constructor. Since overload','line_number':124,'multiline':False]
['text':'/ resolution is done before template resolution, our problem is solved.','line_number':125,'multiline':False]
['text':'/ Constructs a `TensorOptions` object with the given layout.','line_number':143,'multiline':False]
['text':' implicit ','line_number':144,'multiline':True]
['text':'/ Constructs a `TensorOptions` object with the given device.','line_number':148,'multiline':False]
['text':'/ See NOTE [ TensorOptions Constructors ] on why this is templatized.','line_number':149,'multiline':False]
['text':' implicit ','line_number':153,'multiline':True]
['text':'/ Constructs a `TensorOptions` object from arguments allowed in `Device`','line_number':157,'multiline':False]
['text':'/ constructors.','line_number':158,'multiline':False]
['text':'/','line_number':159,'multiline':False]
['text':'/ See NOTE [ TensorOptions Constructors ].','line_number':160,'multiline':False]
['text':'/','line_number':161,'multiline':False]
['text':'/ NB: Ideally we only allow implicit constructors here. But there is no easy','line_number':162,'multiline':False]
['text':'/     way to detect them. So we have this one that allows explicit','line_number':163,'multiline':False]
['text':'/     constructors too.','line_number':164,'multiline':False]
['text':' implicit ','line_number':168,'multiline':True]
['text':'/ Constructs a `TensorOptions` object with the given dtype.','line_number':171,'multiline':False]
['text':' implicit ','line_number':172,'multiline':True]
['text':'/ legacy constructor to support ScalarType','line_number':176,'multiline':False]
['text':' implicit ','line_number':177,'multiline':True]
['text':'/ Constructs a `TensorOptions` object with the given memory format.','line_number':181,'multiline':False]
['text':' implicit ','line_number':182,'multiline':True]
['text':'/ Return a copy of `TensorOptions` with `device` set to the given one, or','line_number':186,'multiline':False]
['text':'/ cleared if `device` is `nullopt`.','line_number':187,'multiline':False]
['text':'/ Return a copy of `TensorOptions` with `device` set to the given one.','line_number':195,'multiline':False]
['text':'/ (This overload ensures that variadic template c10::optional constructor','line_number':196,'multiline':False]
['text':'/ for Device work correctly.)','line_number':197,'multiline':False]
['text':'/ Return a copy of `TensorOptions`, but with device set to CUDA, and the','line_number':204,'multiline':False]
['text':'/ device index set to the given one.','line_number':205,'multiline':False]
['text':'/','line_number':206,'multiline':False]
['text':'/ TODO: This function encourages bad behavior (assuming CUDA is','line_number':207,'multiline':False]
['text':'/ the only device that matters).  Get rid of it / rename it.','line_number':208,'multiline':False]
['text':'/ Return a copy of `TensorOptions` with `dtype` set to the given one.','line_number':214,'multiline':False]
['text':' legacy function to support ScalarType','line_number':222,'multiline':False]
['text':' Since dtype is taken...','line_number':230,'multiline':False]
['text':'/ Sets the layout of the `TensorOptions`.','line_number':238,'multiline':False]
['text':'/ Sets the `requires_grad` property of the `TensorOptions`.','line_number':246,'multiline':False]
['text':'/ Sets the `pinned_memory` property on the `TensorOptions`.','line_number':254,'multiline':False]
['text':'/ Sets the `memory_format` property on `TensorOptions`.','line_number':262,'multiline':False]
['text':'/ Returns the device of the `TensorOptions`.','line_number':270,'multiline':False]
['text':'/ Returns whether the device is specified.','line_number':275,'multiline':False]
['text':'/ Returns the device of the `TensorOptions`, or `c10::nullopt` if','line_number':280,'multiline':False]
['text':'/ device is not specified.','line_number':281,'multiline':False]
['text':'/ Returns the device index of the `TensorOptions`.','line_number':286,'multiline':False]
['text':'/ Returns the dtype of the `TensorOptions`.','line_number':291,'multiline':False]
['text':'/ Returns whether the dtype is specified.','line_number':296,'multiline':False]
['text':'/ Returns the dtype of the `TensorOptions`, or `c10::nullopt` if','line_number':301,'multiline':False]
['text':'/ device is not specified.','line_number':302,'multiline':False]
['text':'/ Returns the layout of the `TensorOptions`.','line_number':307,'multiline':False]
['text':'/ Returns whether the layout is specified.','line_number':312,'multiline':False]
['text':'/ Returns the layout of the `TensorOptions`, or `c10::nullopt` if','line_number':317,'multiline':False]
['text':'/ layout is not specified.','line_number':318,'multiline':False]
['text':'/ Returns the `requires_grad` property of the `TensorOptions`.','line_number':323,'multiline':False]
['text':'/ Returns whether the `requires_grad` is specified.','line_number':328,'multiline':False]
['text':'/ Returns the `requires_grad` property of the `TensorOptions`, or','line_number':333,'multiline':False]
['text':'/ `c10::nullopt` if `requires_grad` is not specified.','line_number':334,'multiline':False]
['text':'/ Returns the `pinned_memory` property of the `TensorOptions`.','line_number':340,'multiline':False]
['text':'/ Returns whether the `pinned_memory` is specified.','line_number':345,'multiline':False]
['text':'/ Returns if the layout is sparse','line_number':350,'multiline':False]
['text':' For compatibility with legacy tensor.type() comparisons','line_number':359,'multiline':False]
['text':'/ Returns the `pinned_memory` property of the `TensorOptions`, or','line_number':365,'multiline':False]
['text':'/ `c10::nullopt` if `pinned_memory` is not specified.','line_number':366,'multiline':False]
['text':'/ Returns whether the `memory_layout` is specified','line_number':372,'multiline':False]
['text':' NB: memory_format() getter is PURPOSELY not defined, as the default','line_number':377,'multiline':False]
['text':' behavior of memory_format varies from function to function.','line_number':378,'multiline':False]
['text':'/ Returns the `memory_layout` property of `TensorOptions, or','line_number':380,'multiline':False]
['text':'/ `c10::nullopt` if `memory_format` is not specified.','line_number':381,'multiline':False]
['text':' Resolves the ATen backend specified by the current construction axes.','line_number':387,'multiline':False]
['text':' TODO: Deprecate this','line_number':388,'multiline':False]
['text':'/ Return the right-biased merge of two TensorOptions.  This has the','line_number':393,'multiline':False]
['text':'/ effect of overwriting settings from self with specified options','line_number':394,'multiline':False]
['text':'/ of options.','line_number':395,'multiline':False]
['text':'/','line_number':396,'multiline':False]
['text':'/ NB: This merging operation does NOT respect device merges.','line_number':397,'multiline':False]
['text':'/ For example, if you device({kCUDA, 1}).merge_in(kCUDA)','line_number':398,'multiline':False]
['text':'/ you will get kCUDA in the end!  Functions like Tensor.new_empty','line_number':399,'multiline':False]
['text':'/ ensure the right device is selected anyway by way of a','line_number':400,'multiline':False]
['text':'/ device guard.','line_number':401,'multiline':False]
['text':'/','line_number':402,'multiline':False]
['text':' NB: requires grad is right biased; not a logical AND/OR!','line_number':411,'multiline':False]
['text':' TODO remove after TensorOptions rationalization','line_number':421,'multiline':False]
['text':' INVARIANT: computeDispatchKey returns only the subset of dispatch keys for','line_number':431,'multiline':False]
['text':' which dispatchKeyToBackend is injective, if it is defined at all  (for','line_number':432,'multiline':False]
['text':' the most part, this just means that this function never returns an','line_number':433,'multiline':False]
['text':' Autograd key)','line_number':434,'multiline':False]
['text':' These methods are currently private because I'm not sure if it's wise','line_number':441,'multiline':False]
['text':' to actually publish them.  They are methods because I need them in','line_number':442,'multiline':False]
['text':' the constructor and the functional API implementation.','line_number':443,'multiline':False]
['text':'','line_number':444,'multiline':False]
['text':' If you really, really need it, you can make these public, but check if you','line_number':445,'multiline':False]
['text':' couldn't just do what you need with the functional API.  Similarly, these','line_number':446,'multiline':False]
['text':' methods are not chainable, because if you wanted chaining, you probably','line_number':447,'multiline':False]
['text':' want to use the functional API instead.  (It's probably OK to make','line_number':448,'multiline':False]
['text':' these chainable, because these functions are all explicitly annotated','line_number':449,'multiline':False]
['text':' with a ref-qualifier, the trailing &, that makes them illegal to call','line_number':450,'multiline':False]
['text':' on temporaries.)','line_number':451,'multiline':False]
['text':'/ Mutably set the device of `TensorOptions`.','line_number':453,'multiline':False]
['text':'/ Mutably set the dtype of `TensorOptions`.','line_number':463,'multiline':False]
['text':' legacy function to support ScalarType','line_number':473,'multiline':False]
['text':'/ Mutably set the layout of `TensorOptions`.','line_number':483,'multiline':False]
['text':'/ Mutably set the `requires_grad` property of `TensorOptions`.','line_number':493,'multiline':False]
['text':'/ Mutably set the `pinned_memory` property of `TensorOptions`.','line_number':503,'multiline':False]
['text':'/ Mutably set the `memory_Format` property of `TensorOptions`.','line_number':513,'multiline':False]
['text':' WARNING: If you edit TensorOptions to add more options, you','line_number':523,'multiline':False]
['text':' may need to adjust the implementation of Tensor::options.','line_number':524,'multiline':False]
['text':' The criteria for whether or not Tensor::options must be adjusted','line_number':525,'multiline':False]
['text':' is whether or not the new option you added should preserved','line_number':526,'multiline':False]
['text':' by functions such as empty_like(); if it should be preserved,','line_number':527,'multiline':False]
['text':' you must adjust options().','line_number':528,'multiline':False]
['text':'','line_number':529,'multiline':False]
['text':' TODO: MemoryFormat is not implemented in this way','line_number':530,'multiline':False]
['text':' NB: We didn't use c10::optional here, because then we can't pack','line_number':532,'multiline':False]
['text':' the has_***_ boolean fields.','line_number':533,'multiline':False]
['text':' 16-bit','line_number':535,'multiline':False]
['text':' 16-bit','line_number':536,'multiline':False]
['text':' 8-bit','line_number':537,'multiline':False]
['text':' 8-bit','line_number':538,'multiline':False]
['text':' Bitmask required here to get this to fit inside 32 bits (or even 64 bits,','line_number':540,'multiline':False]
['text':' for that matter)','line_number':541,'multiline':False]
['text':' We should aspire to fit in one machine-size word; but a size greater than two','line_number':554,'multiline':False]
['text':' words is too much.  (We are doing terribly on 32-bit archs, where we require','line_number':555,'multiline':False]
['text':' three machine size words to store tensor options.  Eek!)','line_number':556,'multiline':False]
['text':'/ Convenience function that returns a `TensorOptions` object with the `dtype`','line_number':561,'multiline':False]
['text':'/ set to the given one.','line_number':562,'multiline':False]
['text':' legacy function to support ScalarType','line_number':567,'multiline':False]
['text':'/ Convenience function that returns a `TensorOptions` object with the `layout`','line_number':572,'multiline':False]
['text':'/ set to the given one.','line_number':573,'multiline':False]
['text':'/ Convenience function that returns a `TensorOptions` object with the `device`','line_number':578,'multiline':False]
['text':'/ set to the given one.','line_number':579,'multiline':False]
['text':'/ Convenience function that returns a `TensorOptions` object with the','line_number':584,'multiline':False]
['text':'/ `device` set to CUDA and the `device_index` set to the given one.','line_number':585,'multiline':False]
['text':'/ Convenience function that returns a `TensorOptions` object with the','line_number':591,'multiline':False]
['text':'/ `requires_grad` set to the given one.','line_number':592,'multiline':False]
['text':'/ Convenience function that returns a `TensorOptions` object with the','line_number':597,'multiline':False]
['text':'/ `memory_format` set to the given one.','line_number':598,'multiline':False]
['text':' This is intended to be a centralized location by which we can determine','line_number':618,'multiline':False]
['text':' what an appropriate DispatchKey for a tensor is.','line_number':619,'multiline':False]
['text':' stuff that's real','line_number':731,'multiline':False]
['text':' Quantized backends don't support at::empty().','line_number':764,'multiline':False]
['text':' They have separate operators like at::empty_quantized() that take in','line_number':765,'multiline':False]
['text':' extra information about how to quantize the tensor.','line_number':766,'multiline':False]
['text':' namespace detail','line_number':770,'multiline':False]
['text':' namespace c10','line_number':772,'multiline':False]
