['text':' This file implements a small program synthesis engine that implements','line_number':36,'multiline':False]
['text':' conversions between one API to another.','line_number':37,'multiline':False]
['text':'','line_number':38,'multiline':False]
['text':' The key data type in this file in NamedCType, short for Named C++ semantic type.  A NamedCType','line_number':39,'multiline':False]
['text':' represents a C++ type, plus semantic information about what it represents.','line_number':40,'multiline':False]
['text':' For example, consider the argument "bool pin_memory"; its normal C++ type is','line_number':41,'multiline':False]
['text':' "bool", but its C++ semantic type also keeps track that this represents a','line_number':42,'multiline':False]
['text':' "pin_memory"; you can't just use a random other boolean in a context where you','line_number':43,'multiline':False]
['text':' need a "pin_memory"!','line_number':44,'multiline':False]
['text':'','line_number':45,'multiline':False]
['text':' The translator takes a list of needed NamedCTypes, and then figures out how','line_number':46,'multiline':False]
['text':' to construct expressions with these NamedCTypes from the given bindings.  Many','line_number':47,'multiline':False]
['text':' of these expressions are trivial (I need a Tensor other; there's a Tensor','line_number':48,'multiline':False]
['text':' other scope); others are more nontrivial and may require packing/unpacking.','line_number':49,'multiline':False]
['text':' Some examples of non-trivial action:','line_number':50,'multiline':False]
['text':'','line_number':51,'multiline':False]
['text':'   - Need the "dtype" binding?  Well, maybe "dtype" isn't available','line_number':52,'multiline':False]
['text':'     in the context, instead, "options" is, and you need to extract','line_number':53,'multiline':False]
['text':'     it from there.  (Gather)','line_number':54,'multiline':False]
['text':'','line_number':55,'multiline':False]
['text':'   - Need the "context" binding?  Well, maybe "context" isn't available','line_number':56,'multiline':False]
['text':'     in the context, and you need to construct it from "dtype", "device",','line_number':57,'multiline':False]
['text':'     etc.  (Scatter)','line_number':58,'multiline':False]
['text':'','line_number':59,'multiline':False]
['text':'   - Need the "memory_format" binding?  Well, actually, it's available','line_number':60,'multiline':False]
['text':'     from both "memory_format" and "options", so you had better make sure','line_number':61,'multiline':False]
['text':'     they are consistent.  (Join)','line_number':62,'multiline':False]
['text':' Given a set of in-scope bindings and a set of target bindings, synthesize','line_number':79,'multiline':False]
['text':' a list of expressions that uses only the in-scope bindings (bindings) that','line_number':80,'multiline':False]
['text':' have all of the types of goals.  You may want to use this function if','line_number':81,'multiline':False]
['text':' you're generating code for a function like:','line_number':82,'multiline':False]
['text':'','line_number':83,'multiline':False]
['text':'   void f({args}) {','line_number':84,'multiline':False]
['text':'     g({exprs}); // g is a different API','line_number':85,'multiline':False]
['text':'   }','line_number':86,'multiline':False]
['text':'','line_number':87,'multiline':False]
['text':' and you need to generate "exprs".','line_number':88,'multiline':False]
['text':'','line_number':89,'multiline':False]
['text':' Typically, a list of Bindings is convenient to get (you usually call something','line_number':90,'multiline':False]
['text':' like arguments() to get them); but technically you only need less information:','line_number':91,'multiline':False]
['text':' for 'bindings' an (un-ordered) list of Exprs is sufficient; similarly, for','line_number':92,'multiline':False]
['text':' 'goals', an (ordered) list of NamedCType goals is sufficient.  If you are doing','line_number':93,'multiline':False]
['text':' something more complicated, e.g., tracking the set of bindings in a context,','line_number':94,'multiline':False]
['text':' you may find using these smaller types more convenient.','line_number':95,'multiline':False]
['text':' Add all the bindings to the context','line_number':122,'multiline':False]
['text':' While we're at it, do some simple forward inference, looking through','line_number':127,'multiline':False]
['text':' constructors.','line_number':128,'multiline':False]
['text':'','line_number':129,'multiline':False]
['text':' NB: When should you do forward inference versus backward inference?','line_number':130,'multiline':False]
['text':' The general idea:','line_number':131,'multiline':False]
['text':'','line_number':132,'multiline':False]
['text':'   - Backward inference WHEN the goal gets smaller','line_number':133,'multiline':False]
['text':'   - Forward inference WHEN the hypothesis gets smaller','line_number':134,'multiline':False]
['text':'','line_number':135,'multiline':False]
['text':' This helps ensure termination: backward inference starts with a goal','line_number':136,'multiline':False]
['text':' and tries to make it simpler and simpler until it's trivial; if the','line_number':137,'multiline':False]
['text':' goal can grow in size, we blow up to a really huge goal size.','line_number':138,'multiline':False]
['text':' Similarly, with forward inference we take hypotheses and decompose','line_number':139,'multiline':False]
['text':' them into simpler hypotheses; if hypotheses could expand in size,','line_number':140,'multiline':False]
['text':' we also have potential nontermination.  (In the code below, forward','line_number':141,'multiline':False]
['text':' inference is only ever carried out at a single step, but you could','line_number':142,'multiline':False]
['text':' imagine repeated application of forward inference being profitable.)','line_number':143,'multiline':False]
['text':'','line_number':144,'multiline':False]
['text':' A good starting point in the literature for exploring more about proof','line_number':145,'multiline':False]
['text':' search are these lecture notes','line_number':146,'multiline':False]
['text':' https://www.cs.cmu.edu/~fp/courses/oregon-m10/04-focusing.pdf','line_number':147,'multiline':False]
['text':'','line_number':148,'multiline':False]
['text':' TODO: My kingdom for a pattern matcher','line_number':149,'multiline':False]
['text':' https://www.python.org/dev/peps/pep-0634/','line_number':150,'multiline':False]
['text':'','line_number':151,'multiline':False]
['text':' TODO: This could get us in recomputation trouble if b.expr is nontrivial.','line_number':152,'multiline':False]
['text':' Fix this by implementing some sort of sharing so that if multiple','line_number':153,'multiline':False]
['text':' goals share the same expression, we only compute it once.  This seems','line_number':154,'multiline':False]
['text':' to matter in practice as compiler is often unwilling to CSE nontrivial','line_number':155,'multiline':False]
['text':' expressions like scalar.to<scalar_t>()','line_number':156,'multiline':False]
['text':' [Note: IOptTensorListRef]','line_number':186,'multiline':False]
['text':' Add implicit bindings if the generated code is inside a Tensor method','line_number':192,'multiline':False]
['text':' This is better!  Byte-for-byte compat','line_number':200,'multiline':False]
['text':' ctx[NamedCType("self", ConstRefCType(BaseCType(tensorT)))] = "*this"','line_number':201,'multiline':False]
['text':' A shitty backtracking search implementation.  It's shitty because it','line_number':219,'multiline':False]
['text':' does backtracking via stack (bad idea!) and for the most part tries to','line_number':220,'multiline':False]
['text':' avoid backtracking.  In particular, if','line_number':221,'multiline':False]
['text':' direct=True, we won't try to do any fancy synthesis, just trivial','line_number':222,'multiline':False]
['text':' conversions (e.g., "T a" is OK for "const T& a").  So all of the','line_number':223,'multiline':False]
['text':' existing rules in this function simply try to solve immediately,','line_number':224,'multiline':False]
['text':' and bail if things don't work out.','line_number':225,'multiline':False]
['text':' Trivial','line_number':231,'multiline':False]
['text':' const & is satisfied with mutable &','line_number':234,'multiline':False]
['text':' WARNING: not strictly decreasing; be careful not','line_number':237,'multiline':False]
['text':' to add a direct conversion that goes satisfies','line_number':238,'multiline':False]
['text':' mutable& with const&','line_number':239,'multiline':False]
['text':' mutable & is satisfied with value','line_number':246,'multiline':False]
['text':' TODO: These are referentially equal, shouldn't have to do this;','line_number':253,'multiline':False]
['text':' ensuring we don't use type synonym IntArrayRef in codegen would','line_number':254,'multiline':False]
['text':' help','line_number':255,'multiline':False]
['text':' For now, all of these rules are mutually exclusive.','line_number':262,'multiline':False]
['text':' No need to join "memory_format" and "options" if the target API takes "options" directly.','line_number':270,'multiline':False]
['text':' Otherwise it will cause the redundant memory_format error.','line_number':271,'multiline':False]
['text':' If we're calling a factory op from its out= variant,','line_number':323,'multiline':False]
['text':' We don't actually care about the value of pin_memory.','line_number':324,'multiline':False]
['text':' We can always do translations from value types to reference types, like vector<int> -> IntArrayRef','line_number':328,'multiline':False]
['text':' We can also go SymIntArrayRef -> IntArrayRef','line_number':333,'multiline':False]
['text':' TODO: You might also want to solve this from longSymVec_ctype or','line_number':368,'multiline':False]
['text':' an optional version of it','line_number':369,'multiline':False]
['text':' Note [translation from C++ reference to value types]','line_number':379,'multiline':False]
['text':' The below cases are all for when we have an argument with a reference type,','line_number':380,'multiline':False]
['text':' and a corresponding goal with a value type.','line_number':381,'multiline':False]
['text':' These are needed when we populate the inputs to a lambda capture and we need','line_number':382,'multiline':False]
['text':' to guarantee the lifetime of each captured argument.','line_number':383,'multiline':False]
['text':' We guard it with an explicit kwarg because converting to a value type is expensive','line_number':384,'multiline':False]
['text':' (O(n)) to convert from IntArrayRef to vector<int>),','line_number':385,'multiline':False]
['text':' so the caller of translate() should be explicit that they need it.','line_number':386,'multiline':False]
['text':' Technically, we also need to handle cases of C++ containers holding reference types.','line_number':414,'multiline':False]
['text':' But there currently aren't any ops that require lambda capture codegen','line_number':415,'multiline':False]
['text':' With arguments like std::vector<IntArrayRef>.','line_number':416,'multiline':False]
['text':' If that changes, we'll have to add the translation here.','line_number':417,'multiline':False]
['text':' We allow const casting on tensors, since const-correctness is a bit broken for at::Tensor.','line_number':419,'multiline':False]
['text':' We could probably generalize this to non-tensor types too.','line_number':420,'multiline':False]
