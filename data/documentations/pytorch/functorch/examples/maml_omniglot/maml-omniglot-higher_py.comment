['text':'!/usr/bin/env python3','line_number':1,'multiline':False]
['text':'','line_number':2,'multiline':False]
['text':' Copyright (c) Facebook, Inc. and its affiliates.','line_number':3,'multiline':False]
['text':'','line_number':4,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':5,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':6,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':7,'multiline':False]
['text':'','line_number':8,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':9,'multiline':False]
['text':'','line_number':10,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':11,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':12,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':13,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':14,'multiline':False]
['text':' limitations under the License.','line_number':15,'multiline':False]
['text':' Set up the Omniglot loader.','line_number':74,'multiline':False]
['text':' Create a vanilla PyTorch neural network that will be','line_number':86,'multiline':False]
['text':' automatically monkey-patched by higher later.','line_number':87,'multiline':False]
['text':' Before higher, models could *not* be created like this','line_number':88,'multiline':False]
['text':' and the parameters needed to be manually updated and copied','line_number':89,'multiline':False]
['text':' for the updates.','line_number':90,'multiline':False]
['text':' We will use Adam to (meta-)optimize the initial parameters','line_number':108,'multiline':False]
['text':' to be adapted.','line_number':109,'multiline':False]
['text':' Sample a batch of support and query images and labels.','line_number':125,'multiline':False]
['text':' TODO: Maybe pull this out into a separate module so it','line_number':131,'multiline':False]
['text':' doesn't have to be duplicated between `train` and `test`?','line_number':132,'multiline':False]
['text':' Initialize the inner optimizer to adapt the parameters to','line_number':134,'multiline':False]
['text':' the support set.','line_number':135,'multiline':False]
['text':' Optimize the likelihood of the support set by taking','line_number':147,'multiline':False]
['text':' gradient steps w.r.t. the model's parameters.','line_number':148,'multiline':False]
['text':' This adapts the model's meta-parameters to the task.','line_number':149,'multiline':False]
['text':' higher is able to automatically keep copies of','line_number':150,'multiline':False]
['text':' your network's parameters as they are being updated.','line_number':151,'multiline':False]
['text':' The final set of adapted parameters will induce some','line_number':157,'multiline':False]
['text':' final loss and accuracy on the query dataset.','line_number':158,'multiline':False]
['text':' These will be used to update the model's meta-parameters.','line_number':159,'multiline':False]
['text':' print([b.shape for b in fnet[1].buffers()])','line_number':166,'multiline':False]
['text':' Update the model's meta-parameters to optimize the query','line_number':168,'multiline':False]
['text':' losses across all of the tasks sampled in this batch.','line_number':169,'multiline':False]
['text':' This unrolls through the gradient steps.','line_number':170,'multiline':False]
['text':' Crucially in our testing procedure here, we do *not* fine-tune','line_number':195,'multiline':False]
['text':' the model during testing for simplicity.','line_number':196,'multiline':False]
['text':' Most research papers using MAML for this task do an extra','line_number':197,'multiline':False]
['text':' stage of fine-tuning here that should be added if you are','line_number':198,'multiline':False]
['text':' adapting this code for research.','line_number':199,'multiline':False]
['text':' TODO: Maybe pull this out into a separate module so it','line_number':211,'multiline':False]
['text':' doesn't have to be duplicated between `train` and `test`?','line_number':212,'multiline':False]
['text':' Optimize the likelihood of the support set by taking','line_number':221,'multiline':False]
['text':' gradient steps w.r.t. the model's parameters.','line_number':222,'multiline':False]
['text':' This adapts the model's meta-parameters to the task.','line_number':223,'multiline':False]
['text':' The query loss and acc induced by these parameters.','line_number':229,'multiline':False]
['text':' Generally you should pull your plotting code out of your training','line_number':250,'multiline':False]
['text':' script but we are doing it here for brevity.','line_number':251,'multiline':False]
['text':' Won't need this after this PR is merged in:','line_number':270,'multiline':False]
['text':' https://github.com/pytorch/pytorch/pull/22245','line_number':271,'multiline':False]
