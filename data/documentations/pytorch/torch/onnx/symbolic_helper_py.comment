['text':' Monkey-patch graph manipulation methods on Graph, used for the ONNX symbolics','line_number':25,'multiline':False]
['text':' ---------------------------------------------------------------------------------','line_number':48,'multiline':False]
['text':' Helper functions','line_number':49,'multiline':False]
['text':' ---------------------------------------------------------------------------------','line_number':50,'multiline':False]
['text':' NOTE: prim::Constant at this stage usually means something not compatible in ONNX,','line_number':154,'multiline':False]
['text':' otherwise it'd be converted to onnx::Constant','line_number':155,'multiline':False]
['text':' TODO(justinchuby): Replace insinstance with _is_value once we figure out mypy','line_number':156,'multiline':False]
['text':' A quantized tensor is represented as tuple of the form (tensor, scale, zero_point, <axis>)','line_number':214,'multiline':False]
['text':' Check if list_value is output from prim::ListConstruct','line_number':227,'multiline':False]
['text':' This is usually called before _unpack_list to ensure the list can be unpacked.','line_number':228,'multiline':False]
['text':' some args may be optional, so the length may be smaller','line_number':268,'multiline':False]
['text':' FIXME(justinchuby): Avoid catching Exception.','line_number':285,'multiline':False]
['text':' Catch a more specific exception instead.','line_number':286,'multiline':False]
['text':' type: ignore[list-item]','line_number':287,'multiline':False]
['text':' type: ignore[assignment]','line_number':290,'multiline':False]
['text':' only support _outputs in kwargs','line_number':293,'multiline':False]
['text':' Support variable length arguments by marking unspecified ones as non-quantized','line_number':375,'multiline':False]
['text':' Run regular symbolic function if none of the argument is QTensor.','line_number':384,'multiline':False]
['text':' ListConstruct','line_number':387,'multiline':False]
['text':' Dequantize arguments that are quantized','line_number':397,'multiline':False]
['text':' Quantized arg is a tuple of (value, scale, zero_point)','line_number':401,'multiline':False]
['text':' Set scale and zero_point to the first quantized input if not already set','line_number':406,'multiline':False]
['text':' ListConstruct','line_number':411,'multiline':False]
['text':' Quantized arg is a tuple of (value, scale, zero_point)','line_number':415,'multiline':False]
['text':' Set scale and zero_point to the first quantized input if not already set','line_number':422,'multiline':False]
['text':' Non-quantized arg','line_number':430,'multiline':False]
['text':' TODO(justinchuby): Only single output is supported for now. We may want to','line_number':432,'multiline':False]
['text':' support multiple outputs in the future.','line_number':433,'multiline':False]
['text':' Note: _C.JitType is not exposed to Python and cannot be checked in runtime.','line_number':501,'multiline':False]
['text':' Each individual symbol is returned as None.','line_number':576,'multiline':False]
['text':' e.g. [1, "a", "b"] -> [1, None, None]','line_number':577,'multiline':False]
['text':' returns None, if exists any symbol in sizes.','line_number':579,'multiline':False]
['text':' e.g. [1, "a", "b"] -> None','line_number':580,'multiline':False]
['text':' If dim is not given, it defaults to the first dimension found with the size 3','line_number':596,'multiline':False]
['text':' For BC reasons, the behavior for Caffe2 does not raise exception for unimplemented operators','line_number':608,'multiline':False]
['text':' Index is a constant scalar. Make it a size 1 constant tensor.','line_number':697,'multiline':False]
['text':' Index is a scalar. Reshape it to a size 1 tensor.','line_number':701,'multiline':False]
['text':' Tensor type','line_number':853,'multiline':False]
['text':' Tensor type','line_number':868,'multiline':False]
['text':' The axes is a scalar. Unsqueeze it to a rank 1 tensor.','line_number':881,'multiline':False]
['text':' only valid when mode="cubic"','line_number':1110,'multiline':False]
['text':' nearest, linear, or cubic','line_number':1111,'multiline':False]
['text':' only valid when mode="nearest"','line_number':1113,'multiline':False]
['text':' only valid when mode="cubic"','line_number':1128,'multiline':False]
['text':' nearest, linear, or cubic','line_number':1129,'multiline':False]
['text':' only valid when mode="nearest"','line_number':1131,'multiline':False]
['text':' in some cases size is not a packed list but size is a scalar','line_number':1164,'multiline':False]
['text':' We need to also verify that (_maybe_get_const(size, "t").dim() == 0)','line_number':1165,'multiline':False]
['text':' but this information is not always available. Try to get the dim,','line_number':1166,'multiline':False]
['text':' and if not assume that it is not a scalar.','line_number':1167,'multiline':False]
['text':' only valid when mode="cubic"','line_number':1209,'multiline':False]
['text':' nearest, linear, or cubic','line_number':1210,'multiline':False]
['text':' if not _is_none(scales)','line_number':1213,'multiline':False]
['text':' only valid when mode="cubic"','line_number':1230,'multiline':False]
['text':' nearest, linear, or cubic','line_number':1231,'multiline':False]
['text':' only valid when mode="nearest"','line_number':1233,'multiline':False]
['text':' type: ignore[no-redef]','line_number':1241,'multiline':False]
['text':' type: ignore[no-redef]','line_number':1243,'multiline':False]
['text':' for mypy, scatter was imported two lines above','line_number':1252,'multiline':False]
['text':' type: ignore[no-redef]','line_number':1253,'multiline':False]
['text':' Convert 'repeats' to 1-d if it is 0-d.','line_number':1281,'multiline':False]
['text':' Create a new dim of size 1, then expand it to be 'repeats' long, and finally collapse it.','line_number':1285,'multiline':False]
['text':' repeats_per_dim is 1 for all dims except for the new unsqueezed dim, where it has value 'repeats'.','line_number':1288,'multiline':False]
['text':' 'Repeats' is a constant, 'repeats_per_dim' can be a constant.','line_number':1290,'multiline':False]
['text':' 'Repeats' is a variable, 'repeats_per_dim' cannot be a constant.','line_number':1295,'multiline':False]
['text':' indices, must be >= 1-dimensional','line_number':1298,'multiline':False]
['text':' depth','line_number':1301,'multiline':False]
['text':' on/off values','line_number':1304,'multiline':False]
['text':' This logic is based on torch.arange docs. If "dtype" is provided,','line_number':1333,'multiline':False]
['text':' infer input types from dtype. If not, then check if any of start, stop,','line_number':1334,'multiline':False]
['text':' or step are floating point, and infer the type from get_default.','line_number':1335,'multiline':False]
['text':' Otherwise, the dtype is inferred to be torch.int64.','line_number':1336,'multiline':False]
['text':' TODO(justinchuby): Check if dtype is indeed a int.','line_number':1346,'multiline':False]
['text':' type: ignore[no-redef]','line_number':1360,'multiline':False]
['text':' 1. reshape index => [1, ..., 1, dim, 1, ..., 1]','line_number':1374,'multiline':False]
['text':' 2. expand index => [..., dim, ...], same shape as self except for dim.','line_number':1375,'multiline':False]
['text':' 3. expand value as well.','line_number':1376,'multiline':False]
['text':' 4. apply onnx::scatter.','line_number':1377,'multiline':False]
['text':' for mypy, scatter was imported two lines above','line_number':1384,'multiline':False]
['text':' type: ignore[no-redef]','line_number':1385,'multiline':False]
['text':' By default, when any value in the 'shape' input is equal to zero','line_number':1403,'multiline':False]
['text':' the corresponding dimension value is copied from the input tensor dynamically.','line_number':1404,'multiline':False]
['text':' allowzero=1 indicates that if any value in the 'shape' input is set to zero,','line_number':1405,'multiline':False]
['text':' the zero value is honored, similar to NumPy.','line_number':1406,'multiline':False]
['text':' allowzero=1 is only supported for opset version >= 14.','line_number':1407,'multiline':False]
['text':' If track_running_stats is set to False batch statistics are instead used during evaluation time','line_number':1454,'multiline':False]
['text':' The modes agree. Do nothing','line_number':1506,'multiline':False]
['text':' Setting the model mode could result in op_mode != GLOBALS.training_mode','line_number':1510,'multiline':False]
['text':' if the model is a FuncModule. In this case we warn the user of','line_number':1511,'multiline':False]
['text':' the state and export depending on op_mode','line_number':1512,'multiline':False]
['text':' This is to support use-cases of fixing certain layer weights','line_number':1513,'multiline':False]
['text':' in training.','line_number':1514,'multiline':False]
['text':' If input tensor is empty, according to ONNX ReduceSum definition,','line_number':1567,'multiline':False]
['text':' set keepdims=1 so that the resulted tensor has the same rank as the input.','line_number':1568,'multiline':False]
['text':' Deprecated. Internally use _type_utils.ScalarType','line_number':1717,'multiline':False]
['text':' TODO: remove these once we support Type's in the JIT IR and we can once again','line_number':1718,'multiline':False]
['text':' use the unified toType operator','line_number':1719,'multiline':False]
['text':' Deprecated. Internally use _type_utils.ScalarType','line_number':1736,'multiline':False]
['text':' Deprecated. Internally use _type_utils.ScalarType','line_number':1756,'multiline':False]
['text':' This indicates each scalar type's corresponding','line_number':1757,'multiline':False]
['text':' torch type. Related source:','line_number':1758,'multiline':False]
['text':' https://github.com/pytorch/pytorch/blob/344defc9733a45fee8d0c4d3f5530f631e823196/c10/core/ScalarType.h','line_number':1759,'multiline':False]
['text':' 0','line_number':1761,'multiline':False]
['text':' 1','line_number':1762,'multiline':False]
['text':' 2','line_number':1763,'multiline':False]
['text':' 3','line_number':1764,'multiline':False]
['text':' 4','line_number':1765,'multiline':False]
['text':' 5','line_number':1766,'multiline':False]
['text':' 6','line_number':1767,'multiline':False]
['text':' 7','line_number':1768,'multiline':False]
['text':' 8','line_number':1769,'multiline':False]
['text':' 9','line_number':1770,'multiline':False]
['text':' 10','line_number':1771,'multiline':False]
['text':' 11','line_number':1772,'multiline':False]
['text':' 12','line_number':1773,'multiline':False]
['text':' 13','line_number':1774,'multiline':False]
['text':' 14','line_number':1775,'multiline':False]
['text':' 15','line_number':1776,'multiline':False]
['text':' Deprecated. Internally use _type_utils.ScalarType','line_number':1779,'multiline':False]
['text':' source of truth is','line_number':1780,'multiline':False]
['text':' https://github.com/pytorch/pytorch/blob/master/torch/csrc/utils/tensor_dtypes.cpp','line_number':1781,'multiline':False]
['text':' Deprecated. Internally use _type_utils.ScalarType','line_number':1801,'multiline':False]
['text':' 0','line_number':1803,'multiline':False]
['text':' 1','line_number':1804,'multiline':False]
['text':' 2','line_number':1805,'multiline':False]
['text':' 3','line_number':1806,'multiline':False]
['text':' 4','line_number':1807,'multiline':False]
['text':' 5','line_number':1808,'multiline':False]
['text':' 6','line_number':1809,'multiline':False]
['text':' 7','line_number':1810,'multiline':False]
['text':' 8','line_number':1811,'multiline':False]
['text':' 9','line_number':1812,'multiline':False]
['text':' 10','line_number':1813,'multiline':False]
['text':' 11','line_number':1814,'multiline':False]
['text':' 12','line_number':1815,'multiline':False]
['text':' 13','line_number':1816,'multiline':False]
['text':' 14','line_number':1817,'multiline':False]
['text':' 15','line_number':1818,'multiline':False]
['text':' Global set to store the list of quantized operators in the network.','line_number':1821,'multiline':False]
['text':' This is currently only used in the conversion of quantized ops from PT -> C2 via ONNX.','line_number':1822,'multiline':False]
