['text':' Copyright (c) Meta Platforms, Inc. and affiliates','line_number':1,'multiline':False]
['text':' type: ignore[var-annotated]','line_number':10,'multiline':False]
['text':' When reduction is "all", then torch.argmin/torch.argmax needs to return the index of the','line_number':50,'multiline':False]
['text':' element corresponding to the min/max, but this operation isn't supported correctly for sparse layouts.','line_number':51,'multiline':False]
['text':' Therefore, this implementation calculates it using the strides.','line_number':52,'multiline':False]
['text':' we simply pass in the values for sparse COO/CSR tensors','line_number':69,'multiline':False]
['text':' TODO: autograd.Function doesn't support kwarg','line_number':127,'multiline':False]
