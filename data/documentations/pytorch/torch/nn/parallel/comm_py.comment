['text':' index of input tensor that already is on the correct device','line_number':77,'multiline':False]
['text':' make a new tensor w/o clone','line_number':98,'multiline':False]
['text':' TODO: When `len(inputs) == 1` and all inputs are on `destination`, just','line_number':122,'multiline':False]
['text':'       return `inputs`.','line_number':123,'multiline':False]
['text':' shape (num_gpus, num_tensors)','line_number':124,'multiline':False]
['text':' process sparse ones first since they may have different sizes on different gpus','line_number':127,'multiline':False]
['text':' this will be sparse too','line_number':130,'multiline':False]
['text':' now the dense ones, which have consistent sizes','line_number':138,'multiline':False]
['text':' (num_gpus,)','line_number':140,'multiline':False]
['text':' The unflattened tensors do not share storage, and we don't expose','line_number':143,'multiline':False]
['text':' base flat tensor anyways, so give them different version counters.','line_number':144,'multiline':False]
['text':' See NOTE [ Version Counter in comm.*_coalesced ]','line_number':145,'multiline':False]
