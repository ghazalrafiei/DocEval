['text':' calculate mean/invstd for input.','line_number':24,'multiline':False]
['text':' C, C, 1 -> (2C + 1)','line_number':34,'multiline':False]
['text':' for empty input, set stats and the count to zero. The stats with','line_number':37,'multiline':False]
['text':' zero count will be filtered out later when computing global mean','line_number':38,'multiline':False]
['text':' & invstd, but they still needs to participate the all_gather','line_number':39,'multiline':False]
['text':' collective communication to unblock other peer processes.','line_number':40,'multiline':False]
['text':' Use allgather instead of allreduce because count could be different across','line_number':47,'multiline':False]
['text':' ranks, simple all reduce op can not give correct results.','line_number':48,'multiline':False]
['text':' batch_norm_gather_stats_with_counts calculates global mean & invstd based on','line_number':49,'multiline':False]
['text':' all gathered mean, invstd and count.','line_number':50,'multiline':False]
['text':' for nccl backend, use the optimized version of all gather.','line_number':51,'multiline':False]
['text':' The Gloo backend does not support `all_gather_into_tensor`.','line_number':52,'multiline':False]
['text':' world_size * (2C + 1)','line_number':54,'multiline':False]
['text':' world_size * (2C + 1) -> world_size * C, world_size * C, world_size * 1','line_number':62,'multiline':False]
['text':' world_size * (2C + 1)','line_number':65,'multiline':False]
['text':' world_size * (2C + 1) -> world_size * C, world_size * C, world_size * 1','line_number':71,'multiline':False]
['text':' The lines below force a synchronization between CUDA and CPU, because','line_number':75,'multiline':False]
['text':' the shape of the result count_all depends on the values in mask tensor.','line_number':76,'multiline':False]
['text':' Such synchronizations break CUDA Graph capturing.','line_number':77,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/78549','line_number':78,'multiline':False]
['text':' FIXME: https://github.com/pytorch/pytorch/issues/78656 describes','line_number':79,'multiline':False]
['text':' a better longer-term solution.','line_number':80,'multiline':False]
['text':' remove stats from empty inputs','line_number':82,'multiline':False]
['text':' calculate global mean & invstd','line_number':88,'multiline':False]
['text':' apply element-wise normalization','line_number':106,'multiline':False]
['text':' calculate local stats as well as grad_weight / grad_bias','line_number':124,'multiline':False]
['text':' synchronizing stats used to calculate input gradient.','line_number':137,'multiline':False]
['text':' backward pass for gradient calculation','line_number':144,'multiline':False]
['text':' synchronizing of grad_weight / grad_bias is not needed as distributed','line_number':157,'multiline':False]
['text':' training would handle all reduce.','line_number':158,'multiline':False]
['text':' This process got an empty input tensor in the forward pass.','line_number':165,'multiline':False]
['text':' Although this process can directly set grad_input as an empty','line_number':166,'multiline':False]
['text':' tensor of zeros, it still needs to participate in the collective','line_number':167,'multiline':False]
['text':' communication to unblock its peers, as other peer processes might','line_number':168,'multiline':False]
['text':' have received non-empty inputs.','line_number':169,'multiline':False]
['text':' launch all_reduce to unblock other peer processes','line_number':172,'multiline':False]
['text':' Leave grad_input, grad_weight and grad_bias as None, which will be','line_number':181,'multiline':False]
['text':' interpreted by the autograd engine as Tensors full of zeros.','line_number':182,'multiline':False]
['text':' use output storage as temporary buffer','line_number':210,'multiline':False]
['text':' compute first feature map normalization','line_number':219,'multiline':False]
['text':' reuse computations for next feature maps normalization','line_number':223,'multiline':False]
['text':' by adding the next feature map and removing the previous','line_number':224,'multiline':False]
