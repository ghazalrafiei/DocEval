['text':' __torch_function__ runs before the pydispatcher so we need to manually use the same','line_number':14,'multiline':False]
['text':' decompositions indexed by their torch equivalent','line_number':15,'multiline':False]
['text':' func: (input_decomp, data_decomp)','line_number':17,'multiline':False]
['text':' all of the RNN decomps run linear with the batch dimension second, even if batch_first was set','line_number':24,'multiline':False]
['text':' to support packed sequences, we need to allow for smaller batches. Expanded weights represents the largest batch','line_number':41,'multiline':False]
['text':' ExpandedWeight represents a weight (parameter) Tensor that has an expanded','line_number':71,'multiline':False]
['text':' batch dimension. Operations on the ExpandedWeight Tensor act exactly like','line_number':72,'multiline':False]
['text':' those without an expanded batch dimension but a call to .backward() populates','line_number':73,'multiline':False]
['text':' the original (unexpanded) tensor with per-sample-gradients for in the grad_sample field','line_number':74,'multiline':False]
['text':'','line_number':75,'multiline':False]
['text':' ExpandedWeight has a fallback that always fails since we cannot know what the batch','line_number':76,'multiline':False]
['text':' dimension of the input tensor is and therefore cannot know if this is a valid call','line_number':77,'multiline':False]
['text':'','line_number':78,'multiline':False]
['text':' This is a __torch_function__ object but it could have also been a Tensor Extension','line_number':79,'multiline':False]
['text':' with a dispatch key.','line_number':80,'multiline':False]
['text':'','line_number':81,'multiline':False]
['text':' Needs to be a tensor subclass to allow reparamaterization','line_number':82,'multiline':False]
['text':' in aten, choosing the input or data variants is done by parsing logic. This mimics some of that','line_number':106,'multiline':False]
['text':' data variant uses a list here','line_number':108,'multiline':False]
['text':' since we aren't using the fused cuda kernels for RNNs, don't do this','line_number':115,'multiline':False]
['text':' We cannot use a fallback here because we do not know the batch dimension for any regular tensor inputs,','line_number':119,'multiline':False]
['text':' i.e. torch.add(torch.Tensor, ExpandedWeight)','line_number':120,'multiline':False]
