['text':' NOTE [ device and dtype of a PackedSequence ]','line_number':70,'multiline':False]
['text':'','line_number':71,'multiline':False]
['text':' See the note above in doc string (starting with ":attr:`data` can be on','line_number':72,'multiline':False]
['text':' arbitrary device...").','line_number':73,'multiline':False]
['text':' Why not convert `batch_sizes`?','line_number':75,'multiline':False]
['text':' See NOTE [ device and dtype of a PackedSequence ]','line_number':76,'multiline':False]
['text':' Tests to see if 'cuda' should be added to kwargs','line_number':82,'multiline':False]
['text':' Why not convert `batch_sizes`?','line_number':132,'multiline':False]
['text':' See NOTE [ device and dtype of a PackedSequence ]','line_number':133,'multiline':False]
['text':' Does not forward device or dtype arg/kwargs, device is set from data.device','line_number':138,'multiline':False]
['text':' TorchScript doesn't support constructors on named tuples, so we use this helper','line_number':154,'multiline':False]
['text':' method to construct PackedSequence','line_number':155,'multiline':False]
['text':' NB: if unsorted_indices is provided, it should be the inverse permutation','line_number':162,'multiline':False]
['text':' to sorted_indices. Don't assert it here because the PackedSequence ctor','line_number':163,'multiline':False]
['text':' should only be used internally.','line_number':164,'multiline':False]
['text':' support being called as `PackedSequence(data, batch_sizes, sorted_indices)`','line_number':169,'multiline':False]
['text':' TODO: Re-enable this check (.type isn't supported in TorchScript)','line_number':171,'multiline':False]
['text':' support being called as `PackedSequence((data, batch_sizes), *, sorted_indices)`','line_number':181,'multiline':False]
['text':' NOTE: .pyi stub allows Iterable[Tensor], but for JIT-compatibility we need to be more restrictive here.','line_number':341,'multiline':False]
['text':' JIT doesn't support `Iterable`','line_number':383,'multiline':False]
['text':' In JIT context this leads to,','line_number':389,'multiline':False]
['text':' RuntimeError: cannot statically infer the expected size of a list in this context','line_number':390,'multiline':False]
['text':' For JIT, we only support Union[Tensor, Tuple[Tensor]]','line_number':393,'multiline':False]
['text':' assuming trailing dimensions and type of all the Tensors','line_number':397,'multiline':False]
['text':' in sequences are same and fetching those from sequences[0]','line_number':398,'multiline':False]
