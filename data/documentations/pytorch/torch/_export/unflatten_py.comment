['text':' Assign attribute 'from_obj' to the qualified name 'target' on 'to_module','line_number':19,'multiline':False]
['text':' This installs empty Modules where none exist yet if they are subpaths of target','line_number':20,'multiline':False]
['text':' If it is a tensor and not a parameter attribute of a module, it should be a named buffer.','line_number':36,'multiline':False]
['text':' So, we register it as a named buffer in the target module.','line_number':37,'multiline':False]
['text':' Dynamo cannot trace through torch.fx.Interpreter, so fall back to','line_number':66,'multiline':False]
['text':' GraphModule codegen in this instance.','line_number':67,'multiline':False]
['text':' Handle **kwargs. FX only natively supports positional','line_number':71,'multiline':False]
['text':' arguments (through placeholders). So in order to pass in','line_number':72,'multiline':False]
['text':' kwargs, we must correspond the names of the placeholders with','line_number':73,'multiline':False]
['text':' the keys in the kwarg dict.','line_number':74,'multiline':False]
['text':' Assert that the kwargs passed in exactly match the positional','line_number':81,'multiline':False]
['text':' arguments specified by the GraphModule. This should be','line_number':82,'multiline':False]
['text':' guaranteed by the unflattening process.','line_number':83,'multiline':False]
['text':' We need to "finalize" because GraphModule populates its own state_dict','line_number':93,'multiline':False]
['text':' based on the get_attrs observed in the graph. So we need to fully','line_number':94,'multiline':False]
['text':' construct the graph and call _sink_params before generating this','line_number':95,'multiline':False]
['text':' GraphModule.','line_number':96,'multiline':False]
['text':' need to set `graph_module` directly on the dict to avoid it getting','line_number':98,'multiline':False]
['text':' registered as a submodule.','line_number':99,'multiline':False]
['text':' Cache arg names for kwarg handling (see forward())','line_number':103,'multiline':False]
['text':' Check all input nodes has been processed.','line_number':150,'multiline':False]
['text':' TODO(zhxchen17) Use lineno map to dump the original stacktrace during error handling.','line_number':171,'multiline':False]
['text':' Replace all uses of the previously functional mutation with our copy_ output.','line_number':231,'multiline':False]
['text':' Remove the mutated buffer from the graph outputs, since we don't need to','line_number':234,'multiline':False]
['text':' thread it through anymore. We don't need to handle the inputs, which will','line_number':235,'multiline':False]
['text':' be handled by _sink_params.','line_number':236,'multiline':False]
['text':' Handle the root module correctly.','line_number':250,'multiline':False]
['text':' Mapping of nodes in the flat graph to nodes in this graph.','line_number':346,'multiline':False]
['text':' x is not in subgraph, create a new placeholder for subgraph','line_number':434,'multiline':False]
['text':' copy all meta fields, even if some fields might be irrelvant for','line_number':437,'multiline':False]
['text':' the placeholder node','line_number':438,'multiline':False]
['text':' Important to *prepend* the output to match how we are','line_number':449,'multiline':False]
['text':' inserting placeholder nodes.','line_number':450,'multiline':False]
['text':' Iterate through nodes we have copied into self.graph.','line_number':481,'multiline':False]
['text':' external user node, need to expose as an output','line_number':485,'multiline':False]
['text':' Rewrite outputs in parent module','line_number':498,'multiline':False]
['text':' Use Proxy to record getitem access.','line_number':506,'multiline':False]
['text':' type: ignore[index]','line_number':507,'multiline':False]
['text':' Copy all graph inputs','line_number':524,'multiline':False]
['text':' Copy graph outputs','line_number':534,'multiline':False]
['text':' Walk through the graph, building up a new graph with the right submodules','line_number':545,'multiline':False]
['text':' We want the output node of the original graph to be handled','line_number':555,'multiline':False]
['text':' specially by the outermost stack frame (in run_outer). So','line_number':556,'multiline':False]
['text':' skip finalization here.','line_number':557,'multiline':False]
['text':' We've reached the end of the graph. Wrap up all the existing stack frames.','line_number':560,'multiline':False]
['text':' This means that the current module is done executing and the','line_number':570,'multiline':False]
['text':' current node is the beginning of a new module.','line_number':571,'multiline':False]
['text':'','line_number':572,'multiline':False]
['text':' In this case, we should finalize this module and return without','line_number':573,'multiline':False]
['text':' incrementing the node counter.','line_number':574,'multiline':False]
['text':' This means that the current node represents the execution of a new','line_number':583,'multiline':False]
['text':' module.','line_number':584,'multiline':False]
['text':' Run a nested version of module outliner from the current node','line_number':587,'multiline':False]
['text':' counter. Once it is complete, continue from that point.','line_number':588,'multiline':False]
['text':' The only remaining possibility is that we are in the right stack','line_number':602,'multiline':False]
['text':' frame. Copy the node into this frame's graph and increment the node counter.','line_number':603,'multiline':False]
['text':' We need to use _modules here instead of named_children(), because we','line_number':647,'multiline':False]
['text':' explicitly want duplicate modules to show up in the traversal.','line_number':648,'multiline':False]
['text':' Not all modules have graphs defined, if they are empty modules with no operations (like ParameterList)','line_number':653,'multiline':False]
['text':' Also remove from call_module nodes','line_number':659,'multiline':False]
['text':' If there's a mismatch beteewn scope name and state name, then there must be multuple scopes','line_number':670,'multiline':False]
['text':' pointing to the same state name, meaning some modules are shared. In such case, we can simply','line_number':671,'multiline':False]
['text':' skip updating the current node because another later iteration will take care of this input','line_number':672,'multiline':False]
['text':' node when the unique match between scope and state name occurs.','line_number':673,'multiline':False]
['text':' To make sure this always happen, we should enforce the invariant that no placeholder node','line_number':674,'multiline':False]
['text':' in the unflattened graph appears in inputs_to_state dict, which means all the extra input','line_number':675,'multiline':False]
['text':' nodes have been handled.','line_number':676,'multiline':False]
