['text':' TODO: implement ref.cast with an option to enforce safe casting','line_number':43,'multiline':False]
['text':' type: ignore[arg-type]','line_number':50,'multiline':False]
['text':' Passthrough None because some functions wrapped with type promotion','line_number':53,'multiline':False]
['text':' wrapper might have optional args','line_number':54,'multiline':False]
['text':' type: ignore[union-attr]','line_number':120,'multiline':False]
['text':' type: ignore[union-attr]','line_number':132,'multiline':False]
['text':' Override the return_dtype if a dtype arg is present and not None','line_number':139,'multiline':False]
['text':' dtype cannot be None','line_number':142,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':151,'multiline':False]
['text':' Returns True if resize is necessary','line_number':155,'multiline':False]
['text':' If the shapes are correct there's nothing to do','line_number':157,'multiline':False]
['text':' TODO: handle tuples of tensors','line_number':172,'multiline':False]
['text':' Checks same device','line_number':183,'multiline':False]
['text':' Checks safe cast','line_number':190,'multiline':False]
['text':' The wrapped function needs to convert the output parameters to ensure','line_number':208,'multiline':False]
['text':' compatability between the Python API (which always uses "out" as the','line_number':209,'multiline':False]
['text':' parameter name and may be a tuple) and the Aten API (which may have','line_number':210,'multiline':False]
['text':' multiple output parematers and use different parameter names such as','line_number':211,'multiline':False]
['text':' "grad_input", "indices" or "values".)','line_number':212,'multiline':False]
['text':' Use default in out name','line_number':216,'multiline':False]
['text':' type: ignore[arg-type]','line_number':254,'multiline':False]
['text':' Naively you might expect this assert to be true, but','line_number':258,'multiline':False]
['text':' it's not:','line_number':259,'multiline':False]
['text':'','line_number':260,'multiline':False]
['text':'   assert type(out) == type(result)','line_number':261,'multiline':False]
['text':'','line_number':262,'multiline':False]
['text':' The reason is that functions under this wrapper can','line_number':263,'multiline':False]
['text':' get registered to the Meta dispatch key, and that','line_number':264,'multiline':False]
['text':' means they can be executed in a context where tensor','line_number':265,'multiline':False]
['text':' subclasses are disabled (with no_dispatch), which is a','line_number':266,'multiline':False]
['text':' handy way for an is-a tensor subclass (e.g.,','line_number':267,'multiline':False]
['text':' FakeTensor) to have the normal meta backend create a','line_number':268,'multiline':False]
['text':' meta tensor, to be wrapped once it gets returned.','line_number':269,'multiline':False]
['text':' In this situation, you will get a FakeTensor as','line_number':270,'multiline':False]
['text':' the output tensor, but not the result--which will','line_number':271,'multiline':False]
['text':' be a normal meta tensor, but this is perfectly','line_number':272,'multiline':False]
['text':' harmless.','line_number':273,'multiline':False]
['text':' These two operations are done in-place','line_number':276,'multiline':False]
['text':' type: ignore[arg-type]','line_number':278,'multiline':False]
['text':' type: ignore[arg-type]','line_number':280,'multiline':False]
['text':' These two operations are done in-place','line_number':286,'multiline':False]
['text':' type: ignore[arg-type]','line_number':288,'multiline':False]
['text':' mypy does not see through  the definition of out_type given that it's in a different scope','line_number':291,'multiline':False]
['text':' type: ignore[operator]','line_number':292,'multiline':False]
['text':' Mark that the function now returns a tuple','line_number':300,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':306,'multiline':False]
['text':' type: ignore[arg-type]','line_number':307,'multiline':False]
['text':' In the special case of having a single tensor out parameter with a','line_number':314,'multiline':False]
['text':' name other than out, add a special annotation to name the parameter','line_number':315,'multiline':False]
['text':' Add an indicator attribute that can be used in special cases','line_number':319,'multiline':False]
['text':' where having a function wrapped by `out_wrapper` is not desirable e.g.','line_number':320,'multiline':False]
['text':' jit','line_number':321,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':322,'multiline':False]
['text':' type: ignore[arg-type]','line_number':347,'multiline':False]
['text':' TODO: There is a subtle bug here: prims like copy_to','line_number':360,'multiline':False]
['text':' return their input argument after mutating it; and custom','line_number':361,'multiline':False]
['text':' autograd function will incorrectly turn the result into','line_number':362,'multiline':False]
['text':' a view which will fail test_python_ref_executor tests.','line_number':363,'multiline':False]
['text':' At the moment, we sidestep this by observing that the','line_number':364,'multiline':False]
['text':' unit tests don't ever try to run the executor with','line_number':365,'multiline':False]
['text':' autograd, so we don't exercise the buggy case, but if','line_number':366,'multiline':False]
['text':' you ever want to feed autograd through this, be aware','line_number':367,'multiline':False]
['text':' of it!  We need a way of properly implementing autograd','line_number':368,'multiline':False]
['text':' for mutating operations in Python to do this.','line_number':369,'multiline':False]
['text':' TODO: when tracing this will add torch tensors and not TensorMeta objects','line_number':377,'multiline':False]
['text':' to the trace -- we should fix this by adding a tracing context and NumberMeta classes','line_number':378,'multiline':False]
['text':' TODO: this wrapper is currently untested','line_number':379,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':398,'multiline':False]
