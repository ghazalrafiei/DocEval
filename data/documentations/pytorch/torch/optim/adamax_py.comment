['text':' State initialization','line_number':74,'multiline':False]
['text':' kwonly args with defaults are not supported by functions compiled with torchscript issue #70627','line_number':190,'multiline':False]
['text':' setting this as kwarg for now as functional API is compiled by torch/distributed/optim','line_number':191,'multiline':False]
['text':' update step','line_number':263,'multiline':False]
['text':' Update biased first moment estimate.','line_number':275,'multiline':False]
['text':' Update the exponentially weighted infinity norm.','line_number':277,'multiline':False]
['text':' Update steps','line_number':323,'multiline':False]
['text':' If steps are on CPU, foreach will fall back to the slow path, which is a for-loop calling t.add(1) over','line_number':324,'multiline':False]
['text':' and over. 1 will then be wrapped into a Tensor over and over again, which is slower than if we just','line_number':325,'multiline':False]
['text':' wrapped it once now. The alpha is required to assure we go to the right overload.','line_number':326,'multiline':False]
['text':' Re-use the intermediate memory (grouped_grads) already allocated for maximize','line_number':334,'multiline':False]
['text':' Update biased first moment estimate.','line_number':339,'multiline':False]
['text':' Update the exponentially weighted infinity norm.','line_number':342,'multiline':False]
