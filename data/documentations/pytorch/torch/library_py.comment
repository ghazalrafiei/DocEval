['text':' Set containing the combination of (namespace, operator, DispatchKey) for which a new kernel has been registered','line_number':20,'multiline':False]
['text':' The keys in the set are of the form `namespace + "/" + op_name + "/" + dispatch_key`.','line_number':21,'multiline':False]
['text':' This set is maintained to ensure that two libraries don't try to override the exact same functionality to avoid','line_number':22,'multiline':False]
['text':' libraries calling into kernels not intended to be called.','line_number':23,'multiline':False]
['text':' prim is reserved by TorchScript interpreter','line_number':27,'multiline':False]
['text':' Use a finalizer to setup the "destructor" instead of __del__.','line_number':70,'multiline':False]
['text':' Python __del__ can lead to weird things (globals and locals may already','line_number':71,'multiline':False]
['text':' be gone when __del__ actually gets called!). finalizers help the','line_number':72,'multiline':False]
['text':' situation because it lets us capture references and keeps them alive','line_number':73,'multiline':False]
['text':' This is added because we also want to disallow PURE_FUNCTION alias analysis which is a valid','line_number':99,'multiline':False]
['text':' AliasAnalysis type in C++','line_number':100,'multiline':False]
['text':' TODO: in future, add more info about where the existing function is registered (this info is','line_number':145,'multiline':False]
['text':' today already returned by the C++ warning when impl is called but we error out before that)','line_number':146,'multiline':False]
['text':' Internally, we shouldn't be registering meta kernels for any operators that','line_number':156,'multiline':False]
['text':' have CompositeImplicitAutograd kernels.','line_number':157,'multiline':False]
['text':' Instead, we should be letting those decompositions run, and writing meta kernels','line_number':158,'multiline':False]
['text':' only for the base operators.','line_number':159,'multiline':False]
['text':' We also support passing a DispatchKey to impl. Please prefer using','line_number':310,'multiline':False]
['text':' the higher-level torch.library APIs and only pass DispatchKey to','line_number':311,'multiline':False]
['text':' torch.library.impl with caution (or even better, don't use this','line_number':312,'multiline':False]
['text':' option and file an issue on GitHub for what you need).','line_number':313,'multiline':False]
['text':' We don't advertise this to users because','line_number':314,'multiline':False]
['text':' it is very easy to shoot yourself in the foot.','line_number':315,'multiline':False]
['text':' This is technically not correct, because although all device_type','line_number':338,'multiline':False]
['text':' DispatchKeys are included in CompositeExplicitAutograd,','line_number':339,'multiline':False]
['text':' not everything in CompositeExplicitAutograd is associated with a','line_number':340,'multiline':False]
['text':' device_type. I don't really care that much about the difference.','line_number':341,'multiline':False]
['text':' Can be none if you call impl_abstract from somewhere there isn't a module','line_number':424,'multiline':False]
['text':' (e.g. __main__)','line_number':425,'multiline':False]
['text':' TODO(rzou): We're gonna need to stage this change with torchvision,','line_number':428,'multiline':False]
['text':' since torchvision is github first.','line_number':429,'multiline':False]
['text':' If the op was defined in C++, then we want to make sure there was an','line_number':450,'multiline':False]
['text':' m.impl_abstract_pystub(module, ...) call and that the module is the','line_number':451,'multiline':False]
['text':' same as the module that called torch.library.impl_abstract.','line_number':452,'multiline':False]
['text':' NOTE [ctx inside the fake implementation]','line_number':489,'multiline':False]
['text':' If a user has an operator with data-dependent output shape, then when writing','line_number':490,'multiline':False]
['text':' a fake implementation they must query the current ctx and use methods on the','line_number':491,'multiline':False]
['text':' ctx to construct a new unbacked symint.','line_number':492,'multiline':False]
['text':'','line_number':493,'multiline':False]
['text':' This is done via us setting the global_ctx_getter function every time a fake','line_number':494,'multiline':False]
['text':' implementation is invoked.','line_number':495,'multiline':False]
