['text':' type: ignore[attr-defined] # noqa: B950','line_number':15,'multiline':False]
['text':' Pairs of (function, op_name)','line_number':18,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':91,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':100,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':101,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':102,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':103,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':105,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':108,'multiline':False]
['text':' ops in torch.functional are bound to torch','line_number':111,'multiline':False]
['text':' in these cases, we want to resolve the function to their python implementation','line_number':112,'multiline':False]
['text':' instead looking up a builtin "aten::" schema','line_number':113,'multiline':False]
['text':' eventually ops should encompass all of torch/functional.py, (torch.functional.__all__)','line_number':117,'multiline':False]
['text':' but we are currently only able to compile some of the functions. additionally,','line_number':118,'multiline':False]
['text':' some functions directly map to their aten:: implementations.','line_number':119,'multiline':False]
['text':' TODO: add support for more ops','line_number':120,'multiline':False]
['text':' lazily built to ensure the correct initialization order','line_number':141,'multiline':False]
['text':' Fixup inconsistency in segment_reduce','line_number':157,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':167,'multiline':False]
['text':' populate the _builtin_table from _builtin_ops','line_number':175,'multiline':False]
