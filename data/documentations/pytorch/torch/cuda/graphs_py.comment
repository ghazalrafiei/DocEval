['text':' Define dummy base classes','line_number':8,'multiline':False]
['text':' noqa: F401','line_number':15,'multiline':False]
['text':' Python shim helps Sphinx process docstrings more reliably.','line_number':30,'multiline':False]
['text':' Python shim helps Sphinx process docstrings more reliably.','line_number':42,'multiline':False]
['text':' noqa: B950','line_number':69,'multiline':False]
['text':' noqa: B950','line_number':142,'multiline':False]
['text':' Lazy-init of default_capture_stream helps avoid circular-import errors.','line_number':153,'multiline':False]
['text':' Not thread safe, but graphs already have the general (explicitly documented)','line_number':154,'multiline':False]
['text':' restriction that only one capture may be underway at a time in the process.','line_number':155,'multiline':False]
['text':' Free as much memory as we can for the graph','line_number':169,'multiline':False]
['text':' Stackoverflow seems comfortable with this pattern','line_number':174,'multiline':False]
['text':' https://stackoverflow.com/questions/26635684/calling-enter-and-exit-manually#39172487','line_number':175,'multiline':False]
['text':' returning None should propagate exceptions from either capture_end or stream_ctx.__exit__()','line_number':185,'multiline':False]
['text':' If a callable is an nn.Module, its graph's full input surface is the args the user explicitly','line_number':291,'multiline':False]
['text':' passes to forward (ie, its sample_args) AND the module's parameter attributes.','line_number':292,'multiline':False]
['text':' Warmup','line_number':308,'multiline':False]
['text':' Hopefully prevents cudnn benchmarking and other lazy-initialization cuda work','line_number':309,'multiline':False]
['text':' from ending up in any captures.','line_number':310,'multiline':False]
['text':' All captures here share a mempool. To avoid replays corrupting each other's memory,','line_number':330,'multiline':False]
['text':' the safest approach is to capture all passes in the same order they'll run:','line_number':331,'multiline':False]
['text':' fwd 1, fwd 2, ... fwd N, then bwd N, bwd N-1, ... bwd 1.','line_number':332,'multiline':False]
['text':' Capture forward graphs','line_number':334,'multiline':False]
['text':' Capture backward graphs in reverse order','line_number':345,'multiline':False]
['text':' For now, assumes all static_outputs require grad','line_number':354,'multiline':False]
['text':' assert all(o.requires_grad for o in static_outputs), "Outputs of graphed callables must require grad."','line_number':355,'multiline':False]
['text':' Constructs a tuple suitable for returning from Graphed.backward:','line_number':369,'multiline':False]
['text':' Pads out the actually-needed grads with Nones in gradient slots for inputs that don't require grad.','line_number':370,'multiline':False]
['text':' I couldn't think of a slick one-liner for this pattern.','line_number':371,'multiline':False]
['text':' type: ignore[arg-type]','line_number':379,'multiline':False]
['text':' type: ignore[assignment]','line_number':380,'multiline':False]
['text':' Reverses the most recent two lists','line_number':385,'multiline':False]
['text':' Now for every per_callable list, per_callable_*[i] holds the stuff for the ith callable.','line_number':388,'multiline':False]
['text':' At this stage, only the user args may (potentially) be new tensors.','line_number':404,'multiline':False]
['text':' don't copy if autograd gods have been kind and the','line_number':418,'multiline':False]
['text':' incoming grad is already in the right place','line_number':419,'multiline':False]
['text':' Input args that didn't require grad expect a None gradient.','line_number':424,'multiline':False]
['text':' Runs the autograd function with inputs == all inputs to the graph that might require grad','line_number':431,'multiline':False]
['text':' (explicit user args + module parameters)','line_number':432,'multiline':False]
['text':' Assumes module params didn't change since capture.','line_number':433,'multiline':False]
['text':' Put together the final graphed callables','line_number':440,'multiline':False]
['text':' If the module's training-or-eval state matches what we graphed,','line_number':459,'multiline':False]
['text':' run the graph, otherwise run the original forward method','line_number':460,'multiline':False]
['text':' type: ignore[assignment]','line_number':468,'multiline':False]
