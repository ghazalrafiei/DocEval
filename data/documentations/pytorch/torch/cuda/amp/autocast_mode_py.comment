['text':' type: ignore[assignment]','line_number':11,'multiline':False]
['text':' TODO: discuss a unified TorchScript-friendly API for autocast','line_number':43,'multiline':False]
['text':' type: ignore[override]','line_number':44,'multiline':False]
['text':' Casts Tensors and containers of Tensors.  Special-cases passthroughs for strings and np.ndarrays, which','line_number':55,'multiline':False]
['text':' may be falsely detected as "Iterables."','line_number':56,'multiline':False]
['text':' custom_fwd is a decorator that may or may not be used with arguments, following','line_number':81,'multiline':False]
['text':' https://github.com/dabeaz/python-cookbook/tree/master/src/9/defining_a_decorator_that_takes_an_optional_argument.','line_number':82,'multiline':False]
['text':' this works:','line_number':83,'multiline':False]
['text':'     @custom_fwd','line_number':84,'multiline':False]
['text':'     def forward(...):','line_number':85,'multiline':False]
['text':' this also works:','line_number':86,'multiline':False]
['text':'     @custom_fwd(cast_inputs=torch.float)','line_number':87,'multiline':False]
['text':'     def forward(...):','line_number':88,'multiline':False]
['text':' Autograd ensures incoming gradients are the same type as forward outputs.  Allowing a separate','line_number':128,'multiline':False]
['text':' cast_inputs argument on custom_bwd is unnecessary and could cause errors if it doesn't match','line_number':129,'multiline':False]
['text':' cast_inputs supplied to custom_fwd.','line_number':130,'multiline':False]
