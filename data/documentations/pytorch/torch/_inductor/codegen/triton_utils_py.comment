['text':' TODO: Remove fp8 special handling when Triton supports PyTorch fp8 dtypes.','line_number':15,'multiline':False]
['text':' Related PR: https://github.com/openai/triton/pull/2279/','line_number':16,'multiline':False]
['text':' had unwrapped 0d tensor as scalar','line_number':24,'multiline':False]
['text':' From triton/runtime/jit.py','line_number':34,'multiline':False]
['text':' `None` is nullptr.  Implicitly convert to *i8.','line_number':35,'multiline':False]
['text':' TODO(voz): These are kinda redundant, if we can solve out statically_known_multiple_of with','line_number':72,'multiline':False]
['text':' _maybe_evaluate_static...','line_number':73,'multiline':False]
