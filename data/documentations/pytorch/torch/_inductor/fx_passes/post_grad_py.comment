['text':' First pass_patterns[0] are applied, then [1], then [2]','line_number':54,'multiline':False]
['text':' patterns applied only in inference','line_number':60,'multiline':False]
['text':' has some issues with mutation in inference mode','line_number':72,'multiline':False]
['text':' Keep this last, since it introduces mutation. Look at','line_number':109,'multiline':False]
['text':' ./fx_passes/README.md for a discussion of mutation invariants.','line_number':110,'multiline':False]
['text':' move node's producers right before it','line_number':133,'multiline':False]
['text':' only reorder nodes before the first copy_ in the graph.','line_number':138,'multiline':False]
['text':' copy_ will appear at the end of functionalized graphs when there is mutation on inputs,','line_number':139,'multiline':False]
['text':' and this reordering doesnt work well with mutation','line_number':140,'multiline':False]
['text':'###############################################################################','line_number':170,'multiline':False]
['text':' Actual patterns below this point.','line_number':171,'multiline':False]
['text':' Priority of patterns is:','line_number':172,'multiline':False]
['text':'   - later output nodes first','line_number':173,'multiline':False]
['text':'   - order patterns are defined in','line_number':174,'multiline':False]
['text':'###############################################################################','line_number':175,'multiline':False]
['text':' bitshift numerics in triton and pytorch don't match for torch.int8','line_number':201,'multiline':False]
['text':' cumsum promotes all integral types to int64','line_number':307,'multiline':False]
['text':' only replace the output node, not all nodes','line_number':318,'multiline':False]
['text':' TODO(jansel): rewrite this as a bmm?','line_number':359,'multiline':False]
['text':' compute output sizes','line_number':369,'multiline':False]
['text':' Optimization is optional, because we can just not fold the cat','line_number':442,'multiline':False]
['text':' size should be within first.get_size()[dim] such that the optimization is valid.','line_number':443,'multiline':False]
['text':' For negative `end`, we currently fallback to not optimizing.','line_number':444,'multiline':False]
['text':' fold 2 cats into 1 cat','line_number':446,'multiline':False]
['text':' don't expect to hit this case, just fall back','line_number':456,'multiline':False]
['text':' The dim of split and cat should match for passthrough','line_number':474,'multiline':False]
['text':' All parts of split should be included in the cat','line_number':482,'multiline':False]
['text':' The order of get_item_args should same with cat_node used.','line_number':485,'multiline':False]
['text':' For example, if the split_node like split_with_sizes(input, [2, 2, 3], 1),','line_number':486,'multiline':False]
['text':' the cat node should be like cat([get_item(0), get_item(1), get_item(2)], 1).','line_number':487,'multiline':False]
['text':' Note, we also always have a check for identical metadata, which is why these','line_number':588,'multiline':False]
['text':' are safe','line_number':589,'multiline':False]
['text':' See fx_passes/README.md for a discussion of why this is','line_number':622,'multiline':False]
['text':' necessary.','line_number':623,'multiline':False]
['text':' _c10d_functional ops are only available when torch','line_number':656,'multiline':False]
['text':' is built with USE_DISTRIBUTED=1.','line_number':657,'multiline':False]
['text':' If the target is a getitem and it indexes a possible clone,','line_number':693,'multiline':False]
['text':' then skip over it','line_number':694,'multiline':False]
['text':' Skip all users before node','line_number':712,'multiline':False]
['text':' Skip over the copy_ epilogue node that could get reinplaced','line_number':715,'multiline':False]
['text':' If mutated arg is view of any of the inputs of the graph,','line_number':741,'multiline':False]
['text':' do not allow for inplacing.','line_number':742,'multiline':False]
['text':' This would require more sophisticated algorithm to handle','line_number':743,'multiline':False]
['text':' TODO(yifu): this doesn't properly remove copy epilogues for','line_number':754,'multiline':False]
['text':' ops that mutate multiple inputs. Need to revise the copy','line_number':755,'multiline':False]
['text':' node tracking logic to support the case.','line_number':756,'multiline':False]
['text':' inplaceable_triton_ops take an additional argument called','line_number':762,'multiline':False]
['text':' tensors_to_clone which contain a list of tensors to clone','line_number':763,'multiline':False]
['text':' This pass iterates over them and sees which ones are safe','line_number':764,'multiline':False]
['text':' to eliminate (i.e. no longer need the clones)','line_number':765,'multiline':False]
['text':' the cat node has other users: can't eliminate','line_number':827,'multiline':False]
['text':' the dim of the cat and split should match','line_number':831,'multiline':False]
['text':' the number of input tensors in cat and the','line_number':838,'multiline':False]
['text':' length of the split sizes should match','line_number':839,'multiline':False]
['text':' each cat input tensor's size along dim','line_number':844,'multiline':False]
['text':' should match the corresponding split size','line_number':845,'multiline':False]
['text':' Input is a number','line_number':912,'multiline':False]
['text':' Shape mismatch','line_number':918,'multiline':False]
['text':' not handling multiple target devices initially','line_number':1096,'multiline':False]
['text':' which constructors cannot be moved to cuda','line_number':1116,'multiline':False]
['text':' For any node in the graph, which constructors does it have a dependency on','line_number':1119,'multiline':False]
['text':' if a cpu node has a dependency on two different cpu constructors,','line_number':1122,'multiline':False]
['text':' then if either constructor cannot be moved to cuda, the other cannot as well.','line_number':1123,'multiline':False]
['text':' In this case any node with a dependency on one will have a dependency on the other','line_number':1124,'multiline':False]
['text':' could use union find but not worth complexity here','line_number':1132,'multiline':False]
['text':' this node was used on a op which takes in multiple devices and output a cuda','line_number':1152,'multiline':False]
['text':' tensor. we can convert its cpu input to cuda without making further changes','line_number':1153,'multiline':False]
['text':' otherwise, we should continue look at its downstream uses','line_number':1162,'multiline':False]
