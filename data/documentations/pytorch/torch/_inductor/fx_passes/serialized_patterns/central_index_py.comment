['text':' This is an auto-generated file. Please do not modify it by hand.','line_number':1,'multiline':False]
['text':' To re-generate, run:','line_number':2,'multiline':False]
['text':' cd ~/pytorch && python','line_number':3,'multiline':False]
['text':' torchgen/fuse_attention_patterns/gen_attention_patterns.py','line_number':4,'multiline':False]
['text':' noqa: F401','line_number':76,'multiline':False]
['text':' TODO - could add more validation that the same set of decomps used when','line_number':81,'multiline':False]
['text':' tracing SDPA are also used in current context. softmax, dropout, etc','line_number':82,'multiline':False]
['text':' decomp use is stable so not an issue in practice.','line_number':83,'multiline':False]
