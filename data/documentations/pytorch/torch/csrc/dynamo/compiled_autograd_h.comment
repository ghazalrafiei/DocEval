['text':' see [Note: Compiled Autograd]','line_number':10,'multiline':False]
['text':' Note: int value is still needed when dynamic to pass as an arg','line_number':16,'multiline':False]
['text':' Key to find the next node in the shadow graph.  We use C++ RTTI for the','line_number':36,'multiline':False]
['text':' type of the node (ntype), then a key generated with a visitor pattern.','line_number':37,'multiline':False]
['text':' don't bother hashing the key data, common case 1 cache entry per node','line_number':57,'multiline':False]
['text':' Represents a de-duplicated tensor that will be passed into the graph','line_number':98,'multiline':False]
['text':' Manages a collection of TensorArgs and mappings from Tensors/SavedVariables','line_number':112,'multiline':False]
['text':' to them.  This also allows us to unpack SavedVariable exactly once and','line_number':113,'multiline':False]
['text':' store the unpacked Tensor.','line_number':114,'multiline':False]
['text':' TODO(jansel): Here we unpack the SavedVariable exactly once.  This might','line_number':141,'multiline':False]
['text':' fire SavedTensor hooks.  In the future we should try to put saved tensor','line_number':142,'multiline':False]
['text':' hooks into the graph.','line_number':143,'multiline':False]
['text':' the concrete tensors that will get passed into the graph as inputs','line_number':150,'multiline':False]
['text':' Every TensorArg from this is actually owned by _args (or _undefined) and','line_number':155,'multiline':False]
['text':' that's why we have an un-owned pointer here.','line_number':156,'multiline':False]
['text':' id=0 used by _undefined','line_number':159,'multiline':False]
['text':' CompiledNodeArgs builds a representation of the constant values found','line_number':182,'multiline':False]
['text':' across all the nodes in the compiled graph, via 'collect' overloads. The','line_number':183,'multiline':False]
['text':' collected constants are specialized on by concatenation into a cache key.','line_number':184,'multiline':False]
['text':' Tensor, symint arguments (which are lifted to become graph inputs rather','line_number':185,'multiline':False]
['text':' than specialized on) are forwarded to the compiler and not included in the','line_number':186,'multiline':False]
['text':' key.','line_number':187,'multiline':False]
['text':' including these in the cache key means dynamo-level tensor guards can','line_number':193,'multiline':False]
['text':' be skipped','line_number':194,'multiline':False]
['text':' Note: this is only capturing the ID of the node not everything','line_number':287,'multiline':False]
['text':' contained inside it.  This is used for tracking connections between','line_number':288,'multiline':False]
['text':' nodes and the actual details of the node itself must be handled by','line_number':289,'multiline':False]
['text':' a seperate call to `node->compiled_args()`.','line_number':290,'multiline':False]
['text':' for validate_outputs','line_number':304,'multiline':False]
['text':' index','line_number':364,'multiline':False]
['text':' we expect sizes to be small, so try to cram them into a single byte','line_number':399,'multiline':False]
['text':' first write a byte indicating the path we followed, then the data','line_number':404,'multiline':False]
['text':' 3 bytes','line_number':406,'multiline':False]
['text':' 5 bytes','line_number':410,'multiline':False]
['text':' 9 bytes','line_number':414,'multiline':False]
['text':' happy case, 1 byte','line_number':419,'multiline':False]
['text':' SwapSavedVariables is used during the tracing/compilation phase after a','line_number':480,'multiline':False]
['text':' cache-miss. It swaps any 'lifted' inputs (tensors, symints) to proxy nodes,','line_number':481,'multiline':False]
['text':' allows tracing to happen, then swaps them back afterwards.','line_number':482,'multiline':False]
['text':' dynamic shape','line_number':512,'multiline':False]
['text':' need for symints used by validate_outputs','line_number':521,'multiline':False]
['text':' Note: we need count here to support duplicate calls to before()','line_number':653,'multiline':False]
['text':' which happen when we have multiple autograd::Edge objects pointing','line_number':654,'multiline':False]
['text':' to the same autograd::Node','line_number':655,'multiline':False]
['text':' keep the value from the prior save()','line_number':666,'multiline':False]
['text':' restore the value on the last restore()','line_number':674,'multiline':False]
['text':' This is a borrowed reference, we do not increment ownership, or lower it,','line_number':686,'multiline':False]
['text':' it's lifecycle is entirely longer than this objects.','line_number':687,'multiline':False]
['text':' These mappings are used to save the prior values when we overwrite things','line_number':691,'multiline':False]
['text':' in before(). In after(), we use these to cleanup after ourselves.','line_number':692,'multiline':False]
['text':' namespace torch::dynamo::autograd','line_number':698,'multiline':False]
