['text':' WARNING: Be careful when adding new includes here. This header will be used','line_number':3,'multiline':False]
['text':' in model.so, and should not refer to any aten/c10 headers except the stable','line_number':4,'multiline':False]
['text':' C ABI defined in torch/csrc/inductor/aoti_torch/c/shim.h. The same rule','line_number':5,'multiline':False]
['text':' applies to other files under torch/csrc/inductor/aoti_runtime/.','line_number':6,'multiline':False]
['text':' FIXME: Currently, CPU and CUDA backend are mutually exclusive.','line_number':10,'multiline':False]
['text':' This is a temporary workaround. We need a better way to support','line_number':11,'multiline':False]
['text':' multi devices.','line_number':12,'multiline':False]
['text':' namespace aot_inductor','line_number':32,'multiline':False]
['text':' namespace torch','line_number':33,'multiline':False]
['text':' !USE_CUDA','line_number':35,'multiline':False]
['text':' namespace aot_inductor','line_number':48,'multiline':False]
['text':' namespace torch','line_number':49,'multiline':False]
['text':' USE_CUDA','line_number':51,'multiline':False]
