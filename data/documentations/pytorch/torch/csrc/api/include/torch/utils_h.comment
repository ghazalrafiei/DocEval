['text':'/ A RAII, thread-local guard that disabled gradient calculation.','line_number':12,'multiline':False]
['text':'/','line_number':13,'multiline':False]
['text':'/ Disabling gradient calculation is useful for inference, when you are sure','line_number':14,'multiline':False]
['text':'/ that you will not call `at::Tensor::backward`. It will reduce memory','line_number':15,'multiline':False]
['text':'/ consumption for computations that would otherwise have `requires_grad() ==','line_number':16,'multiline':False]
['text':'/ true`.','line_number':17,'multiline':False]
['text':'/','line_number':18,'multiline':False]
['text':'/ In this mode, the result of every computation will have','line_number':19,'multiline':False]
['text':'/ `requires_grad() == false`, even when the inputs have `requires_grad() ==','line_number':20,'multiline':False]
['text':'/ true`.','line_number':21,'multiline':False]
['text':'/','line_number':22,'multiline':False]
['text':'/ This context manager is thread-local; it will not affect computation','line_number':23,'multiline':False]
['text':'/ in other threads.','line_number':24,'multiline':False]
['text':'/','line_number':25,'multiline':False]
['text':'/ Example:','line_number':26,'multiline':False]
['text':'/ @code','line_number':27,'multiline':False]
['text':'/ auto x = torch::tensor({1.}, torch::requires_grad());','line_number':28,'multiline':False]
['text':'/ {','line_number':29,'multiline':False]
['text':'/   torch::NoGradGuard no_grad;','line_number':30,'multiline':False]
['text':'/   auto y = x * 2;','line_number':31,'multiline':False]
['text':'/   std::cout << y.requires_grad() << std::endl; // prints `false`','line_number':32,'multiline':False]
['text':'/ }','line_number':33,'multiline':False]
['text':'/ {','line_number':34,'multiline':False]
['text':'/   auto doubler = [](torch::Tensor x) {','line_number':35,'multiline':False]
['text':'/     torch::NoGradGuard no_grad;','line_number':36,'multiline':False]
['text':'/     return x * 2;','line_number':37,'multiline':False]
['text':'/   };','line_number':38,'multiline':False]
['text':'/   auto z = doubler(x);','line_number':39,'multiline':False]
['text':'/   std::cout << z.requires_grad() << std::endl; // prints `false`','line_number':40,'multiline':False]
['text':'/ }','line_number':41,'multiline':False]
['text':'/ @endcode','line_number':42,'multiline':False]
['text':'/ A RAII, thread-local guard that sets gradient calculation to on or off.','line_number':45,'multiline':False]
['text':'/','line_number':46,'multiline':False]
['text':'/ ``AutoGradMode`` will enable or disable grads based on its argument','line_number':47,'multiline':False]
['text':'/ `enabled`.','line_number':48,'multiline':False]
['text':'/','line_number':49,'multiline':False]
['text':'/ This context manager is thread-local; it will not affect computation','line_number':50,'multiline':False]
['text':'/ in other threads.','line_number':51,'multiline':False]
['text':'/','line_number':52,'multiline':False]
['text':'/ \param enabled: Flag whether to enable grad (``true``), or disable','line_number':53,'multiline':False]
['text':'/              (``false``). This can be used to conditionally enable','line_number':54,'multiline':False]
['text':'/              gradients.','line_number':55,'multiline':False]
['text':'/','line_number':56,'multiline':False]
['text':'/ Example:','line_number':57,'multiline':False]
['text':'/ @code','line_number':58,'multiline':False]
['text':'/ auto x = torch::tensor({1.}, torch::requires_grad());','line_number':59,'multiline':False]
['text':'/ {','line_number':60,'multiline':False]
['text':'/   torch::AutoGradMode enable_grad(true);','line_number':61,'multiline':False]
['text':'/   auto y = x * 2;','line_number':62,'multiline':False]
['text':'/   std::cout << y.requires_grad() << std::endl; // prints `true`','line_number':63,'multiline':False]
['text':'/ }','line_number':64,'multiline':False]
['text':'/ {','line_number':65,'multiline':False]
['text':'/   torch::AutoGradMode enable_grad(false);','line_number':66,'multiline':False]
['text':'/   auto y = x * 2;','line_number':67,'multiline':False]
['text':'/   std::cout << y.requires_grad() << std::endl; // prints `false`','line_number':68,'multiline':False]
['text':'/ }','line_number':69,'multiline':False]
['text':'/ @endcode','line_number':70,'multiline':False]
['text':'/ Sets the global random seed for all newly created CPU and CUDA tensors.','line_number':73,'multiline':False]
['text':' Called during new thread initialization','line_number':76,'multiline':False]
['text':' Returns the number of threads used in parallel region.','line_number':79,'multiline':False]
['text':' Sets the number of threads to be used in parallel region.','line_number':82,'multiline':False]
['text':' Returns the number of threads used for inter-op parallelism.','line_number':85,'multiline':False]
['text':' Sets the number of threads to be used for inter-op parallelism.','line_number':88,'multiline':False]
['text':' Returns true if both t1, t2 are undefined or both are defined and equal','line_number':91,'multiline':False]
['text':' RecordFunction API','line_number':98,'multiline':False]
['text':' namespace torch','line_number':116,'multiline':False]
