['text':'/ Options for the `ELU` module.','line_number':11,'multiline':False]
['text':'/','line_number':12,'multiline':False]
['text':'/ Example:','line_number':13,'multiline':False]
['text':'/ ```','line_number':14,'multiline':False]
['text':'/ ELU model(ELUOptions().alpha(42.42).inplace(true));','line_number':15,'multiline':False]
['text':'/ ```','line_number':16,'multiline':False]
['text':'/ The `alpha` value for the ELU formulation. Default: 1.0','line_number':18,'multiline':False]
['text':'/ can optionally do the operation in-place. Default: False','line_number':21,'multiline':False]
['text':'/ Options for `torch::nn::functional::elu`.','line_number':26,'multiline':False]
['text':'/','line_number':27,'multiline':False]
['text':'/ See the documentation for `torch::nn::ELUOptions` class to learn what','line_number':28,'multiline':False]
['text':'/ arguments are supported.','line_number':29,'multiline':False]
['text':'/','line_number':30,'multiline':False]
['text':'/ Example:','line_number':31,'multiline':False]
['text':'/ ```','line_number':32,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':33,'multiline':False]
['text':'/ F::elu(x, F::ELUFuncOptions().alpha(0.42).inplace(true));','line_number':34,'multiline':False]
['text':'/ ```','line_number':35,'multiline':False]
['text':' namespace functional','line_number':37,'multiline':False]
['text':' ============================================================================','line_number':39,'multiline':False]
['text':'/ Options for the `SELU` module.','line_number':41,'multiline':False]
['text':'/','line_number':42,'multiline':False]
['text':'/ Example:','line_number':43,'multiline':False]
['text':'/ ```','line_number':44,'multiline':False]
['text':'/ SELU model(SELUOptions().inplace(true));','line_number':45,'multiline':False]
['text':'/ ```','line_number':46,'multiline':False]
['text':' implicit ','line_number':48,'multiline':True]
['text':'/ can optionally do the operation in-place. Default: False','line_number':50,'multiline':False]
['text':'/ Options for `torch::nn::functional::selu`.','line_number':55,'multiline':False]
['text':'/','line_number':56,'multiline':False]
['text':'/ See the documentation for `torch::nn::SELUOptions` class to learn what','line_number':57,'multiline':False]
['text':'/ arguments are supported.','line_number':58,'multiline':False]
['text':'/','line_number':59,'multiline':False]
['text':'/ Example:','line_number':60,'multiline':False]
['text':'/ ```','line_number':61,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':62,'multiline':False]
['text':'/ F::selu(input, F::SELUFuncOptions(false));','line_number':63,'multiline':False]
['text':'/ ```','line_number':64,'multiline':False]
['text':' namespace functional','line_number':66,'multiline':False]
['text':' ============================================================================','line_number':68,'multiline':False]
['text':'/ Options for the `GLU` module.','line_number':70,'multiline':False]
['text':'/','line_number':71,'multiline':False]
['text':'/ Example:','line_number':72,'multiline':False]
['text':'/ ```','line_number':73,'multiline':False]
['text':'/ GLU model(GLUOptions(1));','line_number':74,'multiline':False]
['text':'/ ```','line_number':75,'multiline':False]
['text':' implicit ','line_number':77,'multiline':True]
['text':'/ the dimension on which to split the input. Default: -1','line_number':79,'multiline':False]
['text':'/ Options for `torch::nn::functional::glu`.','line_number':84,'multiline':False]
['text':'/','line_number':85,'multiline':False]
['text':'/ See the documentation for `torch::nn::GLUOptions` class to learn what','line_number':86,'multiline':False]
['text':'/ arguments are supported.','line_number':87,'multiline':False]
['text':'/','line_number':88,'multiline':False]
['text':'/ Example:','line_number':89,'multiline':False]
['text':'/ ```','line_number':90,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':91,'multiline':False]
['text':'/ F::glu(input, GLUFuncOptions(1));','line_number':92,'multiline':False]
['text':'/ ```','line_number':93,'multiline':False]
['text':' namespace functional','line_number':95,'multiline':False]
['text':' ============================================================================','line_number':97,'multiline':False]
['text':'/ Options for the `GELU` module.','line_number':99,'multiline':False]
['text':'/','line_number':100,'multiline':False]
['text':'/ Example:','line_number':101,'multiline':False]
['text':'/ ```','line_number':102,'multiline':False]
['text':'/ GELU model(GELUOptions().approximate("none"));','line_number':103,'multiline':False]
['text':'/ ```','line_number':104,'multiline':False]
['text':'/ Specifies the approximation to apply to the output.','line_number':106,'multiline':False]
['text':'/ Options for `torch::nn::functional::gelu`.','line_number':111,'multiline':False]
['text':'/','line_number':112,'multiline':False]
['text':'/ See the documentation for `torch::nn::GELUOptions` class to learn what','line_number':113,'multiline':False]
['text':'/ arguments are supported.','line_number':114,'multiline':False]
['text':'/','line_number':115,'multiline':False]
['text':'/ Example:','line_number':116,'multiline':False]
['text':'/ ```','line_number':117,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':118,'multiline':False]
['text':'/ F::gelu(input, F::GELUFuncOptions().approximate("none"));','line_number':119,'multiline':False]
['text':'/ ```','line_number':120,'multiline':False]
['text':' namespace functional','line_number':122,'multiline':False]
['text':' ============================================================================','line_number':124,'multiline':False]
['text':'/ Options for the `Hardshrink` module.','line_number':126,'multiline':False]
['text':'/','line_number':127,'multiline':False]
['text':'/ Example:','line_number':128,'multiline':False]
['text':'/ ```','line_number':129,'multiline':False]
['text':'/ Hardshrink model(HardshrinkOptions().lambda(42.42));','line_number':130,'multiline':False]
['text':'/ ```','line_number':131,'multiline':False]
['text':' implicit ','line_number':133,'multiline':True]
['text':'/ the `lambda` value for the Hardshrink formulation. Default: 0.5','line_number':135,'multiline':False]
['text':'/ Options for `torch::nn::functional::hardshrink`.','line_number':140,'multiline':False]
['text':'/','line_number':141,'multiline':False]
['text':'/ See the documentation for `torch::nn::HardshrinkOptions` class to learn what','line_number':142,'multiline':False]
['text':'/ arguments are supported.','line_number':143,'multiline':False]
['text':'/','line_number':144,'multiline':False]
['text':'/ Example:','line_number':145,'multiline':False]
['text':'/ ```','line_number':146,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':147,'multiline':False]
['text':'/ F::hardshrink(x, F::HardshrinkFuncOptions().lambda(0.42));','line_number':148,'multiline':False]
['text':'/ ```','line_number':149,'multiline':False]
['text':' namespace functional','line_number':151,'multiline':False]
['text':' ============================================================================','line_number':153,'multiline':False]
['text':'/ Options for the `Hardtanh` module.','line_number':155,'multiline':False]
['text':'/','line_number':156,'multiline':False]
['text':'/ Example:','line_number':157,'multiline':False]
['text':'/ ```','line_number':158,'multiline':False]
['text':'/ Hardtanh','line_number':159,'multiline':False]
['text':'/ model(HardtanhOptions().min_val(-42.42).max_val(0.42).inplace(true));','line_number':160,'multiline':False]
['text':'/ ```','line_number':161,'multiline':False]
['text':'/ minimum value of the linear region range. Default: -1','line_number':163,'multiline':False]
['text':'/ maximum value of the linear region range. Default: 1','line_number':166,'multiline':False]
['text':'/ can optionally do the operation in-place. Default: False','line_number':169,'multiline':False]
['text':'/ Options for `torch::nn::functional::hardtanh`.','line_number':174,'multiline':False]
['text':'/','line_number':175,'multiline':False]
['text':'/ See the documentation for `torch::nn::HardtanhOptions` class to learn what','line_number':176,'multiline':False]
['text':'/ arguments are supported.','line_number':177,'multiline':False]
['text':'/','line_number':178,'multiline':False]
['text':'/ Example:','line_number':179,'multiline':False]
['text':'/ ```','line_number':180,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':181,'multiline':False]
['text':'/ F::hardtanh(x,','line_number':182,'multiline':False]
['text':'/ F::HardtanhFuncOptions().min_val(-1.0).max_val(1.0).inplace(true));','line_number':183,'multiline':False]
['text':'/ ```','line_number':184,'multiline':False]
['text':' namespace functional','line_number':186,'multiline':False]
['text':' ============================================================================','line_number':188,'multiline':False]
['text':'/ Options for the `LeakyReLU` module.','line_number':190,'multiline':False]
['text':'/','line_number':191,'multiline':False]
['text':'/ Example:','line_number':192,'multiline':False]
['text':'/ ```','line_number':193,'multiline':False]
['text':'/ LeakyReLU model(LeakyReLUOptions().negative_slope(0.42).inplace(true));','line_number':194,'multiline':False]
['text':'/ ```','line_number':195,'multiline':False]
['text':'/ Controls the angle of the negative slope. Default: 1e-2','line_number':197,'multiline':False]
['text':'/ can optionally do the operation in-place. Default: False','line_number':200,'multiline':False]
['text':'/ Options for `torch::nn::functional::leaky_relu`.','line_number':205,'multiline':False]
['text':'/','line_number':206,'multiline':False]
['text':'/ See the documentation for `torch::nn::LeakyReLUOptions` class to learn what','line_number':207,'multiline':False]
['text':'/ arguments are supported.','line_number':208,'multiline':False]
['text':'/','line_number':209,'multiline':False]
['text':'/ Example:','line_number':210,'multiline':False]
['text':'/ ```','line_number':211,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':212,'multiline':False]
['text':'/ F::leaky_relu(x,','line_number':213,'multiline':False]
['text':'/ F::LeakyReLUFuncOptions().negative_slope(0.42).inplace(true));','line_number':214,'multiline':False]
['text':'/ ```','line_number':215,'multiline':False]
['text':' namespace functional','line_number':217,'multiline':False]
['text':' ============================================================================','line_number':219,'multiline':False]
['text':'/ Options for the `Softmax` module.','line_number':221,'multiline':False]
['text':'/','line_number':222,'multiline':False]
['text':'/ Example:','line_number':223,'multiline':False]
['text':'/ ```','line_number':224,'multiline':False]
['text':'/ Softmax model(SoftmaxOptions(1));','line_number':225,'multiline':False]
['text':'/ ```','line_number':226,'multiline':False]
['text':'/ Dimension along which Softmax will be computed.','line_number':230,'multiline':False]
['text':' ============================================================================','line_number':234,'multiline':False]
['text':'/ Options for `torch::nn::functional::softmax`.','line_number':238,'multiline':False]
['text':'/','line_number':239,'multiline':False]
['text':'/ Example:','line_number':240,'multiline':False]
['text':'/ ```','line_number':241,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':242,'multiline':False]
['text':'/ F::softmax(input, F::SoftmaxFuncOptions(1));','line_number':243,'multiline':False]
['text':'/ ```','line_number':244,'multiline':False]
['text':'/ Dimension along which Softmax will be computed.','line_number':248,'multiline':False]
['text':'/ the desired data type of returned tensor.','line_number':251,'multiline':False]
['text':'/ If specified, the input tensor is casted to `dtype` before the operation','line_number':252,'multiline':False]
['text':'/ is performed. This is useful for preventing data type overflows. Default:','line_number':253,'multiline':False]
['text':'/ None.','line_number':254,'multiline':False]
['text':' namespace functional','line_number':258,'multiline':False]
['text':' ============================================================================','line_number':260,'multiline':False]
['text':'/ Options for the `Softmin` module.','line_number':262,'multiline':False]
['text':'/','line_number':263,'multiline':False]
['text':'/ Example:','line_number':264,'multiline':False]
['text':'/ ```','line_number':265,'multiline':False]
['text':'/ Softmin model(SoftminOptions(1));','line_number':266,'multiline':False]
['text':'/ ```','line_number':267,'multiline':False]
['text':'/ Dimension along which Softmin will be computed.','line_number':271,'multiline':False]
['text':' ============================================================================','line_number':275,'multiline':False]
['text':'/ Options for `torch::nn::functional::softmin`.','line_number':279,'multiline':False]
['text':'/','line_number':280,'multiline':False]
['text':'/ Example:','line_number':281,'multiline':False]
['text':'/ ```','line_number':282,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':283,'multiline':False]
['text':'/ F::softmin(input, F::SoftminFuncOptions(1));','line_number':284,'multiline':False]
['text':'/ ```','line_number':285,'multiline':False]
['text':'/ Dimension along which Softmin will be computed.','line_number':289,'multiline':False]
['text':'/ the desired data type of returned tensor.','line_number':292,'multiline':False]
['text':'/ If specified, the input tensor is casted to `dtype` before the operation','line_number':293,'multiline':False]
['text':'/ is performed. This is useful for preventing data type overflows. Default:','line_number':294,'multiline':False]
['text':'/ None.','line_number':295,'multiline':False]
['text':' namespace functional','line_number':299,'multiline':False]
['text':' ============================================================================','line_number':301,'multiline':False]
['text':'/ Options for the `LogSoftmax` module.','line_number':303,'multiline':False]
['text':'/','line_number':304,'multiline':False]
['text':'/ Example:','line_number':305,'multiline':False]
['text':'/ ```','line_number':306,'multiline':False]
['text':'/ LogSoftmax model(LogSoftmaxOptions(1));','line_number':307,'multiline':False]
['text':'/ ```','line_number':308,'multiline':False]
['text':'/ Dimension along which LogSoftmax will be computed.','line_number':312,'multiline':False]
['text':' ============================================================================','line_number':316,'multiline':False]
['text':'/ Options for `torch::nn::functional::log_softmax`.','line_number':320,'multiline':False]
['text':'/','line_number':321,'multiline':False]
['text':'/ Example:','line_number':322,'multiline':False]
['text':'/ ```','line_number':323,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':324,'multiline':False]
['text':'/ F::log_softmax(input, LogSoftmaxFuncOptions(1));','line_number':325,'multiline':False]
['text':'/ ```','line_number':326,'multiline':False]
['text':'/ Dimension along which LogSoftmax will be computed.','line_number':330,'multiline':False]
['text':'/ the desired data type of returned tensor.','line_number':333,'multiline':False]
['text':'/ If specified, the input tensor is casted to `dtype` before the operation','line_number':334,'multiline':False]
['text':'/ is performed. This is useful for preventing data type overflows. Default:','line_number':335,'multiline':False]
['text':'/ None.','line_number':336,'multiline':False]
['text':' namespace functional','line_number':340,'multiline':False]
['text':' ============================================================================','line_number':342,'multiline':False]
['text':'/ Options for the `PReLU` module.','line_number':344,'multiline':False]
['text':'/','line_number':345,'multiline':False]
['text':'/ Example:','line_number':346,'multiline':False]
['text':'/ ```','line_number':347,'multiline':False]
['text':'/ PReLU model(PReLUOptions().num_parameters(42));','line_number':348,'multiline':False]
['text':'/ ```','line_number':349,'multiline':False]
['text':'/ number of `a` to learn. Although it takes an int as input, there is only','line_number':351,'multiline':False]
['text':'/ two values are legitimate: 1, or the number of channels at input. Default:','line_number':352,'multiline':False]
['text':'/ 1','line_number':353,'multiline':False]
['text':'/ the initial value of `a`. Default: 0.25','line_number':356,'multiline':False]
['text':' ============================================================================','line_number':360,'multiline':False]
['text':'/ Options for the `ReLU` module.','line_number':362,'multiline':False]
['text':'/','line_number':363,'multiline':False]
['text':'/ Example:','line_number':364,'multiline':False]
['text':'/ ```','line_number':365,'multiline':False]
['text':'/ ReLU model(ReLUOptions().inplace(true));','line_number':366,'multiline':False]
['text':'/ ```','line_number':367,'multiline':False]
['text':' implicit ','line_number':369,'multiline':True]
['text':'/ can optionally do the operation in-place. Default: False','line_number':371,'multiline':False]
['text':'/ Options for `torch::nn::functional::relu`.','line_number':376,'multiline':False]
['text':'/','line_number':377,'multiline':False]
['text':'/ See the documentation for `torch::nn::ReLUOptions` class to learn what','line_number':378,'multiline':False]
['text':'/ arguments are supported.','line_number':379,'multiline':False]
['text':'/','line_number':380,'multiline':False]
['text':'/ Example:','line_number':381,'multiline':False]
['text':'/ ```','line_number':382,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':383,'multiline':False]
['text':'/ F::relu(x, F::ReLUFuncOptions().inplace(true));','line_number':384,'multiline':False]
['text':'/ ```','line_number':385,'multiline':False]
['text':' namespace functional','line_number':387,'multiline':False]
['text':' ============================================================================','line_number':389,'multiline':False]
['text':'/ Options for the `ReLU6` module.','line_number':391,'multiline':False]
['text':'/','line_number':392,'multiline':False]
['text':'/ Example:','line_number':393,'multiline':False]
['text':'/ ```','line_number':394,'multiline':False]
['text':'/ ReLU6 model(ReLU6Options().inplace(true));','line_number':395,'multiline':False]
['text':'/ ```','line_number':396,'multiline':False]
['text':' implicit ','line_number':398,'multiline':True]
['text':'/ can optionally do the operation in-place. Default: False','line_number':400,'multiline':False]
['text':'/ Options for `torch::nn::functional::relu6`.','line_number':405,'multiline':False]
['text':'/','line_number':406,'multiline':False]
['text':'/ See the documentation for `torch::nn::ReLU6Options` class to learn what','line_number':407,'multiline':False]
['text':'/ arguments are supported.','line_number':408,'multiline':False]
['text':'/','line_number':409,'multiline':False]
['text':'/ Example:','line_number':410,'multiline':False]
['text':'/ ```','line_number':411,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':412,'multiline':False]
['text':'/ F::relu6(x, F::ReLU6FuncOptions().inplace(true));','line_number':413,'multiline':False]
['text':'/ ```','line_number':414,'multiline':False]
['text':' namespace functional','line_number':416,'multiline':False]
['text':' ============================================================================','line_number':418,'multiline':False]
['text':'/ Options for the `RReLU` module.','line_number':420,'multiline':False]
['text':'/','line_number':421,'multiline':False]
['text':'/ Example:','line_number':422,'multiline':False]
['text':'/ ```','line_number':423,'multiline':False]
['text':'/ RReLU model(RReLUOptions().lower(0.24).upper(0.42).inplace(true));','line_number':424,'multiline':False]
['text':'/ ```','line_number':425,'multiline':False]
['text':'/ lower bound of the uniform distribution. Default: 1/8','line_number':427,'multiline':False]
['text':'/ upper bound of the uniform distribution. Default: 1/3','line_number':430,'multiline':False]
['text':'/ can optionally do the operation in-place. Default: False','line_number':433,'multiline':False]
['text':' ============================================================================','line_number':437,'multiline':False]
['text':'/ Options for `torch::nn::functional::rrelu`.','line_number':441,'multiline':False]
['text':'/','line_number':442,'multiline':False]
['text':'/ Example:','line_number':443,'multiline':False]
['text':'/ ```','line_number':444,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':445,'multiline':False]
['text':'/ F::rrelu(x, F::RReLUFuncOptions().lower(0.1).upper(0.4).inplace(true));','line_number':446,'multiline':False]
['text':'/ ```','line_number':447,'multiline':False]
['text':'/ lower bound of the uniform distribution. Default: 1/8','line_number':449,'multiline':False]
['text':'/ upper bound of the uniform distribution. Default: 1/3','line_number':452,'multiline':False]
['text':'/ can optionally do the operation in-place. Default: False','line_number':457,'multiline':False]
['text':' namespace functional','line_number':461,'multiline':False]
['text':' ============================================================================','line_number':463,'multiline':False]
['text':'/ Options for the `CELU` module.','line_number':465,'multiline':False]
['text':'/','line_number':466,'multiline':False]
['text':'/ Example:','line_number':467,'multiline':False]
['text':'/ ```','line_number':468,'multiline':False]
['text':'/ CELU model(CELUOptions().alpha(42.42).inplace(true));','line_number':469,'multiline':False]
['text':'/ ```','line_number':470,'multiline':False]
['text':'/ The `alpha` value for the CELU formulation. Default: 1.0','line_number':472,'multiline':False]
['text':'/ can optionally do the operation in-place. Default: False','line_number':475,'multiline':False]
['text':'/ Options for `torch::nn::functional::celu`.','line_number':480,'multiline':False]
['text':'/','line_number':481,'multiline':False]
['text':'/ See the documentation for `torch::nn::CELUOptions` class to learn what','line_number':482,'multiline':False]
['text':'/ arguments are supported.','line_number':483,'multiline':False]
['text':'/','line_number':484,'multiline':False]
['text':'/ Example:','line_number':485,'multiline':False]
['text':'/ ```','line_number':486,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':487,'multiline':False]
['text':'/ F::celu(x, F::CELUFuncOptions().alpha(0.42).inplace(true));','line_number':488,'multiline':False]
['text':'/ ```','line_number':489,'multiline':False]
['text':' namespace functional','line_number':491,'multiline':False]
['text':' ============================================================================','line_number':493,'multiline':False]
['text':'/ Options for the `Softplus` module.','line_number':495,'multiline':False]
['text':'/','line_number':496,'multiline':False]
['text':'/ Example:','line_number':497,'multiline':False]
['text':'/ ```','line_number':498,'multiline':False]
['text':'/ Softplus model(SoftplusOptions().beta(0.24).threshold(42.42));','line_number':499,'multiline':False]
['text':'/ ```','line_number':500,'multiline':False]
['text':'/ the `beta` value for the Softplus formulation. Default: 1','line_number':502,'multiline':False]
['text':'/ values above this revert to a linear function. Default: 20','line_number':505,'multiline':False]
['text':'/ Options for `torch::nn::functional::softplus`.','line_number':510,'multiline':False]
['text':'/','line_number':511,'multiline':False]
['text':'/ See the documentation for `torch::nn::SoftplusOptions` class to learn what','line_number':512,'multiline':False]
['text':'/ arguments are supported.','line_number':513,'multiline':False]
['text':'/','line_number':514,'multiline':False]
['text':'/ Example:','line_number':515,'multiline':False]
['text':'/ ```','line_number':516,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':517,'multiline':False]
['text':'/ F::softplus(x, F::SoftplusFuncOptions().beta(0.5).threshold(3.0));','line_number':518,'multiline':False]
['text':'/ ```','line_number':519,'multiline':False]
['text':' namespace functional','line_number':521,'multiline':False]
['text':' ============================================================================','line_number':523,'multiline':False]
['text':'/ Options for the `Softshrink` module.','line_number':525,'multiline':False]
['text':'/','line_number':526,'multiline':False]
['text':'/ Example:','line_number':527,'multiline':False]
['text':'/ ```','line_number':528,'multiline':False]
['text':'/ Softshrink model(SoftshrinkOptions(42.42));','line_number':529,'multiline':False]
['text':'/ ```','line_number':530,'multiline':False]
['text':' implicit ','line_number':532,'multiline':True]
['text':'/ the `lambda` value for the Softshrink formulation. Default: 0.5','line_number':534,'multiline':False]
['text':'/ Options for `torch::nn::functional::softshrink`.','line_number':539,'multiline':False]
['text':'/','line_number':540,'multiline':False]
['text':'/ See the documentation for `torch::nn::SoftshrinkOptions` class to learn what','line_number':541,'multiline':False]
['text':'/ arguments are supported.','line_number':542,'multiline':False]
['text':'/','line_number':543,'multiline':False]
['text':'/ Example:','line_number':544,'multiline':False]
['text':'/ ```','line_number':545,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':546,'multiline':False]
['text':'/ F::softshrink(x, F::SoftshrinkFuncOptions(0.42));','line_number':547,'multiline':False]
['text':'/ ```','line_number':548,'multiline':False]
['text':' namespace functional','line_number':550,'multiline':False]
['text':' ============================================================================','line_number':552,'multiline':False]
['text':'/ Options for the `Threshold` module.','line_number':554,'multiline':False]
['text':'/','line_number':555,'multiline':False]
['text':'/ Example:','line_number':556,'multiline':False]
['text':'/ ```','line_number':557,'multiline':False]
['text':'/ Threshold model(ThresholdOptions(42.42, 24.24).inplace(true));','line_number':558,'multiline':False]
['text':'/ ```','line_number':559,'multiline':False]
['text':'/ The value to threshold at','line_number':564,'multiline':False]
['text':'/ The value to replace with','line_number':567,'multiline':False]
['text':'/ can optionally do the operation in-place. Default: False','line_number':570,'multiline':False]
['text':'/ Options for `torch::nn::functional::threshold`.','line_number':575,'multiline':False]
['text':'/','line_number':576,'multiline':False]
['text':'/ See the documentation for `torch::nn::ThresholdOptions` class to learn what','line_number':577,'multiline':False]
['text':'/ arguments are supported.','line_number':578,'multiline':False]
['text':'/','line_number':579,'multiline':False]
['text':'/ Example:','line_number':580,'multiline':False]
['text':'/ ```','line_number':581,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':582,'multiline':False]
['text':'/ F::threshold(x, F::ThresholdFuncOptions(0.5, 0.5).inplace(true));','line_number':583,'multiline':False]
['text':'/ ```','line_number':584,'multiline':False]
['text':' namespace functional','line_number':586,'multiline':False]
['text':' ============================================================================','line_number':588,'multiline':False]
['text':'/ Options for `torch::nn::functional::gumbel_softmax`.','line_number':592,'multiline':False]
['text':'/','line_number':593,'multiline':False]
['text':'/ Example:','line_number':594,'multiline':False]
['text':'/ ```','line_number':595,'multiline':False]
['text':'/ namespace F = torch::nn::functional;','line_number':596,'multiline':False]
['text':'/ F::gumbel_softmax(logits, F::GumbelSoftmaxFuncOptions().hard(true).dim(-1));','line_number':597,'multiline':False]
['text':'/ ```','line_number':598,'multiline':False]
['text':'/ non-negative scalar temperature','line_number':600,'multiline':False]
['text':'/ returned samples will be discretized as one-hot vectors,','line_number':603,'multiline':False]
['text':'/ but will be differentiated as if it is the soft sample in autograd.','line_number':604,'multiline':False]
['text':'/ Default: False','line_number':605,'multiline':False]
['text':'/ dimension along which softmax will be computed. Default: -1','line_number':608,'multiline':False]
['text':' namespace functional','line_number':612,'multiline':False]
['text':' ============================================================================','line_number':614,'multiline':False]
['text':'/ Options for the `MultiheadAttention` module.','line_number':616,'multiline':False]
['text':'/','line_number':617,'multiline':False]
['text':'/ Example:','line_number':618,'multiline':False]
['text':'/ ```','line_number':619,'multiline':False]
['text':'/ MultiheadAttention model(MultiheadAttentionOptions(20, 10).bias(false));','line_number':620,'multiline':False]
['text':'/ ```','line_number':621,'multiline':False]
['text':'/ total dimension of the model.','line_number':625,'multiline':False]
['text':'/ parallel attention heads.','line_number':628,'multiline':False]
['text':'/ a Dropout layer on attn_output_weights. Default: 0.0.','line_number':631,'multiline':False]
['text':'/ add bias as module parameter. Default: true.','line_number':634,'multiline':False]
['text':'/ add bias to the key and value sequences at dim=0.','line_number':637,'multiline':False]
['text':'/ add a new batch of zeros to the key and value sequences at dim=1.','line_number':640,'multiline':False]
['text':'/ total number of features in key. Default: c10::nullopt.','line_number':643,'multiline':False]
['text':'/ total number of features in key. Default: c10::nullopt.','line_number':646,'multiline':False]
['text':' ============================================================================','line_number':650,'multiline':False]
['text':'/ Options for `torch::nn::functional::multi_head_attention_forward`','line_number':654,'multiline':False]
['text':' namespace functional','line_number':711,'multiline':False]
['text':' namespace nn','line_number':713,'multiline':False]
['text':' namespace torch','line_number':714,'multiline':False]
