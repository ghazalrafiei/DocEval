['text':' NOLINTNEXTLINE','line_number':25,'multiline':False]
['text':' TODO: add a test','line_number':35,'multiline':False]
['text':' TODO: add a test','line_number':40,'multiline':False]
['text':' AT_MKLDNN_ENABLED()','line_number':50,'multiline':False]
['text':' NB: sub isn't supported on boolean, no need to promote to integer.','line_number':61,'multiline':False]
['text':' value needs to promote to input, not vice versa','line_number':504,'multiline':False]
['text':'promote_inputs','line_number':508,'multiline':True]
['text':' promote_inputs ','line_number':556,'multiline':True]
['text':' check if the activation is quantized','line_number':585,'multiline':False]
['text':' approximate == 'tanh'','line_number':748,'multiline':False]
['text':' approximate == 'none'','line_number':765,'multiline':False]
['text':' NOLINT','line_number':1025,'multiline':False]
['text':' NOLINT','line_number':1027,'multiline':False]
['text':' NOLINT','line_number':1029,'multiline':False]
['text':' NOLINT','line_number':1032,'multiline':False]
['text':' NOLINT','line_number':1036,'multiline':False]
['text':' NOLINT','line_number':1040,'multiline':False]
['text':'  x * torch.clamp(x + 3.0, 0.0, 6.0) / 6.0','line_number':1399,'multiline':False]
['text':' see handling of aten::to in tensorexpr_fuser.cpp for why we only','line_number':1587,'multiline':False]
['text':' need to handle the first input','line_number':1588,'multiline':False]
['text':' TODO: convert to schema, add a test','line_number':1682,'multiline':False]
['text':' RegisterNNCLoweringsFunction aten_rand_like(','line_number':1683,'multiline':False]
['text':'     {"aten::rand_like"},','line_number':1684,'multiline':False]
['text':'     [](const std::vector<ArgValue>& inputs,','line_number':1685,'multiline':False]
['text':'        const std::vector<ExprHandle>& outputShape,','line_number':1686,'multiline':False]
['text':'        const c10::optional<ScalarType>& outputType,','line_number':1687,'multiline':False]
['text':'        at::Device device) {','line_number':1688,'multiline':False]
['text':'       return computeOneOperand(','line_number':1689,'multiline':False]
['text':'           "aten_rand_like",','line_number':1690,'multiline':False]
['text':'           inputs,','line_number':1691,'multiline':False]
['text':'           outputShape,','line_number':1692,'multiline':False]
['text':'           outputType,','line_number':1693,'multiline':False]
['text':'           [](const ExprHandle& a) {','line_number':1694,'multiline':False]
['text':'             return Intrinsics::make(IntrinsicsOp::kRand, a.dtype());','line_number':1695,'multiline':False]
['text':'           });','line_number':1696,'multiline':False]
['text':'     });','line_number':1697,'multiline':False]
['text':' TODO: convert to schema, add a test','line_number':1699,'multiline':False]
['text':' RegisterNNCLoweringsFunction aten_slice(','line_number':1700,'multiline':False]
['text':'     {"aten::slice"},','line_number':1701,'multiline':False]
['text':'     [](const std::vector<ArgValue>& inputs,','line_number':1702,'multiline':False]
['text':'        const std::vector<ExprHandle>& outputShape,','line_number':1703,'multiline':False]
['text':'        const c10::optional<ScalarType>& outputType,','line_number':1704,'multiline':False]
['text':'        at::Device device) {','line_number':1705,'multiline':False]
['text':'       return Compute(','line_number':1706,'multiline':False]
['text':'           "aten_slice",','line_number':1707,'multiline':False]
['text':'           outputShape,','line_number':1708,'multiline':False]
['text':'           [&](const std::vector<VarHandle>& axes) {','line_number':1709,'multiline':False]
['text':'             int64_t dim =','line_number':1710,'multiline':False]
['text':'                 at::maybe_wrap_dim(std::get<int64_t>(inputs[1]),','line_number':1711,'multiline':False]
['text':'                 axes.size());','line_number':1712,'multiline':False]
['text':'             ExprHandle start = constant(inputs[2]);','line_number':1713,'multiline':False]
['text':'             ExprHandle stride = constant(inputs[4]);','line_number':1714,'multiline':False]
['text':'             std::vector<ExprHandle> newAxes(axes.begin(), axes.end());','line_number':1716,'multiline':False]
['text':'             newAxes[dim] = stride * newAxes[dim] + start;','line_number':1717,'multiline':False]
['text':'             return tensorOrConstant(inputs[0], newAxes);','line_number':1718,'multiline':False]
['text':'           });','line_number':1719,'multiline':False]
['text':'     });','line_number':1720,'multiline':False]
['text':' To construct an expression for an 'unsqueezed' tensor we need','line_number':1740,'multiline':False]
['text':' to drop the DIM-th axis, i.e.','line_number':1741,'multiline':False]
['text':'    unsqueezed_v[i,j,k,l] = v[i,j,l] # dim = 2 - drop index 'k'','line_number':1742,'multiline':False]
['text':'                 0 1 2 3','line_number':1743,'multiline':False]
['text':' Trivial case of 0-dim tensors: just a copy of the input','line_number':1780,'multiline':False]
['text':' TODO: add a test','line_number':1821,'multiline':False]
['text':' aten::mm is a subset of aten::matmul where both inputs are rank 2','line_number':1832,'multiline':False]
['text':' namespace','line_number':1990,'multiline':False]
['text':' namespace torch::jit::tensorexpr','line_number':2001,'multiline':False]
