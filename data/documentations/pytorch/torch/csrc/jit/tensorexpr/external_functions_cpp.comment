['text':' NOLINTNEXTLINE','line_number':106,'multiline':False]
['text':' TODO: support GPUs too','line_number':109,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':111,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':113,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':117,'multiline':False]
['text':' handle quantized','line_number':125,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':132,'multiline':False]
['text':' TODO: support GPUs too','line_number':135,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':137,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':139,'multiline':False]
['text':' inplace tensor','line_number':143,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':145,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':155,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':216,'multiline':False]
['text':' TODO: support GPUs too','line_number':219,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':221,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':223,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':227,'multiline':False]
['text':' handle quantized','line_number':235,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':242,'multiline':False]
['text':' TODO: support GPUs too','line_number':245,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':247,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':249,'multiline':False]
['text':' inplace tensor','line_number':253,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':255,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':265,'multiline':False]
['text':' _WIN32','line_number':351,'multiline':False]
['text':' Check that if the extra arguments are provided, then the bias tensor is','line_number':373,'multiline':False]
['text':' also present','line_number':374,'multiline':False]
['text':' TODO: can i haz an out version of the conv2d?','line_number':404,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':432,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':465,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':498,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':529,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':560,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':591,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':622,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':653,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':684,'multiline':False]
['text':' TORCH_INTERNAL_ASSERT(tensors.size() == 3);','line_number':699,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':719,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':750,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':783,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':811,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':839,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':866,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':892,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':920,'multiline':False]
['text':' _WIN32','line_number':959,'multiline':False]
['text':' NOLINTNEXTLINE(facebook-hte-LocalUncheckedArrayBounds)','line_number':970,'multiline':False]
['text':' NOLINTNEXTLINE(facebook-hte-LocalUncheckedArrayBounds)','line_number':1013,'multiline':False]
['text':' NOLINTNEXTLINE(facebook-hte-LocalUncheckedArrayBounds)','line_number':1066,'multiline':False]
['text':' NOLINTNEXTLINE(facebook-hte-LocalUncheckedArrayBounds)','line_number':1094,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':1126,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':1153,'multiline':False]
['text':' Check that if the extra arguments are provided, then the bias tensor is','line_number':1176,'multiline':False]
['text':' also present','line_number':1177,'multiline':False]
['text':' Check that if the extra arguments are provided, then the bias tensor is','line_number':1224,'multiline':False]
['text':' also present','line_number':1225,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':1338,'multiline':False]
['text':' TODO: handle other alpha and beta dtypes, e.g. alpha=0.6, beta=0.2','line_number':1367,'multiline':False]
['text':' Only provides first output, the second output is just a copy of one of the','line_number':1376,'multiline':False]
['text':' inputs','line_number':1377,'multiline':False]
['text':' AT_MKLDNN_ENABLED()','line_number':1422,'multiline':False]
['text':' USE_XNNPACK','line_number':1472,'multiline':False]
['text':' TODO: have to copy output because at::embedding doesnt have an out','line_number':1493,'multiline':False]
['text':' variant and NNC's external calls don't support allocations','line_number':1494,'multiline':False]
['text':' _WIN32','line_number':1556,'multiline':False]
['text':' AT_MKLDNN_ENABLED()','line_number':1610,'multiline':False]
['text':' USE_XNNPACK','line_number':1619,'multiline':False]
['text':' C10_MOBILE','line_number':1621,'multiline':False]
['text':' extern "C"','line_number':1624,'multiline':False]
['text':' namespace torch::jit::tensorexpr','line_number':1627,'multiline':False]
