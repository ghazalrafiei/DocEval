['text':' grab the next node before we move this one all the way back','line_number':45,'multiline':False]
['text':' alias analysis will try to hoist a node out of a loop','line_number':48,'multiline':False]
['text':' if asked. if guardee is in a loop, it should only','line_number':49,'multiline':False]
['text':' be moved to the beginning of the basic block','line_number':50,'multiline':False]
['text':' given the current implementation of AliasAnalysis','line_number':51,'multiline':False]
['text':'b->owningNode()->kind() == prim::If','line_number':74,'multiline':True]
['text':' uses on *all* parameters are moved to the same anchor node','line_number':89,'multiline':False]
['text':' and they may come in different order after the anchor node','line_number':90,'multiline':False]
['text':' e.g. (anchor, guard_x, guard_y, guard_x, guard_y)','line_number':91,'multiline':False]
['text':' this pass recognizes contiguous stretches of guards and','line_number':92,'multiline':False]
['text':' keeps track of the guards it's seen for each def. the next time','line_number':93,'multiline':False]
['text':' the guard on the same def, it simply removes it.','line_number':94,'multiline':False]
['text':' If a Node guards a value which isn't mutated, then that node','line_number':121,'multiline':False]
['text':' can replace all other guards of the value which it dominates','line_number':122,'multiline':False]
['text':' find all uses of the input that the guard node dominates','line_number':132,'multiline':False]
['text':' not all uses are guarded','line_number':138,'multiline':False]
['text':' the dominated guard type may be different from the dominator','line_number':147,'multiline':False]
['text':' if it is only executed for a subtype, or if it is executed','line_number':148,'multiline':False]
['text':' in a different global context for grad enabled','line_number':149,'multiline':False]
['text':' check that the types are equal before continuing','line_number':150,'multiline':False]
['text':' remove redundant dominated guards','line_number':160,'multiline':False]
['text':' we need to make sure there are no ops in between guardee's','line_number':179,'multiline':False]
['text':' output and its guard except for other guards as they can','line_number':180,'multiline':False]
['text':' invalidate shape information.','line_number':181,'multiline':False]
['text':' a very simple pass to eliminate redundant guards for ops','line_number':201,'multiline':False]
['text':' whose outputs are fully determined by their inputs','line_number':202,'multiline':False]
['text':' i.e. if inputs to such ops are guarded we are allowed','line_number':203,'multiline':False]
['text':' to remove a guard on ops' outputs','line_number':204,'multiline':False]
['text':' `checkInputs` check the invariants specified in `removableGuard`','line_number':224,'multiline':False]
['text':' on inputs to `n`. The invariants must hold, or an input must','line_number':225,'multiline':False]
['text':' be a `prim::Constant` or be included as an exception in `except`','line_number':226,'multiline':False]
['text':' `removableGuard` relies on the properties checked by `isSummarized()`','line_number':257,'multiline':False]
['text':' and passes shouldn't insert nodes between a guard and its uses that','line_number':258,'multiline':False]
['text':' may alter those properties.','line_number':259,'multiline':False]
['text':' `removableGuard` expects type information to come directly from','line_number':260,'multiline':False]
['text':' Profiler. Passes shouldn't try to alter type information provided by','line_number':261,'multiline':False]
['text':' profiling','line_number':262,'multiline':False]
['text':' While we can derive very simple rules stating when it's valid to remove','line_number':263,'multiline':False]
['text':' `prim::Guard` on operation's output if all of its inputs are guarded for','line_number':264,'multiline':False]
['text':' some','line_number':265,'multiline':False]
['text':' categories of operations','line_number':266,'multiline':False]
['text':' there's no comprehensive set of rules that covers all the operations','line_number':267,'multiline':False]
['text':' available in PyTorch','line_number':268,'multiline':False]
['text':' If your operation falls into one of the categories described below, you','line_number':269,'multiline':False]
['text':' should add it','line_number':270,'multiline':False]
['text':' to switch statement below that contains the other operations in the said','line_number':271,'multiline':False]
['text':' category.','line_number':272,'multiline':False]
['text':' Otherwise, you will need to derive the rules for your case on your own.','line_number':273,'multiline':False]
['text':' Generally, any operation that is stateful in any way or uses its underlying','line_number':274,'multiline':False]
['text':' data','line_number':275,'multiline':False]
['text':' to compute any properties `isSummarized()` isn't amenable to guard','line_number':276,'multiline':False]
['text':' elimination.','line_number':277,'multiline':False]
['text':' Categories:','line_number':278,'multiline':False]
['text':' * Functional-like(e.g. add, sub, le) operations with broadcast semenatics','line_number':279,'multiline':False]
['text':'   Guards can be removed if all inputs are guarded and `isSummarized()`','line_number':280,'multiline':False]
['text':'   returns','line_number':281,'multiline':False]
['text':'   false or inputs are `prim::Constant`','line_number':282,'multiline':False]
['text':' check that the dimension argument is constant','line_number':371,'multiline':False]
['text':' the start offset is constant','line_number':373,'multiline':False]
['text':' the end offset is constant','line_number':375,'multiline':False]
['text':' the stride is constant','line_number':377,'multiline':False]
['text':' check that the kernel size is constant','line_number':383,'multiline':False]
['text':' check that the stride is constant','line_number':385,'multiline':False]
['text':' check that the padding is constant','line_number':387,'multiline':False]
['text':' check that the dilation is constant','line_number':389,'multiline':False]
['text':' check that the ceil_mode is constant','line_number':391,'multiline':False]
['text':' check that the dimension argument is constant','line_number':394,'multiline':False]
['text':' check that the dimension argument is constant','line_number':398,'multiline':False]
['text':' no extra nodes in between aten::cat and prim::ListConstruct','line_number':401,'multiline':False]
['text':' check the inputs to prim::ListConstruct (not aten::cat)','line_number':403,'multiline':False]
['text':' the second and third args do not affect shapes','line_number':406,'multiline':False]
['text':' after some optimizations we might end up with two Guards back-to-back','line_number':408,'multiline':False]
['text':' which case we can remove the one whose input is also prim::Guard','line_number':409,'multiline':False]
['text':' skip checking size argument','line_number':411,'multiline':False]
['text':' aten::size is effectively a constant','line_number':417,'multiline':False]
['text':' this is checked by one of the tests in test_jit_fuser.py','line_number':429,'multiline':False]
['text':' check if the input is a constant chunk','line_number':431,'multiline':False]
['text':' used for LSTM fusions','line_number':432,'multiline':False]
['text':' this is checked by one of the tests in test_jit_fuser.py','line_number':439,'multiline':False]
['text':' namespace jit','line_number':466,'multiline':False]
['text':' namespace torch','line_number':467,'multiline':False]
