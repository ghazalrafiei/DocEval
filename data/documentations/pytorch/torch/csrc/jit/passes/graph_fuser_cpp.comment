['text':' What is a simple mappable operator?  It:','line_number':26,'multiline':False]
['text':'    - Has a single tensor output','line_number':27,'multiline':False]
['text':'    - Output and all tensor inputs have the same shape','line_number':28,'multiline':False]
['text':'    - Output and all tensor inputs have the same scalar type','line_number':29,'multiline':False]
['text':'      or all tensor inputs have the same scalar type and','line_number':30,'multiline':False]
['text':'         output is identified in PropagateInputShapes','line_number':31,'multiline':False]
['text':'    - Output and all tensor inputs should be on the same device','line_number':32,'multiline':False]
['text':'    - Produces dense non-overlapping outputs','line_number':33,'multiline':False]
['text':' Some of these restrictions may be relaxable, but you should','line_number':34,'multiline':False]
['text':' carefully read the code first, as we rely on these assumptions.','line_number':35,'multiline':False]
['text':' nvrtc has a limit on the number of arguments allowed in a CUDA kernel.','line_number':138,'multiline':False]
['text':' The specific limit is a function of constant memory size, amount available','line_number':139,'multiline':False]
['text':' to pass arguments, and some implementation dependence. Select a safe','line_number':140,'multiline':False]
['text':' limit here.','line_number':141,'multiline':False]
['text':' This limit is also applied to other devices in the fuser by default.','line_number':142,'multiline':False]
['text':' Change with setInputArgLimit','line_number':143,'multiline':False]
['text':' Custom passes require kind to specified','line_number':151,'multiline':False]
['text':' Default fusability check - used when the user doesn't pass in','line_number':197,'multiline':False]
['text':' a callback.','line_number':198,'multiline':False]
['text':' We don't want to bother with cross-block node movements, as they','line_number':210,'multiline':False]
['text':' are not necessarily correct.','line_number':211,'multiline':False]
['text':' NB: Note that technically other uses of the list aren't a big problem for','line_number':230,'multiline':False]
['text':' us. It would be enough to place the prim::FusedConcat before the','line_number':231,'multiline':False]
['text':' prim::ListConstruct, and allUsersAreThisConsumerOrOccurAfterIt would','line_number':232,'multiline':False]
['text':' still be satisfied. However, I don't expect this to be necessary any time','line_number':233,'multiline':False]
['text':' soon, and so we're simply assuming that we don't have to deal with it.','line_number':234,'multiline':False]
['text':' Now we have two fusion groups!','line_number':261,'multiline':False]
['text':' Revert the fusion - place all inner nodes of producer back in the outer','line_number':262,'multiline':False]
['text':' graph.','line_number':263,'multiline':False]
['text':' Initialize a map of inner graph values to outer graph values','line_number':267,'multiline':False]
['text':' Clone all nodes','line_number':275,'multiline':False]
['text':' Replace uses of producer_group outputs and destroy the producer','line_number':288,'multiline':False]
['text':' new producer outputs have same aliasing properties as outer_output','line_number':293,'multiline':False]
['text':' Just to get a clear error in case someone uses it','line_number':298,'multiline':False]
['text':' Inline the temporary nodes into the first group','line_number':300,'multiline':False]
['text':' If any of the outputs are still used then we need to add them','line_number':306,'multiline':False]
['text':' insert a producer node into a consuming fusion group.','line_number':322,'multiline':False]
['text':' DOES NOT WORK if n is a consumer of an output of the fusion group','line_number':323,'multiline':False]
['text':' returns the node _inside_ the group that represents the node','line_number':324,'multiline':False]
['text':' map from nodes in the surrounding graph to parameters in the fusion','line_number':328,'multiline':False]
['text':' group's subgraph that correspond to them','line_number':329,'multiline':False]
['text':' add n's inputs to the fusion group's input list if we don't already have','line_number':339,'multiline':False]
['text':' them','line_number':340,'multiline':False]
['text':' we insert tensors first because the fuser assumes that to be the case','line_number':341,'multiline':False]
['text':' (as a legacy from tensors only)','line_number':342,'multiline':False]
['text':' We don't support passing in scalars as arguments to fused kernels,','line_number':362,'multiline':False]
['text':' so we generally don't allow fusing tensor-scalar operations unless','line_number':363,'multiline':False]
['text':' the scalar is constant. In those cases we inline the constants','line_number':364,'multiline':False]
['text':' directly in the body of the fused group.','line_number':365,'multiline':False]
['text':' copy n into the graph, remapping its inputs to internal nodes','line_number':376,'multiline':False]
['text':' if n's outputs are already inputs to the fusion group,','line_number':379,'multiline':False]
['text':' we need to remove them because n is now inside the fusion group.','line_number':380,'multiline':False]
['text':'','line_number':381,'multiline':False]
['text':' i.e.,','line_number':382,'multiline':False]
['text':' x = f(w); group(x, y, z) becomes group(w, y, z).','line_number':383,'multiline':False]
['text':' x, y, z = f(w); group(x, y, z) becomes group(w).','line_number':384,'multiline':False]
['text':'','line_number':385,'multiline':False]
['text':' remapping nodes that used the input to the newly-merged node','line_number':386,'multiline':False]
['text':' n is not an input when the fusion group is empty','line_number':387,'multiline':False]
['text':' turn consumer node n into a fusion group with just n inside','line_number':401,'multiline':False]
['text':' to prepare for fusion and replace uses of n with the new group','line_number':402,'multiline':False]
['text':' propagate position information for the new node so we can always','line_number':405,'multiline':False]
['text':' have a valid mapping','line_number':406,'multiline':False]
['text':' this handles cases where producer can be moved _into_ the fusion group of','line_number':419,'multiline':False]
['text':' consumer.','line_number':420,'multiline':False]
['text':' TODO: extend to fusion of consumer into _producer's_ fusion blob','line_number':421,'multiline':False]
['text':' if the consumer allInputsAreThisProducer(consumer,producer)','line_number':422,'multiline':False]
['text':' we can move the consumer up into the producer.','line_number':423,'multiline':False]
['text':' but this requires better handling of merging fusion groups so it is not','line_number':424,'multiline':False]
['text':' done now','line_number':425,'multiline':False]
['text':' Rearrange nodes such that all uses of producer are after the','line_number':427,'multiline':False]
['text':' consumer. Fusion will rewrite those later uses to use the version of','line_number':428,'multiline':False]
['text':' producer generated by the fused blob. In this case, producer becomes','line_number':429,'multiline':False]
['text':' an output of the fusion group.','line_number':430,'multiline':False]
['text':' remaining uses of this producer can occur because we allow','line_number':454,'multiline':False]
['text':' fusion in cases where uses remain after the consumer','line_number':455,'multiline':False]
['text':' if these exist, re-route them to the version of producer','line_number':456,'multiline':False]
['text':' created in FusionGroup','line_number':457,'multiline':False]
['text':' Does the chunk have constant chunks/dim?','line_number':473,'multiline':False]
['text':' And all uses of the chunk are in this consumer','line_number':477,'multiline':False]
['text':' And isn't a no-op chunk (chunks == 1). Have CSE clean this up.','line_number':485,'multiline':False]
['text':' We could fuse this but it's better to just delete the node.','line_number':486,'multiline':False]
['text':' If subgraph_input is an input to prim::ConstantChunk, it will have 1 use','line_number':502,'multiline':False]
['text':' Find the input to the FusionGroup (group)','line_number':520,'multiline':False]
['text':' Rewrite the graph to use replacement_val','line_number':526,'multiline':False]
['text':' Remove the input, it's no longer needed','line_number':530,'multiline':False]
['text':' There are two invariants for prim::ConstantChunk:','line_number':537,'multiline':False]
['text':' (1) the tensor input to prim::ConstantChunk must be an input to the fusion','line_number':538,'multiline':False]
['text':' group (2) no two ConstantChunks in the same FusionGroup can share a tensor','line_number':539,'multiline':False]
['text':' input.','line_number':540,'multiline':False]
['text':' if producer's input is already an input to a prim::ConstantChunk node,','line_number':546,'multiline':False]
['text':' we cannot add a new prim::ConstantChunk node because of invariant (2).','line_number':547,'multiline':False]
['text':' Move prim::ConstantChunk into the FusionGroup','line_number':555,'multiline':False]
['text':' Sort in reverse topological order','line_number':568,'multiline':False]
['text':' We are doing:','line_number':599,'multiline':False]
['text':'   input_list = listConstruct(a, b, ...)','line_number':600,'multiline':False]
['text':'   output_list = broadcast_tensors(input_list)','line_number':601,'multiline':False]
['text':'   a_broadcasted, b_broadcasted = listUnpack(output_list)','line_number':602,'multiline':False]
['text':' `a_broadcasted` should receive the same aliasing info as `a`','line_number':603,'multiline':False]
['text':' Replace tensors inputs with broadcasted values','line_number':619,'multiline':False]
['text':' in places where op can be fused into a consumer but chunk is in the way','line_number':649,'multiline':False]
['text':' distribute chunk to op's operands:','line_number':650,'multiline':False]
['text':' replace a,b = chunk(op(x,y,z)) with:','line_number':651,'multiline':False]
['text':' x', y', z' = broadcast_tensors([x, y, z])','line_number':652,'multiline':False]
['text':' x0,x1 = chunk(x') (x0 has a's type, x1 has b's type)','line_number':653,'multiline':False]
['text':' y0,y1 = chunk(y') (y0 has a's type, y1 has b's type)','line_number':654,'multiline':False]
['text':' z0,z1 = chunk(z') (z0 has a's type, z1 has b's type)','line_number':655,'multiline':False]
['text':' a = op(x0,y0,z0) (a,b have their same size but are now contiguous)','line_number':656,'multiline':False]
['text':' b = op(x1,y1,x1)','line_number':657,'multiline':False]
['text':'','line_number':658,'multiline':False]
['text':' The graph fuser uses an intermediate prim::BroadcastingChunk node to','line_number':659,'multiline':False]
['text':' represent this behavior concisely. BroadcastingChunk(x, y, z) broadcasts','line_number':660,'multiline':False]
['text':' all of its inputs and then chunks each input, in order, the same way.','line_number':661,'multiline':False]
['text':' The above graph is equivalent to:','line_number':662,'multiline':False]
['text':' x0, x1, y0, y1, z0, z1 = BroadcastingChunk(x, y, z)','line_number':663,'multiline':False]
['text':' a = op(x0,y0,z0)','line_number':664,'multiline':False]
['text':' b = op(x1,y1,x1)','line_number':665,'multiline':False]
['text':'','line_number':666,'multiline':False]
['text':' NB: The explicit broadcast is important for correctness.','line_number':667,'multiline':False]
['text':' Let's say we have:','line_number':668,'multiline':False]
['text':' %z = aten::mul(%x, %y)','line_number':669,'multiline':False]
['text':' %z.1, %z.2 = aten::chunk(%z, ...)','line_number':670,'multiline':False]
['text':' ... = prim::FusionGroup(%z.1, %z.2, ...)','line_number':671,'multiline':False]
['text':' It's possible that %x and %y do not have the same size as %z and','line_number':672,'multiline':False]
['text':' need to be expanded first so that they can be chunked like %z','line_number':673,'multiline':False]
['text':'','line_number':674,'multiline':False]
['text':' NB: Chunk motion only occurs with fusable consumers, which implies','line_number':675,'multiline':False]
['text':' that there is always some other operation, e.g., a+b, that happens','line_number':676,'multiline':False]
['text':' after the chunk, and will be put into the fusion group. This is','line_number':677,'multiline':False]
['text':' important, because distributing the chunk changes the contiguity','line_number':678,'multiline':False]
['text':' of a and b, and so the results would be invalid, except that we know','line_number':679,'multiline':False]
['text':' that simple_mappable operations will restore contiguity before','line_number':680,'multiline':False]
['text':' we exit the fusion group.','line_number':681,'multiline':False]
['text':'','line_number':682,'multiline':False]
['text':' NB: The intermediate BroadcastingChunk is important for moving chunks past','line_number':683,'multiline':False]
['text':' more than one operation: the graph fuser is not able to easily move','line_number':684,'multiline':False]
['text':' operations around broadcast_tensors + chunk nodes. Let f, g, h be fusible','line_number':685,'multiline':False]
['text':' ops','line_number':686,'multiline':False]
['text':'   x = f(v, w)','line_number':687,'multiline':False]
['text':'   z = g(x, y)','line_number':688,'multiline':False]
['text':'   a, b = chunk(z)','line_number':689,'multiline':False]
['text':'   c = h(a, b)','line_number':690,'multiline':False]
['text':' becomes (with the broadcast_tensors + chunk approach):','line_number':691,'multiline':False]
['text':'   x = f(v, w)','line_number':692,'multiline':False]
['text':'   x', y' = broadcast_tensors([x, y])','line_number':693,'multiline':False]
['text':'   ax, bx = chunk(x')','line_number':694,'multiline':False]
['text':'   ay, by = chunk(y')','line_number':695,'multiline':False]
['text':'   a = g(ax, ay)','line_number':696,'multiline':False]
['text':'   b = g(bx, by)','line_number':697,'multiline':False]
['text':'   c = h(a, b)','line_number':698,'multiline':False]
['text':' The broadcast_tensors node makes it harder to move f into the resulting','line_number':699,'multiline':False]
['text':' FusionGroup of g, g, and h. Keeping the broadcasting and chunk behavior','line_number':700,'multiline':False]
['text':' together results in:','line_number':701,'multiline':False]
['text':'   x = f(v, w)','line_number':702,'multiline':False]
['text':'   ax, bx, ay, by = BroadcastingChunk(x, y)','line_number':703,'multiline':False]
['text':'   a = g(ax, ay)','line_number':704,'multiline':False]
['text':'   b = g(bx, by)','line_number':705,'multiline':False]
['text':'   c = h(a, b)','line_number':706,'multiline':False]
['text':' making it easier to move f after the BroadcastingChunk:','line_number':707,'multiline':False]
['text':'   ay, by, av, bv, aw, bw = BroadcastingChunk(y, v, w)','line_number':708,'multiline':False]
['text':'   ax = f(av, aw)','line_number':709,'multiline':False]
['text':'   by = f(bv, bw)','line_number':710,'multiline':False]
['text':'   a = g(ax, ay)','line_number':711,'multiline':False]
['text':'   b = g(bx, by)','line_number':712,'multiline':False]
['text':'   c = h(a, b)','line_number':713,'multiline':False]
['text':' is the output from a chunk/bchunk node?','line_number':716,'multiline':False]
['text':' try to find a producer to move after the chunk/bchunk. The producer must','line_number':722,'multiline':False]
['text':' be fusible into the consumer.','line_number':723,'multiline':False]
['text':' all uses of the chunk must be in this consumer','line_number':737,'multiline':False]
['text':' multiple return operators','line_number':744,'multiline':False]
['text':' Convert chunk to bchunk, if it isn't one already. The bchunk represents a','line_number':748,'multiline':False]
['text':' broadcast and one or more chunk operations.','line_number':749,'multiline':False]
['text':' Add each of op's operands to the bchunk node.','line_number':763,'multiline':False]
['text':' chunked_inputs[input_nr][chunk_output_idx]','line_number':764,'multiline':False]
['text':'  = Node* for chunk_output_idx'th output of the chunk(inputs[input_nr])','line_number':765,'multiline':False]
['text':' XXX: we only work with pointwise ops in here, so we know it is valid to','line_number':769,'multiline':False]
['text':' push the concat only through tensor arguments (and all other args can','line_number':770,'multiline':False]
['text':' be safely ignored).','line_number':771,'multiline':False]
['text':' if 'input' is already an input to the bchunk, reuse it.','line_number':775,'multiline':False]
['text':' NB: I decided not to use cloneFrom here, because if we make cloneFrom','line_number':788,'multiline':False]
['text':' copy selects one day, it is definitely not what you want here (selects','line_number':789,'multiline':False]
['text':' have different types).','line_number':790,'multiline':False]
['text':' TODO: Perhaps we should use cloneFrom now, as it seems unlikely','line_number':791,'multiline':False]
['text':' to copy select nodes now that we have refactored to have a Value','line_number':792,'multiline':False]
['text':' distinct from Node.','line_number':793,'multiline':False]
['text':' alas, to not be C++17','line_number':795,'multiline':False]
['text':' Add a fresh value for each output element of the broadcasting chunk','line_number':799,'multiline':False]
['text':' node. This is safe because it will be consumed only by the chunked','line_number':800,'multiline':False]
['text':' ops.','line_number':801,'multiline':False]
['text':' apply the op to each chunk of the chunked operands,','line_number':807,'multiline':False]
['text':' and then rewrite the graph to use them!','line_number':808,'multiline':False]
['text':' NOLINTNEXTLINE(clang-analyzer-core.DivideZero)','line_number':820,'multiline':False]
['text':' Suppress unused variable warning','line_number':834,'multiline':False]
['text':' The output of producer_for_chunk_node could have been used in some','line_number':838,'multiline':False]
['text':' aten::size operators, so we need to clean those up as well (we simply','line_number':839,'multiline':False]
['text':' broadcast all its tensor inputs).','line_number':840,'multiline':False]
['text':' We need to insert these early in the graph, i.e. immediately after','line_number':841,'multiline':False]
['text':' the producer_for_chunk_node as we will have the _size_if_not_same','line_number':842,'multiline':False]
['text':' that may be before the bchunk.','line_number':843,'multiline':False]
['text':' returns where to continue scanning, and whether any fusion was made','line_number':868,'multiline':False]
['text':' handle inputs in reverse topological order as well...','line_number':871,'multiline':False]
['text':' otherwise in f(a,a+b) it will appear a is used twice if we consider','line_number':872,'multiline':False]
['text':' the f-a fusion before the f-(a+b) fusion first.','line_number':873,'multiline':False]
['text':' the chunk before this consumer was re-arranged to allow fusion,','line_number':877,'multiline':False]
['text':' we scan this consumer again to perform the fusion','line_number':878,'multiline':False]
['text':' after fusion, consumer moves into a FusionGroup, so inputs is no','line_number':883,'multiline':False]
['text':' longer valid so we rescan the new FusionGroup for more fusions...','line_number':884,'multiline':False]
['text':' We might delete node, so increment the iterator now.','line_number':895,'multiline':False]
['text':' Split the bchunk into bchunks.inputs().size() number of chunk nodes.','line_number':906,'multiline':False]
['text':' Builds up expressions that compute shapes of all intermediates (and','line_number':927,'multiline':False]
['text':' outputs) of the fusion group, based on the sizes of inputs. You should run','line_number':928,'multiline':False]
['text':' DCE to remove those that you end up not using.','line_number':929,'multiline':False]
['text':' When we have a guarantee that an output won't be removed, because it's','line_number':948,'multiline':False]
['text':' used in expressions that don't involve size checks, we can use its size','line_number':949,'multiline':False]
['text':' instead of computing a long chain of broadcasts, starting from the','line_number':950,'multiline':False]
['text':' beginning of the kernel.','line_number':951,'multiline':False]
['text':' XXX: Use of shape_of.emplace is crucial to the output shape','line_number':964,'multiline':False]
['text':' optimization!','line_number':965,'multiline':False]
['text':' This is a bit more involved, because we have to account for the case','line_number':967,'multiline':False]
['text':' when inputs have different shapes, but fortunately those tensors are','line_number':968,'multiline':False]
['text':' always outputs, and so we can simply avoid replacing their queries,','line_number':969,'multiline':False]
['text':' because it won't help us.','line_number':970,'multiline':False]
['text':' XXX: Iterating in this order is not only good for performance reasons!','line_number':1016,'multiline':False]
['text':' It is also crucial for correctness (i has to reflect the current true','line_number':1017,'multiline':False]
['text':' index of outputs[i])!','line_number':1018,'multiline':False]
['text':' NB: it is important that this check happens after isFusable, which checks','line_number':1039,'multiline':False]
['text':' that the blocks match, and it's not a special node like prim::Param','line_number':1040,'multiline':False]
['text':' If the number of kernel args could exceed the limit, skip.','line_number':1046,'multiline':False]
['text':' Fusion groups can be merged with concat's group if and only if','line_number':1053,'multiline':False]
['text':' the value they produce isn't already coming from a concat','line_number':1054,'multiline':False]
['text':' NB: this deletes the fused_cat node from the original graph','line_number':1076,'multiline':False]
['text':' We could have destroyed multiple inputs when performing this fusion,','line_number':1102,'multiline':False]
['text':' so we have to recompute the list and iterate over it again.','line_number':1103,'multiline':False]
['text':' TODO: old fuser is not maintained internally, somewhere it is being turned on','line_number':1133,'multiline':False]
['text':' inadvertently for certain workflows. make this a no-op until we identify','line_number':1134,'multiline':False]
['text':' location','line_number':1135,'multiline':False]
['text':' Run the pass until no changes are made.','line_number':1140,'multiline':False]
['text':' This is necessary, because the algorithm can miss out on certain fusion','line_number':1141,'multiline':False]
['text':' opportunities if ran only once. Consider this graph:','line_number':1142,'multiline':False]
['text':'','line_number':1143,'multiline':False]
['text':' %1 = f(...)','line_number':1144,'multiline':False]
['text':' %2 = g(%1)','line_number':1145,'multiline':False]
['text':' %3 = h(%1)','line_number':1146,'multiline':False]
['text':' %4 = l(%3)','line_number':1147,'multiline':False]
['text':' return (%4, %2)','line_number':1148,'multiline':False]
['text':'','line_number':1149,'multiline':False]
['text':' where f, g, h, l are simple map ops.','line_number':1150,'multiline':False]
['text':' The first iteration will fuse %4 and %3, and see that %1 is an input, but','line_number':1151,'multiline':False]
['text':' can't be fused, because it has a different use before the fusion group','line_number':1152,'multiline':False]
['text':' in our topological ordering. Then, %2 will be considered, and fused with','line_number':1153,'multiline':False]
['text':' %1. If we do another iteration, the algorithm will consider the fusion of','line_number':1154,'multiline':False]
['text':' these two groups and fix the situation.','line_number':1155,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1160,'multiline':False]
['text':' The graph fuser can add intermediate prim::BroadcastingChunk nodes.','line_number':1171,'multiline':False]
['text':' Replace them with broadcasts + chunks.','line_number':1172,'multiline':False]
['text':' Fuse starting chunks into the group.','line_number':1175,'multiline':False]
['text':' Remove outputs that have been added only because we need their size','line_number':1180,'multiline':False]
['text':' Remove no-op broadcasts.','line_number':1202,'multiline':False]
['text':' Deduplicate inputs, but use their unique() values to ensure','line_number':1208,'multiline':False]
['text':' this process only depends on the graph.','line_number':1209,'multiline':False]
['text':' Revisit the node with deduplicated inputs','line_number':1227,'multiline':False]
['text':' Remove compose simple chains of broadcasts into a single node.','line_number':1230,'multiline':False]
['text':' NB: we don't care about deduplication in here, as we will visit user','line_number':1235,'multiline':False]
['text':' later.','line_number':1236,'multiline':False]
['text':' anonymous namespace','line_number':1246,'multiline':False]
['text':' After FuseGraph some common subexpressions may come back','line_number':1262,'multiline':False]
['text':' We might have emitted a fair amount of useless shape propagating code, so','line_number':1264,'multiline':False]
['text':' remove it','line_number':1265,'multiline':False]
['text':' Improve the quality of shape propagation code that was left','line_number':1267,'multiline':False]
['text':' namespace jit','line_number':1287,'multiline':False]
['text':' namespace torch','line_number':1288,'multiline':False]
