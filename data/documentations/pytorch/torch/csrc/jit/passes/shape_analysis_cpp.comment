['text':'default_to_union=','line_number':44,'multiline':True]
['text':' propagate counter type','line_number':84,'multiline':False]
['text':'insert_expands=','line_number':89,'multiline':True]
['text':' note: inserting expands is unsafe at this point, we don't know','line_number':90,'multiline':False]
['text':' if the types are stable yet, so the arguments to expand may change','line_number':91,'multiline':False]
['text':' now that the types are stable, we can insert the expands','line_number':97,'multiline':False]
['text':'insert_expands=','line_number':98,'multiline':True]
['text':' allow constants','line_number':123,'multiline':False]
['text':'includeBool=','line_number':130,'multiline':True]
['text':' for each node in the schema with type Tensor, extract the T type','line_number':153,'multiline':False]
['text':' returns c10::nullopt if any Tensor in the schema does not have a known','line_number':154,'multiline':False]
['text':' shape ignores non-tensor in the list of inputs','line_number':155,'multiline':False]
['text':' can't handle varargs primitives because we don't know what should be a','line_number':167,'multiline':False]
['text':' Tensor','line_number':168,'multiline':False]
['text':' non-tensor type ','line_number':184,'multiline':True]
['text':' Promotes result types for arithmetic operations on Tensor operands using','line_number':208,'multiline':False]
['text':' new type promotion logic. See tensor_attributes.rst for details.','line_number':209,'multiline':False]
['text':' This doesn't handle the case of arithmetic ops with Scalar arguments (when','line_number':210,'multiline':False]
['text':' `Tensor.getUnsafeTensorImpl()->is_wrapped_number()` would return true)','line_number':211,'multiline':False]
['text':' binary arithmetic ops, more than 2 args is alpha.','line_number':215,'multiline':False]
['text':' if no dimensions','line_number':225,'multiline':False]
['text':' if a tensor with dimensions is already of the highest category, don't','line_number':229,'multiline':False]
['text':' need to check zero-dim tensors.','line_number':230,'multiline':False]
['text':' int_tensor * zero_dim_floating -> floating_tensor','line_number':234,'multiline':False]
['text':' bool_tensor * non_bool_scalar -> non_bool_tensor','line_number':238,'multiline':False]
['text':' types of dimensioned tensors generally take precedence over zero-dim','line_number':243,'multiline':False]
['text':' tensors if not promoting due to category. e.g.:','line_number':244,'multiline':False]
['text':' int_tensor * long -> int_tensor','line_number':245,'multiline':False]
['text':' no dimmed tensors. e.g. zero_dim_tensor + zero_dim_tensor.','line_number':250,'multiline':False]
['text':' ops which take the result and write to input "out"','line_number':282,'multiline':False]
['text':' if the value is actually constant, just use it!','line_number':307,'multiline':False]
['text':' fallthrough','line_number':321,'multiline':False]
['text':' we should not get here because isValidArgumentForRunning should have','line_number':325,'multiline':False]
['text':' prevented it','line_number':326,'multiline':False]
['text':' Check if this node depends on a value that has been mutated previously. If','line_number':367,'multiline':False]
['text':' it has, then it's not safe to run this node in isolation, since we don't','line_number':368,'multiline':False]
['text':' know whether the dependency has been executed.','line_number':369,'multiline':False]
['text':' If something could have written to a value used by this node, we can't','line_number':377,'multiline':False]
['text':' guarantee the result is the same when running it in isolation.','line_number':378,'multiline':False]
['text':' recursively check the producers of its inputs. We need to do this if the','line_number':383,'multiline':False]
['text':' mutable value has been laundered through a pure function:','line_number':384,'multiline':False]
['text':'   a += 1','line_number':385,'multiline':False]
['text':'   c = a + b','line_number':386,'multiline':False]
['text':'   d = c + 1','line_number':387,'multiline':False]
['text':' In this case, `d` cares whether `a` has been mutated even though it's not','line_number':388,'multiline':False]
['text':' a direct input.','line_number':389,'multiline':False]
['text':' If there's no Tensor in outputs, e.g float / float,','line_number':425,'multiline':False]
['text':' we don't need to propagate shape.','line_number':426,'multiline':False]
['text':' XXX: we're not catching any exceptions from the op for now. This','line_number':450,'multiline':False]
['text':' is to uncover any mistakes we could make when editing this code,','line_number':451,'multiline':False]
['text':' and eventually it shouldn't matter, because this phase should be','line_number':452,'multiline':False]
['text':' preceded by schema checking.','line_number':453,'multiline':False]
['text':' some ops may have mixed tensor/primitive outputs','line_number':458,'multiline':False]
['text':' for primitives, we don't need to change the type because it is already','line_number':459,'multiline':False]
['text':' its most constrained form.','line_number':460,'multiline':False]
['text':' gradient information isn't always available or part of representative','line_number':463,'multiline':False]
['text':' inputs, maintain original grad property','line_number':464,'multiline':False]
['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':528,'multiline':False]
['text':'requires_grad=','line_number':572,'multiline':True]
['text':' returns whether any such values were found','line_number':575,'multiline':False]
['text':' Certain ops like resize_ change the input tensors size. Because our','line_number':588,'multiline':False]
['text':' analysis is flow invariant, we set any Tensor that can alias a resized','line_number':589,'multiline':False]
['text':' Tensor to the base Tensor Type without size information.','line_number':590,'multiline':False]
['text':' These don't require the types, and have complicated schema. Return early','line_number':595,'multiline':False]
['text':' after we process them.','line_number':596,'multiline':False]
['text':' correct num type is already set','line_number':609,'multiline':False]
['text':'requires_grad=','line_number':615,'multiline':True]
['text':'requires_grad=','line_number':618,'multiline':True]
['text':' as_tensor has an overloaded schema and can either have a tensor or','line_number':624,'multiline':False]
['text':' a list as the first input, if the input is a tensor, we delegate','line_number':625,'multiline':False]
['text':' the shape propagation in PropagateTensorShapeOnNode','line_number':626,'multiline':False]
['text':' We refresh the tuple type, because the input types could have been','line_number':633,'multiline':False]
['text':' refined.','line_number':634,'multiline':False]
['text':' If we have specialized the optional type to the element type,','line_number':660,'multiline':False]
['text':' we want to pass it down. We write this as input.isSubtypeOf(output)','line_number':661,'multiline':False]
['text':' to be sure that we don't screw up nested optionals.','line_number':662,'multiline':False]
['text':' grad may be undefined','line_number':682,'multiline':False]
['text':' requires_grad may be required','line_number':683,'multiline':False]
['text':' propagate any type specializations encoded in the type of the class','line_number':696,'multiline':False]
['text':' If we have specialized the optional type to the element type,','line_number':701,'multiline':False]
['text':' we want to pass it down. We write this as input.isSubtypeOf(output)','line_number':702,'multiline':False]
['text':' to be sure that we don't screw up nested optionals.','line_number':703,'multiline':False]
['text':' fall-through','line_number':710,'multiline':False]
['text':'complete=','line_number':723,'multiline':True]
['text':' is it ok to try to run the op','line_number':756,'multiline':False]
['text':' If an input is a constant, then we assume that the input is valid','line_number':757,'multiline':False]
['text':' and we can try to run it.','line_number':758,'multiline':False]
['text':' Otherwise:','line_number':759,'multiline':False]
['text':' Integral typed _inputs_ are often an indicator that we're indexing into','line_number':760,'multiline':False]
['text':' a tensor, so we should special-case these ops in the shape propagation.','line_number':761,'multiline':False]
['text':' Additionally, passing in a zero representative tensor into an integer','line_number':762,'multiline':False]
['text':' division op causes divide-by-zero errors','line_number':763,'multiline':False]
['text':' _Outputs_ must be tensors or primitives','line_number':764,'multiline':False]
['text':' We will call inferTypeFrom on the tensors, and ignore the primitives.','line_number':765,'multiline':False]
['text':' However, we allow primitive returns because we want to support mixed','line_number':766,'multiline':False]
['text':' primitive/tensor outputs.','line_number':767,'multiline':False]
['text':'requires_grad=','line_number':790,'multiline':True]
['text':' Formula is expected to return a vector of length equal to the number of','line_number':794,'multiline':False]
['text':' tensor outputs of the node, or an empty vector which implies that it','line_number':795,'multiline':False]
['text':' failed to propagate.','line_number':796,'multiline':False]
['text':' Requirements:','line_number':807,'multiline':False]
['text':'   dims           : preserved','line_number':808,'multiline':False]
['text':'   scalar type    : preserved','line_number':809,'multiline':False]
['text':'   device         : preserved','line_number':810,'multiline':False]
['text':'   tensor inputs  : 1','line_number':811,'multiline':False]
['text':'   tensor outputs : 1','line_number':812,'multiline':False]
['text':' Additionally:','line_number':813,'multiline':False]
['text':'   - First input should be the only tensor input','line_number':814,'multiline':False]
['text':' Requirements:','line_number':900,'multiline':False]
['text':'   dims           : preserved','line_number':901,'multiline':False]
['text':'   scalar type    : preserved, except complex maps to float','line_number':902,'multiline':False]
['text':'   device         : preserved','line_number':903,'multiline':False]
['text':'   tensor inputs  : 1','line_number':904,'multiline':False]
['text':'   tensor outputs : 1','line_number':905,'multiline':False]
['text':' Additionally:','line_number':906,'multiline':False]
['text':'   - First input should be the only tensor input','line_number':907,'multiline':False]
['text':' Maps complex -> float','line_number':915,'multiline':False]
['text':' Requirements:','line_number':929,'multiline':False]
['text':'   dims           : broadcast all tensor args','line_number':930,'multiline':False]
['text':'   scalar type    : promoted from input dtypes','line_number':931,'multiline':False]
['text':'   device         : always matching and preserved','line_number':932,'multiline':False]
['text':'   tensor inputs  : *','line_number':933,'multiline':False]
['text':'   tensor outputs : 1','line_number':934,'multiline':False]
['text':' Tensor-Tensor operators','line_number':937,'multiline':False]
['text':' Requirements:','line_number':952,'multiline':False]
['text':'   dims           : broadcast all tensor args','line_number':953,'multiline':False]
['text':'   scalar type    : always matching and preserved','line_number':954,'multiline':False]
['text':'   device         : always matching and preserved','line_number':955,'multiline':False]
['text':'   tensor inputs  : *','line_number':956,'multiline':False]
['text':'   tensor outputs : 1','line_number':957,'multiline':False]
['text':' Ops with Tensor-Tensor overloads only','line_number':978,'multiline':False]
['text':' Non-binary ops','line_number':1002,'multiline':False]
['text':' Tensor-Scalar operators','line_number':1019,'multiline':False]
['text':' NB: we always take the scalar type of the Tensor','line_number':1050,'multiline':False]
['text':' aten::where is special in that its return type is the second argument's','line_number':1077,'multiline':False]
['text':' (self) type rather than the that of condition','line_number':1078,'multiline':False]
['text':' Requirements:','line_number':1102,'multiline':False]
['text':'   dims           : always matching and preserved','line_number':1103,'multiline':False]
['text':'   scalar type    : always matching and preserved','line_number':1104,'multiline':False]
['text':'   device         : always matching and preserved','line_number':1105,'multiline':False]
['text':'   tensor inputs  : 2','line_number':1106,'multiline':False]
['text':'   tensor outputs : 1','line_number':1107,'multiline':False]
['text':' Requirements:','line_number':1121,'multiline':False]
['text':'   dims           : all tensor args are broadcast','line_number':1122,'multiline':False]
['text':'   scalar type    : byte/uint8','line_number':1123,'multiline':False]
['text':'   device         : always matching and preserved','line_number':1124,'multiline':False]
['text':'   tensor inputs  : *','line_number':1125,'multiline':False]
['text':'   tensor outputs : 1','line_number':1126,'multiline':False]
['text':' Requirements:','line_number':1157,'multiline':False]
['text':'   dims           : 0','line_number':1158,'multiline':False]
['text':'   scalar type    : preserved','line_number':1159,'multiline':False]
['text':'   device         : preserved','line_number':1160,'multiline':False]
['text':'   tensor inputs  : 1','line_number':1161,'multiline':False]
['text':'   tensor outputs : 1','line_number':1162,'multiline':False]
['text':' Additionally:','line_number':1163,'multiline':False]
['text':'   - First input should be the only tensor input','line_number':1164,'multiline':False]
['text':' Requirements:','line_number':1187,'multiline':False]
['text':'   dims           : 0','line_number':1188,'multiline':False]
['text':'   scalar type    : dtype if specified, else preserved','line_number':1189,'multiline':False]
['text':'   device         : preserved','line_number':1190,'multiline':False]
['text':'   tensor inputs  : 1','line_number':1191,'multiline':False]
['text':'   tensor outputs : 1','line_number':1192,'multiline':False]
['text':' Additionally:','line_number':1193,'multiline':False]
['text':'   - First input should be the only tensor input','line_number':1194,'multiline':False]
['text':' Requirements:','line_number':1210,'multiline':False]
['text':'   dims           : 0','line_number':1211,'multiline':False]
['text':'   scalar type    : dtype if specified, else preserved if floating point,','line_number':1212,'multiline':False]
['text':'   otherwise long/int64 device         : preserved tensor inputs  : 1','line_number':1213,'multiline':False]
['text':'   tensor outputs : 1','line_number':1214,'multiline':False]
['text':' Additionally:','line_number':1215,'multiline':False]
['text':'   - First input should be the only tensor input','line_number':1216,'multiline':False]
['text':' Requirements:','line_number':1279,'multiline':False]
['text':'   dims           : 0 if dim is None, otherwise preserved if keepdim ==','line_number':1280,'multiline':False]
['text':'   false or 1 smaller otherwise scalar type    : preserved device :','line_number':1281,'multiline':False]
['text':'   preserved tensor inputs  : 1 tensor outputs : 1','line_number':1282,'multiline':False]
['text':' Additionally:','line_number':1283,'multiline':False]
['text':'   - First input should be the only tensor input','line_number':1284,'multiline':False]
['text':'   - Has a bool keepdim argument','line_number':1285,'multiline':False]
['text':'num_reduced_dim=','line_number':1297,'multiline':True]
['text':'upcast_integer=','line_number':1297,'multiline':True]
['text':' Requirements:','line_number':1303,'multiline':False]
['text':'   dims           : preserved if keepdim == false, 1 smaller otherwise','line_number':1304,'multiline':False]
['text':'   scalar type    : preserved for first output, byte/uint8 for second','line_number':1305,'multiline':False]
['text':'   output if exists device         : preserved tensor inputs  : 1 tensor','line_number':1306,'multiline':False]
['text':'   outputs : 1 or 2','line_number':1307,'multiline':False]
['text':' Additionally:','line_number':1308,'multiline':False]
['text':'   - First input should be the only tensor input','line_number':1309,'multiline':False]
['text':'   - Has a bool keepdim argument','line_number':1310,'multiline':False]
['text':' Ops returning indices as second output','line_number':1316,'multiline':False]
['text':' NB: Note that while this function is generally meant to be used','line_number':1325,'multiline':False]
['text':' with ops that have a single output, we will fix up its return right','line_number':1326,'multiline':False]
['text':' below.','line_number':1327,'multiline':False]
['text':'num_reduced_dim=','line_number':1329,'multiline':True]
['text':'upcast_integer=','line_number':1329,'multiline':True]
['text':' Requirements:','line_number':1337,'multiline':False]
['text':'   dims           : preserved if keepdim == false, 1 smaller otherwise','line_number':1338,'multiline':False]
['text':'   scalar type    : dtype if specified. preserved if floating point,','line_number':1339,'multiline':False]
['text':'   otherwise long/int64 device         : preserved tensor inputs  : 1','line_number':1340,'multiline':False]
['text':'   tensor outputs : 1','line_number':1341,'multiline':False]
['text':' Additionally:','line_number':1342,'multiline':False]
['text':'   - First input should be the only tensor input','line_number':1343,'multiline':False]
['text':'   - has a bool keepdim argument','line_number':1344,'multiline':False]
['text':'num_reduce_dim=','line_number':1354,'multiline':True]
['text':'integer_upcast=','line_number':1355,'multiline':True]
['text':' Requirements:','line_number':1359,'multiline':False]
['text':'   dims           : preserved','line_number':1360,'multiline':False]
['text':'   scalar type    : dtype if specified, preserved if floating point,','line_number':1361,'multiline':False]
['text':'    otherwise long/int64','line_number':1362,'multiline':False]
['text':'   device         : preserved','line_number':1363,'multiline':False]
['text':'   tensor inputs  : 1','line_number':1364,'multiline':False]
['text':'   tensor outputs : 1','line_number':1365,'multiline':False]
['text':' Additionally:','line_number':1366,'multiline':False]
['text':'   - First input should be the only tensor input','line_number':1367,'multiline':False]
['text':'num_reduce_dim=','line_number':1376,'multiline':True]
['text':'integer_upcast=','line_number':1377,'multiline':True]
['text':' Requirements:','line_number':1381,'multiline':False]
['text':'   dims           : preserved','line_number':1382,'multiline':False]
['text':'   scalar type    : dtype if specified, otherwise preserved','line_number':1383,'multiline':False]
['text':'   device         : preserved','line_number':1384,'multiline':False]
['text':'   tensor inputs  : 1','line_number':1385,'multiline':False]
['text':'   tensor outputs : 1','line_number':1386,'multiline':False]
['text':' Additionally:','line_number':1387,'multiline':False]
['text':'   - has bool keepdim and int[] dim arguments','line_number':1388,'multiline':False]
['text':'num_reduced_dim=','line_number':1395,'multiline':True]
['text':'upcast_integer=','line_number':1396,'multiline':True]
['text':'requires_grad=','line_number':1421,'multiline':True]
['text':'requires_grad=','line_number':1451,'multiline':True]
['text':' Requirements:','line_number':1454,'multiline':False]
['text':'   dims           : preserved','line_number':1455,'multiline':False]
['text':'   scalar type    : equal to value of dtype','line_number':1456,'multiline':False]
['text':'   device         : equal to value of device','line_number':1457,'multiline':False]
['text':'   tensor inputs  : 1','line_number':1458,'multiline':False]
['text':'   tensor outputs : 1','line_number':1459,'multiline':False]
['text':' Additionally:','line_number':1460,'multiline':False]
['text':'   - has ScalarType dtype, Layout layout and Device device arguments','line_number':1461,'multiline':False]
['text':' Requirements:','line_number':1483,'multiline':False]
['text':'   dims           : equal to number of elements in size','line_number':1484,'multiline':False]
['text':'   scalar type    : equal to value of dtype','line_number':1485,'multiline':False]
['text':'   device         : equal to value of device','line_number':1486,'multiline':False]
['text':'   tensor inputs  : 1','line_number':1487,'multiline':False]
['text':'   tensor outputs : 1','line_number':1488,'multiline':False]
['text':' Additionally:','line_number':1489,'multiline':False]
['text':'   - has int[] size, ScalarType dtype, Layout layout and Device device','line_number':1490,'multiline':False]
['text':'   arguments','line_number':1491,'multiline':False]
['text':' First, try to match one of the registered formulas to their operator','line_number':1565,'multiline':False]
['text':' sets.','line_number':1566,'multiline':False]
['text':' This section implements shape prop for an assorted set of nodes that only','line_number':1584,'multiline':False]
['text':' need partial information about their input types.','line_number':1585,'multiline':False]
['text':' index_select behaves very weirdly when self.dim() == 0. It allows both','line_number':1653,'multiline':False]
['text':' 0D and 1D indices, and returns a value that has as many dimensions as','line_number':1654,'multiline':False]
['text':' index.','line_number':1655,'multiline':False]
['text':' Gather has this annoying edge case where index always needs to match','line_number':1669,'multiline':False]
['text':' the number of dims of self, **except** when self is 1D and index is 0D','line_number':1670,'multiline':False]
['text':' in which case we return a 0D output.','line_number':1671,'multiline':False]
['text':' The code below implements formulas that need type information for all','line_number':1709,'multiline':False]
['text':' their tensor inputs, and have exactly one output.','line_number':1710,'multiline':False]
['text':'requires_grad=','line_number':1772,'multiline':True]
['text':' Dot product','line_number':1805,'multiline':False]
['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':1807,'multiline':False]
['text':' Matrix multiply','line_number':1809,'multiline':False]
['text':' Unsqueeze + matrix multiply + squeeze','line_number':1812,'multiline':False]
['text':' Matrix vector multiply','line_number':1815,'multiline':False]
['text':' Batched matrix multiply (possibly with squeeze + unsqueeze if one','line_number':1818,'multiline':False]
['text':' argument is 1D)','line_number':1819,'multiline':False]
['text':' For expensive ops we can directly encode their shape propagation','line_number':1877,'multiline':False]
['text':' here, otherwise we fallback to running a fake version of the op','line_number':1878,'multiline':False]
['text':' to get a quick and dirty propagation.','line_number':1879,'multiline':False]
['text':' These nodes handle tensors of different shapes internally, so there's','line_number':1885,'multiline':False]
['text':' no need to insert explicit expand nodes.','line_number':1886,'multiline':False]
['text':' "div" handle tensors of different shapes internally, so there's no need','line_number':1890,'multiline':False]
['text':' to insert explicit expand nodes.','line_number':1891,'multiline':False]
['text':' Note that this function could be merged to the one above , but "div" is','line_number':1892,'multiline':False]
['text':' not always safe to run by itself due to integer divide-by-zero.','line_number':1893,'multiline':False]
['text':' We fake the execution by running "mul" operation instead.','line_number':1894,'multiline':False]
['text':' Binary broadcasting ops','line_number':1946,'multiline':False]
['text':' NB: we don't handle the nodes in any other way (note the lack of','line_number':1947,'multiline':False]
['text':' return!), because the type casting logic in scalar cases is','line_number':1948,'multiline':False]
['text':' non-trivial. It's better to just run them.','line_number':1949,'multiline':False]
['text':'const_inputs=','line_number':1984,'multiline':True]
['text':'const_inputs=','line_number':2001,'multiline':True]
['text':'const_inputs=','line_number':2019,'multiline':True]
['text':'const_inputs=','line_number':2033,'multiline':True]
['text':'const_inputs=','line_number':2048,'multiline':True]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':2051,'multiline':False]
['text':' This will be a copy, so the result will be contiguous','line_number':2083,'multiline':False]
['text':'const_inputs=','line_number':2091,'multiline':True]
['text':'const_inputs=','line_number':2103,'multiline':True]
['text':'const_inputs=','line_number':2115,'multiline':True]
['text':' anonymous namespace','line_number':2147,'multiline':False]
['text':' anonymous namespace','line_number':2217,'multiline':False]
['text':' namespace jit','line_number':2223,'multiline':False]
['text':' namespace torch','line_number':2224,'multiline':False]
