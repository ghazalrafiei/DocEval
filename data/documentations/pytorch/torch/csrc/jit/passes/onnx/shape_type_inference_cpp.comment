['text':' device not available means this is an invalid tensor type (most likely','line_number':45,'multiline':False]
['text':' an empty one) return inferred type directly.','line_number':46,'multiline':False]
['text':' If this param is already known, assign the same Symbol.','line_number':101,'multiline':False]
['text':' If dim.dim_param() is empty, no need to keep track','line_number':112,'multiline':False]
['text':' because there won't be duplicates.','line_number':113,'multiline':False]
['text':' Populate strides based on sizes info, if sizes are all static.','line_number':145,'multiline':False]
['text':' Creating strides ensures yielding True for isCompleteTensor.','line_number':146,'multiline':False]
['text':' Skip when block size is zero. This is when the node is being created,','line_number':195,'multiline':False]
['text':' and doesn't have subblocks attached yet. Run shape inference for these','line_number':196,'multiline':False]
['text':' nodes later, when the subgraph has already completed shape inferencing.','line_number':197,'multiline':False]
['text':' node kind is not ONNX, skipped.','line_number':212,'multiline':False]
['text':' This is a helper function to decide if the non-ONNX node actually has','line_number':232,'multiline':False]
['text':' custom setType from user','line_number':233,'multiline':False]
['text':' Go through every symbolic_sizes and if any one of them is static, we say','line_number':234,'multiline':False]
['text':' this is set by user. On the other hand, if all of them are * (dynamic), we','line_number':235,'multiline':False]
['text':' take this node does not have given type, since unreliable nodes have *','line_number':236,'multiline':False]
['text':' shape anyway.','line_number':237,'multiline':False]
['text':' In jit/passes/onnx/peephole.cpp::eraseListConstruct,','line_number':259,'multiline':False]
['text':' prim::ListConstruct is converted to onnx::Concat. The conversion should','line_number':260,'multiline':False]
['text':' eventually be moved to symbolic. For now, treat this operator as','line_number':261,'multiline':False]
['text':' special case, and change from list type to tensor type. The scalar type','line_number':262,'multiline':False]
['text':' is preserved. If the elemtype is Int, insert a onnx::Concat node into','line_number':263,'multiline':False]
['text':' the graph.','line_number':264,'multiline':False]
['text':' Clone the node n for the new graph.','line_number':295,'multiline':False]
['text':' Clone the input if it is constant.','line_number':309,'multiline':False]
['text':' Only the first output requires this workaround.','line_number':320,'multiline':False]
['text':' In `peephole` pass, user nodes are modified to consume the','line_number':321,'multiline':False]
['text':' input instead.','line_number':322,'multiline':False]
['text':' Try to lookup input value and insert it into the graph.','line_number':330,'multiline':False]
['text':' If the input value is unknown, set it to graph input in the new','line_number':331,'multiline':False]
['text':' graph, and copy over metadata, such as datatype and shape.','line_number':332,'multiline':False]
['text':' Verify if every input has type (either Tensor, Sequence or Optional) and','line_number':372,'multiline':False]
['text':' scalar type. This is a requirement for ONNX graph inputs.','line_number':373,'multiline':False]
['text':' Similar to the function above, but for symbolic shapes.','line_number':443,'multiline':False]
['text':' input_shape.static_size() could be zero when torch.tensor([]) is used.','line_number':490,'multiline':False]
['text':' sym_map is used to match shape symbols between the input and shape.','line_number':528,'multiline':False]
['text':' If there is a mismatch, the output shape cannot be estimated.','line_number':529,'multiline':False]
['text':' condition for corner case of 0d tensor','line_number':733,'multiline':False]
['text':' 0d tensor with 1d tensor would give us 0d tensor','line_number':734,'multiline':False]
['text':' Handle inputs of rank 1 just like numpy.matmul:','line_number':878,'multiline':False]
['text':' https://numpy.org/doc/stable/reference/generated/numpy.matmul.html','line_number':879,'multiline':False]
['text':' Per https://pytorch.org/docs/stable/generated/torch.matmul.html','line_number':893,'multiline':False]
['text':' the broadcasting logic only applies to the batch dimensions, and not the','line_number':894,'multiline':False]
['text':' matrix dimensions so we remove the matrix dimensions which are the last 2','line_number':895,'multiline':False]
['text':' dimensions before broadcasting','line_number':896,'multiline':False]
['text':' add the last 2 dimensions back, unless they do not exist in the first','line_number':902,'multiline':False]
['text':' place and inserted by this function Then apply [n,k]X[k,m]=[n,m], where','line_number':903,'multiline':False]
['text':' n=input_shape_value_0[rank_0 - 2], m=input_shape_value_1[rank_1 - 1]','line_number':904,'multiline':False]
['text':' ONNX keepdims defaults to 1 when not set.','line_number':933,'multiline':False]
['text':' When `shape` input value is statically known, compute output shape.','line_number':956,'multiline':False]
['text':' When `shape` input value is symbolically known, compute output shape.','line_number':974,'multiline':False]
['text':' Only shape of new shape is known, assign output rank.','line_number':988,'multiline':False]
['text':' ListConstruct is handled at the beginning of ProcessConstantValueMap, no','line_number':998,'multiline':False]
['text':' further process here.','line_number':999,'multiline':False]
['text':' Set rank to Reshape output if possible.','line_number':1001,'multiline':False]
['text':' From shape inference, we have:','line_number':1002,'multiline':False]
['text':' %4236 : Float(*, device=cpu) = onnx::Transpose[perm=[0]](%4235)','line_number':1003,'multiline':False]
['text':' %4237 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4232)','line_number':1004,'multiline':False]
['text':' %4238 : FloatTensor(device=cpu) = onnx::Reshape(%4236, %4237)','line_number':1005,'multiline':False]
['text':' We can have it as SymbolicShape with known rank:','line_number':1006,'multiline':False]
['text':' %4238 : Float(*, *, strides=[2480, 1], requires_grad=0, device=cpu) =','line_number':1007,'multiline':False]
['text':' onnx::Reshape(%4236, %4237)','line_number':1008,'multiline':False]
['text':' For opset version <= 9, starts, ends, axes, steps are attributes,','line_number':1072,'multiline':False]
['text':' so their values are always valid.','line_number':1073,'multiline':False]
['text':' We can only infer shapes if 'axes' is known.','line_number':1075,'multiline':False]
['text':' If starts, ends, or step are unknown,','line_number':1117,'multiline':False]
['text':' then mark all dimensions in 'axes' as unknown.','line_number':1118,'multiline':False]
['text':' When the scalar represents a shape, it is the same as the shape value','line_number':1231,'multiline':False]
['text':' when it gets unsqueezed.','line_number':1232,'multiline':False]
['text':' As an addition to onnx shape inference, this function leverages constant','line_number':1237,'multiline':False]
['text':' folding and a per-Op based process to update rank/shape for the graph, also','line_number':1238,'multiline':False]
['text':' it update ConstantValueMap accordingly.','line_number':1239,'multiline':False]
['text':' Constant folding.','line_number':1254,'multiline':False]
['text':' TODO: getDevice() ?','line_number':1285,'multiline':False]
['text':' Need copy here','line_number':1291,'multiline':False]
['text':' When value of `shape` is statically known,','line_number':1382,'multiline':False]
['text':' output shape can be computed.','line_number':1383,'multiline':False]
['text':' When shape of `shape` is statically known,','line_number':1395,'multiline':False]
['text':' output rank can be computed.','line_number':1396,'multiline':False]
['text':' Some inputs can be non-Tensor type, e.g.,','line_number':1563,'multiline':False]
['text':' __torch__.torch.classes.quantized.LinearPackedParamsBase','line_number':1564,'multiline':False]
['text':' so we only need check Tensor type here.','line_number':1565,'multiline':False]
['text':' Update ConstantValueMap on node outputs from onnx shape inference','line_number':1574,'multiline':False]
['text':' For outputs, only update static shapes. For input, we update symbolic','line_number':1575,'multiline':False]
['text':' shapes also. ONNX If can have different types on different branches, skip','line_number':1576,'multiline':False]
['text':' here.','line_number':1577,'multiline':False]
['text':' Update the shape reliability for each node before processing','line_number':1579,'multiline':False]
['text':' ConstantValueMap to prevent unreliable nodes from producing static','line_number':1580,'multiline':False]
['text':' shapes','line_number':1581,'multiline':False]
['text':' Update ConstantValueMap on node inputs from onnx shape inference.','line_number':1597,'multiline':False]
['text':' ListConstruct is handled here (we only consider IntType, not TensorType) ,','line_number':1598,'multiline':False]
['text':' no need to have a per-op based process.','line_number':1599,'multiline':False]
['text':' Only update shape if the input is onnx node.','line_number':1605,'multiline':False]
['text':' If it is aten operators, for example,','line_number':1606,'multiline':False]
['text':'   Float(20, 20, strides=[1, 0], requires_grad=0, device=cpu),','line_number':1607,'multiline':False]
['text':'     %399 : Float(20, 20, strides=[0, 1], requires_grad=0, device=cpu)','line_number':1608,'multiline':False]
['text':'     = prim::ListUnpack(%397)','line_number':1609,'multiline':False]
['text':' The tracer shape may not be correct when dynamic_axes is enabled.','line_number':1610,'multiline':False]
['text':' Need copy here','line_number':1628,'multiline':False]
['text':' Additional logic to update the graph and ConstantValueMap','line_number':1639,'multiline':False]
['text':' Any additional post process that are specific to individual node kind.','line_number':1643,'multiline':False]
['text':' Special case when input sequence to SequenceInsert is empty.','line_number':1647,'multiline':False]
['text':' onnx Sequence type requires element type to be set.','line_number':1648,'multiline':False]
['text':' If the list to insert is empty, we set the elem type by','line_number':1649,'multiline':False]
['text':' looking at the tensor being inserted.','line_number':1650,'multiline':False]
['text':' 1. Input is from SequenceEmpty.','line_number':1672,'multiline':False]
['text':' 2. Input is subblock input of a Loop node, which takes outer block','line_number':1677,'multiline':False]
['text':' SequenceEmpty as input.','line_number':1678,'multiline':False]
['text':' Found SequenceEmpty','line_number':1694,'multiline':False]
['text':' Outer block node still not SequenceEmpty, call recursively in','line_number':1698,'multiline':False]
['text':' case of nested loop.','line_number':1699,'multiline':False]
['text':' Could not find source SequenceEmpty node.','line_number':1709,'multiline':False]
['text':' Try to find original onnx::SequenceEmpty node in outer block.','line_number':1720,'multiline':False]
['text':' ONNX shape inference is not able to assign output tensor shape,','line_number':1732,'multiline':False]
['text':' when input to onnx::Cast has incomplete tensor shape, for example','line_number':1733,'multiline':False]
['text':' missing shape, rank, dtype, etc. This postprocess sets the correct','line_number':1734,'multiline':False]
['text':' dtype for output tensor, since the dtype info is stored in Cast','line_number':1735,'multiline':False]
['text':' attribute.','line_number':1736,'multiline':False]
['text':' ONNX shape inference is not able to propagate output tensor shape','line_number':1746,'multiline':False]
['text':' for onnx::ConstantOfShape if input `shape` is not constant.','line_number':1747,'multiline':False]
['text':' This is a temporary solution when some partial information is','line_number':1748,'multiline':False]
['text':' available, for example, knowing rank of output tensor, or knowing','line_number':1749,'multiline':False]
['text':' symbolic shape. This solution won't be needed once we have proper','line_number':1750,'multiline':False]
['text':' symbolic propagation.','line_number':1751,'multiline':False]
['text':' Shape -> ConstantOfShape','line_number':1754,'multiline':False]
['text':' Assign symbolic shape of original input of onnx::Shape.','line_number':1759,'multiline':False]
['text':' Assign rank of original input of onnx::Shape.','line_number':1765,'multiline':False]
['text':' ListConstruct -> ConstantOfShape','line_number':1772,'multiline':False]
['text':' get data from value_info and updated original graph.','line_number':1809,'multiline':False]
['text':' Check graph outputs for inferred shapes.','line_number':1820,'multiline':False]
['text':' Check value_infos for inferred shapes.','line_number':1825,'multiline':False]
['text':' Copy node input metadata to subgraph input.','line_number':1834,'multiline':False]
['text':' After processing a node for shape inference, remove intermediate tensors','line_number':1842,'multiline':False]
['text':' that are stored in ConstantValueMap to reduce memory usage.','line_number':1843,'multiline':False]
['text':' This will only remove tensors that are no longer needed by any other node.','line_number':1844,'multiline':False]
['text':' Returns whether a node was already processed for shape inference.','line_number':1846,'multiline':False]
['text':' Assumes shape inference can at least determine the rank of the outputs.','line_number':1850,'multiline':False]
['text':' If this assumption is wrong, some intermediate tensors will only be','line_number':1851,'multiline':False]
['text':' deleted once shape inference is completed for the entire graph.','line_number':1852,'multiline':False]
['text':' An input value is no longer needed if all of its consumer nodes','line_number':1857,'multiline':False]
['text':' have already been processed.','line_number':1858,'multiline':False]
['text':' namespace','line_number':1908,'multiline':False]
['text':' For some operators, there are some inputs not related to shape inference.','line_number':1910,'multiline':False]
['text':' For example, LSTM input 4 (sequence_lens) is optional,','line_number':1911,'multiline':False]
['text':' and the shape inference can be done through other required inputs.','line_number':1912,'multiline':False]
['text':' When we compute reliable, we don't need this input be reliable.','line_number':1913,'multiline':False]
['text':' Always consider None reliable and complete, because it represents','line_number':1933,'multiline':False]
['text':' unspecified optional inputs in ONNX.','line_number':1934,'multiline':False]
['text':' There is no need to put onnx type here, but we need this','line_number':1949,'multiline':False]
['text':' for some legacy tests when onnx_shape_inference=False.','line_number':1950,'multiline':False]
['text':' TODO(84661): This warning comes before setType in symbolic_fn.','line_number':1971,'multiline':False]
['text':' tracked in #84661','line_number':1972,'multiline':False]
['text':' Experimental, nothing sent to stdout nor stderr.','line_number':1978,'multiline':False]
['text':' Assume that the tracer can estimate rank correctly,','line_number':1992,'multiline':False]
['text':' then the output tensor of Shape should always be reliable.','line_number':1993,'multiline':False]
['text':' Create a Graph containing only the single node n.','line_number':2036,'multiline':False]
['text':' This graph is later converted to ONNX to run shape inference.','line_number':2037,'multiline':False]
['text':' Register all node outputs as graph outputs.','line_number':2042,'multiline':False]
['text':' Map original PyTorch graph's i/o name','line_number':2047,'multiline':False]
['text':' to temporal ONNX graph's i/o name for shape inference','line_number':2048,'multiline':False]
['text':' Make inferred_shape_data use name from temporal ONNX graph','line_number':2058,'multiline':False]
['text':' instead of original PyTorch graph','line_number':2059,'multiline':False]
['text':' Use scalar_type_analysis without low precision cast','line_number':2066,'multiline':False]
['text':' TODO: Some ops have conversion happen at Peephole pass.','line_number':2074,'multiline':False]
['text':'       The conversion here is incomplete for these ops.','line_number':2075,'multiline':False]
['text':'       e.g: ListConstruct, ListUnpack, etc.','line_number':2076,'multiline':False]
['text':' infer shape','line_number':2083,'multiline':False]
['text':' TODO(#79208): Enable more operators to support data propagation','line_number':2085,'multiline':False]
['text':'check_type=','line_number':2091,'multiline':True]
['text':'error_mode=','line_number':2092,'multiline':True]
['text':'enable_data_propagation=','line_number':2093,'multiline':True]
['text':' TODO: include this as warning once we have a more consolidated','line_number':2106,'multiline':False]
['text':' warning system.','line_number':2107,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-c-arrays)','line_number':2113,'multiline':False]
['text':' NOLINTNEXTLINE(modernize-avoid-c-arrays,cppcoreguidelines-avoid-c-arrays)','line_number':2115,'multiline':False]
['text':' If the node is not ONNX standard, go through every output to check if','line_number':2126,'multiline':False]
['text':' they all have shape. If they all do, this should be reliable even if the','line_number':2127,'multiline':False]
['text':' Op is not from ONNX.','line_number':2128,'multiline':False]
['text':' Custom setType output should get in here if it's set correctly. They','line_number':2130,'multiline':False]
['text':' will be updated to inferred for later updatereliable function.','line_number':2131,'multiline':False]
['text':' Get data propagation result from ONNX shape inference','line_number':2137,'multiline':False]
['text':' Store data propagation result into shapeValueMap','line_number':2150,'multiline':False]
['text':' Use original name in PyTorch graph instead of','line_number':2152,'multiline':False]
['text':' temporary name in intermediate ONNX graph','line_number':2153,'multiline':False]
['text':' Add this back to original_shape_data','line_number':2154,'multiline':False]
['text':' For the node type that does not have ComputeConstant logic, it may have','line_number':2171,'multiline':False]
['text':' reliable shape but its shape is not in ConstantValueMap. So we need this','line_number':2172,'multiline':False]
['text':' logic to update ConstantValueMap.','line_number':2173,'multiline':False]
['text':' Recursively look into elements in `output_obj`, and assign shape/type info','line_number':2257,'multiline':False]
['text':' into flattened graph outputs. `outputs_index` is passed in to point to the','line_number':2258,'multiline':False]
['text':' current index in flattened graph outputs. The updated `outputs_index` is','line_number':2259,'multiline':False]
['text':' returned at the end of the function.','line_number':2260,'multiline':False]
['text':' When torch output is a list type, but ONNX node is not a','line_number':2330,'multiline':False]
['text':' sequence type. Like prim::ListConstruct','line_number':2331,'multiline':False]
['text':' Support for dict data type is limited to fixed size dictionaries in','line_number':2343,'multiline':False]
['text':' ONNX.','line_number':2344,'multiline':False]
['text':' Dictionary values are unrolled and keys are not preserved.','line_number':2345,'multiline':False]
['text':' Ignore string, since they are not supported as output in ONNX.','line_number':2360,'multiline':False]
['text':' Tracing:','line_number':2362,'multiline':False]
['text':'    Ignore None, since it is not captured in IR graph as output.','line_number':2363,'multiline':False]
['text':' Scripting:','line_number':2364,'multiline':False]
['text':'    Ignore None, if observing a fixed `None` node in IR graph. Because','line_number':2365,'multiline':False]
['text':'    it is meaningless to include it as graph output as it carries no','line_number':2366,'multiline':False]
['text':'    data/information. Plus that static `None` is not supported in ONNX','line_number':2367,'multiline':False]
['text':'    IR. Otherwise, the output should have type `Optional`, and should be','line_number':2368,'multiline':False]
['text':'    converted to ONNX `Optional`.','line_number':2369,'multiline':False]
['text':' More context:','line_number':2371,'multiline':False]
['text':' Cause: in tracing we flatten the outputs in ONNXTracedModule.forward','line_number':2372,'multiline':False]
['text':' in torch/jit/_trace.py while tracing. This means the traced IR graph','line_number':2373,'multiline':False]
['text':' has None outputs omitted.','line_number':2374,'multiline':False]
['text':' But then the outputs passed in here are un-flattened, which means they','line_number':2375,'multiline':False]
['text':' contain None objects. Ideally we'd remove this difference.','line_number':2376,'multiline':False]
['text':' replace only the last value as Optional type only affects','line_number':2416,'multiline':False]
['text':' the value right before output','line_number':2417,'multiline':False]
['text':' TODO: ListType case','line_number':2467,'multiline':False]
['text':' namespace jit','line_number':2478,'multiline':False]
['text':' namespace torch','line_number':2479,'multiline':False]
