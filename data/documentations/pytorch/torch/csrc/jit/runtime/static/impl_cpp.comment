['text':' used in test only','line_number':50,'multiline':False]
['text':' namespace','line_number':73,'multiline':False]
['text':' A manually curated set of ops that are disallowed in static runtime.','line_number':75,'multiline':False]
['text':' These are rarely-used ops. Disallowing them typically eliminates','line_number':76,'multiline':False]
['text':' corner cases in graph optimizations, allowing for more aggressive','line_number':77,'multiline':False]
['text':' optimizations and better performance.','line_number':78,'multiline':False]
['text':' We can't support aten::__is__ (and __isnot__) with tensor arguments.','line_number':85,'multiline':False]
['text':' Consider the following graph:','line_number':86,'multiline':False]
['text':' def forward(x):','line_number':87,'multiline':False]
['text':'     y = x.detach()','line_number':88,'multiline':False]
['text':'     return x is y','line_number':89,'multiline':False]
['text':' We have a graph optimization that removes the `detach` node since it is','line_number':90,'multiline':False]
['text':' a no-op during inference. But this affects the result - we get true','line_number':91,'multiline':False]
['text':' instead of false! There are many other graph passes affected by this','line_number':92,'multiline':False]
['text':' issue.','line_number':93,'multiline':False]
['text':' The ordering prevents && from short circuiting, which we want -','line_number':107,'multiline':False]
['text':' it's useful to see *all* the unsupported ops.','line_number':108,'multiline':False]
['text':' check if can get op from Node','line_number':116,'multiline':False]
['text':' namespace','line_number':126,'multiline':False]
['text':' Graph must be frozen. canEnableStaticRuntime will return false','line_number':128,'multiline':False]
['text':' if there's any prim::CallMethod ops left in the graph.','line_number':129,'multiline':False]
['text':' namespace','line_number':140,'multiline':False]
['text':' These fused ops only have out variants - we can't do the fusion when','line_number':192,'multiline':False]
['text':' out variants are disabled.','line_number':193,'multiline':False]
['text':' custom_ops ','line_number':217,'multiline':True]
['text':' remove unused input 0 from graph','line_number':228,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)','line_number':243,'multiline':False]
['text':' AliasDb is not const-correct here, so we have to const_cast','line_number':250,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)','line_number':251,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)','line_number':259,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)','line_number':264,'multiline':False]
['text':' Static runtime moves its outputs out of the runtime','line_number':275,'multiline':False]
['text':' by default. In some rare cases, this is not actually safe to','line_number':276,'multiline':False]
['text':' do - for example, if the value is a constant, static runtime','line_number':277,'multiline':False]
['text':' needs to hold onto a copy. Rather than adding special logic','line_number':278,'multiline':False]
['text':' to handle this rare case, we use this pass to detect it and','line_number':279,'multiline':False]
['text':' create an owned reference that can be safely moved out of the','line_number':280,'multiline':False]
['text':' runtime.','line_number':281,'multiline':False]
['text':' We assume that each sub-block has at least one output. If we','line_number':284,'multiline':False]
['text':' detect any that have 0, force the sub-block to return None.','line_number':285,'multiline':False]
['text':' namespace','line_number':327,'multiline':False]
['text':' Build `external_aliases` as we look through nodes forwardly from','line_number':332,'multiline':False]
['text':' the graph's inputs and add aliases of the inputs being created by the','line_number':333,'multiline':False]
['text':' nodes.','line_number':334,'multiline':False]
['text':' Constants are already in `external_aliases`.','line_number':345,'multiline':False]
['text':' Build `output_aliases` as we look through nodes reversely so that we can','line_number':355,'multiline':False]
['text':' start from the output values, and follow the flows backwardly from there.','line_number':356,'multiline':False]
['text':' Constants cannot create any aliases.','line_number':360,'multiline':False]
['text':' return true only if all outputs are tensors','line_number':382,'multiline':False]
['text':' namespace','line_number':395,'multiline':False]
['text':' Handle aliases. Aliases may extend a Value*'s lifetime. If a node','line_number':431,'multiline':False]
['text':' has an input and output that may alias each other, set the input's','line_number':432,'multiline':False]
['text':' lifetime end to max(input.lifetime_end, output.lifetime_end). Iterate','line_number':433,'multiline':False]
['text':' backwards to handle chains of aliases.','line_number':434,'multiline':False]
['text':' If the node is a pure function, it doesn't create any aliases,','line_number':437,'multiline':False]
['text':' so we can safely skip it.','line_number':438,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':460,'multiline':False]
['text':' const_cast is safe here, this is just a way to avoid code duplication','line_number':506,'multiline':False]
['text':' between the const/non-const versions of getLifetime.','line_number':507,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)','line_number':509,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)','line_number':512,'multiline':False]
['text':' recursively attach metadata to prim::fork nodes','line_number':555,'multiline':False]
['text':' check opt flags','line_number':558,'multiline':False]
['text':' handle schema','line_number':570,'multiline':False]
['text':' Create ProcessedFunction instances first to freeze their addresses to pass','line_number':592,'multiline':False]
['text':' to ProcessedNode.','line_number':593,'multiline':False]
['text':'isFrozen=','line_number':594,'multiline':True]
['text':' Maps each Value* in the graph to its index in the values_ array that will','line_number':597,'multiline':False]
['text':' eventually be created by StaticRuntime.','line_number':598,'multiline':False]
['text':' see [Check and correct bad schema alias info at runtime]','line_number':700,'multiline':False]
['text':' new ProcessedFunction','line_number':704,'multiline':False]
['text':' create a new ProcessedNode','line_number':745,'multiline':False]
['text':' The index is unused if there are no outputs, so just create a','line_number':747,'multiline':False]
['text':' placeholder value.','line_number':748,'multiline':False]
['text':' FBCODE_CAFFE2','line_number':786,'multiline':False]
['text':' Never manage graph outputs so that we can do std::move(output_ivalue).','line_number':810,'multiline':False]
['text':' This does not affect performance if the graph returns a collection object.','line_number':811,'multiline':False]
['text':' collect register indices of outputs of ops with out variant','line_number':815,'multiline':False]
['text':' Types are stored in the underlying TorchScript IR','line_number':824,'multiline':False]
['text':' We "leak" certain container types because their allocations','line_number':838,'multiline':False]
['text':' take a long time','line_number':839,'multiline':False]
['text':' TODO(T108633124): Turn on manage output tensors for sub-blocks.','line_number':912,'multiline':False]
['text':' attach the async taskLauncher to processedNodes','line_number':928,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':946,'multiline':False]
['text':' Fast path for most common case','line_number':967,'multiline':False]
['text':' namespace','line_number':982,'multiline':False]
['text':' Start at 1 since the schema always contains `self`.','line_number':1031,'multiline':False]
['text':' NB: No need to incref here. This codepath is only hit if the run didn't','line_number':1096,'multiline':False]
['text':' finish, so we shouldn't be returning anything to the client.','line_number':1097,'multiline':False]
['text':' namespace','line_number':1105,'multiline':False]
['text':' We have to iterate in reverse order here due to borrowed','line_number':1108,'multiline':False]
['text':' IValues - we don't want to destroy a value until all of its','line_number':1109,'multiline':False]
['text':' borrows are cleaned up!','line_number':1110,'multiline':False]
['text':' We must clean up intermediate values before inputs in case','line_number':1118,'multiline':False]
['text':' there are borrowed inputs and static runtime owns the only','line_number':1119,'multiline':False]
['text':' reference (e.g. the inputs were std::move'd into the runtime)','line_number':1120,'multiline':False]
['text':' use move here. Otherwise, clean up outputs_[i] explicitly','line_number':1141,'multiline':False]
['text':'/ [Check and correct bad schema alias info at runtime]','line_number':1149,'multiline':False]
['text':'/ Static runtime relies on the operator schema's alias info to be correct for','line_number':1150,'multiline':False]
['text':'/ memory planning. Because it's hard to enforce the alias info to be correct,','line_number':1151,'multiline':False]
['text':'/ we need to do runtime detection for accidental aliases that do not comply','line_number':1152,'multiline':False]
['text':'/ with the schema. Only aliases of managed tensors are problematic. To avoid','line_number':1153,'multiline':False]
['text':'/ runtime crashes, we can add runtime detection and force the op to comply','line_number':1154,'multiline':False]
['text':'/ with its schema by cloning the alias. Because all managed tensors' data_ptrs','line_number':1155,'multiline':False]
['text':'/ are part of the internal buffer that the MemoryPlanner allocates, we can','line_number':1156,'multiline':False]
['text':'/ check aliases by checking the memory overlap with this internal buffer. But','line_number':1157,'multiline':False]
['text':'/ a tensor's storage can be resized during inferenceso we need another way to','line_number':1158,'multiline':False]
['text':'/ handle the resized case.','line_number':1159,'multiline':False]
['text':'/','line_number':1160,'multiline':False]
['text':'/ There are two ways for incorrect schema to break memory planning. Let's look','line_number':1161,'multiline':False]
['text':'/ at two examples:','line_number':1162,'multiline':False]
['text':'/','line_number':1163,'multiline':False]
['text':'/ Example 1:','line_number':1164,'multiline':False]
['text':'/ @code','line_number':1165,'multiline':False]
['text':'/   def forward(x):','line_number':1166,'multiline':False]
['text':'/     a = x + x','line_number':1167,'multiline':False]
['text':'/     b = bad_op(a)  # b ends up aliasing a incorrectly','line_number':1168,'multiline':False]
['text':'/     return (b)','line_number':1169,'multiline':False]
['text':'/ @endcode','line_number':1170,'multiline':False]
['text':'/ bad_op: its schema says it returns a new Tensor, but it actually returns an','line_number':1171,'multiline':False]
['text':'/ alias. In this case, the memory planner would recognize `a` as a managed','line_number':1172,'multiline':False]
['text':'/ tensor and clean up its memory before returning `b`. But `b` is actually an','line_number':1173,'multiline':False]
['text':'/ alias of `a`, when `a`'s data_ptr get reset, `b`'s data_ptr gets reset too.','line_number':1174,'multiline':False]
['text':'/','line_number':1175,'multiline':False]
['text':'/ Example 2:','line_number':1176,'multiline':False]
['text':'/ @code','line_number':1177,'multiline':False]
['text':'/   def forward(x):','line_number':1178,'multiline':False]
['text':'/     a = x + x','line_number':1179,'multiline':False]
['text':'/     a2 = bad_op(a) # a2 ends up alias a incorrectly','line_number':1180,'multiline':False]
['text':'/     b = a + a','line_number':1181,'multiline':False]
['text':'/     c = b * b # c shares storage with a','line_number':1182,'multiline':False]
['text':'/     d = c + 2 # d shares storage with b','line_number':1183,'multiline':False]
['text':'/     e = a2 * a2','line_number':1184,'multiline':False]
['text':'/     return (d, e)','line_number':1185,'multiline':False]
['text':'/ @endcode','line_number':1186,'multiline':False]
['text':'/ With the memory reuse algorithm, `c` could end up sharing storage with `a`,','line_number':1187,'multiline':False]
['text':'/ but because of bad_op, `a2` now aliases `a`. `c` overwrites `a` and','line_number':1188,'multiline':False]
['text':'/ therefore `a2`, leading to the wrong results. We solve this problem with two','line_number':1189,'multiline':False]
['text':'/ steps. Note this doesn't happen with the current memory reuse algorithm','line_number':1190,'multiline':False]
['text':'/ because of the way it's implemented. Things could change with a different','line_number':1191,'multiline':False]
['text':'/ implementation.','line_number':1192,'multiline':False]
['text':'/','line_number':1193,'multiline':False]
['text':'/ Step 1, annotate the ProcessedNodes with a flag `check_memory_overlap_` set','line_number':1194,'multiline':False]
['text':'/ to true if its outputs do not alias its inputs as indicated by the AliasDb','line_number':1195,'multiline':False]
['text':'/ and all of its outputs are Tensors. Then at runtime, we check that the','line_number':1196,'multiline':False]
['text':'/ nodes' output tensors do not overlap with the internal buffer that the','line_number':1197,'multiline':False]
['text':'/ MemoryPlanner allocates. For latency concerns, we only run this check for','line_number':1198,'multiline':False]
['text':'/ fallback ops. The schemas of native ops and out variants are vetted and','line_number':1199,'multiline':False]
['text':'/ enforced with static runtime unit tests. For the first iteration, we do a','line_number':1200,'multiline':False]
['text':'/ full memory overlap check with','line_number':1201,'multiline':False]
['text':'/ ProcessedNode::verify_and_correct_memory_overlap() because the internal','line_number':1202,'multiline':False]
['text':'/ buffer doesn't exist yet.','line_number':1203,'multiline':False]
['text':'/','line_number':1204,'multiline':False]
['text':'/ Step 2, if a managed tensor gets resized during inference, it gets a new','line_number':1205,'multiline':False]
['text':'/ data_ptr which is not from the buffer. We can tackle this corner case by','line_number':1206,'multiline':False]
['text':'/ delaying the deallocation of the managed tensors to after the outputs are no','line_number':1207,'multiline':False]
['text':'/ longer used (essentially merging the internal/output buffers into one).','line_number':1208,'multiline':False]
['text':'/ Before the merging is implemented, we add another flag `overlap_detected_`','line_number':1209,'multiline':False]
['text':'/ to flag any node with overlap detected in Step 1 and do a full memory','line_number':1210,'multiline':False]
['text':'/ overlap check if the fast check (by checking memory overlap with internal','line_number':1211,'multiline':False]
['text':'/ buffer) fails. There is still a corner case that fails with the added flag.','line_number':1212,'multiline':False]
['text':'/ If a resize is triggered at the same time as the op creating an alias at the','line_number':1213,'multiline':False]
['text':'/ same time, the current checks would fail to detect the alias.','line_number':1214,'multiline':False]
['text':' The slow check can be removed once the internal/output buffers are merged','line_number':1216,'multiline':False]
['text':' slow check, for first iter only','line_number':1219,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)','line_number':1235,'multiline':False]
['text':' slow check. Only run when the fast check fails.','line_number':1242,'multiline':False]
['text':' Assume cleanup cannot throw.','line_number':1263,'multiline':False]
['text':'output_returned','line_number':1266,'multiline':True]
['text':' MemoryPlanner is created after the first invocation of `run()`. This','line_number':1271,'multiline':False]
['text':' is done intentionally because MemoryPlanner uses `Tensor` sizes of','line_number':1272,'multiline':False]
['text':' the previous `run()` for memory planning of subsequent runs','line_number':1273,'multiline':False]
['text':' This is the first run, and it didn't finish, so we can't use a','line_number':1281,'multiline':False]
['text':' `MemoryPlanner` to deallocate stuff. Just reset everything manually.','line_number':1282,'multiline':False]
['text':' clean up owning refs of input tensors','line_number':1285,'multiline':False]
['text':' We assume inference workloads, so we do not need','line_number':1296,'multiline':False]
['text':' autograd. Enabling this is a significant win on dispatcher','line_number':1297,'multiline':False]
['text':' overhead because it saves a round of dispatch for at least some','line_number':1298,'multiline':False]
['text':' functions, such as resize_ and resize_as_.','line_number':1299,'multiline':False]
['text':' LOG(INFO) << "Running node: " << PrintNode(n.node());','line_number':1313,'multiline':False]
['text':' Check for incorrect schema alias info.','line_number':1315,'multiline':False]
['text':' no need to keep references of outputs in static runtime anymore','line_number':1321,'multiline':False]
['text':'output_returned','line_number':1326,'multiline':True]
['text':' use move here. Otherwise, clean up outputs_[0] explicitly','line_number':1328,'multiline':False]
['text':' run the graph inline in the caller thread. Async ops will be','line_number':1355,'multiline':False]
['text':' executed on taskLauncher attached to the metadata of ProcessedNodes','line_number':1356,'multiline':False]
['text':' If the output is of type future, return it','line_number':1359,'multiline':False]
['text':' wrap the output into future, mark completed and return it','line_number':1364,'multiline':False]
['text':' namespace','line_number':1454,'multiline':False]
['text':' Suppress unused variable warning','line_number':1590,'multiline':False]
['text':' Suppress unused variable warning','line_number':1601,'multiline':False]
['text':' When the given input is empty, compute the op statistics from the given','line_number':1699,'multiline':False]
['text':' graph without executing it.','line_number':1700,'multiline':False]
['text':' TODO: Collect op statistics from sub-blocks here.','line_number':1705,'multiline':False]
['text':' See comment on above use of InferenceMode for','line_number':1731,'multiline':False]
['text':' explanation.','line_number':1732,'multiline':False]
['text':' setup time','line_number':1735,'multiline':False]
['text':' The first iteration profiles each node's output Tensors' sizes and','line_number':1742,'multiline':False]
['text':' initializes the memory planner with the profile information. Following','line_number':1743,'multiline':False]
['text':' iterations just use the already established memory planning.','line_number':1744,'multiline':False]
['text':' warmup runs','line_number':1752,'multiline':False]
['text':' Suppress unused variable warning','line_number':1754,'multiline':False]
['text':' main runs','line_number':1764,'multiline':False]
['text':' Suppress unused variable warning','line_number':1766,'multiline':False]
['text':' clean up owning refs of input tensors','line_number':1788,'multiline':False]
['text':' no need to keep references of outputs in static runtime anymore','line_number':1797,'multiline':False]
['text':'output_returned','line_number':1803,'multiline':True]
['text':' use move here. Otherwise, clean up outputs_[0] explicitly','line_number':1805,'multiline':False]
['text':' release outputs explicitly to measure the time it takes','line_number':1807,'multiline':False]
['text':' post processing','line_number':1814,'multiline':False]
['text':' check for inputs','line_number':1846,'multiline':False]
['text':' subtlety: isManagedOutputTensorValue may give a false','line_number':1863,'multiline':False]
['text':' negative here if an output is an alias of this value, so','line_number':1864,'multiline':False]
['text':' check the actual tensor!','line_number':1865,'multiline':False]
['text':' `ival` contains a managed output tensor that the runtime doesn't','line_number':1868,'multiline':False]
['text':' reclaim at the end of an iteration, but the client does so','line_number':1869,'multiline':False]
['text':' by explicitly calling','line_number':1870,'multiline':False]
['text':' `BlockRunner::deallocateOutputTensors`.','line_number':1871,'multiline':False]
['text':' check for intermediates','line_number':1879,'multiline':False]
['text':' check for outputs','line_number':1900,'multiline':False]
['text':' ival can not be a tensor if it's being managed by ops like','line_number':1944,'multiline':False]
['text':' to_maybe_copy_out; see ReplaceWithMaybeCopy for details.','line_number':1945,'multiline':False]
['text':' It's possible that manage_output_tensors_ was disabled after initializing','line_number':1967,'multiline':False]
['text':' managed_output_tensor_values, so we have to check that flag here.','line_number':1968,'multiline':False]
['text':' Reset all IValues and destruct planner_ so that it can be reconstructed in','line_number':1984,'multiline':False]
['text':' the next run.','line_number':1985,'multiline':False]
['text':' do not check memory overlap for out variants','line_number':2005,'multiline':False]
['text':' skip this check in opt mode because these ops are better vetted','line_number':2016,'multiline':False]
['text':' Need to store the number of inputs in stack for variadic ops.','line_number':2033,'multiline':False]
['text':' run check but do not enforce','line_number':2110,'multiline':False]
['text':' skip memory overlap check for mutable or view ops with only one output','line_number':2177,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)','line_number':2245,'multiline':False]
['text':' default task launcher set to inter-op thread pool','line_number':2262,'multiline':False]
['text':'is_root_block','line_number':2269,'multiline':True]
['text':' recurse_on_sub_blocks ','line_number':2302,'multiline':True]
['text':' namespace torch::jit','line_number':2325,'multiline':False]
