['text':'*
 * If the type is not NamedTuple, it will return default_type_str. If the type
 * is a NamedTuple, it will return a string with following structure to describe
 * the content in the NamedTuple: "qualified_named[ NamedTuple, [ [filed_name_1,
 * field_type_1], [filed_name_2, field_type_2]
 *   ]
 * ]"
 *  Example NamedTuple type:
 *  "__torch__.base_models.sparse_nn.pytorch_preproc_types.PreprocOutputType[
 *     NamedTuple, [
 *         [float_features, Tensor],
 *         [id_list_features, List[Tensor]],
 *         [label,  Tensor],
 *         [weight, Tensor],
 *         ]
 *     ]"
 *
 * @param compilation_unit Jit compilation unit to look up function schema.
 * @param type_ptr A type pointer and it can be possibly any type.
 * @param default_type_str The default string representation. The string can
 * either from type_ptr->str(), type_ptr->annotation_str(), or
 * type_ptr->repr_str(). In some cases, they could be different in different
 * scenario. For example, Tensor type can be "Tensor", "Tensor (inferred)" and
 * "Tensor[]", and we only want "Tensor". Leave it as part of arguments as the
 * default return, when type_ptr is not a NamedTuple.
 * @return string representation.
 ','line_number':81,'multiline':True]
['text':' For the simple types (Tensor, Tensor), the mobile type parse can parse','line_number':113,'multiline':False]
['text':' it and compilation unit won't have it's definition. The default type','line_number':114,'multiline':False]
['text':' string will be returned instead.','line_number':115,'multiline':False]
['text':' Get the field name and field type for the NamedTuple','line_number':123,'multiline':False]
['text':' When it->type() is Tensor type, in Python, if it's inferred type,','line_number':129,'multiline':False]
['text':' str() return "Tensor" and repr_str() return "Tensor (inferred)". If','line_number':130,'multiline':False]
['text':' it's not inferred type, str() return "Tensor[]" and repr_str()','line_number':131,'multiline':False]
['text':' return "Tensor". In cpp, repr_str() will always return "Tensor"','line_number':132,'multiline':False]
['text':' regardless inferred type. When exporing custom type in bytecode,','line_number':133,'multiline':False]
['text':' "Tensor" is the preferred way to deserialize Tensor type','line_number':134,'multiline':False]
['text':' The type can also be NamedTuple. Will parse it recursively and get','line_number':138,'multiline':False]
['text':' it's string representation.','line_number':139,'multiline':False]
['text':' instructions','line_number':169,'multiline':False]
['text':' operators','line_number':176,'multiline':False]
['text':' types','line_number':190,'multiline':False]
['text':' For DictType, there are two items in t->containedTypes(), the first one','line_number':203,'multiline':False]
['text':' is key and the second one is value. Both of them could be NamedTuple','line_number':204,'multiline':False]
['text':' type.','line_number':205,'multiline':False]
['text':' Construct the dict representation after achieving correct string','line_number':213,'multiline':False]
['text':' representation for both key and value, like','line_number':214,'multiline':False]
['text':' "Dict[str,__torch__.dper3.core.pytorch_schema_utils.IdScoreListFeatureTuple[NamedTuple,','line_number':215,'multiline':False]
['text':' [[lengths, Tensor],[values,','line_number':216,'multiline':False]
['text':' __torch__.dper3.core.pytorch_schema_utils.IdScoreTuple[NamedTuple,','line_number':217,'multiline':False]
['text':' [[ids, Tensor],[scores, Tensor]]]],[offsets, Optional[Tensor]]]]]"','line_number':218,'multiline':False]
['text':' since the register location is embedded into the bytecode, pass the','line_number':244,'multiline':False]
['text':' register size','line_number':245,'multiline':False]
['text':' schema','line_number':255,'multiline':False]
['text':'
        This part adds the argument's name, type and default_value in
        `bytecode.pkl` This has to be consistent with the `code/` directory
        which has annotated py code of the entire module. `type_printer` uses
        `TypeNameUniquer` to get the managled name of the argument. This helps
        in having the right object reference when a class method is called using
        the `self` argument.

        arg.type()->annotation_str(type_printer) => mangled unique name of the
        module/submodule
      ','line_number':274,'multiline':True]
['text':' function tuple','line_number':302,'multiline':False]
['text':' module debug info','line_number':317,'multiline':False]
['text':' This is just a set of debug handles.','line_number':318,'multiline':False]
['text':' We always save debug handles.','line_number':319,'multiline':False]
['text':' debug handles generated by debug_handle_manager','line_number':320,'multiline':False]
['text':' will correspond to {source_range, inlinedCallStackPtr} which we will','line_number':321,'multiline':False]
['text':' serialize separately.','line_number':322,'multiline':False]
['text':' Check if the global static map of backend debug info','line_number':369,'multiline':False]
['text':' contains debug info for this module and any of its children.','line_number':370,'multiline':False]
['text':' If so combine all the maps together and return one.','line_number':371,'multiline':False]
['text':' This map is map of debug handle-to-DebugInfoTuple','line_number':397,'multiline':False]
['text':' DebugInfoTuple= <source range, op name, inlined_cs_ptr>','line_number':398,'multiline':False]
['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':404,'multiline':False]
['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':408,'multiline':False]
['text':' TODO: remove mobileInterfaceCallExport as it is no longer needed.','line_number':427,'multiline':False]
['text':' This function was introduced to guard the usage of `InterfaceCall` and','line_number':428,'multiline':False]
['text':' now the support for `InterfaceCall` should be mature enough.','line_number':429,'multiline':False]
['text':' namespace','line_number':435,'multiline':False]
['text':' Serialize the model object','line_number':455,'multiline':False]
['text':'archive_name=','line_number':458,'multiline':True]
['text':'archive_dir=','line_number':459,'multiline':True]
['text':'tensor_dir=','line_number':460,'multiline':True]
['text':' Then we serialize all code info.','line_number':461,'multiline':False]
['text':' The tensor constants from the code are written to a separate archive','line_number':464,'multiline':False]
['text':' so loading the code does not depend on loading the data','line_number':465,'multiline':False]
['text':'archive_name=','line_number':471,'multiline':True]
['text':'archive_dir=','line_number':472,'multiline':True]
['text':'tensor_dir=','line_number':473,'multiline':True]
['text':'use_storage_context=','line_number':474,'multiline':True]
['text':'archive_name=','line_number':480,'multiline':True]
['text':'archive_dir=','line_number':481,'multiline':True]
['text':'tensor_dir=','line_number':482,'multiline':True]
['text':'archive_name=','line_number':487,'multiline':True]
['text':'archive_dir=','line_number':488,'multiline':True]
['text':'tensor_dir=','line_number':489,'multiline':True]
['text':'use_storage_context','line_number':490,'multiline':True]
['text':'skip_tensor_data','line_number':491,'multiline':True]
['text':' Acquires and sets minimum (dynamic) version','line_number':493,'multiline':False]
['text':' Vector to capture the run-time class types during pickling the IValues','line_number':507,'multiline':False]
['text':' tensors that are already serialized in use_storage_context','line_number':510,'multiline':False]
['text':' returns a string to use in picker.cpp as storage obj key','line_number':522,'multiline':False]
['text':' this case is hit when storage has been serialized already','line_number':531,'multiline':False]
['text':' from a torch.package context','line_number':532,'multiline':False]
['text':' write out tensor data','line_number':544,'multiline':False]
['text':' storage has been serialzed already, skip','line_number':558,'multiline':False]
['text':' serialize all the captured run-time class types','line_number':570,'multiline':False]
['text':' Write out extra files.','line_number':579,'multiline':False]
['text':' Checks if the hooked file is already written in extra files,','line_number':588,'multiline':False]
['text':'   if so, skips it and warns','line_number':589,'multiline':False]
['text':' note: convertNameType may extend class_deps_, so re-checking .size() is','line_number':618,'multiline':False]
['text':' necessary','line_number':619,'multiline':False]
['text':' Mapping of filename => src. We need this because multiple classes may go','line_number':626,'multiline':False]
['text':' in the same file (e.g. foo.bar.Baz and foo.bar.Qux)','line_number':627,'multiline':False]
['text':' Only compress these records if they're not tiny.','line_number':633,'multiline':False]
['text':' The cpu cost of generating zip datastructs and compressing isn't','line_number':634,'multiline':False]
['text':' well-spent for very small records.','line_number':635,'multiline':False]
['text':'compress','line_number':642,'multiline':True]
['text':' Write out the debug information','line_number':644,'multiline':False]
['text':'compress','line_number':654,'multiline':True]
['text':' Always save debug handles','line_number':667,'multiline':False]
['text':'archive_name=','line_number':684,'multiline':True]
['text':'archive_dir=','line_number':685,'multiline':True]
['text':'tensor_dir=','line_number':686,'multiline':True]
['text':'use_storage_context=','line_number':687,'multiline':True]
['text':' At the moment keeping this feature experimental','line_number':691,'multiline':False]
['text':' since we have not evaluated how this affect model size','line_number':692,'multiline':False]
['text':' and we have not build any utility to strip off debug info','line_number':693,'multiline':False]
['text':' when desired','line_number':694,'multiline':False]
['text':' TODO: Build utility to strip off debug map. It should also do the','line_number':695,'multiline':False]
['text':' same for debug_pkl files','line_number':696,'multiline':False]
['text':' Note that stripping off debug map will not strip off','line_number':698,'multiline':False]
['text':' debug handles.','line_number':699,'multiline':False]
['text':' The reason we save debug handles conditionally is so that','line_number':700,'multiline':False]
['text':' we dont end up with a model that has debug handles but has not','line_number':701,'multiline':False]
['text':' debug map to correlate debug handels with.','line_number':702,'multiline':False]
['text':' Once we have a model with both handles and debug map, we can','line_number':703,'multiline':False]
['text':' strip off debug map and have a lean model served to production.','line_number':704,'multiline':False]
['text':' If exception ocurrs we have a model with debug map that can be','line_number':705,'multiline':False]
['text':' used to symbolicate debug handles','line_number':706,'multiline':False]
['text':'archive_name=','line_number':709,'multiline':True]
['text':'archive_dir=','line_number':710,'multiline':True]
['text':'tensor_dir=','line_number':711,'multiline':True]
['text':' For delegated backends get source ranges that are in the debug info','line_number':713,'multiline':False]
['text':' map. Since delegated backend replace original module with lowered','line_number':714,'multiline':False]
['text':' module we will not serialize original module's code which is what would','line_number':715,'multiline':False]
['text':' have contained source range. Since we dont have that anymore, extract','line_number':716,'multiline':False]
['text':' source ranges out of delegated module and store in a separate archive.','line_number':717,'multiline':False]
['text':' Note that we must do this first because in order to serialize inlined','line_number':718,'multiline':False]
['text':' CS appropriate source_range_tags must have been generated.','line_number':719,'multiline':False]
['text':'compress','line_number':730,'multiline':True]
['text':' For delegated backends get debug_info_map','line_number':732,'multiline':False]
['text':' This is merged with other debug_info_map of other modules','line_number':733,'multiline':False]
['text':' which were not delegated.','line_number':734,'multiline':False]
['text':' Now get the debug-handles-to-inlined-cs-ptr-map','line_number':737,'multiline':False]
['text':' And serialize that in a separate archive','line_number':738,'multiline':False]
['text':' Write out map: [debug-handle, {source range, InlinedCallStack}]','line_number':745,'multiline':False]
['text':'compress','line_number':751,'multiline':True]
['text':' namespace','line_number':771,'multiline':False]
['text':'enforce_importable=','line_number':792,'multiline':True]
['text':' Serialize the model object','line_number':803,'multiline':False]
['text':'tensor_dir=','line_number':808,'multiline':True]
['text':'use_storage_context=','line_number':809,'multiline':True]
['text':' Then we serialize all code info.','line_number':810,'multiline':False]
['text':' The tensor constants from the code are written to a separate archive','line_number':812,'multiline':False]
['text':' so loading the code does not depend on loading the data','line_number':813,'multiline':False]
['text':'tensor_dir=','line_number':820,'multiline':True]
['text':'use_storage_context=','line_number':821,'multiline':True]
['text':' Note: writeFiles() call needs to be made in addition to calling this','line_number':823,'multiline':False]
['text':' function to have the code actually saved (tensors are saved)','line_number':824,'multiline':False]
['text':' the zip archive need to know the filepath','line_number':859,'multiline':False]
['text':' NOLINT','line_number':894,'multiline':False]
['text':' NOLINTNEXTLINE(performance-inefficient-string-concatenation)','line_number':942,'multiline':False]
['text':' namespace','line_number':949,'multiline':False]
['text':' Thread local flag (only happens in export, i.e. on server side)','line_number':957,'multiline':False]
['text':' to control if instructions for bytecode default inputs are emitted','line_number':958,'multiline':False]
['text':' or not. It's the major difference between bytecode v5 and v6.','line_number':959,'multiline':False]
['text':' namespace torch::jit','line_number':988,'multiline':False]
