['text':' Protocol 2 is the highest that can be decoded by Python 2','line_number':18,'multiline':False]
['text':' See https://docs.python.org/3/library/pickle.html#data-stream-format','line_number':19,'multiline':False]
['text':' NOLINTNEXTLINE(bugprone-exception-escape)','line_number':22,'multiline':False]
['text':' All attributes get pushed into a tuple and their indices saved in the','line_number':33,'multiline':False]
['text':' module def','line_number':34,'multiline':False]
['text':' unmemoized version called by pushIValue','line_number':47,'multiline':False]
['text':' note: isList must be after isIntList and friends because','line_number':91,'multiline':False]
['text':' isList is true for all lists.','line_number':92,'multiline':False]
['text':' memoize every class type the Pickler encountered','line_number':99,'multiline':False]
['text':' This is used to make sure we capture all the run-time types','line_number':100,'multiline':False]
['text':' and serialize them properly for class/interface polymorphism','line_number':101,'multiline':False]
['text':' It is the same as how rref is pickled in python, see PyRRef::pickle','line_number':176,'multiline':False]
['text':' Mutable ivalues are memoized by pointer equality, which we handle at this','line_number':200,'multiline':False]
['text':' outer granularity.  Immutable ivalues are memoized by value equality which','line_number':201,'multiline':False]
['text':' is handled in the type-specific handlers inside pushIValueImpl.','line_number':202,'multiline':False]
['text':' This value has already been pushed, just do a BINGET','line_number':213,'multiline':False]
['text':' Push 8 byte integer','line_number':243,'multiline':False]
['text':' Memoized too many items, issue a LONG_BINGET instead','line_number':259,'multiline':False]
['text':' unmemoized encoding of a string','line_number':265,'multiline':False]
['text':' Tuple for persistent_load','line_number':297,'multiline':False]
['text':' typename','line_number':299,'multiline':False]
['text':' data_type','line_number':301,'multiline':False]
['text':' root_key','line_number':305,'multiline':False]
['text':' location','line_number':310,'multiline':False]
['text':' size','line_number':312,'multiline':False]
['text':' TODO: Skip this if not writing tensors','line_number':318,'multiline':False]
['text':' Small string that fits: buffer the data.','line_number':327,'multiline':False]
['text':' Otherwise, first flush, then write directly.','line_number':331,'multiline':False]
['text':' Push BINPUT without adding anything to the memoized_ivalues_','line_number':351,'multiline':False]
['text':' layout','line_number':370,'multiline':False]
['text':' size','line_number':375,'multiline':False]
['text':' requires grad','line_number':381,'multiline':False]
['text':' indices','line_number':383,'multiline':False]
['text':' values','line_number':385,'multiline':False]
['text':' backward_hooks','line_number':407,'multiline':False]
['text':' Construct the collections.OrderedDict for the backward_hooks','line_number':410,'multiline':False]
['text':' Call torch._utils._rebuild_sparse_coo_tensor','line_number':413,'multiline':False]
['text':' In contrast to tensor references, literal tensors are included in the','line_number':418,'multiline':False]
['text':' pickle program binary blob. They are written to the file after the STOP','line_number':419,'multiline':False]
['text':' opcode. They can't be included in the pickle program itself without a bunch','line_number':420,'multiline':False]
['text':' of extra machinery since byte strings are limited to 4 GB.','line_number':421,'multiline':False]
['text':'','line_number':422,'multiline':False]
['text':' The format here is the same one used by `torch.save()`. The code for the','line_number':423,'multiline':False]
['text':' format can be found in `torch/serialization.py`.','line_number':424,'multiline':False]
['text':' The arguments to this function are:','line_number':433,'multiline':False]
['text':'    storage, storage_offset, size, stride, requires_grad, backward_hooks','line_number':434,'multiline':False]
['text':' storage offset','line_number':441,'multiline':False]
['text':' size','line_number':444,'multiline':False]
['text':' stride','line_number':451,'multiline':False]
['text':' tuple of (qscheme, scale, zp) or (qscheme, scales, zps, axis)','line_number':461,'multiline':False]
['text':' requires_grad','line_number':483,'multiline':False]
['text':' backward_hooks','line_number':486,'multiline':False]
['text':' Construct the collections.OrderedDict for the backward_hooks','line_number':489,'multiline':False]
['text':' Only push it for regular tensor if the dictionary is not empty.','line_number':493,'multiline':False]
['text':' IValues based on std::unordered_map<K, V> are slow and deprecated.','line_number':496,'multiline':False]
['text':' Thus, pass a c10::Dict to pushDict.','line_number':497,'multiline':False]
['text':' Call torch._utils._rebuild_tensor_v2','line_number':508,'multiline':False]
['text':' Reduce arguments are spread (e.g. `*args`) before calling the global,','line_number':518,'multiline':False]
['text':' so wrap in a tuple','line_number':519,'multiline':False]
['text':' Mark list','line_number':523,'multiline':False]
['text':' Add all items','line_number':526,'multiline':False]
['text':' Finish list','line_number':529,'multiline':False]
['text':' Finish tuple','line_number':532,'multiline':False]
['text':' Call reduce','line_number':535,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':541,'multiline':False]
['text':' Python pickle format is big endian, swap.','line_number':553,'multiline':False]
['text':' Reduce arguments are spread (e.g. `*args`) before calling the global,','line_number':585,'multiline':False]
['text':' so wrap in a tuple','line_number':586,'multiline':False]
['text':' startTypeTag() and endTypeTag() must be called in a pair, with 1 argument','line_number':594,'multiline':False]
['text':' pushed on the stack in between them. They will add the type of a container','line_number':595,'multiline':False]
['text':' ivalue to the stack as a string so we can preserve type tags across','line_number':596,'multiline':False]
['text':' serialization','line_number':597,'multiline':False]
['text':' namespace','line_number':610,'multiline':False]
['text':' See startTypeTag','line_number':612,'multiline':False]
['text':' Push the dict type','line_number':619,'multiline':False]
['text':' Pop the dict and type into a tuple','line_number':626,'multiline':False]
['text':' Call function via reduce','line_number':629,'multiline':False]
['text':' Sort the dict for deterministic keys','line_number':645,'multiline':False]
['text':' Memoized too many items, issue a LONG_BINPUT instead','line_number':661,'multiline':False]
['text':' Push the list items','line_number':674,'multiline':False]
['text':' TODO HIP support','line_number':724,'multiline':False]
['text':' NB: This new tensor is created to support cuda tensors.','line_number':726,'multiline':False]
['text':' Storages can be mutated when converting tensors from cuda to cpu,','line_number':727,'multiline':False]
['text':' and we need a cpu tensor to copy data from.','line_number':728,'multiline':False]
['text':' storage_offset = ','line_number':733,'multiline':True]
['text':' size = ','line_number':734,'multiline':True]
['text':' stride = ','line_number':737,'multiline':True]
['text':' Check that the schemas for __getstate__ and __setstate__ are correct','line_number':747,'multiline':False]
['text':' Check __getstate__','line_number':754,'multiline':False]
['text':'   __getstate__ is expected to be (self) -> T','line_number':755,'multiline':False]
['text':' Check __setstate__ if the method exists','line_number':766,'multiline':False]
['text':'   __setstate__ is expected to be (self, T) -> None','line_number':767,'multiline':False]
['text':' Check that the return type of __getstate__ matches the input to','line_number':790,'multiline':False]
['text':' __setstate__','line_number':791,'multiline':False]
['text':' namespace torch::jit','line_number':806,'multiline':False]
