['text':'//////////////////////////////////////////////////////////////////////////////','line_number':31,'multiline':False]
['text':' Recording the traces','line_number':32,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':33,'multiline':False]
['text':' namespace detail','line_number':66,'multiline':False]
['text':' NOLINTNEXTLINE','line_number':75,'multiline':False]
['text':' Given a IValue 'var', return the 'node' which represents the instruction','line_number':96,'multiline':False]
['text':' which computes the value of this variable in the IR.','line_number':97,'multiline':False]
['text':' Here, we interpret untraced variables as constants that are just embedded','line_number':98,'multiline':False]
['text':' in the graph.  This is useful to handle code which does things like this','line_number':99,'multiline':False]
['text':' (from torch.autograd.variable, now moved to C++):','line_number':100,'multiline':False]
['text':'','line_number':101,'multiline':False]
['text':'    def mm(self, matrix):','line_number':102,'multiline':False]
['text':'      output = Variable(self.data.new(self.data.size(0), matrix.data.size(1)))','line_number':103,'multiline':False]
['text':'      return Addmm.apply(output, self, matrix, 0, 1, True)','line_number':104,'multiline':False]
['text':'','line_number':105,'multiline':False]
['text':' Here, mm fakes up a dummy variable with uninitialized data to do an inplace','line_number':106,'multiline':False]
['text':' update on, but subsequently ignores it because the alpha scaling factor is','line_number':107,'multiline':False]
['text':' zero. This is one of the cases where a Variable can be created inside of a','line_number':108,'multiline':False]
['text':' trace, and if we treat it as a constant, everything will work out.','line_number':109,'multiline':False]
['text':' allow tracing of tuples passed to List[Tensor] or Tuple[Tensor...]','line_number':117,'multiline':False]
['text':' arguments','line_number':118,'multiline':False]
['text':' Didn't find it. Bake in a constant','line_number':167,'multiline':False]
['text':' Find torchbind classes','line_number':193,'multiline':False]
['text':' If the values are non-tensors, we try to create constants','line_number':221,'multiline':False]
['text':' and bake those constants into the traced graph','line_number':222,'multiline':False]
['text':' Support tuple values that contain only tensors','line_number':297,'multiline':False]
['text':' XXX: this function mutates input','line_number':339,'multiline':False]
['text':' Unpack the list values statically','line_number':375,'multiline':False]
['text':'recurse=','line_number':436,'multiline':True]
['text':' Skipping Parameters and Buffers that are behind an `InterfaceType`','line_number':450,'multiline':False]
['text':' because it is illegal for InterfaceType to expose any attribute.','line_number':451,'multiline':False]
['text':' And these attributes should never be used/exposed outside of','line_number':452,'multiline':False]
['text':' InterfaceType'd module anyway.','line_number':453,'multiline':False]
['text':' Start tracing, treating 'inputs' as inputs to the trace, which can be','line_number':471,'multiline':False]
['text':' varied on subsequent invocations of the trace.  Any other variables','line_number':472,'multiline':False]
['text':' will be treated as constants.','line_number':473,'multiline':False]
['text':' if we are a module, then make sure the modules parameters are in the map','line_number':480,'multiline':False]
['text':' and mapped to accesses to the self object','line_number':481,'multiline':False]
['text':' When enough argument name hints are provided, use them as debug names','line_number':488,'multiline':False]
['text':' for traced function/modules.','line_number':489,'multiline':False]
['text':' Here argument_names is allowed to have more names than needed because','line_number':490,'multiline':False]
['text':' some arguments may have valid default values, therefore they don't need','line_number':491,'multiline':False]
['text':' example inputs.','line_number':492,'multiline':False]
['text':' Invoke the traced function','line_number':514,'multiline':False]
['text':' Exit a trace, treating 'out_stack' as the outputs of the trace.  These','line_number':517,'multiline':False]
['text':' are the variables whose values will be computed upon subsequent','line_number':518,'multiline':False]
['text':' invocations of the trace.','line_number':519,'multiline':False]
['text':' NB: The stack is in "reverse" order, so when we pass the diagnostic','line_number':522,'multiline':False]
['text':' number we need to flip it based on size.','line_number':523,'multiline':False]
['text':' Abort tracing. Used to reset the state in case of errors.','line_number':542,'multiline':False]
['text':' If the value comes from a CallFunction or CallMethod, it may not have','line_number':556,'multiline':False]
['text':' shape information attached. For debuggability, we enhance the type','line_number':557,'multiline':False]
['text':' information by assigning the concrete value's tupe to the jit::Value.','line_number':558,'multiline':False]
['text':' if allow undefined, we create a list of optional tensors','line_number':758,'multiline':False]
['text':' Make sure this scalar to tensor isn't traced!','line_number':938,'multiline':False]
['text':' Make sure this scalar to tensor isn't traced!','line_number':961,'multiline':False]
['text':' If we're not converting in-place ops to out-of-place, this check is','line_number':979,'multiline':False]
['text':' unnecessary','line_number':980,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':1002,'multiline':False]
['text':' Argument stash','line_number':1003,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':1004,'multiline':False]
['text':' TODO: check type?','line_number':1012,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':1051,'multiline':False]
['text':' Stack trace recording','line_number':1052,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':1053,'multiline':False]
['text':' no python present so we just do not record source information','line_number':1054,'multiline':False]
['text':' XXX: _kind can be a nullptr','line_number':1102,'multiline':False]
['text':' namespace torch::jit::tracer','line_number':1114,'multiline':False]
