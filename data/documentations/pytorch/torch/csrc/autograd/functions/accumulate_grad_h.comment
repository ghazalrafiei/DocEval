['text':' NB: Since the AccumulateGrad Node is only a weak ref from the Tensor,','line_number':48,'multiline':False]
['text':'     it can be destroyed even though the Tensor is still alive (contrary','line_number':49,'multiline':False]
['text':'     to all other Nodes). So we must lazily read the Tensor hooks here.','line_number':50,'multiline':False]
['text':' NB: Since the AccumulateGrad Node is only a weak ref from the Tensor,','line_number':56,'multiline':False]
['text':'     it can be destroyed even though the Tensor is still alive (contrary','line_number':57,'multiline':False]
['text':'     to all other Nodes). So we must lazily read the Tensor hooks here.','line_number':58,'multiline':False]
['text':' Given a variable with its current grad as variable_grad, accumulates','line_number':62,'multiline':False]
['text':' new_grad into variable_grad if in place accumulation is possible.','line_number':63,'multiline':False]
['text':' Otherwise, uses 'update_grad' to update the grad for the variable.','line_number':64,'multiline':False]
['text':' "Gradient Layout Contract"','line_number':66,'multiline':False]
['text':'','line_number':67,'multiline':False]
['text':' AccumulateGrad tries to stash strided (non-sparse) grads with memory layout','line_number':68,'multiline':False]
['text':' (strides) such that variables and grads interact efficiently in later','line_number':69,'multiline':False]
['text':' optimizer kernels, and grads interact efficiently with c10d::Reducer.cpp.','line_number':70,'multiline':False]
['text':'','line_number':71,'multiline':False]
['text':' Specifically, AccumulateGrad tries to ensure the following','line_number':72,'multiline':False]
['text':' (cf torch/csrc/autograd/utils/grad_layout_contract.h):','line_number':73,'multiline':False]
['text':'   (1) if variable.is_non_overlapping_and_dense(), the stashed grad's','line_number':74,'multiline':False]
['text':'       strides match variable.','line_number':75,'multiline':False]
['text':'   (2) else, stashed grad is rowmajor contiguous.','line_number':76,'multiline':False]
['text':' If variable's grad does not exist (!variable_grad.defined())','line_number':77,'multiline':False]
['text':' AccumulateGrad steals new_grad if it's stealable and obeys the contract','line_number':78,'multiline':False]
['text':' already, otherwise it deep copies new_grad into an obedient clone.','line_number':79,'multiline':False]
['text':'','line_number':80,'multiline':False]
['text':' If variable's grad already exists (variable_grad.defined()), new_grad must','line_number':81,'multiline':False]
['text':' be added to variable_grad.  If we aren't setting up for double backward','line_number':82,'multiline':False]
['text':' (!GradMode::is_enabled()), AccumulateGrad performs "variable_grad +=','line_number':83,'multiline':False]
['text':' new_grad" in-place, which keeps variable_grad's layout. We assume (hope)','line_number':84,'multiline':False]
['text':' variable_grad was created obeying (1) or (2) at some point in the past.','line_number':85,'multiline':False]
['text':'','line_number':86,'multiline':False]
['text':' If we are setting up for double backward, AccumulateGrad updates the grad','line_number':87,'multiline':False]
['text':' out-of-place via "variable_grad + new_grad."  TensorIterator operator+','line_number':88,'multiline':False]
['text':' decides result's layout.  Typically TensorIterator matches strides of the','line_number':89,'multiline':False]
['text':' first arg, so we once again assume (hope) variable_grad was originally','line_number':90,'multiline':False]
['text':' created obeying (1) or (2).','line_number':91,'multiline':False]
['text':'','line_number':92,'multiline':False]
['text':' AccumulateGrad does not enforce the contract with 100% certainty. Examples:','line_number':93,'multiline':False]
['text':'  - If a user manually permutes a param or its grad, then runs a fwd+bwd,','line_number':94,'multiline':False]
['text':'    variable_grad += new_grad keeps variable_grad's layout without','line_number':95,'multiline':False]
['text':'    rechecking the contract.','line_number':96,'multiline':False]
['text':'  - If TensorIterator changes its corner cases about operator+'s result','line_number':97,'multiline':False]
['text':'    (for example, giving more or less priority to channels_last inputs, see','line_number':98,'multiline':False]
['text':'    https://github.com/pytorch/pytorch/pull/37968) the result may not obey.','line_number':99,'multiline':False]
['text':'','line_number':100,'multiline':False]
['text':' Fortunately, if a given grad doesn't satisfy (1) or (2), the penalty is','line_number':101,'multiline':False]
['text':' degraded performance in Reducer.cpp or optimizer kernels, not death by','line_number':102,'multiline':False]
['text':' assert or silently bad numerics.','line_number':103,'multiline':False]
['text':' variable: the variable whose grad we're accumulating.','line_number':105,'multiline':False]
['text':' variable_grad: the current grad for the variable.','line_number':106,'multiline':False]
['text':' new_grad: new grad we want to accumulate for the variable.','line_number':107,'multiline':False]
['text':' num_expected_refs: the number of refs we expect to hold internally','line_number':108,'multiline':False]
['text':'                    such that it is safe to avoid cloning the grad','line_number':109,'multiline':False]
['text':'                    if use_count() of the grad is less than or equal','line_number':110,'multiline':False]
['text':'                    to this value (in addition to post_hooks).','line_number':111,'multiline':False]
['text':' update_grad: Function that is used to update grad for the variable.','line_number':112,'multiline':False]
['text':'              The argument to the function is a Tensor which','line_number':113,'multiline':False]
['text':'              is used to set a new value for the grad.','line_number':114,'multiline':False]
['text':' we aren't setting up for double-backward','line_number':129,'multiline':False]
['text':' not sparse','line_number':130,'multiline':False]
['text':' no other user-visible tensor references new_grad','line_number':131,'multiline':False]
['text':' new_grad obeys the "Gradient Layout Contract", there has a special','line_number':132,'multiline':False]
['text':' case, For MKLDNN tensor, which is a opaque tensor, assuming it obeys','line_number':133,'multiline':False]
['text':' layout_contract. Under these conditions, we can steal new_grad','line_number':134,'multiline':False]
['text':' without a deep copy.','line_number':135,'multiline':False]
['text':' Use count for indices and values should always be <=1 since the','line_number':141,'multiline':False]
['text':' SparseTensor should be the only one holding a reference to these.','line_number':142,'multiline':False]
['text':' Can't detach sparse tensor (since metadata changes are not allowed','line_number':146,'multiline':False]
['text':' after detach), so just create a new one for the grad which is a','line_number':147,'multiline':False]
['text':' shallow copy. We need a shallow copy so that modifying the original','line_number':148,'multiline':False]
['text':' grad tensor doesn't modify the grad we accumulate.','line_number':149,'multiline':False]
['text':' We only skip clone if indices and values themselves are contiguous','line_number':150,'multiline':False]
['text':' for backward compatibility reasons. Since without this optimization,','line_number':151,'multiline':False]
['text':' earlier we would clone the entire SparseTensor which cloned indices','line_number':152,'multiline':False]
['text':' and values.','line_number':153,'multiline':False]
['text':' For details see https://github.com/pytorch/pytorch/issues/34375.','line_number':154,'multiline':False]
['text':' No scenario where we expect this to be true currently','line_number':156,'multiline':False]
['text':' Deep copies new_grad according to the "Gradient Layout Contract."','line_number':175,'multiline':False]
['text':' This case is not strictly necessary, but it makes the first-order only','line_number':181,'multiline':False]
['text':' case slightly more efficient.','line_number':182,'multiline':False]
['text':' If `variable_grad` is sparse and `new_grad` is not sparse, their','line_number':184,'multiline':False]
['text':' sum is not sparse, and we must change the TensorImpl type of','line_number':185,'multiline':False]
['text':' `variable_grad` for it to store the result. However, changing the','line_number':186,'multiline':False]
['text':' TensorImpl type of a tensor requires changing the tensor itself, and','line_number':187,'multiline':False]
['text':' thus in this case we have to change the grad tensor.','line_number':188,'multiline':False]
['text':' Ideally we'd perform an in-place operation to avoid changing','line_number':193,'multiline':False]
['text':' the grad tensor. However, if that's impossible because the grads','line_number':194,'multiline':False]
['text':' are vmap-incompatible (See NOTE: [vmap-incompatible in-place','line_number':195,'multiline':False]
['text':' operations]), then we just add them out-of-place.','line_number':196,'multiline':False]
['text':' In this case we can avoid changing the grad tensor. There are three','line_number':201,'multiline':False]
['text':' scenarios when we'll hit this case:','line_number':202,'multiline':False]
['text':'','line_number':203,'multiline':False]
['text':' 1. `variable_grad` is sparse, and `new_grad` is sparse.','line_number':204,'multiline':False]
['text':' 2. `variable_grad` is dense, and `new_grad` is sparse.','line_number':205,'multiline':False]
['text':' 3. `variable_grad` is dense, and `new_grad` is dense.','line_number':206,'multiline':False]
['text':' 4. `variable_grad` is mkldnn, and `new_grad` is mkldnn.','line_number':207,'multiline':False]
['text':'','line_number':208,'multiline':False]
['text':' In all of these four cases, `variable_grad += new_grad` is a','line_number':209,'multiline':False]
['text':' valid operation which adds `new_grad` to `variable_grad` in','line_number':210,'multiline':False]
['text':' place. `variable_grad` is thus still referring to the same tensor','line_number':211,'multiline':False]
['text':' after the operation.','line_number':212,'multiline':False]
['text':' Also DistributedDataParallel(DDP) package relies on grad being','line_number':213,'multiline':False]
['text':' mutated in place for saving peak memory usage. DDP will still','line_number':214,'multiline':False]
['text':' work correctly if it is mutated out of place here, but DDP will','line_number':215,'multiline':False]
['text':' maintain one extra copy of grad tensors in buffer and thus','line_number':216,'multiline':False]
['text':' increase peak memory usage.','line_number':217,'multiline':False]
['text':' ^ We could enforce the contract more aggressively here by writing:','line_number':220,'multiline':False]
['text':' if (variable_grad.is_sparse() || new_grad.is_sparse()) {','line_number':221,'multiline':False]
['text':'   variable_grad += new_grad;','line_number':222,'multiline':False]
['text':' } else if (obeys_layout_contract(variable_grad, variable)) {','line_number':223,'multiline':False]
['text':'   variable_grad += new_grad;','line_number':224,'multiline':False]
['text':' } else {','line_number':225,'multiline':False]
['text':'   result = at::empty_strided(variable.sizes(), variable.strides(),','line_number':226,'multiline':False]
['text':'                              variable.options().memory_format(c10::nullopt));','line_number':227,'multiline':False]
['text':'   update_grad(at::native::add_out(result, variable_grad,','line_number':228,'multiline':False]
['text':'   new_grad, 1.0);','line_number':229,'multiline':False]
['text':' }','line_number':230,'multiline':False]
['text':' However, that accumulation is sometimes in place and sometimes not,','line_number':231,'multiline':False]
['text':' which may break user code.','line_number':232,'multiline':False]
['text':' CPU backend throws an error on sparse + dense, so prefer dense +','line_number':237,'multiline':False]
['text':' sparse here.','line_number':238,'multiline':False]
['text':' Assumes operator+ result typically matches strides of first arg,','line_number':241,'multiline':False]
['text':' and hopes variable_grad was originally created obeying layout','line_number':242,'multiline':False]
['text':' contract.','line_number':243,'multiline':False]
['text':' ^ We could enforce the contract more aggressively here by saying','line_number':248,'multiline':False]
['text':' if (obeys_layout_contract(new_grad, variable)) {','line_number':249,'multiline':False]
['text':'   update_grad(new_grad + variable_grad);','line_number':250,'multiline':False]
['text':' } else {','line_number':251,'multiline':False]
['text':'   update_grad(variable_grad + new_grad);','line_number':252,'multiline':False]
['text':' }','line_number':253,'multiline':False]
['text':' such that the stashed grad is likely to have the right strides if','line_number':254,'multiline':False]
['text':' either variable_grad or new_grad already has the right strides.','line_number':255,'multiline':False]
['text':' We could enforce the contract with certainty by saying','line_number':256,'multiline':False]
['text':' auto result = variable_grad + new_grad (or vice versa), checking','line_number':257,'multiline':False]
['text':' result's layout, and copying to an obedient clone if necessary before','line_number':258,'multiline':False]
['text':' update_grad. The copy would require another gmem pass.  We can't create','line_number':259,'multiline':False]
['text':' empty result with the right layout then add_out into it with a single','line_number':260,'multiline':False]
['text':' kernel, because GradMode is enabled in this branch, and add_out isn't','line_number':261,'multiline':False]
['text':' differentiable. Maybe more trouble than it's worth.','line_number':262,'multiline':False]
['text':' namespace autograd','line_number':276,'multiline':False]
['text':' namespace torch','line_number':277,'multiline':False]
