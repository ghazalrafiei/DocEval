['text':' GraphTask holds metadata needed for a single execution of backward()','line_number':22,'multiline':False]
['text':' Indicates if an error occurred while executing any task.  When this is','line_number':25,'multiline':False]
['text':' true, it signals all threads to stop executing.','line_number':26,'multiline':False]
['text':' It is safe to read keep_graph_ without synchronization','line_number':29,'multiline':False]
['text':' To protect reads/writes to not_ready_, dependencies_, captured_vars_,','line_number':32,'multiline':False]
['text':' has_error_, future_result_, cpu_ready_queue_, and leaf_streams.','line_number':33,'multiline':False]
['text':' Records the nodes that are in the graph','line_number':38,'multiline':False]
['text':' Note [Exec info]','line_number':41,'multiline':False]
['text':' Exec info is created for each GraphTask, which allows filtering paths on','line_number':42,'multiline':False]
['text':' the graph that are not needed. It has a bit complicated semantics. If it's','line_number':43,'multiline':False]
['text':' empty, it means the task is run in a "default" mode, which means that all','line_number':44,'multiline':False]
['text':' next_edges we encounter should get executed. If it's not empty, only','line_number':45,'multiline':False]
['text':' functions that have an entry and this entry has needed == True should be','line_number':46,'multiline':False]
['text':' executed. exec_info is only empty when the graph is executed via','line_number':47,'multiline':False]
['text':' .backward() and the inputs parameter is not passed. Otherwise, when','line_number':48,'multiline':False]
['text':' executed through .grad(), or when inputs arg is specified for .backward(),','line_number':49,'multiline':False]
['text':' exec_info will be non-empty.','line_number':50,'multiline':False]
['text':'','line_number':51,'multiline':False]
['text':' within Node inputs','line_number':59,'multiline':False]
['text':' within the output vector of a GraphTask','line_number':60,'multiline':False]
['text':' This hook will be executed after a grad is captured. The captured','line_number':62,'multiline':False]
['text':' grad will be replaced by the return value of the hook.','line_number':63,'multiline':False]
['text':' NOTE [Deprecated capture hooks]','line_number':68,'multiline':False]
['text':'','line_number':69,'multiline':False]
['text':' The current status of capture hooks is that we continue to support','line_number':70,'multiline':False]
['text':' the single usage of it by distributed in the dist_engine. If anyone','line_number':71,'multiline':False]
['text':' else needs to use it for other purposes, they should file an issue.','line_number':72,'multiline':False]
['text':'','line_number':73,'multiline':False]
['text':' Capture hooks were originally created because there did not exist','line_number':74,'multiline':False]
['text':' any way to register pre/post hooks to grad_fn in a way such that it','line_number':75,'multiline':False]
['text':' would still be executed even if that is the grad_fn of a Tensor','line_number':76,'multiline':False]
['text':' passed as input= of .grad. As far as I know, only dist_engine uses','line_number':77,'multiline':False]
['text':' this hook.','line_number':78,'multiline':False]
['text':'','line_number':79,'multiline':False]
['text':' However, there are other alternatives today like tensor hooks that can','line_number':80,'multiline':False]
['text':' replace the usage that originally motivated its creation. Also,','line_number':81,'multiline':False]
['text':' Captures hooks are an outlier in terms of the types of hook that','line_number':82,'multiline':False]
['text':' autograd offers in how it is registered and behaves, e.g. it is a hook','line_number':83,'multiline':False]
['text':' registered not to the graph, but to a particular graph_task! This makes','line_number':84,'multiline':False]
['text':' it a burden to maintain.','line_number':85,'multiline':False]
['text':'','line_number':86,'multiline':False]
['text':' It would be very nice to clean up/do a migration from pre/post','line_number':87,'multiline':False]
['text':' hooks used in distributed to use tensor hooks, but for now we just','line_number':88,'multiline':False]
['text':' mark this method as deprecated to prevent additional usage.','line_number':89,'multiline':False]
['text':'','line_number':90,'multiline':False]
['text':' If you still think you really need to capture hooks, please file an','line_number':91,'multiline':False]
['text':' issue (and tag autograd).','line_number':92,'multiline':False]
['text':' See NOTE [deprecated capture hooks]','line_number':97,'multiline':False]
['text':' The hooks will be called one by one in the order as they were added.','line_number':104,'multiline':False]
['text':' The input grad of a hook will be the output of its preceding hook. The','line_number':105,'multiline':False]
['text':' first hook will take the captured grad as the input. The output of the','line_number':106,'multiline':False]
['text':' last hook will replace the captured grad.','line_number':107,'multiline':False]
['text':' exec_info_ is safe to read without synchronization','line_number':118,'multiline':False]
['text':' Captures variables are grads captured that we return to the user. After','line_number':120,'multiline':False]
['text':' execution of the GraphTask is completed, the captured_vars_ are moved','line_number':121,'multiline':False]
['text':' out of the GraphTask and are no longer valid.','line_number':122,'multiline':False]
['text':' Note: this field is not ready to be used until the proper','line_number':125,'multiline':False]
['text':' `thread_locals_.set_grad_mode()` call in the constructor.','line_number':126,'multiline':False]
['text':' Per-device current streams of the execute() that called this GraphTask.','line_number':131,'multiline':False]
['text':' These will be synced with leaf_streams in exec_post_processing.','line_number':132,'multiline':False]
['text':' Collects caller_current_streams_','line_number':135,'multiline':False]
['text':' The value of worker_device in the thread that created this task.','line_number':144,'multiline':False]
['text':' See Note [Reentrant backwards]','line_number':145,'multiline':False]
['text':' Safe to read owner_ and reentrant_depth_ without synchronization','line_number':146,'multiline':False]
['text':' The number of parent graph tasks for this graph task','line_number':148,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-const-or-ref-data-members)','line_number':149,'multiline':False]
['text':' check if the GraphTask is completed or not','line_number':156,'multiline':False]
['text':' mark the graph task as completed and trigger post processing','line_number':158,'multiline':False]
['text':' Set an appropriate exception on this graph_task which was encountered while','line_number':161,'multiline':False]
['text':' running the provided function.','line_number':162,'multiline':False]
['text':' Set an appropriate exception on this graph_task which was encountered while','line_number':165,'multiline':False]
['text':' running the provided function. But doesn't signal completion on','line_number':166,'multiline':False]
['text':' 'future_result_' right away. The user needs to explicitly mark','line_number':167,'multiline':False]
['text':' 'future_result_' completed with an appropriate exception.','line_number':168,'multiline':False]
['text':' Whether or not to stop execution for this GraphTask when an error is','line_number':171,'multiline':False]
['text':' encountered. When set to true, this would cause Engine::execute() to throw','line_number':172,'multiline':False]
['text':' an exception as soon as the autograd engine receives an exception.','line_number':173,'multiline':False]
['text':' CPU threads are dedicated to processing CPU work for the backward they','line_number':176,'multiline':False]
['text':' invoked. So any given graph task maintains its own cpu_ready_queue_ where','line_number':177,'multiline':False]
['text':' you should send work for it to be done. We memoize the cpu_ready_queue_ per','line_number':178,'multiline':False]
['text':' GraphTask so that we know which ready queue we should push to if we are on','line_number':179,'multiline':False]
['text':' device thread (i.e. GPU) and but next NodeTask should be run on CPU.','line_number':180,'multiline':False]
['text':' Future representing the completion of the graph task. Notified when all','line_number':183,'multiline':False]
['text':' tasks are done.','line_number':184,'multiline':False]
['text':' Final callbacks installed during execution of this GraphTask','line_number':187,'multiline':False]
['text':' To protect reads and writes to final_callbacks_. Intentionally no reusing','line_number':189,'multiline':False]
['text':' mutex_ as the two are protecting different data structures.','line_number':190,'multiline':False]
['text':' run GraphTask post processing','line_number':217,'multiline':False]
['text':' The guard that sets and restores current_graph_task.','line_number':221,'multiline':False]
['text':' namespace autograd','line_number':242,'multiline':False]
['text':' namespace torch','line_number':243,'multiline':False]
