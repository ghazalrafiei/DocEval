['text':' Helper functions to enforce the "Gradient Layout Contract" described in','line_number':9,'multiline':False]
['text':' torch/csrc/autograd/functions/accumulate_grad.h.','line_number':10,'multiline':False]
['text':' Checks if grad obeys the contract with variable.','line_number':12,'multiline':False]
['text':' TODO: Nested Tensor does not have an implementation of detach. The','line_number':21,'multiline':False]
['text':' current implementation of nested tensor likely does obey the gradient','line_number':22,'multiline':False]
['text':' contract and should return true, but this would likely change in the','line_number':23,'multiline':False]
['text':' future','line_number':24,'multiline':False]
['text':' Gradient Layout Contract is not applicable for sparse layouts','line_number':27,'multiline':False]
['text':' Only look at stride for dimensions that are not of size 1.','line_number':30,'multiline':False]
['text':' This should not be needed but we don't check if a Tensor has views','line_number':40,'multiline':False]
['text':' before stashing it. And 0-strided Tensors of size 1 are actually','line_number':41,'multiline':False]
['text':' views for ops like cat.','line_number':42,'multiline':False]
['text':' TODO: Actually detect views in the accumulateGrad function so that','line_number':43,'multiline':False]
['text':' this Tensor is not considered at all.','line_number':44,'multiline':False]
['text':' Creates a clone of new_grad that obeys the contract with variable.','line_number':56,'multiline':False]
['text':' The clone should attach to new_grad's history if GradMode::is_enabled().','line_number':57,'multiline':False]
['text':' (1)','line_number':62,'multiline':False]
['text':' Does this dicey-looking sequence attach the result to new_grad's','line_number':63,'multiline':False]
['text':' history if GradMode::is_enabled()?  Yes, and @alband says it should.','line_number':64,'multiline':False]
['text':' (2)','line_number':72,'multiline':False]
['text':' namespace utils','line_number':77,'multiline':False]
['text':' namespace autograd','line_number':78,'multiline':False]
['text':' namespace torch','line_number':79,'multiline':False]
