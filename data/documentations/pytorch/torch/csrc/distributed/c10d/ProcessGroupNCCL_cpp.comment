['text':' NCCL op mapping','line_number':51,'multiline':False]
['text':' NCCL type typing','line_number':62,'multiline':False]
['text':' Helper function that gets the data type and issues error if not supported','line_number':77,'multiline':False]
['text':' https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/api/ops.html#ncclredopcreatepremulsum','line_number':105,'multiline':False]
['text':' tells us that the scalar input is strictly a multiplier.','line_number':106,'multiline':False]
['text':'scalar=','line_number':107,'multiline':True]
['text':' For bool tensors, map sum to max, which both represent a bitwise or.','line_number':124,'multiline':False]
['text':' This is to prevent overflow issues with sum, since we use uint8 to','line_number':125,'multiline':False]
['text':' represent a bool (see ncclDataType mapping).','line_number':126,'multiline':False]
['text':' Get the deviceList String from the list of devices','line_number':186,'multiline':False]
['text':' Get the list of devices from list of tensors','line_number':207,'multiline':False]
['text':' tensors must all be on the same device, or all on distinct devices.','line_number':212,'multiline':False]
['text':' The line below assumes that constraint has already been enforced','line_number':213,'multiline':False]
['text':' (by check_gpu_tensors_same_device or','line_number':214,'multiline':False]
['text':' check_gpu_tensors_different_devices).','line_number':215,'multiline':False]
['text':' [Sync Streams] Helper that lets the input ncclStreams to wait for the current','line_number':223,'multiline':False]
['text':' stream. NCCL communications run on ncclStreams, but input tensors are','line_number':224,'multiline':False]
['text':' allocated on different streams (i.e., current streams). Communications on','line_number':225,'multiline':False]
['text':' ncclStreams cannot start before pending input tensor ops on current streams','line_number':226,'multiline':False]
['text':' finish. Otherwise, ops on two streams might read/write same tensors','line_number':227,'multiline':False]
['text':' concurrently.','line_number':228,'multiline':False]
['text':'','line_number':229,'multiline':False]
['text':' The synchronization above alone is not enough. We also need to make sure','line_number':230,'multiline':False]
['text':' input tensors are not freed before their usages on ncclStreams finish. This','line_number':231,'multiline':False]
['text':' can be achieved by calling c10::cuda::CUDACachingAllocator::recordStream,','line_number':232,'multiline':False]
['text':' which remembers the usage stream (ncclStream), creates an event on the usage','line_number':233,'multiline':False]
['text':' stream when GC attempts to free the input tensor, and delays GC until that','line_number':234,'multiline':False]
['text':' event is done.','line_number':235,'multiline':False]
['text':' Given a ncclUniqueId, convert it to a string representation that can be put','line_number':248,'multiline':False]
['text':' in the store.','line_number':249,'multiline':False]
['text':' Returns exception's what() given an exception_ptr instance.','line_number':263,'multiline':False]
['text':' parentheses avoid some compiler warnings','line_number':277,'multiline':False]
['text':' namespace','line_number':289,'multiline':False]
['text':' Map from each communicator to its device index.','line_number':291,'multiline':False]
['text':' This map is used when register/deregister cache segments from cache','line_number':292,'multiline':False]
['text':' allocator. See design notes below:','line_number':293,'multiline':False]
['text':' - Each segment should be registered only to the communicator on the','line_number':294,'multiline':False]
['text':'   same device.','line_number':295,'multiline':False]
['text':' - We cannot reuse devNCCLCommMap_ in each ProcessGroup because the key may be','line_number':296,'multiline':False]
['text':'   ranks rather than device in point-to-point case.','line_number':297,'multiline':False]
['text':' - This map has also to be maintained as global variable since the register','line_number':298,'multiline':False]
['text':'   hooks are called outside the scope of any PG, thus we need traverse','line_number':299,'multiline':False]
['text':'   communicators in all PGs.','line_number':300,'multiline':False]
['text':' Register after SEGMENT_ALLOC','line_number':306,'multiline':False]
['text':' deregister before SEGMENT_FREE','line_number':324,'multiline':False]
['text':' Return CUDA device with ordinal given by input rank.  If we aren't','line_number':344,'multiline':False]
['text':' bound to a specific device, there is no strict guarantee that this','line_number':345,'multiline':False]
['text':' heuristic is the correct assignment of ranks to GPUs that Python','line_number':346,'multiline':False]
['text':' layers use, but in practice it tends to be.  Fortunately we don't','line_number':347,'multiline':False]
['text':' rely on this for correctness of any tensor operations, just for','line_number':348,'multiline':False]
['text':' ancillary uses like health checks and barriers.','line_number':349,'multiline':False]
['text':' Creates the CUDA event wrappers','line_number':399,'multiline':False]
['text':' Note: The actual events are lazily created when first recorded to with','line_number':400,'multiline':False]
['text':' DEFAULT_FLAGS = cudaEventDisableTiming.','line_number':401,'multiline':False]
['text':' Already detected an exception.','line_number':452,'multiline':False]
['text':' We already have an exception.','line_number':461,'multiline':False]
['text':' Helper that checks if the NCCL kernels are completed on the GPUs','line_number':481,'multiline':False]
['text':' if timing is disabled we won't have allocated start events','line_number':488,'multiline':False]
['text':' Checking the work's corresponding CUDA events' status','line_number':493,'multiline':False]
['text':' Checking the work's corresponding CUDA events' status','line_number':504,'multiline':False]
['text':' Timed out','line_number':523,'multiline':False]
['text':' There is already an error, we don't override it','line_number':525,'multiline':False]
['text':' Call Synchronize without a timeout. We use this method to avoid adding a','line_number':566,'multiline':False]
['text':' timeout argument to the public synchronize API.','line_number':567,'multiline':False]
['text':' Block the current stream on the NCCL stream','line_number':574,'multiline':False]
['text':' Waiting on the work's corresponding CUDA events','line_number':583,'multiline':False]
['text':' In case of blocking, wait for the operation to complete.','line_number':588,'multiline':False]
['text':' Explicitly abort ncclComms here before throwing this timed out','line_number':593,'multiline':False]
['text':' exception to users.','line_number':594,'multiline':False]
['text':' If throwing timed out excepiton without aborting nccl communicators','line_number':595,'multiline':False]
['text':' here, it was observed that CUDA GPU will have 100% utilization and','line_number':596,'multiline':False]
['text':' can not run new events successfully.','line_number':597,'multiline':False]
['text':' Yield','line_number':608,'multiline':False]
['text':' exception() includes timeout and error during blocking wait','line_number':612,'multiline':False]
['text':' Abort NCCL communicators','line_number':614,'multiline':False]
['text':' Throw exception (from main thread here)','line_number':616,'multiline':False]
['text':' Device synchronize only after we've completed timeout checks.','line_number':621,'multiline':False]
['text':' If we use the work to do barrier, we should block here','line_number':623,'multiline':False]
['text':' Same as calling synchronize().','line_number':632,'multiline':False]
['text':' seq','line_number':635,'multiline':False]
['text':' process group ptr','line_number':636,'multiline':False]
['text':' rank','line_number':637,'multiline':False]
['text':' colName','line_number':638,'multiline':False]
['text':' inNelems','line_number':639,'multiline':False]
['text':' outNelems','line_number':640,'multiline':False]
['text':' dType','line_number':641,'multiline':False]
['text':' inSplitSizes','line_number':642,'multiline':False]
['text':' outSplitSizes','line_number':643,'multiline':False]
['text':' worldSize','line_number':646,'multiline':False]
['text':' Always return true, because abort API is not implemented.','line_number':648,'multiline':False]
['text':' Abort all communicators of this work','line_number':653,'multiline':False]
['text':' Same as calling synchronize().','line_number':687,'multiline':False]
['text':' Always return true, because abort API is not implemented.','line_number':693,'multiline':False]
['text':'SkipCleanUp','line_number':721,'multiline':True]
['text':'2 Mins','line_number':729,'multiline':True]
['text':' Perform health check by initializing dummy communicators and destroying','line_number':770,'multiline':False]
['text':' them. This will help indicate any NCCL-related issues prior to the first','line_number':771,'multiline':False]
['text':' collective.','line_number':772,'multiline':False]
['text':' Run it in a separate thread and wait on CV to handle timeouts, since','line_number':773,'multiline':False]
['text':' majority of getNCCLComm failures are hangs.','line_number':774,'multiline':False]
['text':' seq','line_number':845,'multiline':False]
['text':' rank','line_number':847,'multiline':False]
['text':' colName','line_number':848,'multiline':False]
['text':' inNelems','line_number':849,'multiline':False]
['text':' outNelems','line_number':850,'multiline':False]
['text':' dType','line_number':851,'multiline':False]
['text':' inSplitSizes','line_number':852,'multiline':False]
['text':' outSplitSizes','line_number':853,'multiline':False]
['text':' globalRankStart','line_number':854,'multiline':False]
['text':' globalRankStride','line_number':855,'multiline':False]
['text':' worldSize','line_number':856,'multiline':False]
['text':' Attach hooks to cache allocator to trigger the hooks whenever a traced','line_number':858,'multiline':False]
['text':' action is called. In the following hooks, we register a newly allocated','line_number':859,'multiline':False]
['text':' segment when SEGMENT_ALLOC action occurs, and deregister a segment when','line_number':860,'multiline':False]
['text':' SEGMENT_FREE action occurs.','line_number':861,'multiline':False]
['text':' We attach hooks only once at the first PG creation.','line_number':862,'multiline':False]
['text':' If our backend doesn't support splitting, this is a no-op for','line_number':880,'multiline':False]
['text':' ranks not in the new subgroup (and ranks that would be in it will','line_number':881,'multiline':False]
['text':' just use a new communicator rather than split).','line_number':882,'multiline':False]
['text':' Run health check in a separate thread and wait on CV to handle timeouts,','line_number':905,'multiline':False]
['text':' since majority of getNCCLComm failures are hangs.','line_number':906,'multiline':False]
['text':' OpType does not matter, only need to set to not go through send/recv','line_number':921,'multiline':False]
['text':' path.','line_number':922,'multiline':False]
['text':' Now destroy the communicators and remove them from cache so we don't','line_number':924,'multiline':False]
['text':' use destroyed communicators.','line_number':925,'multiline':False]
['text':' Notify main thread the health check is complete.','line_number':927,'multiline':False]
['text':' Populate exception ptr.','line_number':934,'multiline':False]
['text':' Unblock waiting main thread which will report exception.','line_number':936,'multiline':False]
['text':' Unknown exceptions will just cause the program to terminate.','line_number':938,'multiline':False]
['text':' We don't need to join the thread, just need to verify health check via the','line_number':940,'multiline':False]
['text':' CV. Hence we detach the thread here.','line_number':941,'multiline':False]
['text':' NOLINT','line_number':942,'multiline':False]
['text':' If there is no exception, the likely culprit is a timeout/hang which is how','line_number':955,'multiline':False]
['text':' most communicator init issues manifest themselves.','line_number':956,'multiline':False]
['text':' NCCL just starts sequence numbers at 0.','line_number':965,'multiline':False]
['text':' must release GIL when calling this method','line_number':988,'multiline':False]
['text':' Reasoning about hook completion:','line_number':990,'multiline':False]
['text':' 1. waitForPendingWorks should be called after user code has finished','line_number':991,'multiline':False]
['text':' calling','line_number':992,'multiline':False]
['text':'    all collectives. This means, when we got here, all of the collectives','line_number':993,'multiline':False]
['text':'    are either in workMetaList_ or has been erased from workMetaList_.','line_number':994,'multiline':False]
['text':' 2. The watchdog thread grabs both locks to move Work object from the','line_number':995,'multiline':False]
['text':'    workMetaList_ to the completedWorkList_, and the hook thread only erases','line_number':996,'multiline':False]
['text':'    a Work object after the hook is returned. Therefore, after user code','line_number':997,'multiline':False]
['text':'    calls a collective, its Work object is either in workMetaList_ or in','line_number':998,'multiline':False]
['text':'    completedWorkList_ before it finishes.','line_number':999,'multiline':False]
['text':' 3. We have three threads and two locks.','line_number':1000,'multiline':False]
['text':'      a. main thread (this function) grabs two locks atomically','line_number':1001,'multiline':False]
['text':'      b. watchdog thread (watchdogHandler function) always grabs','line_number':1002,'multiline':False]
['text':'      workMetaListMutex_','line_number':1003,'multiline':False]
['text':'         first and then grabs completedWorkListMutex_.','line_number':1004,'multiline':False]
['text':'      c. hook thread (runHookLoop function) only grabs','line_number':1005,'multiline':False]
['text':'      completedWorkListMutex_. Therefore, locks are always acquired in the','line_number':1006,'multiline':False]
['text':'      same order and hence no deadlocks.','line_number':1007,'multiline':False]
['text':' Detach the thread to allow it to run independently','line_number':1042,'multiline':False]
['text':' The process may control multiple devices, loop through the communicators on','line_number':1053,'multiline':False]
['text':' each device','line_number':1054,'multiline':False]
['text':' Note that we don't remove the aborted communicators from the','line_number':1062,'multiline':False]
['text':' cache. The reason is that if we do remove the communicator','line_number':1063,'multiline':False]
['text':' from the cache, it is possible that a new collective operation','line_number':1064,'multiline':False]
['text':' calls `ncclCommInitRank` to create a new communicator whereas','line_number':1065,'multiline':False]
['text':' other ranks might have failed/timed out and didn't enter','line_number':1066,'multiline':False]
['text':' `ncclCommInitRank`. As a result, when there is a failure on','line_number':1067,'multiline':False]
['text':' a communicator the application receives an exception and its','line_number':1068,'multiline':False]
['text':' their responsibility to destroy the process group and recreate','line_number':1069,'multiline':False]
['text':' it to recover from errors.','line_number':1070,'multiline':False]
['text':' Abort all communicators on this rank','line_number':1077,'multiline':False]
['text':' Remove record from global ncclCommDevIdxMapMutex before aboarting,','line_number':1079,'multiline':False]
['text':' so that a new cache segment would not register to already aborded','line_number':1080,'multiline':False]
['text':' communicators. Note that ncclCommDevIdxMap is a global container which may','line_number':1081,'multiline':False]
['text':' contain other PG's communicators, thus we need to only erase communicators','line_number':1082,'multiline':False]
['text':' for the current PG.','line_number':1083,'multiline':False]
['text':' Don't join threads here since the purpose of this method is to abort all','line_number':1099,'multiline':False]
['text':' communicators and signal the threads to exit. Joining on the threads could','line_number':1100,'multiline':False]
['text':' potentially block and hence avoid it in this method.','line_number':1101,'multiline':False]
['text':' Abort communicators after all threads have exited to avoid having the','line_number':1125,'multiline':False]
['text':' threads dying due to aborted communicator and raising a SIGABRT','line_number':1126,'multiline':False]
['text':' We need to wait for abort to finish before we can safely shut down','line_number':1130,'multiline':False]
['text':' heartbeat monitoring thread.','line_number':1131,'multiline':False]
['text':' Serialize all calls to this function to avoid corrupting data, but allow','line_number':1151,'multiline':False]
['text':' multiple calls in one runtime. User is responsible for preserving the','line_number':1152,'multiline':False]
['text':' output file from an earlier call before a later call overwrites it.','line_number':1153,'multiline':False]
['text':' We dump nccl trace into local disk by default and users can register','line_number':1157,'multiline':False]
['text':' their customized writer by inheriting `DebugInfoWriter` via','line_number':1158,'multiline':False]
['text':' `registerDebugInfoWriter`.','line_number':1159,'multiline':False]
['text':' Dump the trace blob into local disk as a fallback.','line_number':1162,'multiline':False]
['text':' Logging with `FATAL`, after errMsg printed, it calls `std::abort()`','line_number':1174,'multiline':False]
['text':' to terminate the program execution.','line_number':1175,'multiline':False]
['text':' This won't have any lock since this lock is only used here.','line_number':1182,'multiline':False]
['text':' Please be aware that mutex `monitorMutex_` should not be used','line_number':1183,'multiline':False]
['text':' somewhere else to avoid the deadlock.','line_number':1184,'multiline':False]
['text':' For the normal complete or user interception, monitorWakeUpCV_','line_number':1190,'multiline':False]
['text':' will get notified, we early return and exit heartbeatMonitor.','line_number':1191,'multiline':False]
['text':' Check the heart beat of watchdog thread.','line_number':1195,'multiline':False]
['text':' No heartbeat increase detected and timeout.','line_number':1200,'multiline':False]
['text':' Store debug info to storage if no other thread does it. (By default to','line_number':1205,'multiline':False]
['text':' local disk)','line_number':1206,'multiline':False]
['text':' Create a error message reported from MonitorThread, so','line_number':1209,'multiline':False]
['text':' we throw exception and make the whole process to be killed.','line_number':1210,'multiline':False]
['text':' There are two possible cases for the watchdog thread exit:','line_number':1219,'multiline':False]
['text':' Case one: desync report runs quickly, and it follows the step:','line_number':1220,'multiline':False]
['text':' collective timeout -> desync -> exception handling -> destructors','line_number':1221,'multiline':False]
['text':' -> set terminateHeartbeatMonitorThread_ -> notify monitorWakeUpCV_.','line_number':1222,'multiline':False]
['text':' So the code either early returns above or will skip the sleep below.','line_number':1223,'multiline':False]
['text':' Case two: desync might be slow or get stuck. Or we get stuck in','line_number':1224,'multiline':False]
['text':' destructors, we will sleep for some time before calling std::abort() to','line_number':1225,'multiline':False]
['text':' kill the whole process.','line_number':1226,'multiline':False]
['text':' Leave another two mins for desync report generation or process group','line_number':1229,'multiline':False]
['text':' destroy.','line_number':1230,'multiline':False]
['text':' At this point, we either already sleep for another `heartbeatTimeoutInSec_`','line_number':1234,'multiline':False]
['text':' or the thread has finished. Because we don't want to block the monitor','line_number':1235,'multiline':False]
['text':' thread, so We mark the thread detach and the dump of debug info becomes','line_number':1236,'multiline':False]
['text':' "best effort". If the process exit normally, marking it detach also makes','line_number':1237,'multiline':False]
['text':' sense because we don't really care about dumping the debug info.','line_number':1238,'multiline':False]
['text':' We already log completion inside the thread, so it may not be necessary to','line_number':1240,'multiline':False]
['text':' check the return value here.  We mainly use a future so we can exit early','line_number':1241,'multiline':False]
['text':' if done.','line_number':1242,'multiline':False]
['text':' Append error message reported from watchdogHandler','line_number':1278,'multiline':False]
['text':' TODO(whc) clean up the rethrow - why is it stored in a class var and','line_number':1285,'multiline':False]
['text':' rethrown?','line_number':1286,'multiline':False]
['text':' In case the start of the work hasn't been logged','line_number':1319,'multiline':False]
['text':' non-blocking from O_NONBLOCK above.','line_number':1358,'multiline':False]
['text':' Ignore EINTR because we already will poll this','line_number':1359,'multiline':False]
['text':' again later.','line_number':1360,'multiline':False]
['text':' We busy-poll the work vector every kWatchdogThreadSleepMillis','line_number':1393,'multiline':False]
['text':' milliseconds as long as the atomic is True.','line_number':1394,'multiline':False]
['text':' Bump up heart beat by one.','line_number':1399,'multiline':False]
['text':' poll store to see if some ranks have flagged a timeout when','line_number':1402,'multiline':False]
['text':' we haven't polled for `heartbeat_timeout` seconds and there haven't','line_number':1403,'multiline':False]
['text':' any work added or removed for `watchdog_timeout` seconds.','line_number':1404,'multiline':False]
['text':' no increment ','line_number':1434,'multiline':True]
['text':' If work hits an exception (either an error or timeout)','line_number':1439,'multiline':False]
['text':' Abort work and corresponding communicators','line_number':1442,'multiline':False]
['text':' PG level abort, which would abort all other communicators on this','line_number':1444,'multiline':False]
['text':' rank','line_number':1445,'multiline':False]
['text':' Report desync state in case of timeout','line_number':1449,'multiline':False]
['text':' Set shutdown mode, so the heartbeat monitor thread will not','line_number':1453,'multiline':False]
['text':' abort process immediately.','line_number':1454,'multiline':False]
['text':' Store debug info to storage. (By default to local disk)','line_number':1461,'multiline':False]
['text':' Store debug info to storage. (By default to local disk)','line_number':1471,'multiline':False]
['text':' Throw exception','line_number':1485,'multiline':False]
['text':' Work status logging for desync debug','line_number':1489,'multiline':False]
['text':' Clean up completed work','line_number':1499,'multiline':False]
['text':' Move Work object to completedWorkList_ to be consumed by the hook','line_number':1503,'multiline':False]
['text':' thread','line_number':1504,'multiline':False]
['text':' Increment the iterator if the current WorkNCCL object is not','line_number':1517,'multiline':False]
['text':' completed.','line_number':1518,'multiline':False]
['text':' process a request to dump the trace','line_number':1522,'multiline':False]
['text':' We busy-poll the work vector every kWatchdogThreadSleepMillis','line_number':1534,'multiline':False]
['text':' milliseconds as long as the atomic is True.','line_number':1535,'multiline':False]
['text':' no increment ','line_number':1545,'multiline':True]
['text':' Hook might grab GIL, unlock first to prevent deadlock','line_number':1547,'multiline':False]
['text':' OpType','line_number':1555,'multiline':False]
['text':' timeStarted','line_number':1556,'multiline':False]
['text':' timeFinished','line_number':1557,'multiline':False]
['text':' activeDuration','line_number':1559,'multiline':False]
['text':' PythonOnCompletionHook has already extracted Python exception message','line_number':1574,'multiline':False]
['text':' and wrapped it with a cpp one. So we no longer need to acquire GIL','line_number':1575,'multiline':False]
['text':' here.','line_number':1576,'multiline':False]
['text':' No need to call abort() on WorkNCCL here as that collective has','line_number':1584,'multiline':False]
['text':' already finished successfully at this point. We just need to abort','line_number':1585,'multiline':False]
['text':' the process Abort all NCCL Communicators on this ProcessGroupNCCL','line_number':1586,'multiline':False]
['text':' instance.','line_number':1587,'multiline':False]
['text':' Lock is still acquired at this point','line_number':1592,'multiline':False]
['text':' Prioritize commFailureReason over checkForNcclError() result if','line_number':1610,'multiline':False]
['text':' commFailureReason is set.','line_number':1611,'multiline':False]
['text':' For collective operations:','line_number':1637,'multiline':False]
['text':' For every NCCL communicator that we create we need to broadcast','line_number':1638,'multiline':False]
['text':' a unique ID from rank 0 to all other ranks. This broadcast is','line_number':1639,'multiline':False]
['text':' done by rank 0 setting a key in the store and all other ranks','line_number':1640,'multiline':False]
['text':' retrieving the contents of that key. A single process group','line_number':1641,'multiline':False]
['text':' may create multiple NCCL communicators, so we use a sequence','line_number':1642,'multiline':False]
['text':' number to differentiate between them.','line_number':1643,'multiline':False]
['text':' For single point-to-point operations:','line_number':1644,'multiline':False]
['text':' The sequence number will only be increased on 2 out of all the','line_number':1645,'multiline':False]
['text':' processes in a Process Group. So all following collective','line_number':1646,'multiline':False]
['text':' operations will see different sequence numbers which will cause','line_number':1647,'multiline':False]
['text':' runtime errors. To avoid that, use the src:target pair instead','line_number':1648,'multiline':False]
['text':' of sequence number for p2p communications.','line_number':1649,'multiline':False]
['text':' Loop through communicators and call ncclCommAbort.','line_number':1710,'multiline':False]
['text':' ncclCommDestroy(comm->getNcclComm()) results in segfault when PG is being','line_number':1712,'multiline':False]
['text':' destroyed, so using ncclCommAbort here.','line_number':1713,'multiline':False]
['text':' Remove communicators from the cache.','line_number':1716,'multiline':False]
['text':' Clear used device indices.','line_number':1718,'multiline':False]
['text':' Sanity check','line_number':1734,'multiline':False]
['text':' Reuse the cached communicator if there is one.','line_number':1760,'multiline':False]
['text':' NCCL communicator not cached, create a new entry','line_number':1765,'multiline':False]
['text':' Create the unique NCCL ID and broadcast it','line_number':1769,'multiline':False]
['text':' For batch_isend_irecv, ncclGroupStart() would be called upfront','line_number':1772,'multiline':False]
['text':' For point-to-point communication, lower rank of the two will get unique id.','line_number':1775,'multiline':False]
['text':' For point-to-point communication on the same process, don't need broadcast.','line_number':1780,'multiline':False]
['text':' Broadcast so that each process can have a unique NCCL ID','line_number':1782,'multiline':False]
['text':' [Group Start/End Note] This is used to ensure that nccl communicator will','line_number':1791,'multiline':False]
['text':' be created before communication primitives are called. Let's look at this','line_number':1792,'multiline':False]
['text':' example: Using the batch_isend_irecv to send a tensor to a target process.','line_number':1793,'multiline':False]
['text':' On the sender side, the corresponding underlying NCCL calls will look like','line_number':1794,'multiline':False]
['text':'   ncclGroupStart() // This is in batch_isend_irecv','line_number':1795,'multiline':False]
['text':'   ncclGroupStart() // This is [Note 1]','line_number':1796,'multiline':False]
['text':'   ncclCommInitRank() // Inside NCCLComm::create','line_number':1797,'multiline':False]
['text':'   ncclSend()','line_number':1798,'multiline':False]
['text':'   ncclGroupEnd() // This is [Note 2]','line_number':1799,'multiline':False]
['text':'   ncclGroupEnd() // This is in batch_isend_irecv','line_number':1800,'multiline':False]
['text':' With this pattern, the nccl communicator will be created in the last','line_number':1801,'multiline':False]
['text':' ncclGroupEnd which means when ncclSend is processed, the passed','line_number':1802,'multiline':False]
['text':' communicator argument is NULL which will lead to runtime error. So we need','line_number':1803,'multiline':False]
['text':' to "close" all active nccl groups to ensure nccl communicator is actually','line_number':1804,'multiline':False]
['text':' created before encountering any communication calls. This is why we need','line_number':1805,'multiline':False]
['text':' the following for loop.','line_number':1806,'multiline':False]
['text':' comms have not been initiated yet, so can only check in blocking-way','line_number':1809,'multiline':False]
['text':' [Note 1] Create the NCCL communicators for each GPU','line_number':1813,'multiline':False]
['text':' GPU world size and GPU rank','line_number':1817,'multiline':False]
['text':' Collective, all-to-all, or batch P2P','line_number':1821,'multiline':False]
['text':' Same process send and recv.','line_number':1825,'multiline':False]
['text':' For single point-to-point operation, there are only 2 processes','line_number':1829,'multiline':False]
['text':' involved so the GPU rank is either 0 or 1.','line_number':1830,'multiline':False]
['text':' Get the device index','line_number':1834,'multiline':False]
['text':' Find a valid, healthy communicator to split from if possible.','line_number':1843,'multiline':False]
['text':' To simplify conditioonal nesting, just create the ncclComms[i]','line_number':1862,'multiline':False]
['text':' entry if it hasn't been yet rather than untangling the','line_number':1863,'multiline':False]
['text':' conditions that might have resulted in a split above.','line_number':1864,'multiline':False]
['text':' Creates the NCCL streams','line_number':1873,'multiline':False]
['text':' [Note 2 ]','line_number':1883,'multiline':False]
['text':' At this point NCCL should have been initialized, hence we can accurately','line_number':1894,'multiline':False]
['text':' get the env value even if NCCL sets it by reading from nccl.conf file','line_number':1895,'multiline':False]
['text':' See [Group Start/End Note]','line_number':1900,'multiline':False]
['text':' Note: these events are created with the (default) cudaEventDisableTiming','line_number':1908,'multiline':False]
['text':' flag This flag provides the best performance when used with','line_number':1909,'multiline':False]
['text':' cudaStreamWaitEvent() and cudaEventQuery(). Since we here don't measure the','line_number':1910,'multiline':False]
['text':' performance using cudaEvent, this should be set.','line_number':1911,'multiline':False]
['text':' Record the communicators based on ncclUniqueId.','line_number':1917,'multiline':False]
['text':' Move the NCCL resource to cache','line_number':1920,'multiline':False]
['text':' A previous thread could've already removed devicesKey from','line_number':1922,'multiline':False]
['text':' inInitializationCommMap_ and added it to devNCCLCommMap_','line_number':1923,'multiline':False]
['text':' Now ncclComms are fully initialized.','line_number':1928,'multiline':False]
['text':' Register all active CUDA memory segments in cache allocator to','line_number':1929,'multiline':False]
['text':' the new NCCL communicators','line_number':1930,'multiline':False]
['text':' Register the segment to a new NCCL communicator if on the same device','line_number':1933,'multiline':False]
['text':' Record the mapping between ncclComm and device index so that later','line_number':1944,'multiline':False]
['text':' register hook can register a newly allocated segment to communicators','line_number':1945,'multiline':False]
['text':' on the same device.','line_number':1946,'multiline':False]
['text':' NOTE: we need remove the communicator from this map when it is','line_number':1947,'multiline':False]
['text':' destroyed, otherwise may register onto an invalid communicator.','line_number':1948,'multiline':False]
['text':' Check validity of tensor','line_number':1976,'multiline':False]
['text':' whether operation is a P2P operation','line_number':1979,'multiline':False]
['text':' Skip the following requirements for P2P operations','line_number':1984,'multiline':False]
['text':' Checks that all `tensors' have the same type and shape and reside on distinct','line_number':1997,'multiline':False]
['text':' GPUs.','line_number':1998,'multiline':False]
['text':' TODO: test_c10d_nccl.py should consider adding tests for the error conditions','line_number':1999,'multiline':False]
['text':' here, ie, that deliberately pass invalid tensors and check the right','line_number':2000,'multiline':False]
['text':' exception is thrown.','line_number':2001,'multiline':False]
['text':' whether operation is a P2P operation','line_number':2004,'multiline':False]
['text':' Set for ensuring that tensors are on separate devices.','line_number':2017,'multiline':False]
['text':' Skip the following requirements for P2P operations','line_number':2034,'multiline':False]
['text':' Checks that all `tensors' have the same type and shape and reside on the same','line_number':2052,'multiline':False]
['text':' GPU.','line_number':2053,'multiline':False]
['text':' TODO: test_c10d_nccl.py should consider adding tests for the error conditions','line_number':2054,'multiline':False]
['text':' here, ie, that deliberately pass invalid tensors and check the right','line_number':2055,'multiline':False]
['text':' exception is thrown. The "Expected list of tensors on the same device"','line_number':2056,'multiline':False]
['text':' condition may be a challenge because the test would need to pass tensors on','line_number':2057,'multiline':False]
['text':' different devices in the same process.','line_number':2058,'multiline':False]
['text':' If we're in this function, the user called a _coalesced collective','line_number':2077,'multiline':False]
['text':' on a set of tensors with potentially different sizes and strides.','line_number':2078,'multiline':False]
['text':' Therefore, we don't check for matching sizes and strides,','line_number':2079,'multiline':False]
['text':' but we do double-check tensors are on the same device.','line_number':2080,'multiline':False]
['text':' Flatten each list in `tensor_lists' for a gather or scatter operation, and','line_number':2100,'multiline':False]
['text':' ensure compatibility with the corresponding tensor in `other'.','line_number':2101,'multiline':False]
['text':' Only check device match for the first tensor in the list; the call to','line_number':2132,'multiline':False]
['text':' newLikeFlat() below will check the rest.','line_number':2133,'multiline':False]
['text':' Flatten the tensors (from all ranks) into a single big tensor.','line_number':2148,'multiline':False]
['text':' namespace','line_number':2154,'multiline':False]
['text':' Avoid view tensors to be processed in cleanup thread.','line_number':2214,'multiline':False]
['text':' View tensors' destruction invokes autograd_meta, which','line_number':2215,'multiline':False]
['text':' needs to be destructed in user thread. Otherwise will','line_number':2216,'multiline':False]
['text':' get deadlock. Here we enqueue work without outputs_.','line_number':2217,'multiline':False]
['text':' There is no actual work being coalesced','line_number':2238,'multiline':False]
['text':' `coalescedComms_` should have same set of comms across collectives','line_number':2241,'multiline':False]
['text':' There is no actual work being coalesced','line_number':2249,'multiline':False]
['text':' `coalescedDevices_` should have same set of devices across collectives','line_number':2253,'multiline':False]
['text':' Create Work object','line_number':2256,'multiline':False]
['text':' Record stream event','line_number':2259,'multiline':False]
['text':' `getKeyFromDevices` is how we get keys for both collectives and batch P2P','line_number':2260,'multiline':False]
['text':' TODO(eqy): is this still necessary if avoidRecordStreams_ is set?','line_number':2263,'multiline':False]
['text':' Set appropriate work parameters.','line_number':2269,'multiline':False]
['text':' other functions expect an initialized ptr if avoidRecordStreams_ is set','line_number':2275,'multiline':False]
['text':' TODO: it seems we never enqueue work for single send/recv or batch P2P,','line_number':2285,'multiline':False]
['text':' see the `pointToPoint` function. This should be fixed. Otherwise, we risk','line_number':2286,'multiline':False]
['text':' not being able to abort hanged P2P ops.','line_number':2287,'multiline':False]
['text':' Environment setting by the user may add onto collective call's option','line_number':2303,'multiline':False]
['text':' Bump collective counter','line_number':2309,'multiline':False]
['text':' Currently, the API permits one scenario where inputs.size() and','line_number':2312,'multiline':False]
['text':' outputs.size() are > 0.','line_number':2313,'multiline':False]
['text':' 1. If the call was a _coalesced call, all inputs must be on the same','line_number':2314,'multiline':False]
['text':' device.','line_number':2315,'multiline':False]
['text':'    The group of nccl calls applies the collective separately to each input,','line_number':2316,'multiline':False]
['text':'    but the group as a whole should be efficient, and might even execute as','line_number':2317,'multiline':False]
['text':'    a single fused kernel.','line_number':2318,'multiline':False]
['text':' Used many times below, so we stash the unordered_map lookup','line_number':2330,'multiline':False]
['text':' First let NCCL streams wait for input tensors allocation streams','line_number':2333,'multiline':False]
['text':' Work itself will create the CUDA events on all GPUs of tensors','line_number':2336,'multiline':False]
['text':' Store references to outputs to be used by WorkNCCL::result and operator<<.','line_number':2347,'multiline':False]
['text':' Start event should only be recorded before the ncclGroupStart()','line_number':2357,'multiline':False]
['text':' Both `inputs' and `outputs' are created on a worker stream and used in','line_number':2385,'multiline':False]
['text':' different ncclStreams.  Hence, both must record the ncclStream to','line_number':2386,'multiline':False]
['text':' prevent being freed before the collective finishes.','line_number':2387,'multiline':False]
['text':'','line_number':2388,'multiline':False]
['text':' We only record `inputs' here, and leave recording `outputs' to `fn' for','line_number':2389,'multiline':False]
['text':' operations where `inputs' and `outputs' are not the same.','line_number':2390,'multiline':False]
['text':'','line_number':2391,'multiline':False]
['text':' See [Sync Streams].','line_number':2392,'multiline':False]
['text':' for sparse input case record streams on both index and value','line_number':2398,'multiline':False]
['text':' tensors','line_number':2399,'multiline':False]
['text':' End event should only be recorded after the ncclGroupEnd()','line_number':2420,'multiline':False]
['text':' Add a callback that runs profiling end callbacks. wrapCallback() in CUDA','line_number':2434,'multiline':False]
['text':' future blocks the stream this callback runs on the corresponding','line_number':2435,'multiline':False]
['text':' ncclEndEvents_ ensuring appropriate synchronization.','line_number':2436,'multiline':False]
['text':' unused ','line_number':2439,'multiline':True]
['text':' uses_future = false allows us to skip synchronization in','line_number':2442,'multiline':False]
['text':' ivalue::Future, but is only valid as long as the lambda doesn't use','line_number':2443,'multiline':False]
['text':' the "Future" argument.','line_number':2444,'multiline':False]
['text':'uses_future=','line_number':2445,'multiline':True]
['text':' Set appropriate work parameters.','line_number':2450,'multiline':False]
['text':' Record size info for debug. We only record the size on the first device as','line_number':2455,'multiline':False]
['text':' multi-device per process is deprecated','line_number':2456,'multiline':False]
['text':' Notify graphs before we check the capture status preemptively','line_number':2460,'multiline':False]
['text':' avoidRecordStreams_ note:','line_number':2481,'multiline':False]
['text':' send, recv, and irecv should be ok with avoidRecordStreams,','line_number':2482,'multiline':False]
['text':' However, for isend, I don't think the API requires the user','line_number':2483,'multiline':False]
['text':' to wait() on the returned handle, so ProcessGroupNCCL can't know','line_number':2484,'multiline':False]
['text':' when it's safe to release the input back to the allocator,','line_number':2485,'multiline':False]
['text':' and the present call has no way to know it's not an isend.','line_number':2486,'multiline':False]
['text':' Therefore, we warn and fall back to the typical recordStream logic:','line_number':2487,'multiline':False]
['text':' Bump sequence number, updated in collective() as well','line_number':2494,'multiline':False]
['text':' For batch_isend_irecv, ncclGroupStart() would be called upfront','line_number':2501,'multiline':False]
['text':' For batch P2P, we need to treat it like a collective when selecting','line_number':2504,'multiline':False]
['text':' communicator, because other ranks can call into this batch other than my','line_number':2505,'multiline':False]
['text':' rank and my peer','line_number':2506,'multiline':False]
['text':' For single P2P, preserve the old two-rank behavior (to avoid perf diff)','line_number':2511,'multiline':False]
['text':' First let NCCL streams wait for input tensors allocation streams','line_number':2525,'multiline':False]
['text':' Work itself will create the CUDA events on all GPUs of tensors','line_number':2528,'multiline':False]
['text':' Store references to outputs to be used by WorkNCCL::result and operator<<.','line_number':2538,'multiline':False]
['text':' Note that these outputs are only valid for recv(), as send() does not','line_number':2539,'multiline':False]
['text':' modify the inputs but we still create these outputs for use cases such as','line_number':2540,'multiline':False]
['text':' profiling.','line_number':2541,'multiline':False]
['text':' Start event should only be recorded before the ncclGroupStart()','line_number':2546,'multiline':False]
['text':' Both send tensor and recv tensor are created on a worker stream and used','line_number':2560,'multiline':False]
['text':' in different ncclStreams.  Hence, both must record the ncclStream to','line_number':2561,'multiline':False]
['text':' prevent being freed before the collective finishes.','line_number':2562,'multiline':False]
['text':'','line_number':2563,'multiline':False]
['text':' See [Sync Streams].','line_number':2564,'multiline':False]
['text':' End event should only be recorded after the ncclGroupEnd()','line_number':2602,'multiline':False]
['text':' Record size info for debug. We only record the size on the first device as','line_number':2614,'multiline':False]
['text':' multi-device per process is deprecated','line_number':2615,'multiline':False]
['text':' Future only needs to be created and marked completed with outputs for','line_number':2618,'multiline':False]
['text':' recv(), but still create future for use cases such as profiling even for','line_number':2619,'multiline':False]
['text':' send().','line_number':2620,'multiline':False]
['text':' Add a callback that runs profiling end callbacks. wrapCallback() in CUDA','line_number':2628,'multiline':False]
['text':' future blocks the stream this callback runs on the corresponding','line_number':2629,'multiline':False]
['text':' ncclEndEvents_ ensuring appropriate synchronization.','line_number':2630,'multiline':False]
['text':' unused ','line_number':2633,'multiline':True]
['text':' uses_future = false allows us to skip synchronization in','line_number':2636,'multiline':False]
['text':' ivalue::Future, but is only valid as long as the lambda doesn't use','line_number':2637,'multiline':False]
['text':' the "Future" argument.','line_number':2638,'multiline':False]
['text':'uses_future=','line_number':2639,'multiline':True]
['text':' Enqueue P2P op so that it can be cancelled by NCCL watchdog','line_number':2642,'multiline':False]
['text':' Notify graphs before we check the capture status preemptively','line_number':2646,'multiline':False]
['text':' prevent output and recvIndices from being freed','line_number':2727,'multiline':False]
['text':' sendbuff','line_number':2733,'multiline':False]
['text':' recv_indices','line_number':2734,'multiline':False]
['text':' block_count','line_number':2735,'multiline':False]
['text':' block_length','line_number':2736,'multiline':False]
['text':' recvbuff','line_number':2737,'multiline':False]
['text':' recv_count','line_number':2738,'multiline':False]
['text':' Convert output tensors to sparse and back into tensors.','line_number':2749,'multiline':False]
['text':' If the nccl branch is not "exp" then we just error','line_number':2766,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':2815,'multiline':False]
['text':' seq + 1 to match collective','line_number':2819,'multiline':False]
['text':' inputTensors','line_number':2821,'multiline':False]
['text':' outputTensors','line_number':2822,'multiline':False]
['text':' rank','line_number':2823,'multiline':False]
['text':' colName','line_number':2824,'multiline':False]
['text':' inNelems','line_number':2825,'multiline':False]
['text':' outNelems','line_number':2826,'multiline':False]
['text':' dType','line_number':2827,'multiline':False]
['text':' inSplitSizes','line_number':2828,'multiline':False]
['text':' outSplitSizes','line_number':2829,'multiline':False]
['text':' globalRankStart','line_number':2830,'multiline':False]
['text':' globalRankStride','line_number':2831,'multiline':False]
['text':' worldSize','line_number':2832,'multiline':False]
['text':' avoidRecordStreams_ note: collective() will stash tensors.','line_number':2834,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':2843,'multiline':False]
['text':' seq + 1 to match collective','line_number':2846,'multiline':False]
['text':' inputTensors','line_number':2848,'multiline':False]
['text':' outputTensors','line_number':2849,'multiline':False]
['text':' rank','line_number':2850,'multiline':False]
['text':' colName','line_number':2851,'multiline':False]
['text':' inNelems','line_number':2852,'multiline':False]
['text':' outNelems','line_number':2853,'multiline':False]
['text':' dType','line_number':2854,'multiline':False]
['text':' I'm not sure what in,outSplitSizes mean here.','line_number':2855,'multiline':False]
['text':' inSplitSizes','line_number':2856,'multiline':False]
['text':' outSplitSizes','line_number':2857,'multiline':False]
['text':' globalRankStart','line_number':2858,'multiline':False]
['text':' globalRankStride','line_number':2859,'multiline':False]
['text':' worldSize','line_number':2860,'multiline':False]
['text':' avoidRecordStreams_ note: collective() will stash tensors.','line_number':2862,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':2871,'multiline':False]
['text':' seq + 1 to match collective','line_number':2875,'multiline':False]
['text':' inputTensors','line_number':2877,'multiline':False]
['text':' outputTensors','line_number':2878,'multiline':False]
['text':' root rank','line_number':2879,'multiline':False]
['text':' colName','line_number':2880,'multiline':False]
['text':' inNelems','line_number':2881,'multiline':False]
['text':' outNelems','line_number':2882,'multiline':False]
['text':' dType','line_number':2883,'multiline':False]
['text':' inSplitSizes','line_number':2884,'multiline':False]
['text':' outSplitSizes','line_number':2885,'multiline':False]
['text':' globalRankStart','line_number':2886,'multiline':False]
['text':' globalRankStride','line_number':2887,'multiline':False]
['text':' worldSize','line_number':2888,'multiline':False]
['text':' avoidRecordStreams_ note: collective() will stash tensors.','line_number':2890,'multiline':False]
['text':' _broadcast_oop adds an out-of-place broadcast in PGNCCL','line_number':2914,'multiline':False]
['text':' Custom collectives may be implemented by coalescing broadcast operations','line_number':2915,'multiline':False]
['text':' One use-case is implementing a vector all_gather (all_gather_v)','line_number':2916,'multiline':False]
['text':' where unevenly sized inputs are gathered among participating ranks','line_number':2917,'multiline':False]
['text':' Since all_gather provides an out-of-place API, an all_gather_v','line_number':2918,'multiline':False]
['text':' semantic implemented inside pg_nccl.all_gather also needs to support','line_number':2919,'multiline':False]
['text':' out-of-place, for which an out-of-place broadcast is required to be added','line_number':2920,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':2928,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':2930,'multiline':False]
['text':' seq + 1 to match collective increment.','line_number':2940,'multiline':False]
['text':' inputTensors','line_number':2942,'multiline':False]
['text':' outputTensors','line_number':2943,'multiline':False]
['text':' root rank','line_number':2944,'multiline':False]
['text':' colName','line_number':2945,'multiline':False]
['text':' inNelems','line_number':2946,'multiline':False]
['text':' outNelems','line_number':2947,'multiline':False]
['text':' dType','line_number':2948,'multiline':False]
['text':' inSplitSizes','line_number':2949,'multiline':False]
['text':' outSplitSizes','line_number':2950,'multiline':False]
['text':' globalRankStart','line_number':2951,'multiline':False]
['text':' globalRankStride','line_number':2952,'multiline':False]
['text':' worldSize','line_number':2953,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':2980,'multiline':False]
['text':' seq + 1 to match collective','line_number':2984,'multiline':False]
['text':' inputTensors','line_number':2986,'multiline':False]
['text':' outputTensors','line_number':2987,'multiline':False]
['text':' root rank','line_number':2988,'multiline':False]
['text':' colName','line_number':2989,'multiline':False]
['text':' inNelems','line_number':2990,'multiline':False]
['text':' outNelems','line_number':2991,'multiline':False]
['text':' dType','line_number':2992,'multiline':False]
['text':' inSplitSizes','line_number':2993,'multiline':False]
['text':' outSplitSizes','line_number':2994,'multiline':False]
['text':' globalRankStart','line_number':2995,'multiline':False]
['text':' globalRankStride','line_number':2996,'multiline':False]
['text':' worldSize','line_number':2997,'multiline':False]
['text':' avoidRecordStreams_ note: collective() will stash tensors.','line_number':3000,'multiline':False]
['text':' _reduce_oop exposes an out-of-place reduce from PGNCCL','line_number':3026,'multiline':False]
['text':' Custom collectives may be implemented by coalescing reduce operations','line_number':3027,'multiline':False]
['text':' One use-case is implementing a vector reduce_scatter (reduce_scatter_v)','line_number':3028,'multiline':False]
['text':' where inputs are reduced and scattered unevenly among participating ranks','line_number':3029,'multiline':False]
['text':' Since reduce_scatter provides an out-of-place API, a reduce_scatter_v','line_number':3030,'multiline':False]
['text':' semantic implemented inside pg_nccl.reduce_scatter also needs to support','line_number':3031,'multiline':False]
['text':' out-of-place, for which an out-of-place reduce is required to be added','line_number':3032,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':3039,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':3041,'multiline':False]
['text':' seq + 1 to match collective','line_number':3050,'multiline':False]
['text':' inputTensors','line_number':3052,'multiline':False]
['text':' outputTensors','line_number':3053,'multiline':False]
['text':' root rank','line_number':3054,'multiline':False]
['text':' colName','line_number':3055,'multiline':False]
['text':' inNelems','line_number':3056,'multiline':False]
['text':' outNelems','line_number':3057,'multiline':False]
['text':' dType','line_number':3058,'multiline':False]
['text':' inSplitSizes','line_number':3059,'multiline':False]
['text':' outSplitSizes','line_number':3060,'multiline':False]
['text':' globalRankStart','line_number':3061,'multiline':False]
['text':' globalRankStride','line_number':3062,'multiline':False]
['text':' worldSize','line_number':3063,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':3096,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':3104,'multiline':False]
['text':' seq + 1 to match collective','line_number':3109,'multiline':False]
['text':' inputTensors','line_number':3111,'multiline':False]
['text':' outputTensors','line_number':3112,'multiline':False]
['text':' rank','line_number':3113,'multiline':False]
['text':' colName','line_number':3114,'multiline':False]
['text':' inNelems','line_number':3115,'multiline':False]
['text':' outNelems','line_number':3116,'multiline':False]
['text':' dType','line_number':3118,'multiline':False]
['text':' inSplitSizes','line_number':3119,'multiline':False]
['text':' outSplitSize','line_number':3120,'multiline':False]
['text':' globalRankStart','line_number':3121,'multiline':False]
['text':' globalRankStride','line_number':3122,'multiline':False]
['text':' worldSize','line_number':3123,'multiline':False]
['text':' avoidRecordStreams_ note: We actually don't need to stash anything','line_number':3146,'multiline':False]
['text':' here.','line_number':3147,'multiline':False]
['text':'  - inputTensors is stashed onto work->stashed_for_allocator_safety_','line_number':3148,'multiline':False]
['text':'    in collective().','line_number':3149,'multiline':False]
['text':'  - outputFlattened is stashed onto work->outputs_ in collective().','line_number':3150,'multiline':False]
['text':'  - User-facing outputTensors should be held by the user until after','line_number':3151,'multiline':False]
['text':'    waiting on work_, or the call makes no sense.','line_number':3152,'multiline':False]
['text':' So all participating tensors are accounted for, and won't be','line_number':3153,'multiline':False]
['text':' released back to their allocation streams until after work_ is','line_number':3154,'multiline':False]
['text':' waited on.','line_number':3155,'multiline':False]
['text':' Copy the flattened output tensors to the outputs.','line_number':3159,'multiline':False]
['text':' See [Sync Streams].','line_number':3163,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':3183,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':3186,'multiline':False]
['text':' unused ','line_number':3204,'multiline':True]
['text':' unused ','line_number':3205,'multiline':True]
['text':' unused ','line_number':3206,'multiline':True]
['text':' @lint-ignore CLANGTIDY','line_number':3240,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':3244,'multiline':False]
['text':' seq + 1 to match collective','line_number':3255,'multiline':False]
['text':' inputTensors','line_number':3257,'multiline':False]
['text':' outputTensors','line_number':3258,'multiline':False]
['text':' rank','line_number':3259,'multiline':False]
['text':' colName','line_number':3260,'multiline':False]
['text':' inNelems','line_number':3261,'multiline':False]
['text':' outNelems','line_number':3262,'multiline':False]
['text':' dType','line_number':3263,'multiline':False]
['text':' inSplitSizes','line_number':3264,'multiline':False]
['text':' outSplitSizes','line_number':3265,'multiline':False]
['text':' globalRankStart','line_number':3266,'multiline':False]
['text':' globalRankStride','line_number':3267,'multiline':False]
['text':' worldSize','line_number':3268,'multiline':False]
['text':' We only need to stash inputTensors.','line_number':3296,'multiline':False]
['text':'  - inputFlattened is stashed onto','line_number':3297,'multiline':False]
['text':'  work->stashed_for_allocator_safety_','line_number':3298,'multiline':False]
['text':'    in collective().','line_number':3299,'multiline':False]
['text':'  - User-facing outputTensors is stashed onto work->outputs_ in','line_number':3300,'multiline':False]
['text':'  collective(),','line_number':3301,'multiline':False]
['text':'    and should also be held by the user until after waiting on','line_number':3302,'multiline':False]
['text':'    work_.','line_number':3303,'multiline':False]
['text':' Copy the input tensors to the flattened inputs.','line_number':3311,'multiline':False]
['text':' See [Sync Streams].','line_number':3315,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':3337,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':3340,'multiline':False]
['text':' @lint-ignore CLANGTIDY','line_number':3372,'multiline':False]
['text':' seq + 1 to match collective','line_number':3376,'multiline':False]
['text':' inputTensor','line_number':3378,'multiline':False]
['text':' outputTensor','line_number':3379,'multiline':False]
['text':' rank','line_number':3380,'multiline':False]
['text':' colName','line_number':3381,'multiline':False]
['text':' inNelems','line_number':3382,'multiline':False]
['text':' outNelems','line_number':3383,'multiline':False]
['text':' dtype','line_number':3384,'multiline':False]
['text':' inSplitSizes','line_number':3385,'multiline':False]
['text':' outSplitSizes','line_number':3386,'multiline':False]
['text':' globalRankStart','line_number':3387,'multiline':False]
['text':' globalRankStride','line_number':3388,'multiline':False]
['text':' worldSize','line_number':3389,'multiline':False]
['text':' avoidRecordStreams_ note: collective() will stash inputs and outputs.','line_number':3395,'multiline':False]
['text':' Note 2: for asyncOp = false, we don't want to record streams because we','line_number':3396,'multiline':False]
['text':' know that the NCCL stream will join back to the "current" stream right','line_number':3397,'multiline':False]
['text':' after this op. So we might just as well keep the stream ownership of the','line_number':3398,'multiline':False]
['text':' input/output tensors unchanged. The benefit would be that the','line_number':3399,'multiline':False]
['text':' allocation/free of the tensors would look deterministic to the "current"','line_number':3400,'multiline':False]
['text':' stream so that the caching allocator can reuse memory pool for this stream','line_number':3401,'multiline':False]
['text':' in a clever way. This setting is added for libraries like FSDP which uses','line_number':3402,'multiline':False]
['text':' `reduce_scatter_tensor`.','line_number':3403,'multiline':False]
['text':'dev_in_group=','line_number':3451,'multiline':True]
['text':' seq + 1 to match collective','line_number':3468,'multiline':False]
['text':' rank','line_number':3470,'multiline':False]
['text':' colName','line_number':3471,'multiline':False]
['text':' inNelems','line_number':3472,'multiline':False]
['text':' outNelems','line_number':3473,'multiline':False]
['text':' dType','line_number':3474,'multiline':False]
['text':' inSplitSizes','line_number':3475,'multiline':False]
['text':' outSplitSizes','line_number':3476,'multiline':False]
['text':' globalRankStart','line_number':3477,'multiline':False]
['text':' globalRankStride','line_number':3478,'multiline':False]
['text':' worldSize','line_number':3479,'multiline':False]
['text':' Use user defined GPU device ids if provided','line_number':3483,'multiline':False]
['text':' This means there is not yet a NCCL collective being called','line_number':3489,'multiline':False]
['text':' Here we have to use the best guesses and will use a single GPU to call','line_number':3490,'multiline':False]
['text':' allreduce to achieve barrier.','line_number':3491,'multiline':False]
['text':' In case the multiple processes fall into the same node, we use rank to','line_number':3492,'multiline':False]
['text':' ensure that each process is on a different GPU','line_number':3493,'multiline':False]
['text':' All reduce to achieve the barrier','line_number':3522,'multiline':False]
['text':' Work will take over barrierTensors','line_number':3525,'multiline':False]
['text':' unused ','line_number':3539,'multiline':True]
['text':' seq + 1 to match collective','line_number':3549,'multiline':False]
['text':' inputTensor','line_number':3551,'multiline':False]
['text':' outputTensor','line_number':3552,'multiline':False]
['text':' rank','line_number':3553,'multiline':False]
['text':' colName','line_number':3554,'multiline':False]
['text':' inNelems','line_number':3555,'multiline':False]
['text':' outNelems','line_number':3556,'multiline':False]
['text':' dType','line_number':3557,'multiline':False]
['text':' inSplitSizes','line_number':3558,'multiline':False]
['text':' outSplitSizes','line_number':3559,'multiline':False]
['text':' globalRankStart','line_number':3560,'multiline':False]
['text':' globalRankStride','line_number':3561,'multiline':False]
['text':' worldSize','line_number':3562,'multiline':False]
['text':' avoidRecordStreams_ note: collective() will stash inputTensors and','line_number':3564,'multiline':False]
['text':' outputTensors.','line_number':3565,'multiline':False]
['text':' See [Sync Streams].','line_number':3573,'multiline':False]
['text':' seq + 1 to match collective','line_number':3593,'multiline':False]
['text':' inputTensor','line_number':3595,'multiline':False]
['text':' outputTensor','line_number':3596,'multiline':False]
['text':' rank','line_number':3597,'multiline':False]
['text':' colName','line_number':3598,'multiline':False]
['text':' inNelems','line_number':3599,'multiline':False]
['text':' outNelems','line_number':3600,'multiline':False]
['text':' dType','line_number':3601,'multiline':False]
['text':' inSplitSizes','line_number':3602,'multiline':False]
['text':' outSplitSizes','line_number':3603,'multiline':False]
['text':' globalRankStart','line_number':3604,'multiline':False]
['text':' globalRankStride','line_number':3605,'multiline':False]
['text':' worldSize','line_number':3606,'multiline':False]
['text':' avoidRecordStreams_ note: collective() will stash inputTensors and','line_number':3608,'multiline':False]
['text':' outputTensors.','line_number':3609,'multiline':False]
['text':' See [Sync Streams].','line_number':3625,'multiline':False]
['text':' unused ','line_number':3651,'multiline':True]
['text':' seq + 1 to match collective','line_number':3671,'multiline':False]
['text':' inputTensors','line_number':3673,'multiline':False]
['text':' outputTensors','line_number':3674,'multiline':False]
['text':' rank','line_number':3675,'multiline':False]
['text':' colName','line_number':3676,'multiline':False]
['text':' inNelems','line_number':3677,'multiline':False]
['text':' outNelems','line_number':3678,'multiline':False]
['text':' dType','line_number':3679,'multiline':False]
['text':' inSplitSizes','line_number':3680,'multiline':False]
['text':' outSplitSizes','line_number':3681,'multiline':False]
['text':' globalRankStart','line_number':3682,'multiline':False]
['text':' globalRankStride','line_number':3683,'multiline':False]
['text':' worldSize','line_number':3684,'multiline':False]
['text':' unused ','line_number':3691,'multiline':True]
['text':' unused ','line_number':3692,'multiline':True]
['text':' inputTensor0 and outputTensor0 are stashed redundantly by','line_number':3701,'multiline':False]
['text':' collective(), but that's ok.','line_number':3702,'multiline':False]
['text':' unused ','line_number':3717,'multiline':True]
['text':' @lint-ignore CLANGTIDY','line_number':3720,'multiline':False]
['text':' seq + 1 to match collective','line_number':3724,'multiline':False]
['text':' inputTensors','line_number':3726,'multiline':False]
['text':' outputTensors','line_number':3727,'multiline':False]
['text':' dst rank','line_number':3728,'multiline':False]
['text':' colName','line_number':3729,'multiline':False]
['text':' inNelems','line_number':3730,'multiline':False]
['text':' outNelems','line_number':3731,'multiline':False]
['text':' dType','line_number':3732,'multiline':False]
['text':' inSplitSizes','line_number':3733,'multiline':False]
['text':' outSplitSizes','line_number':3734,'multiline':False]
['text':' globalRankStart','line_number':3735,'multiline':False]
['text':' globalRankStride','line_number':3736,'multiline':False]
['text':' worldSize','line_number':3737,'multiline':False]
['text':' unused ','line_number':3757,'multiline':True]
['text':' @lint-ignore CLANGTIDY','line_number':3760,'multiline':False]
['text':' seq + 1 to match collective','line_number':3764,'multiline':False]
['text':' inputTensors','line_number':3766,'multiline':False]
['text':' outputTensors','line_number':3767,'multiline':False]
['text':' src rank','line_number':3768,'multiline':False]
['text':' colName','line_number':3769,'multiline':False]
['text':' inNelems','line_number':3770,'multiline':False]
['text':' outNelems','line_number':3771,'multiline':False]
['text':' dType','line_number':3772,'multiline':False]
['text':' inSplitSizes','line_number':3773,'multiline':False]
['text':' outSplitSizes','line_number':3774,'multiline':False]
['text':' globalRankStart','line_number':3775,'multiline':False]
['text':' globalRankStride','line_number':3776,'multiline':False]
['text':' worldSize','line_number':3777,'multiline':False]
['text':' unused ','line_number':3795,'multiline':True]
['text':' unused ','line_number':3796,'multiline':True]
['text':' unused ','line_number':3797,'multiline':True]
['text':' unused ','line_number':3798,'multiline':True]
['text':' unused ','line_number':3799,'multiline':True]
['text':' unused ','line_number':3806,'multiline':True]
['text':' unused ','line_number':3807,'multiline':True]
['text':' unused ','line_number':3808,'multiline':True]
['text':' unused ','line_number':3815,'multiline':True]
['text':' unused ','line_number':3816,'multiline':True]
['text':' unused ','line_number':3817,'multiline':True]
['text':' unused ','line_number':3824,'multiline':True]
['text':' unused ','line_number':3825,'multiline':True]
['text':' unused ','line_number':3826,'multiline':True]
['text':' @lint-ignore CLANGTIDY','line_number':3890,'multiline':False]
['text':' if not in the root rank, initialize outputs as empty list','line_number':3914,'multiline':False]
['text':' append a empty tensor to the list, we don't use it but the','line_number':3919,'multiline':False]
['text':' `collective` template function requires it to invoke its function','line_number':3920,'multiline':False]
['text':' seq + 1 to match collective','line_number':3926,'multiline':False]
['text':' inputTensors','line_number':3928,'multiline':False]
['text':' outputTensors','line_number':3929,'multiline':False]
['text':' root rank','line_number':3930,'multiline':False]
['text':' colName','line_number':3931,'multiline':False]
['text':' inNelems','line_number':3932,'multiline':False]
['text':' outNelems','line_number':3933,'multiline':False]
['text':' dType','line_number':3934,'multiline':False]
['text':' inSplitSizes','line_number':3935,'multiline':False]
['text':' outSplitSize','line_number':3936,'multiline':False]
['text':' globalRankStart','line_number':3937,'multiline':False]
['text':' globalRankStride','line_number':3938,'multiline':False]
['text':' worldSize','line_number':3939,'multiline':False]
['text':' avoidRecordStreams_ note: collective() will stash inputTensors and','line_number':3941,'multiline':False]
['text':' outputs, which == outputTensors[0] on the root rank where it matters.','line_number':3942,'multiline':False]
['text':' unused ','line_number':3946,'multiline':True]
['text':' unused ','line_number':3947,'multiline':True]
['text':' @lint-ignore CLANGTIDY','line_number':3978,'multiline':False]
['text':' if not in the root rank, initialize inputTensors as empty place holder','line_number':4002,'multiline':False]
['text':' with an empty list','line_number':4003,'multiline':False]
['text':' append a empty tensor to the list, we don't use it but the','line_number':4008,'multiline':False]
['text':' `collective` template function requires it to invoke its function','line_number':4009,'multiline':False]
['text':' seq + 1 to match collective','line_number':4015,'multiline':False]
['text':' inputTensors','line_number':4017,'multiline':False]
['text':' outputTensors','line_number':4018,'multiline':False]
['text':' root rank','line_number':4019,'multiline':False]
['text':' colName','line_number':4020,'multiline':False]
['text':' inNelems','line_number':4021,'multiline':False]
['text':' outNelems','line_number':4022,'multiline':False]
['text':' dType','line_number':4023,'multiline':False]
['text':' inSplitSizes','line_number':4024,'multiline':False]
['text':' outSplitSize','line_number':4025,'multiline':False]
['text':' globalRankStart','line_number':4026,'multiline':False]
['text':' globalRankStride','line_number':4027,'multiline':False]
['text':' worldSize','line_number':4028,'multiline':False]
['text':' avoidRecordStreams_ note: collective() will stash outputTensors and','line_number':4030,'multiline':False]
['text':' inputs, which == inputTensors[0] on the root rank where it matters.','line_number':4031,'multiline':False]
['text':' unused ','line_number':4037,'multiline':True]
['text':' unused ','line_number':4038,'multiline':True]
['text':' unused ','line_number':4060,'multiline':True]
['text':' unused ','line_number':4061,'multiline':True]
['text':' @lint-ignore CLANGTIDY','line_number':4084,'multiline':False]
['text':' seq + 1 to match collective','line_number':4088,'multiline':False]
['text':' inputTensors','line_number':4090,'multiline':False]
['text':' outputTensors','line_number':4091,'multiline':False]
['text':' rank','line_number':4092,'multiline':False]
['text':' colName','line_number':4093,'multiline':False]
['text':' inNelems','line_number':4094,'multiline':False]
['text':' outNelems','line_number':4095,'multiline':False]
['text':' dType','line_number':4096,'multiline':False]
['text':' inSplitSizes','line_number':4097,'multiline':False]
['text':' outSplitSize','line_number':4098,'multiline':False]
['text':' globalRankStart','line_number':4099,'multiline':False]
['text':' globalRankStride','line_number':4100,'multiline':False]
['text':' worldSize','line_number':4101,'multiline':False]
['text':' just a wrapper to fit the collective interface','line_number':4103,'multiline':False]
['text':' avoidRecordStreams_ note: collective() will stash inputs and outputs.','line_number':4107,'multiline':False]
['text':' Note 2: for asyncOp = false, we don't want to record streams because we','line_number':4108,'multiline':False]
['text':' know that the NCCL stream will join back to the "current" stream right','line_number':4109,'multiline':False]
['text':' after this op. So we might just as well keep the stream ownership of the','line_number':4110,'multiline':False]
['text':' input/output tensors unchanged. The benefit would be that the','line_number':4111,'multiline':False]
['text':' allocation/free of the tensors would look deterministic to the "current"','line_number':4112,'multiline':False]
['text':' stream so that the caching allocator can reuse memory pool for this stream','line_number':4113,'multiline':False]
['text':' in a clever way. This setting is added for libraries like FSDP which uses','line_number':4114,'multiline':False]
['text':' `all_gather_into_tensor`.','line_number':4115,'multiline':False]
['text':' namespace c10d','line_number':4142,'multiline':False]
['text':' USE_C10D_NCCL','line_number':4144,'multiline':False]
