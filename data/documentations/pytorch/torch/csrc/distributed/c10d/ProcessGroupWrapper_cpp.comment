['text':' A container for information about a particular collective, including optype','line_number':21,'multiline':False]
['text':' and input tensors (if applicable.)','line_number':22,'multiline':False]
['text':' Current collective's operation type.','line_number':24,'multiline':False]
['text':' Number of input tensors','line_number':26,'multiline':False]
['text':' input tensor data types','line_number':28,'multiline':False]
['text':' input tensor device types','line_number':30,'multiline':False]
['text':' input tensor sizes','line_number':32,'multiline':False]
['text':' Constructor for the data received from deserialized fingerprint','line_number':53,'multiline':False]
['text':' Logs collective information in case of a failure.','line_number':68,'multiline':False]
['text':' Executes and verifies the collective fingerprint.','line_number':73,'multiline':False]
['text':' First verify tensor shapes. This is needed because if e.g. tensor dim','line_number':77,'multiline':False]
['text':' does not match across processes, directly verifying tensors will result','line_number':78,'multiline':False]
['text':' in a crash during allgather, but we'd actually like to report a','line_number':79,'multiline':False]
['text':' description about the inconsistency. Since the input is just a 1D tensor','line_number':80,'multiline':False]
['text':' the shape will be a single int k_i and we need to make sure k_i is','line_number':81,'multiline':False]
['text':' consistent across the whole world.','line_number':82,'multiline':False]
['text':' Now verify consistency for the actual tensor.','line_number':85,'multiline':False]
['text':' Takes a serialized fingerprint from','line_number':89,'multiline':False]
['text':' CollectiveFingerPrint::serialize_fingerprint and deserializes it back to a','line_number':90,'multiline':False]
['text':' CollectiveFingerPrint struct','line_number':91,'multiline':False]
['text':' 1. OpType','line_number':99,'multiline':False]
['text':' 2. Num tensors','line_number':106,'multiline':False]
['text':' 3. Tensor dtypes','line_number':113,'multiline':False]
['text':' 4. Device types','line_number':118,'multiline':False]
['text':' 5. Tensor shapes','line_number':123,'multiline':False]
['text':' 5a. Shape size','line_number':125,'multiline':False]
['text':' 5b. Shape','line_number':128,'multiline':False]
['text':' Create output tensor data structure to pass into allgather.','line_number':146,'multiline':False]
['text':' output tensors: [<tensor 0 outputs>, <tensor 1 outputs>, ..., <tensor n','line_number':148,'multiline':False]
['text':' outputs>]','line_number':149,'multiline':False]
['text':' Each rank has its own outputs shape, e.g.','line_number':152,'multiline':False]
['text':' <tensor 0 outputs>: [<rank 0 tensor>, <rank 1 tensor>, ..., <rank n','line_number':153,'multiline':False]
['text':' tensor>]','line_number':154,'multiline':False]
['text':' Suppress unused variable warning','line_number':158,'multiline':False]
['text':' Allgather tensor shapes.','line_number':163,'multiline':False]
['text':' Verify equivalence','line_number':165,'multiline':False]
['text':' Computes the difference between two collectives (seq num, tensor shapes,','line_number':228,'multiline':False]
['text':' collective type, etc) for easier understanding of how mismatched','line_number':229,'multiline':False]
['text':' collectives across ranks differ.','line_number':230,'multiline':False]
['text':' Check seq_num','line_number':234,'multiline':False]
['text':' Check op type','line_number':243,'multiline':False]
['text':' check tensor sizes','line_number':269,'multiline':False]
['text':' check tensor dtypes','line_number':274,'multiline':False]
['text':' check tensor devices','line_number':279,'multiline':False]
['text':' Serializes the information (op type, input shapes, data types, device','line_number':291,'multiline':False]
['text':' types) about the collective fingerprint into a tensor','line_number':292,'multiline':False]
['text':' std::vector<int64_t> data;','line_number':295,'multiline':False]
['text':' 1. OpType','line_number':296,'multiline':False]
['text':' sequence number','line_number':298,'multiline':False]
['text':' 2. Num tensors','line_number':300,'multiline':False]
['text':' 3. Tensor dtypes','line_number':302,'multiline':False]
['text':' 4. Device types','line_number':306,'multiline':False]
['text':' 5. Shapes','line_number':310,'multiline':False]
['text':' Serialize data into tensor','line_number':317,'multiline':False]
['text':' Need to release here and get the ptr due to C++ parameter evaluation','line_number':319,'multiline':False]
['text':' order.','line_number':320,'multiline':False]
['text':' Convert dtype and device type info to string.','line_number':341,'multiline':False]
['text':' namespace','line_number':383,'multiline':False]
['text':' Set the sequence number for the underlying process group.','line_number':391,'multiline':False]
['text':' NOTE: We don't enforce shape checking for allreduce_coalesced because','line_number':416,'multiline':False]
['text':' the implementation itself does not enforce it we have tests that use','line_number':417,'multiline':False]
['text':' inconsistent shapes, see python implementation in distributed_c10d for','line_number':418,'multiline':False]
['text':' details.','line_number':419,'multiline':False]
['text':' NOTE: We don't enforce shape checking for allgather_coalesced because','line_number':456,'multiline':False]
['text':' the implementation itself does not enforce it we have tests that use','line_number':457,'multiline':False]
['text':' inconsistent shapes, see python implementation in distributed_c10d for','line_number':458,'multiline':False]
['text':' details.','line_number':459,'multiline':False]
['text':' alltoall supports uneven split, so don't enforce shape checking.','line_number':498,'multiline':False]
['text':' alltoall supports uneven split, so don't enforce shape checking.','line_number':508,'multiline':False]
['text':' Set underlying pg's sequence number if it is not set.','line_number':520,'multiline':False]
['text':' Set the sequence number for the underlying process group.','line_number':522,'multiline':False]
['text':' first perform a monitored barrier to ensure all ranks can synchronize.','line_number':581,'multiline':False]
['text':' TODO: we should use wrapped backend_'s timeout here, but C++ ProcessGroup','line_number':583,'multiline':False]
['text':' API does not expose timeout.','line_number':584,'multiline':False]
['text':' waitAllRanks ','line_number':590,'multiline':True]
['text':' Attach collective info to the exception and re-raise.','line_number':592,'multiline':False]
['text':' Will throw if an ill-formed collective is detected.','line_number':603,'multiline':False]
['text':' namespace c10d','line_number':607,'multiline':False]
['text':' USE_C10D_GLOO','line_number':609,'multiline':False]
