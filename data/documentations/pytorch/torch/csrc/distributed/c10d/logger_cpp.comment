['text':' Logs runtime stats to configured destination. Note that since data collection','line_number':23,'multiline':False]
['text':' only runs every ddp_runtime_logging_sample_rate iterations, the actual','line_number':24,'multiline':False]
['text':' training iterations recorded will be like 10,','line_number':25,'multiline':False]
['text':' (20-10) * ddp_runtime_logging_sample_rate,','line_number':26,'multiline':False]
['text':' (50-10) * ddp_runtime_logging_sample_rate and so on.','line_number':27,'multiline':False]
['text':' NOLINT','line_number':28,'multiline':False]
['text':' It is useful to report the iteration that training finished at.','line_number':69,'multiline':False]
['text':' Environment variables','line_number':75,'multiline':False]
['text':' The number of parameter tensors','line_number':117,'multiline':False]
['text':' Total parameters size (Bytes)','line_number':120,'multiline':False]
['text':' Parameters' data types, there may be multiple data','line_number':122,'multiline':False]
['text':' types for mixed precision training.','line_number':123,'multiline':False]
['text':' Communication hook. Empty string if not set, in which case it will not be','line_number':156,'multiline':False]
['text':' logged.','line_number':157,'multiline':False]
['text':' Whether we are running under model.join() context manager for DDP uneven','line_number':162,'multiline':False]
['text':' inputs.','line_number':163,'multiline':False]
['text':' Data that can be got during DistributedDataParallel construction time','line_number':172,'multiline':False]
['text':' No lock is needed, as it will be called in DistributedDataParallel','line_number':180,'multiline':False]
['text':' constructor.','line_number':181,'multiline':False]
['text':' In which iteration of the training loop the get_ddp_logging_data()','line_number':189,'multiline':False]
['text':' is called to fetch the DDPLoggingData, 0 if the data is fetched','line_number':190,'multiline':False]
['text':' before training loop.','line_number':191,'multiline':False]
['text':' A list of bucket sizes (Bytes) calculated during construction time','line_number':197,'multiline':False]
['text':' DistributedDataParallel constructor input parameters','line_number':202,'multiline':False]
['text':' TODO: should we set this as human-readable time instead of unixtime?','line_number':238,'multiline':False]
['text':' Sync with reducer's data','line_number':273,'multiline':False]
['text':' Set runtime stats at the sampling iterations.','line_number':275,'multiline':False]
['text':' Set ith iteration when the runtime stats are set.','line_number':280,'multiline':False]
['text':' When get_ddp_logging_data() is called, "unused_parameter_size",','line_number':282,'multiline':False]
['text':' "has_rebuilt_buckets" and "rebuilt_bucket_sizes" are updated in the latest','line_number':283,'multiline':False]
['text':' sampling iteration.','line_number':284,'multiline':False]
['text':' If unused_parameters_ is not empty, calculate its sizes.','line_number':285,'multiline':False]
['text':' unused_parameters_ is calculated in forward call of','line_number':286,'multiline':False]
['text':' each iteration.','line_number':287,'multiline':False]
['text':' No unused params in this iteration','line_number':290,'multiline':False]
['text':' rebuilt_bucket_sizes will not change once buckets are rebuilt,','line_number':298,'multiline':False]
['text':' so it only needs to set once during whole training loop.','line_number':299,'multiline':False]
['text':' Rebuild buckets stats after 1st iteration','line_number':300,'multiline':False]
['text':' Log per-bucket variable indices','line_number':307,'multiline':False]
['text':' Log gradient ready order','line_number':317,'multiline':False]
['text':' Note that the indices are for the previous iteration as','line_number':319,'multiline':False]
['text':' this function is called in forward pass, and we last computed gradient','line_number':320,'multiline':False]
['text':' ready order in the last backward pass.','line_number':321,'multiline':False]
['text':' Cuda time stats are only collected for single device modules.','line_number':328,'multiline':False]
['text':' Log runtime stats to stderr if TORCH_DISTRIBUTED_DEBUG=DETAIL is enabled.','line_number':390,'multiline':False]
['text':' Log runtime (e.g. avg performance) stats at the beginning and also','line_number':395,'multiline':False]
['text':' after a larger number of iterations. Choosing 10/1000/10000 is','line_number':396,'multiline':False]
['text':' not scientific here, it assumes most of applications will run','line_number':397,'multiline':False]
['text':' at least 10 iterations. stats could have smaller variance if','line_number':398,'multiline':False]
['text':' selected num_iterations_ is larger.','line_number':399,'multiline':False]
['text':' namespace c10d','line_number':413,'multiline':False]
