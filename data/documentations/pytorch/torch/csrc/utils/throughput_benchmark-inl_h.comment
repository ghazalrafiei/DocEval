['text':' We pre-generate inputs here for each of the threads. This allows us to','line_number':27,'multiline':False]
['text':' safely move inputs out for each of the threads independently and thus avoid','line_number':28,'multiline':False]
['text':' overhead from the benchmark runner itself','line_number':29,'multiline':False]
['text':' Just in case we generate num_iters inputs for each of the threads','line_number':42,'multiline':False]
['text':' This was if one thread does all the work we will be fine','line_number':43,'multiline':False]
['text':' TODO: add GUARDED_BY once it is available','line_number':55,'multiline':False]
['text':' We use conditional variable as a barrier to make sure each thread','line_number':65,'multiline':False]
['text':' performs required warmeup iterations before we start measuring','line_number':66,'multiline':False]
['text':' NOLINTNEXTLINE(bugprone-infinite-loop)','line_number':76,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)','line_number':130,'multiline':False]
['text':' We use config.num_iters instead of num_attempted_iters as it is','line_number':135,'multiline':False]
['text':' repsesatative of the real work done. Last attempted iteration on each','line_number':136,'multiline':False]
['text':' calling threads doesn't represent the real work (i.e. running the model)','line_number':137,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-narrowing-conversions,bugprone-narrowing-conversions)','line_number':139,'multiline':False]
['text':' namespace detail','line_number':149,'multiline':False]
['text':' namespace throughput_benchmark','line_number':150,'multiline':False]
['text':' namespace torch','line_number':151,'multiline':False]
