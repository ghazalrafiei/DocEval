['text':'=true','line_number':15,'multiline':True]
['text':' No-op stubs.','line_number':37,'multiline':False]
['text':' namespace utils','line_number':43,'multiline':False]
['text':' namespace torch','line_number':44,'multiline':False]
['text':' Try to get exception message, print warning and return false','line_number':69,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':71,'multiline':False]
['text':' shape and stride conversion from int64_t to npy_intp','line_number':90,'multiline':False]
['text':' shape and stride conversion from npy_intp to int64_t','line_number':100,'multiline':False]
['text':'=false','line_number':126,'multiline':True]
['text':' NumPy strides use bytes. Torch strides use element counts.','line_number':170,'multiline':False]
['text':' TODO: This attempts to keep the underlying memory alive by setting the base','line_number':189,'multiline':False]
['text':' object of the ndarray to the tensor and disabling resizes on the storage.','line_number':190,'multiline':False]
['text':' This is not sufficient. For example, the tensor's storage may be changed','line_number':191,'multiline':False]
['text':' via Tensor.set_, which can free the underlying memory.','line_number':192,'multiline':False]
['text':' Use the private storage API','line_number':199,'multiline':False]
['text':'=true','line_number':217,'multiline':True]
['text':' warn_if_not_writable is true when a copy of numpy variable is created.','line_number':226,'multiline':False]
['text':' the warning is suppressed when a copy is being created.','line_number':227,'multiline':False]
['text':' NumPy strides use bytes. Torch strides use element counts.','line_number':235,'multiline':False]
['text':' Workaround: MSVC does not support two switch cases that have the same','line_number':324,'multiline':False]
['text':' value','line_number':325,'multiline':False]
['text':' To cover all cases we must use NPY_INT because','line_number':327,'multiline':False]
['text':' NPY_INT32 is an alias which maybe equal to:','line_number':328,'multiline':False]
['text':' - NPY_INT, when sizeof(int) = 4 and sizeof(long) = 8','line_number':329,'multiline':False]
['text':' - NPY_LONG, when sizeof(int) = 4 and sizeof(long) = 4','line_number':330,'multiline':False]
['text':' NPY_INT64 is an alias which maybe equal to:','line_number':333,'multiline':False]
['text':' - NPY_LONG, when sizeof(long) = 8 and sizeof(long long) = 8','line_number':334,'multiline':False]
['text':' - NPY_LONGLONG, when sizeof(long) = 4 and sizeof(long long) = 8','line_number':335,'multiline':False]
['text':' break as if this is one of the cases above because this is','line_number':338,'multiline':False]
['text':' only a workaround','line_number':339,'multiline':False]
['text':' Extract the `obj.__cuda_array_interface__['shape']` attribute','line_number':378,'multiline':False]
['text':' Extract the `obj.__cuda_array_interface__['typestr']` attribute','line_number':388,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':389,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':391,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':398,'multiline':False]
['text':' Extract the `obj.__cuda_array_interface__['data']` attribute','line_number':408,'multiline':False]
['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':409,'multiline':False]
['text':' Extract the `obj.__cuda_array_interface__['strides']` attribute','line_number':433,'multiline':False]
['text':' __cuda_array_interface__ strides use bytes. Torch strides use element','line_number':445,'multiline':False]
['text':' counts.','line_number':446,'multiline':False]
['text':' Mutated only once (during module init); behaves as an immutable variable','line_number':472,'multiline':False]
['text':' thereafter.','line_number':473,'multiline':False]
['text':' NumPy implemented support for Dlpack capsules in version 1.22.0. However, the','line_number':476,'multiline':False]
['text':' initial implementation did not correctly handle the invocation of','line_number':477,'multiline':False]
['text':' `DLManagedTensor::deleter` in a no-GIL context. Until PyTorch 1.13.0, we','line_number':478,'multiline':False]
['text':' were implicitly holding the GIL when the deleter was invoked, but this','line_number':479,'multiline':False]
['text':' incurred a significant performance overhead when mem-unmapping large tensors.','line_number':480,'multiline':False]
['text':' Starting with PyTorch 1.13.0, we release the GIL in `THPVariable_clear` just','line_number':481,'multiline':False]
['text':' before deallocation, but this triggers the aforementioned bug in NumPy.','line_number':482,'multiline':False]
['text':'','line_number':483,'multiline':False]
['text':' The NumPy bug should be fixed in version 1.24.0, but all releases','line_number':484,'multiline':False]
['text':' between 1.22.0 and 1.23.5 result in internal assertion failures that','line_number':485,'multiline':False]
['text':' consequently lead to segfaults. To work around this, we need to selectively','line_number':486,'multiline':False]
['text':' disable the optimization whenever we detect a buggy NumPy installation.','line_number':487,'multiline':False]
['text':' We would ideally restrict the "fix" just to Dlpack-backed tensors that stem','line_number':488,'multiline':False]
['text':' from NumPy, but given that it is difficult to confidently detect the','line_number':489,'multiline':False]
['text':' provenance of such tensors, we have to resort to a more general approach.','line_number':490,'multiline':False]
['text':'','line_number':491,'multiline':False]
['text':' References:','line_number':492,'multiline':False]
['text':'  https://github.com/pytorch/pytorch/issues/88082','line_number':493,'multiline':False]
['text':'  https://github.com/pytorch/pytorch/issues/77139','line_number':494,'multiline':False]
['text':'  https://github.com/numpy/numpy/issues/22507','line_number':495,'multiline':False]
['text':' Ensure that we don't call this more than once per session.','line_number':497,'multiline':False]
['text':' namespace utils','line_number':533,'multiline':False]
['text':' namespace torch','line_number':534,'multiline':False]
['text':' USE_NUMPY','line_number':536,'multiline':False]
