['text':' Pack pairs of int4 values into int8, in row major order; first int4','line_number':4,'multiline':False]
['text':' value goes into lower order bits, and second int4 value into higher','line_number':5,'multiline':False]
['text':' order bits of resulting int8 value.','line_number':6,'multiline':False]
['text':' Unpack quandruples of bits in int8 values into int4 values, in row','line_number':14,'multiline':False]
['text':' major order; lower 4 bits go into first int4 value goes, and upper 4','line_number':15,'multiline':False]
['text':' bits go into second int4 value.','line_number':16,'multiline':False]
['text':' Transpose the weight matrix, and then reorder its elements according','line_number':25,'multiline':False]
['text':' to underlying requirements of CUTLASS library, so that it could be','line_number':26,'multiline':False]
['text':' used for CUTLASS-based mixed datatypes linear operation.','line_number':27,'multiline':False]
['text':' subbyte_transpose','line_number':38,'multiline':False]
['text':' permute_B_rows_for_mixed_gemm','line_number':51,'multiline':False]
['text':' (permute cols actually, as transpose is applied first here)','line_number':52,'multiline':False]
['text':' interleave_column_major_tensor','line_number':75,'multiline':False]
['text':' add_bias_and_interleave_quantized_tensor_inplace','line_number':108,'multiline':False]
