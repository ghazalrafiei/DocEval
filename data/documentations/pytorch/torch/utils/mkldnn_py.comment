['text':' Bias can be fp32 or bf16 for OneDNN bf16 path, but for good accuracy,','line_number':9,'multiline':False]
['text':' we use fp32 dtype.','line_number':10,'multiline':False]
['text':' TODO: Remove this once ScriptModule supports registering None buffer','line_number':13,'multiline':False]
['text':' Bias can be fp32 or bf16 for OneDNN bf16 path, but for good accuracy,','line_number':52,'multiline':False]
['text':' we use fp32 dtype.','line_number':53,'multiline':False]
['text':' TODO: Remove this once ScriptModule supports registering None buffer','line_number':54,'multiline':False]
['text':' training','line_number':178,'multiline':False]
['text':' cuda_enabled','line_number':181,'multiline':False]
['text':' For batchnorm bf16 path, OneDNN requires weight and bias need fp32 dtype.','line_number':219,'multiline':False]
['text':' so it doesn't need dtype argument.','line_number':220,'multiline':False]
