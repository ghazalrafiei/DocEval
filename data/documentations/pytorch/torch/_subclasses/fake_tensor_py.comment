['text':' Small helper that increments recursion count, and','line_number':57,'multiline':False]
['text':' resets it when the object goes out of scope.  Useful','line_number':58,'multiline':False]
['text':' if you don't want to increase indentation which is','line_number':59,'multiline':False]
['text':' what a context manager would do.','line_number':60,'multiline':False]
['text':' this op is never actually used','line_number':105,'multiline':False]
['text':' This function indicates if the backend device','line_number':109,'multiline':False]
['text':' supports non-contiguous tensors','line_number':110,'multiline':False]
['text':' TODO: no real reason to restrict multiple outputs','line_number':170,'multiline':False]
['text':' need to recurse because we could have nested subclasses','line_number':182,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':214,'multiline':False]
['text':' many of the decompositions registered to torch/_prims do not at the moment model','line_number':217,'multiline':False]
['text':' aliasing or strides, so as an incremental step, just enable the decompositions in','line_number':218,'multiline':False]
['text':' torch/_decomp/decompositions.py.','line_number':219,'multiline':False]
['text':' decomps are used for aot autograd tracing so we would like to unify on their','line_number':220,'multiline':False]
['text':' implementation and add additional testing to them','line_number':221,'multiline':False]
['text':' Similar to `MetaConverter`, this is a class for converting','line_number':236,'multiline':False]
['text':' multiple tensors into fake tensors which share the same view/storage','line_number':237,'multiline':False]
['text':' structure. Like `MetaConverter`, it uses `WeakIdRef` to','line_number':238,'multiline':False]
['text':' hold a weak reference for all memoized tensors.','line_number':239,'multiline':False]
['text':' map from to storage to corresponding constant tensors','line_number':251,'multiline':False]
['text':' when you have a constant, aliased tensor:','line_number':255,'multiline':False]
['text':' const_tensor.add_(torch.rand([1]))','line_number':256,'multiline':False]
['text':' all aliases of it must become no longer const','line_number':257,'multiline':False]
['text':' we need a map from a weak storage to all of its corresponding','line_number':261,'multiline':False]
['text':' constant tensors. python doesn't have the weak value equivalent','line_number':262,'multiline':False]
['text':' of defaultdict(list), so we are using a WeakValueDictionary as one','line_number':263,'multiline':False]
['text':' hold a weak ref to self, otherwise it will be kept alive','line_number':293,'multiline':False]
['text':' by the del_ten closure','line_number':294,'multiline':False]
['text':' on shutdown, th may not be in memo','line_number':301,'multiline':False]
['text':' see note [Tensor Fakification and Symbol Caching]','line_number':318,'multiline':False]
['text':' not yet supported in metatensors','line_number':331,'multiline':False]
['text':' NB: don't use in_kernel_invocation_manager. to','line_number':338,'multiline':False]
['text':' ensure FakeTensor can internally do constant computation','line_number':339,'multiline':False]
['text':' as necessary.  Invocation manager is "more correct" as','line_number':340,'multiline':False]
['text':' it works for more operators in make_meta_t, but','line_number':341,'multiline':False]
['text':' invariant is that make_meta_t only calls factories','line_number':342,'multiline':False]
['text':' for which it is not strictly necessary to use the','line_number':343,'multiline':False]
['text':' invocation manager (I think!)','line_number':344,'multiline':False]
['text':' NB: meta_converter set the memo','line_number':364,'multiline':False]
['text':' If you specify the device, it MUST be a meta tensor.','line_number':367,'multiline':False]
['text':' You can have a real tensor that you need to convert into a fake tensor.','line_number':379,'multiline':False]
['text':' If you have a meta tensor already, call from_meta_and_device.','line_number':380,'multiline':False]
['text':'','line_number':381,'multiline':False]
['text':' You're allowed to pass a meta tensor to be turned into a fake','line_number':382,'multiline':False]
['text':' tensor; although an odd thing to do, this can occur if you're doing','line_number':383,'multiline':False]
['text':' cross ref testing and the inner test is already operating on meta tensors.','line_number':384,'multiline':False]
['text':' TODO: file issue','line_number':433,'multiline':False]
['text':' cpu is default device if none is specified','line_number':436,'multiline':False]
['text':' _like constructors have fake tensor inputs (maybe this causes the non-like','line_number':442,'multiline':False]
['text':' to fail? hmmm)','line_number':443,'multiline':False]
['text':' TODO: I think this does the wrong thing if r is inp','line_number':460,'multiline':False]
['text':' These operators have meta implementations with incorrect strides','line_number':478,'multiline':False]
['text':' This is a workaround for meta implmentations with incorrect strides','line_number':481,'multiline':False]
['text':' For static shapes, we can fall back to eager for the real strides','line_number':490,'multiline':False]
['text':' Dont default to default device handling,','line_number':502,'multiline':False]
['text':' since the device of `the_template` is ignored','line_number':503,'multiline':False]
['text':' TODO: remove me','line_number':512,'multiline':False]
['text':' index.Tensor data-dependent in only some conditions','line_number':516,'multiline':False]
['text':' Avoid importing sympy at a module level','line_number':537,'multiline':False]
['text':' TODO: consider a memo','line_number':541,'multiline':False]
['text':' Without symints/symfloats, cannot handle this','line_number':548,'multiline':False]
['text':' Without symints/symfloats, cannot handle this','line_number':566,'multiline':False]
['text':' This is unsound, but it works well in practice','line_number':572,'multiline':False]
['text':' See https://docs.google.com/document/d/1lFRYAJo5nrfxRhwIzGnfi2pbLpU6T4ytSRSuLJ5qebI/edit#','line_number':573,'multiline':False]
['text':' TODO: Add a config knob to turn off this unsound behavior','line_number':574,'multiline':False]
['text':'','line_number':575,'multiline':False]
['text':' NB: If numel < 2, the bounds here might be COMPLETELY','line_number':576,'multiline':False]
['text':' disjoint with what can actually occur.  But this is fine:','line_number':577,'multiline':False]
['text':' remember, the hypothesis is that if your later code works','line_number':578,'multiline':False]
['text':' with N >= 2, it will work with N = 1 and N = 0.','line_number':579,'multiline':False]
['text':' Avoid importing sympy at a module level','line_number':582,'multiline':False]
['text':' Don't upgrade the range if numel is less than two, since we then','line_number':589,'multiline':False]
['text':' have an empty range which makes things go explodey.  We also','line_number':590,'multiline':False]
['text':' don't allow for 2 because that would specialize the unbacked','line_number':591,'multiline':False]
['text':' SymInt to 2, which is also likely to be buggy.','line_number':592,'multiline':False]
['text':' Without symints/symfloats, cannot handle this','line_number':610,'multiline':False]
['text':' see nonzero for commentary','line_number':615,'multiline':False]
['text':' Avoid importing sympy at a module level','line_number':618,'multiline':False]
['text':' NB: this must be ordered after local_scalar_dense','line_number':633,'multiline':False]
['text':' Bool Indices get Expanded as Masks','line_number':639,'multiline':False]
['text':' See: IndexingUtils.h:expandTensors','line_number':640,'multiline':False]
['text':' copy_','line_number':659,'multiline':False]
['text':' Dont default to default device handling,','line_number':663,'multiline':False]
['text':' Since op can take in non-zero sized cpu','line_number':664,'multiline':False]
['text':' index tensors with cuda self','line_number':665,'multiline':False]
['text':' ensure nonzero call goes to fake tensor','line_number':675,'multiline':False]
['text':' Can take mixed meta/non-meta arguments; the meta registration','line_number':681,'multiline':False]
['text':' will roughly do the right thing even when given real devices','line_number':682,'multiline':False]
['text':' takes in multiple-devices, dont default to default device handling','line_number':691,'multiline':False]
['text':' same with multi_device_op_default, but return the input','line_number':700,'multiline':False]
['text':' need to re-enable mode so the tensors report fake device','line_number':748,'multiline':False]
['text':' if the input is unsqueezed is done in Convolution.cpp we get segfault','line_number':750,'multiline':False]
['text':' Avoid importing sympy at a module level','line_number':754,'multiline':False]
['text':' TODO: We can make this a little more faithful with best effort','line_number':758,'multiline':False]
['text':' channels last detection (but only if it's statically obvious!)','line_number':759,'multiline':False]
['text':' Unlike register_op_impl, these don't do the slow iteration for','line_number':806,'multiline':False]
['text':' run_impl_check, and these run BEFORE decompositions','line_number':807,'multiline':False]
['text':' infer_size_impl in ExpandUtils','line_number':816,'multiline':False]
['text':' NB: It is very important to test for broadcasting, before testing','line_number':829,'multiline':False]
['text':' sizeA == sizeB.  This is because the broadcasting tests are likely','line_number':830,'multiline':False]
['text':' to be statically known (in particular, if sizeA/sizeB is unbacked','line_number':831,'multiline':False]
['text':' but size-like, we will unsoundly assume they never equal 1), but','line_number':832,'multiline':False]
['text':' the sizeA == sizeB test may not be statically known.  However, once','line_number':833,'multiline':False]
['text':' we have established that no broadcasting is happening, the','line_number':834,'multiline':False]
['text':' sizeA == sizeB is now expect_true and we can defer it as a runtime','line_number':835,'multiline':False]
['text':' assert (this works because Python will return the terminal','line_number':836,'multiline':False]
['text':' expression of an or statement as-is, without bool()'ing it; if this','line_number':837,'multiline':False]
['text':' were not the case, we'd need to write this using torch.sym_or() or','line_number':838,'multiline':False]
['text':' something like that).','line_number':839,'multiline':False]
['text':' Fast path (based off of TensorIterator fast path).','line_number':859,'multiline':False]
['text':' Unfortunately, there is no way to easily deduplicate','line_number':860,'multiline':False]
['text':' this with either the TensorIterator C++ implementation','line_number':861,'multiline':False]
['text':' (which we don't want to SymIntify, and also the algorithm','line_number':862,'multiline':False]
['text':' here is slightly different from TensorIterator to allow','line_number':863,'multiline':False]
['text':' for broadcasting), nor the PrimTorch implementation','line_number':864,'multiline':False]
['text':' (which does not actually implement a fast path.)','line_number':865,'multiline':False]
['text':' compute_shape','line_number':869,'multiline':False]
['text':' TODO: Minor optimization: track if the shapes','line_number':881,'multiline':False]
['text':' were equal so you can skip the equality check','line_number':882,'multiline':False]
['text':' below if unnecessary','line_number':883,'multiline':False]
['text':' Do some extra safety checks to see if the output','line_number':887,'multiline':False]
['text':' stride is obvious','line_number':888,'multiline':False]
['text':' compute_types','line_number':895,'multiline':False]
['text':' Use elementwise_dtypes for the tricky case','line_number':903,'multiline':False]
['text':' Slightly simplified here as target_dtype cannot vary','line_number':908,'multiline':False]
['text':' compute promotion','line_number':915,'multiline':False]
['text':' TODO: we don't need the compute type','line_number':916,'multiline':False]
['text':' check all tensors on same device','line_number':921,'multiline':False]
['text':' cpu scalars are assumed allow','line_number':922,'multiline':False]
['text':' hard coded atm','line_number':924,'multiline':False]
['text':' compute_fast_setup_type','line_number':935,'multiline':False]
['text':' TODO: is_non-overlapping_and_dense (not bound from Python','line_number':938,'multiline':False]
['text':' no inplace, no out, everything defined','line_number':939,'multiline':False]
['text':' do contiguous','line_number':952,'multiline':False]
['text':' do channels last','line_number':966,'multiline':False]
['text':' type: ignore[has-type]','line_number':993,'multiline':False]
['text':' Backward will error with cuda Fake Tensors if no cuda tensors have been initialized first','line_number':1002,'multiline':False]
['text':' See: note [Fake Tensor Dispatch Keys]','line_number':1011,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':1016,'multiline':False]
['text':' Return if the function allows Python numbers to bind to Tensors','line_number':1027,'multiline':False]
['text':' This memorizes the unbacked SymInt representing the number of nonzero','line_number':1051,'multiline':False]
['text':' elements in this tensor.  This is helpful if you do something like','line_number':1052,'multiline':False]
['text':' x[mask] and y[mask]; mask.nonzero() gets repeatedly called and should','line_number':1053,'multiline':False]
['text':' give a consistent unbacked SymInt.  It needs to be invalidated in the','line_number':1054,'multiline':False]
['text':' same way constant is.','line_number':1055,'multiline':False]
['text':' TODO: Generalize this as needed, e.g., into a trie of memos','line_number':1056,'multiline':False]
['text':' Indicates to our torch_dispatch dispatching infra that','line_number':1060,'multiline':False]
['text':' this is an "infra" mode with lower dispatching precedence.','line_number':1061,'multiline':False]
['text':' Version counter based tracking isn't 100% sound but it's close','line_number':1068,'multiline':False]
['text':' enough','line_number':1069,'multiline':False]
['text':' Note: [Fake Tensor Dispatch Keys]','line_number':1082,'multiline':False]
['text':' In order to model the behavior of device-specific autocast','line_number':1083,'multiline':False]
['text':' and autograd logic, we update the dispatch keys of FakeTensors','line_number':1084,'multiline':False]
['text':' to reflect their fake device. This includes the BackendComponent','line_number':1085,'multiline':False]
['text':' (DispatchKey::Meta -> DispatchKey::CUDA), and also the BackendComponent','line_number':1086,'multiline':False]
['text':' related Autocast and Autograd keys. __torch__dispatch__ sits below','line_number':1087,'multiline':False]
['text':' Autocast and Autograd, and is only invoked when we are at the','line_number':1088,'multiline':False]
['text':' kernel for the BackendComponent. Then, we add Meta to the','line_number':1089,'multiline':False]
['text':' thread-local dispatch include set to hit the meta kernel','line_number':1090,'multiline':False]
['text':' instead of the kernel of the BackendComponent for the fake device.','line_number':1091,'multiline':False]
['text':' The `device_for_backend_keys` does that below','line_number':1092,'multiline':False]
['text':' NOTE: this probably will not do the right thing for backends','line_number':1093,'multiline':False]
['text':' that have dispatch keys which are higher than the "meta" key:','line_number':1094,'multiline':False]
['text':' https://github.com/pytorch/pytorch/blob/main/c10/core/DispatchKey.h#L189','line_number':1095,'multiline':False]
['text':' NB: it is fine, if a little confusing, for device to be meta','line_number':1109,'multiline':False]
['text':' (we are faking a meta tensor in that case).  However, it often','line_number':1110,'multiline':False]
['text':' indicates some sort of confusion (e.g., you accidentally passed','line_number':1111,'multiline':False]
['text':' in a meta tensor when you should have passed in the real tensor).','line_number':1112,'multiline':False]
['text':' So by default we disallow meta, and if you are working in a situation','line_number':1113,'multiline':False]
['text':' where it is helpful (e.g., crossref testing) you can turn it back','line_number':1114,'multiline':False]
['text':' on','line_number':1115,'multiline':False]
['text':' normalize device.','line_number':1118,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':1130,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':1131,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':1132,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':1133,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':1134,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':1139,'multiline':False]
['text':' In some circumstances, a conventional torch.Tensor constructor','line_number':1142,'multiline':False]
['text':' will get rewritten to call into FakeTensor.  We must provide an','line_number':1143,'multiline':False]
['text':' __init__ method that can accept the Python interpreters initialization','line_number':1144,'multiline':False]
['text':' in such a situation; we must also be able to handle direct fake','line_number':1145,'multiline':False]
['text':' tensor construction via FakeTensor().','line_number':1146,'multiline':False]
['text':'','line_number':1147,'multiline':False]
['text':' In particular, the __init__ call will look funny in the following case:','line_number':1148,'multiline':False]
['text':'','line_number':1149,'multiline':False]
['text':'   with FakeTensorMode():','line_number':1150,'multiline':False]
['text':'       x = torch.Tensor([1, 2, 3])','line_number':1151,'multiline':False]
['text':'','line_number':1152,'multiline':False]
['text':' this desugars into:','line_number':1153,'multiline':False]
['text':'','line_number':1154,'multiline':False]
['text':'   with FakeTensorMode():','line_number':1155,'multiline':False]
['text':'       x = torch.Tensor.__new__([1, 2, 3])','line_number':1156,'multiline':False]
['text':'       # NB: x is a fake tensor, because of the mode!','line_number':1157,'multiline':False]
['text':'       x.__init__([1, 2, 3])  # not the normal fake tensor args!','line_number':1158,'multiline':False]
['text':'','line_number':1159,'multiline':False]
['text':' need to handle here to avoid infinite recursion','line_number':1170,'multiline':False]
['text':' see [in_kernel_invocation]','line_number':1171,'multiline':False]
['text':' Because fake mode can return NotImplemented (if it sees a subclass','line_number':1179,'multiline':False]
['text':' it doesn't know how to deal with), this test here is important','line_number':1180,'multiline':False]
['text':' because the next dispatch after a fake mode will attempt to use','line_number':1181,'multiline':False]
['text':' subclasses of tensors to dispatch, and any FakeTensor arguments','line_number':1182,'multiline':False]
['text':' will be considered eligible.','line_number':1183,'multiline':False]
['text':' If the fake mode is already active, don't try to reapply it!','line_number':1201,'multiline':False]
['text':' NotImplemented is the right thing to return here, because the','line_number':1202,'multiline':False]
['text':' typical situation this can occur is if ProxyTensorMode returned a','line_number':1203,'multiline':False]
['text':' NotImplemented because of a not implemented subclass; we may have','line_number':1204,'multiline':False]
['text':' unluckily attempted to hit FakeTensor's dispatch first,','line_number':1205,'multiline':False]
['text':' NotImplemented lets us keep chaining until we find the actual','line_number':1206,'multiline':False]
['text':' subclass','line_number':1207,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':1219,'multiline':False]
['text':' Returns: (common_device, has_scalar_only_inputs)','line_number':1224,'multiline':False]
['text':' cpu - zero-dim tensors can be called in cuda kernels,','line_number':1226,'multiline':False]
['text':' so overwrite the common_device if it the only existing','line_number':1227,'multiline':False]
['text':' device comes from a cpu zero-dim tensor','line_number':1228,'multiline':False]
['text':' mismatching devices !','line_number':1253,'multiline':False]
['text':' if current tensor is cpu 0 dim, defer to existing device','line_number':1254,'multiline':False]
['text':' current device is from cpu 0 dim tensor, overwrite','line_number':1258,'multiline':False]
['text':' mismatching devices of non-zero dim tensors, throw','line_number':1264,'multiline':False]
['text':' This might be valid behavior and need to be explicitly modeled, e.g. reshape_as','line_number':1265,'multiline':False]
['text':' some functions that allow Python numbers to bind to Tensors','line_number':1273,'multiline':False]
['text':' if we have failed to find a device, and we're running one of these operators,','line_number':1274,'multiline':False]
['text':' we must have scalar only inputs','line_number':1275,'multiline':False]
['text':' ops with scalar only inputs always have result on cpu','line_number':1277,'multiline':False]
['text':' We must handle tolist in a special way for FakeTensors here in the case','line_number':1285,'multiline':False]
['text':' where tolist is called from torch dispatch for tensor subclasses.','line_number':1286,'multiline':False]
['text':' Ordinarily, if a program calls .tolist compiling still works because there is','line_number':1287,'multiline':False]
['text':' special handling in dynamo, but for tensor subclasses if .tolist is called','line_number':1288,'multiline':False]
['text':' inside torch dispatch, the .tolist call may be directly on a FakeTensor.','line_number':1289,'multiline':False]
['text':' This would result in an error since wrapper subclasses don't have storage.','line_number':1290,'multiline':False]
['text':' To avoid this, we handle the FakeTensor case by (1) specializing on the size','line_number':1291,'multiline':False]
['text':' of the tensor to create the output Python list, and (2) creating unbacked','line_number':1292,'multiline':False]
['text':' symints for each element of the list.','line_number':1293,'multiline':False]
['text':' Specialize on the length of the list','line_number':1298,'multiline':False]
['text':' max value?','line_number':1301,'multiline':False]
['text':' We keep one instantiation of `fake_tensor_converter` active','line_number':1309,'multiline':False]
['text':' for the duration of `with FakeTensorMode()`.','line_number':1310,'multiline':False]
['text':' This allows accurate storage aliasing across invocation of','line_number':1311,'multiline':False]
['text':' different operators. While this will keep all freshly allocated','line_number':1312,'multiline':False]
['text':' tensors alive during `FakeTensorMode`, there will no be no','line_number':1313,'multiline':False]
['text':' new allocations of Tensors which have non-meta storage so','line_number':1314,'multiline':False]
['text':' memory should not significantly increase.','line_number':1315,'multiline':False]
['text':' A flag that controls, whether we want to invoke ops on mix of','line_number':1339,'multiline':False]
['text':' real weights/global variables and fake inputs','line_number':1340,'multiline':False]
['text':' [in_kernel_invocation]','line_number':1343,'multiline':False]
['text':' when FakeTensor is invoked in user code, .device should return','line_number':1344,'multiline':False]
['text':' the fake_device of the tensor so that code such as as `if x.is_cuda`','line_number':1345,'multiline':False]
['text':' or torch.zeros([10, 10], device=x.device) continues to execute as if','line_number':1346,'multiline':False]
['text':' the FakeTensor were real. However, within kernel execution, we return','line_number':1347,'multiline':False]
['text':' the `Meta` device because all computation within the kernels should','line_number':1348,'multiline':False]
['text':' behave as if the Tensors are on meta devices. Kernels should allocate','line_number':1349,'multiline':False]
['text':' new tensors on meta devices, and checks like `is_meta` should return true.','line_number':1350,'multiline':False]
['text':' within python refs, we always return the real device by defining','line_number':1351,'multiline':False]
['text':' the device property','line_number':1352,'multiline':False]
['text':' True if we enter'ed and actually enabled fake tensor mode,','line_number':1355,'multiline':False]
['text':' false if it was a no-op.  Not thread safe but neither is','line_number':1356,'multiline':False]
['text':' in_kernel_invocation','line_number':1357,'multiline':False]
['text':' If another fake mode was already active when we enter, we also stash it here.','line_number':1358,'multiline':False]
['text':' That way when we exit, we know to re-enable the previous fake mode.','line_number':1359,'multiline':False]
['text':' Indicates to our torch_dispatch dispatching infra that','line_number':1366,'multiline':False]
['text':' this is an "infra" mode with lower dispatching precedence.','line_number':1367,'multiline':False]
['text':' Typically, there is only one fake tensor mode and you test for it by','line_number':1370,'multiline':False]
['text':' doing an isinstance test.  However, in some situations, there might be','line_number':1371,'multiline':False]
['text':' TWO fake tensor modes.  The canonical example of this is exporting','line_number':1372,'multiline':False]
['text':' a fake model: there is an outer fake mode created by the user, and','line_number':1373,'multiline':False]
['text':' an inner fake mode created by Dynamo.  The two phase process is required','line_number':1374,'multiline':False]
['text':' because the outer fake mode typically won't have a ShapeEnv, even if','line_number':1375,'multiline':False]
['text':' the user is interested in exporting with dynamic shapes (so the inner','line_number':1376,'multiline':False]
['text':' fake mode will actually have a ShapeEnv and swap in symbolic sizes.)','line_number':1377,'multiline':False]
['text':'','line_number':1378,'multiline':False]
['text':' In this case, it's insufficient to test only one FakeTensor: you need','line_number':1379,'multiline':False]
['text':' to distinguish between our fake tensor and other fake tensors.  That's','line_number':1380,'multiline':False]
['text':' what this function does.','line_number':1381,'multiline':False]
['text':' FakeTensorMode should not be set when we're inside of it.','line_number':1387,'multiline':False]
['text':' No-op if FakeTensorMode is already in use','line_number':1397,'multiline':False]
['text':' no-op (still need to re-set the fake mode though since we unset it)','line_number':1404,'multiline':False]
['text':' Re-enable the previous fake mode, if there was one.','line_number':1413,'multiline':False]
['text':' NB: Don't use is_our_fake, just serve the fake information','line_number':1422,'multiline':False]
['text':' as is.  Notice we don't use 'self'; we use args[0].fake_mode','line_number':1423,'multiline':False]
['text':' because they may not be the same.  It would also be possible','line_number':1424,'multiline':False]
['text':' to return NotImplemented here, in which case the FakeTensor','line_number':1425,'multiline':False]
['text':' handler on args[0] would handle it, but we're being nice and','line_number':1426,'multiline':False]
['text':' short-circuiting quickly.','line_number':1427,'multiline':False]
['text':' Some attribute queries that can be serviced directly','line_number':1446,'multiline':False]
['text':' See Note [is_coalesced is dispatched]','line_number':1447,'multiline':False]
['text':' NB: no_dispatch is ok here too, this func is very simple','line_number':1453,'multiline':False]
['text':' To constant propagate through these functions:','line_number':1474,'multiline':False]
['text':' 1, If this is a lift due to a torch.tensor call,','line_number':1475,'multiline':False]
['text':'    the input tensor is guaranteed to be a','line_number':1476,'multiline':False]
['text':'    constant, so we keep a copy of the original argument along so','line_number':1477,'multiline':False]
['text':'    we can query it if we're asked to item() it at some later point.','line_number':1478,'multiline':False]
['text':'    (Note that you can always call a lift fn manually, so we do','line_number':1479,'multiline':False]
['text':'    have to check if there are any fake tensors!)','line_number':1480,'multiline':False]
['text':' 2, Some functions that allow Python numbers to bind to Tensors, e.g, torch.div','line_number':1481,'multiline':False]
['text':' NB: not in_kernel_invocation_manager because we're doing real','line_number':1494,'multiline':False]
['text':' compute here','line_number':1495,'multiline':False]
['text':' NB: no_dispatch() here is VERY DANGEROUS (like, segfault','line_number':1496,'multiline':False]
['text':' dangerous) if this is actually a wrapper subclass tensor,','line_number':1497,'multiline':False]
['text':' therefore the exact type test above','line_number':1498,'multiline':False]
['text':' See [subclass inputs] below','line_number':1503,'multiline':False]
['text':' NB: If you're seeing a mysterious infinite loop involving fake','line_number':1504,'multiline':False]
['text':' tensor, it might be related to this line.  Though I'm not sure','line_number':1505,'multiline':False]
['text':' how you'll know to read this comment, as this line won't show up','line_number':1506,'multiline':False]
['text':' in the stack trace.','line_number':1507,'multiline':False]
['text':' if we are in the dispatch mode, we will enter this function even if the inputs','line_number':1515,'multiline':False]
['text':' are not FakeTensors. For now, throw if any non-Fake Tensor inputs','line_number':1516,'multiline':False]
['text':' and just support constructors.','line_number':1517,'multiline':False]
['text':' this is generated from torch.tensor(), which does not use the','line_number':1519,'multiline':False]
['text':' dispatcher, to allow wrapper subclasses to wrap the new tensor','line_number':1520,'multiline':False]
['text':' Recompute flat_arg_fake_tensors here again in case some of the inputs','line_number':1527,'multiline':False]
['text':' were real tensors and fakified in validate_and_convert_non_fake_tensors','line_number':1528,'multiline':False]
['text':' Invalidated','line_number':1532,'multiline':False]
['text':' The current constant handling only support tracing systems','line_number':1534,'multiline':False]
['text':' (aot autograd, torchdynamo) where each operation is run consecutively.','line_number':1535,'multiline':False]
['text':' Because each operation is run in order, we can trace out and support','line_number':1536,'multiline':False]
['text':' sequences like: x = torch.tensor(0.); y = x.add_(1)','line_number':1537,'multiline':False]
['text':' Whenver a constant is written to but with inputs that cannot be evaluated','line_number':1538,'multiline':False]
['text':' statically, such as random_(), we invalidate all constants that alias the input','line_number':1539,'multiline':False]
['text':' We will rely on functionalization for use of fake tensors constants as persistent','line_number':1540,'multiline':False]
['text':' objects on an FX Graph.','line_number':1541,'multiline':False]
['text':' We dispatch size/stride/numel on the FakeTensor not its constant, so bail on inplace_view','line_number':1543,'multiline':False]
['text':' NB: not in_kernel_invocation_manager(self) as we want to do REAL','line_number':1555,'multiline':False]
['text':' compute','line_number':1556,'multiline':False]
['text':' we weren't able to turn outputs to constants,','line_number':1571,'multiline':False]
['text':' so invalidate all constants that might be aliases of the outputs','line_number':1572,'multiline':False]
['text':' we are falling through to running non constant tensors, any input constant that','line_number':1576,'multiline':False]
['text':' is written to must be invalidated','line_number':1577,'multiline':False]
['text':' Try for fastpath','line_number':1581,'multiline':False]
['text':' If there's a Python meta, prefer that over the decomposition','line_number':1587,'multiline':False]
['text':' Prefer Python decompositions over C++ ones','line_number':1593,'multiline':False]
['text':' TODO: Remove these exclusions, so that we can remove','line_number':1597,'multiline':False]
['text':' this leg entirely','line_number':1598,'multiline':False]
['text':' Decomposes CompositeImplicitAutograd ops','line_number':1607,'multiline':False]
['text':' prims already wrap FakeTensor inputs to FakeTensor outputs','line_number':1612,'multiline':False]
['text':' and do device logic, we dont need do anything but run them','line_number':1613,'multiline':False]
['text':' and ensure that Meta kernels are dispatched to (see)','line_number':1614,'multiline':False]
['text':' Fake Tensor Dispatch Keys','line_number':1615,'multiline':False]
['text':' TODO - we should be use the prim aten impl','line_number':1616,'multiline':False]
['text':' TODO - fix prims complex ops','line_number':1617,'multiline':False]
['text':' Users can register FakeTensor rules for custom operators','line_number':1626,'multiline':False]
['text':' Call them if they exist.','line_number':1627,'multiline':False]
['text':' special handling for funcs registered through `register_op_impl`,','line_number':1637,'multiline':False]
['text':' e.g., manipulating args on constructor calls to construct meta tensors','line_number':1638,'multiline':False]
['text':' and then afterwards wrapping them to a FakeTensor','line_number':1639,'multiline':False]
['text':' It's OK to try the fallback for built-in ops (e.g. aten, prims)','line_number':1656,'multiline':False]
['text':' because we control and test these but the fallback leads to unexpected behavior','line_number':1657,'multiline':False]
['text':' in user-defined custom ops','line_number':1658,'multiline':False]
['text':'','line_number':1659,'multiline':False]
['text':' WARNING: DO NOT add any additional namespaces/operators here if they refer to operators','line_number':1660,'multiline':False]
['text':' outside of the pytorch/pytorch library! Any pre-existing things here','line_number':1661,'multiline':False]
['text':' are either in the pytorch/pytorch library or have been grandfathered in.','line_number':1662,'multiline':False]
['text':' The fallback does not always work and MAY CRASH and emit unreadable error messages','line_number':1663,'multiline':False]
['text':' so it should not be allowed by default.','line_number':1664,'multiline':False]
['text':' We infer the meta of a custom ops that return None to just','line_number':1684,'multiline':False]
['text':' return None. custom ops are not allowed to mutate metadata','line_number':1685,'multiline':False]
['text':' of their inputs, so this is safe.','line_number':1686,'multiline':False]
['text':' no meta kernel registered, fallback to kernel for the device','line_number':1689,'multiline':False]
['text':' Optimization: If there is no Meta kernel, it takes a surprisingly long','line_number':1696,'multiline':False]
['text':' amount of time to catch the NotImplementedError, so we check it here.','line_number':1697,'multiline':False]
['text':' run kernel registered to meta for func, which include','line_number':1703,'multiline':False]
['text':' python meta registrations, prims, decomps, and c++ meta fns (structured kernels)','line_number':1704,'multiline':False]
['text':' It's possible that the kernel will return NotImplementedError','line_number':1705,'multiline':False]
['text':' [subclass inputs]','line_number':1716,'multiline':False]
['text':' Suppose we enable fake tensor mode.  This means that fake tensor','line_number':1717,'multiline':False]
['text':' mode will run first.  But what if we do an operation that','line_number':1718,'multiline':False]
['text':' involves a tensor subclass that will desugar into normal tensor','line_number':1719,'multiline':False]
['text':' operations?  Without returning NotImplemented, fake tensor mode will run first,','line_number':1720,'multiline':False]
['text':' decide that a conversion was made (since there was a non fake','line_number':1721,'multiline':False]
['text':' tensor argument), and report an error that converting non','line_number':1722,'multiline':False]
['text':' fake tensor is not supported.  What we actually wanted to happen','line_number':1723,'multiline':False]
['text':' was to give the subclass a chance to figure out what it wants to','line_number':1724,'multiline':False]
['text':' before erroring out. Returning NotImplemented here allows this.','line_number':1725,'multiline':False]
['text':' Lazily initialized, in case there are no tensor returns','line_number':1778,'multiline':False]
['text':' Under FakeTensorMode, op accepts scalar only inputs, such as aten.add/sub/mul/div,','line_number':1804,'multiline':False]
['text':' returns a real scalar tensor on CPU. See TensorMeta() in _prims/__init__.py for details.','line_number':1805,'multiline':False]
['text':' We thus directly convert real tensor to fake tensor.','line_number':1806,'multiline':False]
['text':' Setting this flag will force FakeTensorMode to return `None` if attempting to convert a tensor we have not','line_number':1871,'multiline':False]
['text':' seen before.','line_number':1872,'multiline':False]
['text':' see note [Tensor Fakification and Symbol Caching]','line_number':1883,'multiline':False]
['text':' NB: returns fake tensors','line_number':1899,'multiline':False]
['text':' these should all be supported, just to be safe','line_number':1903,'multiline':False]
['text':' avoid fallback for operators which inplace modify metadata','line_number':1904,'multiline':False]
['text':' because the input fake tensors would be umodified','line_number':1905,'multiline':False]
['text':' Don't use in_kernel_invocation_manager(fake_mode) as we want to do','line_number':1911,'multiline':False]
['text':' REAL compute (not with meta device)','line_number':1912,'multiline':False]
['text':' TODO: also check metadata change on inputs','line_number':1937,'multiline':False]
['text':' proper aliasing/metadata relationship between outputs and inputs will','line_number':1938,'multiline':False]
['text':' not be set up, bc of conversion to device, unless we can reuse an','line_number':1939,'multiline':False]
['text':' input impl','line_number':1940,'multiline':False]
['text':' We control the built-ins. These may (in rare cases)','line_number':1964,'multiline':False]
['text':' do input metadata mutation (which we have banned on custom ops)','line_number':1965,'multiline':False]
['text':' It's suspicious if the op is not mutable but returns nothing, so we return False out of an abundance of caution','line_number':1968,'multiline':False]
['text':' If the op returns nothing, then it has a trivial abstract impl.','line_number':1973,'multiline':False]
['text':' Just for use to allow copying a module to fake tensors,','line_number':1977,'multiline':False]
['text':' does not apply elsewhere','line_number':1978,'multiline':False]
['text':' clone will get called in Parameter deepcopy','line_number':1986,'multiline':False]
