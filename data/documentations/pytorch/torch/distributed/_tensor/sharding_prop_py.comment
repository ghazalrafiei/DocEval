['text':' op map to save static argnum to decide to reuse sharding prop cache or re-run sharding prop','line_number':42,'multiline':False]
['text':' type: ignore[method-assign]','line_number':44,'multiline':False]
['text':' data dependent ops can't be used for fake propagation','line_number':80,'multiline':False]
['text':' NOTE: We must call the tracing in fake tensor mode so that it','line_number':83,'multiline':False]
['text':' avoids materializing memory','line_number':84,'multiline':False]
['text':' if fake is not a tensor or tuple of tensor, return as none','line_number':112,'multiline':False]
['text':' Either error due to ShardingPropagator or due to incorrect OutputSpec','line_number':129,'multiline':False]
['text':' We cannot use an lru cache if we know that inputs will have dynamic shapes,','line_number':157,'multiline':False]
['text':' because SymInts are not hashable.','line_number':158,'multiline':False]
['text':' This is generally ok because this only happens during tracing in torch.compile,','line_number':159,'multiline':False]
['text':' and tracing does not need to be as fast as eagermode DTensor usages.','line_number':160,'multiline':False]
['text':' special case op, we don't need to propagate for local','line_number':171,'multiline':False]
['text':' scalar. TODO: figure out a better way to handle this','line_number':172,'multiline':False]
['text':' tensor list create tuple strategy','line_number':186,'multiline':False]
['text':' generate op strategy for the op.','line_number':196,'multiline':False]
['text':' swap the args spec with args strategies','line_number':198,'multiline':False]
['text':' construct a new OpSchema on args for strategy based propagation','line_number':205,'multiline':False]
['text':' single Op strategy','line_number':215,'multiline':False]
['text':' for ops return multiple tensors, make output spec return same spec','line_number':239,'multiline':False]
['text':' returned from the op strategy','line_number':240,'multiline':False]
['text':' create a new DTensorSpec with the same placement as the','line_number':243,'multiline':False]
['text':' output_spec in output_strategy','line_number':244,'multiline':False]
['text':' tuple strategy output sharding','line_number':264,'multiline':False]
['text':' reshard_schema._inplace_rewrap_schema_suggestion(op_schema)','line_number':300,'multiline':False]
['text':' associate the output sharding with the output tensor metadata','line_number':311,'multiline':False]
['text':' propagate the sharding with rule','line_number':317,'multiline':False]
['text':' step 1. there's sharding propagation rule, run','line_number':320,'multiline':False]
['text':' sharding propagation to get the output sharding','line_number':321,'multiline':False]
['text':' step 2. if can't get output_spec from sharding','line_number':331,'multiline':False]
['text':' propagation (i.e. no rules apply for input','line_number':332,'multiline':False]
['text':' placements), we return the output sharding','line_number':333,'multiline':False]
['text':' with schema suggestions, which can be used to','line_number':334,'multiline':False]
['text':' decide how to do redistribute on inputs','line_number':335,'multiline':False]
['text':' we do auto redistribute on inputs if necessary','line_number':344,'multiline':False]
['text':' to get an eligible input, which we will pick a','line_number':345,'multiline':False]
['text':' schema suggestion base on the redistribute cost.','line_number':346,'multiline':False]
['text':' For now we simply pick the first suggestion.','line_number':347,'multiline':False]
['text':' run sharding propagation again with suggested schema','line_number':349,'multiline':False]
['text':' we set the output sharding with the new propagation result','line_number':351,'multiline':False]
['text':' so that dispatching know both output_spec and schema_suggestions','line_number':352,'multiline':False]
['text':' exist, which indicates a reshard is needed','line_number':353,'multiline':False]
['text':' associate the output sharding with the output tensor metadata','line_number':357,'multiline':False]
['text':' short cut with only one possible strategy','line_number':370,'multiline':False]
['text':' for eager execution, we just select the one with the minimal redistribute cost','line_number':381,'multiline':False]
