['text':' Only include ShardedTensor when do type checking, exclude it','line_number':20,'multiline':False]
['text':' from run-time to resolve circular dependency.','line_number':21,'multiline':False]
['text':' noqa: B024','line_number':24,'multiline':False]
['text':' Ops customized for a particular ShardingSpec.','line_number':89,'multiline':False]
['text':' Validate each shard has same rank.','line_number':143,'multiline':False]
['text':' check if shards form a valid tensor','line_number':156,'multiline':False]
['text':' TODO: figure out a generic and efficient way to scatter the shards for EnumerableShardingSpec','line_number':165,'multiline':False]
['text':' collect local shard metadatas from the global sharded_tensor_metadata','line_number':188,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':189,'multiline':False]
['text':' If the offset is [0, 0, ..., 0] (all zeros),','line_number':195,'multiline':False]
['text':' we cannot decide whether how the tensor is sharded.','line_number':196,'multiline':False]
['text':' If the offset is [0, N, .,0, M, 0, .., 0],','line_number':199,'multiline':False]
['text':' we are sure it's sharded by more than one dimension.','line_number':200,'multiline':False]
['text':' If the offset is [0, 0, .,0, M, 0, .., 0], aka, it's sharded by just','line_number':204,'multiline':False]
['text':' one dimension, we need to make sure all ranks share the same dimension.','line_number':205,'multiline':False]
['text':' Ensure we infer the correct placement order from offsets','line_number':213,'multiline':False]
