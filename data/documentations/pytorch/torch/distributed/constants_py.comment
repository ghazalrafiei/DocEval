['text':' Default process group wide timeout, if applicable.','line_number':7,'multiline':False]
['text':' This only applies to the non-nccl backends','line_number':8,'multiline':False]
['text':' To make an attempt at backwards compatibility with THD, we use an','line_number':9,'multiline':False]
['text':' extraordinarily high default timeout, given that THD did not have timeouts.','line_number':10,'multiline':False]
['text':' Separate timeout for PGNCCL mainly becuase it's always been that way in the C++ layer, but until recently','line_number':12,'multiline':False]
['text':' there was one default that applied across all backends in the python layer.','line_number':13,'multiline':False]
['text':' Later, we could consider merging them back together at the c++ layer if we can align on a same value.','line_number':14,'multiline':False]
['text':' (only if TORCH_NCCL_BLOCKING_WAIT or TORCH_NCCL_ASYNC_ERROR_HANDLING is set to 1).','line_number':15,'multiline':False]
['text':' if C++ NCCL support is not compiled, we don't have access to the default nccl value.','line_number':21,'multiline':False]
['text':' if anyone is actually trying to use nccl in this state, it should error.','line_number':22,'multiline':False]
