['text':' TODO: if we do ``deepcopy(_codegen)`` and the input argument contains','line_number':50,'multiline':False]
['text':' a dictionary with the form of Dict[torch.Tensor, Any], the','line_number':51,'multiline':False]
['text':' torch.fx._pytree.treen_flatten_spec will not be able to flatten the','line_number':52,'multiline':False]
['text':' dict -- the torch.Tensor will be duplicated because the _input_spec','line_number':53,'multiline':False]
['text':' will save the ``keys`` of a dictionary (the values are not saved).','line_number':54,'multiline':False]
['text':' We have to remove the node in the reversed order to ensure the','line_number':149,'multiline':False]
['text':' node has zero users.','line_number':150,'multiline':False]
['text':' This optimizer node from the legacy _SPMD tracing.','line_number':158,'multiline':False]
['text':' This is the case where the optimizer is','line_number':161,'multiline':False]
['text':' functionalized with copy_.','line_number':162,'multiline':False]
['text':' We have not figured out semantics of forwarding','line_number':167,'multiline':False]
['text':' all diff ops.','line_number':168,'multiline':False]
['text':' This is the step case where there is a virtual data dependency','line_number':174,'multiline':False]
['text':' (in-place update) between step and optimizer. And','line_number':175,'multiline':False]
['text':' functionalize_optim add this dependency','line_number':176,'multiline':False]
['text':' Add all the extra output nodes into a list and append the list to','line_number':189,'multiline':False]
['text':' the original output.args[0].','line_number':190,'multiline':False]
['text':' If the extra-output list already exist, just use it.','line_number':192,'multiline':False]
['text':' type: ignore[index]','line_number':193,'multiline':False]
['text':' When adding the extra-output list, out_spec of _PyTreeCodeGen','line_number':196,'multiline':False]
['text':' must be updated accordingly.','line_number':197,'multiline':False]
['text':' type: ignore[arg-type]','line_number':200,'multiline':False]
['text':' Use None as a placeholder. If we use the extra-output list','line_number':206,'multiline':False]
['text':' the list will be flatten as well and put into out_spec.','line_number':207,'multiline':False]
['text':' Append the extra input nodes to the current input nodes.','line_number':228,'multiline':False]
['text':' Update the inputs of subgraph to use the newly created input nodes.','line_number':243,'multiline':False]
['text':' Update the in_spec of _PyTreeCodeGen if in_spec is not None (the new','line_number':260,'multiline':False]
['text':' SPMD makes in_spec as None).','line_number':261,'multiline':False]
['text':' The main graph must be the last one to be modified. Otherwise, the','line_number':303,'multiline':False]
['text':' mapping may change and hence introduce incorrect mapping for setup','line_number':304,'multiline':False]
['text':' and cleanup graphs.','line_number':305,'multiline':False]
['text':' For the setup graph, no additional input is needed but additional','line_number':307,'multiline':False]
['text':' outputs will be created. The additional output represents the input of','line_number':308,'multiline':False]
['text':' the action to be moved to the next iteration -- main graph.','line_number':309,'multiline':False]
['text':' For the cleanup graph, additional input is required to get the output','line_number':321,'multiline':False]
['text':' from the last iteration -- main graph. Additional nodes are also','line_number':322,'multiline':False]
['text':' needed to perform the action moved from the last iteration.','line_number':323,'multiline':False]
['text':' For the main graph, additional input will be created to represent','line_number':340,'multiline':False]
['text':' the output from the last iteration -- main graph or setup graph.','line_number':341,'multiline':False]
['text':' Additional output will also be generated to represent the input for','line_number':342,'multiline':False]
['text':' the next iteration -- the main graph or the cleanup graph.','line_number':343,'multiline':False]
['text':' TODO: This is a temporary solution. We are going to remove DCE usage','line_number':352,'multiline':False]
['text':' or have something to replace fx DCE.','line_number':353,'multiline':False]
['text':' type: ignore[index]','line_number':356,'multiline':False]
['text':' type: ignore[index]','line_number':359,'multiline':False]
['text':' type: ignore[index]','line_number':574,'multiline':False]
['text':' type: ignore[arg-type]','line_number':584,'multiline':False]
['text':' IterGraph can only support full graph (fwd+bwd+optim). As optimizer','line_number':592,'multiline':False]
['text':' is not a functional call (it is inplace op), this method adds the of','line_number':593,'multiline':False]
['text':' the optimizer call. This method has strong assumption of the optimizer','line_number':594,'multiline':False]
['text':' and may not always be working. This method is intended be a temporary','line_number':595,'multiline':False]
['text':' solution only.','line_number':596,'multiline':False]
['text':' TODO: remove this API after DCE is removed','line_number':598,'multiline':False]
['text':' TODO: remove this API after DCE is not used with IterGraph','line_number':614,'multiline':False]
['text':' No cross-iteration optimization is done. Simply call the','line_number':701,'multiline':False]
['text':' GraphModule.','line_number':702,'multiline':False]
['text':' TODO: remove this API once it is not used.','line_number':739,'multiline':False]
