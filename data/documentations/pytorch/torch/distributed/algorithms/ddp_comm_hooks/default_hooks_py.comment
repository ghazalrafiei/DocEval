['text':' Apply the division first to avoid overflow, especially for FP16.','line_number':14,'multiline':False]
['text':' Decompress in place to reduce the peak memory.','line_number':68,'multiline':False]
['text':' See: https://github.com/pytorch/pytorch/issues/45968','line_number':69,'multiline':False]
['text':' TODO: create an internal helper function and extract the duplicate code in FP16_compress and BF16_compress.','line_number':75,'multiline':False]
['text':' Decompress in place to reduce the peak memory.','line_number':104,'multiline':False]
['text':' See: https://github.com/pytorch/pytorch/issues/45968','line_number':105,'multiline':False]
['text':' Cast bucket tensor to FP16.','line_number':131,'multiline':False]
['text':' Decompress in place to reduce the peak memory.','line_number':138,'multiline':False]
['text':' See: https://github.com/pytorch/pytorch/issues/45968','line_number':139,'multiline':False]
['text':' Decompress after hook has run.','line_number':143,'multiline':False]
['text':' Cast bucket tensor to BF16.','line_number':169,'multiline':False]
['text':' Decompress in place to reduce the peak memory.','line_number':176,'multiline':False]
['text':' See: https://github.com/pytorch/pytorch/issues/45968','line_number':177,'multiline':False]
['text':' Decompress after hook has run.','line_number':181,'multiline':False]
