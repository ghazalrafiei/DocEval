['text':' TensorMetadata is a structure containing pertinent information','line_number':15,'multiline':False]
['text':' about a tensor within a PyTorch program.','line_number':16,'multiline':False]
['text':' General Tensor metadata','line_number':18,'multiline':False]
['text':' Quantization metadata','line_number':25,'multiline':False]
['text':' type: ignore[assignment]','line_number':57,'multiline':False]
['text':' type: ignore[assignment]','line_number':58,'multiline':False]
['text':' In this branch, scale and zero_point are expected to be tensors,','line_number':60,'multiline':False]
['text':' we store the values as immutable_list in TensorMetadata for','line_number':61,'multiline':False]
['text':' easier serialization downstream','line_number':62,'multiline':False]
['text':' type: ignore[assignment]','line_number':63,'multiline':False]
['text':' type: ignore[assignment]','line_number':64,'multiline':False]
['text':' type: ignore[assignment]','line_number':65,'multiline':False]
['text':' Note:','line_number':123,'multiline':False]
['text':' We need fake execution cause the inputs are fake, however, we cannot fakify the module','line_number':124,'multiline':False]
['text':' - because we need to write to the tensor_meta of the real module. So we fakify to','line_number':125,'multiline':False]
['text':' produce a result (L131 below), to extract tensor meta, and then keep going.','line_number':126,'multiline':False]
['text':'','line_number':127,'multiline':False]
['text':' If we were to fakify, we would write to the wrong node, and then downstream fusion','line_number':128,'multiline':False]
['text':' would be missing the tensor_meta.','line_number':129,'multiline':False]
['text':'','line_number':130,'multiline':False]
['text':' See torch/_inductor/overrides.py for where this is called upstream of fusion.','line_number':131,'multiline':False]
['text':' Hacky swap. Alternatively, we could do this with overriding','line_number':143,'multiline':False]
['text':' call_module and get_attr.','line_number':144,'multiline':False]
