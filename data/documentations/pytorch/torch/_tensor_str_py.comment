['text':' We could use **kwargs, but this will give better docs','line_number':23,'multiline':False]
['text':' no valid number, do nothing','line_number':142,'multiline':False]
['text':' Convert to double for easy calculation. HalfTensor overflows with 1e8, and there's no div() on CPU.','line_number':145,'multiline':False]
['text':' in int_mode for floats, all numbers are integers, and we append a decimal to nonfinites','line_number':156,'multiline':False]
['text':' to indicate that the tensor is of floating type. add 1 to the len to account for this.','line_number':157,'multiline':False]
['text':' Check if scientific representation should be used.','line_number':171,'multiline':False]
['text':' handles negative numbers, +0.0, -0.0','line_number':211,'multiline':False]
['text':' length includes spaces and comma between elements','line_number':221,'multiline':False]
['text':' width for imag_formatter + an extra j for complex','line_number':224,'multiline':False]
['text':' handles negative numbers, +0.0, -0.0','line_number':235,'multiline':False]
['text':' Deal with edge case that negative zero is zero','line_number':244,'multiline':False]
['text':' formatter2 is only used for printing complex tensors.','line_number':262,'multiline':False]
['text':' For complex tensors, formatter1 and formatter2 are the formatters for tensor.real','line_number':263,'multiline':False]
['text':' and tensor.imag respesectively','line_number':264,'multiline':False]
['text':' There are two main codepaths (possibly more) that tensor printing goes through:','line_number':307,'multiline':False]
['text':' - tensor data can fit comfortably on screen','line_number':308,'multiline':False]
['text':' - tensor data needs to be summarized','line_number':309,'multiline':False]
['text':' Some of the codepaths don't fully support named tensors, so we send in','line_number':310,'multiline':False]
['text':' an unnamed tensor to the formatting code as a workaround.','line_number':311,'multiline':False]
['text':' handle the negative bit','line_number':319,'multiline':False]
['text':' handle the conjugate bit','line_number':337,'multiline':False]
['text':' This is used to extract the primal value and thus disable the forward AD','line_number':406,'multiline':False]
['text':' within this function.','line_number':407,'multiline':False]
['text':' TODO(albanD) This needs to be updated when more than one level is supported','line_number':408,'multiline':False]
['text':' Note [Print tensor device]:','line_number':411,'multiline':False]
['text':' A general logic here is we only print device when it doesn't match','line_number':412,'multiline':False]
['text':' the device specified in default tensor type.','line_number':413,'multiline':False]
['text':' Currently torch.set_default_tensor_type() only supports CPU/CUDA, thus','line_number':414,'multiline':False]
['text':' torch._C._get_default_device() only returns either cpu or cuda.','line_number':415,'multiline':False]
['text':' In other cases, we don't have a way to set them as default yet,','line_number':416,'multiline':False]
['text':' and we should always print out device for them.','line_number':417,'multiline':False]
['text':' Tensor printing performs tensor operations like slice, indexing, etc to make it in a','line_number':428,'multiline':False]
['text':' representable format. These operations on ipu/xla/lazy/mtia tensor results in compilations. Hence,','line_number':429,'multiline':False]
['text':' to avoid compilations, copying the tensor to cpu before printing.','line_number':430,'multiline':False]
['text':' TODO: add an API to map real -> complex dtypes','line_number':434,'multiline':False]
['text':' Circular import problem, so we import it here','line_number':563,'multiline':False]
['text':' TODO: This implies that ellipses is valid syntax for allocating','line_number':570,'multiline':False]
['text':' a meta tensor or FakeTensor, which it could be, but it isn't right now','line_number':571,'multiline':False]
['text':' Explicitly print the shape if it is not (0,), to match NumPy behavior','line_number':576,'multiline':False]
['text':' In an empty tensor, there are no elements to infer if the dtype','line_number':580,'multiline':False]
['text':' should be int64, so it must be shown explicitly.','line_number':581,'multiline':False]
['text':' Use inp here to get the original grad_fn and not the one generated by the forward grad','line_number':602,'multiline':False]
['text':' unpacking.','line_number':603,'multiline':False]
['text':' Accessing the grad_fn calls rebasing logic which would cause an error','line_number':608,'multiline':False]
['text':' if that tensor is a view created in no-grad mode modified in-place in','line_number':609,'multiline':False]
['text':' no-grad mode. See: https://github.com/pytorch/pytorch/issues/99968','line_number':610,'multiline':False]
['text':' Check if this instance is flagged as a parameter and change the repr accordingly.','line_number':633,'multiline':False]
['text':' Unfortunately, this function has to be aware of this detail.','line_number':634,'multiline':False]
['text':' NB: This is currently skipped for plain tensor parameters to maintain BC. In the future,','line_number':635,'multiline':False]
['text':' this should be done for those as well to produce a valid repr.','line_number':636,'multiline':False]
['text':' Since we're unwrapping the FunctionalTensorWrapper, we need to make sure','line_number':648,'multiline':False]
['text':' that it's up to date first','line_number':649,'multiline':False]
