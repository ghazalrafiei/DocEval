['text':' params can be a list of Tensors OR param_groups OR None','line_number':44,'multiline':False]
['text':' Class object for the Optimizer under test','line_number':84,'multiline':False]
['text':' Function to generate optimizer inputs EXCLUDING params. We delegate params responsibility','line_number':86,'multiline':False]
['text':' to the test using the OptimizerInfo. OptimizerInput.params is likely None.','line_number':87,'multiline':False]
['text':' A subset of the global-cliquey flags (fused, foreach, differentiable) the optimizer','line_number':89,'multiline':False]
['text':' supports. See NOTE: [optimizer kwarg categories] for what global-cliquey means.','line_number':90,'multiline':False]
['text':' the devices on which the optim supports sparse tensors for params and grads, see SGD','line_number':92,'multiline':False]
['text':' the optim only supports one config: sparse grads w/ dense params, see SparseAdam','line_number':94,'multiline':False]
['text':' whether the optimizer.step() function requires a closure to be passed','line_number':96,'multiline':False]
['text':' whether the optimizer supports per-param options with parameter groups','line_number':98,'multiline':False]
['text':' whether the optimizer supports parameters on multiple devices','line_number':100,'multiline':False]
['text':' Indicates which tests to skip','line_number':102,'multiline':False]
['text':' Additional decorators to apply to generated tests','line_number':103,'multiline':False]
['text':' Function to generate optim inputs that error','line_number':104,'multiline':False]
['text':' optimizers aren't limited to be one dtype as parameters can have different dtypes','line_number':143,'multiline':False]
['text':' We default to torch.float32, but dtypes should be specified through passed in','line_number':144,'multiline':False]
['text':' parameters.','line_number':145,'multiline':False]
['text':' Construct the test name; device / dtype parts are handled outside.','line_number':157,'multiline':False]
['text':' See [Note: device and dtype suffix placement]','line_number':158,'multiline':False]
['text':' Construct parameter kwargs to pass to the test.','line_number':161,'multiline':False]
['text':' Provides an error message for debugging before rethrowing the exception','line_number':180,'multiline':False]
['text':' ------------------------------------------------------------------------------------------','line_number':187,'multiline':False]
['text':' NOTE: [optimizer kwarg categories]','line_number':188,'multiline':False]
['text':' We categorize optimizer kwargs as 3 types:','line_number':189,'multiline':False]
['text':'  1. optimizer-specific flags are like amsgrad or rho or beta, flags that are specific to','line_number':190,'multiline':False]
['text':'     algorithms and thus only show up for certain optimizers. There are many of these, so I','line_number':191,'multiline':False]
['text':'     do not bother gathering them all and listing them here. The converse to these would be','line_number':192,'multiline':False]
['text':'     global flags that every optimizer ideally _should_ support. We break global flags into','line_number':193,'multiline':False]
['text':'     2 further categories and list them all below.','line_number':194,'multiline':False]
['text':'  2. global-friendly = ["lr", "weight_decay", "maximize", "capturable"]','line_number':195,'multiline':False]
['text':'     global-friendly flags are global flags who play nicely with all other global flags,','line_number':196,'multiline':False]
['text':'     i.e., are mutually exclusive in function. This means that any pair of the following','line_number':197,'multiline':False]
['text':'     flags can be toggled at once (e.g., maximize and weight_decay). Furthermore, any of the','line_number':198,'multiline':False]
['text':'     following flags theoretically can be enabled with ANY other global flag, including the','line_number':199,'multiline':False]
['text':'     cliquey ones (e.g, capturable and foreach).','line_number':200,'multiline':False]
['text':'  3. global-cliquey = ["foreach", "fused", "differentiable"]','line_number':201,'multiline':False]
['text':'     global-cliquey flags are global flags that do NOT coexist with other cliquey flags,','line_number':202,'multiline':False]
['text':'     usually because they contradict each other in function. For example, one should not flip','line_number':203,'multiline':False]
['text':'     both foreach AND fused to True, because they are two differing performance optimizations','line_number':204,'multiline':False]
['text':'     in which you can only opt into one.','line_number':205,'multiline':False]
['text':'','line_number':206,'multiline':False]
['text':' The following optim_inputs_func_* sampling functions only return constructor combinations of','line_number':207,'multiline':False]
['text':' optimizer-specific and global-friendly flags. This is because we are confident they would mesh','line_number':208,'multiline':False]
['text':' well with additional kwargs. On the flip side of the same coin, we reserve setting the','line_number':209,'multiline':False]
['text':' global-cliquey flags to individual tests and fully expect tests to edit OptimizerInput.kwargs.','line_number':210,'multiline':False]
['text':' TODO: Move out to testing in param_group?','line_number':218,'multiline':False]
['text':' TODO: Move out to testing in param_group?','line_number':229,'multiline':False]
['text':' TODO: Move out to testing in param_group?','line_number':276,'multiline':False]
['text':' TODO: consider tensor LR! See multi_tensor_optimizer_configs in test_optim.py --> tensor LR should work','line_number':303,'multiline':False]
['text':' with all implementation code paths...','line_number':304,'multiline':False]
['text':' Weird story bro, NAdam and RAdam do not have maximize.','line_number':490,'multiline':False]
['text':' Weird story bro, NAdam and RAdam do not have maximize.','line_number':550,'multiline':False]
['text':' TODO: Move out to testing in param_group?','line_number':748,'multiline':False]
['text':' Database of OptimizerInfo entries in alphabetical order.','line_number':795,'multiline':False]
