['text':' noqa: F401','line_number':40,'multiline':False]
['text':' noqa: F401','line_number':44,'multiline':False]
['text':' noqa: F401','line_number':50,'multiline':False]
['text':' NOQA: F401','line_number':100,'multiline':False]
['text':' test if a tensor is close to an integer','line_number':151,'multiline':False]
['text':' Cases with tensor indices.','line_number':179,'multiline':False]
['text':' Cases with list of indices.','line_number':184,'multiline':False]
['text':' Cases with integer section.','line_number':188,'multiline':False]
['text':' Incorrect type for indices_or_section argument','line_number':227,'multiline':False]
['text':' Incorrect type for indices_or_section argument','line_number':245,'multiline':False]
['text':' input shape, output shape, output stride, output storage offset','line_number':265,'multiline':False]
['text':' as_strided on offset, partial views','line_number':284,'multiline':False]
['text':' input shape, output shape, output stride, output storage offset','line_number':292,'multiline':False]
['text':' Scatter to larger dimensions','line_number':299,'multiline':False]
['text':' Scatter to larger dimensions with strides inverted','line_number':301,'multiline':False]
['text':' Create a small tensor and try to scatter it out of bounds','line_number':314,'multiline':False]
['text':' constructs 1-D tensors with varying number of elements','line_number':341,'multiline':False]
['text':' sample with only 1 tensor','line_number':346,'multiline':False]
['text':' sample with 2 tensors','line_number':349,'multiline':False]
['text':' sample with 3 tensors','line_number':352,'multiline':False]
['text':' Ordered as input_shape, dict of dim and eps','line_number':358,'multiline':False]
['text':' type: ignore[assignment]','line_number':359,'multiline':False]
['text':' Test for Broadcasting','line_number':370,'multiline':False]
['text':' Ordered as: input shape, kwargs for training, momentum, eps','line_number':409,'multiline':False]
['text':' type: ignore[assignment]','line_number':410,'multiline':False]
['text':' args: running mean, running var, weight and bias should necessarily be of shape: (channels,)','line_number':422,'multiline':False]
['text':' Checking for permutations of weights and biases as `None`','line_number':440,'multiline':False]
['text':' Test case for no optional kwargs','line_number':457,'multiline':False]
['text':' running_mean and running_var are required in evaluation mode (training: False) but not in training mode','line_number':458,'multiline':False]
['text':' torch.native_batch_norm does not support 0 numel tensors','line_number':482,'multiline':False]
['text':' IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)','line_number':483,'multiline':False]
['text':' torch.native_batch_norm does not support 0 numel tensors','line_number':496,'multiline':False]
['text':' IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)','line_number':497,'multiline':False]
['text':' NumPy does not support bfloat16, so we default to float32 (only for NumPy) in that case','line_number':556,'multiline':False]
['text':' Weight has numel != 1, but self.ndim is zero-dim tensor','line_number':565,'multiline':False]
['text':' Weight has numel != 1, but numel does not match channel size','line_number':571,'multiline':False]
['text':' Weight is neither a scalar nor 1-D tensor','line_number':577,'multiline':False]
['text':' src and index tensors must have the same # of dimensions','line_number':583,'multiline':False]
['text':' ord = inf is tested in inputs_norm_inf as it fails on some tests','line_number':587,'multiline':False]
['text':' Adds alpha kwarg cases','line_number':747,'multiline':False]
['text':' positive direction','line_number':772,'multiline':False]
['text':' negative direction','line_number':774,'multiline':False]
['text':' start == end','line_number':776,'multiline':False]
['text':' divides evenly','line_number':779,'multiline':False]
['text':' bool','line_number':782,'multiline':False]
['text':' default step','line_number':784,'multiline':False]
['text':' default start','line_number':786,'multiline':False]
['text':' includes endpoint','line_number':797,'multiline':False]
['text':' Pass end as positional arg','line_number':816,'multiline':False]
['text':' (Similar to) calling torch.arange(end=3)','line_number':818,'multiline':False]
['text':' this is a bit messy, as we want the args to be tuples','line_number':957,'multiline':False]
['text':' so if we pass size as a tuple, we have a tuple containing a tuple','line_number':958,'multiline':False]
['text':' Extra case to replicate off-by-one issue on CUDA','line_number':1007,'multiline':False]
['text':' Extra case to replicate off-by-one issue on CUDA','line_number':1024,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/82242','line_number':1050,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/82242','line_number':1071,'multiline':False]
['text':' Creates additional inputs to test the rtol, atol, and equal_nan params','line_number':1092,'multiline':False]
['text':' type: ignore[operator]','line_number':1151,'multiline':False]
['text':' sparse.sampled_addmm performs: alpha * (A @ B) * sparse_ones_like(C) + beta * C','line_number':1183,'multiline':False]
['text':' dot/vdot for (conj(input), conj(arg_tensor)) and (conj(input), arg_tensor)','line_number':1226,'multiline':False]
['text':' is tested in test_conj_view (which tests operations with only conjugated input tensor','line_number':1227,'multiline':False]
['text':' -- not conjugated arg tensors)','line_number':1228,'multiline':False]
['text':' addmv performs: beta * M + alpha * (mat @ vec)','line_number':1262,'multiline':False]
['text':' input_shape, batch1_shape, batch2_shape, beta_val, alpha_val, is_broadcasting','line_number':1270,'multiline':False]
['text':' addcdiv should accept inputs with zero value','line_number':1298,'multiline':False]
['text':' Currently, it throws ZeroDivisionError when the denominator is zero','line_number':1299,'multiline':False]
['text':' TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed','line_number':1300,'multiline':False]
['text':' addcdiv should accept inputs with zero value','line_number':1305,'multiline':False]
['text':' Currently, it throws ZeroDivisionError when the denominator is zero','line_number':1306,'multiline':False]
['text':' TODO: exclude_zeros can be removed after https://github.com/pytorch/pytorch/issues/73638 is fixed','line_number':1307,'multiline':False]
['text':' type promotion cases','line_number':1318,'multiline':False]
['text':' RuntimeError: value cannot be converted without overflow','line_number':1342,'multiline':False]
['text':' TypeError: addcdiv(): argument 'value' must be Number, not NoneType','line_number':1351,'multiline':False]
['text':' TODO: add reduction kwargs','line_number':1395,'multiline':False]
['text':' Produce one with weight and one without.','line_number':1405,'multiline':False]
['text':' These samples fail gradcheck','line_number':1435,'multiline':False]
['text':' invalid reduction','line_number':1513,'multiline':False]
['text':' invalid input','line_number':1516,'multiline':False]
['text':' invalid target','line_number':1523,'multiline':False]
['text':' invalid target dtype','line_number':1526,'multiline':False]
['text':' invalid weight','line_number':1529,'multiline':False]
['text':' invalid p','line_number':1536,'multiline':False]
['text':' Test large inputs to check numerical stability','line_number':1549,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/91843','line_number':1562,'multiline':False]
['text':' tests masking','line_number':1569,'multiline':False]
['text':' https://github.com/pytorch/pytorch/pull/91860#pullrequestreview-1241344073','line_number':1570,'multiline':False]
['text':' Hard-code some dtypes/devices. We want to test cases where the','line_number':1580,'multiline':False]
['text':' (dtype, device) is different from the input's (dtype, device)','line_number':1581,'multiline':False]
['text':' shape','line_number':1598,'multiline':False]
['text':' random tests including -1 target labels','line_number':1634,'multiline':False]
['text':' repeated target labels and -1 (labels after the first -1 are ignored)','line_number':1638,'multiline':False]
['text':' invalid reduction','line_number':1654,'multiline':False]
['text':' invalid input','line_number':1657,'multiline':False]
['text':' invalid target','line_number':1664,'multiline':False]
['text':' With high','line_number':1682,'multiline':False]
['text':' With low and high','line_number':1684,'multiline':False]
['text':' With high','line_number':1692,'multiline':False]
['text':' With low and high','line_number':1698,'multiline':False]
['text':' only supports ints and floats','line_number':1732,'multiline':False]
['text':' NaN propagation','line_number':1733,'multiline':False]
['text':' Inf handling','line_number':1742,'multiline':False]
['text':' Broadcasting','line_number':1751,'multiline':False]
['text':' invalid reduction value.','line_number':1759,'multiline':False]
['text':' invalid input shapes','line_number':1762,'multiline':False]
['text':' input_shape, output_shape, strides, kwargs','line_number':1767,'multiline':False]
['text':' lengths of output_shape and strides must be equal','line_number':1768,'multiline':False]
['text':' Hard-code some dtypes/devices. We want to test cases where the','line_number':1774,'multiline':False]
['text':' (dtype, device) is different from the input's (dtype, device)','line_number':1775,'multiline':False]
['text':' shape','line_number':1805,'multiline':False]
['text':' shape','line_number':1814,'multiline':False]
['text':' Not including a scalar tensor in vals because meta tests start failing due to','line_number':1841,'multiline':False]
['text':' lack of meta support for _local_scalar_dense','line_number':1842,'multiline':False]
['text':' torch.tensor(2, device=device)','line_number':1843,'multiline':False]
['text':' only ints >= 0 are allowed for both arguments, unless m is omitted','line_number':1850,'multiline':False]
['text':' TODO: no layout','line_number':1857,'multiline':False]
['text':' TODO: no layout','line_number':1865,'multiline':False]
['text':' The scalar we are passing to new_full must be the same dtype','line_number':1889,'multiline':False]
['text':' as the one of the resulting tensor','line_number':1890,'multiline':False]
['text':' Hard-code some dtypes/devices. We want to test cases where the','line_number':1904,'multiline':False]
['text':' (dtype, device) is different from the input's (dtype, device)','line_number':1905,'multiline':False]
['text':' value_or_size, value_or_size, kwargs','line_number':1950,'multiline':False]
['text':' broadcasting','line_number':1956,'multiline':False]
['text':' more than one element of the written-to tensor refers to a single memory location','line_number':1981,'multiline':False]
['text':' Deprecated behavior in regular PyTorch, but throws an error in primTorch:','line_number':2063,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86968','line_number':2064,'multiline':False]
['text':' ndims == 1','line_number':2066,'multiline':False]
['text':' ndims > 2','line_number':2071,'multiline':False]
['text':' NOTE: since svd_lowrank relies on non rank-revealing SVD,','line_number':2099,'multiline':False]
['text':' it inherits the problem of unstable behavior with repeated','line_number':2100,'multiline':False]
['text':' singular values including zeros.','line_number':2101,'multiline':False]
['text':' Since we want to avoid (repeated) zeros as singular values,','line_number':2102,'multiline':False]
['text':' we can only use k for q.','line_number':2103,'multiline':False]
['text':' This issues could be resolved with using a rank-revealing SVD','line_number':2104,'multiline':False]
['text':' which does not include "zero" singular values.','line_number':2105,'multiline':False]
['text':' without M specified','line_number':2111,'multiline':False]
['text':' now with M','line_number':2114,'multiline':False]
['text':' TODO: fix bug in the documentation for svd_lowrank:','line_number':2115,'multiline':False]
['text':' M has to be (*, m, n), and not (*, 1, n) as written','line_number':2116,'multiline':False]
['text':' in the documentation','line_number':2117,'multiline':False]
['text':' we reuse samples from svd_lowrank which come in group of two with','line_number':2130,'multiline':False]
['text':' kwarg['M'] = None and with kwarg['M'] = <some tensor>','line_number':2131,'multiline':False]
['text':' Wraps numpy's sinc function so that fp16 values are promoted to fp32','line_number':2142,'multiline':False]
['text':' before sinc is invoked. Context: numpy's sinc returns NaN when evaluated','line_number':2143,'multiline':False]
['text':' at 0 for fp16.','line_number':2144,'multiline':False]
['text':' We also want to test mixed complex-non-complex inputs to block_diag','line_number':2200,'multiline':False]
['text':' Using S here would make this one test take 9s','line_number':2222,'multiline':False]
['text':' FIXME add an override for JIT and revert 0. back to 0','line_number':2230,'multiline':False]
['text':' since it's accepted by eager','line_number':2231,'multiline':False]
['text':' The args should never be non-contiguous as this is not supported in the backward','line_number':2234,'multiline':False]
['text':' Adds a sample input where both tensors have the same values','line_number':2253,'multiline':False]
['text':' shape x number of tensors','line_number':2262,'multiline':False]
['text':' type: ignore[assignment]','line_number':2278,'multiline':False]
['text':' different shapes','line_number':2281,'multiline':False]
['text':' empty tensor','line_number':2283,'multiline':False]
['text':' empty tensor with unempty and dim=1 (special case for legacy_cat_wrap_dim)','line_number':2284,'multiline':False]
['text':' dim not passed, fallback to default','line_number':2286,'multiline':False]
['text':' from coat_lite_mini','line_number':2292,'multiline':False]
['text':' error inputs for more than one element of the written-to tensor refer to a single memory location','line_number':2299,'multiline':False]
['text':' error inputs for empty tensors','line_number':2304,'multiline':False]
['text':' error inputs for different sizes','line_number':2308,'multiline':False]
['text':' error inputs for different dimensions','line_number':2314,'multiline':False]
['text':' error inputs for same memory locations','line_number':2320,'multiline':False]
['text':' error inputs for different devices','line_number':2335,'multiline':False]
['text':' error inputs for different input sizes for more than 2 tensors','line_number':2342,'multiline':False]
['text':' error inputs for None input','line_number':2350,'multiline':False]
['text':' error inputs for zero-dimensional tensors','line_number':2354,'multiline':False]
['text':' error inputs for different dtype of out tensors','line_number':2358,'multiline':False]
['text':' Noncontiguous type promoting tensors','line_number':2369,'multiline':False]
['text':' Special 1D tensor with dim length of 0 case','line_number':2376,'multiline':False]
['text':' First Tensor being 1-D is special','line_number':2421,'multiline':False]
['text':' case for hstack','line_number':2422,'multiline':False]
['text':' Different dimension tensor','line_number':2437,'multiline':False]
['text':' empty tensor list','line_number':2440,'multiline':False]
['text':' Note: we don't do any tests where we unbind along 0-length dims','line_number':2444,'multiline':False]
['text':' because in that case unbind returns and empty tuple, and that breaks','line_number':2445,'multiline':False]
['text':' some assumptions in some backward tests in test_ops.py','line_number':2446,'multiline':False]
['text':' Empty index tensor case, see: https://github.com/pytorch/pytorch/pull/65006','line_number':2480,'multiline':False]
['text':' 0D tensor case','line_number':2485,'multiline':False]
['text':' src is [1, 2]','line_number':2504,'multiline':False]
['text':'        [3, 4]','line_number':2505,'multiline':False]
['text':' idx is [0, 0]','line_number':2508,'multiline':False]
['text':'        [1, 0]','line_number':2509,'multiline':False]
['text':' Index should be smaller than self except on dimension 1','line_number':2512,'multiline':False]
['text':' Index must have long dtype','line_number':2517,'multiline':False]
['text':' TODO: FIXME','line_number':2522,'multiline':False]
['text':' out.dtype must match src.dtype','line_number':2523,'multiline':False]
['text':' Creates new src & idx since SampleInputs can't share tensors','line_number':2524,'multiline':False]
['text':' src and index tensors must have the same # of dimensions','line_number':2531,'multiline':False]
['text':' idx too few dimensions','line_number':2532,'multiline':False]
['text':' src too few dimensions','line_number':2538,'multiline':False]
['text':' index out of bounds','line_number':2544,'multiline':False]
['text':' NOTE: this ErrorInput is guarded because bounds checking does not occur on CUDA devices','line_number':2545,'multiline':False]
['text':' Error inputs for scatter','line_number':2585,'multiline':False]
['text':' Error when self.dtype != src.dtype (and src is not a scalar)','line_number':2587,'multiline':False]
['text':' Index dtype must be long','line_number':2594,'multiline':False]
['text':' Index and destination must have the same number of dimensions','line_number':2601,'multiline':False]
['text':' Index and src must have the same number of dimensions when src is not a scalar','line_number':2608,'multiline':False]
['text':' Index out of bounds','line_number':2615,'multiline':False]
['text':' NOTE: this ErrorInput is guarded because bounds checking does not occur on CUDA devices','line_number':2616,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/85218','line_number':2635,'multiline':False]
['text':' error case when input tensor contains `inf`, `nan` or negative element','line_number':2713,'multiline':False]
['text':' error case for the invalid multinomial distribution (sum of probabilities <= 0), 1-D input','line_number':2717,'multiline':False]
['text':' error case for the invalid multinomial distribution (sum of probabilities <= 0), 2-D input','line_number':2722,'multiline':False]
['text':' error case for the invalid multinomial distribution','line_number':2727,'multiline':False]
['text':' `indices` broadcast','line_number':2835,'multiline':False]
['text':' `self` broadcast','line_number':2839,'multiline':False]
['text':' without `dim` arg','line_number':2843,'multiline':False]
['text':' Error Inputs for zero-dim tensors, when 'dim' arg is not provided.','line_number':2850,'multiline':False]
['text':' Error Inputs for tensors with more than 64 dimension','line_number':2859,'multiline':False]
['text':' Error Inputs for repeated 'dim'','line_number':2867,'multiline':False]
['text':' Error Input for illegal dtype','line_number':2875,'multiline':False]
['text':' Unlike regular PyTorch, amax and amin refs don't require input and out','line_number':2881,'multiline':False]
['text':' dtypes to match exactly:','line_number':2882,'multiline':False]
['text':' https://github.com/pytorch/pytorch/pull/87765#pullrequestreview-1162023824','line_number':2883,'multiline':False]
['text':' Error Inputs for functions to raise an error on specified zero'd dimension as reduction dim','line_number':2899,'multiline':False]
['text':' FIXME: eager and ref impl throw different types of errors','line_number':2901,'multiline':False]
['text':' type: ignore[assignment]','line_number':2907,'multiline':False]
['text':' add some samples with n > dim_size','line_number':2958,'multiline':False]
['text':' construct sample input omitting bins arg','line_number':3008,'multiline':False]
['text':' construct sample inputs with a few different bins values','line_number':3011,'multiline':False]
['text':' (unsorted tensor size, (input sizes,), is_scalar)','line_number':3053,'multiline':False]
['text':' `coords` will always contain floating point values and Python 3.10 does not support this','line_number':3107,'multiline':False]
['text':' implicit conversion to an integer using `__int__`','line_number':3108,'multiline':False]
['text':' TODO: this can be simplified after https://github.com/pytorch/pytorch/issues/69316 is fixed','line_number':3109,'multiline':False]
['text':' Test with indices arg','line_number':3143,'multiline':False]
['text':' Test with mask arg','line_number':3150,'multiline':False]
['text':' Test case for large tensor.','line_number':3166,'multiline':False]
['text':' Test cases for small 3d tensors.','line_number':3169,'multiline':False]
['text':' Imitates legacy tests from test/test_torch.py','line_number':3170,'multiline':False]
['text':' default schema without stable sort','line_number':3174,'multiline':False]
['text':' schema with stable sort, no CUDA support yet','line_number':3176,'multiline':False]
['text':' Test cases for scalar tensor','line_number':3181,'multiline':False]
['text':' Test cases for empty tensor','line_number':3187,'multiline':False]
['text':' Test cases for stable sort','line_number':3192,'multiline':False]
['text':' threshold and values args must be numbers','line_number':3201,'multiline':False]
['text':' torch.unique cannot be called if the input tensor has a zero dimension which isn't the selected dim','line_number':3210,'multiline':False]
['text':' skip invalid dim args','line_number':3214,'multiline':False]
['text':' construct a test case with only one distinct value','line_number':3220,'multiline':False]
['text':' construct a test case with mixed 0s and 1s','line_number':3224,'multiline':False]
['text':' construct a test case with many different values','line_number':3229,'multiline':False]
['text':' Ordered as (input shape, output size)','line_number':3241,'multiline':False]
['text':' Batched','line_number':3249,'multiline':False]
['text':' Unbatched','line_number':3251,'multiline':False]
['text':' error inputs for empty output','line_number':3258,'multiline':False]
['text':' error inputs for output_size lesser than 0','line_number':3262,'multiline':False]
['text':' Ordered as (input shape, output size)','line_number':3270,'multiline':False]
['text':' Batched','line_number':3280,'multiline':False]
['text':' Unbatched','line_number':3282,'multiline':False]
['text':' error inputs for incorrect input dimension','line_number':3289,'multiline':False]
['text':' error inputs for empty output','line_number':3293,'multiline':False]
['text':' error inputs for output_size lesser than 0','line_number':3297,'multiline':False]
['text':' Ordered as (input shape, output size)','line_number':3305,'multiline':False]
['text':' Batched','line_number':3316,'multiline':False]
['text':' Unbatched','line_number':3318,'multiline':False]
['text':' error inputs for incorrect input dimension','line_number':3325,'multiline':False]
['text':' error inputs for empty output','line_number':3329,'multiline':False]
['text':' error inputs for output_size lesser than 0','line_number':3333,'multiline':False]
['text':' Ordered as (input shape, output size)','line_number':3341,'multiline':False]
['text':' ((0, 8, 8), (5,)),','line_number':3343,'multiline':False]
['text':' 0 batch size doesn't work,  cannot reshape tensor of 0 elements into shape [0, 8, -1]','line_number':3344,'multiline':False]
['text':' Batched','line_number':3350,'multiline':False]
['text':' Unbatched','line_number':3352,'multiline':False]
['text':' error inputs for empty output','line_number':3359,'multiline':False]
['text':' error inputs for output_size lesser than 0','line_number':3363,'multiline':False]
['text':' Ordered as (input shape, output size)','line_number':3370,'multiline':False]
['text':' ((0, 8, 8, 8), (5, 7)),','line_number':3372,'multiline':False]
['text':' 0 batch size doesn't work,  cannot reshape tensor of 0 elements into shape [0, 8, -1]','line_number':3373,'multiline':False]
['text':' Batched','line_number':3383,'multiline':False]
['text':' Unbatched','line_number':3385,'multiline':False]
['text':' error inputs for incorrect input dimension','line_number':3391,'multiline':False]
['text':' error inputs for empty output','line_number':3395,'multiline':False]
['text':' error inputs for output_size lesser than 0','line_number':3399,'multiline':False]
['text':' Ordered as (input shape, output size)','line_number':3407,'multiline':False]
['text':' ((0, 8, 8, 8, 8), (5, 7, 4)),','line_number':3409,'multiline':False]
['text':' 0 batch size doesn't work,  cannot reshape tensor of 0 elements into shape [0, 8, -1]','line_number':3410,'multiline':False]
['text':' Batched','line_number':3419,'multiline':False]
['text':' Unbatched','line_number':3421,'multiline':False]
['text':' error inputs for incorrect input dimension','line_number':3427,'multiline':False]
['text':' error inputs for empty output','line_number':3431,'multiline':False]
['text':' error inputs for output_size lesser than 0','line_number':3435,'multiline':False]
['text':' batch','line_number':3453,'multiline':False]
['text':' channels','line_number':3454,'multiline':False]
['text':' signal','line_number':3455,'multiline':False]
['text':' shape[0] is None indicates missing batch dimension','line_number':3460,'multiline':False]
['text':' only 2d (N, C, H, W) rank 4 tensors support channels_last memory format','line_number':3465,'multiline':False]
['text':' Toggle requires_grad because `max_pool1d` has different path','line_number':3534,'multiline':False]
['text':' based on whether `requires_grad` is set or not.','line_number':3535,'multiline':False]
['text':' error inputs when pad is negative','line_number':3538,'multiline':False]
['text':' error inputs when pad > kernel_size / 2','line_number':3543,'multiline':False]
['text':' error inputs for input tensor','line_number':3547,'multiline':False]
['text':' error inputs for empty input','line_number':3552,'multiline':False]
['text':' error: unbatched input with 0 sized non-batch dims.','line_number':3557,'multiline':False]
['text':' error: batched input with 0 sized non-batch dims.','line_number':3562,'multiline':False]
['text':' error inputs for empty input with stride=0','line_number':3567,'multiline':False]
['text':' error inputs for empty input with dilation=0','line_number':3572,'multiline':False]
['text':' error inputs for invalid output size','line_number':3578,'multiline':False]
['text':' error inputs when kernel_size=0','line_number':3584,'multiline':False]
['text':' error inputs for strides > 0','line_number':3589,'multiline':False]
['text':' error inputs when pad is negative','line_number':3597,'multiline':False]
['text':' 2-dimensional kernel','line_number':3601,'multiline':False]
['text':' error inputs when pad > kernel_size / 2 (kernel_size : int)','line_number':3605,'multiline':False]
['text':' error inputs when pad > kernel_size / 2 (kernel_size : tuple)','line_number':3609,'multiline':False]
['text':' error: unbatched input with 0 sized non-batch dims.','line_number':3613,'multiline':False]
['text':' error: batched input with 0 sized non-batch dims.','line_number':3619,'multiline':False]
['text':' error inputs when pad is negative','line_number':3627,'multiline':False]
['text':' 3-dimensional kernel','line_number':3631,'multiline':False]
['text':' error inputs when pad > kernel_size / 2 (kernel_size: int)','line_number':3636,'multiline':False]
['text':' error inputs when pad > kernel_size / 2 (kernel_size: tuple)','line_number':3640,'multiline':False]
['text':' error: unbatched input with 0 sized non-batch dims.','line_number':3645,'multiline':False]
['text':' error: batched inputs with 0 sized non-batch dims.','line_number':3651,'multiline':False]
['text':' type: ignore[assignment]','line_number':3660,'multiline':False]
['text':' conv(W, x, b) = conv(Wr, xr, br) - conv(Wi, xi, 0) + i(conv(Wi, xr, bi) + conv(Wr, xi, 0))','line_number':3675,'multiline':False]
['text':' a = conv(Wr, xr, br),','line_number':3676,'multiline':False]
['text':' b = conv(Wi, xi, 0),','line_number':3677,'multiline':False]
['text':' c = conv(Wr + Wi, xr + xi, br + bi)','line_number':3678,'multiline':False]
['text':' conv(W, x, b) = a - b + i(c - a - b)','line_number':3679,'multiline':False]
['text':' Derivative of `conv` is `conv_transpose`.','line_number':3699,'multiline':False]
['text':' To verify the correctness of `conv_transpose`,','line_number':3700,'multiline':False]
['text':' we rely `torch.nn.grad` implementation (which is tested in test_nn.py)','line_number':3701,'multiline':False]
['text':' for floating dtypes.','line_number':3702,'multiline':False]
['text':' Input for `ref` is ndarray.','line_number':3713,'multiline':False]
['text':' Get the input shape for grad_fn.','line_number':3727,'multiline':False]
['text':' Floating','line_number':3736,'multiline':False]
['text':' Ordered as shapes for input, weight, bias','line_number':3748,'multiline':False]
['text':' and a dict of values of (stride, padding, output_padding, groups, dilation)','line_number':3749,'multiline':False]
['text':' type: ignore[assignment]','line_number':3750,'multiline':False]
['text':' Batched','line_number':3764,'multiline':False]
['text':' Unbatched','line_number':3769,'multiline':False]
['text':' Ordered as shapes for input, weight, bias','line_number':3779,'multiline':False]
['text':' and a dict of values of (stride, padding, output_padding, groups, dilation)','line_number':3780,'multiline':False]
['text':' type: ignore[assignment]','line_number':3781,'multiline':False]
['text':' Batched','line_number':3795,'multiline':False]
['text':' Unbatched','line_number':3800,'multiline':False]
['text':' Ordered as shapes for input, weight, bias','line_number':3809,'multiline':False]
['text':' and a dict of values of (stride, padding, output_padding, groups, dilation)','line_number':3810,'multiline':False]
['text':' type: ignore[assignment]','line_number':3811,'multiline':False]
['text':' Batched','line_number':3825,'multiline':False]
['text':' Unbatched','line_number':3830,'multiline':False]
['text':' Ordered as shapes for input, weight, bias,','line_number':3840,'multiline':False]
['text':' and a dict of values of (stride, padding, dilation, groups)','line_number':3841,'multiline':False]
['text':' With defaults','line_number':3847,'multiline':False]
['text':' Batched','line_number':3852,'multiline':False]
['text':' Unbatched','line_number':3857,'multiline':False]
['text':' error inputs for different dtypes of input tensor and bias','line_number':3869,'multiline':False]
['text':' error inputs for different dtypes of input tensor and bias','line_number':3874,'multiline':False]
['text':' error inputs for negative strides','line_number':3879,'multiline':False]
['text':' error inputs for negative padding','line_number':3884,'multiline':False]
['text':' error inputs for negative dilation','line_number':3889,'multiline':False]
['text':' FIXME: https://github.com/pytorch/pytorch/issues/85656','line_number':3894,'multiline':False]
['text':' error inputs for bias shape not equal to the output channels','line_number':3895,'multiline':False]
['text':' yield ErrorInput(SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 1, 3)), make_arg((2,)))),','line_number':3896,'multiline':False]
['text':'                  error_regex="expected bias to be 1-dimensional with 1 elements")','line_number':3897,'multiline':False]
['text':' error inputs for input.ndim != weight.ndim','line_number':3899,'multiline':False]
['text':' error inputs for the weight[0] are less than the number of groups','line_number':3903,'multiline':False]
['text':' error inputs for the weight[0] are less than the number of groups','line_number':3908,'multiline':False]
['text':' error inputs for invalid groups','line_number':3913,'multiline':False]
['text':' error inputs for invalid groups','line_number':3918,'multiline':False]
['text':' error inputs for different dtypes of input tensor and bias','line_number':3929,'multiline':False]
['text':' error inputs for different dtypes of input tensor and bias','line_number':3934,'multiline':False]
['text':' error inputs for negative strides','line_number':3939,'multiline':False]
['text':' error inputs for negative padding','line_number':3944,'multiline':False]
['text':' error inputs for negative dilation','line_number':3949,'multiline':False]
['text':' FIXME: https://github.com/pytorch/pytorch/issues/85656','line_number':3954,'multiline':False]
['text':' error inputs for bias shape not equal to the output channels','line_number':3955,'multiline':False]
['text':' yield ErrorInput(SampleInput(make_arg((1, 1, 4, 4)), args=(make_arg((1, 1, 3, 2)), make_arg((2,)))),','line_number':3956,'multiline':False]
['text':'                  error_regex="expected bias to be 1-dimensional with 1 elements")','line_number':3957,'multiline':False]
['text':' error inputs for input.ndim != weight.ndim','line_number':3959,'multiline':False]
['text':' error inputs for the weight[0] are less than the number of groups','line_number':3964,'multiline':False]
['text':' error inputs for groups the weight[0] are less than the number of groups','line_number':3969,'multiline':False]
['text':' error inputs for invalid groups','line_number':3974,'multiline':False]
['text':' error inputs for invalid groups','line_number':3979,'multiline':False]
['text':' Ordered as shapes for input, weight, bias','line_number':3988,'multiline':False]
['text':' and a dict of values of (stride, padding, groups, dilation)','line_number':3989,'multiline':False]
['text':' Below are the group related samples from common_nn.py','line_number':4005,'multiline':False]
['text':' With defaults','line_number':4013,'multiline':False]
['text':' Batched','line_number':4018,'multiline':False]
['text':' Unbatched','line_number':4023,'multiline':False]
['text':' Ordered as shapes for input, weight, bias','line_number':4033,'multiline':False]
['text':' and dict of values of (stride, padding, dilation, groups)','line_number':4034,'multiline':False]
['text':' Batched','line_number':4049,'multiline':False]
['text':' Unbatched','line_number':4054,'multiline':False]
['text':' error inputs for different dtypes of input tensor and bias','line_number':4066,'multiline':False]
['text':' error inputs for different dtypes of input tensor and bias','line_number':4071,'multiline':False]
['text':' error inputs for negative strides','line_number':4076,'multiline':False]
['text':' error inputs for negative padding','line_number':4081,'multiline':False]
['text':' error inputs for negative dilation','line_number':4086,'multiline':False]
['text':' FIXME: https://github.com/pytorch/pytorch/issues/85656','line_number':4091,'multiline':False]
['text':' error inputs for bias shape not equal to the output channels','line_number':4092,'multiline':False]
['text':' yield ErrorInput(SampleInput(make_arg((1, 1, 4, 4, 4)), args=(make_arg((1, 1, 3, 3, 3)), make_arg((2,)))),','line_number':4093,'multiline':False]
['text':'                  error_regex="expected bias to be 1-dimensional with 1 elements")','line_number':4094,'multiline':False]
['text':' error inputs for input.ndim != weight.ndim','line_number':4096,'multiline':False]
['text':' error inputs for the weight[0] are less than the number of groups','line_number':4101,'multiline':False]
['text':' error inputs for the weight[0] are less than the number of groups','line_number':4107,'multiline':False]
['text':' error inputs for invalid groups','line_number':4113,'multiline':False]
['text':' error inputs for padding='same' not supported by strided convolutions','line_number':4119,'multiline':False]
['text':' Ordered as input shape, num groups, and kwargs for eps','line_number':4129,'multiline':False]
['text':' type: ignore[assignment]','line_number':4130,'multiline':False]
['text':' num_channels is inferred to be input.shape[1] dimension','line_number':4138,'multiline':False]
['text':' Shape of weight and bias should be the same as num_channels','line_number':4140,'multiline':False]
['text':' Checking for permutations of weights and biases as `None`','line_number':4145,'multiline':False]
['text':' Without any optional args','line_number':4156,'multiline':False]
['text':' Ordered as input shape, num groups, and kwargs for eps','line_number':4165,'multiline':False]
['text':' type: ignore[assignment]','line_number':4166,'multiline':False]
['text':' equivalent with InstanceNorm','line_number':4168,'multiline':False]
['text':' GroupNorm(C, num_groups=C) == InstanceNorm(num_features=C)','line_number':4169,'multiline':False]
['text':' equivalent with LayerNorm','line_number':4171,'multiline':False]
['text':' GroupNorm(C, num_groups=1, affine=False) == LayerNorm(normalized_shape=[C, H, W], elementwise_affine=False)','line_number':4172,'multiline':False]
['text':' num_channels is inferred to be input.shape[1] dimension','line_number':4176,'multiline':False]
['text':' Shape of weight and bias should be the same as num_channels','line_number':4178,'multiline':False]
['text':' Checking for permutations of weights and biases as `None`','line_number':4184,'multiline':False]
['text':' Ordered as: input shape, kwargs for momentum, eps','line_number':4200,'multiline':False]
['text':' type: ignore[assignment]','line_number':4201,'multiline':False]
['text':' args: running mean, running var, weight and bias should necessarily be of shape: (channels,)','line_number':4211,'multiline':False]
['text':' Checking for permutations of weights and biases as `None`','line_number':4231,'multiline':False]
['text':' instance_norm assumes that if there's a bias, there's a weight','line_number':4232,'multiline':False]
['text':' Test case for no optional kwargs','line_number':4250,'multiline':False]
['text':' Ordered as input shape, normalized_shape and a kwarg dict for eps','line_number':4257,'multiline':False]
['text':' type: ignore[assignment]','line_number':4258,'multiline':False]
['text':' Shape of weight and bias should be the same as normalized_shape','line_number':4267,'multiline':False]
['text':' Without any optional args','line_number':4275,'multiline':False]
['text':' TODO: @krshrimali, once to_numpy method in SampleInput class is modified to take None inputs,','line_number':4278,'multiline':False]
['text':' enable these inputs; see https://github.com/pytorch/pytorch/pull/63276#discussion_r691950400','line_number':4279,'multiline':False]
['text':' With weight and a `None` bias','line_number':4281,'multiline':False]
['text':' yield SampleInput(make_arg((1, 2)), args=((2,), make_arg((2,)), None))','line_number':4282,'multiline':False]
['text':' With `None` weight and bias (tests failing for this, see the link above)','line_number':4284,'multiline':False]
['text':' yield SampleInput(make_arg((1, 2)), args=((2,), None, make_arg((2,))))','line_number':4285,'multiline':False]
['text':' Ordered as input shape, normalized_shape, eps','line_number':4291,'multiline':False]
['text':' type: ignore[assignment]','line_number':4292,'multiline':False]
['text':' Shape of weight and bias should be the same as normalized_shape','line_number':4301,'multiline':False]
['text':' check that input has minimum number of dimensions','line_number':4324,'multiline':False]
['text':' check that the channels dimension is compatible with number of groups','line_number':4329,'multiline':False]
['text':' Ordered as input shape, size and a kwarg dict for alpha, beta, and k','line_number':4369,'multiline':False]
['text':' type: ignore[assignment]','line_number':4370,'multiline':False]
['text':' make sure we are testing -3 -> 3 range. default is -10 -> 10 so maybe unnecessary ?','line_number':4389,'multiline':False]
['text':' no batch','line_number':4397,'multiline':False]
['text':' no batch','line_number':4419,'multiline':False]
['text':' no batch','line_number':4441,'multiline':False]
['text':' we pick more realistic upper bound 256 instead of default 10 for uint8 dtype','line_number':4487,'multiline':False]
['text':' provide few samples for a more close to typical image processing usage','line_number':4490,'multiline':False]
['text':' we pick more realistic upper bound 256 instead of default 10 for uint8 dtype','line_number':4539,'multiline':False]
['text':' provide few samples for more typical image processing usage','line_number':4542,'multiline':False]
['text':' we pick more realistic upper bound 256 instead of default 10 for uint8 dtype','line_number':4587,'multiline':False]
['text':' provide a single sample for more typical image processing usage','line_number':4590,'multiline':False]
['text':' Tests that gelu errors out when passed an approximation we don't know.','line_number':4627,'multiline':False]
['text':' NaN only exists for floating point numbers','line_number':4653,'multiline':False]
['text':' Generates sample inputs for reduction ops that contain the input tensor','line_number':4659,'multiline':False]
['text':' and dim and keepdim kwargs. If a reduction op needs to test additional','line_number':4660,'multiline':False]
['text':' args/kwargs then create a separate sample_inputs function','line_number':4661,'multiline':False]
['text':' Add case without dim and keepdim kwargs','line_number':4664,'multiline':False]
['text':' Add case without dim and keepdim kwargs','line_number':4677,'multiline':False]
['text':' Interpolation kwarg for now is only supported when providing both dim and keepdim','line_number':4681,'multiline':False]
['text':' count_nonzero does not support keepdim yet','line_number':4691,'multiline':False]
['text':' Order: input_shape, kernel_size','line_number':4704,'multiline':False]
['text':' test case passing a single output size','line_number':4714,'multiline':False]
['text':' test case passing a tuple output size','line_number':4722,'multiline':False]
['text':' test case passing an output ratio','line_number':4730,'multiline':False]
['text':' Order: input_shape, kernel_size','line_number':4741,'multiline':False]
['text':' test case passing a single output size','line_number':4753,'multiline':False]
['text':' test case passing a tuple output size','line_number':4761,'multiline':False]
['text':' test case passing an output ratio','line_number':4769,'multiline':False]
['text':' Order: input_shape, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override','line_number':4780,'multiline':False]
['text':' Case with just input_shape and kernel_size','line_number':4791,'multiline':False]
['text':' Order: input_shape, kernel_size, kwargs','line_number':4797,'multiline':False]
['text':' Order: input_shape, kernel_size, stride, padding, ceil_mode, count_include_pad, divisor_override','line_number':4816,'multiline':False]
['text':' error inputs when pad is negative','line_number':4838,'multiline':False]
['text':' error inputs when pad > kernel_size / 2','line_number':4843,'multiline':False]
['text':' error inputs when pad is negative','line_number':4848,'multiline':False]
['text':' 2-dimensional kernel','line_number':4852,'multiline':False]
['text':' error inputs when pad > kernel_size / 2','line_number':4856,'multiline':False]
['text':' 2-dimensional kernel','line_number':4859,'multiline':False]
['text':' error inputs for zero divisor','line_number':4863,'multiline':False]
['text':' error inputs when pad is negative','line_number':4869,'multiline':False]
['text':' 3-dimensional kernel','line_number':4873,'multiline':False]
['text':' error inputs when pad > kernel_size / 2','line_number':4877,'multiline':False]
['text':' 3-dimensional kernel','line_number':4880,'multiline':False]
['text':' error inputs for zero divisor','line_number':4884,'multiline':False]
['text':' error inputs for invalid input dimension','line_number':4889,'multiline':False]
['text':' test_multiple_devices_to_cuda would fail if we use a different device than given','line_number':4897,'multiline':False]
['text':' TODO: can't switch `to.device` overload to use positional arguments','line_number':4903,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/84265','line_number':4904,'multiline':False]
['text':' to.device overload','line_number':4905,'multiline':False]
['text':' to.dtype overload','line_number':4912,'multiline':False]
['text':' to.other overload','line_number':4919,'multiline':False]
['text':' Missing to test the nondeterminism of the operation','line_number':4960,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/53352','line_number':4961,'multiline':False]
['text':' target.index_select(dim, idx)','line_number':4963,'multiline':False]
['text':' target.index_add(dim, idx, source, *, alpha=1)','line_number':4965,'multiline':False]
['text':' target.index_copy(dim, idx, source)','line_number':4967,'multiline':False]
['text':' target.index_fill(dim, idx, value)','line_number':4969,'multiline':False]
['text':' Extended reference inputs. We generate that exercise atomic adds / writing','line_number':4972,'multiline':False]
['text':' several times to one location','line_number':4973,'multiline':False]
['text':' idx They need to be different for copy and add to be deterministic','line_number':4979,'multiline':False]
['text':' extra parameter for add','line_number':4987,'multiline':False]
['text':' A weird number to catch errors.','line_number':4997,'multiline':False]
['text':' The former one tests `index_fill.int_Scalar`, and the latter one tests `index_fill.int_Tensor`.','line_number':4998,'multiline':False]
['text':' dim. We handle the scalar case','line_number':5007,'multiline':False]
['text':' source','line_number':5014,'multiline':False]
['text':' dim. We handle the scalar case','line_number':5037,'multiline':False]
['text':' Sample inputs to test edge cases for backward','line_number':5046,'multiline':False]
['text':' Check that gradients are propagated correctly for prod when zeros in self/src are reduced','line_number':5048,'multiline':False]
['text':' This sample tests gradients for the following cases','line_number':5049,'multiline':False]
['text':' (a) 1 zero reduced (from source (self[0, 1]), from self (self[0, 0]))','line_number':5050,'multiline':False]
['text':' (b) 2 zeros reduced (1 from src and 1 from self (self[1, 0], self[1, 1])','line_number':5051,'multiline':False]
['text':' (c) no zeros reduced (self[2, 1], self[2, 2])','line_number':5052,'multiline':False]
['text':' (d) 2 zeros reduced (both from src) is tested in test/test_autograd.py','line_number':5053,'multiline':False]
['text':'     test_scatter_index_reduce_prod_gradgrad_error as this case is not supported for gradgrad','line_number':5054,'multiline':False]
['text':' Non-fused mode kernel on CUDA','line_number':5071,'multiline':False]
['text':' Missing to test the nondeterminism of the operation','line_number':5079,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/53352','line_number':5080,'multiline':False]
['text':' Generic inputs','line_number':5087,'multiline':False]
['text':' Scalar cases','line_number':5096,'multiline':False]
['text':' Empty cases','line_number':5107,'multiline':False]
['text':' Generic inputs: take S elements out of S * S','line_number':5124,'multiline':False]
['text':' Scalar cases','line_number':5129,'multiline':False]
['text':' Empty cases','line_number':5137,'multiline':False]
['text':' shape, source, destination','line_number':5156,'multiline':False]
['text':' empty inputs','line_number':5158,'multiline':False]
['text':' int inputs, negative','line_number':5160,'multiline':False]
['text':' swap bounds','line_number':5162,'multiline':False]
['text':' non-sequential, negative','line_number':5164,'multiline':False]
['text':' idempotence, negative','line_number':5166,'multiline':False]
['text':' reverse, sequential, positive','line_number':5168,'multiline':False]
['text':' reverse, non-sequential','line_number':5170,'multiline':False]
['text':' reverse, sequential, negative','line_number':5172,'multiline':False]
['text':' source length < destination length','line_number':5182,'multiline':False]
['text':' source length > destination length','line_number':5190,'multiline':False]
['text':' repeated source dim, with negative indices','line_number':5198,'multiline':False]
['text':' repeated destination dim, with negative indices','line_number':5204,'multiline':False]
['text':' repeated dim (both), with negative indices','line_number':5210,'multiline':False]
['text':' out of bounds source inputs, with negative indices','line_number':5216,'multiline':False]
['text':' out of bounds destination inputs, with negative indices','line_number':5223,'multiline':False]
['text':' out of bounds source input, int','line_number':5230,'multiline':False]
['text':' out of bounds destination input, int','line_number':5237,'multiline':False]
['text':' Tests for variant_consistency_jit, grad, gradgrad','line_number':5250,'multiline':False]
['text':' are slower. Use smaller bags of `rep_dims` and `shapes`','line_number':5251,'multiline':False]
['text':' in this case.','line_number':5252,'multiline':False]
['text':' type: ignore[assignment]','line_number':5253,'multiline':False]
['text':' type: ignore[assignment]','line_number':5254,'multiline':False]
['text':' `torch.repeat` errors for `len(rep_dims) < t.dim()`,','line_number':5258,'multiline':False]
['text':' so we filter such combinations.','line_number':5259,'multiline':False]
['text':' narrow also accepts the start argument being a Tensor','line_number':5278,'multiline':False]
['text':' 1-dim','line_number':5286,'multiline':False]
['text':' 0 elems from the left','line_number':5287,'multiline':False]
['text':' 0 elems from the right','line_number':5288,'multiline':False]
['text':' 3 elems from the left','line_number':5289,'multiline':False]
['text':' 2 elems from the right','line_number':5290,'multiline':False]
['text':' M elems from the left','line_number':5291,'multiline':False]
['text':' M elems from the right','line_number':5292,'multiline':False]
['text':' 2-dim','line_number':5294,'multiline':False]
['text':' dim 1, 0 elems from the left','line_number':5295,'multiline':False]
['text':' dim 0, 0 elems from the right','line_number':5296,'multiline':False]
['text':' dim 1, 3 elems from the left','line_number':5297,'multiline':False]
['text':' dim 1, 2 elems from the left','line_number':5298,'multiline':False]
['text':' dim 0, M elems from the left','line_number':5299,'multiline':False]
['text':' dim 1, L elems from the right','line_number':5300,'multiline':False]
['text':' 3-dim','line_number':5302,'multiline':False]
['text':' dim 2, 0 elems from the left','line_number':5303,'multiline':False]
['text':' dim 2, 0 elems from the right','line_number':5304,'multiline':False]
['text':' dim 2, M elems from the left','line_number':5305,'multiline':False]
['text':' dim 2, M elems from the right','line_number':5306,'multiline':False]
['text':' dim 1, 0 elems from the left','line_number':5307,'multiline':False]
['text':' dim 0, 1 elem from the left','line_number':5308,'multiline':False]
['text':' dim 2, 4 elems from the right','line_number':5309,'multiline':False]
['text':' narrow also accepts the start argument being a Tensor','line_number':5316,'multiline':False]
['text':' 0-dim','line_number':5323,'multiline':False]
['text':' out of bounds dim','line_number':5328,'multiline':False]
['text':' narrow_copy_dense_cpu_out','line_number':5330,'multiline':False]
['text':' out of bounds dim (negative)','line_number':5338,'multiline':False]
['text':' out of bounds start','line_number':5343,'multiline':False]
['text':' out of bounds start (negative)','line_number':5347,'multiline':False]
['text':' out of bounds length','line_number':5352,'multiline':False]
['text':' out of bounds length (negative)','line_number':5356,'multiline':False]
['text':' narrow_copy_dense_cpu_out','line_number':5358,'multiline':False]
['text':' Test Tensor overload that was added for XLA. Start must be an 0-dim','line_number':5367,'multiline':False]
['text':' integral Tensor. narrow_copy doesn't have this overload.','line_number':5368,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/31558','line_number':5369,'multiline':False]
['text':' *1-dim* integral Tensor','line_number':5371,'multiline':False]
['text':' 0-dim *bool* Tensor (bools are not allowed)','line_number':5376,'multiline':False]
['text':' When 'trapezoid' is called with an empty input, it does not produce an output with requires_grad','line_number':5388,'multiline':False]
['text':' See Issue #{61619}','line_number':5389,'multiline':False]
['text':' ((6,0), (6,0), {}),','line_number':5390,'multiline':False]
['text':' When 'cumulative_trapezoid' is called with an empty input, it does not produce an output with requires_grad','line_number':5414,'multiline':False]
['text':' See Issue #{61619}','line_number':5415,'multiline':False]
['text':' ((6,0), (6,0), {}),','line_number':5416,'multiline':False]
['text':' With default args','line_number':5465,'multiline':False]
['text':' NumPy doesn't allow squeezing scalars','line_number':5506,'multiline':False]
['text':' Numpy doesn't allow specifying non-singular dimensions','line_number':5511,'multiline':False]
['text':' ignore','line_number':5522,'multiline':False]
['text':' mode == 'circular'','line_number':5563,'multiline':False]
['text':' test_dtypes fails on ASAN with for the case ab','line_number':5565,'multiline':False]
['text':' runtime error: load of value 190, which is not a valid value for type 'bool'','line_number':5566,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/pull/62814#issuecomment-894156562','line_number':5567,'multiline':False]
['text':' Reference Issue: https://github.com/pytorch/pytorch/issues/63034','line_number':5568,'multiline':False]
['text':' Default args','line_number':5588,'multiline':False]
['text':' mode == 'constant'','line_number':5594,'multiline':False]
['text':' Inherit sample inputs from nn.pad, but transform them to fit','line_number':5614,'multiline':False]
['text':' constant_pad_nd's interface','line_number':5615,'multiline':False]
['text':' NOTE: primTorch is more strict about the type of the fill value argument','line_number':5619,'multiline':False]
['text':' So we must cast it to the correct dtype','line_number':5620,'multiline':False]
['text':' create a helper function wrapping `make_tensor`','line_number':5693,'multiline':False]
['text':' not needed once OpInfo tests support Iterables','line_number':5725,'multiline':False]
['text':' Scalar tensor','line_number':5752,'multiline':False]
['text':' Test var_mean(Tensor self, bool unbiased=True) -> (Tensor, Tensor)','line_number':5822,'multiline':False]
['text':' Adds tricky permutations and permutations with noncontiguity','line_number':5906,'multiline':False]
['text':' The additional sample is to check additional values of lambd beyond the default','line_number':5922,'multiline':False]
['text':' value (what is already checked by sample_inputs_elementwise_unary)','line_number':5923,'multiline':False]
['text':' The additional sample is to check additional values of lambd beyond the default','line_number':5932,'multiline':False]
['text':' value (what is already checked by sample_inputs_elementwise_unary)','line_number':5933,'multiline':False]
['text':' Note that unlike softshrink, lambd is allowed to be negative for hardshrink','line_number':5934,'multiline':False]
['text':' The additional sample is to check additional values of min_val and max_val beyond the default','line_number':5944,'multiline':False]
['text':' value (what is already checked by sample_inputs_elementwise_unary)','line_number':5945,'multiline':False]
['text':' Vector operations','line_number':5967,'multiline':False]
['text':' sum','line_number':5968,'multiline':False]
['text':' outer','line_number':5969,'multiline':False]
['text':' Matrix operations','line_number':5971,'multiline':False]
['text':' col sum','line_number':5972,'multiline':False]
['text':' matmul','line_number':5973,'multiline':False]
['text':' matrix outer product','line_number':5974,'multiline':False]
['text':' Tensor operations','line_number':5976,'multiline':False]
['text':' batch matmul','line_number':5977,'multiline':False]
['text':' tensor matrix contraction','line_number':5978,'multiline':False]
['text':' non contiguous','line_number':5979,'multiline':False]
['text':' Test diagonals','line_number':5981,'multiline':False]
['text':' non-contiguous trace','line_number':5982,'multiline':False]
['text':' Test ellipsis','line_number':5984,'multiline':False]
['text':' broadcasting and oncontiguous cases','line_number':6030,'multiline':False]
['text':' scalar cases','line_number':6047,'multiline':False]
['text':' type promotion cases','line_number':6064,'multiline':False]
['text':' int x float','line_number':6065,'multiline':False]
['text':' NaN propagation','line_number':6079,'multiline':False]
['text':' shrink values to be in the interval [-1, +1] for better precision in gradgradcheck','line_number':6114,'multiline':False]
['text':' Scalar tensors and empty tensor','line_number':6127,'multiline':False]
['text':' test dtype kwarg','line_number':6135,'multiline':False]
['text':' shrink values to be in the interval [-1, +1] for better precision in gradgradcheck','line_number':6175,'multiline':False]
['text':' only Tensor, ignore other inputs','line_number':6184,'multiline':False]
['text':' Generates samples with keepdim = True','line_number':6188,'multiline':False]
['text':' test zero scalar tensor','line_number':6201,'multiline':False]
['text':' dim1 > dim2 is allowed','line_number':6246,'multiline':False]
['text':' negative dims are allowed','line_number':6248,'multiline':False]
['text':' out of bounds offset should return an empty tensor in diagonal and','line_number':6250,'multiline':False]
['text':' offset the diagonal in diag_embed','line_number':6251,'multiline':False]
['text':' make sure we can use non-sequential dims','line_number':6256,'multiline':False]
['text':' these are error inputs for diagonal','line_number':6266,'multiline':False]
['text':' Shapes for 2D Tensors','line_number':6275,'multiline':False]
['text':' Shapes for 3D Tensors','line_number':6278,'multiline':False]
['text':' We can programmatically figure out the right shape for src:','line_number':6286,'multiline':False]
['text':' It should be the same size as input.diagonal(other_args...)','line_number':6287,'multiline':False]
['text':' ignore_index is not supported for probabilities target','line_number':6330,'multiline':False]
['text':' make sure at least one item in target is not ignored','line_number':6352,'multiline':False]
['text':' Note: Operator is very sensitive at points near the','line_number':6361,'multiline':False]
['text':' start and end of domain and leads to NaN for float16','line_number':6362,'multiline':False]
['text':' if domain_eps is 1e-5.','line_number':6363,'multiline':False]
['text':' isin has two paths based on the size of elements and test_elements.','line_number':6379,'multiline':False]
['text':' if elements.numel() < 10 * pow(test_elements.numel(), 0.145):','line_number':6380,'multiline':False]
['text':' else:','line_number':6382,'multiline':False]
['text':' `self` and `mask` on CUDA but `value` is a CPU scalar tensor.','line_number':6420,'multiline':False]
['text':' `value` is not a 0-D tensor.','line_number':6425,'multiline':False]
['text':' downcasting complex value (scalar overload)','line_number':6428,'multiline':False]
['text':' downcasting complex value (tensor overload)','line_number':6431,'multiline':False]
['text':' `self` and `mask` on CPU but `value` is a CUDA scalar tensor.','line_number':6437,'multiline':False]
['text':' Since the accepted lower bound for input','line_number':6536,'multiline':False]
['text':' to mvlgamma depends on `p` argument,','line_number':6537,'multiline':False]
['text':' the following function computes the lower bound','line_number':6538,'multiline':False]
['text':' which we pass to `make_tensor`.','line_number':6539,'multiline':False]
['text':' Round-up minimum value for integral dtypes','line_number':6546,'multiline':False]
['text':' Since `mvlgamma` has multiple entries,','line_number':6553,'multiline':False]
['text':' there are multiple common skips for the additional','line_number':6554,'multiline':False]
['text':' entries. Following function is a helper to that end.','line_number':6555,'multiline':False]
['text':' outside domain values are hard error for mvlgamma op.','line_number':6558,'multiline':False]
['text':' Redundant tests','line_number':6570,'multiline':False]
['text':' type: ignore[assignment]','line_number':6571,'multiline':False]
['text':' To test reference numerics against multiple values of argument `p`,','line_number':6580,'multiline':False]
['text':' we make multiple OpInfo entries with each entry corresponding to different value of p.','line_number':6581,'multiline':False]
['text':' We run the op tests from test_ops.py only for `p=1` to avoid redundancy in testing.','line_number':6582,'multiline':False]
['text':' NOTE: if `dtype` is not same as input, then inplace variants fail with','line_number':6609,'multiline':False]
['text':' `provided dtype must match the dtype of self tensor in cumsum`','line_number':6610,'multiline':False]
['text':' type: ignore[assignment]','line_number':6656,'multiline':False]
['text':' Test case for large tensor.','line_number':6689,'multiline':False]
['text':' no broadcast','line_number':6699,'multiline':False]
['text':' broadcast rhs','line_number':6701,'multiline':False]
['text':' scalar tensor','line_number':6703,'multiline':False]
['text':' broadcast rhs scalar-tensor','line_number':6705,'multiline':False]
['text':' broadcast rhs with weight tensor','line_number':6707,'multiline':False]
['text':' broadcast rhs and weight tensor','line_number':6709,'multiline':False]
['text':' broadcast lhs','line_number':6711,'multiline':False]
['text':' scalar broadcast_lhs','line_number':6713,'multiline':False]
['text':' broadcast all','line_number':6715,'multiline':False]
['text':' tensor broadcast all','line_number':6717,'multiline':False]
['text':' no broadcast with weight tensor','line_number':6720,'multiline':False]
['text':' broadcast lhs with weight tensor','line_number':6722,'multiline':False]
['text':' broadcast lhs and weight tensor','line_number':6725,'multiline':False]
['text':' broadcast lhs and weight tensor variant','line_number':6728,'multiline':False]
['text':' no broadcast','line_number':6733,'multiline':False]
['text':' broadcast rhs','line_number':6736,'multiline':False]
['text':' scalar tensor','line_number':6739,'multiline':False]
['text':' broadcast rhs scalar-tensor','line_number':6742,'multiline':False]
['text':' Sample inputs to test edge cases for backward','line_number':6841,'multiline':False]
['text':' Check that gradients are propagated correctly for prod when zeros in self/src are reduced','line_number':6842,'multiline':False]
['text':' This sample tests gradients for the following cases','line_number':6844,'multiline':False]
['text':' (a) 1 zero reduced (from src (self[0, 1], self[1, 1]), from self (self[0, 0], self[2, 0]))','line_number':6845,'multiline':False]
['text':' (b) 2 zeros reduced (1 from src and 1 from self (self[1, 0])','line_number':6846,'multiline':False]
['text':' (c) no zeros reduced (self([2, 1]))','line_number':6847,'multiline':False]
['text':' (d) 2 zeros reduced (both from src) is tested in test/test_autograd.py','line_number':6848,'multiline':False]
['text':'     test_scatter_index_reduce_prod_gradgrad_error as this case is not supported for gradgrad','line_number':6849,'multiline':False]
['text':' inp_shape, dim, lengths, unsafe','line_number':6864,'multiline':False]
['text':' test when lengths do not sum to dim size','line_number':6869,'multiline':False]
['text':' test for higher dimensions','line_number':6871,'multiline':False]
['text':' error inputs for input.ndim <= 2','line_number':6981,'multiline':False]
['text':' (row, col, offset)','line_number':6985,'multiline':False]
['text':' Large test cases below are deliberately commented out to speed up CI','line_number':6992,'multiline':False]
['text':' tests and to avoid OOM error. When modifying implementations of','line_number':6993,'multiline':False]
['text':' tril_indices and triu_indices, please enable these tests and make sure','line_number':6994,'multiline':False]
['text':' they pass.','line_number':6995,'multiline':False]
['text':' (2, 68435455, 3),','line_number':6996,'multiline':False]
['text':' (5000, 5000),','line_number':6997,'multiline':False]
['text':' (5000, 5000, 1234),','line_number':6998,'multiline':False]
['text':' (5000, 5000, -1233),','line_number':6999,'multiline':False]
['text':' NOTE: the default memory format for clone is torch.preserve_format, for contiguous it's torch.contiguous_format','line_number':7011,'multiline':False]
['text':' This exploits that default to test torch.preserve_format for clone, without causing an error when testing contiguous','line_number':7012,'multiline':False]
['text':' shape, strides, offset','line_number':7036,'multiline':False]
['text':' channels last 2D','line_number':7050,'multiline':False]
['text':' channels last 3D','line_number':7055,'multiline':False]
['text':' list of tuples (shape, shape) defining the shapes of the input and output tensors','line_number':7064,'multiline':False]
['text':' Update `args` based on operator','line_number':7102,'multiline':False]
['text':' resize_ takes shape/tuple of ints,','line_number':7104,'multiline':False]
['text':' resize_as_ takes another tensor','line_number':7107,'multiline':False]
['text':' type:ignore[assignment]','line_number':7108,'multiline':False]
['text':' a, b, is_tensor_supported','line_number':7118,'multiline':False]
['text':' neg index','line_number':7121,'multiline':False]
['text':' neg index','line_number':7122,'multiline':False]
['text':' empty','line_number':7124,'multiline':False]
['text':' skip unsupported cases','line_number':7129,'multiline':False]
['text':' convert to tensor','line_number':7133,'multiline':False]
['text':' a, b, is_tensor_supported','line_number':7143,'multiline':False]
['text':' empty','line_number':7153,'multiline':False]
['text':' empty','line_number':7156,'multiline':False]
['text':' empty','line_number':7158,'multiline':False]
['text':' neg index, empty','line_number':7162,'multiline':False]
['text':' neg index','line_number':7163,'multiline':False]
['text':' skip unsupported cases','line_number':7168,'multiline':False]
['text':' convert to tensor','line_number':7173,'multiline':False]
['text':' skip unsupported cases','line_number':7181,'multiline':False]
['text':' convert to tensor','line_number':7185,'multiline':False]
['text':' a, b, is_tensor_supported','line_number':7194,'multiline':False]
['text':' Reshape to different numel','line_number':7195,'multiline':False]
['text':' empty','line_number':7196,'multiline':False]
['text':' empty','line_number':7197,'multiline':False]
['text':' No valid inference','line_number':7200,'multiline':False]
['text':' neg index','line_number':7201,'multiline':False]
['text':' Two inferred shapes','line_number':7202,'multiline':False]
['text':' neg index','line_number':7203,'multiline':False]
['text':' neg index','line_number':7204,'multiline':False]
['text':' neg index','line_number':7205,'multiline':False]
['text':' skip unsupported cases','line_number':7210,'multiline':False]
['text':' to avoid having issues with a regex','line_number':7221,'multiline':False]
['text':' convert to tensor','line_number':7226,'multiline':False]
['text':' type: ignore[assignment]','line_number':7243,'multiline':False]
['text':' shape x start_dim x end_dim','line_number':7262,'multiline':False]
['text':' in_shape, dim, sizes','line_number':7286,'multiline':False]
['text':' Make sure atleast one element is nonzero,','line_number':7399,'multiline':False]
['text':' except for empty tensor','line_number':7400,'multiline':False]
['text':' TODO: add reference inputs for where(condition) signature','line_number':7431,'multiline':False]
['text':' noncontiguous','line_number':7438,'multiline':False]
['text':' NOTE that the OpInfo for where takes samples of the form a, cond, b','line_number':7443,'multiline':False]
['text':' type promoting','line_number':7446,'multiline':False]
['text':' two python scalars','line_number':7454,'multiline':False]
['text':' NaN propagation','line_number':7461,'multiline':False]
['text':' dtype.is_complex','line_number':7466,'multiline':False]
['text':' Python scalars type promotion','line_number':7476,'multiline':False]
['text':' construct input without any non-zero elements','line_number':7499,'multiline':False]
['text':' construct input with mixed zero and non-zero elements','line_number':7503,'multiline':False]
['text':' construct input without any non-zero elements','line_number':7520,'multiline':False]
['text':' construct input with mixed zero and non-zero elements','line_number':7524,'multiline':False]
['text':' shape x chunks x dim','line_number':7552,'multiline':False]
['text':' tests overlapping output fails','line_number':7592,'multiline':False]
['text':' This is to handle special case for feature_alpha_dropout which has different','line_number':7615,'multiline':False]
['text':' supported dtypes depending on `train` parameter','line_number':7616,'multiline':False]
['text':' a tensor of float / double weights, or None','line_number':7642,'multiline':False]
['text':' to indicate all weights should be taken to be 1','line_number':7643,'multiline':False]
['text':' per_sample_weights is only supported for mode='sum' (got mode='****')','line_number':7651,'multiline':False]
['text':' 1-D index tensor','line_number':7655,'multiline':False]
['text':' bag with zero length','line_number':7668,'multiline':False]
['text':' 2-D index tensor','line_number':7676,'multiline':False]
['text':' The gradient vector at `padding_idx` is not updated.','line_number':7687,'multiline':False]
['text':' Negative padding_idx','line_number':7688,'multiline':False]
['text':' Positive padding_idx','line_number':7698,'multiline':False]
['text':' Following inputs return different gradient from the numerical gradient.','line_number':7714,'multiline':False]
['text':' This is expected and relevant tests are present in `test_nn.py`.','line_number':7715,'multiline':False]
['text':' Due to inplace renorming of weight, the numerical gradient doesn't match the','line_number':7717,'multiline':False]
['text':' analytical gradient.','line_number':7718,'multiline':False]
['text':' Scale the gradient based on the inverse frequency of a particular index.','line_number':7735,'multiline':False]
['text':' Note : smax mode does not support sparse weights','line_number':7736,'multiline':False]
['text':' gradcheck not implemented for sparse tensors.','line_number':7746,'multiline':False]
['text':' Note : max mode does not support sparse weights','line_number':7747,'multiline':False]
['text':' freq more than 1','line_number':7756,'multiline':False]
['text':' freq more than 1','line_number':7757,'multiline':False]
['text':' padding_idx','line_number':7758,'multiline':False]
['text':' 0-D index tensor','line_number':7774,'multiline':False]
['text':' 1-D index tensor','line_number':7778,'multiline':False]
['text':' 2-D index tensor','line_number':7782,'multiline':False]
['text':' Following inputs return different gradient from the numerical gradient.','line_number':7787,'multiline':False]
['text':' This is expected and relevant tests are present in `test_nn.py`.','line_number':7788,'multiline':False]
['text':' The gradient vector at `padding_idx` is not updated.','line_number':7790,'multiline':False]
['text':' Due to inplace renorming of weight, the numerical gradient doesn't match the','line_number':7801,'multiline':False]
['text':' analytical gradient.','line_number':7802,'multiline':False]
['text':' Scale the gradient based on the inverse frequency of a particular index.','line_number':7811,'multiline':False]
['text':' gradcheck not implemented for sparse tensors.','line_number':7818,'multiline':False]
['text':' freq more than 1','line_number':7824,'multiline':False]
['text':' freq more than 1','line_number':7825,'multiline':False]
['text':' padding_idx','line_number':7826,'multiline':False]
['text':' Although most losses also support the reduce and size_average combination instead of reduce, the former is','line_number':7857,'multiline':False]
['text':' deprecated since 0.4.1 and thus is not tested','line_number':7858,'multiline':False]
['text':' We get better tests if we change the range of the values to something like [-2,2]','line_number':7874,'multiline':False]
['text':' because for grid (second tensor argument) the "useful" range is [-1,1] and this way','line_number':7875,'multiline':False]
['text':' you get a better combination of out-of-range and in-range test cases','line_number':7876,'multiline':False]
['text':' Create an affine transformation matrix','line_number':7909,'multiline':False]
['text':' rotation angles','line_number':7911,'multiline':False]
['text':' scales','line_number':7912,'multiline':False]
['text':' We get better tests if we change the range of the values to something like [-2,2]','line_number':7938,'multiline':False]
['text':' because for grid (second tensor argument) the "useful" range is [-1,1] and this way','line_number':7939,'multiline':False]
['text':' you get a better combination of out-of-range and in-range test cases','line_number':7940,'multiline':False]
['text':' Label with -1 or 1','line_number':7965,'multiline':False]
['text':' Dont generate int[] types if reduction = "Mean" since this results in non composite compliant calls','line_number':7999,'multiline':False]
['text':' to ctc_loss.IntList since a tensor needs to be created from the target lengths.','line_number':8000,'multiline':False]
['text':' Creating such a tensor requires the use of pointers to copy data from int[] -> torch.Tensor','line_number':8001,'multiline':False]
['text':' e.g. via std::copy. Similarly symbolic/real tracing with fx will also not work','line_number':8002,'multiline':False]
['text':' FIXME: Derivative wrt. weight not implemented','line_number':8013,'multiline':False]
['text':' Batched, non-batched and 2d','line_number':8029,'multiline':False]
['text':' If "mean", nll returns NaN, so it's not differentiable at those points','line_number':8039,'multiline':False]
['text':' Test ignoring all the targets','line_number':8044,'multiline':False]
['text':' If "mean", nll returns NaN, so it's not differentiable at those points','line_number':8045,'multiline':False]
['text':' Set low slightly above 0 so gradcheck doesn't accidentally dip below 0','line_number':8112,'multiline':False]
['text':' Broadcast','line_number':8117,'multiline':False]
['text':' invalid reduction value','line_number':8144,'multiline':False]
['text':' var is of incorrect shape','line_number':8148,'multiline':False]
['text':' target is of incorrect shape','line_number':8152,'multiline':False]
['text':' target should contain either 1 or -1 as per docs','line_number':8166,'multiline':False]
['text':' scalar input and target.','line_number':8173,'multiline':False]
['text':' invalid reduction value','line_number':8179,'multiline':False]
['text':' only supports ints and floats','line_number':8188,'multiline':False]
['text':' NaN propagation','line_number':8189,'multiline':False]
['text':' target should contain either 1 or -1 as per docs','line_number':8193,'multiline':False]
['text':' Inf Handling','line_number':8199,'multiline':False]
['text':' Broadcasting','line_number':8208,'multiline':False]
['text':' invalid reduction value','line_number':8223,'multiline':False]
['text':' delta <= 0','line_number':8227,'multiline':False]
['text':' For Poisson NLL Loss,','line_number':8242,'multiline':False]
['text':' target is assumed to be from','line_number':8243,'multiline':False]
['text':' Poisson Distribution which','line_number':8244,'multiline':False]
['text':' always has positive samples','line_number':8245,'multiline':False]
['text':' test INT_TO_FLOAT promotion','line_number':8269,'multiline':False]
['text':' invalid reduction value','line_number':8278,'multiline':False]
['text':' invalid input shapes','line_number':8283,'multiline':False]
['text':' invalid reduction value','line_number':8293,'multiline':False]
['text':' invalid input shapes','line_number':8298,'multiline':False]
['text':' input, args, kwargs, error_type, error_regex','line_number':8325,'multiline':False]
['text':' invalid reduction','line_number':8326,'multiline':False]
['text':' shape mismatch','line_number':8331,'multiline':False]
['text':' different dimensions','line_number':8351,'multiline':False]
['text':' two e4m3','line_number':8381,'multiline':False]
['text':' mat1 e4m3 mat2 e5m2','line_number':8385,'multiline':False]
['text':' mat1 e5m2 mat2 e4m3','line_number':8389,'multiline':False]
['text':' Add non standard shapes','line_number':8420,'multiline':False]
['text':' Add an attn_mask','line_number':8429,'multiline':False]
['text':' UpperLeft, LowerRight','line_number':8454,'multiline':False]
['text':' Add non standard shapes','line_number':8477,'multiline':False]
['text':' No Mask','line_number':8488,'multiline':False]
['text':' Add an attn_mask','line_number':8495,'multiline':False]
['text':' No Mask','line_number':8507,'multiline':False]
['text':' Lower bounds must be greater than 'eps' defined in gradcheck.py::gradgradcheck() -> eps','line_number':8600,'multiline':False]
['text':' otherwise perturbation calculation causes Tensor value to become negative triggering','line_number':8601,'multiline':False]
['text':' a device-side hardware assertion','line_number':8602,'multiline':False]
['text':' close sample','line_number':8631,'multiline':False]
['text':' random sample','line_number':8636,'multiline':False]
['text':' test COMPLEX_TO_FLOAT promotion','line_number':8645,'multiline':False]
['text':' invalid reduction value','line_number':8654,'multiline':False]
['text':' invalid input shapes','line_number':8659,'multiline':False]
['text':' This test case always triggers the smooth condition, since absolute difference of input and target','line_number':8672,'multiline':False]
['text':' is smaller than beta','line_number':8673,'multiline':False]
['text':' kl_div works with inputs in [0, 1] (aka the pdf of a probability measure)','line_number':8678,'multiline':False]
['text':' Then log [0, 1] = (-inf, 0], so this is the log space','line_number':8679,'multiline':False]
['text':' shapes (C, ...) do not work as of now,','line_number':8746,'multiline':False]
['text':' see https://github.com/pytorch/pytorch/issues/68337','line_number':8747,'multiline':False]
['text':' TODO: remove once the issue is resolved','line_number':8748,'multiline':False]
['text':' No dilation > 1 for max_unpool,','line_number':8752,'multiline':False]
['text':' see https://github.com/pytorch/pytorch/issues/68420','line_number':8753,'multiline':False]
['text':' Can't unpool without indices','line_number':8757,'multiline':False]
['text':' arg has to be a leaf','line_number':8760,'multiline':False]
['text':' output_size could be None but we specify it explicitly','line_number':8766,'multiline':False]
['text':' to compensate for the information lose in pool due','line_number':8767,'multiline':False]
['text':' to the floor/ceil operation used to compute the shapes','line_number':8768,'multiline':False]
['text':' The samples for max_unpool are generated with max_pool.','line_number':8777,'multiline':False]
['text':' It could be that a single element from the max_pool's','line_number':8778,'multiline':False]
['text':' input is mapped to several locations in its output.','line_number':8779,'multiline':False]
['text':' This situation leads to failed gradchecks because','line_number':8780,'multiline':False]
['text':' the finite difference algorithm perturbs the elements','line_number':8781,'multiline':False]
['text':' of the output one by one, and not in classes of','line_number':8782,'multiline':False]
['text':' equivalences determined by whether two elements','line_number':8783,'multiline':False]
['text':' in the output are coming from the same location in the','line_number':8784,'multiline':False]
['text':' input (simply put, they have the same corresponding index).','line_number':8785,'multiline':False]
['text':' So, there are two ways to resolve this issue:','line_number':8786,'multiline':False]
['text':' 1. Extract a perturbation for one element and apply it all','line_number':8787,'multiline':False]
['text':'    the elements from the same equivalence class, or','line_number':8788,'multiline':False]
['text':' 2. Make sure that the equivalence classes are all singletons,','line_number':8789,'multiline':False]
['text':' i.e. the index tensor has to be comprised of only unique','line_number':8790,'multiline':False]
['text':' indices.','line_number':8791,'multiline':False]
['text':' Here we go with the solution 2, the easiest of all.','line_number':8792,'multiline':False]
['text':' backward tests would take too long to complete, causing the job timeout.','line_number':8800,'multiline':False]
['text':' Includes some values such that N * N won't be a multiple of 4,','line_number':8871,'multiline':False]
['text':' which should ensure we test the vectorized and non-vectorized','line_number':8872,'multiline':False]
['text':' kernel code paths.','line_number':8873,'multiline':False]
['text':' For TensorList <op> Scalar/Tensor, we compute the reference','line_number':8887,'multiline':False]
['text':' by converting it into TensorList <op> ScalarList/TensorList and','line_number':8888,'multiline':False]
['text':' then converting into multiple Tensor <op> Scalar/Tensor.','line_number':8889,'multiline':False]
['text':' ref_args contains the args converted to TensorList <op> ScalarList/TensorList','line_number':8890,'multiline':False]
['text':' unary','line_number':8969,'multiline':False]
['text':' add empty tensor interspersion to test fully fixing #100701','line_number':9067,'multiline':False]
['text':' generate interspersed empty tensors for only 1 N on non-cpu device to lessen redundancy','line_number':9071,'multiline':False]
['text':' zero_size tensor','line_number':9164,'multiline':False]
['text':' due to https://github.com/pytorch/pytorch/pull/102427 enabling jiterator for complex','line_number':9249,'multiline':False]
['text':' These tests fail with aten._local_scalar_dense not being implemented.','line_number':9418,'multiline':False]
['text':' Samples have complex types and inplace only works if the dtype is complex.','line_number':9421,'multiline':False]
['text':' Samples have complex types and inplace only works if the dtype is complex.','line_number':9453,'multiline':False]
['text':' Samples have complex types and inplace only works if the dtype is complex.','line_number':9470,'multiline':False]
['text':' fails with div_cpu is not implemented with ComplexHalf','line_number':9479,'multiline':False]
['text':' note(crcrpar): forward ad not implemented.','line_number':9522,'multiline':False]
['text':' note(crcrpar): forward ad not implemented.','line_number':9541,'multiline':False]
['text':' `np.sign` doesn't support `bool`.','line_number':9657,'multiline':False]
['text':' >>> np.sign(True)','line_number':9658,'multiline':False]
['text':' ufunc 'sign' did not contain a loop','line_number':9659,'multiline':False]
['text':' with signature matching types dtype('bool') -> dtype('bool')','line_number':9660,'multiline':False]
['text':' NumPy doesn't have an equivalent to `torch.sgn` when the dtype is complex.','line_number':9666,'multiline':False]
['text':' For complex inputs, `np.sign` returns sign(x.real) + 0j if x.real != 0 else sign(x.imag) + 0j.','line_number':9667,'multiline':False]
['text':' while `torch.sgn` returns, 0 if abs(input) == 0 else input/abs(input)','line_number':9668,'multiline':False]
['text':' Handle x == 0 case','line_number':9674,'multiline':False]
['text':' Can't assign to np.complex object','line_number':9676,'multiline':False]
['text':' So make a new one.','line_number':9677,'multiline':False]
['text':' Handle x == 0 case','line_number':9681,'multiline':False]
['text':' 'scipy.special.expit' not supported for the input types','line_number':9688,'multiline':False]
['text':' scipy.special.gammaln returns `-inf` when input is `-inf`.','line_number':9708,'multiline':False]
['text':' While Pytorch, C and C++, all return `inf` when input is `-inf`.','line_number':9709,'multiline':False]
['text':' Reference:','line_number':9710,'multiline':False]
['text':' https://en.cppreference.com/w/cpp/numeric/math/lgamma','line_number':9711,'multiline':False]
['text':' https://en.cppreference.com/w/c/numeric/math/lgamma','line_number':9712,'multiline':False]
['text':' To handle the above discrepancy,','line_number':9714,'multiline':False]
['text':' we replace -inf with inf so values','line_number':9715,'multiline':False]
['text':' that were originally -inf map to inf as expected','line_number':9716,'multiline':False]
['text':' `scipy.special.gammaln` returns output of float32 when input is float16,','line_number':9723,'multiline':False]
['text':' while `torch.lgamma` preserves `float16`. But due to smaller range of float16,','line_number':9724,'multiline':False]
['text':' Pytorch version outputs `inf` while SciPy returns finite values.','line_number':9725,'multiline':False]
['text':' reduction == "none"','line_number':9774,'multiline':False]
['text':' We need to call mark step inside freeze_rng_state so that numerics','line_number':9787,'multiline':False]
['text':' match eager execution','line_number':9788,'multiline':False]
['text':' type: ignore[call-overload]','line_number':9800,'multiline':False]
['text':' weight is a vector of length equal to the channel','line_number':9824,'multiline':False]
['text':' bias is a vector of length equal to the channel','line_number':9829,'multiline':False]
['text':' using a custom reference function since numpy only has a string side arg (instead of right and side) and doesn't','line_number':9836,'multiline':False]
['text':' have an out_int32 arg. Additionally, numpy doesn't support searchsorted with ND arrays, so this splits those into','line_number':9837,'multiline':False]
['text':' stacked 1D cases','line_number':9838,'multiline':False]
['text':' numpy searchsorted only supports 1D inputs so we split up ND inputs','line_number':9851,'multiline':False]
['text':' reduction == "none"','line_number':9879,'multiline':False]
['text':' Currently, calling std with correction is only enabled when','line_number':9918,'multiline':False]
['text':' both dim and keepdim are provided.','line_number':9919,'multiline':False]
['text':' numpy implementation of torch.flatten','line_number':9971,'multiline':False]
['text':' unfortunately there's no np.flatten. we figure out the desired shape and call np.reshape','line_number':9972,'multiline':False]
['text':' Operator database (sorted alphabetically)','line_number':9989,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/49224','line_number':10005,'multiline':False]
['text':' TODO: Fix test_out_arg_all_dtypes as torch.empty_like(expected_output) where expected_output=op(input)','line_number':10008,'multiline':False]
['text':' We can break the logic of the loop over all possible types but it is OK.','line_number':10009,'multiline':False]
['text':' https://github.com/pytorch/pytorch/blob/master/test/test_unary_ufuncs.py#L440-L449','line_number':10010,'multiline':False]
['text':' NOTE: CPU complex acos produces incorrect outputs (https://github.com/pytorch/pytorch/issues/42952)','line_number':10030,'multiline':False]
['text':' Failing with wrong imaginary sign on at least some Windows jobs','line_number':10049,'multiline':False]
['text':' Failing with wrong imaginary sign on at least some Windows jobs','line_number':10053,'multiline':False]
['text':' NOTE: the derivative for inplace acosh is not implemented','line_number':10071,'multiline':False]
['text':' Failing with wrong imaginary sign on at least some Windows jobs','line_number':10098,'multiline':False]
['text':' acosh is not defined at x < 1 (real)','line_number':10103,'multiline':False]
['text':' NumPy has no builtin reference for the alpha kwarg, but it is easy enough to emulate','line_number':10108,'multiline':False]
['text':' boolean alpha not handled properly','line_number':10124,'multiline':False]
['text':' Error testing item function variant','line_number':10148,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':10151,'multiline':False]
['text':' RuntimeError: Composite compliance check failed with the above error.','line_number':10153,'multiline':False]
['text':' Booleans mismatch: AssertionError: False is not true','line_number':10155,'multiline':False]
['text':' Booleans mismatch: AssertionError: False is not true','line_number':10157,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/81774','line_number':10168,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':10171,'multiline':False]
['text':' Lazy tensor failures','line_number':10177,'multiline':False]
['text':' Exception raised from analyzeImpl at ../torch/csrc/jit/ir/alias_analysis.cpp:608','line_number':10182,'multiline':False]
['text':' We don't have an op for aten::arange but it isn't a special case.','line_number':10183,'multiline':False]
['text':' Argument types: bool, bool, bool, int, int, Device, boo','line_number':10184,'multiline':False]
['text':' Captured graph does not contain aten::arange (succeeds on complex!)','line_number':10187,'multiline':False]
['text':' g: graph():','line_number':10188,'multiline':False]
['text':'   %25 : Long(1, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value={1}]()','line_number':10189,'multiline':False]
['text':'   return (%25)','line_number':10190,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':10193,'multiline':False]
['text':' Tests that assume input tensor has a meaningful effect on output tensor','line_number':10205,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':10209,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':10212,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':10215,'multiline':False]
['text':' vmap: calling random operator not supported','line_number':10218,'multiline':False]
['text':' Tests that assume input tensor has a meaningful effect on output tensor','line_number':10235,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':10239,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':10242,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':10245,'multiline':False]
['text':' vmap: calling random operator not supported','line_number':10248,'multiline':False]
['text':' Tests that assume input tensor has a meaningful effect on output tensor','line_number':10264,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':10268,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':10271,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':10274,'multiline':False]
['text':' vmap: calling random operator not supported','line_number':10277,'multiline':False]
['text':' Tests that assume input tensor has a meaningful effect on output tensor','line_number':10292,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':10296,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':10299,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':10301,'multiline':False]
['text':' vmap: calling random operator not supported','line_number':10304,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':10319,'multiline':False]
['text':' Tests that assume input tensor has a meaningful effect on output tensor','line_number':10322,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':10328,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':10330,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':10332,'multiline':False]
['text':' vmap: calling random operator not supported','line_number':10334,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':10349,'multiline':False]
['text':' Tests that assume input tensor has a meaningful effect on output tensor','line_number':10351,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':10356,'multiline':False]
['text':' aten.uniform was not decomposed','line_number':10358,'multiline':False]
['text':' RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'','line_number':10370,'multiline':False]
['text':' dispatch to lazy test failed','line_number':10375,'multiline':False]
['text':' test error disabled since rhs non-tensor python scalar is supported','line_number':10377,'multiline':False]
['text':' RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'','line_number':10388,'multiline':False]
['text':' dispatch to lazy test failed','line_number':10393,'multiline':False]
['text':' test error disabled since rhs non-tensor python scalar is supported','line_number':10395,'multiline':False]
['text':' NumPy has no builtin reference for the alpha kwarg, but it is easy enough to emulate','line_number':10412,'multiline':False]
['text':' This addmm OpInfo is for when alpha and beta are not both equal to 1.','line_number':10448,'multiline':False]
['text':' alpha=beta=1 is tested in the following opinfo, because that special case will','line_number':10449,'multiline':False]
['text':' trigger addmm being decomposed by a jit pass.','line_number':10450,'multiline':False]
['text':' Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479','line_number':10460,'multiline':False]
['text':' When alpha=beta=1 as compile-time constants, JIT will decompose addmm into mm and add.','line_number':10468,'multiline':False]
['text':' Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479','line_number':10479,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/71784','line_number':10485,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':10509,'multiline':False]
['text':' MPS has slightly worse precision. Is this acceptable?','line_number':10518,'multiline':False]
['text':' NVIDIA only assures that bfloat16 is supported by bmm if SM >= 5.3','line_number':10536,'multiline':False]
['text':' addbmm does not correctly warn when resizing out= inputs','line_number':10538,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/55907','line_number':10540,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':10551,'multiline':False]
['text':' Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479','line_number':10565,'multiline':False]
['text':' Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479','line_number':10581,'multiline':False]
['text':' Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479','line_number':10596,'multiline':False]
['text':' NVIDIA only assures that bfloat16 is supported by bmm if SM >= 5.3','line_number':10613,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/50747','line_number':10628,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/50747','line_number':10632,'multiline':False]
['text':' TODO: update sample inputs with for_inplace_variant kwarg to support this test','line_number':10644,'multiline':False]
['text':' TODO: update sample inputs with for_inplace_variant kwarg to support this test','line_number':10655,'multiline':False]
['text':' NOTE: derivative for inplace asinh is not implemented','line_number':10698,'multiline':False]
['text':' Incorrectly attempts to use a scalar for the second argument','line_number':10775,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':10830,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/64997','line_number':10844,'multiline':False]
['text':' skip dtype tests since broadcast_shape is not device dependent.','line_number':10846,'multiline':False]
['text':' having dtypes limited to torch.float32 would cause test_dtypes to report unexpected success','line_number':10847,'multiline':False]
['text':' skip these tests since we have non tensor input','line_number':10849,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':10862,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/64997','line_number':10865,'multiline':False]
['text':' JIT does not support variadic tensors.','line_number':10867,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalType','line_number':10868,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,','line_number':10869,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':10870,'multiline':False]
['text':' Default batching rule in core doesn't work for ops with TensorList args','line_number':10878,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/64997','line_number':10881,'multiline':False]
['text':' JIT does not support variadic tensors.','line_number':10883,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalType','line_number':10884,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,','line_number':10885,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':10886,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/70904','line_number':10906,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/70904','line_number':10920,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':10928,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':10938,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalType','line_number':10945,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270','line_number':10946,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':10981,'multiline':False]
['text':' Strides are not the same! Original strides were ((4, 2, 1),) and strides are now ((4, 1, 2),)','line_number':10990,'multiline':False]
['text':' TypeError: _copy_dispatcher() got an unexpected keyword argument 'memory_format'','line_number':11025,'multiline':False]
['text':' (NumPy reference needs to be extended with memory_format)','line_number':11026,'multiline':False]
['text':' lambda impl','line_number':11052,'multiline':False]
['text':' NNC appear to not handle boolean clamp','line_number':11066,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':11091,'multiline':False]
['text':' RuntimeError: inputSet && outputSet','line_number':11107,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":118,','line_number':11108,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':11109,'multiline':False]
['text':' RuntimeError: Tensor must have a last dimension with stride 1','line_number':11144,'multiline':False]
['text':' RuntimeError: "eq_cpu" not implemented for 'ComplexHalf'','line_number':11146,'multiline':False]
['text':' RuntimeError: view size is not compatible with input tensor's size and stride','line_number':11148,'multiline':False]
['text':' Tests don't account for complex's type promotion semantics','line_number':11158,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':11165,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':11174,'multiline':False]
['text':' Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479','line_number':11177,'multiline':False]
['text':' This fails on CUDA but passes on ROCm','line_number':11198,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':11206,'multiline':False]
['text':' Greatest absolute difference: nan at index (700,) (up to 1e-05 allowed)','line_number':11207,'multiline':False]
['text':' Greatest relative difference: nan at index (700,) (up to 0.001 allowed)','line_number':11208,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/48641','line_number':11222,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':11237,'multiline':False]
['text':' Greatest absolute difference: nan at index (6000,) (up to 1e-05 allowed)','line_number':11238,'multiline':False]
['text':' Greatest relative difference: nan at index (6000,) (up to 0.001 allowed)','line_number':11239,'multiline':False]
['text':' Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479','line_number':11252,'multiline':False]
['text':' Float did not match double','line_number':11258,'multiline':False]
['text':' Jacobian mismatch','line_number':11260,'multiline':False]
['text':' JIT test not working for tensor kwargs (https://github.com/pytorch/pytorch/issues/58507)','line_number':11264,'multiline':False]
['text':' RuntimeError:','line_number':11265,'multiline':False]
['text':' undefined value tensor:','line_number':11266,'multiline':False]
['text':'   File "<string>", line 3','line_number':11267,'multiline':False]
['text':' def the_method(i0):','line_number':11268,'multiline':False]
['text':'     return torch.cov(i0, correction=0, fweights=None, aweights=tensor([0.0518, 0.4681], dtype=torch.float32, requires_grad=True)) # noqa: B950','line_number':11269,'multiline':False]
['text':'                                                                ~~~~~~ <--- HERE','line_number':11270,'multiline':False]
['text':' cumsum does not handle correctly out= dtypes','line_number':11284,'multiline':False]
['text':' cumprod does not handle correctly out= dtypes','line_number':11293,'multiline':False]
['text':' gradgradcheck fails in fast_mode=True: #56275','line_number':11296,'multiline':False]
['text':' np.diff has np._NoValue as default values for prepend and append, compare_with_reference breaks if prepend/append','line_number':11330,'multiline':False]
['text':' are set as None when converting to numpy','line_number':11331,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':11336,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':11342,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':11351,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':11364,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/111126','line_number':11372,'multiline':False]
['text':' RuntimeError: MALFORMED INPUT: Unhandled node kind (in computeValue): aten::div','line_number':11376,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':11384,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/111126','line_number':11392,'multiline':False]
['text':' RuntimeError: MALFORMED INPUT: Unhandled node kind (in computeValue): aten::div','line_number':11396,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/48010','line_number':11420,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':11463,'multiline':False]
['text':' RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'','line_number':11507,'multiline':False]
['text':' RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'','line_number':11517,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':11524,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':11548,'multiline':False]
['text':' Fails on XLA','line_number':11573,'multiline':False]
['text':' False is not true : Tensors failed to compare as equal!','line_number':11574,'multiline':False]
['text':' Attempted to compare equality of tensors with different dtypes','line_number':11575,'multiline':False]
['text':' 76047','line_number':11593,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':11605,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':11618,'multiline':False]
['text':' gradcheck fails on ROCm (gh-68429)','line_number':11632,'multiline':False]
['text':' grad is computed improperly (probably for weights tensor)','line_number':11633,'multiline':False]
['text':' Pre-existing condition (calls .item); needs to be fixed','line_number':11635,'multiline':False]
['text':' NotImplementedError: Tensors of type SparseCsrTensorImpl do not have is_contiguous','line_number':11688,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides.','line_number':11690,'multiline':False]
['text':' RuntimeError: sampled_addmm: Expected result to have sparse csr layout, but got Strided','line_number':11693,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11695,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11697,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11699,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11701,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11703,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11705,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11707,'multiline':False]
['text':' RuntimeError: unsupported memory format option Preserve','line_number':11709,'multiline':False]
['text':' RuntimeError: sparse_mask does not support automatic differentiation for outputs with complex dtype','line_number':11711,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11712,'multiline':False]
['text':' ValueError: Sparse output is not supported at gradcheck yet. Please call to_dense(masked_grad=...) ...','line_number':11714,'multiline':False]
['text':' RuntimeError: sparse_mask does not support automatic differentiation for outputs with complex dtype.','line_number':11716,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have is_contiguous','line_number':11717,'multiline':False]
['text':' ValueError: Sparse output is not supported at gradcheck yet. Please call to_dense(masked_grad=...) ...','line_number':11719,'multiline':False]
['text':' NotImplementedError: Tensors of type SparseCsrTensorImpl do not have is_contiguous','line_number':11732,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides.','line_number':11734,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11736,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11738,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11740,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11742,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11744,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11746,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11748,'multiline':False]
['text':' RuntimeError: unsupported memory format option Preserve','line_number':11750,'multiline':False]
['text':' ValueError: Sparse output is not supported at gradcheck yet. Please call to_dense(masked_grad=...) ...','line_number':11752,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have is_contiguou','line_number':11754,'multiline':False]
['text':' ValueError: Sparse output is not supported at gradcheck yet. Please call to_dense(masked_grad=...) ...','line_number':11756,'multiline':False]
['text':' RuntimeError: Sparse CSR tensors do not have strides','line_number':11758,'multiline':False]
['text':' ValueError: Sparse output is not supported at gradcheck yet. Please call to_dense(masked_grad=...) ...','line_number':11760,'multiline':False]
['text':' AssertionError: Results of original model and exported/imported version of model differed','line_number':11786,'multiline':False]
['text':' bfloat16 floor_divide compared with a float32 reference works inconsistently','line_number':11788,'multiline':False]
['text':' int8 floor divide has different results for -128 // -1 vs. NumPy','line_number':11791,'multiline':False]
['text':' The following tests fails on some jobs','line_number':11794,'multiline':False]
['text':' skip testing torch.frexp as it is not supported by ROCm platform yet','line_number':11805,'multiline':False]
['text':' skips below tests as torch.frexp returns tuple-like (mantissa, exponent) as outputs,','line_number':11810,'multiline':False]
['text':' while theses tests currently requires output to a single tensor.','line_number':11811,'multiline':False]
['text':' skips test_reference_numerics due to error in Windows CI.','line_number':11819,'multiline':False]
['text':' The np.frexp returns exponent as np.intc dtype on Windows platform,','line_number':11820,'multiline':False]
['text':' and np.intc does not have the correspond torch dtype','line_number':11821,'multiline':False]
['text':' FIXME: geqrf can't forward with complex inputs that require grad','line_number':11858,'multiline':False]
['text':' Strides are not the same!','line_number':11860,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/66357','line_number':11877,'multiline':False]
['text':' RuntimeError: view_as_real doesn't work on unresolved conjugated tensors.','line_number':11878,'multiline':False]
['text':' Skip since real and imag don't have out variants.','line_number':11881,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':11891,'multiline':False]
['text':' following tests give a runtime error with undefined value tensor','line_number':11895,'multiline':False]
['text':' see discussion : https://github.com/pytorch/pytorch/issues/56660','line_number':11896,'multiline':False]
['text':' RuntimeError:','line_number':11897,'multiline':False]
['text':' Arguments for call are not valid.','line_number':11898,'multiline':False]
['text':' noqa: B950','line_number':11899,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':11934,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':11936,'multiline':False]
['text':' Same failure as arange: cannot find linspace in captured graph','line_number':11942,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':11945,'multiline':False]
['text':' UserWarning: CUDA caching allocator reports a memory leak not verified by the driver API','line_number':11947,'multiline':False]
['text':' in __main__.TestJitCUDA.test_variant_consistency_jit_logspace_cuda_complex64!','line_number':11948,'multiline':False]
['text':' Caching allocator allocated memory was 0 and is now reported as 307200 on device 0.','line_number':11949,'multiline':False]
['text':' CUDA driver allocated memory was 1254555648 and is now 1242955776.','line_number':11950,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':11963,'multiline':False]
['text':' TypeError: 'int' object is not subscriptable','line_number':11965,'multiline':False]
['text':' Same failure as arange: cannot find linspace in captured graph','line_number':11970,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':11973,'multiline':False]
['text':' UserWarning: CUDA caching allocator reports a memory leak not verified by the driver API','line_number':11975,'multiline':False]
['text':' in __main__.TestJitCUDA.test_variant_consistency_jit_logspace_cuda_complex64!','line_number':11976,'multiline':False]
['text':' Caching allocator allocated memory was 0 and is now reported as 307200 on device 0.','line_number':11977,'multiline':False]
['text':' CUDA driver allocated memory was 1254555648 and is now 1242955776.','line_number':11978,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':11990,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':11992,'multiline':False]
['text':' Same failure as arange: cannot find linspace in captured graph','line_number':11997,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':12000,'multiline':False]
['text':' Off-by-one issue when casting floats to ints','line_number':12003,'multiline':False]
['text':' UserWarning: CUDA caching allocator reports a memory leak not verified by the driver API','line_number':12008,'multiline':False]
['text':' in __main__.TestJitCUDA.test_variant_consistency_jit_logspace_cuda_complex64!','line_number':12009,'multiline':False]
['text':' Caching allocator allocated memory was 0 and is now reported as 307200 on device 0.','line_number':12010,'multiline':False]
['text':' CUDA driver allocated memory was 1254555648 and is now 1242955776.','line_number':12011,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':12024,'multiline':False]
['text':' TypeError: 'int' object is not subscriptable','line_number':12026,'multiline':False]
['text':' Same failure as arange: cannot find linspace in captured graph','line_number':12030,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':12033,'multiline':False]
['text':' Off-by-one issue when casting floats to ints','line_number':12036,'multiline':False]
['text':' UserWarning: CUDA caching allocator reports a memory leak not verified by the driver API','line_number':12041,'multiline':False]
['text':' in __main__.TestJitCUDA.test_variant_consistency_jit_logspace_cuda_complex64!','line_number':12042,'multiline':False]
['text':' Caching allocator allocated memory was 0 and is now reported as 307200 on device 0.','line_number':12043,'multiline':False]
['text':' CUDA driver allocated memory was 1254555648 and is now 1242955776.','line_number':12044,'multiline':False]
['text':' log(z)->-inf for |z|->0','line_number':12064,'multiline':False]
['text':' log10(z)->-inf for |z|->0','line_number':12080,'multiline':False]
['text':' log2(z)->-inf for |z|->0','line_number':12095,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':12099,'multiline':False]
['text':' RuntimeError: mul(): functions with out=... arguments don't support','line_number':12108,'multiline':False]
['text':' automatic differentiation, but one of the arguments requires grad','line_number':12109,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/68966','line_number':12110,'multiline':False]
['text':' TODO: FIXME: RuntimeError: not implemented for 'ComplexFloat'','line_number':12132,'multiline':False]
['text':' The function variant always returns BoolTensor','line_number':12149,'multiline':False]
['text':' while the inplace variant preserves the input dtype.','line_number':12150,'multiline':False]
['text':' >>> t = torch.randn(3)','line_number':12151,'multiline':False]
['text':' >>> torch.logical_not(t)','line_number':12152,'multiline':False]
['text':' tensor([False, False, False])','line_number':12153,'multiline':False]
['text':' >>> torch.logical_not(t).dtype','line_number':12154,'multiline':False]
['text':' torch.bool','line_number':12155,'multiline':False]
['text':' >>> t.logical_not_().dtype','line_number':12156,'multiline':False]
['text':' torch.float32','line_number':12157,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':12174,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':12183,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':12187,'multiline':False]
['text':' we skip jit tests because `lu` is a torch function','line_number':12192,'multiline':False]
['text':' RuntimeError:','line_number':12193,'multiline':False]
['text':' 'Tensor (inferred)' object has no attribute or method 'lu'.:','line_number':12194,'multiline':False]
['text':' File "<string>", line 3','line_number':12195,'multiline':False]
['text':' def the_method(i0):','line_number':12196,'multiline':False]
['text':'     return i0.lu(True, True)','line_number':12197,'multiline':False]
['text':'            ~~~~~ <--- HERE','line_number':12198,'multiline':False]
['text':' RuntimeError not raised: Expected RuntimeError when calling with input.device=cpu and out.device=cuda','line_number':12200,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':12202,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/66357','line_number':12209,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':12237,'multiline':False]
['text':' Compiler issue on ROCm. Might need to skip until ROCm5.5','line_number':12249,'multiline':False]
['text':' Needs to construct a 2nx2n matrix by copy_ ing into it','line_number':12257,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':12262,'multiline':False]
['text':' mexp does not support bf16 and fp16','line_number':12265,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':12279,'multiline':False]
['text':' NVIDIA only assures that bfloat16 is supported by bmm if SM >= 5.3','line_number':12286,'multiline':False]
['text':' ROCm intermittently fails the test with standard atol/rtol','line_number':12288,'multiline':False]
['text':' mv for the sample with shapes (S, S, M, M), (M,) has some variance in the','line_number':12295,'multiline':False]
['text':' backward on CPU','line_number':12296,'multiline':False]
['text':' Strides are not the same!','line_number':12309,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/67470','line_number':12311,'multiline':False]
['text':' AssertionError: False is not true : Tensors failed to compare as equal!','line_number':12315,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/71774','line_number':12318,'multiline':False]
['text':' TODO: some signatures of median do support out','line_number':12342,'multiline':False]
['text':' TODO: some signatures of nanmedian do support out','line_number':12351,'multiline':False]
['text':' TODO: some signatures of var_mean do support out','line_number':12359,'multiline':False]
['text':' TODO: some signatures of var_mean do support out','line_number':12372,'multiline':False]
['text':' TODO: some signatures of std_mean do support out','line_number':12384,'multiline':False]
['text':' TODO: some signatures of var_mean do support out','line_number':12397,'multiline':False]
['text':' JIT does not support variadic tensors.','line_number':12412,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalType','line_number':12413,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,','line_number':12414,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':12415,'multiline':False]
['text':' meshgrid is defined in torch.functional to take a','line_number':12417,'multiline':False]
['text':' variadic list of tensors. Variadic parameters are not','line_number':12418,'multiline':False]
['text':' compatible with the normalize operator tests.','line_number':12419,'multiline':False]
['text':' Skip operator schema test because this is a functional and not an operator','line_number':12421,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':12427,'multiline':False]
['text':' Unlike the variant above, we do not use np.meshgrid as a','line_number':12431,'multiline':False]
['text':' ref since it does not officially support list of numpy','line_number':12432,'multiline':False]
['text':' arrays.','line_number':12433,'multiline':False]
['text':' meshgrid is defined in torch.functional to take a','line_number':12437,'multiline':False]
['text':' variadic list of tensors. Variadic parameters are not','line_number':12438,'multiline':False]
['text':' compatible with the normalize operator tests.','line_number':12439,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':12447,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/66357','line_number':12471,'multiline':False]
['text':' Relies on copy_ to broadcast, but the forward AD path calls broadcast_to which','line_number':12472,'multiline':False]
['text':' does not have a batching rule in core','line_number':12473,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/66357','line_number':12480,'multiline':False]
['text':' Relies on copy_ to broadcast, but the forward AD path calls broadcast_to which','line_number':12481,'multiline':False]
['text':' does not have a batching rule in core','line_number':12482,'multiline':False]
['text':' Incorrectly attempts to use a scalar for the second argument','line_number':12495,'multiline':False]
['text':' TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'','line_number':12497,'multiline':False]
['text':' TODO: FIXME: RuntimeError: "max_elementwise_cuda" not implemented for 'ComplexFloat'','line_number':12508,'multiline':False]
['text':' Incorrectly attempts to use a scalar for the second argument','line_number':12522,'multiline':False]
['text':' TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'','line_number':12524,'multiline':False]
['text':' TODO: FIXME: RuntimeError: "min_elementwise_cuda" not implemented for 'ComplexFloat'','line_number':12538,'multiline':False]
['text':' RuntimeError: "bitwise_and_cuda" not implemented for 'Half'','line_number':12573,'multiline':False]
['text':' TODO: FIXME: RuntimeError: "bitwise_or_cuda" not implemented for 'Half'','line_number':12585,'multiline':False]
['text':' TODO: FIXME: RuntimeError: "bitwise_xor_cuda" not implemented for 'Half'','line_number':12599,'multiline':False]
['text':' necessary because np.heaviside incorrectly returns float64 when passed args of dtype int64','line_number':12607,'multiline':False]
['text':' RuntimeError: heaviside is not yet implemented for tensors with different dtypes.','line_number':12614,'multiline':False]
['text':' PyTorch's heaviside does not appear to propagate NaNs','line_number':12619,'multiline':False]
['text':' RuntimeError: Short did not match Int','line_number':12651,'multiline':False]
['text':' `softmax` supports different dtypes based on whether `dtype` argument,','line_number':12660,'multiline':False]
['text':' is passed or not. Hence two OpInfo entries, one with dtype and other without.','line_number':12661,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/68752','line_number':12662,'multiline':False]
['text':' `softmin` supports different dtypes based on whether `dtype` argument,','line_number':12699,'multiline':False]
['text':' is passed or not. Hence two OpInfo entries, one with dtype and other without.','line_number':12700,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/68752','line_number':12701,'multiline':False]
['text':' AssertionError: False is not true : Scalars failed to compare as equal! 0 != 1536','line_number':12737,'multiline':False]
['text':' test_ops.TestJitCUDA.test_variant_consistency_jit_nn_functional_cross_entropy_cuda_float32 leaked','line_number':12738,'multiline':False]
['text':' 1536 bytes CUDA memory on device 0','line_number':12739,'multiline':False]
['text':' vmap does not support inplace views','line_number':12765,'multiline':False]
['text':' Note: This xfail is fine -- it's inherent to how as_strided works','line_number':12769,'multiline':False]
['text':' AssertionError: False is not true : Scalars failed to compare as equal!','line_number':12771,'multiline':False]
['text':' Not close','line_number':12774,'multiline':False]
['text':' Not close','line_number':12777,'multiline':False]
['text':' vmap does not support inplace views','line_number':12789,'multiline':False]
['text':' Note: This xfail is fine -- it's inherent to how as_strided works','line_number':12793,'multiline':False]
['text':' RuntimeError: This operator is not Composite Compliant: the','line_number':12795,'multiline':False]
['text':' storage_offset of the tensor was modified directly without','line_number':12796,'multiline':False]
['text':' going through the PyTorch dispatcher.','line_number':12797,'multiline':False]
['text':' These fail because the test changes the input's in-memory layout','line_number':12801,'multiline':False]
['text':' Fail but are also flaky','line_number':12815,'multiline':False]
['text':' RuntimeError: setStorage: sizes [2, 2], strides [1, 2], storage offset 10, and itemsize 2 requiring a','line_number':12819,'multiline':False]
['text':' storage size of 28 are out of bounds for storage of size 20','line_number':12820,'multiline':False]
['text':' vmap does not support inplace views','line_number':12831,'multiline':False]
['text':' noqa: B950','line_number':12836,'multiline':False]
['text':' noqa: B950','line_number':12837,'multiline':False]
['text':' AssertionError: Tensor-likes are not close! (new_empty_strided.default)','line_number':12842,'multiline':False]
['text':' IndexError: tuple index out of range','line_number':12855,'multiline':False]
['text':' Tests fail when weight=None and bias is defined','line_number':12857,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/79705','line_number':12858,'multiline':False]
['text':' JIT test also tries to compute double backward, which fails','line_number':12860,'multiline':False]
['text':' NotImplementedError: Could not run','line_number':12872,'multiline':False]
['text':' 'aten::native_batch_norm.out' with arguments from the 'CPU' backend.','line_number':12873,'multiline':False]
['text':' RuntimeError: out_invstd.dim() == 1 && out_invstd.is_contiguous() && out_invstd.sizes()[0]','line_number':12875,'multiline':False]
['text':' Problem with _get_numerical_jacobian','line_number':12877,'multiline':False]
['text':' IndexError: tuple index out of range','line_number':12878,'multiline':False]
['text':' RuntimeError: deepEquals(input.iValue, deepCopiedInput) INTERNAL ASSERT FAILED','line_number':12880,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/85960','line_number':12882,'multiline':False]
['text':' AssertionError: Booleans mismatch: True is not False','line_number':12884,'multiline':False]
['text':' NotImplementedError: Could not run','line_number':12899,'multiline':False]
['text':' 'aten::native_batch_norm.out' with arguments from the 'CPU' backend.','line_number':12900,'multiline':False]
['text':' RuntimeError: out_invstd.dim() == 1 && out_invstd.is_contiguous() && out_invstd.sizes()[0]','line_number':12902,'multiline':False]
['text':' Problem with _get_numerical_jacobian','line_number':12904,'multiline':False]
['text':' IndexError: tuple index out of range','line_number':12905,'multiline':False]
['text':' RuntimeError: deepEquals(input.iValue, deepCopiedInput) INTERNAL ASSERT FAILED','line_number':12907,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/85960','line_number':12909,'multiline':False]
['text':' RuntimeError:','line_number':12933,'multiline':False]
['text':' adaptive_avg_pool2d(Tensor input, int[2] output_size) -> (Tensor):','line_number':12934,'multiline':False]
['text':' Expected a value of type 'List[int]' for argument 'output_size' but','line_number':12935,'multiline':False]
['text':' instead found type 'Tuple[NoneType, int]'. :','line_number':12936,'multiline':False]
['text':'   File "<string>", line 3','line_number':12937,'multiline':False]
['text':' def the_method(i0):','line_number':12938,'multiline':False]
['text':'     return torch.nn.functional.adaptive_avg_pool2d(i0, (None, 7))','line_number':12939,'multiline':False]
['text':'            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE','line_number':12940,'multiline':False]
['text':' RuntimeError:','line_number':12953,'multiline':False]
['text':' adaptive_avg_pool3d(Tensor input, int[3] output_size) -> (Tensor):','line_number':12954,'multiline':False]
['text':' Expected a value of type 'List[int]' for argument 'output_size' but','line_number':12955,'multiline':False]
['text':' instead found type 'Tuple[NoneType, NoneType, NoneType]'. :','line_number':12956,'multiline':False]
['text':'   File "<string>", line 3','line_number':12957,'multiline':False]
['text':'','line_number':12958,'multiline':False]
['text':' def the_method(i0):','line_number':12959,'multiline':False]
['text':'     return torch.nn.functional.adaptive_avg_pool3d(i0, (None, None, None))','line_number':12960,'multiline':False]
['text':'            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE','line_number':12961,'multiline':False]
['text':'','line_number':12962,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':12965,'multiline':False]
['text':' got: Batching rule not implemented for aten::flatten.using_ints','line_number':12978,'multiline':False]
['text':' RuntimeError:','line_number':12986,'multiline':False]
['text':' adaptive_max_pool2d(Tensor input, int[2] output_size) -> (Tensor):','line_number':12987,'multiline':False]
['text':' Expected a value of type 'List[int]' for argument 'output_size' but','line_number':12988,'multiline':False]
['text':' instead found type 'Tuple[NoneType, int]'. :','line_number':12989,'multiline':False]
['text':'   File "<string>", line 3','line_number':12990,'multiline':False]
['text':' def the_method(i0):','line_number':12991,'multiline':False]
['text':'     return torch.nn.functional.adaptive_max_pool2d(i0, (None, 7))','line_number':12992,'multiline':False]
['text':'            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE','line_number':12993,'multiline':False]
['text':' got: Batching rule not implemented for aten::flatten.using_ints','line_number':12999,'multiline':False]
['text':' RuntimeError:','line_number':13008,'multiline':False]
['text':' adaptive_max_pool3d(Tensor input, int[3] output_size) -> (Tensor):','line_number':13009,'multiline':False]
['text':' Expected a value of type 'List[int]' for argument 'output_size' but','line_number':13010,'multiline':False]
['text':' instead found type 'Tuple[NoneType, NoneType, NoneType]'. :','line_number':13011,'multiline':False]
['text':'   File "<string>", line 3','line_number':13012,'multiline':False]
['text':'','line_number':13013,'multiline':False]
['text':' def the_method(i0):','line_number':13014,'multiline':False]
['text':'     return torch.nn.functional.adaptive_max_pool3d(i0, (None, None, None))','line_number':13015,'multiline':False]
['text':'            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE','line_number':13016,'multiline':False]
['text':'','line_number':13017,'multiline':False]
['text':' got: Batching rule not implemented for aten::flatten.using_ints','line_number':13023,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':13050,'multiline':False]
['text':' `ref` for this function is backward of','line_number':13088,'multiline':False]
['text':' corresponding `conv*d`','line_number':13089,'multiline':False]
['text':' Reason for Skip: https://github.com/pytorch/pytorch/pull/79694#issuecomment-1186949486','line_number':13116,'multiline':False]
['text':' RuntimeError: UNSUPPORTED DTYPE: complex','line_number':13119,'multiline':False]
['text':' RuntimeError: !lhs.isAliasOf(rhs)INTERNAL ASSERT FAILED at','line_number':13122,'multiline':False]
['text':' "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":104, please report a bug to PyTorch.','line_number':13123,'multiline':False]
['text':' RuntimeError: "slow_conv2d_cpu_grad_input" not implemented for 'Long'','line_number':13126,'multiline':False]
['text':' `ref` for this function is backward of','line_number':13134,'multiline':False]
['text':' corresponding `conv*d`','line_number':13135,'multiline':False]
['text':' Runs very slowly on slow-gradcheck for complex.','line_number':13141,'multiline':False]
['text':' RuntimeError: !lhs.isAliasOf(rhs)INTERNAL ASSERT FAILED at','line_number':13161,'multiline':False]
['text':' "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":104, please report a bug to PyTorch.','line_number':13162,'multiline':False]
['text':' RuntimeError: UNSUPPORTED DTYPE: complex','line_number':13164,'multiline':False]
['text':' RuntimeError: "slow_conv2d_cpu_grad_input" not implemented for 'Long'','line_number':13167,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/86356','line_number':13170,'multiline':False]
['text':' AssertionError: None mismatch: torch.complex64 is not None','line_number':13174,'multiline':False]
['text':' `ref` for this function is backward of','line_number':13182,'multiline':False]
['text':' corresponding `conv*d`','line_number':13183,'multiline':False]
['text':' Runs very slowly on slow-gradcheck - alternatively reduce input sizes','line_number':13192,'multiline':False]
['text':' RuntimeError: !lhs.isAliasOf(rhs)INTERNAL ASSERT FAILED at','line_number':13224,'multiline':False]
['text':' "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":104, please report a bug to PyTorch.','line_number':13225,'multiline':False]
['text':' RuntimeError: "slow_conv3d_cpu_grad_input" not implemented for 'Long'','line_number':13227,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/86356','line_number':13230,'multiline':False]
['text':' RuntimeError: UNSUPPORTED DTYPE: complex','line_number':13234,'multiline':False]
['text':' RuntimeError: !lhs.isAliasOf(rhs)INTERNAL ASSERT FAILED at','line_number':13264,'multiline':False]
['text':' "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":103, please report a bug to PyTorch.','line_number':13265,'multiline':False]
['text':' Ref: https://github.com/pytorch/pytorch/issues/75309','line_number':13267,'multiline':False]
['text':' AssertionError: None mismatch: torch.complex128 is not None','line_number':13268,'multiline':False]
['text':' Ref: https://github.com/pytorch/pytorch/issues/75309','line_number':13271,'multiline':False]
['text':' RuntimeError: UNSUPPORTED DTYPE: complex','line_number':13272,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':13287,'multiline':False]
['text':' RuntimeError: !lhs.isAliasOf(rhs)INTERNAL ASSERT FAILED at','line_number':13299,'multiline':False]
['text':' "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":103, please report a bug to PyTorch.','line_number':13300,'multiline':False]
['text':' Ref: https://github.com/pytorch/pytorch/issues/75309','line_number':13302,'multiline':False]
['text':' AssertionError: None mismatch: torch.complex128 is not None','line_number':13303,'multiline':False]
['text':' RuntimeError: UNSUPPORTED DTYPE: complex','line_number':13306,'multiline':False]
['text':' RuntimeError: !lhs.isAliasOf(rhs) INTERNAL ASSERT FAILED at','line_number':13330,'multiline':False]
['text':' "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":103, please report a bug to PyTorch.','line_number':13331,'multiline':False]
['text':' RuntimeError: UNSUPPORTED DTYPE: complex','line_number':13333,'multiline':False]
['text':' RuntimeError: Conv3D is not supported on MPS','line_number':13336,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':13338,'multiline':False]
['text':' break slow tests','line_number':13339,'multiline':False]
['text':' RuntimeError: Cannot insert a Tensor that requires grad as a constant.','line_number':13354,'multiline':False]
['text':' Consider making it a parameter or input, or detaching the gradient','line_number':13355,'multiline':False]
['text':' no ref because instance_norm will often have numerical instability (large numbers or nan)','line_number':13362,'multiline':False]
['text':' RuntimeError: Cannot insert a Tensor that requires grad as a constant.','line_number':13368,'multiline':False]
['text':' Consider making it a parameter or input, or detaching the gradient','line_number':13369,'multiline':False]
['text':' RuntimeError: falseINTERNAL ASSERT FAILED at','line_number':13403,'multiline':False]
['text':' "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185, please report a bug to PyTorch.','line_number':13404,'multiline':False]
['text':' bool can't be passed to Scalar arguments in JIT tracer because','line_number':13415,'multiline':False]
['text':' BoolType is not a subtype of ScalarType.','line_number':13416,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':13424,'multiline':False]
['text':' Doesn't have a corresponding aten operator.','line_number':13439,'multiline':False]
['text':' RuntimeError: falseINTERNAL ASSERT FAILED at','line_number':13440,'multiline':False]
['text':' "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185, please report a bug to PyTorch.','line_number':13441,'multiline':False]
['text':' Doesn't have a corresponding aten operator.','line_number':13454,'multiline':False]
['text':' RuntimeError: falseINTERNAL ASSERT FAILED at','line_number':13455,'multiline':False]
['text':' "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185, please report a bug to PyTorch.','line_number':13456,'multiline':False]
['text':' Doesn't have a corresponding aten operator.','line_number':13469,'multiline':False]
['text':' RuntimeError: falseINTERNAL ASSERT FAILED at','line_number':13470,'multiline':False]
['text':' "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185, please report a bug to PyTorch.','line_number':13471,'multiline':False]
['text':' Some negative padding cases cause a segfault on MPS','line_number':13473,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':13485,'multiline':False]
['text':' Doesn't have a corresponding aten operator.','line_number':13488,'multiline':False]
['text':' RuntimeError: falseINTERNAL ASSERT FAILED at','line_number':13489,'multiline':False]
['text':' "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185, please report a bug to PyTorch.','line_number':13490,'multiline':False]
['text':' Difference from <type> is larger with decomposition new_empty_strided.default than original on output 0','line_number':13492,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':13513,'multiline':False]
['text':' NOTE: this failure may not reproduce consistently on different systems','line_number':13519,'multiline':False]
['text':' false INTERNAL ASSERT FAILED at "...torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185','line_number':13520,'multiline':False]
['text':' RuntimeError: false','line_number':13533,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,','line_number':13534,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':13535,'multiline':False]
['text':' RuntimeError: false','line_number':13549,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,','line_number':13550,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':13551,'multiline':False]
['text':' RuntimeError: aten::_upsample_nearest_exact*d hit the vmap fallback which is currently disabled','line_number':13553,'multiline':False]
['text':' NotImplementedError: The operator 'aten::_upsample_nearest_exact3d.out' is not currently implemented','line_number':13557,'multiline':False]
['text':' for the MPS device.','line_number':13558,'multiline':False]
['text':' RuntimeError: false','line_number':13572,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,','line_number':13573,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':13574,'multiline':False]
['text':' RuntimeError: false','line_number':13590,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,','line_number':13591,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':13592,'multiline':False]
['text':' RuntimeError: false','line_number':13608,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,','line_number':13609,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':13610,'multiline':False]
['text':' RuntimeError: false','line_number':13625,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,','line_number':13626,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':13627,'multiline':False]
['text':' RuntimeError: false','line_number':13642,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,','line_number':13643,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':13644,'multiline':False]
['text':' RuntimeError: false','line_number':13658,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,','line_number':13659,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':13660,'multiline':False]
['text':' doesn't support grad on target','line_number':13687,'multiline':False]
['text':' RuntimeError: false','line_number':13700,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":185,','line_number':13701,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':13702,'multiline':False]
['text':' AssertionError: False is not true : Scalars failed to compare as equal! 0 != 4096','line_number':13772,'multiline':False]
['text':' __main__.TestJitCUDA.test_variant_consistency_jit_nn_functional_multilabel_soft_margin_loss_cuda_float32','line_number':13773,'multiline':False]
['text':' leaked 4096 bytes CUDA memory on device 0','line_number':13774,'multiline':False]
['text':' Skip instead of expectedFailure because this fails','line_number':13776,'multiline':False]
['text':' locally for me but passes in CI.','line_number':13777,'multiline':False]
['text':' vmap does not support random operations','line_number':13804,'multiline':False]
['text':' FIXME: AssertionError: False is not true : Tensors failed to compare as equal!','line_number':13811,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalType','line_number':13813,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270','line_number':13814,'multiline':False]
['text':' vmap does not support random operations','line_number':13825,'multiline':False]
['text':' FIXME: both derivatives are implemented incorrectly','line_number':13833,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/69322','line_number':13834,'multiline':False]
['text':' FIXME: AssertionError: False is not true : Tensors failed to compare as equal!','line_number':13835,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalType','line_number':13837,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270','line_number':13838,'multiline':False]
['text':' got: Batching rule not implemented for aten::flatten.using_ints','line_number':13848,'multiline':False]
['text':' TODO: add shape checks','line_number':13850,'multiline':False]
['text':' Pre-existing condition; Needs to be fixed','line_number':13855,'multiline':False]
['text':' RuntimeError: The tensor has a non-zero number of elements, but its data is not allocated yet.','line_number':13858,'multiline':False]
['text':' Caffe2 uses a lazy allocation, so you will need to call mutable_data() or raw_mutable_data()','line_number':13859,'multiline':False]
['text':' to actually allocate memory','line_number':13860,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':13867,'multiline':False]
['text':' Vmap is not happy with non-contiguous (channels_last) inputs','line_number':13869,'multiline':False]
['text':' got: Batching rule not implemented for aten::flatten.using_ints','line_number':13874,'multiline':False]
['text':' We've defined a custom op, so there's no corresponding aten op','line_number':13883,'multiline':False]
['text':' We've defined a custom op here, and we don't handle the case where we receive an out kwarg','line_number':13897,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':13900,'multiline':False]
['text':' object has no attribute max_pool2d_with_indices_backward (It's not available on torch -- so expected)','line_number':13902,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':13907,'multiline':False]
['text':' got: Batching rule not implemented for aten::flatten.using_ints','line_number':13912,'multiline':False]
['text':' TODO: add shape checks','line_number':13914,'multiline':False]
['text':' TODO: investigate nondeterminism','line_number':13918,'multiline':False]
['text':' Gradients are tested in `variant_test_name=grad` below.','line_number':13933,'multiline':False]
['text':' We skip tests here because there is non-determinism in backward','line_number':13934,'multiline':False]
['text':' with gather, when there are writes into the same memory location,','line_number':13935,'multiline':False]
['text':' and if there are several indices pointing to the same memory,','line_number':13936,'multiline':False]
['text':' gradcheck is oblivious about that and cannot perturb them all at once','line_number':13937,'multiline':False]
['text':' (see sample_inputs_max_unpool_grad to find out more).','line_number':13938,'multiline':False]
['text':' Gradients are tested in `variant_test_name=grad` below.','line_number':13968,'multiline':False]
['text':' We skip tests here because there is non-determinism in backward','line_number':13969,'multiline':False]
['text':' with gather, when there are writes into the same memory location,','line_number':13970,'multiline':False]
['text':' and if there are several indices pointing to the same memory,','line_number':13971,'multiline':False]
['text':' gradcheck is oblivious about that and cannot perturb them all at once','line_number':13972,'multiline':False]
['text':' (see sample_inputs_max_unpool_grad to find out more).','line_number':13973,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':13983,'multiline':False]
['text':' Vmap is not happy with non-contiguous (channels_last) inputs','line_number':13987,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':13996,'multiline':False]
['text':' Gradients are tested in `variant_test_name=grad` below.','line_number':14006,'multiline':False]
['text':' We skip tests here because there is non-determinism in backward','line_number':14007,'multiline':False]
['text':' with gather, when there are writes into the same memory location,','line_number':14008,'multiline':False]
['text':' and if there are several indices pointing to the same memory,','line_number':14009,'multiline':False]
['text':' gradcheck is oblivious about that and cannot perturb them all at once','line_number':14010,'multiline':False]
['text':' (see sample_inputs_max_unpool_grad to find out more).','line_number':14011,'multiline':False]
['text':' linear calls mm under the hood which is nondeterministic on CUDA','line_number':14038,'multiline':False]
['text':' https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms','line_number':14039,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/66357','line_number':14043,'multiline':False]
['text':' Strides are not the same!','line_number':14047,'multiline':False]
['text':' NVIDIA only assures that bfloat16 is supported by bmm if SM >= 5.3','line_number':14062,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':14066,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':14073,'multiline':False]
['text':' Marked as a Unary function because it has some rather odd broadcasting semantics in its','line_number':14105,'multiline':False]
['text':' second argument','line_number':14106,'multiline':False]
['text':' test_reference_numerics only tests the case when the weight tensor is a scalar','line_number':14120,'multiline':False]
['text':' RuntimeError: Cannot insert a Tensor that requires grad as a constant.','line_number':14126,'multiline':False]
['text':' Consider making it a parameter or input, or detaching the gradient','line_number':14127,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/68752','line_number':14128,'multiline':False]
['text':' lambda impl','line_number':14181,'multiline':False]
['text':' lambda impl','line_number':14183,'multiline':False]
['text':' In-place operations do not play well with forward AD','line_number':14185,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/77447','line_number':14186,'multiline':False]
['text':' The noise vector that's generated in these tests is not the same elementwise','line_number':14189,'multiline':False]
['text':' depends on 'elu'','line_number':14202,'multiline':False]
['text':' Sample inputs isn't really parametrized on dtype','line_number':14228,'multiline':False]
['text':' When attn mask is a composite tensor this fails backward by returning a none','line_number':14246,'multiline':False]
['text':' This is only failing on Linux Bionic 3.10 Cuda 11.6','line_number':14248,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':14253,'multiline':False]
['text':' Forward works for dtype=float64 which is the math path','line_number':14255,'multiline':False]
['text':' Not implemented for Forward AD','line_number':14257,'multiline':False]
['text':' Not implemented for backward derivative','line_number':14260,'multiline':False]
['text':' CPU and CUDA have inconsistencies for intermediate outputs','line_number':14263,'multiline':False]
['text':' TODO: Do not work even on MI200 because of stride mismatching.','line_number':14268,'multiline':False]
['text':' When changing input from Tensor to CompositeCompliantTensor, input.requires_grad() changes from true to false','line_number':14277,'multiline':False]
['text':' OpInfo was implemented with a lambda','line_number':14280,'multiline':False]
['text':' TODO Need to understand what this is testing and why it doesn't work','line_number':14282,'multiline':False]
['text':' TODO skip this for now since we can't skip on runtime arch support','line_number':14285,'multiline':False]
['text':' skip for sm < 80','line_number':14287,'multiline':False]
['text':' Device mismatch due to philox seed and offset','line_number':14305,'multiline':False]
['text':' Checking the scalar value of the philox seed and offset','line_number':14308,'multiline':False]
['text':' None Mismatch Tensor','line_number':14312,'multiline':False]
['text':' Device mismatch due to philox seed and offset','line_number':14330,'multiline':False]
['text':' Checking the scaler value of the philox seed and offset','line_number':14333,'multiline':False]
['text':' None Mismatch Tensor','line_number':14337,'multiline':False]
['text':' TODO: combine this with the nn.functional.silu OpInfo when','line_number':14366,'multiline':False]
['text':' complex autodiff for silu is supported or when','line_number':14367,'multiline':False]
['text':' the forward bug is fixed','line_number':14368,'multiline':False]
['text':' Note: silu errors when given inputs that require grad','line_number':14369,'multiline':False]
['text':'   but it doesn't support grad in their dtype','line_number':14370,'multiline':False]
['text':'   This is why the dtypes list above passes test_dtypes,','line_number':14371,'multiline':False]
['text':'   because it's getting lucky and failing in forward','line_number':14372,'multiline':False]
['text':'   because test_dtypes sets requires_grad to True','line_number':14373,'multiline':False]
['text':'   THIS IS A BUG','line_number':14374,'multiline':False]
['text':' FIXME: intentionally misreports dtypes','line_number':14398,'multiline':False]
['text':' FIXME: numpy reference diverges: Comparing (nan+nanj) and (-0+0j)','line_number':14400,'multiline':False]
['text':' still want to test that first derivative works though second derivative isn't supported','line_number':14425,'multiline':False]
['text':' produces 0 instead of nan on ROCM','line_number':14427,'multiline':False]
['text':' autodiff_nonfusible_nodes=["aten::log_sigmoid"],','line_number':14444,'multiline':False]
['text':' Resized a non-empty tensor but did not warn about it.','line_number':14457,'multiline':False]
['text':' in each case, pytorch will produce a nan while numpy will not','line_number':14515,'multiline':False]
['text':' tan(j * pi/2 * odd_number) is nan which also make tanhshrink nan.','line_number':14524,'multiline':False]
['text':' TODO(whc) should not need sample_inputs_func, but without it','line_number':14545,'multiline':False]
['text':' kwargs aren't being hooked up properly','line_number':14546,'multiline':False]
['text':' This test cannot handle a callable passed to `distance_function`. If we would use','line_number':14567,'multiline':False]
['text':' `distance_function=None`, the test would pass fine.','line_number':14568,'multiline':False]
['text':' RuntimeError: undefined value cpu','line_number':14595,'multiline':False]
['text':' NotImplementedError: Cannot copy out of meta tensor; no data!','line_number':14602,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/84335','line_number':14608,'multiline':False]
['text':' Multiple variants for batch_norm to test with and without cuDNN disabled','line_number':14627,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/63218#discussion_r688549391 for more details','line_number':14628,'multiline':False]
['text':' see https://github.com/pytorch/pytorch/issues/71286','line_number':14638,'multiline':False]
['text':' Trying to use forward AD with miopen_batch_norm that does not support it','line_number':14642,'multiline':False]
['text':' because it has not been implemented yet.','line_number':14643,'multiline':False]
['text':' This variant tests batch_norm with cuDNN disabled only on CUDA devices','line_number':14649,'multiline':False]
['text':' RuntimeError: expected int at position 0, but got: Tensor','line_number':14676,'multiline':False]
['text':' RuntimeError: expected int at position 0, but got: Tensor','line_number':14681,'multiline':False]
['text':' RuntimeError: output with shape [] doesn't match the broadcast shape [5, 5]','line_number':14692,'multiline':False]
['text':' RuntimeError: expected int at position 0, but got: Tensor','line_number':14698,'multiline':False]
['text':' We have to add 2 OpInfo entry for `igamma` and `igammac`.First is the','line_number':14706,'multiline':False]
['text':' standard entry, second is to run gradcheck tests on the second argument.','line_number':14707,'multiline':False]
['text':' TODO: FIXME','line_number':14712,'multiline':False]
['text':' FIXME: incorrectly tries to pass a rhs scalar','line_number':14716,'multiline':False]
['text':' TODO: FIXME, ideally by implemented grad for both inputs','line_number':14720,'multiline':False]
['text':' BinaryUfuncInfo('igamma',','line_number':14721,'multiline':False]
['text':'                 variant_test_name='grad_other',','line_number':14722,'multiline':False]
['text':'                 # Since autograd formula is implemented only for other and','line_number':14723,'multiline':False]
['text':'                 # gradcheck test verifies the formula for input in SampleInput,','line_number':14724,'multiline':False]
['text':'                 # we permute the arguments.','line_number':14725,'multiline':False]
['text':'                 op=lambda self, other, **kwargs: torch.igamma(other, self, **kwargs),','line_number':14726,'multiline':False]
['text':'                 inplace_variant=None,','line_number':14727,'multiline':False]
['text':'                 method_variant=None,','line_number':14728,'multiline':False]
['text':'                 supports_rhs_python_scalar=False,','line_number':14729,'multiline':False]
['text':'                 rhs_make_tensor_kwargs=dict(requires_grad=False),','line_number':14730,'multiline':False]
['text':'                 dtypes=floating_types_and(torch.bfloat16, torch.float16),','line_number':14731,'multiline':False]
['text':'                 backward_dtypesIfCPU=floating_types_and(torch.bfloat16),','line_number':14732,'multiline':False]
['text':'                 dtypesIfCUDA=floating_types(),','line_number':14733,'multiline':False]
['text':'                 backward_dtypesIfCUDA=floating_types(),','line_number':14734,'multiline':False]
['text':'                 supports_inplace_autograd=False,','line_number':14735,'multiline':False]
['text':'                 skips=(','line_number':14736,'multiline':False]
['text':'                     # Derivative wrt first tensor not implemented','line_number':14737,'multiline':False]
['text':'                     DecorateInfo(unittest.expectedFailure, "TestCommon",','line_number':14738,'multiline':False]
['text':'                                  "test_floating_inputs_are_differentiable"),"),','line_number':14739,'multiline':False]
['text':'                     # test does not work with passing lambda for op','line_number':14740,'multiline':False]
['text':'                     # AssertionError: False is not true : Tensors failed to compare as equal!','line_number':14741,'multiline':False]
['text':'                     DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),','line_number':14742,'multiline':False]
['text':'                     # test fails are we permute the arguments function variant','line_number':14743,'multiline':False]
['text':'                     # but not for inplace or method.','line_number':14744,'multiline':False]
['text':'                     DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager'),','line_number':14745,'multiline':False]
['text':'                     # TypeError: igamma(): argument 'input' (position 1) must be Tensor, not float','line_number':14746,'multiline':False]
['text':'                     DecorateInfo(unittest.skip('Skipped!'), 'TestBinaryUfuncs'),','line_number':14747,'multiline':False]
['text':'                 )),','line_number':14748,'multiline':False]
['text':' FIXME: incorrectly tries to pass a rhs scalar','line_number':14756,'multiline':False]
['text':' TODO: FIXME, ideally by implementing grad for both inputs','line_number':14760,'multiline':False]
['text':' BinaryUfuncInfo('igammac',','line_number':14761,'multiline':False]
['text':'                 variant_test_name='grad_other',','line_number':14762,'multiline':False]
['text':'                 # Since autograd formula is implemented only for other and','line_number':14763,'multiline':False]
['text':'                 # gradcheck test verifies the formula for input in SampleInput,','line_number':14764,'multiline':False]
['text':'                 # we permute the arguments','line_number':14765,'multiline':False]
['text':'                 op=lambda self, other, **kwargs: torch.igammac(other, self, **kwargs),','line_number':14766,'multiline':False]
['text':'                 inplace_variant=None,','line_number':14767,'multiline':False]
['text':'                 method_variant=None,','line_number':14768,'multiline':False]
['text':'                 supports_rhs_python_scalar=False,','line_number':14769,'multiline':False]
['text':'                 rhs_make_tensor_kwargs=dict(requires_grad=False),','line_number':14770,'multiline':False]
['text':'                 dtypes=floating_types_and(torch.bfloat16, torch.float16),','line_number':14771,'multiline':False]
['text':'                 backward_dtypesIfCPU=floating_types_and(torch.bfloat16),','line_number':14772,'multiline':False]
['text':'                 dtypesIfCUDA=floating_types(),','line_number':14773,'multiline':False]
['text':'                 backward_dtypesIfCUDA=floating_types(),','line_number':14774,'multiline':False]
['text':'                 supports_inplace_autograd=False,','line_number':14775,'multiline':False]
['text':'                 decorators=[','line_number':14776,'multiline':False]
['text':'                     # Derivative wrt first tensor not implemented','line_number':14777,'multiline':False]
['text':'                     DecorateInfo(unittest.expectedFailure, "TestCommon",','line_number':14778,'multiline':False]
['text':'                                  "test_floating_inputs_are_differentiable"),','line_number':14779,'multiline':False]
['text':'                 ],','line_number':14780,'multiline':False]
['text':'                 skips=(','line_number':14781,'multiline':False]
['text':'                     # test does not work with passing lambda for op','line_number':14782,'multiline':False]
['text':'                     # AssertionError: False is not true : Tensors failed to compare as equal!','line_number':14783,'multiline':False]
['text':'                     DecorateInfo(unittest.skip("Skipped!"), 'TestJit', 'test_variant_consistency_jit'),','line_number':14784,'multiline':False]
['text':'                     # test fails are we permute the arguments function variant','line_number':14785,'multiline':False]
['text':'                     # but not for inplace or method.','line_number':14786,'multiline':False]
['text':'                     DecorateInfo(unittest.skip("Skipped!"), 'TestCommon', 'test_variant_consistency_eager'),','line_number':14787,'multiline':False]
['text':'                     # TypeError: igammac(): argument 'input' (position 1) must be Tensor, not float','line_number':14788,'multiline':False]
['text':'                     DecorateInfo(unittest.skip('Skipped!'), 'TestBinaryUfuncs'),','line_number':14789,'multiline':False]
['text':'                 )),','line_number':14790,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':14835,'multiline':False]
['text':' May not replicate in CI','line_number':14836,'multiline':False]
['text':' Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479','line_number':14857,'multiline':False]
['text':' Resized a non-empty tensor but did not warn about it','line_number':14870,'multiline':False]
['text':' Use of .item()','line_number':14903,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86931','line_number':14916,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/84577','line_number':14921,'multiline':False]
['text':' Lazy tensor failures: mutating and aliasing ops should all have codegen'd kernels','line_number':14924,'multiline':False]
['text':' Could not run 'aten::narrow_copy.out' with arguments from the 'CUDA' backend','line_number':14927,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':14961,'multiline':False]
['text':' torch.autograd.gradcheck.GradcheckError: While computing batched gradients, got:','line_number':14965,'multiline':False]
['text':' Could not allocate memory to change Tensor SizesAndStrides!','line_number':14966,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':14976,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':14982,'multiline':False]
['text':' Strides are not the same!','line_number':14990,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':14998,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':14999,'multiline':False]
['text':' Due to AVX2 currently not being fully supported for Float16, log_vml_cpu can't be enabled','line_number':15010,'multiline':False]
['text':' for Float16, causing this test to fail. pow's autograd for Float16 is thus currently','line_number':15011,'multiline':False]
['text':' unsupported on CPU.','line_number':15012,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':15015,'multiline':False]
['text':' Integer types do not support negative exponentes','line_number':15022,'multiline':False]
['text':' Raising negative real numbers to fractional powers is not supported','line_number':15024,'multiline':False]
['text':' Skipping integers because they are being raised to negative powers causing an error','line_number':15034,'multiline':False]
['text':' FIXME Complex values error with: Greatest absolute difference: nan at index','line_number':15039,'multiline':False]
['text':' Ref: https://github.com/pytorch/pytorch/issues/76853','line_number':15040,'multiline':False]
['text':' For `chalf`, reference computation in `numpy` is computed in `cfloat`.','line_number':15041,'multiline':False]
['text':' Output of `chalf` saturates to `inf` quicker than reference due to its small range','line_number':15042,'multiline':False]
['text':' which leads to failure of this test.','line_number':15043,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':15067,'multiline':False]
['text':' Integer types do not support negative exponentes','line_number':15072,'multiline':False]
['text':' Raising negative real numbers to fractional powers is not supported','line_number':15074,'multiline':False]
['text':' FIXME','line_number':15082,'multiline':False]
['text':' AssertionError: Object comparison failed: torch.float64 != torch.float32','line_number':15083,'multiline':False]
['text':' -3.43399e+38 is outside the range of representable values of type 'float'','line_number':15085,'multiline':False]
['text':' Complex values error with: Greatest absolute difference: nan at index','line_number':15087,'multiline':False]
['text':' Inplace always promotes to double and thus other floating dtypes are not supported','line_number':15094,'multiline':False]
['text':' In-place ops','line_number':15104,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/66357','line_number':15126,'multiline':False]
['text':' Skip since real and imag don't have out variants.','line_number':15129,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':15147,'multiline':False]
['text':' To test reference numerics against multiple values of argument `decimals`,','line_number':15154,'multiline':False]
['text':' we make multiple OpInfo entries with each entry corresponding to different value of decimals.','line_number':15155,'multiline':False]
['text':' test_ops already tested for this overload with `decimals_0` opinfo entry','line_number':15199,'multiline':False]
['text':' test_ops already tested for this overload with `decimals_0` opinfo entry','line_number':15225,'multiline':False]
['text':' Fails on CUDA but passes on ROCm','line_number':15251,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/49133','line_number':15273,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/48641','line_number':15300,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/41245','line_number':15318,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/41245','line_number':15335,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':15347,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':15348,'multiline':False]
['text':' Cannot declare this aten_name because of','line_number':15351,'multiline':False]
['text':' test_variant_consistency_jit_split_list_args_cpu_float32','line_number':15352,'multiline':False]
['text':' `unsafe_split` supports only `int` for split_size argument','line_number':15360,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':15367,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':15368,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':15374,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':15375,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':15398,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/76806','line_number':15402,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':15458,'multiline':False]
['text':' NVIDIA only assures that bfloat16 is supported by bmm if SM >= 5.3','line_number':15465,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/67470','line_number':15478,'multiline':False]
['text':' Fails on XLA.','line_number':15482,'multiline':False]
['text':' AssertionError: False is not true : Tensors failed to compare as equal','line_number':15483,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/71774','line_number':15485,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':15493,'multiline':False]
['text':' Support autograd after torch.remainder(Tensor, Tensor) supports','line_number':15503,'multiline':False]
['text':' autograd of the second argument.','line_number':15504,'multiline':False]
['text':' https://github.com/pytorch/pytorch/pull/58476/files#r637167630','line_number':15505,'multiline':False]
['text':' supports_autograd=False,','line_number':15506,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/54774','line_number':15512,'multiline':False]
['text':' "log2" "_vml_cpu" not implemented for Half','line_number':15513,'multiline':False]
['text':' TODO: FIXME tolerance is too high','line_number':15522,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':15576,'multiline':False]
['text':' tan(pi/2 * odd_number) is nan','line_number':15617,'multiline':False]
['text':' tan(j * pi/2 * odd_number) is nan','line_number':15651,'multiline':False]
['text':' Pre-existing condition; Needs to be fixed','line_number':15664,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':15675,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':15684,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':15693,'multiline':False]
['text':' AssertionError: Scalars are not equal!','line_number':15707,'multiline':False]
['text':' Gradcheck fails','line_number':15709,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/48010','line_number':15747,'multiline':False]
['text':' Passing numpy_kwargs via sample_kwargs, as numpy does comparison','line_number':15783,'multiline':False]
['text':' with BFloat16 in float, since it currently doesn't support BFloat16.','line_number':15784,'multiline':False]
['text':' Ref: https://github.com/pytorch/pytorch/issues/57982#issuecomment-839150556','line_number':15785,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/45690','line_number':15798,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':15815,'multiline':False]
['text':' Greatest absolute difference: nan at index (700,) (up to 0.01 allowed)','line_number':15816,'multiline':False]
['text':' Greatest relative difference: nan at index (700,) (up to 0.001 allowed)','line_number':15817,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/47358','line_number':15842,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/52549','line_number':15856,'multiline':False]
['text':' >>> t = torch.tensor(complex(-0.01, float("inf")))','line_number':15859,'multiline':False]
['text':' >>> np.square(t.numpy())','line_number':15860,'multiline':False]
['text':' (-inf-infj)','line_number':15861,'multiline':False]
['text':' >>> t.square()','line_number':15862,'multiline':False]
['text':' tensor(-inf-infj)','line_number':15863,'multiline':False]
['text':' >>> t.cuda().square()','line_number':15864,'multiline':False]
['text':' tensor(inf+nanj, device='cuda:0')','line_number':15865,'multiline':False]
['text':' Ref: https://github.com/pytorch/pytorch/issues/78413','line_number':15898,'multiline':False]
['text':' we need this lambda because SampleInput expects tensor input as the first argument','line_number':15951,'multiline':False]
['text':' TODO(@heitorschueroff) update SampleInput to handle such cases','line_number':15952,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/66357','line_number':15961,'multiline':False]
['text':' test does not work with passing lambda for op','line_number':15965,'multiline':False]
['text':' there's a test `test_einsum` in `test_jit.py` to handle this case','line_number':15966,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':15967,'multiline':False]
['text':' Runs very slowly on slow-gradcheck - alternatively reduce input sizes','line_number':15974,'multiline':False]
['text':' We're using at::allclose, which does not have a batching rule','line_number':15979,'multiline':False]
['text':' Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479','line_number':15984,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':16007,'multiline':False]
['text':' test does not work with passing lambda for op','line_number':16021,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':16033,'multiline':False]
['text':' test does not work with passing lambda for op','line_number':16047,'multiline':False]
['text':' this function is undefined if 'abs' values are <0','line_number':16054,'multiline':False]
['text':' RuntimeError: Expected object of scalar type Float but got scalar type Double for second argument','line_number':16059,'multiline':False]
['text':' GradcheckError: Jacobian computed with forward mode mismatch for output 0 with respect to input 0','line_number':16062,'multiline':False]
['text':' Numerical:','line_number':16063,'multiline':False]
['text':'  tensor([[0.]], dtype=torch.float64)','line_number':16064,'multiline':False]
['text':' Analytical:','line_number':16065,'multiline':False]
['text':' tensor([[-0.0047]], dtype=torch.float64, grad_fn=<CopySlices>)','line_number':16066,'multiline':False]
['text':' TODO(@kshitij12345): Refactor similar to `mvlgamma` entries.','line_number':16069,'multiline':False]
['text':' To test reference numerics against multiple values of argument `n`,','line_number':16070,'multiline':False]
['text':' we make multiple OpInfo entries with each entry corresponding to different value of n (currently 0 to 4).','line_number':16071,'multiline':False]
['text':' We run the op tests from test_ops.py only for `n=0` to avoid redundancy in testing.','line_number':16072,'multiline':False]
['text':' Redundant tests','line_number':16098,'multiline':False]
['text':' Mismatch: https://github.com/pytorch/pytorch/issues/55357','line_number':16104,'multiline':False]
['text':' polygamma functions have multiple singularities at x <= 0','line_number':16109,'multiline':False]
['text':' Redundant tests','line_number':16122,'multiline':False]
['text':' Mismatch: https://github.com/pytorch/pytorch/issues/55357','line_number':16128,'multiline':False]
['text':' polygamma functions have multiple singularities at x <= 0','line_number':16131,'multiline':False]
['text':' Redundant tests','line_number':16144,'multiline':False]
['text':' Mismatch: https://github.com/pytorch/pytorch/issues/55357','line_number':16150,'multiline':False]
['text':' polygamma functions have multiple singularities at x <= 0','line_number':16153,'multiline':False]
['text':' Redundant tests','line_number':16167,'multiline':False]
['text':' Mismatch: https://github.com/pytorch/pytorch/issues/55357','line_number':16173,'multiline':False]
['text':' polygamma functions have multiple singularities at x <= 0','line_number':16176,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':16184,'multiline':False]
['text':' RuntimeError: view size is not compatible with input tensor's size and stride','line_number':16228,'multiline':False]
['text':' (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.','line_number':16229,'multiline':False]
['text':' RuntimeError: view size is not compatible with input tensor's size and stride','line_number':16243,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':16248,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':16253,'multiline':False]
['text':' JIT does not support variadic tensors.','line_number':16257,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalType','line_number':16258,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,','line_number':16259,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':16260,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':16267,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':16272,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':16282,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':16287,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':16301,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':16318,'multiline':False]
['text':' lambda impl','line_number':16321,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':16355,'multiline':False]
['text':' RuntimeError: Mismatch on aten._unique.default: Shapes torch.Size([2]) and torch.Size([1]) are not equal!','line_number':16358,'multiline':False]
['text':' RuntimeError: Mismatch on aten._unique.default: Shapes torch.Size([2]) and torch.Size([1]) are not equal!','line_number':16360,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':16370,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':16390,'multiline':False]
['text':' boolean alpha not handled properly','line_number':16396,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':16409,'multiline':False]
['text':' AssertionError: False is not true : Scalars failed to compare as equal! 0 != 104448','line_number':16419,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':16428,'multiline':False]
['text':' lambda impl','line_number':16452,'multiline':False]
['text':' lambda impl','line_number':16464,'multiline':False]
['text':' vmap complains of the sizes','line_number':16474,'multiline':False]
['text':' vmap complains of the sizes','line_number':16478,'multiline':False]
['text':' autograd tests don't handle operators that change dtype','line_number':16496,'multiline':False]
['text':' RuntimeError: attribute lookup is not defined on builtin','line_number':16500,'multiline':False]
['text':' RuntimeError: attributis not defined on builtin','line_number':16513,'multiline':False]
['text':' The autograd test runner cannot handle functions that change dtype','line_number':16522,'multiline':False]
['text':' RuntimeError: attribute lookup is not defined on builtin','line_number':16526,'multiline':False]
['text':' The autograd test runner cannot handle functions that change dtype','line_number':16536,'multiline':False]
['text':' RuntimeError: attribute lookup is not defined on builtin','line_number':16540,'multiline':False]
['text':' RuntimeError: attribute lookup is not defined on builtin','line_number':16554,'multiline':False]
['text':' autograd tests don't handle operators that change dtype','line_number':16564,'multiline':False]
['text':' RuntimeError: attribute lookup is not defined on builtin','line_number':16568,'multiline':False]
['text':' autograd tests don't handle operators that change dtype','line_number':16579,'multiline':False]
['text':' RuntimeError: attribute lookup is not defined on builtin','line_number':16583,'multiline':False]
['text':' RuntimeError: attribute lookup is not defined on builtin','line_number':16595,'multiline':False]
['text':' RuntimeError: attribute lookup is not defined on builtin','line_number':16608,'multiline':False]
['text':' RuntimeError: attribute lookup is not defined on builtin','line_number':16621,'multiline':False]
['text':' RuntimeError: attribute lookup is not defined on builtin','line_number':16635,'multiline':False]
['text':' autograd tests don't handle operators that change dtype','line_number':16646,'multiline':False]
['text':' RuntimeError: attribute lookup is not defined on builtin','line_number':16650,'multiline':False]
['text':' autograd tests don't handle operators that change dtype','line_number':16661,'multiline':False]
['text':' use of lambda doesn't work with test_normalize_operator_exhaustive','line_number':16664,'multiline':False]
['text':' RuntimeError: "sum_cpu" not implemented for 'ComplexHalf'','line_number':16666,'multiline':False]
['text':' TypeError: 'int' object is not iterable','line_number':16669,'multiline':False]
['text':' RuntimeError: "sum_cpu" not implemented for 'ComplexHalf'','line_number':16671,'multiline':False]
['text':' RuntimeError: "sum_cpu" not implemented for 'ComplexHalf'','line_number':16674,'multiline':False]
['text':' RuntimeError: "sum_cpu" not implemented for 'ComplexHalf'','line_number':16677,'multiline':False]
['text':' RuntimeError: "neg_conj_cuda" not implemented for 'ComplexHalf'','line_number':16678,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16689,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16692,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16694,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16696,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16698,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16700,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16702,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16704,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16706,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16708,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':16741,'multiline':False]
['text':' CPU randn generates different values based on the strides of out tensor','line_number':16745,'multiline':False]
['text':' randn fails to warn when resizing its out tensor','line_number':16747,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':16749,'multiline':False]
['text':' Tests that assume input tensor has a meaningful effect on output tensor','line_number':16751,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':16756,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':16775,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':16790,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':16804,'multiline':False]
['text':' CPU randint generates different values based on the strides of out tensor','line_number':16808,'multiline':False]
['text':' randint fails to warn when resizing its out tensor','line_number':16810,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':16812,'multiline':False]
['text':' Tests that assume input tensor has a meaningful effect on output tensor','line_number':16814,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':16819,'multiline':False]
['text':' Might need to skip until ROCm5.5','line_number':16821,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':16834,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':16872,'multiline':False]
['text':' Same failure as arange: cannot find linspace in captured graph','line_number':16878,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':16881,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':16892,'multiline':False]
['text':' Same failure as arange: cannot find linspace in captured graph','line_number':16898,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':16901,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':16912,'multiline':False]
['text':' Same failure as arange: cannot find linspace in captured graph','line_number':16917,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':16919,'multiline':False]
['text':' RuntimeError: UNSUPPORTED DTYPE: bool','line_number':16921,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16931,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16933,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16935,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16937,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16939,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16941,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16943,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16945,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16947,'multiline':False]
['text':' FX failed to normalize op','line_number':16963,'multiline':False]
['text':' Lazy tensor failures','line_number':16965,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':16968,'multiline':False]
['text':' FX failed to normalize op - add the op to the op_skip list.','line_number':17008,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':17010,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17012,'multiline':False]
['text':' Lazy tensor failures','line_number':17021,'multiline':False]
['text':' RuntimeError: unsupported operation: more than one element of the written-to tensor refers to a single','line_number':17023,'multiline':False]
['text':' memory location. Please clone() the tensor before performing the operation.','line_number':17024,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17035,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17037,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17039,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17041,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17043,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17045,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17047,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17049,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17051,'multiline':False]
['text':' requires_grad doesn't exist in the jit schema','line_number':17055,'multiline':False]
['text':' TODO: same as this?','line_number':17078,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/81774','line_number':17079,'multiline':False]
['text':' also see: arange, new_full','line_number':17080,'multiline':False]
['text':' fails to match any schemas despite working in the interpreter','line_number':17081,'multiline':False]
['text':' fails to match any schemas despite working in the interpreter','line_number':17083,'multiline':False]
['text':' skip these tests since we have non tensor input','line_number':17085,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':17091,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17102,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17104,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17106,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17108,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17110,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17112,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17114,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17116,'multiline':False]
['text':' Empty tensor data is garbage so it's hard to make comparisons with it.','line_number':17118,'multiline':False]
['text':' requires_grad doesn't exist in the jit schema','line_number':17122,'multiline':False]
['text':' fails to match any schemas despite working in the interpreter','line_number':17143,'multiline':False]
['text':' fails to match any schemas despite working in the interpreter','line_number':17145,'multiline':False]
['text':' skip these tests since we have non tensor input','line_number':17147,'multiline':False]
['text':' Strides are not the same!','line_number':17175,'multiline':False]
['text':' This may not be reproducible in CI','line_number':17176,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':17178,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':17180,'multiline':False]
['text':' The inplace variant (Tensor.normal_) is different from torch.normal','line_number':17187,'multiline':False]
['text':' Tensor-likes are not close!','line_number':17195,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':17197,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':17199,'multiline':False]
['text':' Computed gradient is incorrect -- would be an exfail but gradgrad somehow passes','line_number':17201,'multiline':False]
['text':' RuntimeError: Difference from {dtype} is larger with decomposition','line_number':17205,'multiline':False]
['text':' The inplace variant (Tensor.normal_) is different from torch.normal','line_number':17208,'multiline':False]
['text':' inplace varaint Tensor.normal_ is decomposed using randn_like()','line_number':17209,'multiline':False]
['text':' This has its own variant b/c OpInfos assume the first arg is a Tensor but it is not here','line_number':17212,'multiline':False]
['text':' The inplace variant (Tensor.normal_) is different from torch.normal','line_number':17216,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':17224,'multiline':False]
['text':' AssertionError','line_number':17237,'multiline':False]
['text':' AssertionError','line_number':17239,'multiline':False]
['text':' AssertionError in CUDA variant','line_number':17241,'multiline':False]
['text':' The inplace variant (Tensor.bernoulli_) is different from torch.bernoulli','line_number':17247,'multiline':False]
['text':' vmap: We do not yet support calling random operations inside of vmap','line_number':17258,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':17261,'multiline':False]
['text':' Expected RuntimeError when doing an unsafe cast from a result of','line_number':17263,'multiline':False]
['text':' dtype torch.float32 into an out= with dtype torch.lon','line_number':17264,'multiline':False]
['text':' UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':17266,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/77046','line_number':17283,'multiline':False]
['text':' histogram is only implemented on CPU','line_number':17303,'multiline':False]
['text':' JIT tests don't work with Tensor keyword arguments','line_number':17307,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/58507','line_number':17308,'multiline':False]
['text':' RuntimeError:','line_number':17309,'multiline':False]
['text':' undefined value tensor:','line_number':17310,'multiline':False]
['text':'   File "<string>", line 3','line_number':17311,'multiline':False]
['text':' def the_method(i0):','line_number':17312,'multiline':False]
['text':'     return torch.histogram(i0, 1, weight=tensor(-0.5735, dtype=torch.float32), density=False)','line_number':17313,'multiline':False]
['text':'                                          ~~~~~~ <--- HERE','line_number':17314,'multiline':False]
['text':' Not Implemented on XLA.','line_number':17316,'multiline':False]
['text':' histogramdd is only implemented on CPU','line_number':17321,'multiline':False]
['text':' Not implemented on CUDA','line_number':17326,'multiline':False]
['text':' JIT tests don't work with Tensor keyword arguments','line_number':17329,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/58507','line_number':17330,'multiline':False]
['text':' CUDA histc returns a float tensor but does not correctly warn when passed an integral out tensor','line_number':17340,'multiline':False]
['text':' "AssertionError: RuntimeError not raised : Expected RuntimeError when doing an unsafe cast','line_number':17341,'multiline':False]
['text':' from a result of dtype torch.float32 into an out= with dtype torch.long"','line_number':17342,'multiline':False]
['text':' JIT tests don't work with Tensor keyword arguments','line_number':17351,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/58507','line_number':17352,'multiline':False]
['text':' JIT tests don't work with Tensor keyword arguments','line_number':17363,'multiline':False]
['text':' JIT tests don't work with Tensor keyword arguments','line_number':17373,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/58507','line_number':17374,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':17384,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/66357','line_number':17388,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/89353','line_number':17392,'multiline':False]
['text':' RuntimeError: Arguments for call not valid.','line_number':17394,'multiline':False]
['text':'               Expected a value of type 'List[Tensor]' for argument','line_number':17395,'multiline':False]
['text':'               'tensors' but instead found type 'Tensor (inferred)'.','line_number':17396,'multiline':False]
['text':' see https://github.com/pytorch/pytorch/issues/71286','line_number':17398,'multiline':False]
['text':' see https://github.com/pytorch/pytorch/issues/99806','line_number':17400,'multiline':False]
['text':' RuntimeError: The size of tensor a (25) must match the size of tensor b (0) at non-singleton dimension 0.','line_number':17401,'multiline':False]
['text':' RuntimeError: _fn() Expected a value of type','line_number':17422,'multiline':False]
['text':'   'Tensor (inferred)' for argument 't0' but instead found type 'tuple'.','line_number':17423,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':17431,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':17438,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/66357','line_number':17444,'multiline':False]
['text':' Skip operator schema test because this is a functional and not an operator','line_number':17448,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':17455,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/66357','line_number':17461,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':17479,'multiline':False]
['text':' RuntimeError: Difference from float64 is larger with decomposition','line_number':17491,'multiline':False]
['text':' linalg_vector_norm.default than original on output 0.','line_number':17492,'multiline':False]
['text':' Original max diff: 2.560596747969157e-07,','line_number':17493,'multiline':False]
['text':' Decomp max diff: 1.8187482915266173e-06','line_number':17494,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':17502,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':17516,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':17517,'multiline':False]
['text':' vmap does not support inplace views','line_number':17521,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':17523,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':17532,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':17533,'multiline':False]
['text':' vmap does not support inplace views','line_number':17536,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':17538,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':17549,'multiline':False]
['text':' JIT has issue when op is passed as lambda','line_number':17554,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':17555,'multiline':False]
['text':' the test fails because resize_ doesn't work with imag views as expected by the test','line_number':17564,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/65945','line_number':17565,'multiline':False]
['text':' Cannot resize variables that require grad','line_number':17571,'multiline':False]
['text':' Cannot resize variables that require grad','line_number':17585,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':17596,'multiline':False]
['text':' RuntimeError: view size is not compatible with input tensor's size and stride','line_number':17601,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':17607,'multiline':False]
['text':' TODO: in the future, 'trapz' should be made a proper alias of 'trapezoid'','line_number':17613,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':17618,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':17626,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':17633,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':17642,'multiline':False]
['text':' vmap does not support inplace views','line_number':17644,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':17648,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':17649,'multiline':False]
['text':' We don't test 0 as the gradient will be NaN and it'll break','line_number':17658,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':17665,'multiline':False]
['text':' vmap does not support inplace views','line_number':17701,'multiline':False]
['text':' lambda impl','line_number':17711,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':17722,'multiline':False]
['text':' lambda impl','line_number':17725,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':17732,'multiline':False]
['text':' lambda impl','line_number':17738,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':17746,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':17751,'multiline':False]
['text':' lambda impl','line_number':17754,'multiline':False]
['text':' skip these tests since we have non tensor input','line_number':17777,'multiline':False]
['text':' skip these tests since we have non tensor input','line_number':17790,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':17799,'multiline':False]
['text':' RuntimeError: view size is not compatible with input tensor's size and stride','line_number':17806,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':17815,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':17825,'multiline':False]
['text':' Skip operator schema test because this is a functional and not an operator.','line_number':17829,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/54574','line_number':17830,'multiline':False]
['text':' NotImplementedError: Could not run 'aten::normal_' with arguments from the 'SparseCPU' backend','line_number':17846,'multiline':False]
['text':' TODO: FIXME: complex inputs requiring grad error in forward','line_number':17848,'multiline':False]
['text':' lambda impl','line_number':17850,'multiline':False]
['text':' Allowed exception: sparse tensors don't have strides','line_number':17852,'multiline':False]
['text':' TODO: implement csr.to_sparse(sample_dim) where sampled_dim is 1.','line_number':17856,'multiline':False]
['text':' Compiler issue on ROCm. Might need to skip until ROCm5.5','line_number':17859,'multiline':False]
['text':' AssertionError: UserWarning not triggered : Resized a non-empty tensor but did not warn about it.','line_number':17871,'multiline':False]
['text':' RuntimeError: "max_values_cpu" not implemented for 'ComplexDouble'','line_number':17873,'multiline':False]
['text':' Falling back to non-numerically stablized exp, causing nan in the results.','line_number':17874,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/56012','line_number':17888,'multiline':False]
['text':' sigmoid(z) = 1 / (1 + exp(-z)), at z = j * pi * odd_number, the denominator is zero','line_number':17899,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/pull/49155#issuecomment-742664611','line_number':17961,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalTypeINTERNAL ASSERT FAILED','line_number':17980,'multiline':False]
['text':' at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270, please report a bug to PyTorch.','line_number':17981,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalTypeINTERNAL ASSERT FAILED','line_number':17993,'multiline':False]
['text':' at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270, please report a bug to PyTorch.','line_number':17994,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/pull/50140#issuecomment-756150214','line_number':18013,'multiline':False]
['text':' lgamma have multiple singularities at x <= 0','line_number':18019,'multiline':False]
['text':' `log_softmax` supports different dtypes based on whether `dtype` argument,','line_number':18029,'multiline':False]
['text':' is passed or not. Hence two OpInfo entries, one with dtype and other without.','line_number':18030,'multiline':False]
['text':' Currently only the `input` is tested in gradcheck.','line_number':18064,'multiline':False]
['text':' If we pass `condition` first, none of the input which supports','line_number':18065,'multiline':False]
['text':' autograd will be tested. Hence the following lambda.','line_number':18066,'multiline':False]
['text':' lambda impl','line_number':18078,'multiline':False]
['text':' nonzero(): argument 'out' must be Tensor, not tuple','line_number':18089,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/67458','line_number':18091,'multiline':False]
['text':' nonzero is not raising a warning when the out is resized','line_number':18093,'multiline':False]
['text':' Can't find schemas for this operator for some reason','line_number':18095,'multiline':False]
['text':' Compiler issue on ROCm. Might need to skip until ROCm5.5','line_number':18097,'multiline':False]
['text':' Following tests are for jiterator's python interface','line_number':18116,'multiline':False]
['text':' Jiterator can be used to author elementwise CUDA kernel','line_number':18117,'multiline':False]
['text':' jiterator._create_jit_fn returns a callable that behaves like a regular pytorch op','line_number':18118,'multiline':False]
['text':' See create_jit_fn in jiterator.py for more information','line_number':18119,'multiline':False]
['text':' jiterator ops doesn't have backward defined','line_number':18126,'multiline':False]
['text':' Jiterator ops doesn't support neg or conj view','line_number':18139,'multiline':False]
['text':' Jiterator ops doesn't support CompositeCompliantTensor','line_number':18143,'multiline':False]
['text':' Following test should expectedFailure, but it's causing cascading failures in CUDA, thus skipped','line_number':18144,'multiline':False]
['text':' Skip reference_numerics tests for bool type, as the defined function doesn't work for bool','line_number':18146,'multiline':False]
['text':' ROCm generates -inf+infj instead of nan+infj for complex64 for some of the results','line_number':18153,'multiline':False]
['text':' Expected failure: torch.jiterator_unary is not a valid op','line_number':18156,'multiline':False]
['text':' Skip Nvfuser','line_number':18158,'multiline':False]
['text':' jiterator ops doesn't have backward defined','line_number':18171,'multiline':False]
['text':' Jiterator ops doesn't support neg or conj view','line_number':18175,'multiline':False]
['text':' Jiterator ops doesn't support CompositeCompliantTensor','line_number':18179,'multiline':False]
['text':' Following test should expectedFailure, but it's causing cascading failures in CUDA, thus skipped','line_number':18180,'multiline':False]
['text':' Expected failure: torch.jiterator_binary is not a valid op','line_number':18182,'multiline':False]
['text':' Skip Nvfuser','line_number':18184,'multiline':False]
['text':' jiterator ops doesn't have backward defined','line_number':18197,'multiline':False]
['text':' Jiterator ops doesn't support neg or conj view','line_number':18200,'multiline':False]
['text':' Jiterator ops doesn't support CompositeCompliantTensor','line_number':18204,'multiline':False]
['text':' Following test should expectedFailure, but it's causing cascading failures in CUDA, thus skipped','line_number':18205,'multiline':False]
['text':' Expected failure: torch.jiterator_4inputs_with_extra_args is not a valid op','line_number':18207,'multiline':False]
['text':' Skip Nvfuser','line_number':18209,'multiline':False]
['text':' jiterator ops doesn't have backward defined','line_number':18227,'multiline':False]
['text':' Jiterator ops doesn't support neg or conj view','line_number':18231,'multiline':False]
['text':' Jiterator ops doesn't support CompositeCompliantTensor','line_number':18235,'multiline':False]
['text':' Following test should expectedFailure, but it's causing cascading failures in CUDA, thus skipped','line_number':18236,'multiline':False]
['text':' Expected failure: torch.jiterator_4inputs_with_extra_args is not a valid op','line_number':18238,'multiline':False]
['text':' Skip Nvfuser','line_number':18240,'multiline':False]
['text':' jiterator ops doesn't have backward defined','line_number':18259,'multiline':False]
['text':' Jiterator ops doesn't support neg or conj view','line_number':18262,'multiline':False]
['text':' Jiterator ops doesn't support CompositeCompliantTensor','line_number':18266,'multiline':False]
['text':' Following test should expectedFailure, but it's causing cascading failures in CUDA, thus skipped','line_number':18267,'multiline':False]
['text':' Expected failure: torch.jiterator_4inputs_with_extra_args is not a valid op','line_number':18269,'multiline':False]
['text':' Skip Nvfuser','line_number':18271,'multiline':False]
['text':' `torch.norm` has multiple code paths depending on the value of `p`.','line_number':18275,'multiline':False]
['text':' These paths have different dtype support. Also JIT supports,','line_number':18276,'multiline':False]
['text':' most variants but not all of them. So we split the OpInfo entries,','line_number':18277,'multiline':False]
['text':' for `norm` based on the code-paths and JIT support.','line_number':18278,'multiline':False]
['text':' TODO Benchmark again with the new implementation','line_number':18283,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':18284,'multiline':False]
['text':' Dispatches in Python to vector_norm. Not sure how to make this test happy','line_number':18290,'multiline':False]
['text':' Happens to pass on complex64. Also a mystery','line_number':18291,'multiline':False]
['text':' torch.autograd.gradcheck.GradcheckError: While computing batched gradients','line_number':18300,'multiline':False]
['text':' got: Could not allocate memory to change Tensor SizesAndStrides!','line_number':18301,'multiline':False]
['text':' Dispatches in Python to matrix_norm. Not sure how to make this test happy','line_number':18308,'multiline':False]
['text':' torch.autograd.gradcheck.GradcheckError: While computing batched gradients','line_number':18322,'multiline':False]
['text':' got: Could not allocate memory to change Tensor SizesAndStrides!','line_number':18323,'multiline':False]
['text':' MPS has some mild accuracy issues for float16. We divide the tolerances by 10','line_number':18327,'multiline':False]
['text':' Issue with conj and torch dispatch, see https://github.com/pytorch/pytorch/issues/82479','line_number':18334,'multiline':False]
['text':' Dispatches in Python to vector_norm. Not sure how to make this test happy','line_number':18340,'multiline':False]
['text':' fast gradcheck produces NaNs','line_number':18352,'multiline':False]
['text':' Dispatches in Python to vector_norm. Not sure how to make this test happy','line_number':18359,'multiline':False]
['text':' Happens to pass on complex64. Also a mystery','line_number':18360,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':18370,'multiline':False]
['text':' vmap does not support inplace views','line_number':18372,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':18374,'multiline':False]
['text':' aliases inputs, shouldn't be fused','line_number':18375,'multiline':False]
['text':' Probably because we have used lambda for the op here','line_number':18386,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':18387,'multiline':False]
['text':' inplace variant dispatches to dropout kernel, while on CUDA','line_number':18389,'multiline':False]
['text':' the op dispatches to _fused_dropout (with a few more conditions)','line_number':18390,'multiline':False]
['text':' hence, different values and this skip here','line_number':18391,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/66357','line_number':18396,'multiline':False]
['text':' Lazy tensor failures','line_number':18412,'multiline':False]
['text':' These tests fail only when built with ASAN','line_number':18414,'multiline':False]
['text':' lambda impl','line_number':18430,'multiline':False]
['text':' As per the docs, valid input dims are (3, 4)','line_number':18438,'multiline':False]
['text':' lambda impl','line_number':18448,'multiline':False]
['text':' As per the docs, valid input dims are (4, 5)','line_number':18456,'multiline':False]
['text':' lambda impl','line_number':18474,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':18476,'multiline':False]
['text':' Fails in cuda11.7','line_number':18477,'multiline':False]
['text':' Error Log: https://github.com/pytorch/pytorch/actions/runs/3440108478/jobs/5738475757','line_number':18478,'multiline':False]
['text':' In training mode, feature_alpha_dropout currently doesn't support inputs of complex dtype','line_number':18481,'multiline':False]
['text':' unlike when `train=False`, it supports complex inputs, hence 2 OpInfos to cover all cases','line_number':18482,'multiline':False]
['text':' lambda impl','line_number':18490,'multiline':False]
['text':' torch.autograd.gradcheck.GradcheckError: While computing batched gradients, got:','line_number':18493,'multiline':False]
['text':' vmap: We do not yet support calling random operations inside of vmap.','line_number':18494,'multiline':False]
['text':' Please perform random operations outside of vmap as a workaround','line_number':18495,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':18499,'multiline':False]
['text':' As per the docs, valid input dims are (4, 5)','line_number':18504,'multiline':False]
['text':' lambda impl','line_number':18515,'multiline':False]
['text':' We use lambda to reshuffle the positional arguments.','line_number':18535,'multiline':False]
['text':' This is because currently only the `input` field of SampleInput','line_number':18536,'multiline':False]
['text':' is tested in gradient tests.','line_number':18537,'multiline':False]
['text':' lambda impl','line_number':18545,'multiline':False]
['text':' Fails on CI https://github.com/pytorch/pytorch/issues/85377','line_number':18548,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/67084','line_number':18550,'multiline':False]
['text':' Not a problem: embedding does weird stuff to its input (it renormalizes)','line_number':18552,'multiline':False]
['text':' We use lambda to reshuffle the positional arguments.','line_number':18560,'multiline':False]
['text':' This is because currently only the `input` field of SampleInput','line_number':18561,'multiline':False]
['text':' is tested in gradient tests.','line_number':18562,'multiline':False]
['text':' backward is not supported for mode `max` and dtype `bfloat16`','line_number':18566,'multiline':False]
['text':' lambda impl','line_number':18570,'multiline':False]
['text':' Not a problem: embedding_bag does weird stuff to its input (it renormalizes)','line_number':18573,'multiline':False]
['text':' Tensor-likes are not close','line_number':18587,'multiline':False]
['text':' TODO skip this for now since we can't skip on runtime arch support (taken from scaled_dot_product_attention)','line_number':18591,'multiline':False]
['text':' randomness','line_number':18593,'multiline':False]
['text':' lambda impl','line_number':18596,'multiline':False]
['text':' AssertionError: JIT Test does not execute any logic','line_number':18597,'multiline':False]
['text':' tests running very slowly break slow tests, so we skip them instead of using `slowTest`.','line_number':18600,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':18618,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalType','line_number':18653,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":252,','line_number':18654,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':18655,'multiline':False]
['text':' TODO: delete this OpInfo once we add meta support for grid_sampler_3d','line_number':18668,'multiline':False]
['text':' Compiler issue on ROCm. Might need to skip until ROCm5.5','line_number':18685,'multiline':False]
['text':' FIXME: uint8 input returns uint8 instead of bool','line_number':18698,'multiline':False]
['text':' FIXME: uint8 input returns uint8 instead of bool','line_number':18710,'multiline':False]
['text':' FIXME: reduces all dimensions when dim=[]','line_number':18723,'multiline':False]
['text':' FIXME: reduces all dimensions when dim=[]','line_number':18738,'multiline':False]
['text':' FIXME: count_nonzero does not accept keepdim kwarg','line_number':18771,'multiline':False]
['text':' FIXME: dim=[] reduces all dimensions','line_number':18779,'multiline':False]
['text':' FIXME: mean needs 'dim' parameter when using the 'out' overload.','line_number':18788,'multiline':False]
['text':' Adding it with 'generate_args_kwargs' does not work, since these also get passed','line_number':18789,'multiline':False]
['text':' onto the reference implementations.','line_number':18790,'multiline':False]
['text':' FIXME: mean does not support passing keepdim without passing dim','line_number':18799,'multiline':False]
['text':' FIXME: mean reduces all dimensions when dim=[]','line_number':18801,'multiline':False]
['text':' FIXME: improve precision','line_number':18804,'multiline':False]
['text':' AssertionError: False is not true :','line_number':18824,'multiline':False]
['text':' Failure in testing nodes' autodifferentiation.','line_number':18825,'multiline':False]
['text':' FIXME: prod reduces all dimensions when dim=[]','line_number':18827,'multiline':False]
['text':' FIXME: improve precision','line_number':18830,'multiline':False]
['text':' FIXME: cannot specify keepdim without dim','line_number':18855,'multiline':False]
['text':' FIXME: dim=[] reduces all dimensions','line_number':18857,'multiline':False]
['text':' FIXME: improve precision','line_number':18860,'multiline':False]
['text':' FIXME: dim=[] reduces all dimensions','line_number':18882,'multiline':False]
['text':' FIXME: cannot specify keepdim without dim','line_number':18903,'multiline':False]
['text':' FIXME: dim=[] reduces all dimensions','line_number':18905,'multiline':False]
['text':' FIXME: improve precision','line_number':18908,'multiline':False]
['text':' NumPy is giving NaN for this','line_number':18911,'multiline':False]
['text':' FIXME: dim=[] reduces all dimensions','line_number':18930,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/80411','line_number':18940,'multiline':False]
['text':' FIXME: prod does not support passing keepdim without passing dim','line_number':18952,'multiline':False]
['text':' FIXME: prod reduces all dimensions when dim=[]','line_number':18954,'multiline':False]
['text':' FIXME: prod does not support passing None to dim','line_number':18957,'multiline':False]
['text':' FIXME: ValueError: The data in MaskedTensor a and Tensor b do not match','line_number':18964,'multiline':False]
['text':' FIXME: sum does not support passing keepdim without passing dim','line_number':18987,'multiline':False]
['text':' FIXME: sum reduces all dimensions when dim=[]','line_number':18989,'multiline':False]
['text':' FIXME: improve precision','line_number':18992,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':19015,'multiline':False]
['text':' FIXME: nansum reduces all dimensions when dim=[]','line_number':19017,'multiline':False]
['text':' FIXME: flaky test so skipped instead of xfailed','line_number':19020,'multiline':False]
['text':' possibly bad low precision reference in numpy','line_number':19021,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/67462','line_number':19032,'multiline':False]
['text':' torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0','line_number':19033,'multiline':False]
['text':' RuntimeError: derivative for aten::_ctc_loss_backward is not implemented','line_number':19040,'multiline':False]
['text':' RuntimeError: derivative for aten::_ctc_loss_backward is not implemented','line_number':19047,'multiline':False]
['text':' Ref: https://github.com/pytorch/pytorch/issues/85231','line_number':19054,'multiline':False]
['text':' RuntimeError:','line_number':19078,'multiline':False]
['text':' undefined value tensor:','line_number':19079,'multiline':False]
['text':'   File "<string>", line 3','line_number':19080,'multiline':False]
['text':' def the_method(i0, i1):','line_number':19081,'multiline':False]
['text':'     return torch.nn.functional.nll_loss(i0, i1, weight=tensor([8.4784, 1.7658, 4.3228], dtype=torch.float32))','line_number':19082,'multiline':False]
['text':'                                                        ~~~~~~ <--- HERE','line_number':19083,'multiline':False]
['text':' Runs very slowly on slow gradcheck - alternatively reduce input sizes','line_number':19090,'multiline':False]
['text':' Pre-existing condition (calls .item); needs to be fixed','line_number':19098,'multiline':False]
['text':' Pre-existing condition (calls .item); needs to be fixed','line_number':19101,'multiline':False]
['text':' JIT does not support variadic tensors.','line_number':19103,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalType','line_number':19104,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270,','line_number':19105,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':19106,'multiline':False]
['text':' JIT does not support variadic tensors.','line_number':19129,'multiline':False]
['text':' RuntimeError: input->type()->kind() == TypeKind::OptionalType','line_number':19130,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../torch/csrc/jit/passes/utils/check_alias_annotation.cpp":270,','line_number':19131,'multiline':False]
['text':' please report a bug to PyTorch.','line_number':19132,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':19180,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/pull/78358','line_number':19259,'multiline':False]
['text':' complex not added to dtypes as complex gradients are not properly handled','line_number':19265,'multiline':False]
['text':' and scatter_reduce hasn't been added to the whitelist in gen_variable_type yet','line_number':19266,'multiline':False]
['text':' complex not added to dtypes as complex gradients are not properly handled','line_number':19275,'multiline':False]
['text':' and scatter_reduce hasn't been added to the whitelist in gen_variable_type yet','line_number':19276,'multiline':False]
['text':' Not implemented','line_number':19281,'multiline':False]
['text':' complex not added to dtypes as complex gradients are not properly handled','line_number':19290,'multiline':False]
['text':' and scatter_reduce hasn't been added to the whitelist in gen_variable_type yet','line_number':19291,'multiline':False]
['text':' RuntimeError: derivative for aten::_segment_reduce_backward is not implemented','line_number':19324,'multiline':False]
['text':' FIXME: CUDA driver API confirmed a leak in','line_number':19328,'multiline':False]
['text':' __main__.TestJitCUDA.test_variant_consistency_jit_segment_reduce_cuda_float32','line_number':19329,'multiline':False]
['text':' RuntimeError: derivative for aten::_segment_reduce_backward is not implemented','line_number':19344,'multiline':False]
['text':' FIXME: CUDA driver API confirmed a leak in','line_number':19348,'multiline':False]
['text':' __main__.TestJitCUDA.test_variant_consistency_jit_segment_reduce_cuda_float32','line_number':19349,'multiline':False]
['text':' Separate registry for experimental Python Reference OpInfos.','line_number':19362,'multiline':False]
['text':'','line_number':19364,'multiline':False]
['text':' Elementwise Unary OpInfos','line_number':19365,'multiline':False]
['text':'','line_number':19366,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/49224','line_number':19371,'multiline':False]
['text':' Failing with wrong imaginary sign on at least some Windows jobs','line_number':19389,'multiline':False]
['text':' Failing with wrong imaginary sign on at least some Windows jobs','line_number':19394,'multiline':False]
['text':' Failing with wrong imaginary sign on at least some Windows jobs','line_number':19433,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':19501,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':19511,'multiline':False]
['text':' TODO: RuntimeError: no _refs support for torch.rand_like','line_number':19521,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':19525,'multiline':False]
['text':' dtypes that do not support check_uniform_bounds of rand_like','line_number':19545,'multiline':False]
['text':' TODO: RuntimeError: no _refs support for torch.rand_like','line_number':19550,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':19555,'multiline':False]
['text':' dtypes that do not support check_uniform_bounds of rand_like','line_number':19575,'multiline':False]
['text':' TODO: RuntimeError: no _refs support for torch.rand_like','line_number':19582,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':19590,'multiline':False]
['text':' TODO: RuntimeError: no _refs support for torch.rand_like','line_number':19609,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':19617,'multiline':False]
['text':' TODO: RuntimeError: no _refs support for torch.rand_like','line_number':19636,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':19641,'multiline':False]
['text':' TODO: RuntimeError: no _refs support for torch.rand_like','line_number':19665,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':19670,'multiline':False]
['text':' TODO: RuntimeError: no _refs support for torch.rand_like','line_number':19695,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':19700,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':19722,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':19732,'multiline':False]
['text':' cpu implementation is wrong on some integral types','line_number':19737,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/81996','line_number':19738,'multiline':False]
['text':' cuda implementation is off-by-one on some inputs due to precision issues','line_number':19744,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/82230','line_number':19745,'multiline':False]
['text':' TypeError: 'int' object is not subscriptable','line_number':19762,'multiline':False]
['text':' cpu implementation is wrong on some integral types','line_number':19766,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/81996','line_number':19767,'multiline':False]
['text':' cuda implementation is off-by-one on some inputs due to precision issues','line_number':19773,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/82230','line_number':19774,'multiline':False]
['text':' Tests that assume input is a tensor or sequence of tensors','line_number':19790,'multiline':False]
['text':' Off-by-one issue when casting floats to ints','line_number':19795,'multiline':False]
['text':' TypeError: 'int' object is not subscriptable','line_number':19812,'multiline':False]
['text':' Off-by-one issue when casting floats to ints','line_number':19816,'multiline':False]
['text':' the implementation uses torch.stack that violates view consistency','line_number':19857,'multiline':False]
['text':' skip these tests since we have non tensor input','line_number':19860,'multiline':False]
['text':' the implementation uses torch.stack that violates view consistency','line_number':19869,'multiline':False]
['text':' skip these tests since we have non tensor input','line_number':19872,'multiline':False]
['text':' RuntimeError: It appears that you're trying to get value out of a tracing tensor with','line_number':19892,'multiline':False]
['text':'  aten._local_scalar_dense.default - erroring out! [...]','line_number':19893,'multiline':False]
['text':' triggered by mid_val = boundaries[mid]','line_number':19894,'multiline':False]
['text':' RuntimeError: Cannot cast FakeTensor to number','line_number':19902,'multiline':False]
['text':' Fails on int32','line_number':19973,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/85258','line_number':19974,'multiline':False]
['text':' RuntimeError: Cannot cast FakeTensor(FakeTensor(..., device='meta', size=()), cpu) to number','line_number':19980,'multiline':False]
['text':' ValueError: Can't convert a tensor with 10 elements to a number!','line_number':19982,'multiline':False]
['text':' This fails on CUDA but passes on ROCm','line_number':19998,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':20009,'multiline':False]
['text':' Greatest absolute difference: nan at index (700,) (up to 1e-05 allowed)','line_number':20010,'multiline':False]
['text':' Greatest relative difference: nan at index (700,) (up to 0.001 allowed)','line_number':20011,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/48641','line_number':20022,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':20043,'multiline':False]
['text':' Greatest absolute difference: nan at index (6000,) (up to 1e-05 allowed)','line_number':20044,'multiline':False]
['text':' Greatest relative difference: nan at index (6000,) (up to 0.001 allowed)','line_number':20045,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/pull/49155#issuecomment-742664611','line_number':20067,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/48010','line_number':20090,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/48010','line_number':20110,'multiline':False]
['text':' Fails on int32','line_number':20127,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/85258','line_number':20128,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/pull/50140#issuecomment-756150214','line_number':20191,'multiline':False]
['text':' When keepdim=False logsumexp function uses squeeze operation','line_number':20257,'multiline':False]
['text':' that is not yet exposed in nvFuser's Python API.','line_number':20258,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/45690','line_number':20285,'multiline':False]
['text':' Fails on int32','line_number':20294,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/85258','line_number':20295,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':20313,'multiline':False]
['text':' Greatest absolute difference: nan at index (700,) (up to 0.01 allowed)','line_number':20314,'multiline':False]
['text':' Greatest relative difference: nan at index (700,) (up to 0.001 allowed)','line_number':20315,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/56012','line_number':20325,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/56012','line_number':20332,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/41245','line_number':20345,'multiline':False]
['text':' This is an issue with the vectorised abs on CPU','line_number':20355,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/41245','line_number':20359,'multiline':False]
['text':' Fails on CUDA but passes on ROCm','line_number':20375,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/49133','line_number':20395,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/48641','line_number':20417,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/47358','line_number':20438,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/pull/47293#issuecomment-721774436','line_number':20443,'multiline':False]
['text':' AssertionError: Reference result was farther (2.2417024338305655e-07) from the precise computation','line_number':20454,'multiline':False]
['text':' Reference: https://github.com/pytorch/pytorch/issues/52549','line_number':20456,'multiline':False]
['text':' Fails on int32','line_number':20506,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/85258','line_number':20507,'multiline':False]
['text':' alias','line_number':20511,'multiline':False]
['text':' alias','line_number':20517,'multiline':False]
['text':'','line_number':20521,'multiline':False]
['text':' Elementwise Unary Special OpInfos','line_number':20522,'multiline':False]
['text':'','line_number':20523,'multiline':False]
['text':'','line_number':20528,'multiline':False]
['text':' Elementwise Unary nn.functional OpInfos','line_number':20529,'multiline':False]
['text':'','line_number':20530,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':20538,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':20545,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':20549,'multiline':False]
['text':' dropout is not comparable','line_number':20590,'multiline':False]
['text':' TODO: Port this to an UnaryOpInfo','line_number':20613,'multiline':False]
['text':' Reference result was farther (3.5762786809723224e-07) from the precise computation','line_number':20621,'multiline':False]
['text':' than the torch result was (2.5068410824946596e-07)!','line_number':20622,'multiline':False]
['text':' RunTimeError: no _refs support for torch.Tensor.index_select','line_number':20642,'multiline':False]
['text':' alias','line_number':20652,'multiline':False]
['text':' alias','line_number':20698,'multiline':False]
['text':' The corresponding PyTorch op doesn't support out.  But the ref is','line_number':20735,'multiline':False]
['text':' registered as a decomp and ATen has an out variant.','line_number':20736,'multiline':False]
['text':' For simpler indexing, we flatten target indices, then reshape the result tensor.','line_number':20738,'multiline':False]
['text':' This creates inconsistent view state with reference impl.','line_number':20739,'multiline':False]
['text':' RuntimeError: It appears that you're trying to get value out of a tracing tensor - erroring out!','line_number':20742,'multiline':False]
['text':' The corresponding PyTorch op doesn't support out.  But the ref is','line_number':20751,'multiline':False]
['text':' registered as a decomp and ATen has an out variant.','line_number':20752,'multiline':False]
['text':' in each case, pytorch will produce a nan while numpy will not','line_number':20768,'multiline':False]
['text':'','line_number':20788,'multiline':False]
['text':' Elementwise Binary Reference OpInfos','line_number':20789,'multiline':False]
['text':'','line_number':20790,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/76944','line_number':20794,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/70904','line_number':20821,'multiline':False]
['text':' # https://github.com/pytorch/pytorch/issues/70904','line_number':20829,'multiline':False]
['text':' RuntimeError: Expected divisor (b) to be on the same device (cuda:0) as dividend (a), but it is found on cpu!','line_number':20845,'multiline':False]
['text':' FIXME output 0: meta disagrees with real impl','line_number':20847,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/76944','line_number':20855,'multiline':False]
['text':' NotImplementedError: argument of type: <class 'complex'>','line_number':20859,'multiline':False]
['text':' Reference result was farther (0.7433461727239705) from the precise','line_number':20864,'multiline':False]
['text':' computation than the torch result was (nan)!','line_number':20865,'multiline':False]
['text':' Reference result was farther (0.7433461727239705) from the precise','line_number':20870,'multiline':False]
['text':' computation than the torch result was (nan)!','line_number':20871,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/76944','line_number':20882,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/111126','line_number':20886,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/76944','line_number':20894,'multiline':False]
['text':' See https://github.com/pytorch/pytorch/issues/111126','line_number':20898,'multiline':False]
['text':' Test doesn't account for float -> double type promotion','line_number':20910,'multiline':False]
['text':' Complex values error with: Greatest absolute difference: nan at index','line_number':20912,'multiline':False]
['text':' failure due to mismatch in edge cases, which boils down to what torch.exp(inf + infj) should be','line_number':20928,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/76944','line_number':20943,'multiline':False]
['text':' bfloat16 floor_divide compared with a float32 reference works inconsistently','line_number':20946,'multiline':False]
['text':' bfloat16 floor_divide compared with a float32 reference works inconsistently','line_number':20952,'multiline':False]
['text':' int8 floor divide has different results for -128 // -1 vs. NumPy','line_number':20955,'multiline':False]
['text':' The following tests fails on some jobs','line_number':20959,'multiline':False]
['text':' FIXME output 0: meta disagrees with real impl','line_number':20965,'multiline':False]
['text':' PyTorch's heaviside does not appear to propagate NaNs','line_number':21026,'multiline':False]
['text':' Intentional xfail -- isclose does not type promote','line_number':21049,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/76944','line_number':21102,'multiline':False]
['text':' Reference result was farther (0.0) from the precise computation','line_number':21106,'multiline':False]
['text':' than the torch result was (nan)!','line_number':21107,'multiline':False]
['text':' Reference result was farther (0.0) from the precise computation','line_number':21112,'multiline':False]
['text':' than the torch result was (nan)!','line_number':21113,'multiline':False]
['text':' Reference result was farther (0.0) from the precise computation','line_number':21118,'multiline':False]
['text':' than the torch result was (nan)!','line_number':21119,'multiline':False]
['text':' Reference result was farther (inf) from the precise','line_number':21147,'multiline':False]
['text':' computation than the torch result was (nan)!','line_number':21148,'multiline':False]
['text':' Reference result was farther (inf) from the precise','line_number':21153,'multiline':False]
['text':' computation than the torch result was (nan)!','line_number':21154,'multiline':False]
['text':' Reference result was farther (inf) from the precise','line_number':21159,'multiline':False]
['text':' computation than the torch result was (nan)!','line_number':21160,'multiline':False]
['text':' Skipping integers because they are being raised to negative powers causing an error','line_number':21165,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/76944','line_number':21205,'multiline':False]
['text':' Reference result was farther (nan) from the precise computation than','line_number':21207,'multiline':False]
['text':' the torch result was (nan)!','line_number':21208,'multiline':False]
['text':' Reference result was farther (nan) from the precise computation than','line_number':21211,'multiline':False]
['text':' the torch result was (nan)!','line_number':21212,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/76944','line_number':21220,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/76944','line_number':21253,'multiline':False]
['text':' Reference result was farther (0.7433461727239705) from the precise','line_number':21257,'multiline':False]
['text':' computation than the torch result was (nan)!','line_number':21258,'multiline':False]
['text':' Reference result was farther (0.7433461727239705) from the precise','line_number':21263,'multiline':False]
['text':' computation than the torch result was (nan)!','line_number':21264,'multiline':False]
['text':' Reference result was farther (0.7433461727239705) from the precise','line_number':21269,'multiline':False]
['text':' computation than the torch result was (nan)!','line_number':21270,'multiline':False]
['text':'','line_number':21277,'multiline':False]
['text':' Elementwise Ternary Reference OpInfos','line_number':21278,'multiline':False]
['text':'','line_number':21279,'multiline':False]
['text':' Reference result was farther (1.3343989849090576e-05)','line_number':21288,'multiline':False]
['text':' from the precise computation than the torch result','line_number':21289,'multiline':False]
['text':' was (9.592622518539429e-06)!','line_number':21290,'multiline':False]
['text':' FIXME: enable dtype-based tolerances in test_ops.py:TestCommon._ref_test_helper','line_number':21291,'multiline':False]
['text':' test error disabled since rhs non-tensor python scalar is supported','line_number':21302,'multiline':False]
['text':' test error disabled since rhs non-tensor python scalar is supported','line_number':21310,'multiline':False]
['text':' TODO: Uses minimum and clamp','line_number':21322,'multiline':False]
['text':' AssertionError: Tensor-likes are not close!','line_number':21324,'multiline':False]
['text':' Greatest absolute difference: 6.103515625e-05 at index (4,) (up to 1e-05 allowed)','line_number':21325,'multiline':False]
['text':' Greatest relative difference: 8.519846983548175e-06 at index (4,) (up to 1.3e-06 allowed)','line_number':21326,'multiline':False]
['text':'','line_number':21336,'multiline':False]
['text':' Elementwise Binary Special OpInfos','line_number':21337,'multiline':False]
['text':'','line_number':21338,'multiline':False]
['text':'','line_number':21344,'multiline':False]
['text':' Data Conversion & Data Movement Opinfos','line_number':21345,'multiline':False]
['text':'','line_number':21346,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21350,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21351,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21352,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21358,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21359,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21360,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21366,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21367,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21368,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21377,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21378,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21379,'multiline':False]
['text':' Tests don't account for complex's type promotion semantics','line_number':21390,'multiline':False]
['text':' Tests don't account for complex's type promotion semantics','line_number':21399,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21407,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21408,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21409,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21415,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21416,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21417,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21423,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21424,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21425,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21431,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21432,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21433,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21442,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21443,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21444,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21453,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21454,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21455,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21464,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21465,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21466,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21472,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21473,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21474,'multiline':False]
['text':' TODO: If self already has the correct dtype and device, then self is','line_number':21480,'multiline':False]
['text':' returned ignoring memory_format.','line_number':21481,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/86558','line_number':21482,'multiline':False]
['text':'','line_number':21489,'multiline':False]
['text':' View & Shape OpInfos','line_number':21490,'multiline':False]
['text':'','line_number':21491,'multiline':False]
['text':' FIXME: doesn't support chalf','line_number':21510,'multiline':False]
['text':' cloned_mutable_input.is_same(returned_output) INTERNAL ASSERT FAILED','line_number':21513,'multiline':False]
['text':' FIXME: doesn't support chalf','line_number':21523,'multiline':False]
['text':' cloned_mutable_input.is_same(returned_output) INTERNAL ASSERT FAILED','line_number':21526,'multiline':False]
['text':' returns a view of an intermediate tensor (as_strided)','line_number':21536,'multiline':False]
['text':' FIXME: AssertionError: RuntimeError not raised','line_number':21559,'multiline':False]
['text':' returns a view of an intermediate tensor (as_strided)','line_number':21609,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/78613','line_number':21652,'multiline':False]
['text':' TensorMeta doesn't support tolist','line_number':21741,'multiline':False]
['text':' RuntimeError: no _refs support for torch.Tensor.tolist','line_number':21743,'multiline':False]
['text':' .conj() does not set ._is_view() correctly in ATen','line_number':21759,'multiline':False]
['text':' RuntimeError: no _refs support for torch.Tensor.is_conj','line_number':21762,'multiline':False]
['text':' .conj() does not set ._is_view() correctly in ATen','line_number':21770,'multiline':False]
['text':' RuntimeError: no _refs support for torch.Tensor.is_conj','line_number':21773,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/78613','line_number':21815,'multiline':False]
['text':'','line_number':21827,'multiline':False]
['text':' Reduction Reference OpInfos','line_number':21828,'multiline':False]
['text':'','line_number':21829,'multiline':False]
['text':' FIXME: uint8 input returns uint8 instead of bool','line_number':21834,'multiline':False]
['text':' FIXME: reduces all dimensions when dim=[]','line_number':21845,'multiline':False]
['text':' FIXME: reduces all dimensions when dim=[]','line_number':21857,'multiline':False]
['text':' FIXME: uint8 input returns uint8 instead of bool','line_number':21868,'multiline':False]
['text':' FIXME: count_nonzero does not accept keepdim kwarg','line_number':21878,'multiline':False]
['text':' FIXME: dim=[] reduces all dimensions','line_number':21893,'multiline':False]
['text':' FIXME: reduces all dimensions when dim=[]','line_number':21903,'multiline':False]
['text':' FIXME: reduces all dimensions when dim=[]','line_number':21915,'multiline':False]
['text':' FIXME: improve precision','line_number':21920,'multiline':False]
['text':' std_mean and var_mean are not ReductionInfos','line_number':21930,'multiline':False]
['text':' FIXME: doesn't test out behavior properly for this operator','line_number':21940,'multiline':False]
['text':' FIXME: mean reduces all dimensions when dim=[]','line_number':21942,'multiline':False]
['text':' FIXME: improve precision','line_number':21946,'multiline':False]
['text':' doesn't test out behavior properly for this operator','line_number':21964,'multiline':False]
['text':' doesn't test out behavior properly for this operator','line_number':21973,'multiline':False]
['text':' FIXME: doesn't test out behavior properly for this operator','line_number':21988,'multiline':False]
['text':' FIXME: reduces all dimensions when dim=[]','line_number':21990,'multiline':False]
['text':' FIXME: improve precision','line_number':21995,'multiline':False]
['text':' FIXME: reduces all dimensions when dim=[]','line_number':22006,'multiline':False]
['text':' FIXME: improve precision','line_number':22011,'multiline':False]
['text':'','line_number':22021,'multiline':False]
['text':' Linear Algebra Operators','line_number':22022,'multiline':False]
['text':'','line_number':22023,'multiline':False]
['text':' Uses vector_norm inside and vector_norm is affected by','line_number':22039,'multiline':False]
['text':' https://github.com/pytorch/pytorch/issues/77216','line_number':22040,'multiline':False]
['text':'','line_number':22043,'multiline':False]
['text':' Tensor Creation Reference OpInfos','line_number':22044,'multiline':False]
['text':'','line_number':22045,'multiline':False]
['text':' FIXME: shouldn't check empty results','line_number':22071,'multiline':False]
['text':' FIXME: should not compare results of empty_like','line_number':22101,'multiline':False]
['text':' see https://github.com/pytorch/pytorch/issues/85121','line_number':22111,'multiline':False]
['text':' These tests expect the input to be a tensor or a sequence of tensors','line_number':22115,'multiline':False]
['text':' skip these tests since we have non tensor input','line_number':22126,'multiline':False]
['text':' FIXME: should not compare results of empty_like','line_number':22157,'multiline':False]
['text':'','line_number':22225,'multiline':False]
['text':' Conditional Reference OpInfos','line_number':22226,'multiline':False]
['text':'','line_number':22227,'multiline':False]
['text':' empty_strided','line_number':22246,'multiline':False]
['text':' no _refs support for Tensor.__setitem__','line_number':22248,'multiline':False]
['text':' Sample out= with a stride of zero. This _out operation checks that the input has no','line_number':22250,'multiline':False]
['text':' inner overlap','line_number':22251,'multiline':False]
['text':' empty_strided','line_number':22257,'multiline':False]
['text':' no _refs support for Tensor.__setitem__','line_number':22259,'multiline':False]
['text':' empty_strided','line_number':22266,'multiline':False]
['text':' no _refs support for Tensor.__setitem__','line_number':22268,'multiline':False]
['text':' empty_strided','line_number':22276,'multiline':False]
['text':' no _refs support for Tensor.__setitem__','line_number':22278,'multiline':False]
['text':'','line_number':22281,'multiline':False]
['text':' Test-related functions','line_number':22282,'multiline':False]
['text':'','line_number':22283,'multiline':False]
['text':'','line_number':22288,'multiline':False]
['text':' Misc functions','line_number':22289,'multiline':False]
['text':'','line_number':22290,'multiline':False]
['text':' RuntimeError: no _refs support for aten.pad','line_number':22295,'multiline':False]
['text':' RuntimeError: no _refs support for aten.unfold_backward','line_number':22305,'multiline':False]
['text':' Common operator groupings','line_number':22318,'multiline':False]
['text':' TODO: review porting these to make_tensor','line_number':22333,'multiline':False]
['text':' Copied from functorch','line_number':22362,'multiline':False]
['text':' This decorator doesn't modify fn in any way','line_number':22392,'multiline':False]
