['text':' Events (operator invocations) that are expected to be ran as part of the above','line_number':75,'multiline':False]
['text':' function.','line_number':76,'multiline':False]
['text':' Remote operations are prefixed with the following string for RPC profiling.','line_number':87,'multiline':False]
['text':' RpcBackendOptions.','line_number':118,'multiline':False]
['text':' it is used to test python user defined function over rpc','line_number':138,'multiline':False]
['text':' classes and functions are used to test python user defined class and','line_number':139,'multiline':False]
['text':' methods over rpc','line_number':140,'multiline':False]
['text':' delay initialization to simulate errors if specified','line_number':178,'multiline':False]
['text':' this method returns immediately without blocking the callee, but will','line_number':306,'multiline':False]
['text':' generate additional requests.','line_number':307,'multiline':False]
['text':' Note that it needs to inherit from Exception, not BaseException. See comment','line_number':398,'multiline':False]
['text':' in rpc/internal.py','line_number':399,'multiline':False]
['text':' TODO: use torch.futures.collect_all','line_number':546,'multiline':False]
['text':' A custom Python class that contains a tensor, needed to see if we correctly','line_number':587,'multiline':False]
['text':' use the Python pickler to extract tensors from non-IValue-convertible types.','line_number':588,'multiline':False]
['text':' Add one non-picklable field, to ensure it's ignored/skipped.','line_number':594,'multiline':False]
['text':' Must call the __init__ of the superclass (and do so directly,','line_number':641,'multiline':False]
['text':' without using super()) because... pybind.','line_number':642,'multiline':False]
['text':' load_tests from common_utils is used to automatically filter tests for','line_number':647,'multiline':False]
['text':' sharding on sandcastle. This line silences flake warnings','line_number':648,'multiline':False]
['text':' intentionally adding delay to current CUDA stream','line_number':722,'multiline':False]
['text':' return an empty dict to avoid inspecting the model contents on the','line_number':727,'multiline':False]
['text':' owner','line_number':728,'multiline':False]
['text':' worker0 drives and waits for worker1 and worker2','line_number':822,'multiline':False]
['text':' throughout the test.','line_number':823,'multiline':False]
['text':' Phase 1: Only worker1 has workload.','line_number':827,'multiline':False]
['text':' Phase 2: Only worker2 has workload.','line_number':837,'multiline':False]
['text':' If join is not correctly implemented,','line_number':838,'multiline':False]
['text':' worker2 should be closed by now.','line_number':839,'multiline':False]
['text':' worker0 calls this at the end after waiting for RPC responses.','line_number':861,'multiline':False]
['text':' worker1/2 calls this immediately and has some works after it.','line_number':862,'multiline':False]
['text':' worker3 calls this immediately and has no more work.','line_number':863,'multiline':False]
['text':' Wait before proceeding to shutdown to ensure worker0 RPCs make','line_number':866,'multiline':False]
['text':' it through to other workers.','line_number':867,'multiline':False]
['text':' worker0 calls this at the end after waiting for RPC responses.','line_number':883,'multiline':False]
['text':' worker1/2 calls this immediately and has some works after it.','line_number':884,'multiline':False]
['text':' worker3 calls this immediately and has no more work.','line_number':885,'multiline':False]
['text':' Wait before proceeding to shutdown to ensure worker0 RPCs make','line_number':889,'multiline':False]
['text':' it through to other workers.','line_number':890,'multiline':False]
['text':' Say C has 2 OwnerRRefs.','line_number':1025,'multiline':False]
['text':' B has 2 UserRRefs to those 2 OwnerRRefs, respectively.','line_number':1026,'multiline':False]
['text':' This call is effectively A asking B to share its 2 UserRRefs.','line_number':1027,'multiline':False]
['text':' We check proper CUDA stream synchronization by adding to the tensor','line_number':1088,'multiline':False]
['text':' in one stream to get the expected value, and reading it from another stream.','line_number':1089,'multiline':False]
['text':' Test dense tensor','line_number':1159,'multiline':False]
['text':' Test invalid ranks','line_number':1164,'multiline':False]
['text':' Wait for all init to complete.','line_number':1416,'multiline':False]
['text':' TODO: with TCP init, rank 0 raises Address already in use because','line_number':1419,'multiline':False]
['text':' rank 0 is the start daemon and the store is created before checking if','line_number':1420,'multiline':False]
['text':' RPC is already initialized in init_rpc.','line_number':1421,'multiline':False]
['text':' If the number in the message does not match, it is likely that the','line_number':1481,'multiline':False]
['text':' value of MAX_NAME_LEN in RPC WorkerInfo has changed.','line_number':1482,'multiline':False]
['text':' Test that WorkerInfo can be pickled and sent in RPC call','line_number':1486,'multiline':False]
['text':' Test rpc barrier when called with full list of workers','line_number':1644,'multiline':False]
['text':' Test rpc barrier when processes are called with different subsets of the full list','line_number':1652,'multiline':False]
['text':' Test rpc barrier when some processes are not involved in the barrier','line_number':1663,'multiline':False]
['text':' This tests validates the implementation of barrier when multiple threads call into it','line_number':1674,'multiline':False]
['text':' We only need to check that it does not hang in this case','line_number':1675,'multiline':False]
['text':' Initialize RPC.','line_number':1694,'multiline':False]
['text':' Tests that the name that shows up as an Event in profiling RPCs has all','line_number':1747,'multiline':False]
['text':' the necessary information.','line_number':1748,'multiline':False]
['text':' Run profiler on equivalent local op and validate shapes are the same.','line_number':1784,'multiline':False]
['text':' if cpu_memory_usage was not propagated over the wire, this set would','line_number':1807,'multiline':False]
['text':' only contain 0 (indicates no memory being profiled)','line_number':1808,'multiline':False]
['text':' No memory profiled if profile_memory=False','line_number':1810,'multiline':False]
['text':' tests that remote events are properly prefixed with the RPC profiling key.','line_number':1842,'multiline':False]
['text':' Spawn multiple threads that send RPCs to ensure keys are correctly','line_number':1846,'multiline':False]
['text':' prefixed when there are multiple RPCs being created/in flight at the','line_number':1847,'multiline':False]
['text':' same time.','line_number':1848,'multiline':False]
['text':' Ensure that we have the expected key as part of the remote','line_number':1869,'multiline':False]
['text':' event.','line_number':1870,'multiline':False]
['text':' Ensure that the remote event name also contains the operator.','line_number':1874,'multiline':False]
['text':' Note: we don't assert that every remote event needs to be','line_number':1876,'multiline':False]
['text':' in the above set, the set is just a representative set of','line_number':1877,'multiline':False]
['text':' what we expect to see. The profiler can change and add more','line_number':1878,'multiline':False]
['text':' events, but we should always expect to see this representative','line_number':1879,'multiline':False]
['text':' set.','line_number':1880,'multiline':False]
['text':' The set should be empty, otherwise its contained elements did','line_number':1888,'multiline':False]
['text':' not show up in the remote profiler output.','line_number':1889,'multiline':False]
['text':' Wait for workers to finish test','line_number':1905,'multiline':False]
['text':' Tests that we can successfully invoke the profiler on a remote node,','line_number':1910,'multiline':False]
['text':' and collect the remote events back in the local profiler.','line_number':1911,'multiline':False]
['text':' Remote event should have a node ID corresponding to the worker','line_number':1945,'multiline':False]
['text':' it ran on.','line_number':1946,'multiline':False]
['text':' Validate order remote events show up in profiling output.','line_number':1949,'multiline':False]
['text':' slow_async_add resulted in an RPC from dst1 -> dst2, so this should be','line_number':2002,'multiline':False]
['text':' recorded.','line_number':2003,'multiline':False]
['text':' slow_async_add's RPC does an add on dst2, which should be reflected as well.','line_number':2019,'multiline':False]
['text':' Validate that node_id is dst2.','line_number':2028,'multiline':False]
['text':' test that functions run over RPC with record_function show the expected','line_number':2049,'multiline':False]
['text':' profiled block.','line_number':2050,'multiline':False]
['text':' cpu_children only returns direct children, so here we get all','line_number':2067,'multiline':False]
['text':' children recursively.','line_number':2068,'multiline':False]
['text':' Get local children and verify parity.','line_number':2079,'multiline':False]
['text':' Cases where we can double wrap messages with profiling information and autograd info.','line_number':2129,'multiline':False]
['text':' Ensure that flipped order of ctx managers results in events being','line_number':2136,'multiline':False]
['text':' recorded as expected.','line_number':2137,'multiline':False]
['text':' only run profiler on rank 1.','line_number':2157,'multiline':False]
['text':' kineto','line_number':2158,'multiline':False]
['text':' Ensure multiple async RPCs don't cause issues.','line_number':2174,'multiline':False]
['text':' Would have raised','line_number':2175,'multiline':False]
['text':' "RuntimeError: Cannot call','line_number':2176,'multiline':False]
['text':' RemoteProfilerManager::setCurrentKey when current','line_number':2177,'multiline':False]
['text':' key is already set." error if RPC profiling was','line_number':2178,'multiline':False]
['text':' not disabled properly for kineto.','line_number':2179,'multiline':False]
['text':' To avoid flakiness, wait for the RRef to be profiled. This','line_number':2187,'multiline':False]
['text':' means that we received the acknowledgement of successful','line_number':2188,'multiline':False]
['text':' creation on the owner and ran the callbacks responsible','line_number':2189,'multiline':False]
['text':' for recording the profiling event.','line_number':2190,'multiline':False]
['text':' RPC profiling is disabled so there should be no rpc related','line_number':2195,'multiline':False]
['text':' events.','line_number':2196,'multiline':False]
['text':' verify Node ID for this rpc event.','line_number':2203,'multiline':False]
['text':' Ensure recording of remote events.','line_number':2205,'multiline':False]
['text':' Since RPC call is within the scope, its CPU interval should be','line_number':2213,'multiline':False]
['text':' contained within foo's interval.','line_number':2214,'multiline':False]
['text':' the sender, dest worker, function run, and type of RPC should all','line_number':2217,'multiline':False]
['text':' be recorded.','line_number':2218,'multiline':False]
['text':' verify order by ensuring that the outer context comes','line_number':2223,'multiline':False]
['text':' before the rpc event.','line_number':2224,'multiline':False]
['text':' Test to ensure that kineto profiler enabled in RPC does not enable','line_number':2263,'multiline':False]
['text':' RPC profiling (it is unsupported) and does not result in issues.','line_number':2264,'multiline':False]
['text':' test remote to self','line_number':2299,'multiline':False]
['text':' test remote to self','line_number':2320,'multiline':False]
['text':' test remote to self','line_number':2384,'multiline':False]
['text':' Get top-level events from all events happened on a thread.','line_number':2400,'multiline':False]
['text':' Validate that calling the function twice results in an error.','line_number':2451,'multiline':False]
['text':' Test the legacy _record_function ops work','line_number':2466,'multiline':False]
['text':' Note: These exist for backward compatibility with TorchScript','line_number':2467,'multiline':False]
['text':' Intentionally calling record_function internals','line_number':2496,'multiline':False]
['text':' Validate that the profiling future returns the same value as the RPC','line_number':2499,'multiline':False]
['text':' future.','line_number':2500,'multiline':False]
['text':' This barrier prevents a race condition where the main thread has','line_number':2628,'multiline':False]
['text':' not entered the context manager when the remote function runs.','line_number':2629,'multiline':False]
['text':' This barrier prevents a race condition where the main thread exits','line_number':2637,'multiline':False]
['text':' context manager before the remote function has ran.','line_number':2638,'multiline':False]
['text':' Validate that trainers log errors when running functions.','line_number':2641,'multiline':False]
['text':' Ensure newlines are unescaped to provide a better repr of error.','line_number':2654,'multiline':False]
['text':' This test will exit right away, but there will be a chain of async','line_number':2793,'multiline':False]
['text':' RPCs. The termination algorithm should detect those messages properly.','line_number':2794,'multiline':False]
['text':' Otherwise, some peer could exit early, leaving others to timeout','line_number':2795,'multiline':False]
['text':' errors or connection closed errors.','line_number':2796,'multiline':False]
['text':' check ref to other workers','line_number':2807,'multiline':False]
['text':' check ref to itself','line_number':2811,'multiline':False]
['text':' ensure that an error message is thrown if a user tries to call','line_number':2854,'multiline':False]
['text':' local_value() on a non-owning node.','line_number':2855,'multiline':False]
['text':' Note that cached calls with blocking=False all return the same','line_number':2930,'multiline':False]
['text':' cached original future.','line_number':2931,'multiline':False]
['text':' Ensure we never launch another RPC, other than for the very','line_number':2935,'multiline':False]
['text':' first call.','line_number':2936,'multiline':False]
['text':' 10 ms timeout','line_number':2955,'multiline':False]
['text':' Blocking: error raised inline','line_number':2957,'multiline':False]
['text':' Non-blocking: Immediately return future, block on wait','line_number':2962,'multiline':False]
['text':' to ensure clean termination','line_number':3017,'multiline':False]
['text':' creates a remote object','line_number':3079,'multiline':False]
['text':' modifies state of the remote object','line_number':3082,'multiline':False]
['text':' queries state of the remote object','line_number':3099,'multiline':False]
['text':' Notice `rpc.api.shutdown()` accesses','line_number':3106,'multiline':False]
['text':' `_delete_all_user_and_unforked_owner_rrefs` through','line_number':3107,'multiline':False]
['text':' `torch.distributed.rpc.api`, so patching','line_number':3108,'multiline':False]
['text':' `torch.distributed.rpc._delete_all_user_and_unforked_owner_rrefs` will','line_number':3109,'multiline':False]
['text':' not help.','line_number':3110,'multiline':False]
['text':' Wait for all init to complete.','line_number':3122,'multiline':False]
['text':' Tests that we can obtain the future corresponding to the creation of','line_number':3170,'multiline':False]
['text':' the RRef on remote end','line_number':3171,'multiline':False]
['text':' Builtin','line_number':3173,'multiline':False]
['text':' UDF','line_number':3179,'multiline':False]
['text':' Script','line_number':3185,'multiline':False]
['text':' This test checks local states that are modified by remote workers.','line_number':3194,'multiline':False]
['text':' This means that we would need barrier before and after every check.','line_number':3195,'multiline':False]
['text':' The barrier before the check makes sure that all previous states are','line_number':3196,'multiline':False]
['text':' cleared globally, the barrier after ensures that no following states','line_number':3197,'multiline':False]
['text':' change gets into the current check.','line_number':3198,'multiline':False]
['text':' Check 1: local RRef does not update owners_ map or add a pending user.','line_number':3201,'multiline':False]
['text':'################################################','line_number':3202,'multiline':False]
['text':' don't need a barrier here as local RRef is handled by this thread','line_number':3206,'multiline':False]
['text':' RRef on local value is not added to context until shared across RPC','line_number':3210,'multiline':False]
['text':' barrier after the check 1','line_number':3213,'multiline':False]
['text':' Check 2: Sharing RRef as an arg should update owners_ map','line_number':3216,'multiline':False]
['text':'##########################################################','line_number':3217,'multiline':False]
['text':' barrier before check 2','line_number':3222,'multiline':False]
['text':' no pending users since the fork is finished','line_number':3229,'multiline':False]
['text':' barrier after check 2','line_number':3231,'multiline':False]
['text':' clear states for check 2','line_number':3234,'multiline':False]
['text':' Wait for owner rref to be cleared.','line_number':3237,'multiline':False]
['text':' Check 3: rpc.remote call should update owners_ map','line_number':3243,'multiline':False]
['text':'###################################################','line_number':3244,'multiline':False]
['text':' barrier before check 3','line_number':3254,'multiline':False]
['text':' no pending users since the fork is finished','line_number':3261,'multiline':False]
['text':' barrier after check 3','line_number':3264,'multiline':False]
['text':' test that rpc.enable_gil_profiling(false) will result in','line_number':3269,'multiline':False]
['text':' GIL wait time not being recorded.','line_number':3270,'multiline':False]
['text':' GIL profiling should be disabled by default.','line_number':3272,'multiline':False]
['text':' test that we can start RPC and then immediately locally shutdown','line_number':3288,'multiline':False]
['text':' without sending any messages.','line_number':3289,'multiline':False]
['text':' pass in graceful=False to ensure that we don't wait for other workers.','line_number':3297,'multiline':False]
['text':' only test keys in this test case. Values should be covered by','line_number':3302,'multiline':False]
['text':' individual module debug info tests','line_number':3303,'multiline':False]
['text':' NB: Key ordering is only preserved in python 3.6+. So here, we','line_number':3316,'multiline':False]
['text':' manually check keys are equal.','line_number':3317,'multiline':False]
['text':' test that if a callee node has gone down, we raise an appropriate','line_number':3330,'multiline':False]
['text':' exception instead of just crashing.','line_number':3331,'multiline':False]
['text':' This barrier is needed to ensure that some workers do not exit before','line_number':3340,'multiline':False]
['text':' others have been brought up.','line_number':3341,'multiline':False]
['text':' allow destination worker to exit without joining','line_number':3347,'multiline':False]
['text':' Shutdown sequence is not very well defined and as a result','line_number':3351,'multiline':False]
['text':' we can see any of the error messages defined in get_shutdown_error_regex.','line_number':3352,'multiline':False]
['text':' exit all workers non-gracefully.','line_number':3355,'multiline':False]
['text':' this test is copied from https://github.com/pytorch/pytorch/issues/45089','line_number':3360,'multiline':False]
['text':' test that we can start RPC, send RPCs, and then run local shutdown.','line_number':3378,'multiline':False]
['text':' A barrier is needed to ensure that all RPCs are processed.','line_number':3393,'multiline':False]
['text':' Otherwise, some RPCs can timeout since the receiving end','line_number':3394,'multiline':False]
['text':' has terminated.','line_number':3395,'multiline':False]
['text':' pass in graceful=False to ensure that we don't wait for other workers.','line_number':3398,'multiline':False]
['text':' A new `RpcBackendOptions` is constructed','line_number':3405,'multiline':False]
['text':' when accessing `self.rpc_backend_options`.','line_number':3406,'multiline':False]
['text':' 1 ms','line_number':3428,'multiline':False]
['text':' futures should time out and be marked with an exception indicating it as such.','line_number':3429,'multiline':False]
['text':' ensure that if a new timeout is set old futures don't time out but new ones do.','line_number':3439,'multiline':False]
['text':' 200 seconds','line_number':3440,'multiline':False]
['text':' create a longstanding RPC.','line_number':3441,'multiline':False]
['text':' now, set a short timeout.','line_number':3443,'multiline':False]
['text':' fut2 should time out, fut1 should not.','line_number':3445,'multiline':False]
['text':' Zero timeout means infinity, so future should run to completion.','line_number':3451,'multiline':False]
['text':' reset to default timeout so shutdown messages can process cleanly.','line_number':3455,'multiline':False]
['text':' TODO: enable timeouts for rpc.remote/RRef (https://github.com/pytorch/pytorch/issues/33803)','line_number':3460,'multiline':False]
['text':' 100 ms','line_number':3463,'multiline':False]
['text':' Test async UDF','line_number':3465,'multiline':False]
['text':' Ensure run to completion if there is no timeout and we use the default','line_number':3470,'multiline':False]
['text':' RPC timeout.','line_number':3471,'multiline':False]
['text':' Test sync UDF','line_number':3474,'multiline':False]
['text':' Ensure run to completion if there is no timeout and we use the default','line_number':3478,'multiline':False]
['text':' RPC timeout.','line_number':3479,'multiline':False]
['text':' If we set a default timeout for RPCs, it should be respected, though','line_number':3482,'multiline':False]
['text':' still overridden if we pass in a different timeout to the APIs.','line_number':3483,'multiline':False]
['text':' The RPCs should run to completion since we override the timeout.','line_number':3491,'multiline':False]
['text':' Passing in a zero timeout should ensure that the RPC won't time out.','line_number':3494,'multiline':False]
['text':' Reset for clean shutdown','line_number':3497,'multiline':False]
['text':' 100 ms','line_number':3556,'multiline':False]
['text':' Initialize the event in the subprocess.','line_number':3612,'multiline':False]
['text':' Wait for all processes to initialize event.','line_number':3615,'multiline':False]
['text':' We should receive the error from fut2','line_number':3624,'multiline':False]
['text':' Unblock RPC thread for fut1','line_number':3628,'multiline':False]
['text':' Initialize the event in the subprocess.','line_number':3633,'multiline':False]
['text':' Wait for all processes to initialize event.','line_number':3636,'multiline':False]
['text':' We should receive the error from fut2','line_number':3645,'multiline':False]
['text':' Unblock RPC thread for fut1','line_number':3649,'multiline':False]
['text':' Initialize the event in the subprocess.','line_number':3654,'multiline':False]
['text':' Wait for all processes to initialize event.','line_number':3657,'multiline':False]
['text':' We should receive the error from fut2','line_number':3666,'multiline':False]
['text':' Unblock RPC thread for fut1','line_number':3670,'multiline':False]
['text':' test that if a function does not exist on a callee, we don't crash,','line_number':3676,'multiline':False]
['text':' instead we get an AttributeError indicating that the func does not exist.','line_number':3677,'multiline':False]
['text':' Use delattr to remove the binding of a func on this nodes','line_number':3683,'multiline':False]
['text':' notify remote end that we have removed it.','line_number':3685,'multiline':False]
['text':' func exists on caller, but not callee.','line_number':3689,'multiline':False]
['text':' wait for remote end to remove the binding of foo_add func.','line_number':3690,'multiline':False]
['text':' Ensure that we have the attribute on this module. Otherwise, the test could fail due to a caller-side pickling error.','line_number':3692,'multiline':False]
['text':' This is to make Python not garbage collect a and b.','line_number':3706,'multiline':False]
['text':' pass in graceful=True to ensure that local UserRRefs are deleted.','line_number':3733,'multiline':False]
['text':' Create a non-contiguous tensor.','line_number':3807,'multiline':False]
['text':' Send non-cont tensor over RPC.','line_number':3815,'multiline':False]
['text':' Verify the returned tensor.','line_number':3819,'multiline':False]
['text':' We have no guarantee that the add_done_callback fn will execute before the test finishes.','line_number':4005,'multiline':False]
['text':' Adding a 'then' callback that runs afterwards to guarantee we wait for the first callback','line_number':4006,'multiline':False]
['text':' This test is similar to ones in FaultyProcessGroupTest, but is meant to be','line_number':4291,'multiline':False]
['text':' run with other backends besides ProcessGroup.','line_number':4292,'multiline':False]
['text':' 10 ms timeout','line_number':4298,'multiline':False]
['text':' Future corresponding to the remote creation should time out.','line_number':4300,'multiline':False]
['text':' Call to ensure pending callbacks are run.','line_number':4304,'multiline':False]
['text':' Test RPC.','line_number':4332,'multiline':False]
['text':' Test PG','line_number':4337,'multiline':False]
['text':' Test RPC.','line_number':4363,'multiline':False]
['text':' Test PG','line_number':4368,'multiline':False]
['text':' Wait for all init to complete.','line_number':4412,'multiline':False]
['text':' Use a different file name for the next initialization','line_number':4415,'multiline':False]
['text':' Ensure rpc initialization works again.','line_number':4419,'multiline':False]
['text':' Verify RPCs work after re-init.','line_number':4428,'multiline':False]
['text':' An exception should be raised if the backend isn't specified but','line_number':4460,'multiline':False]
['text':' options are given which are not an instance of any of the known','line_number':4461,'multiline':False]
['text':' agents' option classes.','line_number':4462,'multiline':False]
['text':' Do _not_ pass backend.','line_number':4470,'multiline':False]
['text':' Double backward.','line_number':4489,'multiline':False]
['text':' Test errors.','line_number':4497,'multiline':False]
['text':' Monkey-patch _broadcast_to_followers to fail, which would ensure','line_number':4552,'multiline':False]
['text':' _all_gather on leader raises an exception.','line_number':4553,'multiline':False]
['text':' Monkey-patch _delete_all_user_and_unforked_owner_rrefs to fail,','line_number':4558,'multiline':False]
['text':' which would ensure barrier is not called on followers.','line_number':4559,'multiline':False]
['text':' Validate that EXPECTED_REMOTE_EVENTS is a subset of remotely profiled','line_number':4624,'multiline':False]
['text':' events.','line_number':4625,'multiline':False]
['text':' An exception should be raised if the options are not an instance of','line_number':4634,'multiline':False]
['text':' TensorPipeRpcBackendOptions.','line_number':4635,'multiline':False]
['text':' Do _not_ pass backend.','line_number':4659,'multiline':False]
['text':' FIXME Merge this test with the corresponding one in RpcTest.','line_number':4665,'multiline':False]
['text':' FIXME Merge this test with the corresponding one in RpcTest.','line_number':4686,'multiline':False]
['text':' Set a high timeout since it doesn't affect test runtime and ensures','line_number':4689,'multiline':False]
['text':' the test doesn't erroneously timeout due to slow machines.','line_number':4690,'multiline':False]
['text':' FIXME Merge this test with the corresponding one in RpcTest.','line_number':4710,'multiline':False]
['text':' Ensure that constructing TensorPipeRpcBackendOptions with timedelta fails','line_number':4716,'multiline':False]
['text':' Test where we try to get the type of a RRef from an owner, but RRef','line_number':4726,'multiline':False]
['text':' creation is slower than timeout passed into _get_type.','line_number':4727,'multiline':False]
['text':' Blocking: blocks on inline call','line_number':4733,'multiline':False]
['text':' Non-blocking: blocks on wait','line_number':4737,'multiline':False]
['text':' FIXME We wait until the remote completed creating the OwnerRRef','line_number':4743,'multiline':False]
['text':' because there's currently a race if we shut down RPC before that.','line_number':4744,'multiline':False]
['text':' Ensure RRef is created on remote node.','line_number':4765,'multiline':False]
['text':' Case where rpc.remote() is stuck and exceeds timeout','line_number':4778,'multiline':False]
['text':' Note that even when we call rref.rpc_async() in this case, we','line_number':4782,'multiline':False]
['text':' time out in future creation, not waiting for future. This is because','line_number':4783,'multiline':False]
['text':' rref proxy function calls rref._get_type before returning future,','line_number':4784,'multiline':False]
['text':' which blocks on the RRef being created on owner node, until the','line_number':4785,'multiline':False]
['text':' specified timeout.','line_number':4786,'multiline':False]
['text':' rpc_async returns immediately and surface a timeout through wait()','line_number':4789,'multiline':False]
['text':' FIXME We wait until the remote completed creating the OwnerRRef','line_number':4793,'multiline':False]
['text':' because there's currently a race if we shut down RPC before that.','line_number':4794,'multiline':False]
['text':' Test sparse tensor','line_number':4806,'multiline':False]
['text':' Test init_rpc without world_size argument','line_number':4994,'multiline':False]
['text':' Dynamic RPC new ranks communicate with existing ranks','line_number':5005,'multiline':False]
['text':' Rank 0 will be initialized with RPC after this barrier','line_number':5018,'multiline':False]
['text':' Newly joined ranks will be able to communicate with rank 0, since that was created first','line_number':5022,'multiline':False]
['text':' Barrier to ensure that all rpc_sync calls are finished','line_number':5032,'multiline':False]
['text':' Dynamic RPC existing ranks can communicate with new ranks','line_number':5036,'multiline':False]
['text':' Rank 0 will be initialized with RPC after this barrier','line_number':5049,'multiline':False]
['text':' Rest of ranks join after barrier','line_number':5052,'multiline':False]
['text':' Newly joined ranks will be able to communicate with rank 0, since that was created first','line_number':5054,'multiline':False]
['text':' Barrier to ensure that all rpc_sync calls are finished','line_number':5068,'multiline':False]
['text':' Dynamic RPC existing ranks can communicate with new ranks using CUDA rpc','line_number':5072,'multiline':False]
['text':' Rank 0 will be initialized with RPC after this barrier','line_number':5091,'multiline':False]
['text':' Rest of ranks join after barrier','line_number':5094,'multiline':False]
['text':' Newly joined ranks will be able to communicate with rank 0, since that was created first','line_number':5096,'multiline':False]
['text':' TODO: Cuda RPC is failing due to:','line_number':5104,'multiline':False]
['text':' terminate called after throwing an instance of 'c10::Error'','line_number':5105,'multiline':False]
['text':' what():  0 <= device && static_cast<size_t>(device) < device_allocator.size()','line_number':5106,'multiline':False]
['text':' INTERNAL ASSERT FAILED at "../c10/cuda/CUDACachingAllocator.cpp":1937,','line_number':5107,'multiline':False]
['text':' please report a bug to PyTorch. Allocator not initialized for device 1: did you call init?','line_number':5108,'multiline':False]
['text':' dist.barrier()','line_number':5109,'multiline':False]
['text':' if self.rank == 0:','line_number':5110,'multiline':False]
['text':'     for i in range(1, self.world_size):','line_number':5111,'multiline':False]
['text':'         x = torch.ones(2)','line_number':5112,'multiline':False]
['text':'         result_on_device_0 = rpc.rpc_sync(worker_name(i), torch.add, args=(x.to(0), 1))','line_number':5113,'multiline':False]
['text':'         result_on_device_1 = rpc.rpc_sync(worker_name(i), torch.add, args=(x.to(1), 1))','line_number':5114,'multiline':False]
['text':'         self.assertEqual(torch.add(torch.ones(2), 1), result_on_device_0)','line_number':5115,'multiline':False]
['text':'         self.assertEqual(torch.device('cuda:0'), result_on_device_0.device)','line_number':5116,'multiline':False]
['text':'         self.assertEqual(torch.add(torch.ones(2), 1), result_on_device_1)','line_number':5117,'multiline':False]
['text':'         self.assertEqual(torch.device('cuda:1'), result_on_device_1.device)','line_number':5118,'multiline':False]
['text':' Barrier to ensure that all rpc_sync calls are finished','line_number':5120,'multiline':False]
['text':' default initialization uses file init','line_number':5126,'multiline':False]
['text':' env init','line_number':5134,'multiline':False]
['text':' tcp init','line_number':5143,'multiline':False]
['text':' Initialize a static rpc group with size = self.world_size - 1','line_number':5154,'multiline':False]
['text':' Attempt to add an additional dynamic group member','line_number':5173,'multiline':False]
['text':' Expect error message to be thrown','line_number':5175,'multiline':False]
['text':' make sure RPC is still functioning','line_number':5713,'multiline':False]
['text':' make sure RPC is still functioning','line_number':5737,'multiline':False]
['text':' This test compares rref.rpc_sync().forward(x) vs rref.remote().forward(x).to_here()','line_number':5996,'multiline':False]
['text':' If to_here() is properly synchronized with forward(x) the results must be identical','line_number':5997,'multiline':False]
['text':' This test needs multiple iterations and significant batch size to simulate real','line_number':5998,'multiline':False]
['text':' training of a CNN of MNIST-like data.','line_number':5999,'multiline':False]
['text':' see https://github.com/pytorch/pytorch/issues/54771','line_number':6000,'multiline':False]
['text':' This test compares rref.rpc_sync().forward(x) vs rref.remote().forward(x).to_here()','line_number':6051,'multiline':False]
['text':' If to_here() is properly synchronized with forward(x) the results must be identical','line_number':6052,'multiline':False]
['text':' This test needs multiple iterations and significant batch size to simulate real','line_number':6053,'multiline':False]
['text':' training of a CNN of MNIST-like data.','line_number':6054,'multiline':False]
['text':' see https://github.com/pytorch/pytorch/issues/54771','line_number':6055,'multiline':False]
['text':' devicesOptions','line_number':6086,'multiline':False]
['text':' for 1) model construction 2) forward execution','line_number':6101,'multiline':False]
['text':' Forward output will be first copied to the relay node before','line_number':6104,'multiline':False]
['text':' returning to the worker. This is intentional, to test RRef','line_number':6105,'multiline':False]
['text':' forward CUDA stream synchronizations.','line_number':6106,'multiline':False]
['text':' worker1 hosts the model and runs forward. The forward functions','line_number':6109,'multiline':False]
['text':' calls RRef.to_here(), hence needs to configure the device map','line_number':6110,'multiline':False]
['text':' worker2 will get the out RRef and call to_here() and hence, needs','line_number':6113,'multiline':False]
['text':' to configure device map.','line_number':6114,'multiline':False]
['text':' This test compares rref.rpc_sync().forward(x) vs rref.remote().forward(x).to_here()','line_number':6126,'multiline':False]
['text':' If to_here() is properly synchronized with forward(x) the results must be identical','line_number':6127,'multiline':False]
['text':' This test needs multiple iterations and significant batch size to simulate real','line_number':6128,'multiline':False]
['text':' training of a CNN of MNIST-like data.','line_number':6129,'multiline':False]
['text':' see https://github.com/pytorch/pytorch/issues/54771','line_number':6130,'multiline':False]
['text':' to_here() internally calls localValue as the caller is','line_number':6178,'multiline':False]
['text':' the owner of the RRef.','line_number':6179,'multiline':False]
['text':' serialization of the return value will create a new tensor from the','line_number':6206,'multiline':False]
['text':' view, which is done outside of the user function.','line_number':6207,'multiline':False]
['text':' We check proper CUDA stream synchronization by filling the tensor with','line_number':6322,'multiline':False]
['text':' the expected value in one stream, and reading it from another stream.','line_number':6323,'multiline':False]
['text':' As a plus, we test that futures still invoke callbacks even in case of','line_number':6351,'multiline':False]
['text':' error, and that the child futures are successful if those callbacks','line_number':6352,'multiline':False]
['text':' don't access the parent future.','line_number':6353,'multiline':False]
['text':' It's weird to modify the value of a future once it's complete, but','line_number':6430,'multiline':False]
['text':' technically possible. Currently this is considered undefined behavior','line_number':6431,'multiline':False]
['text':' (in practice the future will ignore the modification and still','line_number':6432,'multiline':False]
['text':' synchronize with the original value). We could one day add logic to','line_number':6433,'multiline':False]
['text':' detect and warn or throw in such cases, but for now we just check that','line_number':6434,'multiline':False]
['text':' this doesn't crash.','line_number':6435,'multiline':False]
['text':' It's weird to modify the value of a future once it's complete, but','line_number':6444,'multiline':False]
['text':' technically possible. Currently this is considered undefined behavior','line_number':6445,'multiline':False]
['text':' (in practice the future will ignore the modification and still','line_number':6446,'multiline':False]
['text':' synchronize with the original value). We could one day add logic to','line_number':6447,'multiline':False]
['text':' detect and warn or throw in such cases, but for now we just check that','line_number':6448,'multiline':False]
['text':' this doesn't crash.','line_number':6449,'multiline':False]
['text':' We set things up so that the original tensor contained in the list','line_number':6450,'multiline':False]
['text':' gets deleted once we replace it with the other one. This will','line_number':6451,'multiline':False]
['text':' invalidate any cached information held by the future.','line_number':6452,'multiline':False]
