['text':' Linear args','line_number':30,'multiline':False]
['text':' BatchNorm1d args','line_number':32,'multiline':False]
['text':' num_features: out_features','line_number':33,'multiline':False]
['text':' affine: True','line_number':35,'multiline':False]
['text':' track_running_stats: True','line_number':36,'multiline':False]
['text':' Args for this module','line_number':37,'multiline':False]
['text':' this needs to be called after reset_bn_parameters,','line_number':52,'multiline':False]
['text':' as they modify the same state','line_number':53,'multiline':False]
['text':' Scale the linear weights by BN's running statistics to reduce','line_number':86,'multiline':False]
['text':' weight jitter, see https://arxiv.org/pdf/1806.08342.pdf, page 18','line_number':87,'multiline':False]
['text':' for motivation.','line_number':88,'multiline':False]
['text':'','line_number':89,'multiline':False]
['text':' Instead of','line_number':90,'multiline':False]
['text':'','line_number':91,'multiline':False]
['text':'   x1 = F.linear(x0, fq(w), b)','line_number':92,'multiline':False]
['text':'   x2 = self.bn(x1)','line_number':93,'multiline':False]
['text':'','line_number':94,'multiline':False]
['text':' We have','line_number':95,'multiline':False]
['text':'','line_number':96,'multiline':False]
['text':'   # scale the weight by previous batch's running statistics','line_number':97,'multiline':False]
['text':'   scale_factor = bn.w / bn.running_std_from_prev_batch','line_number':98,'multiline':False]
['text':'   # do the linear transformation without bias','line_number':99,'multiline':False]
['text':'   x1_scaled = F.linear(x0, fq(w * scale_factor), 0)','line_number':100,'multiline':False]
['text':'   # reverse the scaling and add original bias','line_number':101,'multiline':False]
['text':'   x1_orig = x1_scaled / scale_factor + b','line_number':102,'multiline':False]
['text':'   x2 = self.bn(x1_orig)','line_number':103,'multiline':False]
