['text':' noqa: F401','line_number':6,'multiline':False]
['text':' noqa: F401','line_number':7,'multiline':False]
['text':' for each layer, for each direction we need to quantize and pack','line_number':27,'multiline':False]
['text':' weights and pack parameters in this order:','line_number':28,'multiline':False]
['text':'','line_number':29,'multiline':False]
['text':'   w_ih, w_hh','line_number':30,'multiline':False]
['text':' for each layer, for each direction we need to quantize and pack','line_number':36,'multiline':False]
['text':' weights and pack parameters in this order:','line_number':37,'multiline':False]
['text':'','line_number':38,'multiline':False]
['text':'   packed_ih, packed_hh, b_ih, b_hh','line_number':39,'multiline':False]
['text':' "type: ignore" is required since ints and Numbers are not fully comparable','line_number':86,'multiline':False]
['text':' https://github.com/python/mypy/issues/8566','line_number':87,'multiline':False]
['text':' type: ignore[operator]','line_number':89,'multiline':False]
['text':' type: ignore[operator]','line_number':93,'multiline':False]
['text':' We don't want to show `ModuleList` children, hence custom','line_number':155,'multiline':False]
['text':' `__repr__`. This is the same as nn.Module.__repr__, except the check','line_number':156,'multiline':False]
['text':' for the `PackedParameter` and `nn.ModuleList`.','line_number':157,'multiline':False]
['text':' You should still override `extra_repr` to add more info.','line_number':158,'multiline':False]
['text':' empty string will be split into list ['']','line_number':161,'multiline':False]
['text':' simple one-liner info, which most builtin Modules will use','line_number':175,'multiline':False]
['text':' TODO: dedup with __init__ of RNNBase','line_number':237,'multiline':False]
['text':' We have the circular import issues if we import the qconfig in the beginning of this file:','line_number':278,'multiline':False]
['text':' https://github.com/pytorch/pytorch/pull/24231. The current workaround is to postpone the','line_number':279,'multiline':False]
['text':' import until we need it.','line_number':280,'multiline':False]
['text':' RNNBase can be either LSTM or GRU','line_number':288,'multiline':False]
['text':' Returns a dict of weights and biases','line_number':352,'multiline':False]
['text':' packed weights are part of torchbind class, CellParamsSerializationType','line_number':361,'multiline':False]
['text':' Within the packed weight class, the weight and bias are accessible as Tensors','line_number':362,'multiline':False]
['text':' Each batch of the hidden state should match the input sequence that','line_number':417,'multiline':False]
['text':' the user believes he/she is passing in.','line_number':418,'multiline':False]
['text':' "type: ignore" is required due to issue #43072','line_number':466,'multiline':False]
['text':' type: ignore[override]','line_number':467,'multiline':False]
['text':' "type: ignore" is required due to issue #43072','line_number':474,'multiline':False]
['text':' type: ignore[override]','line_number':475,'multiline':False]
['text':' assuming there is layer 0, which should be OK','line_number':509,'multiline':False]
['text':' Each batch of the hidden state should match the input sequence that','line_number':670,'multiline':False]
['text':' the user believes he/she is passing in.','line_number':671,'multiline':False]
['text':' assuming there is layer 0, which should be OK','line_number':761,'multiline':False]
['text':' _FLOAT_MODULE = nn.CellRNNBase','line_number':768,'multiline':False]
['text':' for each layer, for each direction we need to quantize and pack','line_number':791,'multiline':False]
['text':' weights and pack parameters in this order:','line_number':792,'multiline':False]
['text':'','line_number':793,'multiline':False]
['text':'   w_ih, w_hh','line_number':794,'multiline':False]
['text':' for each layer, for each direction we need to quantize and pack','line_number':800,'multiline':False]
['text':' weights and pack parameters in this order:','line_number':801,'multiline':False]
['text':'','line_number':802,'multiline':False]
['text':'   packed_ih, packed_hh, b_ih, b_hh','line_number':803,'multiline':False]
['text':' We have the circular import issues if we import the qconfig in the beginning of this file:','line_number':849,'multiline':False]
['text':' https://github.com/pytorch/pytorch/pull/24231. The current workaround is to postpone the','line_number':850,'multiline':False]
['text':' import until we need it.','line_number':851,'multiline':False]
['text':' Returns a dict of weights and biases','line_number':920,'multiline':False]
['text':' TODO: these can be simplified to one level? e.g. using weight_ih as key','line_number':924,'multiline':False]
['text':' directly','line_number':925,'multiline':False]
['text':' TODO: these can be simplified to one level? e.g. using weight_ih as key','line_number':939,'multiline':False]
['text':' directly','line_number':940,'multiline':False]
['text':' TODO: remove when jit supports exception flow','line_number':1005,'multiline':False]
['text':' type: ignore[misc]','line_number':1036,'multiline':False]
