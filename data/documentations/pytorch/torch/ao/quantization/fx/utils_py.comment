['text':' importing the lib so that the quantized_decomposed ops are registered','line_number':38,'multiline':False]
['text':' noqa: F401','line_number':39,'multiline':False]
['text':' TODO: revisit this list. Many helper methods shouldn't be public','line_number':47,'multiline':False]
['text':' using set to dedup','line_number':126,'multiline':False]
['text':' Returns a function that can get a new attribute name for module with given','line_number':155,'multiline':False]
['text':' prefix, for example,','line_number':156,'multiline':False]
['text':' >> get_new_observer_name = get_new_attr_name_with_prefix('_observer')','line_number':157,'multiline':False]
['text':' >> new_name = get_new_observer_name(module)','line_number':158,'multiline':False]
['text':' new_name will be an unused attribute name on module, e.g. `_observer_1`','line_number':159,'multiline':False]
['text':' hit input, can't fold in this case','line_number':194,'multiline':False]
['text':' since we traced back from node to getattr','line_number':212,'multiline':False]
['text':' Create get_attr with value','line_number':257,'multiline':False]
['text':' will be overwritten','line_number':271,'multiline':False]
['text':' type: ignore[arg-type]','line_number':279,'multiline':False]
['text':' type: ignore[arg-type]','line_number':283,'multiline':False]
['text':' x1 = x0.ndim','line_number':287,'multiline':False]
['text':' x1 = x0.size(0)','line_number':290,'multiline':False]
['text':' If found_one_tensor is True, there is no point in','line_number':302,'multiline':False]
['text':' recursing further as the end result will always','line_number':303,'multiline':False]
['text':' be True.','line_number':304,'multiline':False]
['text':' TODO(future PR): remove this entire function  and','line_number':305,'multiline':False]
['text':' change to dtype inference without recursion.','line_number':306,'multiline':False]
['text':' If found_one_tensor is True, there is no point in','line_number':319,'multiline':False]
['text':' recursing further as the end result will always','line_number':320,'multiline':False]
['text':' be True.','line_number':321,'multiline':False]
['text':' TODO(future PR): remove this entire function  and','line_number':322,'multiline':False]
['text':' change to dtype inference without recursion.','line_number':323,'multiline':False]
['text':' this dict identifies which indices of a node are non tensors','line_number':353,'multiline':False]
['text':' so that they can be propagated correctly since inserting observers','line_number':354,'multiline':False]
['text':' for them would cause errors','line_number':355,'multiline':False]
['text':' standalone module and custom module config are applied in top level module','line_number':448,'multiline':False]
['text':' QuantizeHandler, but we cannot include the type here due to circular imports','line_number':459,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':467,'multiline':False]
['text':' QuantizeHandler, but we cannot include the type here due to circular imports','line_number':478,'multiline':False]
['text':' type: ignore[attr-defined]','line_number':486,'multiline':False]
['text':' (1) Split the LSTM node into (output, (hidden0, hidden1))','line_number':584,'multiline':False]
['text':' (2) Insert a DeQuantStub after each internal node','line_number':585,'multiline':False]
['text':' (3) Recombine the DeQuantStubs into the same structure as before','line_number':598,'multiline':False]
['text':' (4) Reroute all consumers of the original LSTM node and its sub-nodes','line_number':604,'multiline':False]
['text':' The getitem and tuple nodes we added here may interfere with reference quantized','line_number':608,'multiline':False]
['text':' pattern matching, so we need to redirect the consumers of internal nodes to the','line_number':609,'multiline':False]
['text':' corresponding nodes with DeQuantStubs (e.g. lstm_output_dq[0] -> output_dq) attached,','line_number':610,'multiline':False]
['text':' in order to preserve reference patterns like "dequantize - consumer - quantize".','line_number':611,'multiline':False]
['text':' Match next arg, for tuple the arg is a tuple of a list, e.g. ([dq_1, other_node],)','line_number':663,'multiline':False]
['text':' type: ignore[assignment,index]','line_number':666,'multiline':False]
['text':' type: ignore[assignment]','line_number':668,'multiline':False]
['text':' Avoid duplicating work','line_number':733,'multiline':False]
['text':' Iterate through users of this node to find tuple/getitem nodes to match','line_number':739,'multiline':False]
['text':' type: ignore[arg-type]','line_number':742,'multiline':False]
['text':' Collect all matched patterns','line_number':755,'multiline':False]
['text':' (node, index_stack)','line_number':757,'multiline':False]
['text':' For each pattern, redirect all consumers of the last getitem node to the correct input','line_number':761,'multiline':False]
['text':' of the first tuple node','line_number':762,'multiline':False]
['text':' type: ignore[index]','line_number':769,'multiline':False]
['text':' type: ignore[return-value]','line_number':784,'multiline':False]
['text':' TODO: log warnings only when the user enabled a debug flag','line_number':802,'multiline':False]
['text':' TODO: for now, just use the existing eps value as scale_min. In the future, we should','line_number':810,'multiline':False]
['text':' resolve the differences between the two, either by renaming eps or some other way','line_number':811,'multiline':False]
['text':' check quantization ranges','line_number':818,'multiline':False]
['text':' check scale min','line_number':831,'multiline':False]
['text':' check fixed scale and zero point','line_number':842,'multiline':False]
['text':' For tests only, accept the following qconfigs for now','line_number':844,'multiline':False]
['text':' TODO: handle fp16 qconfigs properly','line_number':845,'multiline':False]
['text':' If dtypes don't match, don't check the activation_post_process and return True early','line_number':880,'multiline':False]
