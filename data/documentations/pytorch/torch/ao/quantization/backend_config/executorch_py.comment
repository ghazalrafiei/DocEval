['text':' TODO: rename executorch to qnnpack_executorch since executorch is a general runtime','line_number':1,'multiline':False]
['text':' not a specific backend','line_number':2,'multiline':False]
['text':' ===================','line_number':37,'multiline':False]
['text':' |  DTYPE CONFIGS  |','line_number':38,'multiline':False]
['text':' ===================','line_number':39,'multiline':False]
['text':' =============================','line_number':96,'multiline':False]
['text':' |  BACKEND PATTERN CONFIGS  |','line_number':97,'multiline':False]
['text':' =============================','line_number':98,'multiline':False]
['text':' linear module','line_number':114,'multiline':False]
['text':' noqa: E131','line_number':117,'multiline':False]
['text':' linear qat module','line_number':123,'multiline':False]
['text':' noqa: E131','line_number':126,'multiline':False]
['text':' functional linear','line_number':131,'multiline':False]
['text':' noqa: E131','line_number':134,'multiline':False]
['text':' (1) Single conv modules/functions','line_number':152,'multiline':False]
['text':' -----------------------------------','line_number':153,'multiline':False]
['text':' conv module','line_number':154,'multiline':False]
['text':' noqa: E131','line_number':157,'multiline':False]
['text':' conv qat module','line_number':163,'multiline':False]
['text':' noqa: E131','line_number':166,'multiline':False]
['text':' functional conv','line_number':171,'multiline':False]
['text':' noqa: E131','line_number':174,'multiline':False]
['text':' (2) Conv + relu','line_number':179,'multiline':False]
['text':' -----------------------------------','line_number':180,'multiline':False]
['text':' conv module + relu module','line_number':181,'multiline':False]
['text':' noqa: E131','line_number':184,'multiline':False]
['text':' conv module + functional relu','line_number':188,'multiline':False]
['text':' noqa: E131','line_number':191,'multiline':False]
['text':' fused conv relu module','line_number':195,'multiline':False]
['text':' noqa: E131','line_number':198,'multiline':False]
['text':' conv relu, qat fused module','line_number':204,'multiline':False]
['text':' noqa: E131','line_number':207,'multiline':False]
['text':' functional conv + relu module','line_number':212,'multiline':False]
['text':' noqa: E131','line_number':215,'multiline':False]
['text':' functional conv + functional relu','line_number':218,'multiline':False]
['text':' noqa: E131','line_number':221,'multiline':False]
['text':' fused conv relu','line_number':224,'multiline':False]
['text':' noqa: E131','line_number':227,'multiline':False]
['text':' noqa: E131','line_number':233,'multiline':False]
['text':' (3) Conv + batchnorm (+ relu)','line_number':238,'multiline':False]
['text':' -------------------------------','line_number':239,'multiline':False]
['text':' conv + batchnorm (+ relu)','line_number':240,'multiline':False]
['text':' noqa: E131','line_number':243,'multiline':False]
['text':' conv + bn + relu module fusion','line_number':247,'multiline':False]
['text':' noqa: E131','line_number':250,'multiline':False]
['text':' conv + bn + relu functional fusion','line_number':254,'multiline':False]
['text':' noqa: E131','line_number':257,'multiline':False]
['text':' TODO: we can add fusion for torch.relu as well','line_number':262,'multiline':False]
['text':' 3.2 conv + bn (+ relu) fused module configs','line_number':263,'multiline':False]
['text':' fused conv bn','line_number':264,'multiline':False]
['text':' noqa: E131','line_number':267,'multiline':False]
['text':' fused conv bn relu','line_number':271,'multiline':False]
['text':' noqa: E131','line_number':274,'multiline':False]
['text':' conv bn, qat fused module','line_number':278,'multiline':False]
['text':' noqa: E131','line_number':281,'multiline':False]
['text':' conv bn relu, qat fused module','line_number':286,'multiline':False]
['text':' noqa: E131','line_number':289,'multiline':False]
['text':' TODO: this is not used right now since we have extra check in prepare','line_number':306,'multiline':False]
['text':' will need to change this to NO_OBSERVER later after we implemented','line_number':307,'multiline':False]
['text':' Tensor dtype inference properly','line_number':308,'multiline':False]
['text':' noqa: E131','line_number':324,'multiline':False]
['text':' noqa: E131','line_number':385,'multiline':False]
['text':' noqa: E131','line_number':403,'multiline':False]
['text':' noqa: E131','line_number':446,'multiline':False]
['text':' config for qat op','line_number':452,'multiline':False]
['text':' noqa: E131','line_number':457,'multiline':False]
['text':' config for functional embedding','line_number':463,'multiline':False]
['text':' noqa: E131','line_number':468,'multiline':False]
['text':' =====================','line_number':476,'multiline':False]
['text':' |  BACKEND CONFIGS  |','line_number':477,'multiline':False]
['text':' =====================','line_number':478,'multiline':False]
