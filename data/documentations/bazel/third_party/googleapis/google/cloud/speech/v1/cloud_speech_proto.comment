['text':' Copyright 2017 Google Inc.','line_number':1,'multiline':False]
['text':'','line_number':2,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':3,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':4,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':5,'multiline':False]
['text':'','line_number':6,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':7,'multiline':False]
['text':'','line_number':8,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':9,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':10,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':11,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':12,'multiline':False]
['text':' limitations under the License.','line_number':13,'multiline':False]
['text':' Service that implements Google Cloud Speech API.','line_number':32,'multiline':False]
['text':' Performs synchronous speech recognition: receive results after all audio','line_number':34,'multiline':False]
['text':' has been sent and processed.','line_number':35,'multiline':False]
['text':' Performs asynchronous speech recognition: receive results via the','line_number':40,'multiline':False]
['text':' google.longrunning.Operations interface. Returns either an','line_number':41,'multiline':False]
['text':' `Operation.error` or an `Operation.response` which contains','line_number':42,'multiline':False]
['text':' a `LongRunningRecognizeResponse` message.','line_number':43,'multiline':False]
['text':' Performs bidirectional streaming speech recognition: receive results while','line_number':48,'multiline':False]
['text':' sending audio. This method is only available via the gRPC API (not REST).','line_number':49,'multiline':False]
['text':' The top-level message sent by the client for the `Recognize` method.','line_number':53,'multiline':False]
['text':' *Required* Provides information to the recognizer that specifies how to','line_number':55,'multiline':False]
['text':' process the request.','line_number':56,'multiline':False]
['text':' *Required* The audio data to be recognized.','line_number':59,'multiline':False]
['text':' The top-level message sent by the client for the `LongRunningRecognize`','line_number':63,'multiline':False]
['text':' method.','line_number':64,'multiline':False]
['text':' *Required* Provides information to the recognizer that specifies how to','line_number':66,'multiline':False]
['text':' process the request.','line_number':67,'multiline':False]
['text':' *Required* The audio data to be recognized.','line_number':70,'multiline':False]
['text':' The top-level message sent by the client for the `StreamingRecognize` method.','line_number':74,'multiline':False]
['text':' Multiple `StreamingRecognizeRequest` messages are sent. The first message','line_number':75,'multiline':False]
['text':' must contain a `streaming_config` message and must not contain `audio` data.','line_number':76,'multiline':False]
['text':' All subsequent messages must contain `audio` data and must not contain a','line_number':77,'multiline':False]
['text':' `streaming_config` message.','line_number':78,'multiline':False]
['text':' Provides information to the recognizer that specifies how to process the','line_number':81,'multiline':False]
['text':' request. The first `StreamingRecognizeRequest` message must contain a','line_number':82,'multiline':False]
['text':' `streaming_config`  message.','line_number':83,'multiline':False]
['text':' The audio data to be recognized. Sequential chunks of audio data are sent','line_number':86,'multiline':False]
['text':' in sequential `StreamingRecognizeRequest` messages. The first','line_number':87,'multiline':False]
['text':' `StreamingRecognizeRequest` message must not contain `audio_content` data','line_number':88,'multiline':False]
['text':' and all subsequent `StreamingRecognizeRequest` messages must contain','line_number':89,'multiline':False]
['text':' `audio_content` data. The audio bytes must be encoded as specified in','line_number':90,'multiline':False]
['text':' `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a','line_number':91,'multiline':False]
['text':' pure binary representation (not base64). See','line_number':92,'multiline':False]
['text':' [audio limits](https://cloud.google.com/speech/limits#content).','line_number':93,'multiline':False]
['text':' Provides information to the recognizer that specifies how to process the','line_number':98,'multiline':False]
['text':' request.','line_number':99,'multiline':False]
['text':' *Required* Provides information to the recognizer that specifies how to','line_number':101,'multiline':False]
['text':' process the request.','line_number':102,'multiline':False]
['text':' *Optional* If `false` or omitted, the recognizer will perform continuous','line_number':105,'multiline':False]
['text':' recognition (continuing to wait for and process audio even if the user','line_number':106,'multiline':False]
['text':' pauses speaking) until the client closes the input stream (gRPC API) or','line_number':107,'multiline':False]
['text':' until the maximum time limit has been reached. May return multiple','line_number':108,'multiline':False]
['text':' `StreamingRecognitionResult`s with the `is_final` flag set to `true`.','line_number':109,'multiline':False]
['text':'','line_number':110,'multiline':False]
['text':' If `true`, the recognizer will detect a single spoken utterance. When it','line_number':111,'multiline':False]
['text':' detects that the user has paused or stopped speaking, it will return an','line_number':112,'multiline':False]
['text':' `END_OF_SINGLE_UTTERANCE` event and cease recognition. It will return no','line_number':113,'multiline':False]
['text':' more than one `StreamingRecognitionResult` with the `is_final` flag set to','line_number':114,'multiline':False]
['text':' `true`.','line_number':115,'multiline':False]
['text':' *Optional* If `true`, interim results (tentative hypotheses) may be','line_number':118,'multiline':False]
['text':' returned as they become available (these interim results are indicated with','line_number':119,'multiline':False]
['text':' the `is_final=false` flag).','line_number':120,'multiline':False]
['text':' If `false` or omitted, only `is_final=true` result(s) are returned.','line_number':121,'multiline':False]
['text':' Provides information to the recognizer that specifies how to process the','line_number':125,'multiline':False]
['text':' request.','line_number':126,'multiline':False]
['text':' Audio encoding of the data sent in the audio message. All encodings support','line_number':128,'multiline':False]
['text':' only 1 channel (mono) audio. Only `FLAC` includes a header that describes','line_number':129,'multiline':False]
['text':' the bytes of audio that follow the header. The other encodings are raw','line_number':130,'multiline':False]
['text':' audio bytes with no header.','line_number':131,'multiline':False]
['text':'','line_number':132,'multiline':False]
['text':' For best results, the audio source should be captured and transmitted using','line_number':133,'multiline':False]
['text':' a lossless encoding (`FLAC` or `LINEAR16`). Recognition accuracy may be','line_number':134,'multiline':False]
['text':' reduced if lossy codecs, which include the other codecs listed in','line_number':135,'multiline':False]
['text':' this section, are used to capture or transmit the audio, particularly if','line_number':136,'multiline':False]
['text':' background noise is present.','line_number':137,'multiline':False]
['text':' Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][].','line_number':139,'multiline':False]
['text':' Uncompressed 16-bit signed little-endian samples (Linear PCM).','line_number':142,'multiline':False]
['text':' [`FLAC`](https://xiph.org/flac/documentation.html) (Free Lossless Audio','line_number':145,'multiline':False]
['text':' Codec) is the recommended encoding because it is','line_number':146,'multiline':False]
['text':' lossless--therefore recognition is not compromised--and','line_number':147,'multiline':False]
['text':' requires only about half the bandwidth of `LINEAR16`. `FLAC` stream','line_number':148,'multiline':False]
['text':' encoding supports 16-bit and 24-bit samples, however, not all fields in','line_number':149,'multiline':False]
['text':' `STREAMINFO` are supported.','line_number':150,'multiline':False]
['text':' 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.','line_number':153,'multiline':False]
['text':' Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.','line_number':156,'multiline':False]
['text':' Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.','line_number':159,'multiline':False]
['text':' Opus encoded audio frames in Ogg container','line_number':162,'multiline':False]
['text':' ([OggOpus](https://wiki.xiph.org/OggOpus)).','line_number':163,'multiline':False]
['text':' `sample_rate_hertz` must be 16000.','line_number':164,'multiline':False]
['text':' Although the use of lossy encodings is not recommended, if a very low','line_number':167,'multiline':False]
['text':' bitrate encoding is required, `OGG_OPUS` is highly preferred over','line_number':168,'multiline':False]
['text':' Speex encoding. The [Speex](https://speex.org/)  encoding supported by','line_number':169,'multiline':False]
['text':' Cloud Speech API has a header byte in each block, as in MIME type','line_number':170,'multiline':False]
['text':' `audio/x-speex-with-header-byte`.','line_number':171,'multiline':False]
['text':' It is a variant of the RTP Speex encoding defined in','line_number':172,'multiline':False]
['text':' [RFC 5574](https://tools.ietf.org/html/rfc5574).','line_number':173,'multiline':False]
['text':' The stream is a sequence of blocks, one block per RTP packet. Each block','line_number':174,'multiline':False]
['text':' starts with a byte containing the length of the block, in bytes, followed','line_number':175,'multiline':False]
['text':' by one or more frames of Speex data, padded to an integral number of','line_number':176,'multiline':False]
['text':' bytes (octets) as specified in RFC 5574. In other words, each RTP header','line_number':177,'multiline':False]
['text':' is replaced with a single byte containing the block length. Only Speex','line_number':178,'multiline':False]
['text':' wideband is supported. `sample_rate_hertz` must be 16000.','line_number':179,'multiline':False]
['text':' *Required* Encoding of audio data sent in all `RecognitionAudio` messages.','line_number':183,'multiline':False]
['text':' *Required* Sample rate in Hertz of the audio data sent in all','line_number':186,'multiline':False]
['text':' `RecognitionAudio` messages. Valid values are: 8000-48000.','line_number':187,'multiline':False]
['text':' 16000 is optimal. For best results, set the sampling rate of the audio','line_number':188,'multiline':False]
['text':' source to 16000 Hz. If that's not possible, use the native sample rate of','line_number':189,'multiline':False]
['text':' the audio source (instead of re-sampling).','line_number':190,'multiline':False]
['text':' *Required* The language of the supplied audio as a','line_number':193,'multiline':False]
['text':' [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.','line_number':194,'multiline':False]
['text':' Example: "en-US".','line_number':195,'multiline':False]
['text':' See [Language Support](https://cloud.google.com/speech/docs/languages)','line_number':196,'multiline':False]
['text':' for a list of the currently supported language codes.','line_number':197,'multiline':False]
['text':' *Optional* Maximum number of recognition hypotheses to be returned.','line_number':200,'multiline':False]
['text':' Specifically, the maximum number of `SpeechRecognitionAlternative` messages','line_number':201,'multiline':False]
['text':' within each `SpeechRecognitionResult`.','line_number':202,'multiline':False]
['text':' The server may return fewer than `max_alternatives`.','line_number':203,'multiline':False]
['text':' Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of','line_number':204,'multiline':False]
['text':' one. If omitted, will return a maximum of one.','line_number':205,'multiline':False]
['text':' *Optional* If set to `true`, the server will attempt to filter out','line_number':208,'multiline':False]
['text':' profanities, replacing all but the initial character in each filtered word','line_number':209,'multiline':False]
['text':' with asterisks, e.g. "f***". If set to `false` or omitted, profanities','line_number':210,'multiline':False]
['text':' won't be filtered out.','line_number':211,'multiline':False]
['text':' *Optional* A means to provide context to assist the speech recognition.','line_number':214,'multiline':False]
['text':' Provides "hints" to the speech recognizer to favor specific words and phrases','line_number':218,'multiline':False]
['text':' in the results.','line_number':219,'multiline':False]
['text':' *Optional* A list of strings containing words and phrases "hints" so that','line_number':221,'multiline':False]
['text':' the speech recognition is more likely to recognize them. This can be used','line_number':222,'multiline':False]
['text':' to improve the accuracy for specific words and phrases, for example, if','line_number':223,'multiline':False]
['text':' specific commands are typically spoken by the user. This can also be used','line_number':224,'multiline':False]
['text':' to add additional words to the vocabulary of the recognizer. See','line_number':225,'multiline':False]
['text':' [usage limits](https://cloud.google.com/speech/limits#content).','line_number':226,'multiline':False]
['text':' Contains audio data in the encoding specified in the `RecognitionConfig`.','line_number':230,'multiline':False]
['text':' Either `content` or `uri` must be supplied. Supplying both or neither','line_number':231,'multiline':False]
['text':' returns [google.rpc.Code.INVALID_ARGUMENT][]. See','line_number':232,'multiline':False]
['text':' [audio limits](https://cloud.google.com/speech/limits#content).','line_number':233,'multiline':False]
['text':' The audio data bytes encoded as specified in','line_number':236,'multiline':False]
['text':' `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a','line_number':237,'multiline':False]
['text':' pure binary representation, whereas JSON representations use base64.','line_number':238,'multiline':False]
['text':' URI that points to a file that contains audio data bytes as specified in','line_number':241,'multiline':False]
['text':' `RecognitionConfig`. Currently, only Google Cloud Storage URIs are','line_number':242,'multiline':False]
['text':' supported, which must be specified in the following format:','line_number':243,'multiline':False]
['text':' `gs://bucket_name/object_name` (other URI formats return','line_number':244,'multiline':False]
['text':' [google.rpc.Code.INVALID_ARGUMENT][]). For more information, see','line_number':245,'multiline':False]
['text':' [Request URIs](https://cloud.google.com/storage/docs/reference-uris).','line_number':246,'multiline':False]
['text':' The only message returned to the client by the `Recognize` method. It','line_number':251,'multiline':False]
['text':' contains the result as zero or more sequential `SpeechRecognitionResult`','line_number':252,'multiline':False]
['text':' messages.','line_number':253,'multiline':False]
['text':' *Output-only* Sequential list of transcription results corresponding to','line_number':255,'multiline':False]
['text':' sequential portions of audio.','line_number':256,'multiline':False]
['text':' The only message returned to the client by the `LongRunningRecognize` method.','line_number':260,'multiline':False]
['text':' It contains the result as zero or more sequential `SpeechRecognitionResult`','line_number':261,'multiline':False]
['text':' messages. It is included in the `result.response` field of the `Operation`','line_number':262,'multiline':False]
['text':' returned by the `GetOperation` call of the `google::longrunning::Operations`','line_number':263,'multiline':False]
['text':' service.','line_number':264,'multiline':False]
['text':' *Output-only* Sequential list of transcription results corresponding to','line_number':266,'multiline':False]
['text':' sequential portions of audio.','line_number':267,'multiline':False]
['text':' Describes the progress of a long-running `LongRunningRecognize` call. It is','line_number':271,'multiline':False]
['text':' included in the `metadata` field of the `Operation` returned by the','line_number':272,'multiline':False]
['text':' `GetOperation` call of the `google::longrunning::Operations` service.','line_number':273,'multiline':False]
['text':' Approximate percentage of audio processed thus far. Guaranteed to be 100','line_number':275,'multiline':False]
['text':' when the audio is fully processed and the results are available.','line_number':276,'multiline':False]
['text':' Time when the request was received.','line_number':279,'multiline':False]
['text':' Time of the most recent processing update.','line_number':282,'multiline':False]
['text':' `StreamingRecognizeResponse` is the only message returned to the client by','line_number':286,'multiline':False]
['text':' `StreamingRecognize`. A series of one or more `StreamingRecognizeResponse`','line_number':287,'multiline':False]
['text':' messages are streamed back to the client.','line_number':288,'multiline':False]
['text':'','line_number':289,'multiline':False]
['text':' Here's an example of a series of ten `StreamingRecognizeResponse`s that might','line_number':290,'multiline':False]
['text':' be returned while processing audio:','line_number':291,'multiline':False]
['text':'','line_number':292,'multiline':False]
['text':' 1. results { alternatives { transcript: "tube" } stability: 0.01 }','line_number':293,'multiline':False]
['text':'','line_number':294,'multiline':False]
['text':' 2. results { alternatives { transcript: "to be a" } stability: 0.01 }','line_number':295,'multiline':False]
['text':'','line_number':296,'multiline':False]
['text':' 3. results { alternatives { transcript: "to be" } stability: 0.9 }','line_number':297,'multiline':False]
['text':'    results { alternatives { transcript: " or not to be" } stability: 0.01 }','line_number':298,'multiline':False]
['text':'','line_number':299,'multiline':False]
['text':' 4. results { alternatives { transcript: "to be or not to be"','line_number':300,'multiline':False]
['text':'                             confidence: 0.92 }','line_number':301,'multiline':False]
['text':'              alternatives { transcript: "to bee or not to bee" }','line_number':302,'multiline':False]
['text':'              is_final: true }','line_number':303,'multiline':False]
['text':'','line_number':304,'multiline':False]
['text':' 5. results { alternatives { transcript: " that's" } stability: 0.01 }','line_number':305,'multiline':False]
['text':'','line_number':306,'multiline':False]
['text':' 6. results { alternatives { transcript: " that is" } stability: 0.9 }','line_number':307,'multiline':False]
['text':'    results { alternatives { transcript: " the question" } stability: 0.01 }','line_number':308,'multiline':False]
['text':'','line_number':309,'multiline':False]
['text':' 7. speech_event_type: END_OF_SINGLE_UTTERANCE','line_number':310,'multiline':False]
['text':'','line_number':311,'multiline':False]
['text':' 8. results { alternatives { transcript: " that is the question"','line_number':312,'multiline':False]
['text':'                             confidence: 0.98 }','line_number':313,'multiline':False]
['text':'              alternatives { transcript: " that was the question" }','line_number':314,'multiline':False]
['text':'              is_final: true }','line_number':315,'multiline':False]
['text':'','line_number':316,'multiline':False]
['text':' Notes:','line_number':317,'multiline':False]
['text':'','line_number':318,'multiline':False]
['text':' - Only two of the above responses #4 and #8 contain final results; they are','line_number':319,'multiline':False]
['text':'   indicated by `is_final: true`. Concatenating these together generates the','line_number':320,'multiline':False]
['text':'   full transcript: "to be or not to be that is the question".','line_number':321,'multiline':False]
['text':'','line_number':322,'multiline':False]
['text':' - The others contain interim `results`. #3 and #6 contain two interim','line_number':323,'multiline':False]
['text':'   `results`: the first portion has a high stability and is less likely to','line_number':324,'multiline':False]
['text':'   change; the second portion has a low stability and is very likely to','line_number':325,'multiline':False]
['text':'   change. A UI designer might choose to show only high stability `results`.','line_number':326,'multiline':False]
['text':'','line_number':327,'multiline':False]
['text':' - The specific `stability` and `confidence` values shown above are only for','line_number':328,'multiline':False]
['text':'   illustrative purposes. Actual values may vary.','line_number':329,'multiline':False]
['text':'','line_number':330,'multiline':False]
['text':' - In each response, only one of these fields will be set:','line_number':331,'multiline':False]
['text':'     `error`,','line_number':332,'multiline':False]
['text':'     `speech_event_type`, or','line_number':333,'multiline':False]
['text':'     one or more (repeated) `results`.','line_number':334,'multiline':False]
['text':' Indicates the type of speech event.','line_number':336,'multiline':False]
['text':' No speech event specified.','line_number':338,'multiline':False]
['text':' This event indicates that the server has detected the end of the user's','line_number':341,'multiline':False]
['text':' speech utterance and expects no additional speech. Therefore, the server','line_number':342,'multiline':False]
['text':' will not process additional audio (although it may subsequently return','line_number':343,'multiline':False]
['text':' additional results). The client should stop sending additional audio','line_number':344,'multiline':False]
['text':' data, half-close the gRPC connection, and wait for any additional results','line_number':345,'multiline':False]
['text':' until the server closes the gRPC connection. This event is only sent if','line_number':346,'multiline':False]
['text':' `single_utterance` was set to `true`, and is not used otherwise.','line_number':347,'multiline':False]
['text':' *Output-only* If set, returns a [google.rpc.Status][] message that','line_number':351,'multiline':False]
['text':' specifies the error for the operation.','line_number':352,'multiline':False]
['text':' *Output-only* This repeated list contains zero or more results that','line_number':355,'multiline':False]
['text':' correspond to consecutive portions of the audio currently being processed.','line_number':356,'multiline':False]
['text':' It contains zero or one `is_final=true` result (the newly settled portion),','line_number':357,'multiline':False]
['text':' followed by zero or more `is_final=false` results.','line_number':358,'multiline':False]
['text':' *Output-only* Indicates the type of speech event.','line_number':361,'multiline':False]
['text':' A streaming speech recognition result corresponding to a portion of the audio','line_number':365,'multiline':False]
['text':' that is currently being processed.','line_number':366,'multiline':False]
['text':' *Output-only* May contain one or more recognition hypotheses (up to the','line_number':368,'multiline':False]
['text':' maximum specified in `max_alternatives`).','line_number':369,'multiline':False]
['text':' *Output-only* If `false`, this `StreamingRecognitionResult` represents an','line_number':372,'multiline':False]
['text':' interim result that may change. If `true`, this is the final time the','line_number':373,'multiline':False]
['text':' speech service will return this particular `StreamingRecognitionResult`,','line_number':374,'multiline':False]
['text':' the recognizer will not return any further hypotheses for this portion of','line_number':375,'multiline':False]
['text':' the transcript and corresponding audio.','line_number':376,'multiline':False]
['text':' *Output-only* An estimate of the likelihood that the recognizer will not','line_number':379,'multiline':False]
['text':' change its guess about this interim result. Values range from 0.0','line_number':380,'multiline':False]
['text':' (completely unstable) to 1.0 (completely stable).','line_number':381,'multiline':False]
['text':' This field is only provided for interim results (`is_final=false`).','line_number':382,'multiline':False]
['text':' The default of 0.0 is a sentinel value indicating `stability` was not set.','line_number':383,'multiline':False]
['text':' A speech recognition result corresponding to a portion of the audio.','line_number':387,'multiline':False]
['text':' *Output-only* May contain one or more recognition hypotheses (up to the','line_number':389,'multiline':False]
['text':' maximum specified in `max_alternatives`).','line_number':390,'multiline':False]
['text':' Alternative hypotheses (a.k.a. n-best list).','line_number':394,'multiline':False]
['text':' *Output-only* Transcript text representing the words that the user spoke.','line_number':396,'multiline':False]
['text':' *Output-only* The confidence estimate between 0.0 and 1.0. A higher number','line_number':399,'multiline':False]
['text':' indicates an estimated greater likelihood that the recognized words are','line_number':400,'multiline':False]
['text':' correct. This field is typically provided only for the top hypothesis, and','line_number':401,'multiline':False]
['text':' only for `is_final=true` results. Clients should not rely on the','line_number':402,'multiline':False]
['text':' `confidence` field as it is not guaranteed to be accurate, or even set, in','line_number':403,'multiline':False]
['text':' any of the results.','line_number':404,'multiline':False]
['text':' The default of 0.0 is a sentinel value indicating `confidence` was not set.','line_number':405,'multiline':False]
