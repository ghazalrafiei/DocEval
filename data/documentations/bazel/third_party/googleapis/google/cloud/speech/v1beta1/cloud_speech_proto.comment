['text':' Copyright 2017 Google Inc.','line_number':1,'multiline':False]
['text':'','line_number':2,'multiline':False]
['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':3,'multiline':False]
['text':' you may not use this file except in compliance with the License.','line_number':4,'multiline':False]
['text':' You may obtain a copy of the License at','line_number':5,'multiline':False]
['text':'','line_number':6,'multiline':False]
['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':7,'multiline':False]
['text':'','line_number':8,'multiline':False]
['text':' Unless required by applicable law or agreed to in writing, software','line_number':9,'multiline':False]
['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':10,'multiline':False]
['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':11,'multiline':False]
['text':' See the License for the specific language governing permissions and','line_number':12,'multiline':False]
['text':' limitations under the License.','line_number':13,'multiline':False]
['text':' Service that implements Google Cloud Speech API.','line_number':31,'multiline':False]
['text':' Performs synchronous speech recognition: receive results after all audio','line_number':33,'multiline':False]
['text':' has been sent and processed.','line_number':34,'multiline':False]
['text':' Performs asynchronous speech recognition: receive results via the','line_number':39,'multiline':False]
['text':' [google.longrunning.Operations]','line_number':40,'multiline':False]
['text':' (/speech/reference/rest/v1beta1/operations#Operation)','line_number':41,'multiline':False]
['text':' interface. Returns either an','line_number':42,'multiline':False]
['text':' `Operation.error` or an `Operation.response` which contains','line_number':43,'multiline':False]
['text':' an `AsyncRecognizeResponse` message.','line_number':44,'multiline':False]
['text':' Performs bidirectional streaming speech recognition: receive results while','line_number':49,'multiline':False]
['text':' sending audio. This method is only available via the gRPC API (not REST).','line_number':50,'multiline':False]
['text':' The top-level message sent by the client for the `SyncRecognize` method.','line_number':54,'multiline':False]
['text':' *Required* Provides information to the recognizer that specifies how to','line_number':56,'multiline':False]
['text':' process the request.','line_number':57,'multiline':False]
['text':' *Required* The audio data to be recognized.','line_number':60,'multiline':False]
['text':' The top-level message sent by the client for the `AsyncRecognize` method.','line_number':64,'multiline':False]
['text':' *Required* Provides information to the recognizer that specifies how to','line_number':66,'multiline':False]
['text':' process the request.','line_number':67,'multiline':False]
['text':' *Required* The audio data to be recognized.','line_number':70,'multiline':False]
['text':' The top-level message sent by the client for the `StreamingRecognize` method.','line_number':74,'multiline':False]
['text':' Multiple `StreamingRecognizeRequest` messages are sent. The first message','line_number':75,'multiline':False]
['text':' must contain a `streaming_config` message and must not contain `audio` data.','line_number':76,'multiline':False]
['text':' All subsequent messages must contain `audio` data and must not contain a','line_number':77,'multiline':False]
['text':' `streaming_config` message.','line_number':78,'multiline':False]
['text':' Provides information to the recognizer that specifies how to process the','line_number':81,'multiline':False]
['text':' request. The first `StreamingRecognizeRequest` message must contain a','line_number':82,'multiline':False]
['text':' `streaming_config`  message.','line_number':83,'multiline':False]
['text':' The audio data to be recognized. Sequential chunks of audio data are sent','line_number':86,'multiline':False]
['text':' in sequential `StreamingRecognizeRequest` messages. The first','line_number':87,'multiline':False]
['text':' `StreamingRecognizeRequest` message must not contain `audio_content` data','line_number':88,'multiline':False]
['text':' and all subsequent `StreamingRecognizeRequest` messages must contain','line_number':89,'multiline':False]
['text':' `audio_content` data. The audio bytes must be encoded as specified in','line_number':90,'multiline':False]
['text':' `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a','line_number':91,'multiline':False]
['text':' pure binary representation (not base64). See','line_number':92,'multiline':False]
['text':' [audio limits](https://cloud.google.com/speech/limits#content).','line_number':93,'multiline':False]
['text':' Provides information to the recognizer that specifies how to process the','line_number':98,'multiline':False]
['text':' request.','line_number':99,'multiline':False]
['text':' *Required* Provides information to the recognizer that specifies how to','line_number':101,'multiline':False]
['text':' process the request.','line_number':102,'multiline':False]
['text':' *Optional* If `false` or omitted, the recognizer will perform continuous','line_number':105,'multiline':False]
['text':' recognition (continuing to wait for and process audio even if the user','line_number':106,'multiline':False]
['text':' pauses speaking) until the client closes the input stream (gRPC API) or','line_number':107,'multiline':False]
['text':' until the maximum time limit has been reached. May return multiple','line_number':108,'multiline':False]
['text':' `StreamingRecognitionResult`s with the `is_final` flag set to `true`.','line_number':109,'multiline':False]
['text':'','line_number':110,'multiline':False]
['text':' If `true`, the recognizer will detect a single spoken utterance. When it','line_number':111,'multiline':False]
['text':' detects that the user has paused or stopped speaking, it will return an','line_number':112,'multiline':False]
['text':' `END_OF_UTTERANCE` event and cease recognition. It will return no more than','line_number':113,'multiline':False]
['text':' one `StreamingRecognitionResult` with the `is_final` flag set to `true`.','line_number':114,'multiline':False]
['text':' *Optional* If `true`, interim results (tentative hypotheses) may be','line_number':117,'multiline':False]
['text':' returned as they become available (these interim results are indicated with','line_number':118,'multiline':False]
['text':' the `is_final=false` flag).','line_number':119,'multiline':False]
['text':' If `false` or omitted, only `is_final=true` result(s) are returned.','line_number':120,'multiline':False]
['text':' Provides information to the recognizer that specifies how to process the','line_number':124,'multiline':False]
['text':' request.','line_number':125,'multiline':False]
['text':' Audio encoding of the data sent in the audio message. All encodings support','line_number':127,'multiline':False]
['text':' only 1 channel (mono) audio. Only `FLAC` includes a header that describes','line_number':128,'multiline':False]
['text':' the bytes of audio that follow the header. The other encodings are raw','line_number':129,'multiline':False]
['text':' audio bytes with no header.','line_number':130,'multiline':False]
['text':'','line_number':131,'multiline':False]
['text':' For best results, the audio source should be captured and transmitted using','line_number':132,'multiline':False]
['text':' a lossless encoding (`FLAC` or `LINEAR16`). Recognition accuracy may be','line_number':133,'multiline':False]
['text':' reduced if lossy codecs (such as AMR, AMR_WB and MULAW) are used to capture','line_number':134,'multiline':False]
['text':' or transmit the audio, particularly if background noise is present.','line_number':135,'multiline':False]
['text':' Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].','line_number':137,'multiline':False]
['text':' Uncompressed 16-bit signed little-endian samples (Linear PCM).','line_number':140,'multiline':False]
['text':' This is the only encoding that may be used by `AsyncRecognize`.','line_number':141,'multiline':False]
['text':' This is the recommended encoding for `SyncRecognize` and','line_number':144,'multiline':False]
['text':' `StreamingRecognize` because it uses lossless compression; therefore','line_number':145,'multiline':False]
['text':' recognition accuracy is not compromised by a lossy codec.','line_number':146,'multiline':False]
['text':'','line_number':147,'multiline':False]
['text':' The stream FLAC (Free Lossless Audio Codec) encoding is specified at:','line_number':148,'multiline':False]
['text':' http://flac.sourceforge.net/documentation.html.','line_number':149,'multiline':False]
['text':' 16-bit and 24-bit samples are supported.','line_number':150,'multiline':False]
['text':' Not all fields in STREAMINFO are supported.','line_number':151,'multiline':False]
['text':' 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.','line_number':154,'multiline':False]
['text':' Adaptive Multi-Rate Narrowband codec. `sample_rate` must be 8000 Hz.','line_number':157,'multiline':False]
['text':' Adaptive Multi-Rate Wideband codec. `sample_rate` must be 16000 Hz.','line_number':160,'multiline':False]
['text':' *Required* Encoding of audio data sent in all `RecognitionAudio` messages.','line_number':164,'multiline':False]
['text':' *Required* Sample rate in Hertz of the audio data sent in all','line_number':167,'multiline':False]
['text':' `RecognitionAudio` messages. Valid values are: 8000-48000.','line_number':168,'multiline':False]
['text':' 16000 is optimal. For best results, set the sampling rate of the audio','line_number':169,'multiline':False]
['text':' source to 16000 Hz. If that's not possible, use the native sample rate of','line_number':170,'multiline':False]
['text':' the audio source (instead of re-sampling).','line_number':171,'multiline':False]
['text':' *Optional* The language of the supplied audio as a BCP-47 language tag.','line_number':174,'multiline':False]
['text':' Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt','line_number':175,'multiline':False]
['text':' If omitted, defaults to "en-US". See','line_number':176,'multiline':False]
['text':' [Language Support](https://cloud.google.com/speech/docs/languages)','line_number':177,'multiline':False]
['text':' for a list of the currently supported language codes.','line_number':178,'multiline':False]
['text':' *Optional* Maximum number of recognition hypotheses to be returned.','line_number':181,'multiline':False]
['text':' Specifically, the maximum number of `SpeechRecognitionAlternative` messages','line_number':182,'multiline':False]
['text':' within each `SpeechRecognitionResult`.','line_number':183,'multiline':False]
['text':' The server may return fewer than `max_alternatives`.','line_number':184,'multiline':False]
['text':' Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of','line_number':185,'multiline':False]
['text':' one. If omitted, will return a maximum of one.','line_number':186,'multiline':False]
['text':' *Optional* If set to `true`, the server will attempt to filter out','line_number':189,'multiline':False]
['text':' profanities, replacing all but the initial character in each filtered word','line_number':190,'multiline':False]
['text':' with asterisks, e.g. "f***". If set to `false` or omitted, profanities','line_number':191,'multiline':False]
['text':' won't be filtered out.','line_number':192,'multiline':False]
['text':' *Optional* A means to provide context to assist the speech recognition.','line_number':195,'multiline':False]
['text':' Provides "hints" to the speech recognizer to favor specific words and phrases','line_number':199,'multiline':False]
['text':' in the results.','line_number':200,'multiline':False]
['text':' *Optional* A list of strings containing words and phrases "hints" so that','line_number':202,'multiline':False]
['text':' the speech recognition is more likely to recognize them. This can be used','line_number':203,'multiline':False]
['text':' to improve the accuracy for specific words and phrases, for example, if','line_number':204,'multiline':False]
['text':' specific commands are typically spoken by the user. This can also be used','line_number':205,'multiline':False]
['text':' to add additional words to the vocabulary of the recognizer. See','line_number':206,'multiline':False]
['text':' [usage limits](https://cloud.google.com/speech/limits#content).','line_number':207,'multiline':False]
['text':' Contains audio data in the encoding specified in the `RecognitionConfig`.','line_number':211,'multiline':False]
['text':' Either `content` or `uri` must be supplied. Supplying both or neither','line_number':212,'multiline':False]
['text':' returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. See','line_number':213,'multiline':False]
['text':' [audio limits](https://cloud.google.com/speech/limits#content).','line_number':214,'multiline':False]
['text':' The audio data bytes encoded as specified in','line_number':217,'multiline':False]
['text':' `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a','line_number':218,'multiline':False]
['text':' pure binary representation, whereas JSON representations use base64.','line_number':219,'multiline':False]
['text':' URI that points to a file that contains audio data bytes as specified in','line_number':222,'multiline':False]
['text':' `RecognitionConfig`. Currently, only Google Cloud Storage URIs are','line_number':223,'multiline':False]
['text':' supported, which must be specified in the following format:','line_number':224,'multiline':False]
['text':' `gs://bucket_name/object_name` (other URI formats return','line_number':225,'multiline':False]
['text':' [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see','line_number':226,'multiline':False]
['text':' [Request URIs](https://cloud.google.com/storage/docs/reference-uris).','line_number':227,'multiline':False]
['text':' The only message returned to the client by `SyncRecognize`. It','line_number':232,'multiline':False]
['text':' contains the result as zero or more sequential `SpeechRecognitionResult`','line_number':233,'multiline':False]
['text':' messages.','line_number':234,'multiline':False]
['text':' *Output-only* Sequential list of transcription results corresponding to','line_number':236,'multiline':False]
['text':' sequential portions of audio.','line_number':237,'multiline':False]
['text':' The only message returned to the client by `AsyncRecognize`. It contains the','line_number':241,'multiline':False]
['text':' result as zero or more sequential `SpeechRecognitionResult` messages. It is','line_number':242,'multiline':False]
['text':' included in the `result.response` field of the `Operation` returned by the','line_number':243,'multiline':False]
['text':' `GetOperation` call of the `google::longrunning::Operations` service.','line_number':244,'multiline':False]
['text':' *Output-only* Sequential list of transcription results corresponding to','line_number':246,'multiline':False]
['text':' sequential portions of audio.','line_number':247,'multiline':False]
['text':' Describes the progress of a long-running `AsyncRecognize` call. It is','line_number':251,'multiline':False]
['text':' included in the `metadata` field of the `Operation` returned by the','line_number':252,'multiline':False]
['text':' `GetOperation` call of the `google::longrunning::Operations` service.','line_number':253,'multiline':False]
['text':' Approximate percentage of audio processed thus far. Guaranteed to be 100','line_number':255,'multiline':False]
['text':' when the audio is fully processed and the results are available.','line_number':256,'multiline':False]
['text':' Time when the request was received.','line_number':259,'multiline':False]
['text':' Time of the most recent processing update.','line_number':262,'multiline':False]
['text':' `StreamingRecognizeResponse` is the only message returned to the client by','line_number':266,'multiline':False]
['text':' `StreamingRecognize`. A series of one or more `StreamingRecognizeResponse`','line_number':267,'multiline':False]
['text':' messages are streamed back to the client.','line_number':268,'multiline':False]
['text':'','line_number':269,'multiline':False]
['text':' Here's an example of a series of ten `StreamingRecognizeResponse`s that might','line_number':270,'multiline':False]
['text':' be returned while processing audio:','line_number':271,'multiline':False]
['text':'','line_number':272,'multiline':False]
['text':' 1. endpointer_type: START_OF_SPEECH','line_number':273,'multiline':False]
['text':'','line_number':274,'multiline':False]
['text':' 2. results { alternatives { transcript: "tube" } stability: 0.01 }','line_number':275,'multiline':False]
['text':'    result_index: 0','line_number':276,'multiline':False]
['text':'','line_number':277,'multiline':False]
['text':' 3. results { alternatives { transcript: "to be a" } stability: 0.01 }','line_number':278,'multiline':False]
['text':'    result_index: 0','line_number':279,'multiline':False]
['text':'','line_number':280,'multiline':False]
['text':' 4. results { alternatives { transcript: "to be" } stability: 0.9 }','line_number':281,'multiline':False]
['text':'    results { alternatives { transcript: " or not to be" } stability: 0.01 }','line_number':282,'multiline':False]
['text':'    result_index: 0','line_number':283,'multiline':False]
['text':'','line_number':284,'multiline':False]
['text':' 5. results { alternatives { transcript: "to be or not to be"','line_number':285,'multiline':False]
['text':'                             confidence: 0.92 }','line_number':286,'multiline':False]
['text':'              alternatives { transcript: "to bee or not to bee" }','line_number':287,'multiline':False]
['text':'              is_final: true }','line_number':288,'multiline':False]
['text':'    result_index: 0','line_number':289,'multiline':False]
['text':'','line_number':290,'multiline':False]
['text':' 6. results { alternatives { transcript: " that's" } stability: 0.01 }','line_number':291,'multiline':False]
['text':'    result_index: 1','line_number':292,'multiline':False]
['text':'','line_number':293,'multiline':False]
['text':' 7. results { alternatives { transcript: " that is" } stability: 0.9 }','line_number':294,'multiline':False]
['text':'    results { alternatives { transcript: " the question" } stability: 0.01 }','line_number':295,'multiline':False]
['text':'    result_index: 1','line_number':296,'multiline':False]
['text':'','line_number':297,'multiline':False]
['text':' 8. endpointer_type: END_OF_SPEECH','line_number':298,'multiline':False]
['text':'','line_number':299,'multiline':False]
['text':' 9. results { alternatives { transcript: " that is the question"','line_number':300,'multiline':False]
['text':'                             confidence: 0.98 }','line_number':301,'multiline':False]
['text':'              alternatives { transcript: " that was the question" }','line_number':302,'multiline':False]
['text':'              is_final: true }','line_number':303,'multiline':False]
['text':'    result_index: 1','line_number':304,'multiline':False]
['text':'','line_number':305,'multiline':False]
['text':' 10. endpointer_type: END_OF_AUDIO','line_number':306,'multiline':False]
['text':'','line_number':307,'multiline':False]
['text':' Notes:','line_number':308,'multiline':False]
['text':'','line_number':309,'multiline':False]
['text':' - Only two of the above responses #5 and #9 contain final results, they are','line_number':310,'multiline':False]
['text':'   indicated by `is_final: true`. Concatenating these together generates the','line_number':311,'multiline':False]
['text':'   full transcript: "to be or not to be that is the question".','line_number':312,'multiline':False]
['text':'','line_number':313,'multiline':False]
['text':' - The others contain interim `results`. #4 and #7 contain two interim','line_number':314,'multiline':False]
['text':'   `results`, the first portion has a high stability and is less likely to','line_number':315,'multiline':False]
['text':'   change, the second portion has a low stability and is very likely to','line_number':316,'multiline':False]
['text':'   change. A UI designer might choose to show only high stability `results`.','line_number':317,'multiline':False]
['text':'','line_number':318,'multiline':False]
['text':' - The specific `stability` and `confidence` values shown above are only for','line_number':319,'multiline':False]
['text':'   illustrative purposes. Actual values may vary.','line_number':320,'multiline':False]
['text':'','line_number':321,'multiline':False]
['text':' - The `result_index` indicates the portion of audio that has had final','line_number':322,'multiline':False]
['text':'   results returned, and is no longer being processed. For example, the','line_number':323,'multiline':False]
['text':'   `results` in #6 and later correspond to the portion of audio after','line_number':324,'multiline':False]
['text':'   "to be or not to be".','line_number':325,'multiline':False]
['text':' Indicates the type of endpointer event.','line_number':327,'multiline':False]
['text':' No endpointer event specified.','line_number':329,'multiline':False]
['text':' Speech has been detected in the audio stream, and the service is','line_number':332,'multiline':False]
['text':' beginning to process it.','line_number':333,'multiline':False]
['text':' Speech has ceased to be detected in the audio stream. (For example, the','line_number':336,'multiline':False]
['text':' user may have paused after speaking.) If `single_utterance` is `false`,','line_number':337,'multiline':False]
['text':' the service will continue to process audio, and if subsequent speech is','line_number':338,'multiline':False]
['text':' detected, will send another START_OF_SPEECH event.','line_number':339,'multiline':False]
['text':' This event is sent after the client has half-closed the input stream gRPC','line_number':342,'multiline':False]
['text':' connection and the server has received all of the audio. (The server may','line_number':343,'multiline':False]
['text':' still be processing the audio and may subsequently return additional','line_number':344,'multiline':False]
['text':' results.)','line_number':345,'multiline':False]
['text':' This event is only sent when `single_utterance` is `true`. It indicates','line_number':348,'multiline':False]
['text':' that the server has detected the end of the user's speech utterance and','line_number':349,'multiline':False]
['text':' expects no additional speech. Therefore, the server will not process','line_number':350,'multiline':False]
['text':' additional audio (although it may subsequently return additional','line_number':351,'multiline':False]
['text':' results). The client should stop sending additional audio data,','line_number':352,'multiline':False]
['text':' half-close the gRPC connection, and wait for any additional results','line_number':353,'multiline':False]
['text':' until the server closes the gRPC connection.','line_number':354,'multiline':False]
['text':' *Output-only* If set, returns a [google.rpc.Status][google.rpc.Status] message that','line_number':358,'multiline':False]
['text':' specifies the error for the operation.','line_number':359,'multiline':False]
['text':' *Output-only* This repeated list contains zero or more results that','line_number':362,'multiline':False]
['text':' correspond to consecutive portions of the audio currently being processed.','line_number':363,'multiline':False]
['text':' It contains zero or one `is_final=true` result (the newly settled portion),','line_number':364,'multiline':False]
['text':' followed by zero or more `is_final=false` results.','line_number':365,'multiline':False]
['text':' *Output-only* Indicates the lowest index in the `results` array that has','line_number':368,'multiline':False]
['text':' changed. The repeated `StreamingRecognitionResult` results overwrite past','line_number':369,'multiline':False]
['text':' results at this index and higher.','line_number':370,'multiline':False]
['text':' *Output-only* Indicates the type of endpointer event.','line_number':373,'multiline':False]
['text':' A streaming speech recognition result corresponding to a portion of the audio','line_number':377,'multiline':False]
['text':' that is currently being processed.','line_number':378,'multiline':False]
['text':' *Output-only* May contain one or more recognition hypotheses (up to the','line_number':380,'multiline':False]
['text':' maximum specified in `max_alternatives`).','line_number':381,'multiline':False]
['text':' *Output-only* If `false`, this `StreamingRecognitionResult` represents an','line_number':384,'multiline':False]
['text':' interim result that may change. If `true`, this is the final time the','line_number':385,'multiline':False]
['text':' speech service will return this particular `StreamingRecognitionResult`,','line_number':386,'multiline':False]
['text':' the recognizer will not return any further hypotheses for this portion of','line_number':387,'multiline':False]
['text':' the transcript and corresponding audio.','line_number':388,'multiline':False]
['text':' *Output-only* An estimate of the likelihood that the recognizer will not','line_number':391,'multiline':False]
['text':' change its guess about this interim result. Values range from 0.0','line_number':392,'multiline':False]
['text':' (completely unstable) to 1.0 (completely stable).','line_number':393,'multiline':False]
['text':' This field is only provided for interim results (`is_final=false`).','line_number':394,'multiline':False]
['text':' The default of 0.0 is a sentinel value indicating `stability` was not set.','line_number':395,'multiline':False]
['text':' A speech recognition result corresponding to a portion of the audio.','line_number':399,'multiline':False]
['text':' *Output-only* May contain one or more recognition hypotheses (up to the','line_number':401,'multiline':False]
['text':' maximum specified in `max_alternatives`).','line_number':402,'multiline':False]
['text':' Alternative hypotheses (a.k.a. n-best list).','line_number':406,'multiline':False]
['text':' *Output-only* Transcript text representing the words that the user spoke.','line_number':408,'multiline':False]
['text':' *Output-only* The confidence estimate between 0.0 and 1.0. A higher number','line_number':411,'multiline':False]
['text':' indicates an estimated greater likelihood that the recognized words are','line_number':412,'multiline':False]
['text':' correct. This field is typically provided only for the top hypothesis, and','line_number':413,'multiline':False]
['text':' only for `is_final=true` results. Clients should not rely on the','line_number':414,'multiline':False]
['text':' `confidence` field as it is not guaranteed to be accurate, or even set, in','line_number':415,'multiline':False]
['text':' any of the results.','line_number':416,'multiline':False]
['text':' The default of 0.0 is a sentinel value indicating `confidence` was not set.','line_number':417,'multiline':False]
