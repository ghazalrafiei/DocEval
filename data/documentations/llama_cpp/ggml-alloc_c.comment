['text':'#define GGML_ALLOCATOR_DEBUG','line_number':15,'multiline':False]
['text':'#define AT_PRINTF(...) fprintf(stderr, __VA_ARGS__)','line_number':17,'multiline':False]
['text':' TODO: GGML_PAD ?','line_number':20,'multiline':False]
['text':' power of 2','line_number':22,'multiline':False]
['text':' check if a tensor is allocated by this buffer','line_number':73,'multiline':False]
['text':' views generally get data pointer from one of their sources','line_number':83,'multiline':False]
['text':' avoid allocating tensor which already has memory allocated','line_number':84,'multiline':False]
['text':' find the best fitting free block besides the last block','line_number':93,'multiline':False]
['text':' the last block is our last resort','line_number':108,'multiline':False]
['text':' remove block if empty','line_number':125,'multiline':False]
['text':' this is a very naive implementation, but for our case the number of free blocks should be very small','line_number':155,'multiline':False]
['text':' the tensor was not allocated in this buffer','line_number':158,'multiline':False]
['text':' this can happen because the graph allocator will try to free weights and other tensors from different buffers','line_number':159,'multiline':False]
['text':' the easiest way to deal with this is just to ignore it','line_number':160,'multiline':False]
['text':' AT_PRINTF("ignoring %s (their buffer: %p, our buffer: %p)\n", tensor->name, (void *)tensor->buffer, (void *)alloc->buffer);','line_number':161,'multiline':False]
['text':' see if we can merge with an existing block','line_number':175,'multiline':False]
['text':' check if ptr is at the end of the block','line_number':178,'multiline':False]
['text':' check if we can merge with the next block','line_number':181,'multiline':False]
['text':' check if ptr is at the beginning of the block','line_number':191,'multiline':False]
['text':' check if we can merge with the previous block','line_number':195,'multiline':False]
['text':' otherwise, add a new block','line_number':206,'multiline':False]
['text':' insert the new block in the correct position to keep the array sorted by address (to make merging blocks faster)','line_number':208,'multiline':False]
['text':' shift all blocks from insert_pos onward to make room for the new block','line_number':213,'multiline':False]
['text':' insert the new block','line_number':217,'multiline':False]
['text':' restrict maximum size of a measure allocator to half size_t max to avoid overflows','line_number':229,'multiline':False]
['text':'.buffer        = ','line_number':241,'multiline':True]
['text':'.buffer_owned  = ','line_number':242,'multiline':True]
['text':'.base          = ','line_number':243,'multiline':True]
['text':'.alignment     = ','line_number':244,'multiline':True]
['text':'.n_free_blocks = ','line_number':245,'multiline':True]
['text':'.free_blocks   = ','line_number':246,'multiline':True]
['text':'.max_size      = ','line_number':247,'multiline':True]
['text':'.measure       = ','line_number':248,'multiline':True]
['text':'.allocated_tensors = ','line_number':250,'multiline':True]
['text':' create a backend buffer to get the correct tensor allocation sizes','line_number':267,'multiline':False]
['text':' TODO: move alloc initialization to a common ggml_tallocr_new_impl function','line_number':270,'multiline':False]
['text':'.buffer        = ','line_number':289,'multiline':True]
['text':'.buffer_owned  = ','line_number':290,'multiline':True]
['text':'.base          = ','line_number':291,'multiline':True]
['text':'.alignment     = ','line_number':292,'multiline':True]
['text':'.n_free_blocks = ','line_number':293,'multiline':True]
['text':'.free_blocks   = ','line_number':294,'multiline':True]
['text':'.max_size      = ','line_number':295,'multiline':True]
['text':'.measure       = ','line_number':296,'multiline':True]
['text':'.allocated_tensors = ','line_number':298,'multiline':True]
['text':' graph allocator','line_number':330,'multiline':False]
['text':'.talloc           = ','line_number':351,'multiline':True]
['text':'.hash_set         = ','line_number':352,'multiline':True]
['text':'.hash_values      = ','line_number':353,'multiline':True]
['text':'.hash_values_size = ','line_number':354,'multiline':True]
['text':'.hash_allocs      = ','line_number':355,'multiline':True]
['text':'.parse_seq        = ','line_number':356,'multiline':True]
['text':'.parse_seq_len    = ','line_number':357,'multiline':True]
['text':' FIXME: the view should be initialized by the owning buffer, but currently this breaks the CUDA backend','line_number':455,'multiline':False]
['text':' due to the ggml_tensor_extra_gpu ring buffer overwriting the KV cache extras','line_number':456,'multiline':False]
['text':' see if we can reuse a parent's buffer (inplace)','line_number':471,'multiline':False]
['text':' if the node's data is external, then we cannot re-use it','line_number':479,'multiline':False]
['text':' TODO: the offset of the view parent must be kept to ensure that the op doesn't overwrite','line_number':491,'multiline':False]
['text':' the parent's data that it will need later (same layout requirement). the problem is that then','line_number':492,'multiline':False]
['text':' we cannot free the tensor because the original address of the allocation is lost.','line_number':493,'multiline':False]
['text':' adding a view_src pointer to the tensor would solve this and simplify the code dealing with views','line_number':494,'multiline':False]
['text':' for now, we only reuse the parent's data if the offset is zero (view_src->data == parent->data)','line_number':495,'multiline':False]
['text':' count number of children and views','line_number':527,'multiline':False]
['text':' view of a pre-allocated tensor, didn't call init_view() yet','line_number':535,'multiline':False]
['text':' allocate tensors','line_number':552,'multiline':False]
['text':' if we have parse_seq then we allocate nodes following the list, and we only free nodes at barriers','line_number':553,'multiline':False]
['text':' allocate a node if there is no parse_seq or this is not a barrier','line_number':558,'multiline':False]
['text':' allocate parents (leafs)','line_number':563,'multiline':False]
['text':' allocate node','line_number':572,'multiline':False]
['text':' update parents','line_number':589,'multiline':False]
['text':' update immediately if there is no parse_seq','line_number':590,'multiline':False]
['text':' update only at barriers if there is parse_seq','line_number':591,'multiline':False]
['text':'AT_PRINTF("parent %s: %d children, %d views\n", parent->name, parent->n_children, parent->n_views);','line_number':607,'multiline':False]
['text':' check if the hash table is initialized and large enough','line_number':636,'multiline':False]
['text':' reset hash table','line_number':649,'multiline':False]
['text':' alloc hash_values if needed','line_number':669,'multiline':False]
['text':' free hash_set.keys if needed','line_number':676,'multiline':False]
['text':' reset hash values','line_number':682,'multiline':False]
['text':' remove unowned resources','line_number':689,'multiline':False]
['text':' legacy API wrapper','line_number':694,'multiline':False]
['text':'.talloc = ','line_number':704,'multiline':True]
['text':'.galloc = ','line_number':705,'multiline':True]
['text':' utils','line_number':764,'multiline':False]
