['text':' sampling parameters','line_number':11,'multiline':False]
['text':' number of previous tokens to remember','line_number':13,'multiline':False]
['text':' if greater than 0, output the probabilities of top n_probs tokens.','line_number':14,'multiline':False]
['text':' <= 0 to use vocab size','line_number':15,'multiline':False]
['text':' 1.0 = disabled','line_number':16,'multiline':False]
['text':' 0.0 = disabled','line_number':17,'multiline':False]
['text':' 1.0 = disabled','line_number':18,'multiline':False]
['text':' 1.0 = disabled','line_number':19,'multiline':False]
['text':' 1.0 = disabled','line_number':20,'multiline':False]
['text':' last n tokens to penalize (0 = disable penalty, -1 = context size)','line_number':21,'multiline':False]
['text':' 1.0 = disabled','line_number':22,'multiline':False]
['text':' 0.0 = disabled','line_number':23,'multiline':False]
['text':' 0.0 = disabled','line_number':24,'multiline':False]
['text':' 0 = disabled, 1 = mirostat, 2 = mirostat 2.0','line_number':25,'multiline':False]
['text':' target entropy','line_number':26,'multiline':False]
['text':' learning rate','line_number':27,'multiline':False]
['text':' consider newlines as a repeatable token','line_number':28,'multiline':False]
['text':' top_k, tail_free, typical_p, top_p, min_p, temp','line_number':29,'multiline':False]
['text':' optional BNF-like grammar to constrain sampling','line_number':31,'multiline':False]
['text':' Classifier-Free Guidance','line_number':33,'multiline':False]
['text':' https://arxiv.org/abs/2306.17806','line_number':34,'multiline':False]
['text':' string to help guidance','line_number':35,'multiline':False]
['text':' how strong is guidance','line_number':36,'multiline':False]
['text':' logit bias for specific tokens','line_number':38,'multiline':False]
['text':' general sampler context','line_number':41,'multiline':False]
['text':' TODO: move to llama.h','line_number':42,'multiline':False]
['text':' parameters that will be used for sampling','line_number':44,'multiline':False]
['text':' mirostat sampler state','line_number':47,'multiline':False]
['text':' internal','line_number':52,'multiline':False]
['text':' TODO: replace with ring-buffer','line_number':55,'multiline':False]
['text':' Create a new sampling context instance.','line_number':62,'multiline':False]
['text':' Reset the sampler context','line_number':67,'multiline':False]
['text':' - clear prev tokens','line_number':68,'multiline':False]
['text':' - reset grammar','line_number':69,'multiline':False]
['text':' Copy the sampler context','line_number':72,'multiline':False]
['text':' Get the last sampled token','line_number':75,'multiline':False]
['text':' Get a string representation of the last sampled tokens','line_number':78,'multiline':False]
['text':' Print sampling parameters into a string','line_number':81,'multiline':False]
['text':' Print sampling order into a string','line_number':84,'multiline':False]
['text':' this is a common sampling function used across the examples for convenience','line_number':87,'multiline':False]
['text':' it can serve as a starting point for implementing your own sampling function','line_number':88,'multiline':False]
['text':' Note: When using multiple sequences, it is the caller's responsibility to call','line_number':89,'multiline':False]
['text':'       llama_sampling_reset when a sequence ends','line_number':90,'multiline':False]
['text':'','line_number':91,'multiline':False]
['text':' required:','line_number':92,'multiline':False]
['text':'  - ctx_main:     context to use for sampling','line_number':93,'multiline':False]
['text':'  - ctx_sampling: sampling-specific context','line_number':94,'multiline':False]
['text':'','line_number':95,'multiline':False]
['text':' optional:','line_number':96,'multiline':False]
['text':'  - ctx_cfg:      context to use for classifier-free guidance','line_number':97,'multiline':False]
['text':'  - idx:          sample from llama_get_logits_ith(ctx, idx)','line_number':98,'multiline':False]
['text':'','line_number':99,'multiline':False]
['text':' returns:','line_number':100,'multiline':False]
['text':'  - token:      sampled token','line_number':101,'multiline':False]
['text':'  - candidates: vector of candidate tokens','line_number':102,'multiline':False]
['text':'','line_number':103,'multiline':False]
