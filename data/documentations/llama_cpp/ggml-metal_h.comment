['text':' An interface allowing to compute ggml_cgraph with Metal','line_number':1,'multiline':False]
['text':'','line_number':2,'multiline':False]
['text':' This is a fully functional interface that extends ggml with GPU support for Apple devices.','line_number':3,'multiline':False]
['text':' A similar interface can be created for other GPU backends (e.g. Vulkan, CUDA, OpenCL, etc.)','line_number':4,'multiline':False]
['text':'','line_number':5,'multiline':False]
['text':' How it works?','line_number':6,'multiline':False]
['text':'','line_number':7,'multiline':False]
['text':' As long as your program can create and evaluate a ggml_cgraph on the CPU, you can use this','line_number':8,'multiline':False]
['text':' interface to evaluate the same graph on the GPU. Instead of using ggml_graph_compute(), you','line_number':9,'multiline':False]
['text':' use ggml_metal_graph_compute() (or ggml_vulkan_graph_compute(), etc.)','line_number':10,'multiline':False]
['text':'','line_number':11,'multiline':False]
['text':' You only need to make sure that all memory buffers that you used during the graph creation','line_number':12,'multiline':False]
['text':' are mapped to the device memory with the ggml_metal_add_buffer() function. This mapping is','line_number':13,'multiline':False]
['text':' used during the graph evaluation to determine the arguments of the compute kernels.','line_number':14,'multiline':False]
['text':'','line_number':15,'multiline':False]
['text':' Synchronization between device and host memory (for example for input and output tensors)','line_number':16,'multiline':False]
['text':' is done with the ggml_metal_set_tensor() and ggml_metal_get_tensor() functions.','line_number':17,'multiline':False]
['text':'','line_number':18,'multiline':False]
['text':' max memory buffers that can be mapped to the device','line_number':28,'multiline':False]
['text':'','line_number':39,'multiline':False]
['text':' internal API','line_number':40,'multiline':False]
['text':' temporary exposed to user-code','line_number':41,'multiline':False]
['text':'','line_number':42,'multiline':False]
['text':' number of command buffers to use','line_number':48,'multiline':False]
['text':' set the number of command buffers to use','line_number':55,'multiline':False]
['text':' creates a mapping between a host memory buffer and a device memory buffer','line_number':58,'multiline':False]
['text':' - make sure to map all buffers used in the graph before calling ggml_metal_graph_compute','line_number':59,'multiline':False]
['text':' - the mapping is used during computation to determine the arguments of the compute kernels','line_number':60,'multiline':False]
['text':' - you don't need to keep the host memory buffer allocated as it is never accessed by Metal','line_number':61,'multiline':False]
['text':' - max_size specifies the maximum size of a tensor and is used to create shared views such','line_number':62,'multiline':False]
['text':'   that it is guaranteed that the tensor will fit in at least one of the views','line_number':63,'multiline':False]
['text':'','line_number':64,'multiline':False]
['text':' set data from host memory into the device','line_number':72,'multiline':False]
['text':' get data from the device into host memory','line_number':75,'multiline':False]
['text':' try to find operations that can be run concurrently in the graph','line_number':78,'multiline':False]
['text':' you should run it again if the topology of your graph changes','line_number':79,'multiline':False]
['text':' if the graph has been optimized for concurrently dispatch, return length of the concur_list if optimized','line_number':82,'multiline':False]
['text':' output the concur_list for ggml_alloc','line_number':85,'multiline':False]
['text':' same as ggml_graph_compute but uses Metal','line_number':88,'multiline':False]
['text':' creates gf->n_threads command buffers in parallel','line_number':89,'multiline':False]
['text':'','line_number':92,'multiline':False]
['text':' backend API','line_number':93,'multiline':False]
['text':' user-code should use only these functions','line_number':94,'multiline':False]
['text':'','line_number':95,'multiline':False]
['text':' helper to check if the device supports a specific family','line_number':104,'multiline':False]
['text':' ideally, the user code should be doing these checks','line_number':105,'multiline':False]
['text':' ref: https://developer.apple.com/metal/Metal-Feature-Set-Tables.pdf','line_number':106,'multiline':False]
