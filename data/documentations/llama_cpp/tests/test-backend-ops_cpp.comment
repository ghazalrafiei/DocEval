['text':' access elements by index to avoid gaps in views','line_number':76,'multiline':False]
['text':'
static double cosine_similarity(const float * v1, const float * v2, size_t n) {
    double dot = 0.0;
    double mag1 = 0.0;
    double mag2 = 0.0;

    for (size_t i = 0; i < n; i++) {
        if (std::isnan(v1[i]) || std::isnan(v2[i])) {
            return -1.0f;
        }
        if (std::isinf(v1[i]) && std::isinf(v2[i])) {
            continue;
        }
        dot  += v1[i]*v2[i];
        mag1 += v1[i]*v1[i];
        mag2 += v2[i]*v2[i];
    }

    return dot/sqrt(mag1*mag2);
}

static float distance(const float * v1, const float * v2, size_t n) {
    double d = 0.0;

    for (size_t i = 0; i < n; i++) {
        if (std::isnan(v1[i]) || std::isnan(v2[i])) {
            return INFINITY;
        }
        if (std::isinf(v1[i]) && std::isinf(v2[i])) {
            continue;
        }
        d += (v1[i] - v2[i])*(v1[i] - v2[i]);
    }

    return sqrt(d);
}

static float vec_len(const float * v, size_t n) {
    double d = 0.0;

    for (size_t i = 0; i < n; i++) {
        if (std::isnan(v[i])) {
            return INFINITY;
        }
        if (std::isinf(v[i])) {
            continue;
        }
        d += v[i]*v[i];
    }

    return sqrt(d);
}
','line_number':103,'multiline':True]
['text':' normalized mean squared error = mse(a, b) / mse(a, 0)','line_number':157,'multiline':False]
['text':' utils for printing the variables of the test cases','line_number':173,'multiline':False]
['text':'static std::string var_to_str(ggml_unary_op unary_op) {','line_number':207,'multiline':False]
['text':'    return ggml_unary_op_name(unary_op);','line_number':208,'multiline':False]
['text':'}','line_number':209,'multiline':False]
['text':' accept FLT_MAX as infinity','line_number':228,'multiline':False]
['text':' add source tensors','line_number':267,'multiline':False]
['text':' hijack ggml_new_tensor to add sentinels after each tensor to check for overflows in the backend','line_number':293,'multiline':False]
['text':' .mem_size = ','line_number':329,'multiline':True]
['text':' .mem_base = ','line_number':330,'multiline':True]
['text':' .no_alloc = ','line_number':331,'multiline':True]
['text':' pre-graph sentinel','line_number':337,'multiline':False]
['text':'printf("  %s: skipping\n", op_desc(out).c_str());','line_number':343,'multiline':False]
['text':' check if backends support op','line_number':351,'multiline':False]
['text':' post-graph sentinel','line_number':360,'multiline':False]
['text':' allocate','line_number':363,'multiline':False]
['text':' build graph','line_number':366,'multiline':False]
['text':' add sentinels as graph nodes so that they are checked in the callback','line_number':369,'multiline':False]
['text':' randomize tensors','line_number':374,'multiline':False]
['text':' compare','line_number':377,'multiline':False]
['text':' sentinels must be unchanged','line_number':392,'multiline':False]
['text':' check for nans','line_number':409,'multiline':False]
['text':' check for infs: both must be inf of the same sign, or both must be finite','line_number':415,'multiline':False]
['text':'for (int i = 0; i < f1.size(); i++) {','line_number':434,'multiline':False]
['text':'    printf("%5d %9.6f %9.6f, diff = %9.6f\n", i, f1[i], f2[i], f1[i] - f2[i]);','line_number':435,'multiline':False]
['text':'}','line_number':436,'multiline':False]
['text':'printf("\n");','line_number':437,'multiline':False]
['text':'exit(1);','line_number':438,'multiline':False]
['text':' .mem_size = ','line_number':467,'multiline':True]
['text':' .mem_base = ','line_number':468,'multiline':True]
['text':' .no_alloc = ','line_number':469,'multiline':True]
['text':'printf("  %s: skipping\n", op_desc(out).c_str());','line_number':476,'multiline':False]
['text':' check if backends support op','line_number':484,'multiline':False]
['text':' align while also leaving some margin for variations in parameters','line_number':491,'multiline':False]
['text':' allocate','line_number':500,'multiline':False]
['text':' randomize tensors','line_number':503,'multiline':False]
['text':' build graph','line_number':506,'multiline':False]
['text':' warmup run','line_number':510,'multiline':False]
['text':' duplicate the op','line_number':513,'multiline':False]
['text':' 8 GB CPU, 32 GB GPU','line_number':514,'multiline':False]
['text':' calculate memory','line_number':520,'multiline':False]
['text':' add source tensors','line_number':524,'multiline':False]
['text':' run','line_number':539,'multiline':False]
['text':' GGML_OP_UNARY','line_number':562,'multiline':False]
['text':' GGML_OP_GET_ROWS','line_number':584,'multiline':False]
['text':' cols','line_number':587,'multiline':False]
['text':' rows','line_number':588,'multiline':False]
['text':' rows to get','line_number':589,'multiline':False]
['text':' batch size','line_number':590,'multiline':False]
['text':' view (non-contiguous src1)','line_number':591,'multiline':False]
['text':' rows','line_number':614,'multiline':False]
['text':' GGML_OP_REPEAT','line_number':627,'multiline':False]
['text':' GGML_OP_DUP','line_number':654,'multiline':False]
['text':' GGML_OP_CPY','line_number':674,'multiline':False]
['text':' GGML_OP_CONT','line_number':700,'multiline':False]
['text':' GGML_OP_ADD','line_number':722,'multiline':False]
['text':' GGML_OP_MUL','line_number':723,'multiline':False]
['text':' GGML_OP_DIV','line_number':724,'multiline':False]
['text':' avoid division by zero','line_number':755,'multiline':False]
['text':' GGML_OP_SCALE','line_number':764,'multiline':False]
['text':' GGML_OP_NORM','line_number':785,'multiline':False]
['text':' GGML_OP_RMS_NORM','line_number':807,'multiline':False]
['text':' GGML_OP_MUL_MAT','line_number':829,'multiline':False]
['text':' dims 3 and 4','line_number':836,'multiline':False]
['text':' repeat in dims 3 and 4','line_number':837,'multiline':False]
['text':' C^T = A * B^T: (k, m) * (k, n) => (m, n)','line_number':863,'multiline':False]
['text':' GGML_OP_MUL_MAT_ID','line_number':871,'multiline':False]
['text':' view (non-contiguous ids)','line_number':880,'multiline':False]
['text':' C^T = A * B^T: (k, m) * (k, n) => (m, n)','line_number':906,'multiline':False]
['text':' ids','line_number':927,'multiline':False]
['text':' GGML_OP_SQR','line_number':943,'multiline':False]
['text':' GGML_OP_CLAMP','line_number':963,'multiline':False]
['text':' GGML_OP_DIAG_MASK_INF','line_number':986,'multiline':False]
['text':' GGML_OP_SOFT_MAX','line_number':1008,'multiline':False]
['text':' GGML_OP_ROPE','line_number':1028,'multiline':False]
['text':' pos','line_number':1055,'multiline':False]
['text':' GGML_OP_ALIBI','line_number':1068,'multiline':False]
['text':' GGML_OP_IM2COL','line_number':1092,'multiline':False]
['text':' stride','line_number':1098,'multiline':False]
['text':' padding','line_number':1101,'multiline':False]
['text':' dilatation','line_number':1104,'multiline':False]
['text':' mode','line_number':1107,'multiline':False]
['text':' [input_width, input_height, input_channels, 1]','line_number':1115,'multiline':False]
['text':' [kernel_width, kernel_height, input_channels, 1]','line_number':1116,'multiline':False]
['text':' GGML_OP_CONCAT','line_number':1131,'multiline':False]
['text':' GGML_OP_ARGSORT','line_number':1154,'multiline':False]
['text':' indices','line_number':1180,'multiline':False]
['text':' initialize with unique values to avoid ties','line_number':1188,'multiline':False]
['text':' GGML_OP_SUM_ROWS','line_number':1204,'multiline':False]
['text':' GGML_OP_UPSCALE','line_number':1224,'multiline':False]
['text':' GGML_OP_GROUP_NORM','line_number':1246,'multiline':False]
['text':' GGML_OP_ACC','line_number':1268,'multiline':False]
['text':' GGML_OP_PAD','line_number':1291,'multiline':False]
['text':' GGML_OP_LEAKY_RELU','line_number':1314,'multiline':False]
['text':' Mixtral MOE','line_number':1336,'multiline':False]
['text':' select experts','line_number':1376,'multiline':False]
['text':' compute expert outputs','line_number':1388,'multiline':False]
['text':' unary ops','line_number':1433,'multiline':False]
['text':' stable diffusion','line_number':1481,'multiline':False]
['text':'add_test_bin_bcast(GGML_TYPE_F32, {3, 3, 2560, 1280}, {1, 1, 1, 1});','line_number':1495,'multiline':False]
['text':'add_test_bin_bcast(GGML_TYPE_F32, {3, 3, 2560, 1280}, {2, 1, 1, 1});','line_number':1496,'multiline':False]
['text':', GGML_TYPE_F16 ','line_number':1506,'multiline':True]
['text':' FIXME: CPU crashes on f16xf16','line_number':1507,'multiline':False]
['text':', GGML_TYPE_F16 ','line_number':1527,'multiline':True]
['text':' llama 7B','line_number':1548,'multiline':False]
['text':' llama 13B','line_number':1549,'multiline':False]
['text':' llama 30B','line_number':1550,'multiline':False]
['text':' llama 65B','line_number':1551,'multiline':False]
['text':' neox (falcon 7B)','line_number':1552,'multiline':False]
['text':' neox (falcon 7B)','line_number':1553,'multiline':False]
['text':' neox (falcon 40B)','line_number':1554,'multiline':False]
['text':' neox (falcon 40B)','line_number':1555,'multiline':False]
['text':' neox (stablelm)','line_number':1556,'multiline':False]
['text':' FIXME: these tests use too much memory with thread sanitizer','line_number':1576,'multiline':False]
['text':'test_cases.emplace_back(new test_moe(8, 2, 8, 4096, 14336));','line_number':1578,'multiline':False]
['text':' run tests','line_number':1581,'multiline':False]
['text':' enumerate backends','line_number':1645,'multiline':False]
