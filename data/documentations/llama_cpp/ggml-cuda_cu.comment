['text':' for rocblas_initialize()','line_number':19,'multiline':False]
['text':' __HIP_PLATFORM_AMD__','line_number':21,'multiline':False]
['text':' defined(GGML_USE_HIPBLAS)','line_number':85,'multiline':False]
['text':' minimum compute capability for __dp4a, an intrinsic for byte-wise dot products','line_number':91,'multiline':False]
['text':' define this if you want to always fallback to MMQ kernels and not use cuBLAS for matrix multiplication','line_number':98,'multiline':False]
['text':' on modern hardware, using cuBLAS is recommended as it utilizes F16 tensor cores which are very performant','line_number':99,'multiline':False]
['text':' for large computational tasks. the drawback is that this requires some extra amount of VRAM:','line_number':100,'multiline':False]
['text':' -  7B quantum model: +100-200 MB','line_number':101,'multiline':False]
['text':' - 13B quantum model: +200-400 MB','line_number':102,'multiline':False]
['text':'','line_number':103,'multiline':False]
['text':'#define GGML_CUDA_FORCE_MMQ','line_number':104,'multiline':False]
['text':' TODO: improve this to be correct for more hardware','line_number':106,'multiline':False]
['text':'       for example, currently fails for GeForce GTX 1660 which is TURING arch (> VOLTA) but does not have tensor cores','line_number':107,'multiline':False]
['text':'       probably other such cases, and not sure what happens on AMD hardware','line_number':108,'multiline':False]
['text':' max batch size to use MMQ kernels when tensor cores are available','line_number':113,'multiline':False]
['text':' __has_builtin(__builtin_elementwise_sub_sat)','line_number':151,'multiline':False]
['text':' defined(GGML_USE_HIPBLAS)','line_number':180,'multiline':False]
['text':' possible loss of data','line_number':183,'multiline':False]
['text':' CUDART_VERSION >= 11','line_number':226,'multiline':False]
['text':' CUDART_VERSION >= 11100','line_number':232,'multiline':False]
['text':' dequantize float','line_number':235,'multiline':False]
['text':' dequantize float','line_number':238,'multiline':False]
['text':'GGML_CUDA_F16','line_number':240,'multiline':False]
['text':' assume at least 2 byte alignment','line_number':243,'multiline':False]
['text':' assume at least 2 byte alignment','line_number':253,'multiline':False]
['text':' assume at least 4 byte alignment','line_number':263,'multiline':False]
['text':' assume at least 4 byte alignment','line_number':267,'multiline':False]
['text':' QK = number of values after dequantization','line_number':287,'multiline':False]
['text':' QR = QK / number of values before dequantization','line_number':288,'multiline':False]
['text':' QI = number of 32 bit integers before dequantization','line_number':289,'multiline':False]
['text':' delta','line_number':295,'multiline':False]
['text':' nibbles / quants','line_number':296,'multiline':False]
['text':' dm.x = delta, dm.y = min','line_number':304,'multiline':False]
['text':' nibbles / quants','line_number':305,'multiline':False]
['text':' delta','line_number':313,'multiline':False]
['text':' 5-th bit of quants','line_number':314,'multiline':False]
['text':' nibbles / quants','line_number':315,'multiline':False]
['text':' dm.x = delta, dm.y = min','line_number':323,'multiline':False]
['text':' 5-th bit of quants','line_number':324,'multiline':False]
['text':' nibbles / quants','line_number':325,'multiline':False]
['text':' delta','line_number':333,'multiline':False]
['text':' quants','line_number':334,'multiline':False]
['text':' ds.x = delta, ds.y = sum','line_number':342,'multiline':False]
['text':' quants','line_number':343,'multiline':False]
['text':'================================= k-quants','line_number':356,'multiline':False]
['text':' scales and mins, quantized with 4 bits','line_number':369,'multiline':False]
['text':' quants','line_number':370,'multiline':False]
['text':' super-block scale for quantized scales/mins','line_number':371,'multiline':False]
['text':' quants - high bit','line_number':378,'multiline':False]
['text':' quants - low 2 bits','line_number':379,'multiline':False]
['text':' scales, quantized with 8 bits','line_number':381,'multiline':False]
['text':' scales, quantized with 6 bits','line_number':383,'multiline':False]
['text':' super-block scale','line_number':385,'multiline':False]
['text':'static_assert(sizeof(block_q3_K) == sizeof(ggml_fp16_t) + QK_K / 4 + QK_K / 8 + K_SCALE_SIZE, "wrong q3_K block size/padding");','line_number':387,'multiline':False]
['text':' super-block scales/mins','line_number':393,'multiline':False]
['text':' 4-bit block scales/mins','line_number':394,'multiline':False]
['text':' 4--bit quants','line_number':395,'multiline':False]
['text':' super-block scale for quantized scales/mins','line_number':400,'multiline':False]
['text':' scales, quantized with 6 bits','line_number':401,'multiline':False]
['text':' 4--bit quants','line_number':402,'multiline':False]
['text':' super-block scale','line_number':411,'multiline':False]
['text':' block scales','line_number':412,'multiline':False]
['text':' quants, high bit','line_number':413,'multiline':False]
['text':' quants, low 4 bits','line_number':414,'multiline':False]
['text':' super-block scale for quantized scales/mins','line_number':419,'multiline':False]
['text':' scales and mins, quantized with 6 bits','line_number':420,'multiline':False]
['text':' quants, high bit','line_number':421,'multiline':False]
['text':' quants, low 4 bits','line_number':422,'multiline':False]
['text':' quants, lower 4 bits','line_number':430,'multiline':False]
['text':' quants, upper 2 bits','line_number':431,'multiline':False]
['text':' scales','line_number':432,'multiline':False]
['text':' delta','line_number':433,'multiline':False]
['text':' last row of quant. matrices is a multiple of this to avoid out-of-bounds memory accesses','line_number':438,'multiline':False]
['text':' dmmv = dequantize_mul_mat_vec','line_number':461,'multiline':False]
['text':' GGML_CUDA_PEER_MAX_BATCH_SIZE','line_number':477,'multiline':False]
['text':' 1 pointer for each device for split tensors','line_number':485,'multiline':False]
['text':' events for synchronizing multiple GPUs','line_number':486,'multiline':False]
['text':' this is faster on Windows','line_number':489,'multiline':False]
['text':' probably because the Windows CUDA libraries forget to make this check before invoking the drivers','line_number':490,'multiline':False]
['text':' disabled by default','line_number':508,'multiline':False]
['text':'int s0, ','line_number':558,'multiline':True]
['text':'int s10,','line_number':559,'multiline':True]
['text':'int s0, ','line_number':591,'multiline':True]
['text':'int s10,','line_number':592,'multiline':True]
['text':' sum up partial sums','line_number':717,'multiline':False]
['text':' operation','line_number':745,'multiline':False]
['text':' src0','line_number':750,'multiline':False]
['text':' operation','line_number':771,'multiline':False]
['text':' operation','line_number':791,'multiline':False]
['text':' partial sum for thread in warp','line_number':818,'multiline':False]
['text':' partial sum for thread in warp','line_number':871,'multiline':False]
['text':' sum up partial sums','line_number':878,'multiline':False]
['text':' GGML_CUDA_F16','line_number':916,'multiline':False]
['text':' GGML_CUDA_F16','line_number':936,'multiline':False]
['text':' GGML_CUDA_F16','line_number':959,'multiline':False]
['text':' GGML_CUDA_F16','line_number':983,'multiline':False]
['text':' GGML_CUDA_F16','line_number':999,'multiline':False]
['text':'================================== k-quants','line_number':1002,'multiline':False]
['text':' 0 or 1','line_number':1026,'multiline':False]
['text':' 0...15','line_number':1027,'multiline':False]
['text':' 0 or 1','line_number':1070,'multiline':False]
['text':' 0...15','line_number':1071,'multiline':False]
['text':' 0...1','line_number':1072,'multiline':False]
['text':' 0...7','line_number':1073,'multiline':False]
['text':' assume 32 threads','line_number':1110,'multiline':False]
['text':' assume 64 threads - this is very slightly better than the one below','line_number':1151,'multiline':False]
['text':' il is in 0...3','line_number':1153,'multiline':False]
['text':' ir is in 0...15','line_number':1154,'multiline':False]
['text':' is is in 0...6','line_number':1155,'multiline':False]
['text':' 0...3','line_number':1180,'multiline':False]
['text':' 0...7','line_number':1181,'multiline':False]
['text':' 0 or 1','line_number':1182,'multiline':False]
['text':' assume 64 threads - this is very slightly better than the one below','line_number':1198,'multiline':False]
['text':' ip is 0 or 1','line_number':1200,'multiline':False]
['text':' 0...32','line_number':1201,'multiline':False]
['text':' assume 32 threads','line_number':1218,'multiline':False]
['text':' 0 or 1','line_number':1220,'multiline':False]
['text':' 0...15','line_number':1221,'multiline':False]
['text':' partial sum for thread in warp','line_number':1248,'multiline':False]
['text':' 0...31 or 0...15','line_number':1251,'multiline':False]
['text':' 0 or 0,1','line_number':1252,'multiline':False]
['text':' 0 or 1. 0 computes 0..., 1 computes 128...','line_number':1256,'multiline':False]
['text':' 0...15 or 0...7','line_number':1257,'multiline':False]
['text':' 0...15 or 0...14 in steps of 2','line_number':1259,'multiline':False]
['text':' 0...15 or 0...7','line_number':1300,'multiline':False]
['text':' 0....1 or 0...3','line_number':1301,'multiline':False]
['text':' sum up partial sums and write back result','line_number':1331,'multiline':False]
['text':' partial sum for thread in warp','line_number':1352,'multiline':False]
['text':' 0...31 or 0...16','line_number':1359,'multiline':False]
['text':' 0 or 0,1','line_number':1360,'multiline':False]
['text':' iterations in the inner loop','line_number':1362,'multiline':False]
['text':' 0 or 1. 0 computes 0..., 1 computes 128...','line_number':1364,'multiline':False]
['text':' 0....15 or 0...7','line_number':1365,'multiline':False]
['text':' 0...15 or 0...14 in steps of 2','line_number':1369,'multiline':False]
['text':' 0...15 or 0...7','line_number':1408,'multiline':False]
['text':' 0....1 or 0...3','line_number':1409,'multiline':False]
['text':' 0...15 or 0...14','line_number':1410,'multiline':False]
['text':' 0 or 1','line_number':1411,'multiline':False]
['text':' 0...7','line_number':1412,'multiline':False]
['text':' sum up partial sums and write back result','line_number':1435,'multiline':False]
['text':' 0...31 or 0...16','line_number':1460,'multiline':False]
['text':' 0 or 0,1','line_number':1461,'multiline':False]
['text':' 8 or 4','line_number':1463,'multiline':False]
['text':' 0...3','line_number':1465,'multiline':False]
['text':' 0...7 or 0...3','line_number':1466,'multiline':False]
['text':' 2 or 4','line_number':1467,'multiline':False]
['text':' 0 or 1. 0 computes 0,32 + 128,160, 1 computes 64,96 + 192,224','line_number':1469,'multiline':False]
['text':' partial sum for thread in warp','line_number':1487,'multiline':False]
['text':' 0...15','line_number':1541,'multiline':False]
['text':' sum up partial sums and write back result','line_number':1571,'multiline':False]
['text':' partial sum for thread in warp','line_number':1590,'multiline':False]
['text':' 0...15','line_number':1597,'multiline':False]
['text':' 0...3','line_number':1600,'multiline':False]
['text':' 0...3','line_number':1601,'multiline':False]
['text':' 0 or 1. 0 computes 0,32 + 128,160, 1 computes 64,96 + 192,224','line_number':1604,'multiline':False]
['text':' 0...15','line_number':1664,'multiline':False]
['text':' sum up partial sums and write back result','line_number':1687,'multiline':False]
['text':' 0...31 or 0...16','line_number':1712,'multiline':False]
['text':' 0 or 0, 1','line_number':1713,'multiline':False]
['text':' 16 or 8','line_number':1715,'multiline':False]
['text':' 0 or 1. 0 computes 0..., 1 computes 128...','line_number':1717,'multiline':False]
['text':' 0...15 or 0...7','line_number':1718,'multiline':False]
['text':' 0...15','line_number':1721,'multiline':False]
['text':' 0, 4, 8, ..., 28','line_number':1724,'multiline':False]
['text':' partial sum for thread in warp','line_number':1732,'multiline':False]
['text':' 0...7','line_number':1768,'multiline':False]
['text':' 0...3','line_number':1769,'multiline':False]
['text':' partial sum for thread in warp','line_number':1773,'multiline':False]
['text':' sum up partial sums and write back result','line_number':1797,'multiline':False]
['text':' automatic half -> float type cast if dfloat == float','line_number':1811,'multiline':False]
['text':' automatic half -> float type cast if dfloat == float','line_number':1819,'multiline':False]
['text':' block index','line_number':1837,'multiline':False]
['text':' quant index','line_number':1838,'multiline':False]
['text':'int64_t ne01, int64_t ne02, int64_t ne03,','line_number':1866,'multiline':True]
['text':'int64_t ne10, int64_t ne11,','line_number':1867,'multiline':True]
['text':'int64_t ne13,','line_number':1867,'multiline':True]
['text':'size_t s0,','line_number':1868,'multiline':True]
['text':'size_t nb00,','line_number':1869,'multiline':True]
['text':', size_t s13','line_number':1870,'multiline':True]
['text':' block index','line_number':1886,'multiline':False]
['text':' quant index','line_number':1887,'multiline':False]
['text':' dst block start index','line_number':1888,'multiline':False]
['text':' dequantize','line_number':1891,'multiline':False]
['text':'int64_t ne01, int64_t ne02, int64_t ne03,','line_number':1902,'multiline':True]
['text':'int64_t ne10, int64_t ne11,','line_number':1903,'multiline':True]
['text':'int64_t ne13,','line_number':1903,'multiline':True]
['text':'size_t s0,','line_number':1904,'multiline':True]
['text':'size_t nb00,','line_number':1905,'multiline':True]
['text':', size_t s13','line_number':1906,'multiline':True]
['text':' block index','line_number':1933,'multiline':False]
['text':' quant index','line_number':1934,'multiline':False]
['text':' y block start index','line_number':1935,'multiline':False]
['text':' dequantize','line_number':1938,'multiline':False]
['text':' VDR = vec dot ratio, how many contiguous integers each thread processes when the vec dot kernel is called','line_number':1946,'multiline':False]
['text':' MMVQ = mul_mat_vec_q, MMQ = mul_mat_q','line_number':1947,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':1955,'multiline':False]
['text':' SIMD dot product of quantized values','line_number':1963,'multiline':False]
['text':' second part effectively subtracts 8 from each quant value','line_number':1970,'multiline':False]
['text':' only to satisfy the compiler','line_number':1974,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':1975,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':1984,'multiline':False]
['text':' SIMD dot product of quantized values','line_number':1992,'multiline':False]
['text':' GGML_CUDA_F16','line_number':2006,'multiline':False]
['text':' scale second part of sum by QI8_1/(vdr * QR4_1) to compensate for multiple threads adding it','line_number':2008,'multiline':False]
['text':' only to satisfy the compiler','line_number':2012,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2013,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2022,'multiline':False]
['text':' lower 4 qs bits, still need qh as 5th bits','line_number':2027,'multiline':False]
['text':' 0 ->  4','line_number':2028,'multiline':False]
['text':' 1 -> 12','line_number':2029,'multiline':False]
['text':' 2 -> 20','line_number':2030,'multiline':False]
['text':' 3 -> 28','line_number':2031,'multiline':False]
['text':' SIMD dot product of quantized values','line_number':2032,'multiline':False]
['text':' upper 4 qs bits, still need qh as 5th bits','line_number':2034,'multiline':False]
['text':' 16 ->  4','line_number':2035,'multiline':False]
['text':' 17 -> 12','line_number':2036,'multiline':False]
['text':' 18 -> 20','line_number':2037,'multiline':False]
['text':' 19 -> 28','line_number':2038,'multiline':False]
['text':' SIMD dot product of quantized values','line_number':2039,'multiline':False]
['text':' second part effectively subtracts 16 from each quant value','line_number':2044,'multiline':False]
['text':' only to satisfy the compiler','line_number':2048,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2049,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2058,'multiline':False]
['text':' lower 4 qs bits, still need qh as 5th bits','line_number':2063,'multiline':False]
['text':' 0 ->  4','line_number':2064,'multiline':False]
['text':' 1 -> 12','line_number':2065,'multiline':False]
['text':' 2 -> 20','line_number':2066,'multiline':False]
['text':' 3 -> 28','line_number':2067,'multiline':False]
['text':' SIMD dot product of quantized values','line_number':2068,'multiline':False]
['text':' upper 4 qs bits, still need qh as 5th bits','line_number':2070,'multiline':False]
['text':' 16 ->  4','line_number':2071,'multiline':False]
['text':' 17 -> 12','line_number':2072,'multiline':False]
['text':' 18 -> 20','line_number':2073,'multiline':False]
['text':' 19 -> 28','line_number':2074,'multiline':False]
['text':' SIMD dot product of quantized values','line_number':2075,'multiline':False]
['text':' GGML_CUDA_F16','line_number':2087,'multiline':False]
['text':' scale second part of sum by QI5_1 / vdr to compensate for multiple threads adding it','line_number':2089,'multiline':False]
['text':' only to satisfy the compiler','line_number':2094,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2095,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2104,'multiline':False]
['text':' SIMD dot product of quantized values','line_number':2109,'multiline':False]
['text':' only to satisfy the compiler','line_number':2116,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2117,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2123,'multiline':False]
['text':' SIMD dot product of quantized values','line_number':2128,'multiline':False]
['text':' GGML_CUDA_F16','line_number':2141,'multiline':False]
['text':' scale second part of sum by QI8_1/ vdr to compensate for multiple threads adding it','line_number':2143,'multiline':False]
['text':' only to satisfy the compiler','line_number':2147,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2148,'multiline':False]
['text':' contiguous v/x values','line_number':2154,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2159,'multiline':False]
['text':' SIMD dot product','line_number':2169,'multiline':False]
['text':' fill int with 4x m','line_number':2171,'multiline':False]
['text':' multiply constant q2_K part with sum of q8_1 values','line_number':2175,'multiline':False]
['text':' only to satisfy the compiler','line_number':2183,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2184,'multiline':False]
['text':' contiguous u/y values','line_number':2187,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2192,'multiline':False]
['text':' fill int with 4x m','line_number':2202,'multiline':False]
['text':' SIMD dot product','line_number':2209,'multiline':False]
['text':' multiply sum of q8_1 values with m','line_number':2210,'multiline':False]
['text':' only to satisfy the compiler','line_number':2221,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2222,'multiline':False]
['text':' contiguous v/x values','line_number':2228,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2233,'multiline':False]
['text':' SIMD dot product','line_number':2256,'multiline':False]
['text':' only to satisfy the compiler','line_number':2262,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2263,'multiline':False]
['text':' contiguous u/y values','line_number':2266,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2271,'multiline':False]
['text':' SIMD dot product','line_number':2279,'multiline':False]
['text':' only to satisfy the compiler','line_number':2288,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2289,'multiline':False]
['text':' contiguous v/x values','line_number':2295,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2300,'multiline':False]
['text':' SIMD dot product','line_number':2309,'multiline':False]
['text':' sum of u','line_number':2310,'multiline':False]
['text':' multiply constant part of q4_K with sum of q8_1 values','line_number':2313,'multiline':False]
['text':' only to satisfy the compiler','line_number':2322,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2323,'multiline':False]
['text':' contiguous u/y values','line_number':2326,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2331,'multiline':False]
['text':' SIMD dot product','line_number':2341,'multiline':False]
['text':' sum of q8_1 block * q4_K min val','line_number':2347,'multiline':False]
['text':' only to satisfy the compiler','line_number':2356,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2357,'multiline':False]
['text':' contiguous v/x values','line_number':2363,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2368,'multiline':False]
['text':' SIMD dot product','line_number':2383,'multiline':False]
['text':' sum of u','line_number':2384,'multiline':False]
['text':' only to satisfy the compiler','line_number':2397,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2398,'multiline':False]
['text':' contiguous u/y values','line_number':2401,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2406,'multiline':False]
['text':' SIMD dot product','line_number':2416,'multiline':False]
['text':' sum of q8_1 block * q4_K min val','line_number':2422,'multiline':False]
['text':' only to satisfy the compiler','line_number':2431,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2432,'multiline':False]
['text':' contiguous v/x values','line_number':2438,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2443,'multiline':False]
['text':' vi = (vil | vih) - 32','line_number':2454,'multiline':False]
['text':' SIMD dot product','line_number':2456,'multiline':False]
['text':' only to satisfy the compiler','line_number':2462,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2463,'multiline':False]
['text':' contiguous u/y values','line_number':2466,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':2471,'multiline':False]
['text':' 2 q6_K scales per q8_1 scale','line_number':2476,'multiline':False]
['text':' SIMD dot product','line_number':2480,'multiline':False]
['text':' SIMD dot product','line_number':2481,'multiline':False]
['text':' SIMD dot product','line_number':2483,'multiline':False]
['text':' SIMD dot product','line_number':2484,'multiline':False]
['text':' only to satisfy the compiler','line_number':2494,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':2495,'multiline':False]
['text':' x_dmf[i * (WARP_SIZE/QI4_0) + i / QI4_0 + kbx] = bxi->d;','line_number':2553,'multiline':False]
['text':' 0 ->  4','line_number':2746,'multiline':False]
['text':' 1 -> 12','line_number':2747,'multiline':False]
['text':' 2 -> 20','line_number':2748,'multiline':False]
['text':' 3 -> 28','line_number':2749,'multiline':False]
['text':' subtract 16','line_number':2750,'multiline':False]
['text':' 16 ->  4','line_number':2755,'multiline':False]
['text':' 17 -> 12','line_number':2756,'multiline':False]
['text':' 18 -> 20','line_number':2757,'multiline':False]
['text':' 19 -> 28','line_number':2758,'multiline':False]
['text':' subtract 16','line_number':2759,'multiline':False]
['text':' 0 ->  4','line_number':2863,'multiline':False]
['text':' 1 -> 12','line_number':2864,'multiline':False]
['text':' 2 -> 20','line_number':2865,'multiline':False]
['text':' 3 -> 28','line_number':2866,'multiline':False]
['text':' 16 ->  4','line_number':2871,'multiline':False]
['text':' 17 -> 12','line_number':2872,'multiline':False]
['text':' 18 -> 20','line_number':2873,'multiline':False]
['text':' 19 -> 28','line_number':2874,'multiline':False]
['text':' invert the mask with ~ so that a 0/1 results in 4/0 being subtracted','line_number':3132,'multiline':False]
['text':' invert the mask with ~ so that a 0/1 results in 4/0 being subtracted','line_number':3214,'multiline':False]
['text':' iqs is in 0,2..30. bq8_offset = iqs/4 -> bq8_offset = 0, 2, 4, 6','line_number':3283,'multiline':False]
['text':' iqs = 0....3 -> bq8_offset = 0, want q4_offset = 0, 4, 8, 12','line_number':3286,'multiline':False]
['text':' iqs = 4....7 -> bq8_offset = 2, want q4_offset = 32, 36, 40, 44','line_number':3287,'multiline':False]
['text':' iqs = 8...11 -> bq8_offset = 4, want q4_offset = 64, 68, 72, 76','line_number':3288,'multiline':False]
['text':' iqs = 12..15 -> bq8_offset = 6, want q4_offset = 96, 100, 104, 108','line_number':3289,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':3321,'multiline':False]
['text':' only to satisfy the compiler','line_number':3361,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':3362,'multiline':False]
['text':' == 0 if QK_K == 256','line_number':3389,'multiline':False]
['text':' == k if QK_K == 256','line_number':3390,'multiline':False]
['text':' == 1 if QK_K == 256','line_number':3407,'multiline':False]
['text':' == 0 if QK_K == 256','line_number':3408,'multiline':False]
['text':' scale arrangement after the following two lines: sc0,...,sc3, sc4,...,sc7, m0,...,m3, m4,...,m8','line_number':3441,'multiline':False]
['text':' lower 4 bits','line_number':3442,'multiline':False]
['text':' upper 2 bits','line_number':3443,'multiline':False]
['text':' lowest compute capability for integer intrinsics','line_number':3509,'multiline':False]
['text':' 0, 4, 8, 12','line_number':3528,'multiline':False]
['text':' = 0 for iqs = 0, 2, = 1 for iqs = 4, 6','line_number':3529,'multiline':False]
['text':' 0, 4, 0, 4','line_number':3530,'multiline':False]
['text':' only to satisfy the compiler','line_number':3545,'multiline':False]
['text':' __CUDA_ARCH__ >= MIN_CC_DP4A','line_number':3546,'multiline':False]
['text':' == 0 if QK_K == 256','line_number':3573,'multiline':False]
['text':' == k if QK_K == 256','line_number':3574,'multiline':False]
['text':' == 1 if QK_K == 256','line_number':3604,'multiline':False]
['text':' == 0 if QK_K == 256','line_number':3605,'multiline':False]
['text':' scale arrangement after the following two lines: sc0,...,sc3, sc4,...,sc7, m0,...,m3, m4,...,m8','line_number':3636,'multiline':False]
['text':' lower 4 bits','line_number':3637,'multiline':False]
['text':' upper 2 bits','line_number':3638,'multiline':False]
['text':' == 0 if QK_K == 256','line_number':3705,'multiline':False]
['text':' == k if QK_K == 256','line_number':3706,'multiline':False]
['text':' == 1 if QK_K == 256','line_number':3736,'multiline':False]
['text':' == 0 if QK_K == 256','line_number':3737,'multiline':False]
['text':' to prevent out-of-bounds memory accesses','line_number':3827,'multiline':False]
['text':' if the sum is not needed it's faster to transform the scale to f32 ahead of time','line_number':3841,'multiline':False]
['text':' #pragma unroll // unrolling this loop causes too much register pressure','line_number':3854,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':3915,'multiline':False]
['text':' defined(GGML_USE_HIPBLAS) && defined(__HIP_PLATFORM_AMD__)','line_number':3916,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':3930,'multiline':False]
['text':' __CUDA_ARCH__ >= CC_VOLTA','line_number':3956,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':3982,'multiline':False]
['text':' __CUDA_ARCH__ < CC_VOLTA','line_number':3985,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':3999,'multiline':False]
['text':' __CUDA_ARCH__ >= CC_VOLTA','line_number':4025,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4051,'multiline':False]
['text':' defined(GGML_USE_HIPBLAS) && defined(__HIP_PLATFORM_AMD__)','line_number':4052,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4066,'multiline':False]
['text':' __CUDA_ARCH__ >= CC_VOLTA','line_number':4092,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4118,'multiline':False]
['text':' defined(GGML_USE_HIPBLAS) && defined(__HIP_PLATFORM_AMD__)','line_number':4119,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4133,'multiline':False]
['text':' __CUDA_ARCH__ >= CC_VOLTA','line_number':4159,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4185,'multiline':False]
['text':' defined(GGML_USE_HIPBLAS) && defined(__HIP_PLATFORM_AMD__)','line_number':4186,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4200,'multiline':False]
['text':' __CUDA_ARCH__ >= CC_VOLTA','line_number':4226,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4252,'multiline':False]
['text':' defined(GGML_USE_HIPBLAS) && defined(__HIP_PLATFORM_AMD__)','line_number':4253,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4267,'multiline':False]
['text':' __CUDA_ARCH__ >= CC_VOLTA','line_number':4293,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4319,'multiline':False]
['text':' __CUDA_ARCH__ < CC_VOLTA','line_number':4322,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4336,'multiline':False]
['text':' __CUDA_ARCH__ >= CC_VOLTA','line_number':4362,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4388,'multiline':False]
['text':' __CUDA_ARCH__ < CC_VOLTA','line_number':4391,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4405,'multiline':False]
['text':' __CUDA_ARCH__ >= CC_VOLTA','line_number':4431,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4457,'multiline':False]
['text':' defined(GGML_USE_HIPBLAS) && defined(__HIP_PLATFORM_AMD__)','line_number':4458,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4472,'multiline':False]
['text':' __CUDA_ARCH__ >= CC_VOLTA','line_number':4498,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4524,'multiline':False]
['text':' __CUDA_ARCH__ < CC_VOLTA','line_number':4527,'multiline':False]
['text':' defined(RDNA3) || defined(RDNA2)','line_number':4541,'multiline':False]
['text':' __CUDA_ARCH__ >= CC_VOLTA','line_number':4567,'multiline':False]
['text':' partial sum for each thread','line_number':4581,'multiline':False]
['text':' x block index','line_number':4588,'multiline':False]
['text':' y block index that aligns with ibx','line_number':4590,'multiline':False]
['text':' x block quant index when casting the quants to int','line_number':4592,'multiline':False]
['text':' sum up partial sums and write back result','line_number':4597,'multiline':False]
['text':' qk = quantized weights per x block','line_number':4610,'multiline':False]
['text':' qr = number of quantized weights per data value in x block','line_number':4611,'multiline':False]
['text':' num quantized vals per thread and i iter','line_number':4621,'multiline':False]
['text':' partial sum for each thread','line_number':4624,'multiline':False]
['text':' two sums for f16 to take advantage of half2 intrinsics','line_number':4626,'multiline':False]
['text':' GGML_CUDA_F16','line_number':4629,'multiline':False]
['text':' x block index','line_number':4633,'multiline':False]
['text':' x quant index','line_number':4634,'multiline':False]
['text':' y block start index','line_number':4635,'multiline':False]
['text':' processing >2 values per i iter is faster for fast GPUs','line_number':4637,'multiline':False]
['text':' process 2 vals per j iter','line_number':4640,'multiline':False]
['text':' dequantize','line_number':4642,'multiline':False]
['text':' for qr = 2 the iqs needs to increase by 1 per j iter because 2 weights per data val','line_number':4643,'multiline':False]
['text':' matrix multiplication','line_number':4647,'multiline':False]
['text':' for qr = 2 the y index needs to increase by 1 per j iter because of y_offset = qk/2','line_number':4648,'multiline':False]
['text':' GGML_CUDA_F16','line_number':4657,'multiline':False]
['text':' sum up partial sums and write back result','line_number':4661,'multiline':False]
['text':' GGML_CUDA_F16','line_number':4672,'multiline':False]
['text':' x is transposed and permuted','line_number':4699,'multiline':False]
['text':' y is not transposed but permuted','line_number':4706,'multiline':False]
['text':' dst is not transposed and not permuted','line_number':4712,'multiline':False]
['text':' sum up partial sums and write back result','line_number':4715,'multiline':False]
['text':' nc == non-contiguous','line_number':4726,'multiline':False]
['text':' sum up partial sums and write back result','line_number':4761,'multiline':False]
['text':' determine indices i02/i12, i01/i11, i00/i10 as a function of index i of flattened tensor','line_number':4803,'multiline':False]
['text':' then combine those indices with the corresponding byte offsets to get the total offsets','line_number':4804,'multiline':False]
['text':' absolute max','line_number':4822,'multiline':False]
['text':' YaRN algorithm based on LlamaYaRNScaledRotaryEmbedding.py from https://github.com/jquesnelle/yarn','line_number':4937,'multiline':False]
['text':' MIT licensed. Copyright (c) 2023 Jeffrey Quesnelle and Bowen Peng.','line_number':4938,'multiline':False]
['text':' Get n-d rotational scaling corrected for extrapolation','line_number':4943,'multiline':False]
['text':' Get n-d magnitude scaling corrected for interpolation','line_number':4950,'multiline':False]
['text':' rope == RoPE == rotary positional embedding','line_number':4957,'multiline':False]
['text':' FIXME: this is likely wrong','line_number':5035,'multiline':False]
['text':' bitonic sort','line_number':5107,'multiline':False]
['text':' initialize indices','line_number':5116,'multiline':False]
['text':'dst[i] = col > (n_past + row % rows_per_channel) ? -INFINITY : x[i];','line_number':5150,'multiline':False]
['text':'dst[i] = x[i] - (col > n_past + row % rows_per_channel) * INT_MAX; // equivalent within rounding error but slightly faster on GPU','line_number':5151,'multiline':False]
['text':' broadcast the mask (y) in the row dimension','line_number':5158,'multiline':False]
['text':' find the max value in the block','line_number':5175,'multiline':False]
['text':' find the sum of exps in the block','line_number':5202,'multiline':False]
['text':' strides in elements','line_number':5287,'multiline':False]
['text':'const size_t s0 = nb0 / ggml_element_size(dst);','line_number':5288,'multiline':False]
['text':'const size_t s13 = nb13 / ggml_element_size(src1);','line_number':5296,'multiline':False]
['text':'ne01, ne02, ne03,','line_number':5302,'multiline':True]
['text':'ne10, ne11,','line_number':5303,'multiline':True]
['text':'ne13,','line_number':5303,'multiline':True]
['text':' s0,','line_number':5304,'multiline':True]
['text':' nb00,','line_number':5305,'multiline':True]
['text':', s13','line_number':5306,'multiline':True]
['text':' strides in elements','line_number':5321,'multiline':False]
['text':'const size_t s0 = nb0 / ggml_element_size(dst);','line_number':5322,'multiline':False]
['text':'const size_t s13 = nb13 / ggml_element_size(src1);','line_number':5330,'multiline':False]
['text':'ne01, ne02, ne03,','line_number':5334,'multiline':True]
['text':'ne10, ne11,','line_number':5335,'multiline':True]
['text':'ne13,','line_number':5335,'multiline':True]
['text':' s0,','line_number':5336,'multiline':True]
['text':' nb00,','line_number':5337,'multiline':True]
['text':', s13','line_number':5338,'multiline':True]
['text':' collapse dimensions until first broadcast dimension','line_number':5359,'multiline':False]
['text':' this is the maximum number of blocks in z direction, fallback to 1D grid kernel','line_number':5438,'multiline':False]
['text':' s0, ','line_number':5444,'multiline':True]
['text':' s10, ','line_number':5445,'multiline':True]
['text':' s0, ','line_number':5451,'multiline':True]
['text':' s10, ','line_number':5452,'multiline':True]
['text':' the number of rows may exceed maximum grid size in the y or z dimensions, use the x dimension instead','line_number':5674,'multiline':False]
['text':' very slightly faster than 1 even when K_QUANTS_PER_ITERATION = 2','line_number':5719,'multiline':False]
['text':' bitonic sort requires ncols to be power of 2','line_number':6476,'multiline':False]
['text':' buffer pool for cuda','line_number':6515,'multiline':False]
['text':' spin','line_number':6522,'multiline':False]
['text':' Workaround for a rocBLAS bug when using multiple graphics cards:','line_number':6623,'multiline':False]
['text':' https://github.com/ROCmSoftwarePlatform/rocBLAS/issues/1346','line_number':6624,'multiline':False]
['text':' defined(GGML_USE_HIPBLAS) && defined(__HIP_PLATFORM_AMD__)','line_number':6659,'multiline':False]
['text':' create cuda streams','line_number':6668,'multiline':False]
['text':' create cublas handle','line_number':6673,'multiline':False]
['text':' configure logging to stdout','line_number':6678,'multiline':False]
['text':' CUBLAS_CHECK(cublasLoggerConfigure(1, 1, 0, nullptr));','line_number':6679,'multiline':False]
['text':' The allocation error can be bypassed. A null ptr will assigned out of this function.','line_number':6718,'multiline':False]
['text':' This can fixed the OOM error in WSL.','line_number':6719,'multiline':False]
['text':' pretend the row is a matrix with cols=1','line_number':6772,'multiline':False]
['text':' TODO: k-quants','line_number':6816,'multiline':False]
['text':' just 3D tensors supported','line_number':6866,'multiline':False]
['text':' 4 bytes of float32','line_number':6868,'multiline':False]
['text':' 4 bytes of float32','line_number':6869,'multiline':False]
['text':' int nb3 = dst->op_params[2] / 4; // 4 bytes of float32 - unused','line_number':6870,'multiline':False]
['text':' offset in bytes','line_number':6871,'multiline':False]
['text':' just 3D tensors','line_number':7052,'multiline':False]
['text':' just 3D tensors','line_number':7068,'multiline':False]
['text':' the main device has a larger memory buffer to hold the results from all GPUs','line_number':7115,'multiline':False]
['text':' nrows_dst == nrows of the matrix that the dequantize_mul_mat kernel writes into','line_number':7116,'multiline':False]
['text':' defined(GGML_USE_HIPBLAS) && defined(__HIP_PLATFORM_AMD__)','line_number':7218,'multiline':False]
['text':' on some GPUs it is faster to convert src1 to half and to use half precision intrinsics','line_number':7282,'multiline':False]
['text':' dfloat == half','line_number':7285,'multiline':False]
['text':' dfloat == float, no conversion','line_number':7299,'multiline':False]
['text':' GGML_CUDA_F16','line_number':7300,'multiline':False]
['text':' GGML_CUDA_F16','line_number':7345,'multiline':False]
['text':' the main device has a larger memory buffer to hold the results from all GPUs','line_number':7373,'multiline':False]
['text':' ldc == nrows of the matrix that cuBLAS writes into','line_number':7374,'multiline':False]
['text':' convert src0 and src1 to fp16, multiply as fp16, convert dst to fp32','line_number':7380,'multiline':False]
['text':' NOLINT','line_number':7438,'multiline':False]
['text':'const int n_past      = ((int32_t *) dst->op_params)[0];','line_number':7477,'multiline':False]
['text':' RoPE alteration for extended context','line_number':7483,'multiline':False]
['text':' compute','line_number':7505,'multiline':False]
['text':'const int n_past = ((int32_t *) dst->op_params)[0];','line_number':7556,'multiline':False]
['text':'GGML_ASSERT(ne01 + n_past == ne00);','line_number':7561,'multiline':False]
['text':' nb is byte offset, src is type float32','line_number':7602,'multiline':False]
['text':' src1 contains mask and it is optional','line_number':7674,'multiline':False]
['text':' HACK: support for ggml backend interface','line_number':7697,'multiline':False]
['text':' TODO: pass pointer to kernel instead of copying to host','line_number':7701,'multiline':False]
['text':' dd = data device','line_number':7752,'multiline':False]
['text':' as = actual size','line_number':7757,'multiline':False]
['text':' do the computation','line_number':7786,'multiline':False]
['text':' copy dst to host if necessary','line_number':7790,'multiline':False]
['text':' NDEBUG','line_number':7842,'multiline':False]
['text':' dd = data device','line_number':7900,'multiline':False]
['text':' float','line_number':7902,'multiline':False]
['text':' q8_1','line_number':7903,'multiline':False]
['text':' as = actual size','line_number':7906,'multiline':False]
['text':' by default, use all rows','line_number':7918,'multiline':False]
['text':' for multi GPU, get the row boundaries from tensor split','line_number':7922,'multiline':False]
['text':' and round to mul_mat_q tile sizes','line_number':7923,'multiline':False]
['text':' const size_t size_src0_ddq = split ? (row_high[id]-row_low[id])*ne00 * src0_ts/src0_bs : ggml_nbytes(src0);','line_number':7955,'multiline':False]
['text':' if multiple devices are used they need to wait for the main device','line_number':7982,'multiline':False]
['text':' here an event is recorded that signals that the main device has finished calculating the input data','line_number':7983,'multiline':False]
['text':' wait for main GPU data if necessary','line_number':8006,'multiline':False]
['text':' for split tensors the data begins at i0 == i0_offset_low','line_number':8017,'multiline':False]
['text':' the main device memory buffer can be on VRAM scratch, with space for all partial results','line_number':8023,'multiline':False]
['text':' in that case an offset on dst_ddf_i is needed','line_number':8024,'multiline':False]
['text':' offset is 0 if no tensor split','line_number':8026,'multiline':False]
['text':' copy src0, src1 to device if necessary','line_number':8029,'multiline':False]
['text':' do the computation','line_number':8059,'multiline':False]
['text':' copy dst to host or other device if necessary','line_number':8064,'multiline':False]
['text':' src0 = weight matrix is saved as a transposed matrix for better memory layout.','line_number':8078,'multiline':False]
['text':' dst is NOT transposed.','line_number':8079,'multiline':False]
['text':' The outputs of matrix matrix multiplications can therefore NOT simply be concatenated for >1 GPU.','line_number':8080,'multiline':False]
['text':' Instead they need to be copied to the correct slice in ne0 = dst row index.','line_number':8081,'multiline':False]
['text':' If dst is a vector with ne0 == 1 then you don't have to do this but it still produces correct results.','line_number':8082,'multiline':False]
['text':' add event for the main device to wait on until other device is done','line_number':8096,'multiline':False]
['text':' free buffers again when done','line_number':8110,'multiline':False]
['text':' main device waits for all other devices to be finished','line_number':8125,'multiline':False]
['text':' TODO: find the optimal values for these','line_number':8231,'multiline':False]
['text':' 0213 permutation','line_number':8241,'multiline':False]
['text':' 0213 permutation','line_number':8242,'multiline':False]
['text':' convert src1 to fp16','line_number':8370,'multiline':False]
['text':' broadcast factors','line_number':8384,'multiline':False]
['text':' use cublasGemmEx','line_number':8392,'multiline':False]
['text':' there is no broadcast and src0, src1 are contiguous across dims 2, 3','line_number':8412,'multiline':False]
['text':' use cublasGemmStridedBatchedEx','line_number':8413,'multiline':False]
['text':' strideA','line_number':8417,'multiline':False]
['text':' strideB','line_number':8418,'multiline':False]
['text':' strideC','line_number':8419,'multiline':False]
['text':' use cublasGemmBatchedEx','line_number':8424,'multiline':False]
['text':' debug helpers','line_number':8495,'multiline':False]
['text':'printf("src0: %8d %8d %8d %8d\n", src0->ne[0], src0->ne[1], src0->ne[2], src0->ne[3]);','line_number':8496,'multiline':False]
['text':'printf("      %8d %8d %8d %8d\n", src0->nb[0], src0->nb[1], src0->nb[2], src0->nb[3]);','line_number':8497,'multiline':False]
['text':'printf("src1: %8d %8d %8d %8d\n", src1->ne[0], src1->ne[1], src1->ne[2], src1->ne[3]);','line_number':8498,'multiline':False]
['text':'printf("      %8d %8d %8d %8d\n", src1->nb[0], src1->nb[1], src1->nb[2], src1->nb[3]);','line_number':8499,'multiline':False]
['text':'printf("src0 is contiguous %d, transposed %d, type = %s, name = %s\n", ggml_is_contiguous(src0), ggml_is_transposed(src0), ggml_type_name(src0->type), src0->name);','line_number':8500,'multiline':False]
['text':'printf("src1 is contiguous %d, transposed %d, type = %s, name = %s\n", ggml_is_contiguous(src1), ggml_is_transposed(src1), ggml_type_name(src1->type), src1->name);','line_number':8501,'multiline':False]
['text':' KQ single-batch','line_number':8504,'multiline':False]
['text':' KQV single-batch','line_number':8507,'multiline':False]
['text':' KQ + KQV multi-batch','line_number':8510,'multiline':False]
['text':' GGML_CUDA_FORCE_DMMV','line_number':8520,'multiline':False]
['text':' NOTE: this kernel does not support ggml_nrows(src1) > 1','line_number':8523,'multiline':False]
['text':' when tensor cores are available, use them for large batch size','line_number':8531,'multiline':False]
['text':' ref: https://github.com/ggerganov/llama.cpp/pull/3776','line_number':8532,'multiline':False]
['text':'const int64_t nb01 = src00->nb[1];','line_number':8610,'multiline':False]
['text':'const int64_t nb11 = src1->nb[1];','line_number':8619,'multiline':False]
['text':'ggml_tensor_extra_gpu * src0_extra = (ggml_tensor_extra_gpu *) src0->extra;','line_number':8631,'multiline':False]
['text':'void * src0_ddq = src0_extra->data_device[g_main_device];','line_number':8632,'multiline':False]
['text':'half * src0_as_f16 = (half *) src0_ddq;','line_number':8633,'multiline':False]
['text':' convert src1 to fp16','line_number':8641,'multiline':False]
['text':' broadcast factors','line_number':8655,'multiline':False]
['text':' use cublasGemmBatchedEx','line_number':8662,'multiline':False]
['text':' TODO: mmq/mmv support','line_number':8732,'multiline':False]
['text':'int32_t row_id;','line_number':8774,'multiline':False]
['text':'CUDA_CHECK(cudaMemcpyAsync(&row_id, ids_dev + i01*ids->nb[1] + id*ids->nb[0], sizeof(int32_t), cudaMemcpyDeviceToHost, g_cudaStreams[g_main_device][0]));','line_number':8775,'multiline':False]
['text':'CUDA_CHECK(cudaStreamSynchronize(g_cudaStreams[g_main_device][0]));','line_number':8776,'multiline':False]
['text':' TODO: why do we pass dst as src1 here?','line_number':8859,'multiline':False]
['text':' TODO: this restriction is temporary until non-cont support is implemented','line_number':8873,'multiline':False]
['text':' pad last row to a multiple of 512 elements to avoid out-of-bounds memory accesses','line_number':8948,'multiline':False]
['text':' set padding to 0 to avoid possible NaN values','line_number':8958,'multiline':False]
['text':' recursively assign CUDA buffers until a compute tensor is found','line_number':9024,'multiline':False]
['text':' allocate new buffers outside of scratch','line_number':9078,'multiline':False]
['text':' this is a hack to not completely break llama.cpp when using multiple models or contexts simultaneously','line_number':9160,'multiline':False]
['text':' it still won't always work as expected, but it's better than nothing','line_number':9161,'multiline':False]
['text':'//////////////////////////////////////////////////////////////////////////////','line_number':9345,'multiline':False]
['text':' backend interface','line_number':9347,'multiline':False]
['text':' cuda buffer','line_number':9351,'multiline':False]
['text':' TODO','line_number':9394,'multiline':False]
['text':' initialize padding to 0 to avoid possible NaN values','line_number':9408,'multiline':False]
['text':' .free_buffer     = ','line_number':9445,'multiline':True]
['text':' .get_base        = ','line_number':9446,'multiline':True]
['text':' .init_tensor     = ','line_number':9447,'multiline':True]
['text':' .set_tensor      = ','line_number':9448,'multiline':True]
['text':' .get_tensor      = ','line_number':9449,'multiline':True]
['text':' .cpy_tensor_from = ','line_number':9450,'multiline':True]
['text':' .cpy_tensor_to   = ','line_number':9451,'multiline':True]
['text':' cuda buffer type','line_number':9454,'multiline':False]
['text':' cudaMalloc returns null for size 0','line_number':9461,'multiline':False]
['text':' .alloc_buffer     = ','line_number':9505,'multiline':True]
['text':' .get_alignment    = ','line_number':9506,'multiline':True]
['text':' .get_alloc_size   = ','line_number':9507,'multiline':True]
['text':' .supports_backend = ','line_number':9508,'multiline':True]
['text':' .iface    = ','line_number':9517,'multiline':True]
['text':' .context  = ','line_number':9518,'multiline':True]
['text':' host buffer type','line_number':9527,'multiline':False]
['text':' FIXME: this is a hack to avoid having to implement a new buffer type','line_number':9539,'multiline':False]
['text':' .alloc_buffer     = ','line_number':9550,'multiline':True]
['text':' .get_alignment    = ','line_number':9551,'multiline':True]
['text':' .get_alloc_size   = ','line_number':9552,'multiline':True]
['text':' .supports_backend = ','line_number':9553,'multiline':True]
['text':' .iface    = ','line_number':9558,'multiline':True]
['text':' .context  = ','line_number':9559,'multiline':True]
['text':' backend','line_number':9565,'multiline':False]
['text':' .get_name                = ','line_number':9810,'multiline':True]
['text':' .free                    = ','line_number':9811,'multiline':True]
['text':' .get_default_buffer_type = ','line_number':9812,'multiline':True]
['text':' .set_tensor_async        = ','line_number':9813,'multiline':True]
['text':' .get_tensor_async        = ','line_number':9814,'multiline':True]
['text':' .cpy_tensor_from_async   = ','line_number':9815,'multiline':True]
['text':' .cpy_tensor_to_async     = ','line_number':9816,'multiline':True]
['text':' .synchronize             = ','line_number':9817,'multiline':True]
['text':' .graph_plan_create       = ','line_number':9818,'multiline':True]
['text':' .graph_plan_free         = ','line_number':9819,'multiline':True]
['text':' .graph_plan_compute      = ','line_number':9820,'multiline':True]
['text':' .graph_compute           = ','line_number':9821,'multiline':True]
['text':' .supports_op             = ','line_number':9822,'multiline':True]
['text':' TODO: remove from ggml.c','line_number':9826,'multiline':False]
['text':' not strictly necessary, but it may reduce the overhead of the first graph_compute','line_number':9833,'multiline':False]
['text':' .device = ','line_number':9837,'multiline':True]
['text':' .interface = ','line_number':9841,'multiline':True]
['text':' .context   = ','line_number':9842,'multiline':True]
['text':'int device_count = 1; // DEBUG: some tools require delaying CUDA initialization','line_number':9863,'multiline':False]
