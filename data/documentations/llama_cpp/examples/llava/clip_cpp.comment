['text':' NOTE: This is modified from clip.cpp only for LLaVA,','line_number':1,'multiline':False]
['text':' so there might be still unnecessary artifacts hanging around','line_number':2,'multiline':False]
['text':' I'll gradually clean and extend it','line_number':3,'multiline':False]
['text':' NOLINT','line_number':31,'multiline':False]
['text':'','line_number':40,'multiline':False]
['text':' key constants','line_number':41,'multiline':False]
['text':'','line_number':42,'multiline':False]
['text':'','line_number':64,'multiline':False]
['text':' tensor name constants','line_number':65,'multiline':False]
['text':'','line_number':66,'multiline':False]
['text':'','line_number':86,'multiline':False]
['text':' utilities to get data from a gguf file','line_number':87,'multiline':False]
['text':'','line_number':88,'multiline':False]
['text':'','line_number':142,'multiline':False]
['text':' clip layers','line_number':143,'multiline':False]
['text':'','line_number':144,'multiline':False]
['text':' attention','line_number':147,'multiline':False]
['text':' layernorm 1','line_number':158,'multiline':False]
['text':' ff','line_number':162,'multiline':False]
['text':' layernorm 2','line_number':169,'multiline':False]
['text':' embeddings','line_number':177,'multiline':False]
['text':' LLaVA projection','line_number':192,'multiline':False]
['text':' Replacement for std::vector<uint8_t> that doesn't require zero-initialization.','line_number':199,'multiline':False]
['text':' memory buffers to evaluate the model','line_number':225,'multiline':False]
['text':'const int n_intermediate = hparams.n_intermediate;','line_number':248,'multiline':False]
['text':'const int projection_dim = hparams.projection_dim;','line_number':249,'multiline':False]
['text':'.mem_size =','line_number':259,'multiline':True]
['text':'.mem_buffer =','line_number':260,'multiline':True]
['text':'.no_alloc =','line_number':261,'multiline':True]
['text':' concat class_embeddings and patch_embeddings','line_number':299,'multiline':False]
['text':' pre-layernorm','line_number':325,'multiline':False]
['text':' loop over layers','line_number':339,'multiline':False]
['text':' embeddings = residual, cur = hidden_states','line_number':341,'multiline':False]
['text':'const size_t nb_q_w = model.layers[il].q_w->nb[0];','line_number':343,'multiline':False]
['text':' layernorm1','line_number':345,'multiline':False]
['text':' self-attention','line_number':353,'multiline':False]
['text':' attention output','line_number':387,'multiline':False]
['text':' re-add the layer input, e.g., residual','line_number':390,'multiline':False]
['text':' embeddings = residual, cur = hidden_states','line_number':393,'multiline':False]
['text':' layernorm2','line_number':395,'multiline':False]
['text':' residual 2','line_number':415,'multiline':False]
['text':' llava projector','line_number':421,'multiline':False]
['text':' mm projection 0','line_number':435,'multiline':False]
['text':' build the graph','line_number':445,'multiline':False]
['text':' read and create ggml_context containing the tensors and their data','line_number':453,'multiline':False]
['text':'.no_alloc = ','line_number':459,'multiline':True]
['text':'.ctx      = ','line_number':460,'multiline':True]
['text':' make name optional temporarily as some of the uploaded models missing it due to a bug','line_number':476,'multiline':False]
['text':' kv','line_number':489,'multiline':False]
['text':' data','line_number':501,'multiline':False]
['text':' model size and capabilities','line_number':524,'multiline':False]
['text':' see monatis/clip.cpp for image and/or text encoding for semantic search','line_number':537,'multiline':False]
['text':' load tensors','line_number':553,'multiline':False]
['text':'.mem_size =','line_number':556,'multiline':True]
['text':'.mem_buffer =','line_number':557,'multiline':True]
['text':'.no_alloc =','line_number':558,'multiline':True]
['text':' vision model','line_number':596,'multiline':False]
['text':' load vision model','line_number':598,'multiline':False]
['text':' measure mem requirement and allocate','line_number':664,'multiline':False]
['text':' normalize: x = (x - mean) / std','line_number':724,'multiline':False]
['text':' TODO: implement bicubic interpolation instead of linear.','line_number':725,'multiline':False]
['text':' the logic below is to pad the shorter side to the longer side with a background color: rgb(122, 116, 104)','line_number':732,'multiline':False]
['text':' see https://github.com/haotian-liu/LLaVA/blob/e854a2bf85118c504f6f16bf5c3c7c92f8fa8c6b/llava/conversation.py#L113-L156','line_number':733,'multiline':False]
['text':' we will keep the input image data here temporarily','line_number':735,'multiline':False]
['text':' background color in RGB from LLaVA','line_number':742,'multiline':False]
['text':' fill with background color','line_number':744,'multiline':False]
['text':' copy from the input image','line_number':749,'multiline':False]
['text':' copy','line_number':764,'multiline':False]
['text':' {0.48145466f, 0.4578275f, 0.40821073f};','line_number':783,'multiline':False]
['text':' {0.26862954f, 0.26130258f, 0.27577711f};','line_number':784,'multiline':False]
['text':' linear interpolation','line_number':789,'multiline':False]
['text':' TODO: support multiple images','line_number':857,'multiline':False]
['text':' reset alloc buffer to clean the memory from previous invocations','line_number':860,'multiline':False]
['text':' build the inference graph','line_number':863,'multiline':False]
['text':' the last node is the embedding tensor','line_number':874,'multiline':False]
['text':' copy the embeddings to the location passed by the user','line_number':877,'multiline':False]
['text':' regexes of tensor names to be quantized','line_number':936,'multiline':False]
['text':' quantize only 2D tensors','line_number':964,'multiline':False]
['text':' go back to beginning of file and write the updated metadata','line_number':1042,'multiline':False]
