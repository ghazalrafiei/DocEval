['text':'*
 * Extends sharded_base_partitioned.js.
 *
 * Exercises the concurrent moveChunk operations, with each thread operating on its own set of
 * chunks.
 *
 * @tags: [
 *  requires_sharding,
 *  assumes_balancer_off,
 * ]
 ','line_number':1,'multiline':True]
['text':' number of shard key values','line_number':23,'multiline':False]
['text':' Create at least as many additional split points in this thread's partition as there','line_number':25,'multiline':False]
['text':' will be iterations (to accommodate as many mergeChunks operations in this thread's','line_number':26,'multiline':False]
['text':' partition as iterations).','line_number':27,'multiline':False]
['text':'','line_number':28,'multiline':False]
['text':' This is done in setup rather than in a mergeChunk-specific init state after the','line_number':29,'multiline':False]
['text':' sharded_base_partitioned.js init state because the states are multi-threaded:','line_number':30,'multiline':False]
['text':' since the mergeChunks operation used to create the chunks within each partition is not','line_number':31,'multiline':False]
['text':' guaranteed to succeed (it can fail if another concurrent chunk operation is in progress),','line_number':32,'multiline':False]
['text':' it is much more complicated to do this setup step in a multi-threaded context.','line_number':33,'multiline':False]
['text':' Add as many additional split points as iterations.','line_number':36,'multiline':False]
['text':' Define the inner chunk size as the max size of the range of shard key','line_number':37,'multiline':False]
['text':' values in each inner chunk within the thread partition as the largest','line_number':38,'multiline':False]
['text':' whole number that allows for as many inner chunks as iterations without','line_number':39,'multiline':False]
['text':' exceeding partitionSize.','line_number':40,'multiline':False]
['text':'','line_number':41,'multiline':False]
['text':' Diagram for partitionSize = 5, iterations = 4 ==> innerChunkSize = 1:','line_number':42,'multiline':False]
['text':' [----------] ==> [-|-|-|-|-]','line_number':43,'multiline':False]
['text':' 0          5     0 1 2 3 4 5','line_number':44,'multiline':False]
['text':'','line_number':45,'multiline':False]
['text':' Diagram for partitionSize = 5, iterations = 2 ==> innerChunkSize = 2:','line_number':46,'multiline':False]
['text':' [----------] ==> [-|--|--]','line_number':47,'multiline':False]
['text':' 0          5     0 1  3  5','line_number':48,'multiline':False]
['text':'','line_number':49,'multiline':False]
['text':' Diagram for partitionSize = 5, iterations = 1 ==> innerChunkSize = 5:','line_number':50,'multiline':False]
['text':' [----------] ==> [-|----]','line_number':51,'multiline':False]
['text':' 0          5     0 1    5','line_number':52,'multiline':False]
['text':' Override sharded_base_partitioned's init state to prevent the default check','line_number':60,'multiline':False]
['text':' that only 1 chunk is in our partition and to instead check that there are','line_number':61,'multiline':False]
['text':' at least as many chunks in our partition as iterations.','line_number':62,'multiline':False]
['text':' Inform this thread about its partition.','line_number':64,'multiline':False]
['text':' Each thread has tid in range 0..(n-1) where n is the number of threads.','line_number':65,'multiline':False]
['text':' Verify that there is at least one chunk in our partition and that','line_number':77,'multiline':False]
['text':' there are at least as many chunks in our partition as iterations.','line_number':78,'multiline':False]
['text':' Merge a random chunk in this thread's partition with its upper neighbor.','line_number':87,'multiline':False]
['text':' Skip this iteration if our data partition contains less than 2 chunks.','line_number':95,'multiline':False]
['text':' Grab a chunk and its upper neighbor.','line_number':105,'multiline':False]
['text':' If we randomly chose the last chunk, choose the one before it.','line_number':107,'multiline':False]
['text':' Save the number of documents found in these two chunks' ranges before the mergeChunks','line_number':113,'multiline':False]
['text':' operation. This will be used to verify that the same number of documents in that','line_number':114,'multiline':False]
['text':' range are still found after the mergeChunks.','line_number':115,'multiline':False]
['text':' Choose the mongos randomly to distribute load.','line_number':116,'multiline':False]
['text':' If the second chunk is not on the same shard as the first, move it,','line_number':120,'multiline':False]
['text':' because mergeChunks requires the chunks being merged to be on the same shard.','line_number':121,'multiline':False]
['text':' Verify that no docs were lost in the moveChunk.','line_number':126,'multiline':False]
['text':' Save the number of chunks before the mergeChunks operation. This will be used','line_number':133,'multiline':False]
['text':' to verify that the number of chunks after a successful mergeChunks decreases','line_number':134,'multiline':False]
['text':' by one, or after a failed mergeChunks stays the same.','line_number':135,'multiline':False]
['text':' Use chunk_helper.js's mergeChunks wrapper to tolerate acceptable failures','line_number':139,'multiline':False]
['text':' and to use a limited number of retries with exponential backoff.','line_number':140,'multiline':False]
['text':' Regardless of whether the mergeChunks operation succeeded or failed,','line_number':152,'multiline':False]
['text':' verify that the shard chunk1 was on returns all data for the chunk.','line_number':153,'multiline':False]
['text':' Verify that all config servers have the correct after-state.','line_number':160,'multiline':False]
['text':' (see comments below for specifics).','line_number':161,'multiline':False]
['text':' If the mergeChunks operation succeeded, verify that there is now one chunk','line_number':166,'multiline':False]
['text':' between the original chunks' lower and upper bounds. If the operation failed,','line_number':167,'multiline':False]
['text':' verify that there are still two chunks between the original chunks' lower and','line_number':168,'multiline':False]
['text':' upper bounds.','line_number':169,'multiline':False]
['text':' If the mergeChunks operation succeeded, verify that the total number','line_number':182,'multiline':False]
['text':' of chunks in our partition has decreased by 1. If it failed, verify','line_number':183,'multiline':False]
['text':' that it has stayed the same.','line_number':184,'multiline':False]
['text':' Verify that all mongos processes see the correct after-state on the shards and configs.','line_number':199,'multiline':False]
['text':' (see comments below for specifics).','line_number':200,'multiline':False]
['text':' Regardless of if the mergeChunks operation succeeded or failed, verify that each','line_number':202,'multiline':False]
['text':' mongos sees as many documents in the original chunks' range after the move as there','line_number':203,'multiline':False]
['text':' were before.','line_number':204,'multiline':False]
['text':' Regardless of if the mergeChunks operation succeeded or failed, verify that each','line_number':210,'multiline':False]
['text':' mongos sees all data in the original chunks' range only on the shard the original','line_number':211,'multiline':False]
['text':' chunk was on.','line_number':212,'multiline':False]
['text':' If the mergeChunks operation succeeded, verify that the mongos sees one chunk between','line_number':224,'multiline':False]
['text':' the original chunks' lower and upper bounds. If the operation failed, verify that the','line_number':225,'multiline':False]
['text':' mongos still sees two chunks between the original chunks' lower and upper bounds.','line_number':226,'multiline':False]
['text':' If the mergeChunks operation succeeded, verify that the mongos sees that the total','line_number':239,'multiline':False]
['text':' number of chunks in our partition has decreased by 1. If it failed, verify that it','line_number':240,'multiline':False]
['text':' has stayed the same.','line_number':241,'multiline':False]
