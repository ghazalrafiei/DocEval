['text':'
 * Tests the following scenarios where the featureCompatibilityVersion document is rolled back and
 * verify that the in-memory and on-disk FCV stay consistent.
 * - the FCV document is rolled back from fully upgraded to upgrading
 * - the FCV document is rolled back from upgrading to fully downgraded
 * - the FCV document is rolled back from fully downgraded to downgrading
 * - the FCV document is rolled back from downgrading to fully upgraded
 *
 *  @tags: [multiversion_incompatible]
 ','line_number':1,'multiline':True]
['text':' Using getParameter results in waiting for the current FCV to be majority committed.  In this','line_number':22,'multiline':False]
['text':' test, it never will, so we need to get the FCV directly.','line_number':23,'multiline':False]
['text':' We need to use a new connection here because we run an internalClient command, which','line_number':29,'multiline':False]
['text':' will make the connection be marked as internal and leads to following commands fail.','line_number':30,'multiline':False]
['text':' fromFCV refers to the FCV we will test rolling back from.','line_number':38,'multiline':False]
['text':' toFCV refers to the FCV we will test rolling back to.','line_number':39,'multiline':False]
['text':' Ensure the cluster starts at the correct FCV.','line_number':46,'multiline':False]
['text':' Wait until the config has propagated to the other nodes and the primary has learned of it, so','line_number':49,'multiline':False]
['text':' that the config replication check in 'setFeatureCompatibilityVersion' is satisfied. This is','line_number':50,'multiline':False]
['text':' only important since 'setFeatureCompatibilityVersion' is known to implicitly call internal','line_number':51,'multiline':False]
['text':' reconfigs as part of upgrade/downgrade behavior.','line_number':52,'multiline':False]
['text':' Wait for the majority commit point to be updated on the secondary, because checkFCV calls','line_number':54,'multiline':False]
['text':' getParameter for the featureCompatibilityVersion, which will wait until the FCV change makes','line_number':55,'multiline':False]
['text':' it into the node's majority committed snapshot.','line_number':56,'multiline':False]
['text':' timeout ','line_number':57,'multiline':True]
['text':' Wait for the FCV update to be reflected on the primary. This should eventually be rolled','line_number':64,'multiline':False]
['text':' back.','line_number':65,'multiline':False]
['text':' Secondaries should never have received the FCV update.','line_number':71,'multiline':False]
['text':' There should be 3 topology version changes without FCV change when we transition to','line_number':79,'multiline':False]
['text':' kSyncSourceOpsDuringRollback and kSteadyStateOps, including reconnect node, transition from','line_number':80,'multiline':False]
['text':' primary to rollback and transition from rollback to secondary. If the FCV change also','line_number':81,'multiline':False]
['text':' triggers a topology version change, then the topology version gap between before and after','line_number':82,'multiline':False]
['text':' rollback should be 4.','line_number':83,'multiline':False]
['text':' The primary should have rolled back their FCV to be consistent with the rest of the replica','line_number':87,'multiline':False]
['text':' set.','line_number':88,'multiline':False]
['text':' As a rule, we forbid downgrading a node while a node is still in the upgrading state and','line_number':93,'multiline':False]
['text':' vice versa. Ensure that the in-memory and on-disk FCV are consistent by checking that we are','line_number':94,'multiline':False]
['text':' able to set the FCV back to the original version.','line_number':95,'multiline':False]
['text':' fromFCV refers to the FCV we will test rolling back from.','line_number':100,'multiline':False]
['text':' toFCV refers to the FCV we will test rolling back to.','line_number':101,'multiline':False]
['text':' Complete the upgrade/downgrade to ensure we are not in the upgrading/downgrading state.','line_number':108,'multiline':False]
['text':' Wait for the majority commit point to be updated on the secondary, because checkFCV calls','line_number':111,'multiline':False]
['text':' getParameter for the featureCompatibilityVersion, which will wait until the FCV change makes','line_number':112,'multiline':False]
['text':' it into the node's majority committed snapshot.','line_number':113,'multiline':False]
['text':' timeout ','line_number':114,'multiline':True]
['text':' A failpoint to hang right before unsetting the targetVersion.','line_number':119,'multiline':False]
['text':' Turn off the failpoint so the primary will proceed to unset the targetVersion. This update','line_number':124,'multiline':False]
['text':' should never make it to the secondary.','line_number':125,'multiline':False]
['text':' The secondary should never have received the update to unset the targetVersion.','line_number':133,'multiline':False]
['text':' When downgrading, the secondary should still be in isCleaningServerMetadata.','line_number':135,'multiline':False]
['text':' isCleaningServerMetadata ','line_number':136,'multiline':True]
['text':' There should be 3 topology version changes without FCV change when we transition to','line_number':147,'multiline':False]
['text':' kSyncSourceOpsDuringRollback and kSteadyStateOps, including reconnect node, transition from','line_number':148,'multiline':False]
['text':' primary to rollback and transition from rollback to secondary. If the FCV change also','line_number':149,'multiline':False]
['text':' triggers a topology version change, then the topology version gap between before and after','line_number':150,'multiline':False]
['text':' rollback should be 4.','line_number':151,'multiline':False]
['text':' The primary should have rolled back their FCV to contain the targetVersion.','line_number':155,'multiline':False]
['text':' Rolling back from downgraded to isCleaningServerMetadata state.','line_number':157,'multiline':False]
['text':' isCleaningServerMetadata ','line_number':158,'multiline':True]
['text':' isCleaningServerMetadata ','line_number':159,'multiline':True]
['text':' As a rule, we forbid downgrading a node while a node is still in the upgrading state and','line_number':166,'multiline':False]
['text':' vice versa.','line_number':167,'multiline':False]
['text':' With the new downgrading to upgrading path, we do not permit upgrading if we are cleaning','line_number':168,'multiline':False]
['text':' server metadata.','line_number':169,'multiline':False]
['text':' Ensure that the in-memory and on-disk FCV are consistent by checking that this rule is','line_number':170,'multiline':False]
['text':' upheld after rollback.','line_number':171,'multiline':False]
['text':' Test rolling back from upgrading to downgrading.','line_number':183,'multiline':False]
['text':' Start off with downgrading from latest to lastLTS.','line_number':184,'multiline':False]
['text':' Go to upgrading from lastLTS to latest state.','line_number':185,'multiline':False]
['text':' Rollback and make sure the FCV doc is back in the downgrading from latest to lastLTS state.','line_number':186,'multiline':False]
['text':' Ensure the cluster starts at the correct FCV.','line_number':194,'multiline':False]
['text':' Wait until the config has propagated to the other nodes and the rollbackNode has learned of','line_number':216,'multiline':False]
['text':' it, so that the config replication check in 'setFeatureCompatibilityVersion' is satisfied.','line_number':217,'multiline':False]
['text':' This is only important since 'setFeatureCompatibilityVersion' is known to implicitly call','line_number':218,'multiline':False]
['text':' internal reconfigs as part of upgrade/downgrade behavior.','line_number':219,'multiline':False]
['text':' Wait for the majority commit point to be updated on the sync source, because checkFCV calls','line_number':221,'multiline':False]
['text':' getParameter for the featureCompatibilityVersion, which will wait until the FCV change makes','line_number':222,'multiline':False]
['text':' it into the node's majority committed snapshot.','line_number':223,'multiline':False]
['text':' timeout ','line_number':224,'multiline':True]
['text':' test rolling back from upgrading to downgrading','line_number':226,'multiline':False]
['text':' Wait for the FCV update to be reflected on the rollbackNode. This should eventually be rolled','line_number':232,'multiline':False]
['text':' back.','line_number':233,'multiline':False]
['text':' Secondaries should never have received the FCV update.','line_number':254,'multiline':False]
['text':' timeout ','line_number':306,'multiline':True]
['text':' A failpoint to hang right before setting isCleaningServerMetadata.','line_number':310,'multiline':False]
['text':' Turn off the failpoint so the primary will proceed to set isCleaningServerMetadata. This','line_number':316,'multiline':False]
['text':' update should never make it to the secondary.','line_number':317,'multiline':False]
['text':' The secondary should never have received the update to set isCleaningServerMetadata','line_number':328,'multiline':False]
['text':' There should be 3 topology version changes without FCV change when we transition to','line_number':336,'multiline':False]
['text':' kSyncSourceOpsDuringRollback and kSteadyStateOps, including reconnect node, transition from','line_number':337,'multiline':False]
['text':' primary to rollback and transition from rollback to secondary. When rollback from','line_number':338,'multiline':False]
['text':' isCleaningServerMetadata to downgrading, FCV change should not increment topology version.','line_number':339,'multiline':False]
['text':' With the new downgrading to upgrading path, we can still go from downgrading -> upgrading','line_number':345,'multiline':False]
['text':' after rollback.','line_number':346,'multiline':False]
['text':' Tests the case where we roll back the FCV state from downgrading to fully upgraded.','line_number':355,'multiline':False]
['text':' Tests the case where we roll back the FCV state from upgrading to fully downgraded.','line_number':358,'multiline':False]
['text':' Tests the case where we roll back the FCV state from fully downgraded to downgrading (while in','line_number':361,'multiline':False]
['text':' isCleaningServerMetadata state).','line_number':362,'multiline':False]
['text':' Tests the case where we roll back the FCV state from fully upgraded to upgrading.','line_number':365,'multiline':False]
['text':' Tests the case where we roll back the FCV state from upgrading to downgrading.','line_number':368,'multiline':False]
['text':' Tests roll back from isCleaningServerMetadata to downgrading.','line_number':371,'multiline':False]
