['text':'*
 *    Copyright (C) 2020-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]
['text':'*
 * Fulfills the promise if it is not already. Otherwise, does nothing.
 ','line_number':138,'multiline':True]
['text':' Ensure that we would only attempt to fulfill the promise with the same value.','line_number':159,'multiline':False]
['text':' namespace','line_number':261,'multiline':False]
['text':' It is illegal to transition into kError if the state has already surpassed','line_number':368,'multiline':False]
['text':' kStrictConsistency.','line_number':369,'multiline':False]
['text':' Intentionally swallow the error - by transitioning to kError, the','line_number':373,'multiline':False]
['text':' recipient effectively recovers from encountering the error and','line_number':374,'multiline':False]
['text':' should continue running in the future chain.','line_number':375,'multiline':False]
['text':' The recipient is done with all local transitions until the coordinator makes its','line_number':393,'multiline':False]
['text':' decision.','line_number':394,'multiline':False]
['text':' The recipient has progressed past the point where it needs to update the coordinator in','line_number':408,'multiline':False]
['text':' order for the coordinator to make its decision.','line_number':409,'multiline':False]
['text':' There is an implicit 'clustered' index on a clustered collection.','line_number':424,'multiline':False]
['text':' Increment the total index count similar to storage stats:','line_number':425,'multiline':False]
['text':' https://github.com/10gen/mongo/blob/29d8030f8aa7f3bc119081007fb09777daffc591/src/mongo/db/stats/storage_stats.cpp#L249C1-L251C22','line_number':426,'multiline':False]
['text':' Wait for all of the data replication components to halt. We','line_number':467,'multiline':False]
['text':' ignore any errors because resharding is known to have failed','line_number':468,'multiline':False]
['text':' already.','line_number':469,'multiline':False]
['text':' It is safe to drop the oplog collections once either (1) the','line_number':478,'multiline':False]
['text':' collection is renamed or (2) the operation is aborting.','line_number':479,'multiline':False]
['text':' If a failover occured before removing the recipient document, the','line_number':486,'multiline':False]
['text':' recipient could already be in state done.','line_number':487,'multiline':False]
['text':' We explicitly shut down and join the ReshardingDataReplication::_oplogFetcherExecutor','line_number':531,'multiline':False]
['text':' because waiting on the _dataReplicationQuiesced future may not do this automatically if','line_number':532,'multiline':False]
['text':' the scoped task executor was already been shut down.','line_number':533,'multiline':False]
['text':' Destroy metrics early so it's lifetime will not be tied to the lifetime of this','line_number':545,'multiline':False]
['text':' state machine. This is because we have future callbacks copy shared pointers to this','line_number':546,'multiline':False]
['text':' state machine that causes it to live longer than expected and potentially overlap','line_number':547,'multiline':False]
['text':' with a newer instance when stepping up.','line_number':548,'multiline':False]
['text':' If the stepdownToken was triggered, it takes priority in order to make sure that','line_number':551,'multiline':False]
['text':' the promise is set with an error that the coordinator can retry with. If it ran into','line_number':552,'multiline':False]
['text':' an unrecoverable error, it would have fasserted earlier.','line_number':553,'multiline':False]
['text':' Wait for all of the data replication components to halt. We ignore any data','line_number':560,'multiline':False]
['text':' replication errors because resharding is known to have failed already.','line_number':561,'multiline':False]
['text':' Propagate any errors from the recipient stepping down.','line_number':586,'multiline':False]
['text':' Propagate any errors from the recipient failing to notify the coordinator.','line_number':591,'multiline':False]
['text':' The operation will continue on a new RecipientStateMachine.','line_number':602,'multiline':False]
['text':' The shared_ptr stored in the PrimaryOnlyService's map for the ReshardingRecipientService','line_number':612,'multiline':False]
['text':' Instance is removed when the donor state document tied to the instance is deleted. It is','line_number':613,'multiline':False]
['text':' necessary to use shared_from_this() to extend the lifetime so the all earlier code can','line_number':614,'multiline':False]
['text':' safely finish executing.','line_number':615,'multiline':False]
['text':' On stepdown or shutdown, the _scopedExecutor may have already been shut down.','line_number':617,'multiline':False]
['text':' Everything in this function runs on the instance's cleanup executor, and will','line_number':618,'multiline':False]
['text':' execute regardless of any work on _scopedExecutor ever running.','line_number':619,'multiline':False]
['text':' This behavior in this phase is only used to validate whether this resharding','line_number':713,'multiline':False]
['text':' should be permitted, we need to call','line_number':714,'multiline':False]
['text':' validateShardKeyIndexExistsOrCreateIfPossible again in the buildIndex phase','line_number':715,'multiline':False]
['text':' to make sure we have the indexSpecs even after restart.','line_number':716,'multiline':False]
['text':' unique ','line_number':724,'multiline':True]
['text':' enforceUniquenessCheck ','line_number':725,'multiline':True]
['text':' unique ','line_number':744,'multiline':True]
['text':' enforceUniquenessCheck ','line_number':745,'multiline':True]
['text':' We add a fake 'shardCollection' notification here so that the C2C replicator can sync the','line_number':750,'multiline':False]
['text':' resharding operation to the target cluster. The only information we have is the shard','line_number':751,'multiline':False]
['text':' key, but all other fields must either be default-valued or are ignored by C2C.','line_number':752,'multiline':False]
['text':' TODO SERVER-66671: The 'createCollRequest' should include the full contents of the','line_number':753,'multiline':False]
['text':' ShardsvrCreateCollectionRequest rather than just the 'shardKey' field.','line_number':754,'multiline':False]
['text':' We refresh the routing information for the source collection to ensure the','line_number':771,'multiline':False]
['text':' ReshardingOplogApplier is making its decisions according to the chunk distribution after the','line_number':772,'multiline':False]
['text':' sharding metadata was frozen.','line_number':773,'multiline':False]
['text':' The metrics map can already be pre-populated if it was recovered from disk.','line_number':781,'multiline':False]
['text':' We call validateShardKeyIndexExistsOrCreateIfPossible again here in case if we','line_number':892,'multiline':False]
['text':' restarted after creatingCollection phase, whatever indexSpec we get in that','line_number':893,'multiline':False]
['text':' phase will go away.','line_number':894,'multiline':False]
['text':' unique ','line_number':902,'multiline':True]
['text':' enforceUniquenessCheck ','line_number':903,'multiline':True]
['text':' Get all indexSpecs need to build.','line_number':906,'multiline':False]
['text':' Build all the indexes.','line_number':918,'multiline':False]
['text':' When we create the collection we use the metadata resharding UUID as the','line_number':925,'multiline':False]
['text':' collection UUID.','line_number':926,'multiline':False]
['text':' In case of failover, the index build could have been started by oplog','line_number':936,'multiline':False]
['text':' applier, so we just wait those finish.','line_number':937,'multiline':False]
['text':' Allow bypassing user write blocking. The check has already been performed on the','line_number':1050,'multiline':False]
['text':' db-primary shard's ReshardCollectionCoordinator.','line_number':1051,'multiline':False]
['text':' We need to do this even though the feature flag is not on because the resharding can','line_number':1079,'multiline':False]
['text':' be aborted by setFCV downgrade, when the FCV is already in downgrading and the','line_number':1080,'multiline':False]
['text':' feature flag is treated as off.','line_number':1081,'multiline':False]
['text':' abortCollectionIndexBuilds can return on index commit/abort without waiting the index','line_number':1091,'multiline':False]
['text':' build done, so we need to explicitly wait here to make sure there is no building','line_number':1092,'multiline':False]
['text':' index after this point.','line_number':1093,'multiline':False]
['text':' For logging purposes.','line_number':1126,'multiline':False]
['text':'*
 * Returns a query filter of the form
 * {
 *     _id: <reshardingUUID>,
 *     recipientShards: {$elemMatch: {
 *         id: <this recipient's ShardId>,
 *         "mutableState.state: {$in: [ <list of valid current states> ]},
 *     }},
 * }
 ','line_number':1190,'multiline':True]
['text':' The recipient only updates the coordinator when it transitions to states which the','line_number':1202,'multiline':False]
['text':' coordinator depends on for its own transitions. The table maps the recipient states which','line_number':1203,'multiline':False]
['text':' could be updated on the coordinator to the only states the recipient could have already','line_number':1204,'multiline':False]
['text':' persisted to the current coordinator document in order for its transition to the newState to','line_number':1205,'multiline':False]
['text':' be valid.','line_number':1206,'multiline':False]
['text':' The network isn't perfectly reliable so it is possible for update commands sent by','line_number':1223,'multiline':False]
['text':' _updateCoordinator() to be received out of order by the coordinator. To overcome this','line_number':1224,'multiline':False]
['text':' behavior, the recipient shard includes the list of valid current states as part of','line_number':1225,'multiline':False]
['text':' the update to transition to the next state. This way, the update from a delayed','line_number':1226,'multiline':False]
['text':' message won't match the document if it or any later state transitions have already','line_number':1227,'multiline':False]
['text':' occurred.','line_number':1228,'multiline':False]
['text':' justOne ','line_number':1396,'multiline':True]
['text':' Before cloning, these values are 0. After cloning these values are written to the','line_number':1439,'multiline':False]
['text':' metrics section of the recipient state document and restored during metrics','line_number':1440,'multiline':False]
['text':' initialization. This is so that applied oplog entries that add or remove','line_number':1441,'multiline':False]
['text':' documents do not affect the cloning metrics.','line_number':1442,'multiline':False]
['text':' Restore stats here where interrupts will never occur, this is to ensure we will only update','line_number':1492,'multiline':False]
['text':' the metrics only once.','line_number':1493,'multiline':False]
['text':' onReshardingFieldsChanges() missed canceling _abortSource because _initAbortSource()','line_number':1524,'multiline':False]
['text':' hadn't been called yet. We used an error status stored in','line_number':1525,'multiline':False]
['text':' _coordinatorHasDecisionPersisted as an indication that an abort had been received.','line_number':1526,'multiline':False]
['text':' Canceling _abortSource immediately allows callers to use the returned abortToken as a','line_number':1527,'multiline':False]
['text':' definitive means of checking whether the operation has been aborted.','line_number':1528,'multiline':False]
['text':' run() hasn't been called, notify the operation should be aborted by setting an','line_number':1561,'multiline':False]
['text':' error. Abort is allowed to be retried, so setError only if it has not yet been','line_number':1562,'multiline':False]
['text':' done before.','line_number':1563,'multiline':False]
['text':' namespace mongo','line_number':1577,'multiline':False]
