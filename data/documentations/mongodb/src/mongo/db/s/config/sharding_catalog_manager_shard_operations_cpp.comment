['text':'*
 *    Copyright (C) 2018-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]
['text':' IWYU pragma: no_include "ext/alloc_traits.h"','line_number':37,'multiline':False]
['text':'*
 * Generates a unique name to be given to a newly added shard.
 ','line_number':184,'multiline':True]
['text':' TODO: fix so that we can have more than 10000 automatically generated shard names','line_number':217,'multiline':False]
['text':' namespace','line_number':227,'multiline':False]
['text':' Block until the command is carried out','line_number':254,'multiline':False]
['text':' Check whether any host in the connection is already part of the cluster.','line_number':301,'multiline':False]
['text':' Now check if this shard already exists - if it already exists *with the same options* then','line_number':309,'multiline':False]
['text':' the addShard request can return success early without doing anything more.','line_number':310,'multiline':False]
['text':' Function for determining if the options for the shard that is being added match the','line_number':318,'multiline':False]
['text':' options of an existing shard that conflicts with it.','line_number':319,'multiline':False]
['text':' Function for determining if there is an overlap amongst the hosts of the existing shard','line_number':335,'multiline':False]
['text':' and the propsed shard.','line_number':336,'multiline':False]
['text':' At least one of the hosts in the shard being added already exists in','line_number':343,'multiline':False]
['text':' an existing shard. If the options aren't the same, then this is an','line_number':344,'multiline':False]
['text':' error, but if the options match then the addShard operation should be','line_number':345,'multiline':False]
['text':' immediately considered a success and terminated.','line_number':346,'multiline':False]
['text':' An existing shard has the same replica set name as the shard being added.','line_number':369,'multiline':False]
['text':' If the options aren't the same, then this is an error.','line_number':370,'multiline':False]
['text':' If the shards are equivalent, there must be some overlap amongst their hosts, if not','line_number':371,'multiline':False]
['text':' then addShard results in an error.','line_number':372,'multiline':False]
['text':' Look if any of the hosts in the existing shard are present within the shard trying','line_number':391,'multiline':False]
['text':' to be added.','line_number':392,'multiline':False]
['text':' If we get here then we're trying to add a shard with the same name as an','line_number':399,'multiline':False]
['text':' existing shard, but there was no overlap in the hosts between the existing','line_number':400,'multiline':False]
['text':' shard and the proposed connection string for the new shard.','line_number':401,'multiline':False]
['text':' Check for a command response error','line_number':427,'multiline':False]
['text':' Fail if the node being added is a mongos.','line_number':436,'multiline':False]
['text':' Extract the maxWireVersion so we can verify that the node being added has a binary version','line_number':442,'multiline':False]
['text':' greater than or equal to the cluster's featureCompatibilityVersion. We expect an incompatible','line_number':443,'multiline':False]
['text':' binary node to be unable to communicate, returning an IncompatibleServerVersion error,','line_number':444,'multiline':False]
['text':' because of our internal wire version protocol. So we can safely invariant here that the node','line_number':445,'multiline':False]
['text':' is compatible.','line_number':446,'multiline':False]
['text':' Check whether the host is a writable primary. If not, the replica set may not have been','line_number':455,'multiline':False]
['text':' initiated. If the connection is a standalone, it will return true for "isWritablePrimary".','line_number':456,'multiline':False]
['text':' Make sure the specified replica set name (if any) matches the actual shard's replica set','line_number':475,'multiline':False]
['text':' Make sure the set name specified in the connection string matches the one where its hosts','line_number':489,'multiline':False]
['text':' belong into','line_number':490,'multiline':False]
['text':' Is it a config server?','line_number':497,'multiline':False]
['text':' If the shard is part of a replica set, make sure all the hosts mentioned in the connection','line_number':549,'multiline':False]
['text':' string are part of the set. It is fine if not all members of the set are mentioned in the','line_number':550,'multiline':False]
['text':' connection string, though.','line_number':551,'multiline':False]
['text':' host:port','line_number':557,'multiline':False]
['text':' host:port','line_number':563,'multiline':False]
['text':' host:port','line_number':570,'multiline':False]
['text':' host:port','line_number':575,'multiline':False]
['text':' Default it to the name of the replica set','line_number':590,'multiline':False]
['text':' Disallow adding shard replica set with name 'config'','line_number':594,'multiline':False]
['text':' Retrieve the most up to date connection string that we know from the replica set monitor (if','line_number':599,'multiline':False]
['text':' this is a replica set shard, otherwise it will be the same value as connectionString).','line_number':600,'multiline':False]
['text':' Throw out any accumulated results on error.','line_number':685,'multiline':False]
['text':' Skip views and special collections.','line_number':696,'multiline':False]
['text':' metadata tracking, only used for shards ','line_number':747,'multiline':True]
['text':' command network timeout ','line_number':748,'multiline':True]
['text':' getMore network timeout ','line_number':749,'multiline':True]
['text':' Insert a shard identity document. Note we insert with local write concern, so the shard','line_number':771,'multiline':False]
['text':' identity may roll back, which will trigger an fassert to clear the in-memory sharding state.','line_number':772,'multiline':False]
['text':' Only need to update the parameter when adding the second shard.','line_number':813,'multiline':False]
['text':' Only need to update the parameter when removing the second shard.','line_number':827,'multiline':False]
['text':' Take the cluster cardinality parameter lock and the shard membership lock in exclusive mode','line_number':848,'multiline':False]
['text':' so that no add/remove shard operation and its set cluster cardinality parameter operation can','line_number':849,'multiline':False]
['text':' interleave with the ones below. Release the shard membership lock before initiating the','line_number':850,'multiline':False]
['text':' _configsvrSetClusterParameter command after finishing the add shard operation since setting a','line_number':851,'multiline':False]
['text':' cluster parameter requires taking this lock.','line_number':852,'multiline':False]
['text':' Check if this shard has already been added (can happen in the case of a retry after a network','line_number':856,'multiline':False]
['text':' error, for example) and thus this addShard request should be considered a no-op.','line_number':857,'multiline':False]
['text':' These hosts already belong to an existing shard, so report success and terminate the','line_number':863,'multiline':False]
['text':' addShard request.  Make sure to set the last optime for the client to the system last','line_number':864,'multiline':False]
['text':' optime so that we'll still wait for replication so that this state is visible in the','line_number':865,'multiline':False]
['text':' committed snapshot.','line_number':866,'multiline':False]
['text':' Release the shard membership lock since the set cluster parameter operation below','line_number':869,'multiline':False]
['text':' require taking this lock.','line_number':870,'multiline':False]
['text':' Do not remove the RSM for the config server because it is still needed even if','line_number':885,'multiline':False]
['text':' adding the config server as a shard failed.','line_number':886,'multiline':False]
['text':' This is a workaround for the case were we could have some bad shard being','line_number':892,'multiline':False]
['text':' requested to be added and we put that bad connection string on the global replica set','line_number':893,'multiline':False]
['text':' monitor registry. It needs to be cleaned up so that when a correct replica set is','line_number':894,'multiline':False]
['text':' added, it will be recreated.','line_number':895,'multiline':False]
['text':' Validate the specified connection string may serve as shard at all','line_number':900,'multiline':False]
['text':' TODO SERVER-80532: the sharding catalog might lose some databases.','line_number':908,'multiline':False]
['text':' Check that none of the existing shard candidate's dbs exist already','line_number':909,'multiline':False]
['text':' Check that the shard candidate does not have a local config.system.sessions collection','line_number':929,'multiline':False]
['text':' If the shard is also the config server itself, there is no need to pull the keys since','line_number':938,'multiline':False]
['text':' the keys already exists in the local admin.system.keys collection.','line_number':939,'multiline':False]
['text':' If a name for a shard wasn't provided, generate one','line_number':946,'multiline':False]
['text':' Helper function that runs a command on the to-be shard and returns the status','line_number':955,'multiline':False]
['text':' Grabs the underlying status from a StatusWith object by taking the first','line_number':962,'multiline':False]
['text':' non-OK status, if there is one. This is needed due to the semantics of','line_number':963,'multiline':False]
['text':' _runCommandForAddShard.','line_number':964,'multiline':False]
['text':' Use the _addShard command to add the shard, which in turn inserts a shardIdentity','line_number':973,'multiline':False]
['text':' document into the shard and triggers sharding state initialization.','line_number':974,'multiline':False]
['text':' Set the user-writes blocking state on the new shard.','line_number':980,'multiline':False]
['text':' Determine the set of cluster parameters to be used.','line_number':983,'multiline':False]
['text':' Keep the FCV stable across checking the FCV, sending setFCV to the new shard and writing','line_number':988,'multiline':False]
['text':' the entry for the new shard to config.shards. This ensures the FCV doesn't change after','line_number':989,'multiline':False]
['text':' we send setFCV to the new shard, but before we write its entry to config.shards.','line_number':990,'multiline':False]
['text':'','line_number':991,'multiline':False]
['text':' NOTE: We don't use a Global IX lock here, because we don't want to hold the global lock','line_number':992,'multiline':False]
['text':' while blocking on the network).','line_number':993,'multiline':False]
['text':' TODO SERVER-80532: the sharding catalog might lose some collections.','line_number':1000,'multiline':False]
['text':' (Generic FCV reference): These FCV checks should exist across LTS binary versions.','line_number':1009,'multiline':False]
['text':' Tick clusterTime to get a new topologyTime for this mutation of the topology.','line_number':1039,'multiline':False]
['text':' Record in changelog','line_number':1051,'multiline':False]
['text':' Ensure the added shard is visible to this process.','line_number':1064,'multiline':False]
['text':' Release the shard membership lock since the set cluster parameter operation below','line_number':1075,'multiline':False]
['text':' require taking this lock.','line_number':1076,'multiline':False]
['text':' Set the operation context read concern level to local for reads into the config','line_number':1089,'multiline':False]
['text':' database.','line_number':1090,'multiline':False]
['text':' Find how many *other* shards exist, which are *not* currently draining','line_number':1123,'multiline':False]
['text':' Ensure there are no non-empty zones that only belong to this shard','line_number':1132,'multiline':False]
['text':' Figure out if shard is already draining','line_number':1143,'multiline':False]
['text':' Record start in changelog','line_number':1153,'multiline':False]
['text':' Draining has already started, now figure out how many chunks and databases are still on the','line_number':1178,'multiline':False]
['text':' shard.','line_number':1179,'multiline':False]
['text':' Still more draining to do','line_number':1192,'multiline':False]
['text':' The config server may be added as a shard again, so we locally drop its drained','line_number':1206,'multiline':False]
['text':' sharded collections to enable that without user intervention. But we have to wait for','line_number':1207,'multiline':False]
['text':' the range deleter to quiesce to give queries and stale routers time to discover the','line_number':1208,'multiline':False]
['text':' migration, to match the usual probabilistic guarantees for migrations.','line_number':1209,'multiline':False]
['text':' Drop all tracked databases locally now that all user data has been drained so the config','line_number':1223,'multiline':False]
['text':' server can transition back to catalog shard mode without requiring users to manually drop','line_number':1224,'multiline':False]
['text':' them.','line_number':1225,'multiline':False]
['text':' Also drop the sessions collection, which we assume is the only sharded collection in the','line_number':1245,'multiline':False]
['text':' config database.','line_number':1246,'multiline':False]
['text':' Draining is done, now finish removing the shard.','line_number':1256,'multiline':False]
['text':' Take the cluster cardinality parameter lock and the shard membership lock in exclusive mode','line_number':1259,'multiline':False]
['text':' so that no add/remove shard operation and its set cluster cardinality parameter operation can','line_number':1260,'multiline':False]
['text':' interleave with the ones below. Release the shard membership lock before initiating the','line_number':1261,'multiline':False]
['text':' _configsvrSetClusterParameter command after finishing the remove shard operation since','line_number':1262,'multiline':False]
['text':' setting a cluster parameter requires taking this lock.','line_number':1263,'multiline':False]
['text':' Synchronize the control shard selection, the shard's document removal, and the topology time','line_number':1265,'multiline':False]
['text':' update to exclude potential race conditions in case of concurrent add/remove shard','line_number':1266,'multiline':False]
['text':' operations.','line_number':1267,'multiline':False]
['text':' Find a controlShard to be updated.','line_number':1270,'multiline':False]
['text':' Since it's not possible to remove the last shard, there should always be a control shard.','line_number':1280,'multiline':False]
['text':' Tick clusterTime to get a new topologyTime for this mutation of the topology.','line_number':1288,'multiline':False]
['text':' Remove the shard's document and update topologyTime within a transaction.','line_number':1291,'multiline':False]
['text':' The shard which was just removed must be reflected in the shard registry, before the replica','line_number':1296,'multiline':False]
['text':' set monitor is removed, otherwise the shard would be referencing a dropped RSM.','line_number':1297,'multiline':False]
['text':' Don't remove the config shard's RSM because it is used to target the config server.','line_number':1301,'multiline':False]
['text':' Record finish in changelog','line_number':1305,'multiline':False]
['text':' Get BSONObj containing:','line_number':1328,'multiline':False]
['text':' 1) note about moving or dropping databases in a shard','line_number':1329,'multiline':False]
['text':' 2) list of databases (excluding 'local' database) that need to be moved','line_number':1330,'multiline':False]
['text':' Delete all the config.user_writes_critical_sections documents from the new shard.','line_number':1421,'multiline':False]
['text':'multi','line_number':1425,'multiline':True]
['text':' Propagate the cluster's current user write blocking state onto the new shard.','line_number':1437,'multiline':False]
['text':' global ','line_number':1448,'multiline':True]
['text':' Throw out any accumulated results on error.','line_number':1502,'multiline':False]
['text':' metadata tracking, only used for shards ','line_number':1531,'multiline':True]
['text':' command network timeout ','line_number':1532,'multiline':True]
['text':' getMore network timeout ','line_number':1533,'multiline':True]
['text':' migrationId ','line_number':1552,'multiline':True]
['text':' previousTime ','line_number':1600,'multiline':True]
['text':' We can safely query the cluster parameters because the replica set must have been started','line_number':1610,'multiline':False]
['text':' with --shardsvr in order to add it into the cluster, and in this mode no setClusterParameter','line_number':1611,'multiline':False]
['text':' can be called on the replica set directly.','line_number':1612,'multiline':False]
['text':' If for some reason the callback never gets invoked, we will return this status in','line_number':1618,'multiline':False]
['text':' response.','line_number':1619,'multiline':False]
['text':' Remove possible leftovers config.clusterParameters documents from the new shard.','line_number':1663,'multiline':False]
['text':'multi','line_number':1667,'multiline':True]
['text':' First, remove all existing parameters from the new shard.','line_number':1684,'multiline':False]
['text':' Push cluster parameters into the newly added shard.','line_number':1693,'multiline':False]
['text':' If this is the first shard being added, and no cluster parameters have been set, then this','line_number':1738,'multiline':False]
['text':' can be seen as a replica set to shard conversion -- absorb all of this shard's cluster','line_number':1739,'multiline':False]
['text':' parameters. Otherwise, push our cluster parameters to the shard.','line_number':1740,'multiline':False]
['text':' 1. Send out the "prepareCommit" notification','line_number':1764,'multiline':False]
['text':'addImported','line_number':1771,'multiline':True]
['text':' 2. Set up and run the commit statements','line_number':1783,'multiline':False]
['text':' TODO SERVER-66261 newShard may be passed by reference.','line_number':1784,'multiline':False]
['text':' TODO SERVER-81582: generate batches of transactions to insert the database/placementHistory','line_number':1785,'multiline':False]
['text':' and collection/placementHistory before adding the shard in config.shards.','line_number':1786,'multiline':False]
['text':' Create a single chunk for this','line_number':1860,'multiline':False]
['text':' 3. Reuse the existing notification object to also broadcast the event of successful commit.','line_number':1927,'multiline':False]
['text':' namespace mongo','line_number':1991,'multiline':False]
