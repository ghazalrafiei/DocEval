['text':'*
 *    Copyright (C) 2018-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]
['text':'*
 * This is the implementation for the Sorter.
 *
 * It is intended to be included in other cpp files like this:
 *
 * #include <normal/include/files.h>
 *
 * #include "mongo/db/sorter/sorter.h"
 *
 * namespace mongo {
 *     // Your code
 * }
 *
 * #include "mongo/db/sorter/sorter.cpp"
 * MONGO_CREATE_SORTER(MyKeyType, MyValueType, MyComparatorType);
 *
 * Do this once for each unique set of parameters to MONGO_CREATE_SORTER.
 ','line_number':30,'multiline':True]
['text':' IWYU pragma: no_include "boost/container/detail/std_fwd.hpp"','line_number':70,'multiline':False]
['text':' IWYU pragma: keep','line_number':81,'multiline':False]
['text':' This should be checked by consumers, but if it isn't try to fail early.','line_number':107,'multiline':False]
['text':'*
 * Returns the current EncryptionHooks registered with the global service context.
 * Returns nullptr if the service context is not available; or if the EncyptionHooks
 * registered is not enabled.
 ','line_number':114,'multiline':True]
['text':' Some tests may not run with a global service context.','line_number':120,'multiline':False]
['text':' namespace','line_number':134,'multiline':False]
['text':' We need to use the "real" errno everywhere, not GetLastError() on Windows','line_number':138,'multiline':False]
['text':' MSVC++ already does similar verification in debug mode in addition to using','line_number':149,'multiline':False]
['text':' algorithms that do more comparisons. Doing our own verification in addition makes','line_number':150,'multiline':False]
['text':' debug builds considerably slower without any additional safety.','line_number':151,'multiline':False]
['text':' test reversed comparisons','line_number':153,'multiline':False]
['text':' test reflexivity','line_number':163,'multiline':False]
['text':'*
 * Returns results from sorted in-memory storage.
 ','line_number':169,'multiline':True]
['text':'/ No data to iterate','line_number':177,'multiline':False]
['text':'/ Only a single value','line_number':180,'multiline':False]
['text':'/ Any number of values','line_number':183,'multiline':False]
['text':'*
 * This class is used to return the in-memory state from the sorter in read-only mode.
 * This is used by streams checkpoint use case mainly to save in-memory state on persistent
 * storage."
 ','line_number':217,'multiline':True]
['text':'*
 * Returns results from a sorted range within a file. Each instance is given a file name and start
 * and end offsets.
 *
 * This class is NOT responsible for file clean up / deletion. There are openSource() and
 * closeSource() functions to ensure the FileIterator is not holding the file open when the file is
 * deleted. Since it is one among many FileIterators, it cannot close a file that may still be in
 * use elsewhere.
 ','line_number':260,'multiline':True]
['text':' If the file iterator reads through all data objects, we can ensure non-corrupt data','line_number':296,'multiline':False]
['text':' by comparing the newly calculated checksum with the original checksum from the data','line_number':297,'multiline':False]
['text':' written to disk. Some iterators do not read back all data from the file, which prohibits','line_number':298,'multiline':False]
['text':' the _afterReadChecksum from obtaining all the information needed. Thus, we only fassert','line_number':299,'multiline':False]
['text':' if all data that was written to disk is read back and the checksums are not equivalent.','line_number':300,'multiline':False]
['text':' may change _done','line_number':313,'multiline':False]
['text':' Note: calling read() on the _bufferReader buffer in the deserialize function advances the','line_number':330,'multiline':False]
['text':' buffer. Since Key comes before Value in the _bufferReader, and C++ makes no function','line_number':331,'multiline':False]
['text':' parameter evaluation order guarantees, we cannot deserialize Key and Value straight into','line_number':332,'multiline':False]
['text':' the Data constructor','line_number':333,'multiline':False]
['text':' The difference of _bufferReader's position before and after reading the data','line_number':342,'multiline':False]
['text':' will provide the length of the data that was just read.','line_number':343,'multiline':False]
['text':'*
     * Attempts to refill the _bufferReader if it is empty. Expects _done to be false.
     ','line_number':367,'multiline':True]
['text':'*
     * Tries to read from disk and places any results in _bufferReader. If there is no more data to
     * read, then _done is set to true and the function returns immediately.
     ','line_number':383,'multiline':True]
['text':' negative size means compressed','line_number':393,'multiline':False]
['text':' hold on to decompressed data and throw out compressed data at block exit','line_number':435,'multiline':False]
['text':'*
     * Attempts to read data from disk. Sets _done to true when file offset reaches _fileEndOffset.
     ','line_number':440,'multiline':True]
['text':' File containing the sorted data range.','line_number':463,'multiline':False]
['text':' File offset at which the sorted data range starts.','line_number':464,'multiline':False]
['text':' File offset at which we are currently reading from.','line_number':465,'multiline':False]
['text':' File offset at which the sorted data range ends.','line_number':466,'multiline':False]
['text':' Points to the beginning of a serialized key in the key-value pair currently being read, and','line_number':469,'multiline':False]
['text':' used for computing the checksum value. This is set to nullptr after reading each key-value','line_number':470,'multiline':False]
['text':' pair.','line_number':471,'multiline':False]
['text':' Checksum value that is updated with each read of a data object from disk. We can compare','line_number':473,'multiline':False]
['text':' this value with _originalChecksum to check for data corruption if and only if the','line_number':474,'multiline':False]
['text':' FileIterator is exhausted.','line_number':475,'multiline':False]
['text':' Checksum value retrieved from SortedFileWriter that was calculated as data was spilled','line_number':478,'multiline':False]
['text':' to disk. This is not modified, and is only used for comparison against _afterReadChecksum','line_number':479,'multiline':False]
['text':' when the FileIterator is exhausted to ensure no data corruption.','line_number':480,'multiline':False]
['text':'*
 * Merge-sorts results from 0 or more FileIterators, all of which should be iterating over sorted
 * ranges within the same file. The input iterators must implement nextWithDeferredValue() and
 * getDeferredValue(). This class is given the data source file name upon construction and is
 * responsible for deleting the data source file upon destruction.
 ','line_number':484,'multiline':True]
['text':'*
     * Data iterator over an Input stream.
     *
     * This class is responsible for closing the Input source upon destruction, unfortunately,
     * because that is the path of least resistence to a design change requiring MergeIterator to
     * handle eventual deletion of said Input source.
     ','line_number':610,'multiline':True]
['text':' uses greater rather than less-than to maintain a MinHeap','line_number':650,'multiline':False]
['text':' first compare data','line_number':656,'multiline':False]
['text':' then compare fileNums to ensure stability','line_number':662,'multiline':False]
['text':' MinHeap','line_number':674,'multiline':False]
['text':' named so calls make sense','line_number':675,'multiline':False]
['text':' The maximum file identifier used thus far','line_number':676,'multiline':False]
['text':'*
     * Merge the spills in order to approximately respect memory usage. This method will calculate
     * the number of spills that can be merged simultaneously in order to respect memory limits and
     * reduce the spills to that number if necessary by merging them iteratively.
     ','line_number':697,'multiline':True]
['text':'*
     * An implementation of a k-way merge sort.
     *
     * This method will take a target number of sorted spills to merge and will proceed to merge the
     * set of them in batches of at most numTargetedSpills until it reaches the target.
     *
     * To give an example, if we have 5 spills and a target number of 2 the algorithm will do the
     * following:
     *
     * {1, 2, 3, 4, 5}
     * {12, 34, 5}
     * {1234, 5}
     ','line_number':710,'multiline':True]
['text':' This error message only applies to sorts from user queries made through the find or','line_number':934,'multiline':False]
['text':' aggregation commands. Other clients, such as bulk index builds, should suppress this','line_number':935,'multiline':False]
['text':' error, either by allowing external sorting or by catching and throwing a more','line_number':936,'multiline':False]
['text':' appropriate error.','line_number':937,'multiline':False]
['text':' We expect that all buffers are unused at this point.','line_number':956,'multiline':False]
['text':' Data that has not been spilled.','line_number':967,'multiline':False]
['text':' Since this class is only used for limit==1, it omits all logic to','line_number':973,'multiline':False]
['text':' spill to disk and only tracks memory usage if explicitly requested.','line_number':974,'multiline':False]
['text':' not good enough','line_number':991,'multiline':False]
['text':' Invoking dataProducer could invalidate key if it uses move semantics,','line_number':996,'multiline':False]
['text':' don't reference them anymore from this point on.','line_number':997,'multiline':False]
['text':' ok to return InMemIterator as this is a single value constructed from copy','line_number':1027,'multiline':False]
['text':' false at start, set to true on first call to add()','line_number':1043,'multiline':False]
['text':' This also *works* with limit==1 but LimitOneSorter should be used instead','line_number':1061,'multiline':False]
['text':' Preallocate a fixed sized vector of the required size if we don't expect it to have a','line_number':1064,'multiline':False]
['text':' major impact on our memory budget. This is the common case with small limits.','line_number':1065,'multiline':False]
['text':' Invoking dataProducer could invalidate key if it uses move semantics,','line_number':1086,'multiline':False]
['text':' don't reference them anymore from this point on.','line_number':1087,'multiline':False]
['text':' not good enough','line_number':1105,'multiline':False]
['text':' Remove the old worst pair and insert the contender, adjusting _memUsed','line_number':1107,'multiline':False]
['text':' Invoking dataProducer could invalidate key if it uses move semantics,','line_number':1114,'multiline':False]
['text':' don't reference them anymore from this point on.','line_number':1115,'multiline':False]
['text':' Can only be called after _data is sorted','line_number':1198,'multiline':False]
['text':' Theory of operation: We want to be able to eagerly ignore values we know will not','line_number':1200,'multiline':False]
['text':' be in the TopK result set by setting _cutoff to a value we know we have at least','line_number':1201,'multiline':False]
['text':' K values equal to or better than. There are two values that we track to','line_number':1202,'multiline':False]
['text':' potentially become the next value of _cutoff: _worstSeen and _lastMedian. When','line_number':1203,'multiline':False]
['text':' one of these values becomes the new _cutoff, its associated counter is reset to 0','line_number':1204,'multiline':False]
['text':' and a new value is chosen for that member the next time we spill.','line_number':1205,'multiline':False]
['text':'','line_number':1206,'multiline':False]
['text':' _worstSeen is the worst value we've seen so that all kept values are better than','line_number':1207,'multiline':False]
['text':' (or equal to) it. This means that once _worstCount >= _opts.limit there is no','line_number':1208,'multiline':False]
['text':' reason to consider values worse than _worstSeen so it can become the new _cutoff.','line_number':1209,'multiline':False]
['text':' This technique is especially useful when the input is already roughly sorted (eg','line_number':1210,'multiline':False]
['text':' sorting ASC on an ObjectId or Date field) since we will quickly find a cutoff','line_number':1211,'multiline':False]
['text':' that will exclude most later values, making the full TopK operation including','line_number':1212,'multiline':False]
['text':' the MergeIterator phase is O(K) in space and O(N + K*Log(K)) in time.','line_number':1213,'multiline':False]
['text':'','line_number':1214,'multiline':False]
['text':' _lastMedian was the median of the _data in the first spill() either overall or','line_number':1215,'multiline':False]
['text':' following a promotion of _lastMedian to _cutoff. We count the number of kept','line_number':1216,'multiline':False]
['text':' values that are better than or equal to _lastMedian in _medianCount and can','line_number':1217,'multiline':False]
['text':' promote _lastMedian to _cutoff once _medianCount >=_opts.limit. Assuming','line_number':1218,'multiline':False]
['text':' reasonable median selection (which should happen when the data is completely','line_number':1219,'multiline':False]
['text':' unsorted), after the first K spilled values, we will keep roughly 50% of the','line_number':1220,'multiline':False]
['text':' incoming values, 25% after the second K, 12.5% after the third K, etc. This means','line_number':1221,'multiline':False]
['text':' that by the time we spill 3*K values, we will have seen (1*K + 2*K + 4*K) values,','line_number':1222,'multiline':False]
['text':' so the expected number of kept values is O(Log(N/K) * K). The final run time if','line_number':1223,'multiline':False]
['text':' using the O(K*Log(N)) merge algorithm in MergeIterator is O(N + K*Log(K) +','line_number':1224,'multiline':False]
['text':' K*LogLog(N/K)) which is much closer to O(N) than O(N*Log(K)).','line_number':1225,'multiline':False]
['text':'','line_number':1226,'multiline':False]
['text':' This leaves a currently unoptimized worst case of data that is already roughly','line_number':1227,'multiline':False]
['text':' sorted, but in the wrong direction, such that the desired results are all the','line_number':1228,'multiline':False]
['text':' last ones seen. It will require O(N) space and O(N*Log(K)) time. Since this','line_number':1229,'multiline':False]
['text':' should be trivially detectable, as a future optimization it might be nice to','line_number':1230,'multiline':False]
['text':' detect this case and reverse the direction of input (if possible) which would','line_number':1231,'multiline':False]
['text':' turn this into the best case described above.','line_number':1232,'multiline':False]
['text':'','line_number':1233,'multiline':False]
['text':' Pedantic notes: The time complexities above (which count number of comparisons)','line_number':1234,'multiline':False]
['text':' ignore the sorting of batches prior to spilling to disk since they make it more','line_number':1235,'multiline':False]
['text':' confusing without changing the results. If you want to add them back in, add an','line_number':1236,'multiline':False]
['text':' extra term to each time complexity of (SPACE_COMPLEXITY * Log(BATCH_SIZE)). Also,','line_number':1237,'multiline':False]
['text':' all space complexities measure disk space rather than memory since this class is','line_number':1238,'multiline':False]
['text':' O(1) in memory due to the _opts.maxMemoryUsageBytes limit.','line_number':1239,'multiline':False]
['text':' less is "better" for TopK.','line_number':1241,'multiline':False]
['text':' Pick a new _worstSeen or _lastMedian if should.','line_number':1243,'multiline':False]
['text':' chooses the higher if size() is even.','line_number':1248,'multiline':False]
['text':' Add the counters of kept objects better than or equal to _worstSeen/_lastMedian.','line_number':1252,'multiline':False]
['text':' everything is better or equal','line_number':1253,'multiline':False]
['text':' Promote _worstSeen or _lastMedian to _cutoff and reset counters if should.','line_number':1259,'multiline':False]
['text':' This error message only applies to sorts from user queries made through the find or','line_number':1283,'multiline':False]
['text':' aggregation commands. Other clients should suppress this error, either by allowing','line_number':1284,'multiline':False]
['text':' external sorting or by catching and throwing a more appropriate error.','line_number':1285,'multiline':False]
['text':' clear _data and release backing array's memory','line_number':1301,'multiline':False]
['text':' Data that has not been spilled. Organized as max-heap if size == limit.','line_number':1314,'multiline':False]
['text':' See updateCutoff() for a full description of how these members are used.','line_number':1317,'multiline':False]
['text':' We can definitely ignore values worse than this.','line_number':1319,'multiline':False]
['text':' The worst Data seen so far. Reset when _worstCount >= _opts.limit.','line_number':1320,'multiline':False]
['text':' Number of docs better or equal to _worstSeen kept so far.','line_number':1321,'multiline':False]
['text':' Median of a batch. Reset when _medianCount >= _opts.limit.','line_number':1322,'multiline':False]
['text':' Number of docs better or equal to _lastMedian kept so far.','line_number':1323,'multiline':False]
['text':' namespace sorter','line_number':1326,'multiline':False]
['text':' namespace','line_number':1335,'multiline':False]
['text':' If the _offset is not -1, we may have written data to it, so we must flush.','line_number':1410,'multiline':False]
['text':' We open the provided file in append mode so that SortedFileWriter instances can share','line_number':1478,'multiline':False]
['text':' the same file, used serially. We want to share files in order to stay below system','line_number':1479,'multiline':False]
['text':' open file limits.','line_number':1480,'multiline':False]
['text':' If we are opening the file for the first time, or if we previously flushed and switched to','line_number':1499,'multiline':False]
['text':' read mode, we need to set the _offset to the file size.','line_number':1500,'multiline':False]
['text':'','line_number':1507,'multiline':False]
['text':' SortedFileWriter','line_number':1508,'multiline':False]
['text':'','line_number':1509,'multiline':False]
['text':' This should be checked by consumers, but if we get here don't allow writes.','line_number':1521,'multiline':False]
['text':' Offset that points to the place in the buffer where a new data object will be stored.','line_number':1534,'multiline':False]
['text':' Add serialized key and value to the buffer.','line_number':1537,'multiline':False]
['text':' Serializing the key and value grows the buffer, but _buffer.buf() still points to the','line_number':1541,'multiline':False]
['text':' beginning. Use _buffer.len() to determine portion of buffer containing new datum.','line_number':1542,'multiline':False]
['text':' Negative size means compressed.','line_number':1595,'multiline':False]
['text':' If a new value violates what we thought was our min bound, something has gone wrong.','line_number':1658,'multiline':False]
['text':' Each new item can potentially give us a tighter bound (a higher min).','line_number':1664,'multiline':False]
['text':' In state kDone, the heap and spill are usually empty, because kDone means the sorter has','line_number':1683,'multiline':False]
['text':' no more elements to return. However, if there is a limit then we can also reach state','line_number':1684,'multiline':False]
['text':' kDone when 'this->_stats.numSorted() == _opts.limit'.','line_number':1685,'multiline':False]
['text':' There are now two possible states we could be in:','line_number':1693,'multiline':False]
['text':' - Typically, we should be ready for more input (kWait).','line_number':1694,'multiline':False]
['text':' - If there is a limit and we reached it, then we're done. We were done before restart()','line_number':1695,'multiline':False]
['text':'   and we're still done.','line_number':1696,'multiline':False]
['text':' No more input will arrive, so we're never in state kWait.','line_number':1714,'multiline':False]
['text':' _heap.top() is the min of _heap, but we also need to consider whether a smaller input','line_number':1721,'multiline':False]
['text':' will arrive later. So _heap.top() is safe to return only if _heap.top() < _min.','line_number':1722,'multiline':False]
['text':' Similarly, we can return the next element from the spilled iterator if it's < _min.','line_number':1726,'multiline':False]
['text':' A later call to add() may improve _min. Or in the worst case, after done() is called','line_number':1730,'multiline':False]
['text':' we will return everything in _heap.','line_number':1731,'multiline':False]
['text':' If we have a small $limit, we can simply extract that many of the smallest elements from','line_number':1781,'multiline':False]
['text':' the _heap and discard the rest, avoiding an expensive spill to disk.','line_number':1782,'multiline':False]
['text':' Write out all the values from the heap in sorted order.','line_number':1806,'multiline':False]
['text':'','line_number':1827,'multiline':False]
['text':' Factory Functions','line_number':1828,'multiline':False]
['text':'','line_number':1829,'multiline':False]
['text':' namespace mongo','line_number':1878,'multiline':False]
