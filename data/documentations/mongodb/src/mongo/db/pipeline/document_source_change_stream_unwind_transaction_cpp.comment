['text':'*
 *    Copyright (C) 2021-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]
['text':'*
 * Build a filter, similar to the optimized oplog filter, designed to reject individual transaction
 * entries that we know would eventually get rejected by the 'userMatch' filter if they continued
 * through the rest of the pipeline. We must also adjust the filter slightly for user rewrites, as
 * events within a transaction do not have certain fields that are common to other oplog entries.
 *
 * NB: The new filter may contain references to strings in the BSONObj that 'userMatch' originated
 * from. Callers that keep the new filter long-term should serialize and re-parse it to guard
 * against the possibility of stale string references.
 ','line_number':80,'multiline':True]
['text':' The transaction unwind filter is the same as the operation filter applied to the oplog. This','line_number':92,'multiline':False]
['text':' includes a namespace filter, which ensures that it will discard all documents that would be','line_number':93,'multiline':False]
['text':' filtered out by the default 'ns' filter this stage gets initialized with.','line_number':94,'multiline':False]
['text':' To correctly handle filtering out entries of direct write operations on orphaned documents,','line_number':97,'multiline':False]
['text':' we include a filter for "fromMigrate" flagged operations, unless "fromMigrate" events are','line_number':98,'multiline':False]
['text':' explicitly requested in the spec.','line_number':99,'multiline':False]
['text':' Attempt to rewrite the user's filter and combine it with the standard operation filter. We do','line_number':104,'multiline':False]
['text':' this separately because we need to exclude certain fields from the user's filters. Unwound','line_number':105,'multiline':False]
['text':' transaction events do not have these fields until we populate them from the commitTransaction','line_number':106,'multiline':False]
['text':' event. We already applied these predicates during the oplog scan, so we know that they match.','line_number':107,'multiline':False]
['text':'*
 * This filter is only used internally, to test the applicability of the EOT event we generate for
 * unprepared transactions.
 ','line_number':116,'multiline':True]
['text':'options','line_number':128,'multiline':True]
['text':' namespace change_stream_filter','line_number':130,'multiline':False]
['text':' If we're unwinding an 'applyOps' from a transaction, check if there are any documents','line_number':223,'multiline':False]
['text':' we have stored that can be returned.','line_number':224,'multiline':False]
['text':' Get the next input document.','line_number':233,'multiline':False]
['text':' If the oplog entry is not part of a transaction, allow it to pass through.','line_number':241,'multiline':False]
['text':' The only two commands we will see here are an applyOps or a commit, which both mean','line_number':246,'multiline':False]
['text':' we need to open a "transaction context" representing a group of updates that all','line_number':247,'multiline':False]
['text':' occurred at once as part of a transaction. If we already have a transaction context','line_number':248,'multiline':False]
['text':' open, that would mean we are looking at an applyOps or commit nested within an','line_number':249,'multiline':False]
['text':' applyOps, which is not allowed in the oplog.','line_number':250,'multiline':False]
['text':' Once we initialize the transaction iterator, we can loop back to the top in order to','line_number':253,'multiline':False]
['text':' call 'getNextTransactionOp' on it. Note that is possible for the transaction iterator','line_number':254,'multiline':False]
['text':' to be empty of any relevant operations, meaning that this loop may need to execute','line_number':255,'multiline':False]
['text':' multiple times before it encounters a relevant change to return.','line_number':256,'multiline':False]
['text':' We should never see an "abortTransaction" command at this point.','line_number':268,'multiline':False]
['text':' The lsid and txnNumber can be missing in case of batched writes.','line_number':286,'multiline':False]
['text':' We want to parse the OpTime out of this document using the BSON OpTime parser. Instead of','line_number':296,'multiline':False]
['text':' converting the entire Document back to BSON, we convert only the fields we need.','line_number':297,'multiline':False]
['text':' We found an applyOps that implicitly commits a transaction. We include it in the','line_number':313,'multiline':False]
['text':' '_txnOplogEntries' stack of applyOps entries that the change stream should process as','line_number':314,'multiline':False]
['text':' part of this transaction. There may be additional applyOps entries linked through the','line_number':315,'multiline':False]
['text':' 'prevOpTime' field, which will also get added to '_txnOplogEntries' later in this','line_number':316,'multiline':False]
['text':' function. Note that this style of transaction does not have a 'commitTransaction'','line_number':317,'multiline':False]
['text':' command.','line_number':318,'multiline':False]
['text':' This must be a "commitTransaction" command, which commits a prepared transaction.','line_number':321,'multiline':False]
['text':' This style of transaction does not have an applyOps entry that implicitly commits it,','line_number':322,'multiline':False]
['text':' as in the previous case. We're going to iterate through the other oplog entries in','line_number':323,'multiline':False]
['text':' the transaction, but this entry does not have any updates in it, so we do not include','line_number':324,'multiline':False]
['text':' it in the '_txnOplogEntries' stack.','line_number':325,'multiline':False]
['text':' We need endOfTransaction only for unprepared transactions: so this must be an applyOps with','line_number':331,'multiline':False]
['text':' set lsid and txnNumber.','line_number':332,'multiline':False]
['text':' As with the 'txnOpTime' parsing above, we convert a portion of 'input' back to BSON','line_number':339,'multiline':False]
['text':' in order to parse an OpTime, this time from the "prevOpTime" field.','line_number':340,'multiline':False]
['text':' Pop the first OpTime off the stack and use it to load the first oplog entry into the','line_number':346,'multiline':False]
['text':' '_currentApplyOps' field.','line_number':347,'multiline':False]
['text':' This transaction consists of only one oplog entry, from which we have already','line_number':353,'multiline':False]
['text':' extracted the "applyOps" array, so there is no need to do any more work.','line_number':354,'multiline':False]
['text':' This transaction consists of multiple oplog entries; grab the chronologically first','line_number':361,'multiline':False]
['text':' entry and extract its "applyOps" array.','line_number':362,'multiline':False]
['text':' Initialize iterators at the beginning of the transaction.','line_number':375,'multiline':False]
['text':' If the document is relevant, update it with the required txn fields before returning.','line_number':396,'multiline':False]
['text':' There are no more operations in this transaction.','line_number':403,'multiline':False]
['text':' We've processed all the operations in the previous applyOps entry, but we have a new','line_number':407,'multiline':False]
['text':' one to process.','line_number':408,'multiline':False]
['text':' The 'getNextTransactionOp' increments the '_txnOpIndex' by 1, to point to the next','line_number':442,'multiline':False]
['text':' transaction number. The 'txnOpIndex()' must be called to get the current transaction number.','line_number':443,'multiline':False]
['text':' The 'getNextTransactionOp' updates the '_currentApplyOpsIndex' to point to the next entry in','line_number':447,'multiline':False]
['text':' the '_currentApplyOps' array. The 'applyOpsIndex()' method must be called to get the index of','line_number':448,'multiline':False]
['text':' the current entry.','line_number':449,'multiline':False]
['text':' TODO SERVER-78670:  move namespace extraction to change_stream_helpers.cpp and make generic','line_number':503,'multiline':False]
['text':' The additional filtering added by this optimization may incorrectly filter out events if it','line_number':562,'multiline':False]
['text':' runs with the non-simple collation.','line_number':563,'multiline':False]
['text':' Seek to the stage that immediately follows the change streams stages.','line_number':568,'multiline':False]
['text':' This pipeline is just the change stream.','line_number':574,'multiline':False]
['text':' This function only attempts to optimize a $match that immediately follows expanded','line_number':580,'multiline':False]
['text':' $changeStream stages. That does not apply here, and we resume optimization at the last','line_number':581,'multiline':False]
['text':' change stream stage, in case a "swap" optimization can apply between it and the stage','line_number':582,'multiline':False]
['text':' that follows it. For example, $project stages can swap in front of the last change stream','line_number':583,'multiline':False]
['text':' stages.','line_number':584,'multiline':False]
['text':' Build a filter which discards unwound transaction operations which would have been filtered','line_number':588,'multiline':False]
['text':' out later in the pipeline by the user's $match filter.','line_number':589,'multiline':False]
['text':' Replace the default filter with the new, more restrictive one. Note that the resulting','line_number':593,'multiline':False]
['text':' expression must be serialized then deserialized to ensure it does not retain unsafe','line_number':594,'multiline':False]
['text':' references to strings in the 'matchStage' filter.','line_number':595,'multiline':False]
['text':' Continue optimization at the next change stream stage.','line_number':598,'multiline':False]
['text':' namespace mongo','line_number':601,'multiline':False]
