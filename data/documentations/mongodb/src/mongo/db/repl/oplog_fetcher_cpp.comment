['text':'*
 *    Copyright (C) 2018-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]
['text':' IWYU pragma: no_include "ext/alloc_traits.h"','line_number':40,'multiline':False]
['text':' The number and time spent reading batches off the network','line_number':132,'multiline':False]
['text':' The oplog entries read via the oplog reader','line_number':134,'multiline':False]
['text':' The bytes read via the oplog reader','line_number':136,'multiline':False]
['text':'*
 * Calculates await data timeout based on the current replica set configuration.
 ','line_number':143,'multiline':True]
['text':' Under protocol version 1, make the awaitData timeout (maxTimeMS) dependent on the election','line_number':151,'multiline':False]
['text':' timeout. This enables the sync source to communicate liveness of the primary to secondaries.','line_number':152,'multiline':False]
['text':' We never wait longer than 30 seconds.','line_number':153,'multiline':False]
['text':' namespace','line_number':156,'multiline':False]
['text':' The count of the bytes of the documents read off the network.','line_number':171,'multiline':False]
['text':' If this is the first response (to the $gte query) then we already applied the first doc.','line_number':178,'multiline':False]
['text':' Check to see if the oplog entry goes back in time for this document.','line_number':189,'multiline':False]
['text':' These numbers are for the documents we will apply.','line_number':201,'multiline':False]
['text':' The count is one less since the first document found was already applied ($gte $ts query)','line_number':205,'multiline':False]
['text':' and we will not apply it again.','line_number':206,'multiline':False]
['text':' autoReconnect ','line_number':227,'multiline':True]
['text':' Can only call this once, before startup.','line_number':244,'multiline':False]
['text':' Tests use this failpoint to prevent the oplog fetcher from starting.  If those','line_number':252,'multiline':False]
['text':' tests fail and the oplog fetcher is canceled, we want to continue so we see','line_number':253,'multiline':False]
['text':' a test failure quickly instead of a test timeout eventually.','line_number':254,'multiline':False]
['text':' setSoTimeout takes a double representing the number of seconds for send and receive','line_number':330,'multiline':False]
['text':' timeouts. Thus, we must express the timeout in milliseconds and divide by 1000.0 to get','line_number':331,'multiline':False]
['text':' the number of seconds with a fractional part.','line_number':332,'multiline':False]
['text':' If the oplog fetcher is shutting down, consolidate return code to CallbackCanceled.','line_number':351,'multiline':False]
['text':' Release any resources that might be held by the '_onShutdownCallbackFn' function object.','line_number':364,'multiline':False]
['text':' The function object will be destroyed outside the lock since the temporary variable','line_number':365,'multiline':False]
['text':' 'onShutdownCallbackFn' is declared before 'lock'.','line_number':366,'multiline':False]
['text':' Release any resources held by the OplogFetcherRestartDecision.','line_number':370,'multiline':False]
['text':' Error out if we failed to connect after exhausting the allowed retry attempts.','line_number':397,'multiline':False]
['text':' initialFind ','line_number':405,'multiline':True]
['text':' If we are a TenantOplogFetcher, we never retry as we will always restart the entire','line_number':408,'multiline':False]
['text':' TenantMigrationRecipient state machine on failure. So instead, we just fail and exit.','line_number':409,'multiline':False]
['text':' Both of these checks need to happen while holding the mutex since they could race','line_number':416,'multiline':False]
['text':' with shutdown.','line_number':417,'multiline':False]
['text':' Determine if we should stop syncing from our current sync source. If we're going','line_number':434,'multiline':False]
['text':' to change sync sources anyway, do it immediately rather than checking if we can','line_number':435,'multiline':False]
['text':' retry the error.','line_number':436,'multiline':False]
['text':' Recreate a cursor if we have enough retries left.','line_number':441,'multiline':False]
['text':' If we are a TenantOplogFetcher, we never retry as we will always restart the','line_number':442,'multiline':False]
['text':' TenantMigrationRecipient state machine on failure. So instead, we just fail and exit.','line_number':443,'multiline':False]
['text':' This will advance our view of _lastFetched.','line_number':455,'multiline':False]
['text':' The stopReplProducer fail point expects this to return successfully. If another fail','line_number':458,'multiline':False]
['text':' point wants this to return unsuccessfully, it should use a different error code.','line_number':459,'multiline':False]
['text':' Wait a little before re-running the aggregation command on the donor's','line_number':474,'multiline':False]
['text':' oplog. We are not actually intending to wait for shutdown here, we use','line_number':475,'multiline':False]
['text':' this as a way to wait while still being able to be interrupted outside of','line_number':476,'multiline':False]
['text':' primary-only service shutdown.','line_number':477,'multiline':False]
['text':' This means the sync source closes the tailable cursor with a returned cursorId of','line_number':490,'multiline':False]
['text':' 0. Any users of the oplog fetcher should create a new oplog fetcher if they see a','line_number':491,'multiline':False]
['text':' successful status and would like to continue fetching more oplog entries.','line_number':492,'multiline':False]
['text':' If this is a retry, let the DBClientConnection handle the reconnect itself','line_number':509,'multiline':False]
['text':' for proper backoff behavior.','line_number':510,'multiline':False]
['text':' Reset any state needed to track restarts on successful connection.','line_number':522,'multiline':False]
['text':' Run VectorClockMetadataHook on request metadata so this matches the behavior of','line_number':550,'multiline':False]
['text':' the connections in the replication coordinator thread pool.','line_number':551,'multiline':False]
['text':' Run VectorClockMetadataHook on reply metadata so this matches the behavior of the','line_number':559,'multiline':False]
['text':' connections in the replication coordinator thread pool.','line_number':560,'multiline':False]
['text':' explain ','line_number':572,'multiline':True]
['text':' fromMongos ','line_number':573,'multiline':True]
['text':' needsMerge ','line_number':574,'multiline':True]
['text':' allowDiskUse ','line_number':575,'multiline':True]
['text':' bypassDocumentValidation ','line_number':576,'multiline':True]
['text':' isMapReduceCommand ','line_number':577,'multiline':True]
['text':' runtimeConstants ','line_number':579,'multiline':True]
['text':' collator ','line_number':580,'multiline':True]
['text':' collUUID ','line_number':583,'multiline':True]
['text':' Match oplog entries greater than or equal to the last fetched timestamp.','line_number':585,'multiline':False]
['text':' Do another filter on the timestamp as the 'FindAndModifyImageLookup' stage can forge','line_number':591,'multiline':False]
['text':' synthetic no-op entries if the oplog corresponding to the 'startTs' is a retryable','line_number':592,'multiline':False]
['text':' 'findAndModify' entry.','line_number':593,'multiline':False]
['text':' Construct the find command's filter and set it on the 'FindCommandRequest'.','line_number':618,'multiline':False]
['text':' Handle caller-provided filter.','line_number':625,'multiline':False]
['text':' This ensures that the sync source waits for all earlier oplog writes to be visible.','line_number':655,'multiline':False]
['text':' Since Timestamp(0, 0) isn't allowed, Timestamp(0, 1) is the minimal we can use.','line_number':656,'multiline':False]
['text':' Caller-provided read concern.','line_number':661,'multiline':False]
['text':' Set the socket timeout to the 'find' timeout plus a network buffer.','line_number':670,'multiline':False]
['text':' We set 'secondaryOk'=false here to avoid duplicating OP_MSG fields since we already','line_number':676,'multiline':False]
['text':' set the request metadata readPreference to `secondaryPreferred`.','line_number':677,'multiline':False]
['text':' secondaryOk ','line_number':681,'multiline':True]
['text':' An error occurred and we should recreate the cursor.','line_number':708,'multiline':False]
['text':' The OplogFetcher uses an aggregation command in tenant migrations, which does not','line_number':709,'multiline':False]
['text':' support tailable cursors. When recreating the cursor, use the longer initial max time','line_number':710,'multiline':False]
['text':' to avoid timing out.','line_number':711,'multiline':False]
['text':' initialFind ','line_number':713,'multiline':True]
['text':' If it is the first batch, we should initialize the cursor, which will run the find query.','line_number':718,'multiline':False]
['text':' Otherwise we should call more() to get the next batch.','line_number':719,'multiline':False]
['text':' Network errors manifest as exceptions that are handled in the catch block. If init','line_number':721,'multiline':False]
['text':' returns false it means that the sync source responded with nothing, which could','line_number':722,'multiline':False]
['text':' indicate a problem with the sync source.','line_number':723,'multiline':False]
['text':' We can't call `init()` when using an aggregate command because','line_number':724,'multiline':False]
['text':' `DBClientCursor::fromAggregationRequest` will already have processed the `cursorId`.','line_number':725,'multiline':False]
['text':' Aggregate commands do not support tailable cursors outside of change streams.','line_number':733,'multiline':False]
['text':' This will also set maxTimeMS on the generated getMore command.','line_number':735,'multiline':False]
['text':' The 'find' command has already been executed, so reset the socket timeout to reflect','line_number':739,'multiline':False]
['text':' the awaitData timeout with a network buffer.','line_number':740,'multiline':False]
['text':' TODO SERVER-46240: Handle batchSize 1 in DBClientCursor.','line_number':743,'multiline':False]
['text':' Due to a bug in DBClientCursor, it actually uses batchSize 2 if the given batchSize','line_number':744,'multiline':False]
['text':' is 1 for the find command. So if the given batchSize is 1, we need to set it','line_number':745,'multiline':False]
['text':' explicitly for getMores.','line_number':746,'multiline':False]
['text':' For non-exhaust cursors, only set the lastKnownCommittedOpTime when it is not','line_number':755,'multiline':False]
['text':' a null opTime. This is to avoid sending null opTime again and again and','line_number':756,'multiline':False]
['text':' triggering oplog empty batches every single time in case we can't advance our','line_number':757,'multiline':False]
['text':' commit point (e.g. during initial sync).','line_number':758,'multiline':False]
['text':' For exhaust cursors, it is safe to set a null lastKnownCommittedOpTime in the','line_number':762,'multiline':False]
['text':' initial getMore because the sync source will update the exhaust cursor's','line_number':763,'multiline':False]
['text':' lastKnownCommittedOpTime to the commit point sent in the last response after','line_number':764,'multiline':False]
['text':' each oplog batch.','line_number':765,'multiline':False]
['text':' This value is only used on a successful batch for metrics.repl.network.getmores. This','line_number':776,'multiline':False]
['text':' metric intentionally tracks the time taken by the initial find as well.','line_number':777,'multiline':False]
['text':' Close the connection because the connection cannot be used anymore as more data is on','line_number':781,'multiline':False]
['text':' the way from the server for the exhaust stream. Thus, we have to reconnect. The','line_number':782,'multiline':False]
['text':' DBClientConnection does autoreconnect on the next network operation.','line_number':783,'multiline':False]
['text':' Stop fetching and return on fail point.','line_number':801,'multiline':False]
['text':' This fail point makes the oplog fetcher ignore the downloaded batch of operations and not','line_number':802,'multiline':False]
['text':' error out. The FailPointEnabled error will be caught by the caller.','line_number':803,'multiline':False]
['text':' Stop fetching and return when we reach a particular document. This failpoint should be used','line_number':808,'multiline':False]
['text':' with the setParameter bgSyncOplogFetcherBatchSize=1, so that documents are fetched one at a','line_number':809,'multiline':False]
['text':' time.','line_number':810,'multiline':False]
['text':' TODO SERVER-46240: Handle batchSize 1 in DBClientCursor.','line_number':825,'multiline':False]
['text':' Due to a bug in DBClientCursor, it actually uses batchSize 2 if the given','line_number':826,'multiline':False]
['text':' batchSize is 1 for the find command. So we need to check up to two documents.','line_number':827,'multiline':False]
['text':' Stop oplog fetcher and execute rollback if necessary.','line_number':865,'multiline':False]
['text':' We do not always enqueue the first document. We elect to skip it for the following','line_number':874,'multiline':False]
['text':' reasons:','line_number':875,'multiline':False]
['text':'    1. This is the first batch and no rollback is needed. Callers specify','line_number':876,'multiline':False]
['text':'       StartingPoint::kSkipFirstDoc when they want this behavior.','line_number':877,'multiline':False]
['text':'    2. We have already enqueued that document in a previous attempt. We can get into','line_number':878,'multiline':False]
['text':'       this situation if we had a batch with StartingPoint::kEnqueueFirstDoc that failed','line_number':879,'multiline':False]
['text':'       right after that first document was enqueued. In such a scenario, we would not','line_number':880,'multiline':False]
['text':'       have advanced the lastFetched opTime, so we skip past that document to avoid','line_number':881,'multiline':False]
['text':'       duplicating it.','line_number':882,'multiline':False]
['text':'    3. We have a query filter, and the first document doesn't match that filter.  This','line_number':883,'multiline':False]
['text':'       happens on the first batch when we always accept a document with the previous','line_number':884,'multiline':False]
['text':'       fetched timestamp.','line_number':885,'multiline':False]
['text':' collator ','line_number':892,'multiline':True]
['text':' This lastFetched value is the last OpTime from the previous batch.','line_number':899,'multiline':False]
['text':' If the batch is empty, set 'lastDocOpTime' to the lastFetched from the previous batch.','line_number':908,'multiline':False]
['text':' Process replset metadata.  It is important that this happen after we've validated the','line_number':911,'multiline':False]
['text':' first batch, so we don't progress our knowledge of the commit point from a','line_number':912,'multiline':False]
['text':' response that triggers a rollback.','line_number':913,'multiline':False]
['text':' Determine if we should stop syncing from our current sync source.','line_number':925,'multiline':False]
['text':' Increment stats. We read all of the docs in the query.','line_number':944,'multiline':False]
['text':' Start skipping the first doc after at least one doc has been enqueued in the lifetime','line_number':974,'multiline':False]
['text':' of this fetcher.','line_number':975,'multiline':False]
['text':' We have now processed the batch. We should only move forward our view of _lastFetched if the','line_number':978,'multiline':False]
['text':' batch was not empty.','line_number':979,'multiline':False]
['text':' Once we establish our cursor, if we use rollback-via-refetch, we need to ensure that our','line_number':999,'multiline':False]
['text':' upstream node hasn't rolled back since that could cause it to not have our required minValid','line_number':1000,'multiline':False]
['text':' point. The cursor will be killed if the upstream node rolls back so we don't need to keep','line_number':1001,'multiline':False]
['text':' checking once the cursor is established. If we do not use rollback-via-refetch, this check is','line_number':1002,'multiline':False]
['text':' not necessary, and _config.requiredRBID will be set to kUninitializedRollbackId in that case.','line_number':1003,'multiline':False]
['text':' Set _receivedRBID to remoteRBID so that it can be returned when the oplog fetcher shuts down.','line_number':1010,'multiline':False]
['text':' Sometimes our remoteLastOpApplied may be stale; if we received a document with an','line_number':1013,'multiline':False]
['text':' opTime later than remoteLastApplied, we can assume the remote is at least up to that','line_number':1014,'multiline':False]
['text':' opTime.','line_number':1015,'multiline':False]
['text':' The sync source could be behind us if it rolled back after we selected it. We could have','line_number':1025,'multiline':False]
['text':' failed to detect the rollback if it occurred between sync source selection (when we check the','line_number':1026,'multiline':False]
['text':' candidate is ahead of us) and sync source resolution (when we got '_receivedRBID'). If the','line_number':1027,'multiline':False]
['text':' sync source is now behind us, choose a new sync source to prevent going into rollback.','line_number':1028,'multiline':False]
['text':' If '_requireFresherSyncSource' is true, we must check that the sync source's','line_number':1036,'multiline':False]
['text':' lastApplied is ahead of us to prevent forming a cycle. Although we check for','line_number':1037,'multiline':False]
['text':' this condition in sync source selection, if an undetected rollback occurred between sync','line_number':1038,'multiline':False]
['text':' source selection and sync source resolution, this condition may no longer hold.','line_number':1039,'multiline':False]
['text':' '_requireFresherSyncSource' is false for initial sync, since no other node can sync off an','line_number':1040,'multiline':False]
['text':' initial syncing node, so we do not need to check for cycles. In addition, it would be','line_number':1041,'multiline':False]
['text':' problematic to check this condition for initial sync, since the 'lastFetched' OpTime will','line_number':1042,'multiline':False]
['text':' almost always equal the 'remoteLastApplied', since we fetch the sync source's last applied','line_number':1043,'multiline':False]
['text':' OpTime to determine where to start our OplogFetcher.','line_number':1044,'multiline':False]
['text':' At this point we know that our sync source has our minValid and is not behind us, so if our','line_number':1053,'multiline':False]
['text':' history diverges from our sync source's we should prefer its history and roll back ours.','line_number':1054,'multiline':False]
['text':' Since we checked for rollback and our sync source is ahead of us, an empty batch means that','line_number':1056,'multiline':False]
['text':' we have a higher timestamp on our last fetched OpTime than our sync source's last applied','line_number':1057,'multiline':False]
['text':' OpTime, but a lower term. When this occurs, we must roll back our inconsistent oplog entry.','line_number':1058,'multiline':False]
['text':' We should never return an OK status here.','line_number':1077,'multiline':False]
['text':' Check to see if the sync source's first oplog entry is later than 'lastFetched'. If it is, we','line_number':1086,'multiline':False]
['text':' are too stale to sync from this node. If it isn't, we should go into rollback instead.','line_number':1087,'multiline':False]
['text':' Query for the first oplog entry in the sync source's oplog.','line_number':1090,'multiline':False]
['text':' Since this function is called after the first batch, the exhaust stream has not been','line_number':1093,'multiline':False]
['text':' started yet. As a result, using the same connection is safe.','line_number':1094,'multiline':False]
['text':' If an error occurs with the query, throw an error.','line_number':1097,'multiline':False]
['text':' remoteFirstOpTime may come from a very old config, so we cannot compare their terms.','line_number':1118,'multiline':False]
['text':' We are too stale to sync from our current sync source.','line_number':1120,'multiline':False]
['text':' If we are not too stale to sync from the source, we should go into rollback.','line_number':1128,'multiline':False]
['text':' If we try to sync from a node that is shutting down, do not attempt to reconnect.','line_number':1138,'multiline':False]
['text':' We should choose a new sync source.','line_number':1139,'multiline':False]
['text':' namespace repl','line_number':1167,'multiline':False]
['text':' namespace mongo','line_number':1168,'multiline':False]
