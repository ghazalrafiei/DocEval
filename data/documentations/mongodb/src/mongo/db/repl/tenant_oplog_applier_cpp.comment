['text':'*
 *    Copyright (C) 2020-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]
['text':' IWYU pragma: no_include "ext/alloc_traits.h"','line_number':40,'multiline':False]
['text':' Final applyOp for a transaction.','line_number':105,'multiline':False]
['text':' If it has a statement id but isn't a transaction, it's a retryable write.','line_number':112,'multiline':False]
['text':' There are two types of no-ops we expect here. One is pre/post image, which will have an empty','line_number':116,'multiline':False]
['text':' o2 field. The other is previously transformed retryable write entries from earlier','line_number':117,'multiline':False]
['text':' migrations, which we should avoid re-wrapping.','line_number':118,'multiline':False]
['text':' Since multi-tenant migration uses logical cloning, the oplog entries will be','line_number':157,'multiline':False]
['text':' applied on a inconsistent copy of donor data. Hence, using','line_number':158,'multiline':False]
['text':' OplogApplication::Mode::kInitialSync.','line_number':159,'multiline':False]
['text':' Since shard merge  uses backup cursor for database cloning and tenant oplog','line_number':162,'multiline':False]
['text':' catchup phase is not resumable on failovers, the oplog entries will be applied','line_number':163,'multiline':False]
['text':' on a consistent copy of donor data. Hence, using','line_number':164,'multiline':False]
['text':' OplogApplication::Mode::kSecondary.','line_number':165,'multiline':False]
['text':' If we're not running, return a future with the status we shut down with.','line_number':187,'multiline':False]
['text':' If this optime has already passed, just return a ready future.','line_number':191,'multiline':False]
['text':' This will pull a new future off the existing promise for this time if it exists, otherwise','line_number':197,'multiline':False]
['text':' it constructs a new promise and pulls a future off of it.','line_number':198,'multiline':False]
['text':' Shutting down the oplog batcher will make the _applyLoop stop with an error future, thus','line_number':236,'multiline':False]
['text':' shutting down the applier.','line_number':237,'multiline':False]
['text':' Oplog applier executor can shutdown before executing _applyLoop() and shouldStopApplying().','line_number':239,'multiline':False]
['text':' This can cause the applier to miss notifying the waiters in _opTimeNotificationList. So,','line_number':240,'multiline':False]
['text':' shutdown() is responsible to notify those waiters when _applyLoop() is not running.','line_number':241,'multiline':False]
['text':' We actually hold the required lock, but the lock object itself is not passed through.','line_number':243,'multiline':False]
['text':' Applier is not active as someone might have called shutdown().','line_number':258,'multiline':False]
['text':' Getting the future for the next batch here means the batcher can retrieve the next batch','line_number':264,'multiline':False]
['text':' while the applier is processing the current one.','line_number':265,'multiline':False]
['text':' Set the _finalStatus. This guarantees that the shutdown() called after releasing','line_number':308,'multiline':False]
['text':' the mutex will signal donor opTime waiters with the 'status' error code and not with','line_number':309,'multiline':False]
['text':' ErrorCodes::CallbackCanceled.','line_number':310,'multiline':False]
['text':' shouldStopApplying() might have already set the final status. So, don't mask the original','line_number':334,'multiline':False]
['text':' error.','line_number':335,'multiline':False]
['text':' Any unfulfilled notifications are errored out.','line_number':345,'multiline':False]
['text':' Make sure all the workers succeeded.','line_number':380,'multiline':False]
['text':' If the batch contains only resume token no-ops, then the last batch completed','line_number':402,'multiline':False]
['text':' recipient optime returned will be null.','line_number':403,'multiline':False]
['text':' Notify all the waiters on optimes before and including _lastAppliedOpTimesUpToLastBatch.','line_number':418,'multiline':False]
['text':' Shard merge protocol checks the namespace and UUID when ops are assigned to writer pool.','line_number':442,'multiline':False]
['text':' namespace','line_number':506,'multiline':False]
['text':' Out-of-order processing within a migration lifetime is not possible,','line_number':568,'multiline':False]
['text':' except in recipient failovers. However, merge and tenant migration','line_number':569,'multiline':False]
['text':' are not resilient to recipient failovers. If attempted, beginOrContinue()','line_number':570,'multiline':False]
['text':' will throw ErrorCodes::TransactionTooOld.','line_number':571,'multiline':False]
['text':' autocommit ','line_number':574,'multiline':True]
['text':' startTransaction ','line_number':575,'multiline':True]
['text':' We can end up here under the following circumstances:','line_number':578,'multiline':False]
['text':' 1) LastWriteOpTime is not null.','line_number':579,'multiline':False]
['text':'    - During a back-to-back migration (rs0->rs1->rs0) or a migration retry,','line_number':580,'multiline':False]
['text':'      when 'txnNum'== txnParticipant.o().activeTxnNumber and rs0 already has','line_number':581,'multiline':False]
['text':'      the oplog chain.','line_number':582,'multiline':False]
['text':'','line_number':583,'multiline':False]
['text':' 2) LastWriteOpTime is null.','line_number':584,'multiline':False]
['text':'    - During a back-to-back migration (rs0->rs1->rs0) when','line_number':585,'multiline':False]
['text':'      'txnNum' < txnParticipant.o().activeTxnNumber and last activeTxnNumber corresponds','line_number':586,'multiline':False]
['text':'      to a no-op session write, like, no-op retryable update, read transaction, etc.','line_number':587,'multiline':False]
['text':'    - New session with no transaction started yet on this node (this will be a no-op).','line_number':588,'multiline':False]
['text':' Reset the statements executed list in the txnParticipant.','line_number':596,'multiline':False]
['text':' autocommit ','line_number':602,'multiline':True]
['text':' startTransaction ','line_number':603,'multiline':True]
['text':' Reset the retryable write history chain.','line_number':605,'multiline':False]
['text':' We should never process the same donor statement twice, except in failover','line_number':609,'multiline':False]
['text':' cases where we'll also have "forgotten" the statement was executed.','line_number':610,'multiline':False]
['text':' Set sessionId, txnNumber, and statementId for all ops in a retryable write.','line_number':618,'multiline':False]
['text':' set fromMigrate on the no-op so the session update tracker recognizes it.','line_number':623,'multiline':False]
['text':' Use the same wallclock time as the noop entry.  The lastWriteOpTime will be filled','line_number':626,'multiline':False]
['text':' in after the no-op is written.','line_number':627,'multiline':False]
['text':' If we have a prePostImage no-op without the original entry, do not write it. This can','line_number':631,'multiline':False]
['text':' happen in some very unlikely rollback situations.','line_number':632,'multiline':False]
['text':' We should only write the noop entry for this transaction commit once.','line_number':668,'multiline':False]
['text':' Only set sessionId, txnNumber and txnRetryCounter for the final applyOp in a','line_number':679,'multiline':False]
['text':' transaction.','line_number':680,'multiline':False]
['text':' Write a fake applyOps with the tenantId as the namespace so that this will be picked','line_number':685,'multiline':False]
['text':' up by the committed transaction prefetch pipeline in subsequent migrations.','line_number':686,'multiline':False]
['text':'','line_number':687,'multiline':False]
['text':' Unlike MTM, shard merge copies all tenants from the donor. This means that merge does','line_number':688,'multiline':False]
['text':' not need to filter prefetched committed transactions by tenantId. As a result,','line_number':689,'multiline':False]
['text':' setting a nss containing the tenantId for the fake transaction applyOps entry isn't','line_number':690,'multiline':False]
['text':' necessary.','line_number':691,'multiline':False]
['text':' Use the same wallclock time as the noop entry.','line_number':697,'multiline':False]
['text':' Group donor oplog entries from the same session together.','line_number':710,'multiline':False]
['text':' All other oplog entries.','line_number':712,'multiline':False]
['text':' The 'opCtx' must be interruptible on stepdown and stepup to avoid a deadlock situation with','line_number':715,'multiline':False]
['text':' the RSTL.','line_number':716,'multiline':False]
['text':' Prevent the node from being able to change state when reserving oplog slots and writing','line_number':719,'multiline':False]
['text':' entries.','line_number':720,'multiline':False]
['text':' We start WriteUnitOfWork only to reserve oplog slots. So, it's ok to abort the','line_number':723,'multiline':False]
['text':' WriteUnitOfWork when it goes out of scope.','line_number':724,'multiline':False]
['text':' Reserve oplog slots for all entries.  This allows us to write them in parallel.','line_number':726,'multiline':False]
['text':' Keep track of the greatest oplog slot actually used, ignoring resume token noops. This is','line_number':728,'multiline':False]
['text':' what we want to return from this function.','line_number':729,'multiline':False]
['text':' Since we won't apply resume token noop oplog entries and internal collection','line_number':734,'multiline':False]
['text':' oplog entries (for shard merge protocol), we do not want to set the recipient optime','line_number':735,'multiline':False]
['text':' for them.','line_number':736,'multiline':False]
['text':' Group oplog entries from the same session for noop writes.','line_number':741,'multiline':False]
['text':' Vector to store errors from each writer thread. The first numOplogThreads entries store','line_number':771,'multiline':False]
['text':' errors from the noop writes for non-session oplog entries. And the rest store errors from the','line_number':772,'multiline':False]
['text':' noop writes for each session in the batch.','line_number':773,'multiline':False]
['text':' Dispatch noop writes for non-session oplog entries into numOplogThreads writer threads.','line_number':776,'multiline':False]
['text':' Dispatch noop writes for oplog entries from the same session into the same writer thread.','line_number':800,'multiline':False]
['text':' Make sure all the workers succeeded.','line_number':821,'multiline':False]
['text':' Write the pre/post image entry, if it exists.','line_number':856,'multiline':False]
['text':' Write the noop entry and update config.transactions.','line_number':859,'multiline':False]
['text':' Since the client object persists across each noop write call and the same writer thread could','line_number':877,'multiline':False]
['text':' be reused to write noop entries with older optime, we need to clear the lastOp associated','line_number':878,'multiline':False]
['text':' with the client to avoid the invariant in replClientInfo::setLastOp that the optime only goes','line_number':879,'multiline':False]
['text':' forward.','line_number':880,'multiline':False]
['text':' All the ops will have the same session, so we can retain the scopedSession throughout','line_number':885,'multiline':False]
['text':' the loop, except when invalidated by multi-document transactions. This allows us to','line_number':886,'multiline':False]
['text':' track the statements in a retryable write.','line_number':887,'multiline':False]
['text':' Make sure a partial session doesn't escape.','line_number':890,'multiline':False]
['text':' Empty 'o' field.','line_number':910,'multiline':False]
['text':' entry.getEntry().toBSON() is the pre- or post-image in BSON format.','line_number':928,'multiline':False]
['text':' Clear the old tenant migration UUID.','line_number':936,'multiline':False]
['text':' Don't write the no-op entry, both the no-op entry and prePostImage entry will be','line_number':938,'multiline':False]
['text':' written on the next iteration.','line_number':939,'multiline':False]
['text':' entry.getEntry().toBSON() is the original migrated no-op in BSON format.','line_number':948,'multiline':False]
['text':' Clear the old tenant migration UUID.','line_number':952,'multiline':False]
['text':' Set the inner 'o2' optime to the donor entry's optime because the recipient','line_number':955,'multiline':False]
['text':' uses the timestamp in 'o2' to determine where to resume applying from.','line_number':956,'multiline':False]
['text':' Handle as for kOplogEntryTypeRetryableWrite after extracting original op.','line_number':962,'multiline':False]
['text':' Check out the session.','line_number':994,'multiline':False]
['text':' If we have a prePostImage no-op here that hasn't already been logged, it is orphaned;','line_number':1008,'multiline':False]
['text':' this can happen in some very unlikely rollback situations. Otherwise, the image entry','line_number':1009,'multiline':False]
['text':' should have been written at this point so we need to reset it for the next iteration.','line_number':1010,'multiline':False]
['text':' Invalidate in-memory state so that the next time the session is checked out, it','line_number':1013,'multiline':False]
['text':' would reload the transaction state from config.transactions.','line_number':1014,'multiline':False]
['text':' Since the client object persists across each noop write call and the same writer thread could','line_number':1031,'multiline':False]
['text':' be reused to write noop entries with older optime, we need to clear the lastOp associated','line_number':1032,'multiline':False]
['text':' with the client to avoid the invariant in replClientInfo::setLastOp that the optime only goes','line_number':1033,'multiline':False]
['text':' forward.','line_number':1034,'multiline':False]
['text':' We don't want to write noops for resume token noop oplog entries. They would','line_number':1047,'multiline':False]
['text':' not be applied in a change stream anyways.','line_number':1048,'multiline':False]
['text':' We don't need to link no-ops entries for operations done outside of a session.','line_number':1051,'multiline':False]
['text':' Empty 'o' field.','line_number':1059,'multiline':False]
['text':' We link the no-ops together by recipient op time the same way the actual ops','line_number':1061,'multiline':False]
['text':' were linked together by donor op time.  This is to allow retryable writes','line_number':1062,'multiline':False]
['text':' and changestreams to find the ops they need.','line_number':1063,'multiline':False]
['text':' Determine all involved tenants.','line_number':1076,'multiline':False]
['text':' Acquire a lock for each tenant.','line_number':1092,'multiline':False]
['text':' If the operation's optime is before or the same as the startApplyingAfterOpTime we don't','line_number':1107,'multiline':False]
['text':' want to apply it, so don't include it in writerVectors.','line_number':1108,'multiline':False]
['text':' We never need to apply no-ops or partial transactions.','line_number':1118,'multiline':False]
['text':' This is an applyOps or transaction; add the expansions to the writer vectors.','line_number':1123,'multiline':False]
['text':' If the transaction contains a command, serialize the operations.','line_number':1144,'multiline':False]
['text':' serial ','line_number':1157,'multiline':True]
['text':' Add a single op to the writer vectors.','line_number':1163,'multiline':False]
['text':' We must ensure the opCtx uses replicated writes, because that will ensure we get a','line_number':1176,'multiline':False]
['text':' NotWritablePrimary error if a stepdown occurs.','line_number':1177,'multiline':False]
['text':' During tenant migration oplog application, we only need to apply createIndex on empty','line_number':1201,'multiline':False]
['text':' collections. Otherwise, the index is guaranteed to be dropped after. This is because','line_number':1202,'multiline':False]
['text':' we block index builds on the donor for the duration of the tenant migration.','line_number':1203,'multiline':False]
['text':' If the collection doesn't exist, it is safe to ignore.','line_number':1214,'multiline':False]
['text':' We don't count tenant application in the ops applied stats.','line_number':1218,'multiline':False]
['text':' opCounters','line_number':1226,'multiline':True]
['text':'  isKillableByStepdown ','line_number':1271,'multiline':True]
['text':' namespace repl','line_number':1274,'multiline':False]
['text':' namespace mongo','line_number':1275,'multiline':False]
