['text':'*
 *    Copyright (C) 2022-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]
['text':'*
 * A callback function to return a 'CardinalityEstimator' of a specific type. Used with the
 * 'Benchmark' class implementations to specify which estimation method to benchmark.
 ','line_number':72,'multiline':True]
['text':'*
 * A map between measured metrics (such as "optimize" method or "deriveCE") and a vector of time
 * series holding elapsed execution time for each metric. A benchmark is executed a number of
 * iterations, and during each iteration each metric could be collected multiple times (as a
 * corresponding method could be invoked multiple times). For instance, if the number of iterations
 * was 2, and "deriveCE" method was called 3 times, then one entry in this map might look as
 follows:

 *    "deriveCE" => [12, 11, 10, 12, 14, 16]
 ','line_number':79,'multiline':True]
['text':'*
 * When generating histograms for a benchmark, this is used to define which type of data be to put
 * into histogram buckets.
 ','line_number':91,'multiline':True]
['text':'*
 * A utility function to return a string holding a name of the given ABT node.
 ','line_number':104,'multiline':True]
['text':'*
 * Returns a factory function to create a histograms-based estimator using a provided collection
 * statistics.
 ','line_number':112,'multiline':True]
['text':'*
 * Returns a factory function to create a heuristics based estimator.
 ','line_number':123,'multiline':True]
['text':'*
 * Contains various parameters describing the setup under which a particular benchmark is to be
 * executed. Used to report the results of the benchmark.
 ','line_number':132,'multiline':True]
['text':'*
     * The number of times to repeat the benchmark.
     ','line_number':139,'multiline':True]
['text':'*
     * The number of buckets per a generated  histogram.
     ','line_number':144,'multiline':True]
['text':'*
     * A map between field paths and value types enum indicating which values to be put in a
     * histogram for this path.
     ','line_number':149,'multiline':True]
['text':'*
     * A collection metadata describing indexes defined on the collection. Stored as a map between
     * an index name and 'IndexDefinition' object.
     ','line_number':155,'multiline':True]
['text':'*
     * The number of individual (atom) predicates in a benchmark query.
     ','line_number':161,'multiline':True]
['text':'*
 * Some benchamrk parameters can only be computed in runtime based on the provided static parameters
 * specified in a 'BenchmarkDescriptor'. For example, a total size of the generated historgrams.
 * This struct will hold such parameters for each individual benchmark.
 ','line_number':167,'multiline':True]
['text':'*
     * Runtime parameters per field path.
     ','line_number':173,'multiline':True]
['text':'*
 * This class holds the results of an execution of a single CE benchmark. Given a query and certain
 * input parameters (such as collection statistics) a typical benchmark will run a number of
 * experiments to measure execution time (or time metrics) across different optimizer phases, using
 * different estimation methods, using different granularity (e.g., total time vs time per specific
 * ABT node). All collected data will be stored in this result class.
 *
 * Here is an example of what it may look like:
 *
 *      benchmarkName: "BucketSmallNumberSmallSize"
 *      numIterations: 100
 *      results:
 *          "heuristics":
 *               "optimize": [1200, 1215, 1210, ...]
 *               "deriveCE": [200, 210, 215, 210, 211, ...]
 *               "deriveCE_Sargable": [1000, 950, 1100, ...]
 *               "deriveCE_Scan": [100, 120, 115, ...]
 *          "histograms":
 *               "optimize": [1300, 1315, 1310, ...]
 *               "deriveCE": [300, 310, 315, 310, 311, ...]
 *               "deriveCE_Sargable": [1100, 990, 1150, ...]
 *               "deriveCE_Scan": [200, 220, 215, ...]
 *
 * The class also provides methods to serialize aggregated data into different formats, such as
 * plain string or BSON. For each metric under each estimation method the output will contain the
 * following aggregated data:
 *
 *          "heuristics":
 *                "optimize":
 *                      "totalTime": 445565
 *                      "minTime": 4427
 *                      "maxTime": 4758
 *                      "avgTime": 4455
 *                      "calls": 100
 *                "deriveCE":
 *                      "totalTime": 25098
 *                      "minTime": 13
 *                      "maxTime": 86
 *                      "avgTime": 35
 *                      "calls": 700
 *
 * Where,
 *    - totalTime - total execution time for a metric (method) across all iterations
 *    - minTime - min execution time for a metric across all iterations
 *    - maxTime - max execution time for a specific metric across all iterations
 *    - avgTime - average execution time for a specific metric across all iterations (totalTme /
 *                calls)
 *    - calls - a total number of calls of a specific method across all iterations. E.g., if
 *              the number of iterations per benchmark was 100 and in each iteration the
 *              "deriveCE_Scan" method was called 7 times, the reported "calls" metric will be 700.
 *
 * Note that presently we do not distinguish between different instances of ABT types. For instance,
 * if there were two Scan nodes in the plan, their data points will be collected under a single
 * "deriveCE_Scan" metric.
 ','line_number':195,'multiline':True]
['text':'*
     * Adds time metrics for the given cardinally 'estimationType' to this results instance.
     * This method can be called multiple times during execution of a particular CE benchmark,
     * so the results for each 'estimationType' are merged together. For instance, a benchmark
     * could collected time metrics for the "optimize" methods of the "heuristics" estimation
     * and put them into a 'BenchmarkResults' object, and then run another experiment to collect
     * various "deriveCE" metrics for the same estimation method. When 'addTimeMetrics' is called
     * for the second time, the result is merged with the previously stored metrics for the
     * "heuristics" estimation type.
     ','line_number':263,'multiline':True]
['text':'*
     * Serializes aggregated results of the benchmark into a BSON object.
     ','line_number':277,'multiline':True]
['text':'*
     * Serializes aggregated results of the benchmark into a plan string.
     ','line_number':282,'multiline':True]
['text':'*
     * The returned DurationType values correspond to total, min, max, avg times aggregated from
     * the given 'times' array, with the last parameter being the number of calls performed to
     * collect the times.
     ','line_number':290,'multiline':True]
['text':'*
 * This interface defines an aggregator for 'BenchmarkResults'. Each CE benchmark will produce a
 * 'BenchmarkResults' holding the results of the experiment. Rather than dumping this result
 * straight into console, we will store it within a specific 'BenchmarkResultsAggregator' and output
 * all results at once at the end of the test in a configured format. A deferred output will not
 * interfere with the output of the test framework, making it easier to interpret the results
 * without test noise.
 ','line_number':303,'multiline':True]
['text':'*
 * A benchmark results aggregator which wil output the results as a BSON array of serialized
 * 'BenchmarkResults' objects.
 ','line_number':320,'multiline':True]
['text':'pretty','line_number':332,'multiline':True]
['text':'isArray','line_number':332,'multiline':True]
['text':'*
 * A benchmark results aggregator which wil output the results as a plain text. The results of each
 * benchmark will output on a new line.
 ','line_number':340,'multiline':True]
['text':'*
 * A base class to implement a CE benchmark. It provides a 'runBenchmark' method which takes a
 * pipeline (representing as a raw string) and a 'numIterations' parameter to indicate how many
 * times to run the benchmark. On each iteration the pipeline is translated into an ABT and
 * 'CETester::getCE' is called. Specially crafted CE benchmarks will measure execution of different
 * phases of the optimizer and collect metrics. This class provides helper utilities to obtain
 * a 'ScopedTimer' and collect metrics within a 'TimeMetrics' instances, which can be obtained once
 * the benchmark is completed.
 *
 * Note that CE benchmarks are implemented using an ad-hoc benchmark facility, rather than the
 * standard Google benchmark framework. This was done so as Google benchmark doesn't fit for purpose
 * in this particular case, since it was designed to measure an overall execution time of a
 * particular function. So, it would suite fine if we wanted to benchmark just the
 * 'OptPhaseManager::optimize' call. However, we're also interested in benchmarking just the CE
 * module which is invoked many times during 'optimize' without including any other overhead, so
 * we had to hand craft this framework for CE benchmarks.
 ','line_number':360,'multiline':True]
['text':'*
     * Executes 'getCE' method 'numIterations' number of times on an ABT translated from the
     * given pipeline. Collected time merics can be obtained with 'extractTimeMetrics' at the
     * end of the benchmark run.
     ','line_number':381,'multiline':True]
['text':'*
     * Returns time metrics collected during the benchmark run. This is a destructive method as
     * the metrics are extracted (moved) from the internal state of this instance.
     ','line_number':388,'multiline':True]
['text':'*
 * This CardinalityEstimator implementation is a wrapper around a specific CardinalityEstimator
 * passed to this object during construction. Its purpose is to override the 'deriveCE' method
 * to measure execution time of the wrapped estimator and save collected time metrics within the
 * provided 'Benchmark' instance.
 ','line_number':412,'multiline':True]
['text':' Collect total 'deriveCE' time.','line_number':425,'multiline':False]
['text':'*
 * A CE benchmark designed to measure execution time of the 'OptPhaseManager::optimize' method.
 * A cardinally estimation method to be used during this benchmark is specified with the
 * 'CardinalityEstimatorFactoryFn' passed to the constructor.
 ','line_number':441,'multiline':True]
['text':'forValidation','line_number':457,'multiline':True]
['text':'*
 * A CE benchmark designed to measure execution time spent in CE module. A cardinally estimation
 * method to be used during this benchmark is specified with the 'CardinalityEstimatorFactoryFn'
 * passed to the constructor.
 ','line_number':465,'multiline':True]
['text':' namespace mongo::optimizer::ce','line_number':488,'multiline':False]
