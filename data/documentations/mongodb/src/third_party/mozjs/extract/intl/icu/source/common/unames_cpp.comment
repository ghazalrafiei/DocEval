['text':' Â© 2016 and later: Unicode, Inc. and others.','line_number':1,'multiline':False]
['text':' License & terms of use: http://www.unicode.org/copyright.html','line_number':2,'multiline':False]
['text':'
******************************************************************************
*
*   Copyright (C) 1999-2014, International Business Machines
*   Corporation and others.  All Rights Reserved.
*
******************************************************************************
*   file name:  unames.c
*   encoding:   UTF-8
*   tab size:   8 (not used)
*   indentation:4
*
*   created on: 1999oct04
*   created by: Markus W. Scherer
','line_number':3,'multiline':True]
['text':' prototypes ------------------------------------------------------------- ','line_number':36,'multiline':True]
['text':'
 * This struct was replaced by explicitly accessing equivalent
 * fields from triples of uint16_t.
 * The Group struct was padded to 8 bytes on compilers for early ARM CPUs,
 * which broke the assumption that sizeof(Group)==6 and that the ++ operator
 * would advance by 6 bytes (3 uint16_t).
 *
 * We can't just change the data structure because it's loaded from a data file,
 * and we don't want to make it less compact, so we changed the access code.
 *
 * For details see ICU tickets 6331 and 6008.
typedef struct {
    uint16_t groupMSB,
             offsetHigh, offsetLow; / * avoid padding * /
} Group;
 ','line_number':45,'multiline':True]
['text':'
 * Get the 32-bit group offset.
 * @param group (const uint16_t *) pointer to a Group triple of uint16_t
 * @return group offset (int32_t)
 ','line_number':68,'multiline':True]
['text':'
 * Get the groups table from a UCharNames struct.
 * The groups table consists of one uint16_t groupCount followed by
 * groupCount groups. Each group is a triple of uint16_t, see GROUP_LENGTH
 * and the comment for the old struct Group above.
 *
 * @param names (const UCharNames *) pointer to the UCharNames indexes
 * @return (const uint16_t *) pointer to the groups table
 ','line_number':88,'multiline':True]
['text':'
 * Maximum length of character names (regular & 1.0).
 ','line_number':110,'multiline':True]
['text':'
 * Set of chars used in character names (regular & 1.0).
 * Chars are platform-dependent (can be EBCDIC).
 ','line_number':115,'multiline':True]
['text':' implementation ----------------------------------------------------------- ','line_number':163,'multiline':True]
['text':'context','line_number':180,'multiline':True]
['text':'type','line_number':181,'multiline':True]
['text':'name','line_number':181,'multiline':True]
['text':' dataFormat="unam" ','line_number':187,'multiline':True]
['text':'
 * Important: expandName() and compareName() are almost the same -
 * apply fixes to both.
 *
 * UnicodeData.txt uses ';' as a field separator, so no
 * field can contain ';' as part of its contents.
 * In unames.dat, it is marked as token[';']==-1 only if the
 * semicolon is used in the data file - which is iff we
 * have Unicode 1.0 names or ISO comments or aliases.
 * So, it will be token[';']==-1 if we store U1.0 names/ISO comments/aliases
 * although we know that it will never be part of a name.
 ','line_number':225,'multiline':True]
['text':'
         * skip the modern name if it is not requested _and_
         * if the semicolon byte value is a character, not a token number
         ','line_number':247,'multiline':True]
['text':'
             * the semicolon byte value is a token number, therefore
             * only modern names are stored in unames.dat and there is no
             * such requested alternate name here
             ','line_number':262,'multiline':True]
['text':' write each letter directly, and write a token word per token ','line_number':271,'multiline':True]
['text':' implicit letter ','line_number':278,'multiline':True]
['text':' finished ','line_number':281,'multiline':True]
['text':' this is a lead byte for a double-byte token ','line_number':287,'multiline':True]
['text':' explicit letter ','line_number':293,'multiline':True]
['text':' stop, but skip the semicolon if we are seeking
                       extended names and there was no 2.0 name but there
                       is a 1.0 name. ','line_number':296,'multiline':True]
['text':' finished ','line_number':304,'multiline':True]
['text':' write token word ','line_number':308,'multiline':True]
['text':' zero-terminate ','line_number':317,'multiline':True]
['text':'
 * compareName() is almost the same as expandName() except that it compares
 * the currently expanded name to an input name.
 * It returns the match/no match result as soon as possible.
 ','line_number':325,'multiline':True]
['text':'
         * skip the modern name if it is not requested _and_
         * if the semicolon byte value is a character, not a token number
         ','line_number':341,'multiline':True]
['text':'
             * the semicolon byte value is a token number, therefore
             * only modern names are stored in unames.dat and there is no
             * such requested alternate name here
             ','line_number':356,'multiline':True]
['text':' compare each letter directly, and compare a token word per token ','line_number':365,'multiline':True]
['text':' implicit letter ','line_number':372,'multiline':True]
['text':' finished ','line_number':377,'multiline':True]
['text':' this is a lead byte for a double-byte token ','line_number':383,'multiline':True]
['text':' explicit letter ','line_number':389,'multiline':True]
['text':' stop, but skip the semicolon if we are seeking
                       extended names and there was no 2.0 name but there
                       is a 1.0 name. ','line_number':394,'multiline':True]
['text':' finished ','line_number':402,'multiline':True]
['text':' write token word ','line_number':406,'multiline':True]
['text':' complete match? ','line_number':417,'multiline':True]
['text':' Return unknown if the table of names above is not up to
       date. ','line_number':438,'multiline':True]
['text':'
 * getGroup() does a binary search for the group that contains the
 * Unicode code point "code".
 * The return value is always a valid Group* that may contain "code"
 * or else is the highest group before "code".
 * If the lowest group is after "code", then that one is returned.
 ','line_number':475,'multiline':True]
['text':' binary search for the group of names that contains the one for code ','line_number':490,'multiline':True]
['text':' return this regardless of whether it is an exact match ','line_number':500,'multiline':True]
['text':'
 * expandGroupLengths() reads a block of compressed lengths of 32 strings and
 * expands them into offsets and lengths for each string.
 * Lengths are stored with a variable-width encoding in consecutive nibbles:
 * If a nibble<0xc, then it is the length itself (0=empty string).
 * If a nibble>=0xc, then it forms a length value with the following nibble.
 * Calculation see below.
 * The offsets and lengths arrays must be at least 33 (one more) long because
 * there is no check here at the end if the last nibble is still used.
 ','line_number':504,'multiline':True]
['text':' read the lengths of the 32 strings in this group and get each string's offset ','line_number':517,'multiline':True]
['text':' all 32 lengths must be read to get the offset of the first group string ','line_number':521,'multiline':True]
['text':' read even nibble - MSBs of lengthByte ','line_number':525,'multiline':True]
['text':' double-nibble length spread across two bytes ','line_number':527,'multiline':True]
['text':' &0xf0 ','line_number':530,'multiline':True]
['text':' double-nibble length spread across this one byte ','line_number':531,'multiline':True]
['text':' single-nibble length in MSBs ','line_number':534,'multiline':True]
['text':' read odd nibble - LSBs of lengthByte ','line_number':545,'multiline':True]
['text':' this nibble was not consumed for a double-nibble length above ','line_number':547,'multiline':True]
['text':' single-nibble length in LSBs ','line_number':550,'multiline':True]
['text':' prevent double-nibble detection in the next iteration ','line_number':558,'multiline':True]
['text':' now, s is at the first group string ','line_number':562,'multiline':True]
['text':' group not found ','line_number':585,'multiline':True]
['text':' zero-terminate ','line_number':586,'multiline':True]
['text':'
 * enumGroupNames() enumerates all the names in a 32-group
 * and either calls the enumerator function or finds a given input name.
 ','line_number':594,'multiline':True]
['text':' here, we assume that the buffer is large enough ','line_number':616,'multiline':True]
['text':'
 * enumExtNames enumerate extended names.
 * It only needs to do it if it is called with a real function and not
 * with the dummy DO_FIND_NAME, because u_charFromName() does a check
 * for extended names by itself.
 ','line_number':637,'multiline':True]
['text':' here, we assume that the buffer is large enough ','line_number':653,'multiline':True]
['text':' find the group that contains start, or the highest before it ','line_number':677,'multiline':True]
['text':' enumerate synthetic names between start and the group start ','line_number':681,'multiline':True]
['text':' if start and limit-1 are in the same group, then enumerate only in that one ','line_number':694,'multiline':True]
['text':' enumerate characters in the partial start group ','line_number':703,'multiline':True]
['text':' continue with the next group ','line_number':710,'multiline':True]
['text':' make sure that we start enumerating with the first group after start ','line_number':713,'multiline':True]
['text':' enumerate entire groups between the start- and end-groups ','line_number':727,'multiline':True]
['text':' enumerate within the end group (group[GROUP_MSB]==endGroupMSB) ','line_number':747,'multiline':True]
['text':' we have not found a group, which means everything is made of
       extended names. ','line_number':760,'multiline':True]
['text':' suffix elements ','line_number':774,'multiline':True]
['text':' output fields from here ','line_number':776,'multiline':True]
['text':' write elements according to the factors ','line_number':782,'multiline':True]
['text':'
     * the factorized elements are determined by modulo arithmetic
     * with the factors of this algorithm
     *
     * note that for fewer operations, count is decremented here
     ','line_number':784,'multiline':True]
['text':'
     * we don't need to calculate the last modulus because start<=code<=end
     * guarantees here that code<=factors[0]
     ','line_number':796,'multiline':True]
['text':' write each element ','line_number':802,'multiline':True]
['text':' skip indexes[i] strings ','line_number':808,'multiline':True]
['text':' write element ','line_number':818,'multiline':True]
['text':' we do not need to perform the rest of this loop for i==count - break here ','line_number':823,'multiline':True]
['text':' skip the rest of the strings for this factors[i] ','line_number':828,'multiline':True]
['text':' zero-terminate ','line_number':838,'multiline':True]
['text':'
 * Important:
 * Parts of findAlgName() are almost the same as some of getAlgName().
 * Fixes must be applied to both.
 ','line_number':846,'multiline':True]
['text':' Only the normative character name can be algorithmic. ','line_number':856,'multiline':True]
['text':' zero-terminate ','line_number':858,'multiline':True]
['text':' name = prefix hex-digits ','line_number':867,'multiline':True]
['text':' copy prefix ','line_number':873,'multiline':True]
['text':' write hexadecimal code point value ','line_number':878,'multiline':True]
['text':' zero-terminate ','line_number':881,'multiline':True]
['text':' name = prefix factorized-elements ','line_number':903,'multiline':True]
['text':' copy prefix ','line_number':910,'multiline':True]
['text':' undefined type ','line_number':920,'multiline':True]
['text':' zero-terminate ','line_number':921,'multiline':True]
['text':'
 * Important: enumAlgNames() and findAlgName() are almost the same.
 * Any fix must be applied to both.
 ','line_number':931,'multiline':True]
['text':' get the full name of the start character ','line_number':952,'multiline':True]
['text':' call the enumerator function with this first character ','line_number':958,'multiline':True]
['text':' go to the end of the name; all these names have the same length ','line_number':963,'multiline':True]
['text':' enumerate the rest of the names ','line_number':969,'multiline':True]
['text':' increment the hexadecimal number on a character-basis ','line_number':971,'multiline':True]
['text':' name = prefix factorized-elements ','line_number':1003,'multiline':True]
['text':' copy prefix ','line_number':1005,'multiline':True]
['text':' append the suffix of the start character ','line_number':1013,'multiline':True]
['text':' call the enumerator function with this first character ','line_number':1019,'multiline':True]
['text':' enumerate the rest of the names ','line_number':1024,'multiline':True]
['text':' increment the indexes in lexical order bound by the factors ','line_number':1026,'multiline':True]
['text':' skip one index and its element string ','line_number':1031,'multiline':True]
['text':' reset this index to 0 and its element string to the first one ','line_number':1039,'multiline':True]
['text':' to make matters a little easier, just append all elements to the suffix ','line_number':1045,'multiline':True]
['text':' zero-terminate ','line_number':1055,'multiline':True]
['text':' undefined type ','line_number':1065,'multiline':True]
['text':'
 * findAlgName() is almost the same as enumAlgNames() except that it
 * returns the code point for a name if it fits into the range.
 * It returns 0xffff otherwise.
 ','line_number':1072,'multiline':True]
['text':' name = prefix hex-digits ','line_number':1087,'multiline':True]
['text':' compare prefix ','line_number':1093,'multiline':True]
['text':' read hexadecimal code point value ','line_number':1100,'multiline':True]
['text':' does it fit into the range? ','line_number':1114,'multiline':True]
['text':' name = prefix factorized-elements ','line_number':1132,'multiline':True]
['text':' compare prefix ','line_number':1134,'multiline':True]
['text':' initialize the suffix elements for enumeration; indexes should all be set to 0 ','line_number':1144,'multiline':True]
['text':' compare the first suffix ','line_number':1148,'multiline':True]
['text':' enumerate and compare the rest of the suffixes ','line_number':1153,'multiline':True]
['text':' increment the indexes in lexical order bound by the factors ','line_number':1155,'multiline':True]
['text':' skip one index and its element string ','line_number':1160,'multiline':True]
['text':' reset this index to 0 and its element string to the first one ','line_number':1167,'multiline':True]
['text':' to make matters a little easier, just compare all elements of the suffix ','line_number':1173,'multiline':True]
['text':' does not match ','line_number':1179,'multiline':True]
['text':' undefined type ','line_number':1191,'multiline':True]
['text':' sets of name characters, maximum name lengths ---------------------------- ','line_number':1198,'multiline':True]
['text':' enumerate algorithmic ranges ','line_number':1222,'multiline':True]
['text':' name = prefix + (range->variant times) hex-digits ','line_number':1229,'multiline':True]
['text':' prefix ','line_number':1230,'multiline':True]
['text':' name = prefix factorized-elements ','line_number':1237,'multiline':True]
['text':' prefix length ','line_number':1242,'multiline':True]
['text':' start of factor suffixes ','line_number':1245,'multiline':True]
['text':' get the set and maximum factor suffix length for each factor ','line_number':1247,'multiline':True]
['text':' unknown type ','line_number':1266,'multiline':True]
['text':'
         * for each category, count the length of the category name
         * plus 9=
         * 2 for <>
         * 1 for -
         * 6 for most hex digits per code point
         ','line_number':1281,'multiline':True]
['text':' implicit letter ','line_number':1306,'multiline':True]
['text':' this is a lead byte for a double-byte token ','line_number':1312,'multiline':True]
['text':' explicit letter ','line_number':1317,'multiline':True]
['text':' count token word ','line_number':1321,'multiline':True]
['text':' use cached token length ','line_number':1323,'multiline':True]
['text':' enumerate all groups ','line_number':1364,'multiline':True]
['text':' enumerate all lines in each group ','line_number':1369,'multiline':True]
['text':' read regular name ','line_number':1379,'multiline':True]
['text':' read Unicode 1.0 name ','line_number':1388,'multiline':True]
['text':' read ISO comment ','line_number':1397,'multiline':True]
['text':'length=calcNameSetLength(tokens, tokenCount, tokenStrings, tokenLengths, gISOCommentSet, &line, lineLimit);','line_number':1398,'multiline':True]
['text':' set gMax... - name length last for threading ','line_number':1409,'multiline':True]
['text':' set hex digits, used in various names, and <>-, used in extended names ','line_number':1426,'multiline':True]
['text':' set sets and lengths from algorithmic names ','line_number':1431,'multiline':True]
['text':' set sets and lengths from extended names ','line_number':1434,'multiline':True]
['text':' set sets and lengths from group names, set global maximum values ','line_number':1437,'multiline':True]
['text':' public API --------------------------------------------------------------- ','line_number':1445,'multiline':True]
['text':' check the argument values ','line_number':1458,'multiline':True]
['text':' try algorithmic names first ','line_number':1474,'multiline':True]
['text':' extended character name ','line_number':1491,'multiline':True]
['text':' normal character name ','line_number':1495,'multiline':True]
['text':'c','line_number':1504,'multiline':True]
['text':' check the argument values ','line_number':1507,'multiline':True]
['text':' Undefined, but use this for backwards compatibility. ','line_number':1530,'multiline':True]
['text':' construct the uppercase and lowercase of the name first ','line_number':1545,'multiline':True]
['text':' name too long, there is no such character ','line_number':1556,'multiline':True]
['text':' i==strlen(name)==strlen(lower)==strlen(upper)','line_number':1560,'multiline':False]
['text':' try extended names first ','line_number':1562,'multiline':True]
['text':' Parse a string like "<category-HHHH>" where HHHH is a hex code point.','line_number':1565,'multiline':False]
['text':' There should be 1 to 8 hex digits.','line_number':1569,'multiline':False]
['text':' Prevent signed-integer overflow and out-of-range code points.','line_number':1585,'multiline':False]
['text':' Now validate the category name.
                   We could use a binary search, or a trie, if
                   we really wanted to. ','line_number':1592,'multiline':True]
['text':' try algorithmic names now ','line_number':1612,'multiline':True]
['text':' normal character name ','line_number':1624,'multiline':True]
['text':' interleave the data-driven ones with the algorithmic ones ','line_number':1664,'multiline':True]
['text':' iterate over all algorithmic ranges; assume that they are in ascending order ','line_number':1665,'multiline':True]
['text':' enumerate the character names before the current algorithmic range ','line_number':1670,'multiline':True]
['text':' here: start<limit ','line_number':1671,'multiline':True]
['text':' enumerate the character names in the current algorithmic range ','line_number':1682,'multiline':True]
['text':' here: algRange->start<=start<limit ','line_number':1683,'multiline':True]
['text':' continue to the next algorithmic range (here: start<limit) ','line_number':1694,'multiline':True]
['text':' enumerate the character names after the last algorithmic range ','line_number':1698,'multiline':True]
['text':'*
 * Converts the char set cset into a Unicode set uset.
 * @param cset Set of 256 bit flags corresponding to a set of chars.
 * @param uset USet to receive characters. Existing contents are deleted.
 ','line_number':1712,'multiline':True]
['text':' build a char string with all chars that are used in character names ','line_number':1731,'multiline':True]
['text':' convert the char string to a UChar string ','line_number':1739,'multiline':True]
['text':' add each UChar to the USet ','line_number':1742,'multiline':True]
['text':' non-invariant chars become (UChar)0 ','line_number':1744,'multiline':True]
['text':'*
 * Fills set with characters that are used in Unicode character names.
 * @param set USet to receive characters.
 ','line_number':1750,'multiline':True]
['text':' data swapping ------------------------------------------------------------ ','line_number':1759,'multiline':True]
['text':'
 * The token table contains non-negative entries for token bytes,
 * and -1 for bytes that represent themselves in the data file's charset.
 * -2 entries are used for lead bytes.
 *
 * Direct bytes (-1 entries) must be translated from the input charset family
 * to the output charset family.
 * makeTokenMap() writes a permutation mapping for this.
 * Use it once for single-/lead-byte tokens and once more for all trail byte
 * tokens. (';' is an unused trail byte marked with -1.)
 ','line_number':1761,'multiline':True]
['text':' Same charset family: identity permutation ','line_number':1786,'multiline':True]
['text':' set the direct bytes (byte 0 always maps to itself) ','line_number':1798,'multiline':True]
['text':' convert the direct byte character ','line_number':1801,'multiline':True]
['text':' enter the converted character into the map and mark it used ','line_number':1810,'multiline':True]
['text':' set the mappings for the rest of the permutation ','line_number':1816,'multiline':True]
['text':' set mappings that were not set for direct bytes ','line_number':1818,'multiline':True]
['text':' set an output byte value that was not used as an output byte above ','line_number':1820,'multiline':True]
['text':'
         * leave mappings at tokenCount and above unset if tokenCount<256
         * because they won't be used
         ','line_number':1828,'multiline':True]
['text':' udata_swapDataHeader checks the arguments ','line_number':1851,'multiline':True]
['text':' check data format and format version ','line_number':1857,'multiline':True]
['text':' dataFormat="unam" ','line_number':1860,'multiline':True]
['text':' preflighting: iterate through algorithmic ranges ','line_number':1891,'multiline':True]
['text':' swap data ','line_number':1901,'multiline':True]
['text':' copy the data for inaccessible bytes ','line_number':1910,'multiline':True]
['text':' the initial 4 offsets first ','line_number':1915,'multiline':True]
['text':'
         * now the tokens table
         * it needs to be permutated along with the compressed name strings
         ','line_number':1921,'multiline':True]
['text':' read and swap the tokenCount ','line_number':1928,'multiline':True]
['text':' read the first 512 tokens and make the token maps ','line_number':1934,'multiline':True]
['text':' fill the rest of the tokens array if tokenCount<512 ','line_number':1944,'multiline':True]
['text':'
         * swap and permutate the tokens
         * go through a temporary array to support in-place swapping
         ','line_number':1952,'multiline':True]
['text':' swap and permutate single-/lead-byte tokens ','line_number':1964,'multiline':True]
['text':' swap and permutate trail-byte tokens ','line_number':1969,'multiline':True]
['text':' copy the result into the output and free the temporary array ','line_number':1974,'multiline':True]
['text':'
         * swap the token strings but not a possible padding byte after
         * the terminating NUL of the last string
         ','line_number':1978,'multiline':True]
['text':' swap the group table ','line_number':1989,'multiline':True]
['text':'
         * swap the group strings
         * swap the string bytes but not the nibble-encoded string lengths
         ','line_number':1994,'multiline':True]
['text':' iterate through string groups until only a few padding bytes are left ','line_number':2011,'multiline':True]
['text':' move past the length bytes ','line_number':2015,'multiline':True]
['text':' total number of string bytes in this group ','line_number':2020,'multiline':True]
['text':' swap the string bytes using map[] and trailMap[] ','line_number':2023,'multiline':True]
['text':' token lead byte: swap the trail byte, too ','line_number':2030,'multiline':True]
['text':' swap the algorithmic ranges ','line_number':2038,'multiline':True]
['text':' swap prefix string ','line_number':2060,'multiline':True]
['text':' swap factors and the prefix and factor strings ','line_number':2071,'multiline':True]
['text':' swap the strings, up to the last terminating NUL ','line_number':2079,'multiline':True]
['text':'
 * Hey, Emacs, please set the following:
 *
 * Local Variables:
 * indent-tabs-mode: nil
 * End:
 *
 ','line_number':2101,'multiline':True]
