['text':' -*- Mode: C++; tab-width: 8; indent-tabs-mode: nil; c-basic-offset: 2 -*-
 * vim: set ts=8 sts=2 et sw=2 tw=80:
 *
 * Copyright 2015 Mozilla Foundation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 ','line_number':1,'multiline':True]
['text':' js::Scalar::Type','line_number':29,'multiline':False]
['text':' We store SSA definitions in the value stack.','line_number':54,'multiline':False]
['text':' We store loop headers and then/else blocks in the control flow stack.','line_number':58,'multiline':False]
['text':' CallCompileState describes a call that is being compiled.','line_number':66,'multiline':False]
['text':' A generator object that is passed each argument as it is compiled.','line_number':69,'multiline':False]
['text':' Accumulates the register arguments while compiling arguments.','line_number':72,'multiline':False]
['text':' Reserved argument for passing Instance* to builtin instance method calls.','line_number':75,'multiline':False]
['text':' The stack area in which the callee will write stack return values, or','line_number':78,'multiline':False]
['text':' nullptr if no stack results.','line_number':79,'multiline':False]
['text':' Only FunctionCompiler should be directly manipulating CallCompileState.','line_number':82,'multiline':False]
['text':' Encapsulates the compilation of a single function in an asm.js module. The','line_number':86,'multiline':False]
['text':' function compiler handles the creation and final backend compilation of the','line_number':87,'multiline':False]
['text':' MIR graph.','line_number':88,'multiline':False]
['text':' TLS pointer argument to the current function.','line_number':119,'multiline':False]
['text':' FIXME(1401675): Replace with BlockType.','line_number':147,'multiline':False]
['text':' Prepare the entry block for MIR generation:','line_number':159,'multiline':False]
['text':' prev ','line_number':166,'multiline':True]
['text':' Set up a parameter that receives the hidden TLS pointer argument.','line_number':185,'multiline':False]
['text':'************************ Read-only interface (after local scope setup) ','line_number':248,'multiline':True]
['text':'**************************** Code generation (after local scope setup) ','line_number':263,'multiline':True]
['text':' MConstant has a lot of baggage so we don't use that here.','line_number':317,'multiline':False]
['text':' wasm can't fold x - 0.0 because of NaN with custom payloads.','line_number':398,'multiline':False]
['text':' Convert signaling NaN to quiet NaNs.','line_number':421,'multiline':False]
['text':' wasm can't fold x * 1.0 because of NaN with custom payloads.','line_number':438,'multiline':False]
['text':' Enforce the signedness of the operation by coercing the operands','line_number':452,'multiline':False]
['text':' to signed.  Otherwise, operands that "look" unsigned to Ion but','line_number':453,'multiline':False]
['text':' are not unsigned to Baldr (eg, unsigned right shifts) may lead to','line_number':454,'multiline':False]
['text':' the operation being executed unsigned.  Applies to mod() as well.','line_number':455,'multiline':False]
['text':'','line_number':456,'multiline':False]
['text':' Do this for Int32 only since Int64 is not subject to the same','line_number':457,'multiline':False]
['text':' issues.','line_number':458,'multiline':False]
['text':'','line_number':459,'multiline':False]
['text':' Note the offsets passed to MWasmBuiltinTruncateToInt32 are wrong here,','line_number':460,'multiline':False]
['text':' but it doesn't matter: they're not codegen'd to calls since inputs','line_number':461,'multiline':False]
['text':' already are int32.','line_number':462,'multiline':False]
['text':' For x86 and arm we implement i64 div via c++ builtin.','line_number':471,'multiline':False]
['text':' A call to c++ builtin requires tls pointer.','line_number':472,'multiline':False]
['text':' See block comment in div().','line_number':504,'multiline':False]
['text':' For x86 and arm we implement i64 mod via c++ builtin.','line_number':513,'multiline':False]
['text':' A call to c++ builtin requires tls pointer.','line_number':514,'multiline':False]
['text':' Should be handled separately because we call BuiltinThunk for this case','line_number':525,'multiline':False]
['text':' and so, need to add the dependency from tlsPointer.','line_number':526,'multiline':False]
['text':' About Wasm SIMD as supported by Ion:','line_number':682,'multiline':False]
['text':'','line_number':683,'multiline':False]
['text':' The expectation is that Ion will only ever support SIMD on x86 and x64,','line_number':684,'multiline':False]
['text':' since Cranelift will be the optimizing compiler for Arm64, ARMv7 will cease','line_number':685,'multiline':False]
['text':' to be a tier-1 platform soon, and MIPS32 and MIPS64 will never implement','line_number':686,'multiline':False]
['text':' SIMD.','line_number':687,'multiline':False]
['text':'','line_number':688,'multiline':False]
['text':' The division of the operations into MIR nodes reflects that expectation,','line_number':689,'multiline':False]
['text':' and is a good fit for x86/x64.  Should the expectation change we'll','line_number':690,'multiline':False]
['text':' possibly want to re-architect the SIMD support to be a little more general.','line_number':691,'multiline':False]
['text':'','line_number':692,'multiline':False]
['text':' Most SIMD operations map directly to a single MIR node that ultimately ends','line_number':693,'multiline':False]
['text':' up being expanded in the macroassembler.','line_number':694,'multiline':False]
['text':'','line_number':695,'multiline':False]
['text':' Some SIMD operations that do have a complete macroassembler expansion are','line_number':696,'multiline':False]
['text':' open-coded into multiple MIR nodes here; in some cases that's just','line_number':697,'multiline':False]
['text':' convenience, in other cases it may also allow them to benefit from Ion','line_number':698,'multiline':False]
['text':' optimizations.  The reason for the expansions will be documented by a','line_number':699,'multiline':False]
['text':' comment.','line_number':700,'multiline':False]
['text':' (v128,v128) -> v128 effect-free binary operations','line_number':702,'multiline':False]
['text':' (v128,i32) -> v128 effect-free shift operations','line_number':717,'multiline':False]
['text':' (v128,scalar,imm) -> v128','line_number':731,'multiline':False]
['text':' (scalar) -> v128 effect-free unary operations','line_number':745,'multiline':False]
['text':' (v128) -> v128 effect-free unary operations','line_number':756,'multiline':False]
['text':' (v128, imm) -> scalar effect-free unary operations','line_number':768,'multiline':False]
['text':' (v128, v128, v128) -> v128 effect-free operations','line_number':782,'multiline':False]
['text':' (v128, v128, imm_v128) -> v128 effect-free operations','line_number':797,'multiline':False]
['text':' Generate better code (on x86)','line_number':822,'multiline':False]
['text':' Generate better code (on x86) by loading as a double with an','line_number':846,'multiline':False]
['text':' operation that sign extends directly.','line_number':847,'multiline':False]
['text':' ENABLE_WASM_SIMD','line_number':907,'multiline':False]
['text':' Only sets *mustAdd if it also returns true.','line_number':955,'multiline':False]
['text':' asm.js accesses are always aligned and need no checks.','line_number':960,'multiline':False]
['text':' OK to wrap around the address computation here.','line_number':967,'multiline':False]
['text':' Fold a constant base into the offset and make the base 0, provided the','line_number':985,'multiline':False]
['text':' offset stays below the guard limit.  The reason for folding the base into','line_number':986,'multiline':False]
['text':' the offset rather than vice versa is that a small offset can be ignored','line_number':987,'multiline':False]
['text':' by both explicit bounds checking and bounds check elimination.','line_number':988,'multiline':False]
['text':' If the offset is bigger than the guard region, a separate instruction is','line_number':1004,'multiline':False]
['text':' necessary to add the offset to the base and check for overflow.','line_number':1005,'multiline':False]
['text':'','line_number':1006,'multiline':False]
['text':' Also add the offset if we have a Wasm atomic access that needs alignment','line_number':1007,'multiline':False]
['text':' checking and the offset affects alignment.','line_number':1008,'multiline':False]
['text':' If the bounds check uses the full 64 bits of the bounds check limit, then','line_number':1020,'multiline':False]
['text':' *base must be zero-extended to 64 bits before checking and wrapped back','line_number':1021,'multiline':False]
['text':' to 32-bits after Spectre masking.  (And it's important that the value we','line_number':1022,'multiline':False]
['text':' end up with has flowed through the Spectre mask.)','line_number':1023,'multiline':False]
['text':'','line_number':1024,'multiline':False]
['text':' If the memory's max size is known to be smaller than 64K pages exactly,','line_number':1025,'multiline':False]
['text':' we can use a 32-bit check and avoid extension and wrapping.','line_number':1026,'multiline':False]
['text':' At the outset, actualBase could be the result of pretty much any i32','line_number':1035,'multiline':False]
['text':' operation, or it could be the load of an i32 constant.  We may assume','line_number':1036,'multiline':False]
['text':' the value has a canonical representation for the platform, see doc','line_number':1037,'multiline':False]
['text':' block in MacroAssembler.h.','line_number':1038,'multiline':False]
['text':' Extend the index value to perform a 64-bit bounds check if the memory','line_number':1041,'multiline':False]
['text':' can be 4GB.','line_number':1042,'multiline':False]
['text':' If we're masking, then we update *base to create a dependency chain','line_number':1054,'multiline':False]
['text':' through the masked index.  But we will first need to wrap the index','line_number':1055,'multiline':False]
['text':' value if it was extended above.','line_number':1056,'multiline':False]
['text':' These smaller accesses should all be zero-extending.','line_number':1071,'multiline':False]
['text':'bottomHalf=','line_number':1155,'multiline':True]
['text':'bottomHalf=','line_number':1160,'multiline':True]
['text':'bottomHalf=','line_number':1192,'multiline':True]
['text':'bottomHalf=','line_number':1225,'multiline':True]
['text':' Pull a pointer to the value out of TlsData::globalArea, then','line_number':1255,'multiline':False]
['text':' load from that pointer.  Note that the pointer is immutable','line_number':1256,'multiline':False]
['text':' even though the value it points at may change, hence the use of','line_number':1257,'multiline':False]
['text':' |true| for the first node's |isConst| value, irrespective of','line_number':1258,'multiline':False]
['text':' the |isConst| formal parameter to this method.  The latter','line_number':1259,'multiline':False]
['text':' applies to the denoted value as a whole.','line_number':1260,'multiline':False]
['text':'isConst=','line_number':1263,'multiline':True]
['text':' Pull the value directly out of TlsData::globalArea.','line_number':1267,'multiline':False]
['text':' Pull a pointer to the value out of TlsData::globalArea, then','line_number':1284,'multiline':False]
['text':' store through that pointer.','line_number':1285,'multiline':False]
['text':'isConst=','line_number':1288,'multiline':True]
['text':' Store the value directly in TlsData::globalArea.','line_number':1298,'multiline':False]
['text':'**************************************************************** Calls ','line_number':1324,'multiline':True]
['text':' The IonMonkey backend maintains a single stack offset (from the stack','line_number':1326,'multiline':False]
['text':' pointer to the base of the frame) by adding the total amount of spill','line_number':1327,'multiline':False]
['text':' space required plus the maximum stack required for argument passing.','line_number':1328,'multiline':False]
['text':' Since we do not use IonMonkey's MPrepareCall/MPassArg/MCall, we must','line_number':1329,'multiline':False]
['text':' manually accumulate, for the entire function, the maximum required stack','line_number':1330,'multiline':False]
['text':' space for argument passing. (This is passed to the CodeGenerator via','line_number':1331,'multiline':False]
['text':' MIRGenerator::maxWasmStackArgBytes.) This is just be the maximum of the','line_number':1332,'multiline':False]
['text':' stack space required for each individual call (as determined by the call','line_number':1333,'multiline':False]
['text':' ABI).','line_number':1334,'multiline':False]
['text':' Operations that modify a CallCompileState.','line_number':1336,'multiline':False]
['text':' Should only pass an instance once.  And it must be a non-GC pointer.','line_number':1343,'multiline':False]
['text':' Do not call this directly.  Call one of the passArg() variants instead.','line_number':1350,'multiline':False]
['text':' bottomHalf = ','line_number':1358,'multiline':True]
['text':' bottomHalf = ','line_number':1361,'multiline':True]
['text':' If the call returns results on the stack, prepare a stack area to receive','line_number':1398,'multiline':False]
['text':' them, and pass the address of the stack area to the callee as an additional','line_number':1399,'multiline':False]
['text':' argument.','line_number':1400,'multiline':False]
['text':' No stack results.','line_number':1411,'multiline':False]
['text':' Wrappers for creating various kinds of calls.','line_number':1451,'multiline':False]
['text':' The result iterator goes in the order in which results would be popped','line_number':1497,'multiline':False]
['text':' off; we want the order in which they would be pushed.','line_number':1498,'multiline':False]
['text':'********************************************** Control flow generation ','line_number':1701,'multiline':True]
['text':' Switch to iterate in FIFO order instead of the default LIFO.','line_number':1715,'multiline':False]
['text':' Create the loop header.','line_number':1912,'multiline':False]
['text':' Flag all redundant phis as unused.','line_number':1966,'multiline':False]
['text':' Fix up phis stored in the slots Vector of pending blocks.','line_number':1975,'multiline':False]
['text':' The loop body, if any, might be referencing recycled phis too.','line_number':1985,'multiline':False]
['text':' Discard redundant phis and add to the free list.','line_number':1990,'multiline':False]
['text':' Op::Loop doesn't have an implicit backedge so temporarily set','line_number':2022,'multiline':False]
['text':' aside the end of the loop body to bind backedges.','line_number':2023,'multiline':False]
['text':' As explained in bug 1253544, Ion apparently has an invariant that','line_number':2027,'multiline':False]
['text':' there is only one backedge to loop headers. To handle wasm's ability','line_number':2028,'multiline':False]
['text':' to have multiple backedges to the same loop header, we bind all those','line_number':2029,'multiline':False]
['text':' branches as forward jumps to a single backward jump. This is','line_number':2030,'multiline':False]
['text':' unfortunate but the optimizer is able to fold these into single jumps','line_number':2031,'multiline':False]
['text':' to backedges.','line_number':2032,'multiline':False]
['text':' We're on the loop backedge block, created by bindBranches.','line_number':2041,'multiline':False]
['text':' If the loop depth still at the inner loop body, correct it.','line_number':2062,'multiline':False]
['text':'*********************************************************** DECODING **','line_number':2195,'multiline':True]
['text':'***********************************************************************','line_number':2208,'multiline':True]
['text':' end anonymous namespace','line_number':2328,'multiline':False]
['text':' If we didn't see an Else, create a trivial else block so that we create','line_number':2465,'multiline':False]
['text':' a diamond anyway, to preserve Ion invariants.','line_number':2466,'multiline':False]
['text':' If all the targets are the same, or there are no targets, we can just','line_number':2538,'multiline':False]
['text':' use a goto. This is not just an optimization: MaybeFoldConditionBlock','line_number':2539,'multiline':False]
['text':' assumes that tables have more than one successor.','line_number':2540,'multiline':False]
['text':' We always call the C++ postbarrier because the location will never be in','line_number':2848,'multiline':False]
['text':' the nursery, and the value stored will very frequently be in the nursery.','line_number':2849,'multiline':False]
['text':' The C++ postbarrier performs any necessary filtering.','line_number':2850,'multiline':False]
['text':' This call to readBinary assumes both operands have the same type.','line_number':3305,'multiline':False]
['text':' Compute the number of copies of each width we will need to do','line_number':3622,'multiline':False]
['text':' Load all source bytes from low to high using the widest transfer width we','line_number':3634,'multiline':False]
['text':' can for the system. We will trap without writing anything if any source','line_number':3635,'multiline':False]
['text':' byte is out-of-bounds.','line_number':3636,'multiline':False]
['text':' Store all source bytes to the destination from high to low. We will trap','line_number':3680,'multiline':False]
['text':' without writing anything on the first store if any dest byte is','line_number':3681,'multiline':False]
['text':' out-of-bounds.','line_number':3682,'multiline':False]
['text':' Compute the number of copies of each width we will need to do','line_number':3869,'multiline':False]
['text':' Generate splatted definitions for wider fills as needed','line_number':3881,'multiline':False]
['text':' Store the fill value to the destination from high to low. We will trap','line_number':3896,'multiline':False]
['text':' without writing anything on the first store if any dest byte is','line_number':3897,'multiline':False]
['text':' out-of-bounds.','line_number':3898,'multiline':False]
['text':' Note, table.{get,grow,set} on table(funcref) are currently rejected by the','line_number':4005,'multiline':False]
['text':' verifier.','line_number':4006,'multiline':False]
['text':' The return value here is either null, denoting an error, or a short-lived','line_number':4089,'multiline':False]
['text':' pointer to a location containing a possibly-null ref.','line_number':4090,'multiline':False]
['text':' The return value here is either null, denoting an error, or a short-lived','line_number':4264,'multiline':False]
['text':' pointer to a location containing a possibly-null ref.','line_number':4265,'multiline':False]
['text':' Control opcodes','line_number':4534,'multiline':False]
['text':' Calls','line_number':4591,'multiline':False]
['text':' asmJSFuncDef = ','line_number':4593,'multiline':True]
['text':' oldStyle = ','line_number':4595,'multiline':True]
['text':' Parametric operators','line_number':4597,'multiline':False]
['text':'typed','line_number':4601,'multiline':True]
['text':'typed','line_number':4603,'multiline':True]
['text':' Locals and globals','line_number':4605,'multiline':False]
['text':' Memory-related operators','line_number':4621,'multiline':False]
['text':' Constants','line_number':4673,'multiline':False]
['text':' Comparison operators','line_number':4683,'multiline':False]
['text':' Numeric operators','line_number':4785,'multiline':False]
['text':' isUnsigned = ','line_number':4878,'multiline':True]
['text':' isUnsigned = ','line_number':4907,'multiline':True]
['text':' Conversions','line_number':4915,'multiline':False]
['text':' Reinterpretations','line_number':4960,'multiline':False]
['text':' Sign extensions','line_number':4985,'multiline':False]
['text':' Gc operations','line_number':4997,'multiline':False]
['text':' SIMD operations','line_number':5004,'multiline':False]
['text':' commutative= ','line_number':5079,'multiline':True]
['text':' commutative= ','line_number':5139,'multiline':True]
['text':' switch (op.b1)','line_number':5291,'multiline':False]
['text':' Miscellaneous operations','line_number':5296,'multiline':False]
['text':'isData=','line_number':5318,'multiline':True]
['text':'isMem=','line_number':5322,'multiline':True]
['text':'isData=','line_number':5326,'multiline':True]
['text':'isMem=','line_number':5328,'multiline':True]
['text':' Thread operations','line_number':5341,'multiline':False]
['text':' Though thread ops can be used on nonshared memories, we make them','line_number':5343,'multiline':False]
['text':' unavailable if shared memory has been disabled in the prefs, for','line_number':5344,'multiline':False]
['text':' maximum predictability and safety and consistency with JS.','line_number':5345,'multiline':False]
['text':' asm.js-specific operators','line_number':5536,'multiline':False]
['text':' isUnsigned = ','line_number':5578,'multiline':True]
['text':' asmJSFuncDef = ','line_number':5600,'multiline':True]
['text':' oldStyle = ','line_number':5602,'multiline':True]
['text':' Swap in already-allocated empty vectors to avoid malloc/free.','line_number':5637,'multiline':False]
['text':' Create a description of the stack layout created by GenerateTrapExit().','line_number':5643,'multiline':False]
['text':' Build the local types vector.','line_number':5660,'multiline':False]
['text':' Set up for Ion compilation.','line_number':5672,'multiline':False]
['text':' Build MIR graph','line_number':5683,'multiline':False]
['text':' Compile MIR graph','line_number':5701,'multiline':False]
