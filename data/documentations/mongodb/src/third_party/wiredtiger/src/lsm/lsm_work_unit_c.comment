['text':'-
 * Copyright (c) 2014-present MongoDB, Inc.
 * Copyright (c) 2008-2014 WiredTiger, Inc.
 *	All rights reserved.
 *
 * See the file LICENSE for redistribution information.
 ','line_number':1,'multiline':True]
['text':'
 * __lsm_copy_chunks --
 *     Take a copy of part of the LSM tree chunk array so that we can work on the contents without
 *     holding the LSM tree handle lock long term.
 ','line_number':14,'multiline':True]
['text':' Always return zero chunks on error. ','line_number':27,'multiline':True]
['text':' Take a copy of the current state of the LSM tree. ','line_number':36,'multiline':True]
['text':'
     * If the tree array of active chunks is larger than our current buffer, increase the size of
     * our current buffer to match.
     ','line_number':41,'multiline':True]
['text':'
     * Mark each chunk as active, so we don't drop it until after we know it's safe.
     ','line_number':51,'multiline':True]
['text':'
 * __wt_lsm_get_chunk_to_flush --
 *     Find and pin a chunk in the LSM tree that is likely to need flushing.
 ','line_number':65,'multiline':True]
['text':' Search for a chunk to evict and/or a chunk to flush. ','line_number':88,'multiline':True]
['text':'
             * Normally we don't want to force out the last chunk. But if we're doing a forced flush
             * on behalf of a compact, then we want to include the final chunk.
             ','line_number':92,'multiline':True]
['text':'
     * Don't be overly zealous about pushing old chunks from cache. Attempting too many drops can
     * interfere with checkpoints.
     *
     * If retrying a discard push an additional work unit so there are enough to trigger
     * checkpoints.
     ','line_number':103,'multiline':True]
['text':'
 * __lsm_unpin_chunks --
 *     Decrement the reference count for a set of chunks. Allowing those chunks to be considered for
 *     deletion.
 ','line_number':130,'multiline':True]
['text':' Ensure subsequent calls don't double decrement. ','line_number':146,'multiline':True]
['text':'
 * __wt_lsm_work_switch --
 *     Do a switch if the LSM tree needs one.
 ','line_number':150,'multiline':True]
['text':' We've become responsible for freeing the work unit. ','line_number':160,'multiline':True]
['text':' Failing to complete the switch is fine ','line_number':167,'multiline':True]
['text':'
 * __wt_lsm_work_bloom --
 *     Try to create a Bloom filter for the newest on-disk chunk that doesn't have one.
 ','line_number':181,'multiline':True]
['text':' Create bloom filters in all checkpointed chunks. ','line_number':197,'multiline':True]
['text':'
         * Skip if a thread is still active in the chunk or it isn't suitable.
         ','line_number':202,'multiline':True]
['text':' Never create a bloom filter on the oldest chunk ','line_number':210,'multiline':True]
['text':'
         * See if we win the race to switch on the "busy" flag and recheck that the chunk still
         * needs a Bloom filter.
         ','line_number':213,'multiline':True]
['text':'
                 * Record if we were successful so that we can later push a merge work unit.
                 ','line_number':220,'multiline':True]
['text':'
     * If we created any bloom filters, we push a merge work unit now.
     ','line_number':230,'multiline':True]
['text':'
 * __wt_lsm_chunk_visible_all --
 *     Setup a timestamp and check visibility for a chunk, can be called from multiple threads in
 *     parallel
 ','line_number':242,'multiline':True]
['text':' Once a chunk has been flushed it's contents must be visible ','line_number':254,'multiline':True]
['text':'
     * Once all transactions with updates in the chunk are visible all timestamps associated with
     * those updates are assigned so setup a timestamp for visibility checking.
     ','line_number':262,'multiline':True]
['text':' Set the timestamp if we won the race ','line_number':269,'multiline':True]
['text':'
         * If timestamps aren't in use when the chunk becomes visible use the zero timestamp for
         * visibility checks. Otherwise there could be confusion if timestamps start being used.
         ','line_number':281,'multiline':True]
['text':'
 * __lsm_set_chunk_evictable --
 *     Enable eviction in an LSM chunk.
 ','line_number':290,'multiline':True]
['text':' See if we win the race to enable eviction. ','line_number':303,'multiline':True]
['text':'
 * __lsm_checkpoint_chunk --
 *     Checkpoint an LSM chunk, separated out to make locking easier.
 ','line_number':319,'multiline':True]
['text':'
     * Turn on metadata tracking to ensure the checkpoint gets the necessary handle locks.
     ','line_number':331,'multiline':True]
['text':'
 * __wt_lsm_checkpoint_chunk --
 *     Flush a single LSM chunk to disk.
 ','line_number':341,'multiline':True]
['text':'
     * If the chunk is already checkpointed, make sure it is also evicted. Either way, there is no
     * point trying to checkpoint it again.
     ','line_number':355,'multiline':True]
['text':' Stop if a running transaction needs the chunk. ','line_number':375,'multiline':True]
['text':'
         * If there is cache pressure consider making a chunk evictable to avoid the cache getting
         * stuck when history is required.
         ','line_number':378,'multiline':True]
['text':'
     * Flush the file before checkpointing: this is the expensive part in
     * terms of I/O.
     *
     * !!!
     * We can wait here for checkpoints and fsyncs to complete, which can
     * take a long time.
     ','line_number':395,'multiline':True]
['text':'
     * Set read-uncommitted: we have already checked that all of the updates in this chunk are
     * globally visible, use the cheapest possible check in reconciliation.
     ','line_number':406,'multiline':True]
['text':'
     * Ensure we don't race with a running checkpoint: the checkpoint lock protects against us
     * racing with an application checkpoint in this chunk.
     ','line_number':418,'multiline':True]
['text':' Now the file is written, get the chunk size. ','line_number':427,'multiline':True]
['text':' Lock the tree, mark the chunk as on disk and update the metadata. ','line_number':432,'multiline':True]
['text':' Update the flush timestamp to help track ongoing progress. ','line_number':434,'multiline':True]
['text':' Update the throttle time. ','line_number':440,'multiline':True]
['text':'
     * Enable eviction on the live chunk so it doesn't block the cache. Future reads should direct
     * to the on-disk chunk anyway.
     ','line_number':446,'multiline':True]
['text':' Make sure we aren't pinning a transaction ID. ','line_number':458,'multiline':True]
['text':' Schedule a bloom filter create for our newly flushed chunk. ','line_number':463,'multiline':True]
['text':'
 * __wt_lsm_work_enable_evict --
 *     LSM usually pins live chunks in memory - preferring to force them out via a checkpoint when
 *     they are no longer required. For applications that keep data pinned for a long time this can
 *     lead to the cache being pinned full. This work unit detects that case, and enables regular
 *     eviction in chunks that can be correctly evicted.
 ','line_number':478,'multiline':True]
['text':' Only do this if there is cache pressure ','line_number':495,'multiline':True]
['text':'
     * Turn on eviction in chunks that have had some chance to checkpoint if there is cache
     * pressure.
     ','line_number':501,'multiline':True]
['text':'
         * Skip if the chunk isn't on disk yet, or if it's still in cache for a reason other than
         * transaction visibility.
         ','line_number':508,'multiline':True]
['text':'
 * __lsm_bloom_create --
 *     Create a bloom filter for a chunk of the LSM tree that has been checkpointed but not yet been
 *     merged.
 ','line_number':525,'multiline':True]
['text':'
     * This is merge-like activity, and we don't want compacts to give up because we are creating a
     * bunch of bloom filters before merging.
     ','line_number':543,'multiline':True]
['text':' Open a special merge cursor just on this chunk. ','line_number':551,'multiline':True]
['text':'
     * Setup so that we don't hold pages we read into cache, and so that we don't get stuck if the
     * cache is full. If we allow ourselves to get stuck creating bloom filters, the entire tree can
     * stall since there may be no worker threads available to flush.
     ','line_number':556,'multiline':True]
['text':' Load the new Bloom filter into cache. ','line_number':574,'multiline':True]
['text':' Ensure the bloom filter is in the metadata. ','line_number':582,'multiline':True]
['text':'
 * __lsm_discard_handle --
 *     Try to discard a handle from cache.
 ','line_number':599,'multiline':True]
['text':' This will fail with EBUSY if the file is still in use. ','line_number':606,'multiline':True]
['text':'
 * __lsm_drop_file --
 *     Helper function to drop part of an LSM tree.
 ','line_number':614,'multiline':True]
['text':'
     * We need to grab the schema lock to drop the file, so first try to make sure there is minimal
     * work to freeing space in the cache. Only bother trying to discard the checkpoint handle: the
     * in-memory handle should have been closed already.
     *
     * This will fail with EBUSY if the file is still in use.
     ','line_number':624,'multiline':True]
['text':'
     * Take the schema lock for the drop operation. Since __wt_schema_drop results in the hot backup
     * lock being taken when it updates the metadata (which would be too late to prevent our drop).
     ','line_number':635,'multiline':True]
['text':'
 * __lsm_free_chunks --
 *     Try to drop chunks from the tree that are no longer required.
 ','line_number':651,'multiline':True]
['text':'
     * Take a copy of the current state of the LSM tree and look for chunks to drop. We do it this
     * way to avoid holding the LSM tree lock while doing I/O or waiting on the schema lock.
     *
     * This is safe because only one thread will be in this function at a time. Merges may complete
     * concurrently, and the old_chunks array may be extended, but we shuffle down the pointers each
     * time we free one to keep the non-NULL slots at the beginning of the array.
     ','line_number':667,'multiline':True]
['text':' Skip the chunk if another worker is using it. ','line_number':680,'multiline':True]
['text':'
         * Drop any bloom filters and chunks we can. Don't try to drop
         * a chunk if the bloom filter drop fails.
         *  An EBUSY return indicates that a cursor is still open in
         *       the tree - move to the next chunk in that case.
         * An ENOENT return indicates that the LSM tree metadata was
         *       out of sync with the on disk state. Update the
         *       metadata to match in that case.
         ','line_number':686,'multiline':True]
['text':' Lock the tree to clear out the old chunk information. ','line_number':718,'multiline':True]
['text':'
         * The chunk we are looking at should be the first one in the tree that we haven't already
         * skipped over.
         ','line_number':721,'multiline':True]
['text':' Shuffle down to keep all occupied slots at the beginning. ','line_number':730,'multiline':True]
['text':'
         * Clear the chunk in the cookie so we don't attempt to decrement the reference count.
         ','line_number':739,'multiline':True]
['text':' Flush the metadata unless the system is in panic ','line_number':746,'multiline':True]
['text':' Returning non-zero means there is no work to do. ','line_number':755,'multiline':True]
['text':'
 * __wt_lsm_free_chunks --
 *     Try to drop chunks from the tree that are no longer required.
 ','line_number':762,'multiline':True]
['text':'
     * Make sure only a single thread is freeing the old chunk array at any time.
     ','line_number':774,'multiline':True]
