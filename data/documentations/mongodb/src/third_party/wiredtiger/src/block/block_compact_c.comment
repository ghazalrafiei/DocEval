['text':'-
 * Copyright (c) 2014-present MongoDB, Inc.
 * Copyright (c) 2008-2014 WiredTiger, Inc.
 *	All rights reserved.
 *
 * See the file LICENSE for redistribution information.
 ','line_number':1,'multiline':True]
['text':'
 * __wt_block_compact_start --
 *     Start compaction of a file.
 ','line_number':13,'multiline':True]
['text':' Switch to first-fit allocation. ','line_number':24,'multiline':True]
['text':' Reset the compaction state information. ','line_number':27,'multiline':True]
['text':'
 * __wt_block_compact_end --
 *     End compaction of a file.
 ','line_number':44,'multiline':True]
['text':' Restore the original allocation plan. ','line_number':51,'multiline':True]
['text':' Ensure this the same session that started compaction. ','line_number':54,'multiline':True]
['text':' Dump the results of the compaction pass. ','line_number':58,'multiline':True]
['text':'
 * __wt_block_compact_get_progress_stats --
 *     Collect compact progress stats.
 ','line_number':71,'multiline':True]
['text':'
 * __block_compact_trim_extent --
 *     Trim the extent to the given range mask, specified via start and end offsets.
 ','line_number':90,'multiline':True]
['text':' Trim from the beginning. ','line_number':105,'multiline':True]
['text':' Trim from the end. ','line_number':115,'multiline':True]
['text':'
 * __block_compact_skip_internal --
 *     Return if compaction will shrink the file. This function takes a few extra parameters, so
 *     that it can be useful for both making the actual compaction decisions as well as for
 *     estimating the work ahead of the compaction itself: the file size, the smallest offset that
 *     the first-fit allocation is likely to consider, and the number of available (unallocated)
 *     bytes before that offset.
 ','line_number':124,'multiline':True]
['text':' Sum the available bytes in the initial 80% and 90% of the file. ','line_number':142,'multiline':True]
['text':'
     * Skip files where we can't recover at least 1MB.
     *
     * WiredTiger uses first-fit compaction: It finds space in the beginning of the file and moves
     * data from the end of the file into that space. If at least 20% of the total file is available
     * and in the first 80% of the file, we'll try compaction on the last 20% of the file; else, if
     * at least 10% of the total file is available and in the first 90% of the file, we'll try
     * compaction on the last 10% of the file.
     *
     * We could push this further, but there's diminishing returns, a mostly empty file can be
     * processed quickly, so more aggressive compaction is less useful.
     ','line_number':159,'multiline':True]
['text':'
 * __block_compact_estimate_remaining_work --
 *     Estimate how much more work the compaction needs to do for the given file.
 ','line_number':204,'multiline':True]
['text':'
     * We must have reviewed at least some interesting number of pages for any estimates below to be
     * worthwhile.
     ','line_number':218,'multiline':True]
['text':' Assume that we have already checked whether this file can be skipped. ','line_number':225,'multiline':True]
['text':'
     * Get the average block size that we encountered so far during compaction. Note that we are not
     * currently accounting for overflow pages, as compact does not currently account for them
     * either.
     ','line_number':228,'multiline':True]
['text':' We don't currently have a way to track the internal page size, but this should be okay. ','line_number':236,'multiline':True]
['text':'
     * Estimate the average number of leaf pages per one internal page. This way of doing the
     * estimate is sufficient, because we expect each internal node to have a large number of
     * children, so that the number of higher-level internal nodes is small relative to the internal
     * nodes at the bottom.
     ','line_number':239,'multiline':True]
['text':'
     * Estimate the size of a "depth 1" subtree consisting of one internal page and the
     * corresponding leaves.
     ','line_number':248,'multiline':True]
['text':'
     * We would like to estimate how much data will be moved during compaction, so that we can
     * inform users how far along we are in the process. We will estimate how many pages are in the
     * last part of the file (typically the last 10%) and where they will be written using the
     * first-fit allocation, and then repeat as long as we continue to make progress, to emulate the
     * behavior of the actual compaction. This does not account for all complexities that we may
     * encounter, but the hope is that the estimate would be still good enough.
     ','line_number':260,'multiline':True]
['text':' Macro for estimating the number of leaf pages that can be stored within an extent. ','line_number':278,'multiline':True]
['text':' Now do the actual estimation, simulating one compact pass at a time. ','line_number':283,'multiline':True]
['text':'
         * Estimate how many pages we would like to move, just using the live checkpoint. The
         * checkpoint doesn't have a complete list of allocated extents, so we estimate it in two
         * phases: We first take an inverse of the "available" list, which gives us all extents that
         * are either currently allocated or are to be discarded at the next checkpoint. We do this
         * by first estimating the number of pages that can fit in the inverse of the "available"
         * list, and then we subtract the number of pages determined from the "discard" list.
         ','line_number':293,'multiline':True]
['text':' Estimate where in the file we would be when we finish moving those pages. ','line_number':347,'multiline':True]
['text':' See if we ran out of pages to move. ','line_number':378,'multiline':True]
['text':' If there is more work that could be done, repeat with the shorter file. ','line_number':382,'multiline':True]
['text':'
 * __wt_block_compact_progress --
 *     Output compact progress message.
 ','line_number':405,'multiline':True]
['text':' Log one progress message every twenty seconds. ','line_number':421,'multiline':True]
['text':'
         * If we don't have the estimate at this point, it means that we haven't reviewed even
         * enough pages. This should almost never happen.
         ','line_number':426,'multiline':True]
['text':'
 * __wt_block_compact_skip --
 *     Return if compaction will shrink the file.
 ','line_number':451,'multiline':True]
['text':' Return a default skip. ','line_number':458,'multiline':True]
['text':'
     * We do compaction by copying blocks from the end of the file to the beginning of the file, and
     * we need some metrics to decide if it's worth doing. Ignore small files, and files where we
     * are unlikely to recover 10% of the file.
     ','line_number':460,'multiline':True]
['text':' Dump the current state of the file. ','line_number':475,'multiline':True]
['text':'
     * Check if the number of available bytes matches the expected configured threshold. Only
     * perform that check during the first iteration.
     ','line_number':479,'multiline':True]
['text':'
 * __compact_page_skip --
 *     Return if writing a particular page will shrink the file.
 ','line_number':498,'multiline':True]
['text':' Return a default skip. ','line_number':510,'multiline':True]
['text':'
     * If this block is in the chosen percentage of the file and there's a block on the available
     * list that appears before that percentage of the file, rewrite the block. Checking the
     * available list is necessary (otherwise writing the block would extend the file), but there's
     * an obvious race if the file is sufficiently busy.
     ','line_number':512,'multiline':True]
['text':' Estimate how much work is left. ','line_number':540,'multiline':True]
['text':'
 * __wt_block_compact_page_skip --
 *     Return if writing a particular page will shrink the file.
 ','line_number':545,'multiline':True]
['text':' Return a default skip. ','line_number':557,'multiline':True]
['text':' Crack the cookie. ','line_number':560,'multiline':True]
['text':'
 * __wt_block_compact_page_rewrite --
 *     Rewrite a page if it will shrink the file.
 ','line_number':569,'multiline':True]
['text':' Return a default skip. ','line_number':584,'multiline':True]
['text':' -Werror=maybe-uninitialized ','line_number':585,'multiline':True]
['text':' Check if the block is worth rewriting. ','line_number':592,'multiline':True]
['text':' Read the block. ','line_number':598,'multiline':True]
['text':' Allocate a replacement block. ','line_number':602,'multiline':True]
['text':' Write the block. ','line_number':610,'multiline':True]
['text':' Free the original block. ','line_number':613,'multiline':True]
['text':' Build the returned address cookie. ','line_number':619,'multiline':True]
['text':'
 * __block_dump_bucket_stat --
 *     Dump out the information about available and used blocks in the given bucket (part of the
 *     file).
 ','line_number':644,'multiline':True]
['text':' Handle rounding error in which case bucket used size can be negative. ','line_number':657,'multiline':True]
['text':'
 * __block_dump_file_stat --
 *     Dump out the avail/used list so we can see what compaction will look like.
 ','line_number':673,'multiline':True]
['text':'
     * Bucket the available memory into file deciles/percentiles. Large pieces of memory will cross
     * over multiple buckets, assign to the decile/percentile in 512B chunks.
     ','line_number':714,'multiline':True]
['text':'
     * The verbose output always displays 10% buckets, running this code as well also displays 1%
     * buckets. There will be rounding error in the `used` stats because of the bucket size
     * calculation. Adding 50 to minimize the rounding error.
     ','line_number':727,'multiline':True]
['text':'
     * There will be rounding error in the `used` stats because of the bucket size calculation.
     * Adding 5 to minimize the rounding error.
     ','line_number':738,'multiline':True]
