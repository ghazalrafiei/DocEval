['text':'-
 * Public Domain 2014-present MongoDB, Inc.
 * Public Domain 2008-2014 WiredTiger, Inc.
 *
 * This is free and unencumbered software released into the public domain.
 *
 * Anyone is free to copy, modify, publish, use, compile, sell, or
 * distribute this software, either in source code form or as a compiled
 * binary, for any purpose, commercial or non-commercial, and by any
 * means.
 *
 * In jurisdictions that recognize copyright laws, the author or authors
 * of this software dedicate any and all copyright interest in the
 * software to the public domain. We make this dedication for the benefit
 * of the public at large and to the detriment of our heirs and
 * successors. We intend this dedication to be an overt act of
 * relinquishment in perpetuity of all present and future rights to this
 * software under copyright law.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR
 * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
 * OTHER DEALINGS IN THE SOFTWARE.
 ','line_number':1,'multiline':True]
['text':'
 * This test simulates system crashes. It uses direct I/O, and currently
 * runs only on Linux.
 *
 * Our strategy is to run a subordinate 'writer' process that creates/modifies
 * data, including schema modifications. Every N seconds, asynchronously, we
 * send a stop signal to the writer and then copy (with direct I/O) the entire
 * contents of its database home to a new saved location where we can run and
 * verify the recovered home. Then we send a continue signal. We repeat this:
 *
 *   sleep N, STOP, copy, run recovery, CONTINUE
 *
 * which allows the writer to make continuing progress, while the main
 * process is verifying what's on disk.
 *
 * By using stop signal to suspend the process and copying with direct I/O,
 * we are roughly simulating a system crash, by seeing what's actually on
 * disk (not in file system buffer cache) at the moment that the copy is
 * made. It's not quite as harsh as a system crash, as suspending does not
 * halt writes that are in-flight. Still, it's a reasonable proxy for testing.
 *
 * In the main table, the keys look like:
 *
 *   xxxx:T:LARGE_STRING
 *
 * where xxxx represents an increasing decimal id (0 padded to 12 digits).
 * These ids are only unique per thread, so this key is the xxxx-th key
 * written by a thread.  T represents the thread id reduced to a single
 * hex digit. LARGE_STRING is a portion of a large string that includes
 * the thread id and a lot of spaces, over and over (see the large_buf
 * function).  When forming the key, the large string is truncated so
 * that the key is effectively padded to the right length.
 *
 * The key space for the main table is designed to be interleaved tightly
 * among all the threads.  The matching values in the main table are the
 * same, except with the xxxx string reversed.  So the keys and values
 * are the same size.
 *
 * There is also a reverse table where the keys/values are swapped.
 ','line_number':29,'multiline':True]
['text':'
 * The number of threads cannot be more than 16, we are using a hex digit to encode this in the key.
 ','line_number':81,'multiline':True]
['text':' Maximum interval between checkpoints ','line_number':97,'multiline':True]
['text':' Must be one char string ','line_number':99,'multiline':True]
['text':' 64 spaces ','line_number':110,'multiline':True]
['text':'
 * Set the "schema operation frequency" higher to be less stressful for schema
 * operations.  With the current value, 100, there are sequences of schema
 * operations that are begun when the id is in the range 0 to 9, 100 to 109,
 * 200 to 209, etc. That is, 10 sequences per 100.  A higher number (say 1000)
 * means there are 10 sequences started per 1000.  A sequence of schema
 * operations lasts for 4 ids.  So, for example, if thread 3 is inserting id
 * 100 into the main table, an additional schema operation is done (creating a
 * table), and operations on this table continue (while other schema operations
 * continue).
 *
 * Starting at the insert of id 99 (which has no schema operations), here's
 * what will happen (for thread #3).
 *
 * insert k/v 99 into table:main      (with no additional schema operations)
 *
 * insert k/v 100 into table:main
 * create table:A100-3       (3 for thread #3)
 *
 * insert k/v 101 into table:main
 * insert into table:A100-3     (continuing the sequence)
 * create table:A101-3          (starts a new sequence)
 *
 * insert k/v 102 into table:main
 * rename table:A100-3 -> table:B100-3  (third step in sequence)
 * insert into table:A101-3             (second step in sequence)
 * create table:A102-3                  (starting new sequence)
 *
 * insert k/v 103 into table:main
 * update key in table:B100-3          (fourth step)
 * rename table:A101-3 -> table:B101-3 (third step)
 * insert into table:A102-3
 * create table:A103-3
 *
 * insert k/v 104 into table:main
 * drop table:B100-3                   (fifth and last step)
 * update key in table:B101-3          (fourth step)
 * rename table:A102-3 -> table:B102-3
 * insert into table:A103-3
 * create table:A104-3
 * ...
 *
 * This continues, with the last table created when k/v 109 is inserted into
 * table:main and the last sequence finishing at k/v 113.  Each clump above
 * separated by a blank line represents a transaction.  Meanwhile, other
 * threads are doing the same thing.  That stretch, from id 100 to id 113
 * that has schema operations happens again at id 200, assuming frequency
 * set to 100. So it is a good test of schema operations 'in flight'.
 ','line_number':113,'multiline':True]
['text':'
 * Values for flags used in various places.
 ','line_number':173,'multiline':True]
['text':' Uses SCHEMA_* values above ','line_number':202,'multiline':True]
['text':'
 * usage --
 *     Print usage and exit.
 ','line_number':209,'multiline':True]
['text':'
 * has_schema_operation --
 *     Return true if a schema operation should be performed for this id. See the comment above
 *     describing schema operation frequency.
 ','line_number':255,'multiline':True]
['text':'
 * large_buf --
 *     Fill or check a large buffer.
 ','line_number':266,'multiline':True]
['text':'
     * Set up a large value putting our id in it every 1024 bytes or so.
     ','line_number':277,'multiline':True]
['text':'
 * reverse --
 *     Reverse a string in place.
 ','line_number':292,'multiline':True]
['text':'
 * gen_kv --
 *     Generate a key/value.
 ','line_number':310,'multiline':True]
['text':'
 * gen_table_name --
 *     Generate a table name used for the schema test.
 ','line_number':330,'multiline':True]
['text':'
 * gen_table2_name --
 *     Generate a second table name used for the schema test.
 ','line_number':340,'multiline':True]
['text':' table is not renamed, so use original table name ','line_number':348,'multiline':True]
['text':'
 * schema_operation --
 *     TODO: Add a comment describing this function.
 ','line_number':354,'multiline':True]
['text':' Create a table. ','line_number':374,'multiline':True]
['text':'
        fprintf(stderr, "CREATE: %s\n", uri1);
        ','line_number':376,'multiline':True]
['text':' Insert a value into the table. ','line_number':384,'multiline':True]
['text':'
        fprintf(stderr, "INSERT: %s\n", uri1);
        ','line_number':386,'multiline':True]
['text':' Rename the table. ','line_number':398,'multiline':True]
['text':'
            fprintf(stderr, "RENAME: %s->%s\n", uri1, uri2);
            ','line_number':403,'multiline':True]
['text':' Update the single value in the table. ','line_number':412,'multiline':True]
['text':'
        fprintf(stderr, "UPDATE: %s\n", uri2);
        ','line_number':418,'multiline':True]
['text':' Drop the table. ','line_number':427,'multiline':True]
['text':'
            fprintf(stderr, "DROP: %s\n", uri1);
            ','line_number':431,'multiline':True]
['text':'
     * XXX We notice occasional EBUSY errors from rename or drop, even though neither URI should be
     * used by any other thread. Report it, and retry.
     ','line_number':439,'multiline':True]
['text':'
 * set_flush_tier_delay --
 *     Set up a random delay for the next flush_tier.
 ','line_number':454,'multiline':True]
['text':'
     * We are checkpointing with a random interval up to MAX_CKPT_INVL seconds, and we'll do a flush
     * tier randomly every 0-10 seconds.
     ','line_number':461,'multiline':True]
['text':'
 * thread_ckpt_run --
 *     Runner function for the checkpoint thread.
 ','line_number':468,'multiline':True]
['text':'
     * Keep a separate file with the records we wrote for checking.
     ','line_number':486,'multiline':True]
['text':' NOTREACHED ','line_number':503,'multiline':True]
['text':'
 * thread_run --
 *     Run a writer thread.
 ','line_number':508,'multiline':True]
['text':'
     * Split the allocated buffer into two parts, one for the key, one for the value.
     ','line_number':537,'multiline':True]
['text':'
     * Continuing writing until we're killed.
     ','line_number':544,'multiline':True]
['text':'
        if (i > 0 && i % (10 * WT_THOUSAND) == 0)
                printf("Thread %" PRIu32
                    " completed %" PRIu64 " entries\n",
                    td->id, i);
        ','line_number':550,'multiline':True]
['text':'
         * Every 1000th record write a very large value that exceeds the log buffer size. This
         * forces us to use the unbuffered path.
         ','line_number':562,'multiline':True]
['text':'
         * The reverse table has no very large records.
         ','line_number':573,'multiline':True]
['text':'
         * If we are not running integrated tests, then we commit the transaction now so that schema
         * operations are not part of the transaction operations for the main table. If we are
         * running 'integrated' then we'll first do the schema operations and commit later.
         ','line_number':580,'multiline':True]
['text':'
         * If we are doing a schema test, generate operations for additional tables. Each table has
         * a 'lifetime' of 4 values of the id.
         ','line_number':587,'multiline':True]
['text':' Create is implied by any schema operation. ','line_number':592,'multiline':True]
['text':'
             * Any or all of the schema operations may be performed as part of this transaction. See
             * the comment for schema operation frequency.
             ','line_number':595,'multiline':True]
['text':'
                 * Only rollback if integrated and we have an active transaction.
                 ','line_number':603,'multiline':True]
['text':'
         * If schema operations are integrated, commit the transaction now that they're complete.
         ','line_number':612,'multiline':True]
['text':' NOTREACHED ','line_number':618,'multiline':True]
['text':'
 * create_db --
 *     Creates the database and tables so they are fully ready to be accessed by subordinate
 *     threads, and copied/recovered.
 ','line_number':621,'multiline':True]
['text':'
     * Checkpoint to help ensure that everything gets out to disk, so any direct I/O copy will have
     * at least have tables that can be opened.
     ','line_number':646,'multiline':True]
['text':'
 * fill_db --
 *     The child process creates worker threads to add data until it is killed by the parent.
 ','line_number':658,'multiline':True]
['text':' Allocate number of threads plus another for checkpoint. ','line_number':671,'multiline':True]
['text':' Add an extra byte for string termination ','line_number':690,'multiline':True]
['text':'
     * The threads never exit, so the child will just wait here until it is killed.
     ','line_number':710,'multiline':True]
['text':'
     * NOTREACHED
     ','line_number':717,'multiline':True]
['text':'
 * check_kv --
 *     Check that a key exists with a value, or does not exist.
 ','line_number':725,'multiline':True]
['text':'
 * check_dropped --
 *     Check that the uri has been dropped.
 ','line_number':753,'multiline':True]
['text':'
 * check_empty --
 *     Check that the uri exists and is empty.
 ','line_number':767,'multiline':True]
['text':'
 * check_one_entry --
 *     Check that the uri exists and has one entry.
 ','line_number':783,'multiline':True]
['text':'
 * check_schema --
 *     Check that the database has the expected schema according to the last id seen for this
 *     thread.
 ','line_number':805,'multiline':True]
['text':' Create table operation. ','line_number':821,'multiline':True]
['text':' Insert value operation. ','line_number':829,'multiline':True]
['text':' Table rename operation. ','line_number':837,'multiline':True]
['text':' Value update operation. ','line_number':848,'multiline':True]
['text':' Drop table operation. ','line_number':857,'multiline':True]
['text':'
 * kill_child --
 *     TODO: Add a comment describing this function.
 ','line_number':865,'multiline':True]
['text':'
     * The child is stopped, it won't process an abort until it is continued. First signal the
     * abort, then signal continue so that the child process will process the abort and dump core.
     ','line_number':874,'multiline':True]
['text':'
 * die --
 *     Called when testutil_assert or testutil_check fails to clean up a child process if it exists.
 ','line_number':884,'multiline':True]
['text':'
 * check_db --
 *     Make a copy of the database and verify its contents.
 ','line_number':899,'multiline':True]
['text':'
     * We make a copy of the directory (possibly using direct I/O) for recovery and checking, and an
     * identical copy that keeps the state of all files before recovery starts.
     ','line_number':929,'multiline':True]
['text':'
     * Copy the original home directory explicitly without direct I/O. Copy this first because
     * copying with directio may abort and we want to see what the original copy saw.
     ','line_number':936,'multiline':True]
['text':' If this fails, abort the child process before we die so we can see what it was doing. ','line_number':952,'multiline':True]
['text':'
 * We're most interested in the final records on disk. Rather than walk all records, we do a quick
 * scan to find the last complete set of written ids. Each thread writes each id, along with the
 * thread id, so they are interleaved. Once we have the neighborhood where some keys may be missing,
 * we'll back up to do a scan from that point.
 ','line_number':963,'multiline':True]
['text':' Keep bitmap of "active" threads. ','line_number':996,'multiline':True]
['text':'
         * See if the expected thread has finished at this point. If so, remove it from the thread
         * map.
         ','line_number':1016,'multiline':True]
['text':'
                 * Any newly removed value in the main table should not be present as a key in the
                 * reverse table, since they were transactionally inserted at the same time.
                 ','line_number':1024,'multiline':True]
['text':'
         * Check that the key and value fully match.
         ','line_number':1037,'multiline':True]
['text':'
         * Every 1000th record is large.
         ','line_number':1045,'multiline':True]
['text':'
         * Check the reverse file, with key/value reversed.
         ','line_number':1053,'multiline':True]
['text':' Bump thread number and id to the next expected key. ','line_number':1060,'multiline':True]
['text':'
         * Check metadata to see if there are any tables present that shouldn't be there.
         ','line_number':1068,'multiline':True]
['text':'
             * Names involved in schema testing are of the form:
             *   table:Axxx-t
             *   table:Bxxx-t
             * xxx corresponds to the id inserted into the main
             * table when the table was created, and t corresponds
             * to the thread id that did this.
             ','line_number':1075,'multiline':True]
['text':'
                 * If table operations are truly transactional, then there shouldn't be any extra
                 * files that unaccounted for.
                 ','line_number':1088,'multiline':True]
['text':'
 * handler --
 *     Child signal handler
 ','line_number':1112,'multiline':True]
['text':' Check if child has been killed by die(), if so, no need to wait. ','line_number':1124,'multiline':True]
['text':' Nothing to wait for. ','line_number':1130,'multiline':True]
['text':'
     * The core file will indicate why the child exited. Choose EINVAL here.
     ','line_number':1144,'multiline':True]
['text':'
 * has_direct_io --
 *     Check for direct I/O support.
 ','line_number':1151,'multiline':True]
['text':'
 * main --
 *     Top level test.
 ','line_number':1165,'multiline':True]
['text':' Set our own abort handler ','line_number':1184,'multiline':True]
['text':' The option is either one that we're asking testutil to support, or illegal. ','line_number':1293,'multiline':True]
['text':' Among other things, this initializes the random number generators in the option structure. ','line_number':1301,'multiline':True]
['text':'
     * If the user wants to verify they need to tell us how many threads there were so we know what
     * records we can expect.
     ','line_number':1308,'multiline':True]
['text':'
             * Fork a child to insert as many items. We will then randomly suspend the child, run
             * recovery and make sure all items we wrote exist after recovery runs.
             ','line_number':1350,'multiline':True]
['text':' child, or populate_only ','line_number':1359,'multiline':True]
['text':' NOTREACHED ','line_number':1361,'multiline':True]
['text':' parent ','line_number':1364,'multiline':True]
['text':'
         * Sleep for the configured amount of time before killing the child.
         ','line_number':1366,'multiline':True]
['text':'
         * Begin our cycles of suspend, copy, recover.
         ','line_number':1371,'multiline':True]
