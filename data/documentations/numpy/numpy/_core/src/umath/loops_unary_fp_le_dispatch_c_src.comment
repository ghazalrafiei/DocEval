['text':'@targets
 ** $maxopt baseline
 ** sse2 sse41
 ** vsx2
 ** neon asimd
 *','line_number':1,'multiline':True]
['text':'*
 * Force use SSE only on x86, even if AVX2 or AVX512F are enabled
 * through the baseline, since scatter(AVX512F) and gather very costly
 * to handle non-contiguous memory access comparing with SSE for
 * such small operations that this file covers.
 ','line_number':8,'multiline':True]
['text':' Provides the various *_LOOP macros','line_number':24,'multiline':False]
['text':'*
 * This code should really be merged into loops_unary_fp.dispatch.c.src
 * However there is an issue with enabling the code here for VX and VXE
 * as the shifts don't behave as expected.
 * See the code below that references NPY__CPU_TARGET_VX and
 * NPY_BIG_ENDIAN. Suspect that this is a big endian vector issue.
 *
 * Splitting the files out allows us to keep loops_unary_fp.dispatch.c.src
 * building for VX and VXE so we don't regress performance while adding this
 * code for other platforms.
 ','line_number':27,'multiline':True]
['text':' TODO(@seiko2plus): add support for big-endian','line_number':38,'multiline':False]
['text':'******************************************************************************
 ** extra SIMD intrinsics
 *****************************************************************************','line_number':48,'multiline':True]
['text':'*
 * We define intrinsics for isnan, isinf, isfinite, and signbit below.  There's
 * a few flavors of each.  We'll use f32 as an example although f64 versions
 * are also defined.
 * 
 * npyv_u32 npyv_KIND_f32(npyv_f32 v)
 *   These are mainly used for the single vector loops.  As such, result should
 *   be bool true / false, ready to write back.
 * 
 * npyv_b32 _npyv_KIND_f32(npyv_f32 v)
 *   These are used by the geneal intrinsics above as well as the multi-vector
 *   packing intrinsics.  The multi-vector packing intrinsics are the ones
 *   utilized in the unrolled vector loops.  Results should be vector masks
 *   of 0x00/0xff.
 * 
 * npyv_u8 npyv_pack_KIND_f32(npyv_f32 v0, npyv_f32 v1, npyv_f32 v2, npyv_f32 v3)
 *   These are the multi-vector packing intrinsics utilized by unrolled vector
 *   loops.  They perform the operation on all input vectors and pack the
 *   results to a single npyv_u8.  Assuming NPY_SIMD == 128, that means we
 *   can pack results from 4x npyv_f32 or 8x npyv_64 in a single npyv_u8.
 *   Result should be bool true / false, ready to write back.
 ','line_number':54,'multiline':True]
['text':' abs(v) > FLT_MAX','line_number':128,'multiline':False]
['text':' cast out the sign and check if all exponent bits are set.','line_number':132,'multiline':False]
['text':' NPY_SIMD_F32','line_number':155,'multiline':False]
['text':' abs(v) > DBL_MAX','line_number':161,'multiline':False]
['text':' cast out the sign and check if all exponent bits are set.','line_number':165,'multiline':False]
['text':' NPY_SIMD_F64','line_number':193,'multiline':False]
['text':' cast out the sign and check if all exponent bits are set','line_number':200,'multiline':False]
['text':' no matter the mentissa is.','line_number':201,'multiline':False]
['text':' F32 exponent is 8-bits, which means we can pack multiple into','line_number':218,'multiline':False]
['text':' a single vector.  We shift out sign bit so that we're left','line_number':219,'multiline':False]
['text':' with only exponent in high byte.  If not all bits are set,','line_number':220,'multiline':False]
['text':' then we've got a finite number.','line_number':221,'multiline':False]
['text':' NPY_SIMD_F32','line_number':245,'multiline':False]
['text':' cast out the sign and check if all exponent bits are set','line_number':250,'multiline':False]
['text':' no matter the mantissa is.','line_number':251,'multiline':False]
['text':' F64 exponent is 11-bits, which means we can pack multiple into','line_number':269,'multiline':False]
['text':' a single vector.  We'll need to use u16 to fit all exponent','line_number':270,'multiline':False]
['text':' bits.  If not all bits are set, then we've got a finite number.','line_number':271,'multiline':False]
['text':' NPY_SIMD_F64','line_number':310,'multiline':False]
['text':' We only need high byte for signbit, which means we can pack','line_number':322,'multiline':False]
['text':' multiple inputs into a single vector.','line_number':323,'multiline':False]
['text':' NPY_SIMD_F32','line_number':343,'multiline':False]
['text':' We only need high byte for signbit, which means we can pack','line_number':355,'multiline':False]
['text':' multiple inputs into a single vector.','line_number':356,'multiline':False]
['text':' vuzp2 faster than vtbl for f64','line_number':358,'multiline':False]
['text':' NPY_SIMD_F64','line_number':383,'multiline':False]
['text':' NPY_SIMD','line_number':385,'multiline':False]
['text':'*******************************************************************************
 ** Defining the SIMD kernels
 *******************************************************************************','line_number':387,'multiline':True]
['text':'* Notes:
 * - avoid the use of libmath to unify fp/domain errors
 *   for both scalars and vectors among all compilers/architectures.
 * - use intrinsic npyv_load_till_* instead of npyv_load_tillz_
 *   to fill the remind lanes with 1.0 to avoid divide by zero fp
 *   exception in reciprocal.
 ','line_number':390,'multiline':True]
['text':'*begin repeat
 * #TYPE = FLOAT, DOUBLE#
 * #sfx  = f32, f64#
 * #VCHK = NPY_SIMD_F32, NPY_SIMD_F64#
 * #ssfx = 32, 64#
 ','line_number':400,'multiline':True]
['text':'*begin repeat1
 * #kind = isnan, isinf, isfinite, signbit#
 ','line_number':407,'multiline':True]
['text':'*begin repeat2
 * #STYPE  = CONTIG, NCONTIG, CONTIG,  NCONTIG#
 * #DTYPE  = CONTIG, CONTIG,  NCONTIG, NCONTIG#
 ','line_number':410,'multiline':True]
['text':' How many vectors can be packed into a u8 / bool vector?','line_number':420,'multiline':False]
['text':' unrolled iterations','line_number':427,'multiline':False]
['text':' Load vectors','line_number':429,'multiline':False]
['text':' contiguous input','line_number':431,'multiline':False]
['text':' non-contiguous input','line_number':443,'multiline':False]
['text':' @DTYPE@ == CONTIG','line_number':464,'multiline':False]
['text':' Results are packed, so we can just loop over them','line_number':465,'multiline':False]
['text':' @DTYPE@ == CONTIG','line_number':471,'multiline':False]
['text':' vector-sized iterations','line_number':474,'multiline':False]
['text':' Scalar loop to finish off','line_number':497,'multiline':False]
['text':'*end repeat2*','line_number':504,'multiline':True]
['text':'*end repeat1*','line_number':505,'multiline':True]
['text':' @VCHK@','line_number':507,'multiline':False]
['text':'*end repeat*','line_number':508,'multiline':True]
['text':'*******************************************************************************
 ** Defining ufunc inner functions
 *******************************************************************************','line_number':510,'multiline':True]
['text':'*begin repeat
 * #TYPE = FLOAT, DOUBLE#
 * #sfx  = f32, f64#
 * #VCHK = NPY_SIMD_F32, NPY_SIMD_F64#
 ','line_number':513,'multiline':True]
['text':'*begin repeat1
 * #kind = isnan, isinf, isfinite, signbit#
 *','line_number':519,'multiline':True]
['text':' @VCHK@','line_number':554,'multiline':False]
['text':'*end repeat1*','line_number':564,'multiline':True]
['text':'*end repeat*','line_number':565,'multiline':True]
