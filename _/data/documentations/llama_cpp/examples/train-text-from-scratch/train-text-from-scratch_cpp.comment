['text':' possible loss of data','line_number':19,'multiline':False]['text':' float f_norm_eps     = 1e-5f; // falcon','line_number':33,'multiline':False]['text':' llama','line_number':34,'multiline':False]['text':' normalization','line_number':41,'multiline':False]['text':' attention','line_number':44,'multiline':False]['text':' normalization','line_number':50,'multiline':False]['text':' ff','line_number':53,'multiline':False]['text':' gguf constants (sync with gguf.py)','line_number':73,'multiline':False]['text':' TODO load in llama.cpp','line_number':87,'multiline':False]['text':' context for model tensors without their data','line_number':205,'multiline':False]['text':' measure data size','line_number':255,'multiline':False]['text':' allocate data','line_number':261,'multiline':False]['text':' KQ_pos - contains the positions','line_number':336,'multiline':False]['text':' rope has so much parameters that we make a custom function for it','line_number':346,'multiline':False]['text':' not capturing these, to silcence warnings','line_number':349,'multiline':False]['text':' make sure some tensors are not reallocated by inserting new temporary nodes depending on them','line_number':444,'multiline':False]['text':' output tensors','line_number':448,'multiline':False]['text':' input gradient','line_number':451,'multiline':False]['text':' KQ_pos','line_number':453,'multiline':False]['text':' allocating checkpoints in one block to reduce memory fragmentation','line_number':459,'multiline':False]['text':' note: they will be freed in reverse order','line_number':460,'multiline':False]['text':'int n_leafs_after = gb->n_leafs;','line_number':467,'multiline':False]['text':'int n_nodes_after = gb->n_nodes;','line_number':468,'multiline':False]['text':' remove the additional nodes and leafs','line_number':472,'multiline':False]['text':' NOTE: gguf_context must be initialized with f_ggml_ctx and no_alloc=false, otherwise tensor data can not be read','line_number':503,'multiline':False]['text':' n_ctx was not saved in earlier checkpoint file versions, so we make it optional here','line_number':533,'multiline':False]['text':' set arch','line_number':584,'multiline':False]['text':' set hparams','line_number':588,'multiline':False]['text':' TODO load in llama.cpp','line_number':597,'multiline':False]['text':' set vocab by copying from vocab_model gguf file','line_number':600,'multiline':False]['text':'.no_alloc = ','line_number':603,'multiline':True]['text':'.ctx      = ','line_number':604,'multiline':True]['text':' default special tokens','line_number':641,'multiline':False]['text':' read and copy bpe merges','line_number':648,'multiline':False]['text':' default special tokens','line_number':663,'multiline':False]['text':' add tensors','line_number':696,'multiline':False]['text':' write file','line_number':722,'multiline':False]['text':' write file','line_number':766,'multiline':False]['text':' llama.cpp requires n_rot to be exactly n_embd / n_head','line_number':996,'multiline':False]['text':' set opt params from command line','line_number':1005,'multiline':False]['text':' overwrite last n_ctx with user provided n_ctx','line_number':1028,'multiline':False]['text':' need to discard previous optimizer past function value statistics and opt_init with new shapes','line_number':1037,'multiline':False]['text':' TODO','line_number':1038,'multiline':False]['text':' context for input tensors without their data','line_number':1086,'multiline':False]['text':' mem_size','line_number':1088,'multiline':False]['text':' mem_buffer','line_number':1089,'multiline':False]['text':' no_alloc','line_number':1090,'multiline':False]['text':' the input tensors','line_number':1094,'multiline':False]['text':' measure required memory for input tensors','line_number':1098,'multiline':False]['text':' allocate input tensors','line_number':1104,'multiline':False]['text':' context for compute tensors without their data','line_number':1111,'multiline':False]['text':' mem_size','line_number':1117,'multiline':False]['text':' mem_buffer','line_number':1118,'multiline':False]['text':' no_alloc','line_number':1119,'multiline':False]['text':' measure required memory for compute tensors','line_number':1130,'multiline':False]['text':' find best evaluation order','line_number':1133,'multiline':False]['text':' allocate compute tensors','line_number':1166,'multiline':False]['text':' measure required memory for work buffer','line_number':1264,'multiline':False]['text':' context for work buffer','line_number':1268,'multiline':False]['text':' mem_size','line_number':1270,'multiline':False]['text':' mem_buffer','line_number':1271,'multiline':False]['text':' no_alloc','line_number':1272,'multiline':False]