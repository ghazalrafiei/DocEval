['text':' possible loss of data','line_number':20,'multiline':False]['text':'argc','line_number':61,'multiline':True]['text':' create the ggml context','line_number':105,'multiline':False]['text':'const int sizex = 4096;','line_number':107,'multiline':False]['text':'const int sizey = 11008;','line_number':108,'multiline':False]['text':' Working - let's increase size ','line_number':116,'multiline':True]['text':'const int sizey = 1;
    const int sizex = 3*(8*32);
    const int sizez = 1;','line_number':121,'multiline':True]['text':'printf("Memsize required = %i\n", sizex*sizex);','line_number':126,'multiline':False]['text':' TODO: perform the bench for all types or for a user specified type','line_number':128,'multiline':False]['text':' BLAS','line_number':137,'multiline':False]['text':' BLAS','line_number':138,'multiline':False]['text':'.mem_size   =','line_number':144,'multiline':True]['text':'.mem_buffer =','line_number':145,'multiline':True]['text':' no_alloc   =','line_number':146,'multiline':True]['text':' printf("Creating new tensor m1\n");','line_number':157,'multiline':False]['text':' printf("Creating new tensor m1\n");','line_number':161,'multiline':False]['text':' printf("Creating new tensor m2\n");','line_number':165,'multiline':False]['text':' printf("Creating new tensor m11xm2\n");','line_number':170,'multiline':False]['text':' printf("Creating compute graph\n");','line_number':173,'multiline':False]['text':' Set up a the benchmark matrices','line_number':194,'multiline':False]['text':' printf("Creating new tensor q11 & Running quantize\n");','line_number':195,'multiline':False]['text':' Set up a the compute graph','line_number':199,'multiline':False]['text':' printf("Creating new tensor q31\n");','line_number':200,'multiline':False]['text':' printf("Creating compute graph\n");','line_number':203,'multiline':False]['text':' Set up a second graph computation to make sure we override the CPU cache lines','line_number':207,'multiline':False]['text':' printf("Creating new tensor q12 & Running quantize\n");','line_number':208,'multiline':False]['text':' printf("Creating new tensor q32\n");','line_number':212,'multiline':False]['text':'printf("Creating compute graph\n");','line_number':215,'multiline':False]['text':' Let's use the F32 result from above as a reference for the quantized multiplication','line_number':228,'multiline':False]['text':'printf("Running ggml_graph_compute\n");','line_number':238,'multiline':False]['text':' Check that the matrix multiplication result is in the right ballpark','line_number':255,'multiline':False]['text':' We cannot use the exact value from the F32 multiplication because the quantizuation will be slightly different','line_number':256,'multiline':False]['text':'  Let's accept an epsilon of 10^-6','line_number':259,'multiline':False]['text':' Running a different graph computation to make sure we override the CPU cache lines','line_number':271,'multiline':False]