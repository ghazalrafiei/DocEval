['text':' if YCM cannot find <arm_neon.h>, make a symbolic link to it, for example:','line_number':11,'multiline':False]['text':'','line_number':12,'multiline':False]['text':'   $ ln -sfn /Library/Developer/CommandLineTools/usr/lib/clang/13.1.6/include/arm_neon.h ./src/','line_number':13,'multiline':False]['text':'','line_number':14,'multiline':False]['text':' multiply int8_t, add results pairwise twice','line_number':53,'multiline':False]['text':' Get absolute values of x vectors','line_number':55,'multiline':False]['text':' Sign the values of the y vectors','line_number':57,'multiline':False]['text':' Perform multiplication and create 16-bit values','line_number':59,'multiline':False]['text':' horizontally add 8 floats','line_number':66,'multiline':False]['text':' horizontally add 8 int32_t','line_number':75,'multiline':False]['text':' horizontally add 4 int32_t','line_number':84,'multiline':False]['text':' spread 32 bits to 32 bytes { 0x00, 0xFF }','line_number':93,'multiline':False]['text':' Unpack 32 4-bit fields into 32 bytes','line_number':106,'multiline':False]['text':' The output vector contains 32 bytes, each one in [ 0 .. 15 ] interval','line_number':107,'multiline':False]['text':' add int16_t pairwise and return as float vector','line_number':116,'multiline':False]['text':' Perform multiplication and create 16-bit values','line_number':129,'multiline':False]['text':' multiply int8_t, add results pairwise twice and return as float vector','line_number':135,'multiline':False]['text':' Get absolute values of x vectors','line_number':142,'multiline':False]['text':' Sign the values of the y vectors','line_number':144,'multiline':False]['text':' Move bits within 16-bit lanes from 0000_abcd_0000_efgh into 0000_0000_abcd_efgh','line_number':152,'multiline':False]['text':' 0000_0000_abcd_0000','line_number':154,'multiline':False]['text':' 0000_abcd_abcd_efgh','line_number':155,'multiline':False]['text':' abcd_efgh','line_number':156,'multiline':False]['text':' Compress uint16_t lanes into bytes','line_number':164,'multiline':False]['text':' spread 32 bits to 32 bytes { 0x00, 0xFF }','line_number':171,'multiline':False]['text':' Unpack 32 4-bit fields into 32 bytes','line_number':187,'multiline':False]['text':' The output vector contains 32 bytes, each one in [ 0 .. 15 ] interval','line_number':188,'multiline':False]['text':' Load 16 bytes from memory','line_number':191,'multiline':False]['text':' add int16_t pairwise and return as float vector','line_number':200,'multiline':False]['text':' Perform multiplication and create 16-bit values','line_number':214,'multiline':False]['text':' multiply int8_t, add results pairwise twice and return as float vector','line_number':220,'multiline':False]['text':' Get absolute values of x vectors','line_number':226,'multiline':False]['text':' Sign the values of the y vectors','line_number':229,'multiline':False]['text':' Perform multiplication and create 16-bit values','line_number':232,'multiline':False]['text':' Move bits within 16-bit lanes from 0000_abcd_0000_efgh into 0000_0000_abcd_efgh','line_number':240,'multiline':False]['text':' horizontally add 4x4 floats','line_number':255,'multiline':False]['text':' __AVX__ || __AVX2__ || __AVX512F__','line_number':265,'multiline':False]['text':' defined(__AVX__) || defined(__AVX2__) || defined(__AVX512F__) || defined(__SSSE3__)','line_number':266,'multiline':False]['text':' 64-bit compatibility','line_number':271,'multiline':False]['text':' vaddvq_s16','line_number':273,'multiline':False]['text':' vpaddq_s16','line_number':274,'multiline':False]['text':' vaddvq_s32','line_number':275,'multiline':False]['text':' vaddvq_f32','line_number':276,'multiline':False]['text':' vmaxvq_f32','line_number':277,'multiline':False]['text':' vcvtnq_s32_f32','line_number':278,'multiline':False]['text':' vld1q_s16_x2','line_number':319,'multiline':False]['text':' vld1q_u8_x2','line_number':320,'multiline':False]['text':' vld1q_u8_x4','line_number':321,'multiline':False]['text':' vld1q_s8_x2','line_number':322,'multiline':False]['text':' vld1q_s8_x4','line_number':323,'multiline':False]['text':' TODO: double-check these work correctly','line_number':324,'multiline':False]['text':' precomputed tables for expanding 8bits to 8 bytes:','line_number':422,'multiline':False]['text':' ( b) << 4','line_number':423,'multiline':False]['text':' (!b) << 4','line_number':424,'multiline':False]['text':' reference implementation for deterministic creation of model files','line_number':427,'multiline':False]['text':' absolute max','line_number':436,'multiline':False]['text':' absolute max','line_number':518,'multiline':False]['text':' get the 5-th bit and store it in qh at the right position','line_number':545,'multiline':False]['text':' get the 5-th bit and store it in qh at the right position','line_number':593,'multiline':False]['text':' reference implementation for deterministic creation of model files','line_number':606,'multiline':False]['text':' absolute max','line_number':612,'multiline':False]['text':' Load elements into 4 AVX vectors','line_number':704,'multiline':False]['text':' Compute max(abs(e)) for the block','line_number':711,'multiline':False]['text':' Quantize these floats','line_number':723,'multiline':False]['text':' Apply the multiplier','line_number':729,'multiline':False]['text':' Round to nearest integer','line_number':735,'multiline':False]['text':' Convert floats to integers','line_number':741,'multiline':False]['text':' Convert int32 to int16','line_number':748,'multiline':False]['text':' 0, 1, 2, 3,  8, 9, 10, 11,  4, 5, 6, 7, 12, 13, 14, 15','line_number':749,'multiline':False]['text':' 16, 17, 18, 19,  24, 25, 26, 27,  20, 21, 22, 23, 28, 29, 30, 31','line_number':750,'multiline':False]['text':' Convert int16 to int8','line_number':751,'multiline':False]['text':' 0, 1, 2, 3,  8, 9, 10, 11,  16, 17, 18, 19,  24, 25, 26, 27,  4, 5, 6, 7, 12, 13, 14, 15, 20, 21, 22, 23, 28, 29, 30, 31','line_number':752,'multiline':False]['text':' We got our precious signed bytes, but the order is now wrong','line_number':754,'multiline':False]['text':' These AVX2 pack instructions process 16-byte pieces independently','line_number':755,'multiline':False]['text':' The following instruction is fixing the order','line_number':756,'multiline':False]['text':' Since we don't have in AVX some necessary functions,','line_number':762,'multiline':False]['text':' we split the registers in half and call AVX2 analogs from SSE','line_number':763,'multiline':False]['text':' Convert int32 to int16','line_number':773,'multiline':False]['text':' Convert int16 to int8','line_number':778,'multiline':False]['text':' load elements','line_number':791,'multiline':False]['text':' convert to integer','line_number':806,'multiline':False]['text':' store result','line_number':810,'multiline':False]['text':' scalar','line_number':815,'multiline':False]['text':' reference implementation for deterministic creation of model files','line_number':820,'multiline':False]['text':' absolute max','line_number':827,'multiline':False]['text':' Load elements into 4 AVX vectors','line_number':942,'multiline':False]['text':' Compute max(abs(e)) for the block','line_number':949,'multiline':False]['text':' Quantize these floats','line_number':961,'multiline':False]['text':' Apply the multiplier','line_number':967,'multiline':False]['text':' Round to nearest integer','line_number':973,'multiline':False]['text':' Convert floats to integers','line_number':979,'multiline':False]['text':' Compute the sum of the quants and set y[i].s','line_number':986,'multiline':False]['text':' Convert int32 to int16','line_number':989,'multiline':False]['text':' 0, 1, 2, 3,  8, 9, 10, 11,  4, 5, 6, 7, 12, 13, 14, 15','line_number':990,'multiline':False]['text':' 16, 17, 18, 19,  24, 25, 26, 27,  20, 21, 22, 23, 28, 29, 30, 31','line_number':991,'multiline':False]['text':' Convert int16 to int8','line_number':992,'multiline':False]['text':' 0, 1, 2, 3,  8, 9, 10, 11,  16, 17, 18, 19,  24, 25, 26, 27,  4, 5, 6, 7, 12, 13, 14, 15, 20, 21, 22, 23, 28, 29, 30, 31','line_number':993,'multiline':False]['text':' We got our precious signed bytes, but the order is now wrong','line_number':995,'multiline':False]['text':' These AVX2 pack instructions process 16-byte pieces independently','line_number':996,'multiline':False]['text':' The following instruction is fixing the order','line_number':997,'multiline':False]['text':' Since we don't have in AVX some necessary functions,','line_number':1003,'multiline':False]['text':' we split the registers in half and call AVX2 analogs from SSE','line_number':1004,'multiline':False]['text':' Compute the sum of the quants and set y[i].s','line_number':1014,'multiline':False]['text':' Convert int32 to int16','line_number':1019,'multiline':False]['text':' Convert int16 to int8','line_number':1024,'multiline':False]['text':' load elements','line_number':1037,'multiline':False]['text':' convert to integer','line_number':1052,'multiline':False]['text':' store result','line_number':1056,'multiline':False]['text':' compute sum for y[i].s','line_number':1059,'multiline':False]['text':' set y[i].s','line_number':1063,'multiline':False]['text':' scalar','line_number':1069,'multiline':False]['text':'','line_number':1184,'multiline':False]['text':' 2-6 bit quantization in super-blocks','line_number':1185,'multiline':False]['text':'','line_number':1186,'multiline':False]['text':'','line_number':1188,'multiline':False]['text':' ===================== Helper functions','line_number':1189,'multiline':False]['text':'','line_number':1190,'multiline':False]['text':' all zero','line_number':1205,'multiline':False]['text':' all zero','line_number':1269,'multiline':False]['text':' use 'volatile' to prevent unroll and work around a bug in Apple ld64 1015.7','line_number':1372,'multiline':False]['text':'========================- 2-bit (de)-quantization','line_number':1456,'multiline':False]['text':' as we are deducting the min, scales are always positive','line_number':1471,'multiline':False]['text':' TODO: collect histograms','line_number':1586,'multiline':False]['text':'========================= 3-bit (de)-quantization','line_number':1595,'multiline':False]['text':' We put the high-bit for the 1st 8 quants into bit 0, the next 8 into bit 1, etc.','line_number':1682,'multiline':False]['text':' TODO: collect histograms','line_number':1799,'multiline':False]['text':' ====================== 4-bit (de)-quantization','line_number':1808,'multiline':False]['text':' as we are deducting the min, scales are always positive','line_number':1822,'multiline':False]['text':'scales[j] = make_qkx1_quants(32, 15, x + 32*j, L + 32*j, &mins[j], 9, 0.5f);','line_number':1825,'multiline':False]['text':' TODO: collect histograms','line_number':1964,'multiline':False]['text':' ====================== 5-bit (de)-quantization','line_number':1973,'multiline':False]['text':' as we are deducting the min, scales are always positive','line_number':1994,'multiline':False]['text':'scales[j] = make_qkx1_quants(32, 31, x + 32*j, L + 32*j, &mins[j], 9, 0.5f);','line_number':1997,'multiline':False]['text':' TODO: collect histograms','line_number':2170,'multiline':False]['text':' ====================== 6-bit (de)-quantization','line_number':2179,'multiline':False]['text':' TODO: collect histograms','line_number':2318,'multiline':False]['text':'===================================== Q8_K ==============================================','line_number':2327,'multiline':False]['text':'===================================== Dot ptoducts =================================','line_number':2381,'multiline':False]['text':'','line_number':2383,'multiline':False]['text':' Helper functions','line_number':2384,'multiline':False]['text':'','line_number':2385,'multiline':False]['text':' shuffles to pick the required scales in dot products','line_number':2388,'multiline':False]['text':' TODO: handle odd nb','line_number':2439,'multiline':False]['text':' 4-bit -> 8-bit','line_number':2453,'multiline':False]['text':' sub 8','line_number':2459,'multiline':False]['text':' load y','line_number':2465,'multiline':False]['text':' dot product into int32x4_t','line_number':2472,'multiline':False]['text':' Initialize accumulator with zeros','line_number':2501,'multiline':False]['text':' Main loop','line_number':2504,'multiline':False]['text':' Compute combined scale for the block ','line_number':2506,'multiline':True]['text':' Now we have a vector with bytes in [ 0 .. 15 ] interval. Offset them into [ -8 .. +7 ] interval.','line_number':2511,'multiline':False]['text':' Multiply q with scale and accumulate ','line_number':2519,'multiline':True]['text':' Initialize accumulator with zeros','line_number':2525,'multiline':False]['text':' Main loop','line_number':2528,'multiline':False]['text':' Compute combined scale for the block','line_number':2530,'multiline':False]['text':' Convert int32_t to float','line_number':2548,'multiline':False]['text':' Apply the scale, and accumulate','line_number':2551,'multiline':False]['text':' set constants','line_number':2557,'multiline':False]['text':' Initialize accumulator with zeros','line_number':2561,'multiline':False]['text':' First round without accumulation','line_number':2567,'multiline':False]['text':' Compute combined scale for the block 0 and 1','line_number':2572,'multiline':False]['text':' Compute combined scale for the block 2 and 3','line_number':2590,'multiline':False]['text':' Convert int32_t to float','line_number':2605,'multiline':False]['text':' Apply the scale','line_number':2611,'multiline':False]['text':' TODO: handle odd nb','line_number':2618,'multiline':False]['text':' Main loop','line_number':2620,'multiline':False]['text':' Compute combined scale for the block 0 and 1','line_number':2625,'multiline':False]['text':' Compute combined scale for the block 2 and 3','line_number':2643,'multiline':False]['text':' Convert int32_t to float','line_number':2658,'multiline':False]['text':' Apply the scale','line_number':2664,'multiline':False]['text':' Acummulate','line_number':2670,'multiline':False]['text':' load elements','line_number':2684,'multiline':False]['text':' mask and store lower part of x, and then upper part','line_number':2690,'multiline':False]['text':' subtract offset','line_number':2697,'multiline':False]['text':' scalar','line_number':2716,'multiline':False]['text':' TODO: add WASM SIMD','line_number':2745,'multiline':False]['text':' TODO: handle odd nb','line_number':2752,'multiline':False]['text':' 4-bit -> 8-bit','line_number':2767,'multiline':False]['text':' load y','line_number':2773,'multiline':False]['text':' dot product into int32x4_t','line_number':2780,'multiline':False]['text':' Initialize accumulator with zeros','line_number':2809,'multiline':False]['text':' Main loop','line_number':2814,'multiline':False]['text':' Compute combined scales','line_number':2824,'multiline':False]['text':' Load 16 bytes, and unpack 4 bit fields into bytes, making 32 bytes','line_number':2827,'multiline':False]['text':' Accumulate d0*d1*x*y','line_number':2833,'multiline':False]['text':' load elements','line_number':2848,'multiline':False]['text':' mask and store lower part of x, and then upper part','line_number':2854,'multiline':False]['text':' scalar','line_number':2876,'multiline':False]['text':' TODO: handle odd nb','line_number':2916,'multiline':False]['text':' extract the 5th bit via lookup table ((!b) << 4)','line_number':2926,'multiline':False]['text':' 4-bit -> 8-bit','line_number':2948,'multiline':False]['text':' add high bit and sub 16 (equivalent to sub 0x10 when bit is zero)','line_number':2954,'multiline':False]['text':' load y','line_number':2960,'multiline':False]['text':' TODO: check if unrolling this is better','line_number':3001,'multiline':False]['text':' extract the 5th bit','line_number':3008,'multiline':False]['text':' 4-bit -> 8-bit','line_number':3021,'multiline':False]['text':' add high bit and sub 16 (equivalent to sub 0x10 when bit is zero)','line_number':3025,'multiline':False]['text':' load y','line_number':3029,'multiline':False]['text':' int8x16 -> int16x8','line_number':3033,'multiline':False]['text':' dot product','line_number':3044,'multiline':False]['text':' Initialize accumulator with zeros','line_number':3057,'multiline':False]['text':' Main loop','line_number':3060,'multiline':False]['text':' Compute combined scale for the block ','line_number':3062,'multiline':True]['text':' Multiply q with scale and accumulate ','line_number':3074,'multiline':True]['text':' Initialize accumulator with zeros','line_number':3080,'multiline':False]['text':' Main loop','line_number':3084,'multiline':False]['text':' Compute combined scale for the block ','line_number':3086,'multiline':True]['text':' Multiply q with scale and accumulate ','line_number':3105,'multiline':True]['text':' These temporary registers are for masking and shift operations','line_number':3117,'multiline':False]['text':' ((qh & (1u << (j + 0 ))) >> (j + 0 )) << 4;','line_number':3127,'multiline':False]['text':' ((qh & (1u << (j + 16))) >> (j + 12));','line_number':3132,'multiline':False]['text':' narrowing','line_number':3136,'multiline':False]['text':' load','line_number':3143,'multiline':False]['text':' scalar','line_number':3176,'multiline':False]['text':' TODO: handle odd nb','line_number':3225,'multiline':False]['text':' extract the 5th bit via lookup table ((b) << 4)','line_number':3238,'multiline':False]['text':' 4-bit -> 8-bit','line_number':3260,'multiline':False]['text':' add high bit','line_number':3266,'multiline':False]['text':' load y','line_number':3272,'multiline':False]['text':' TODO: check if unrolling this is better','line_number':3315,'multiline':False]['text':' extract the 5th bit','line_number':3324,'multiline':False]['text':' 4-bit -> 8-bit','line_number':3337,'multiline':False]['text':' add high bit','line_number':3341,'multiline':False]['text':' load y','line_number':3345,'multiline':False]['text':' int8x16 -> int16x8','line_number':3349,'multiline':False]['text':' dot product','line_number':3360,'multiline':False]['text':' Initialize accumulator with zeros','line_number':3373,'multiline':False]['text':' Main loop','line_number':3378,'multiline':False]['text':' Initialize accumulator with zeros','line_number':3399,'multiline':False]['text':' Main loop','line_number':3405,'multiline':False]['text':' temporary registers for shift operations','line_number':3439,'multiline':False]['text':' load qh','line_number':3446,'multiline':False]['text':' ((qh >> (j +  0)) << 4) & 0x10;','line_number':3449,'multiline':False]['text':' ((qh >> (j + 12))     ) & 0x10;','line_number':3454,'multiline':False]['text':' narrowing','line_number':3458,'multiline':False]['text':' load','line_number':3465,'multiline':False]['text':' scalar','line_number':3495,'multiline':False]['text':' TODO: handle odd nb','line_number':3534,'multiline':False]['text':' load y','line_number':3547,'multiline':False]['text':' Initialize accumulator with zeros','line_number':3585,'multiline':False]['text':' Main loop','line_number':3588,'multiline':False]['text':' Compute combined scale for the block','line_number':3590,'multiline':False]['text':' Multiply q with scale and accumulate','line_number':3597,'multiline':False]['text':' load elements','line_number':3611,'multiline':False]['text':' scalar','line_number':3627,'multiline':False]['text':' We use this macro instead of a function call because for some reason','line_number':3690,'multiline':False]['text':' the code runs 2-3% slower, even if the function is declared inline','line_number':3691,'multiline':False]['text':' load mins and scales from block_q2_K.scales[QK_K/16]','line_number':3819,'multiline':False]['text':' summs = y[i].bsums * (x[i].scales >> 4) in 16bits*8*2 to 32bits*4*2','line_number':3826,'multiline':False]['text':' sumf += -dmin * summs in 32bits*8','line_number':3830,'multiline':False]['text':' load Q8 quants int8*16*8 from block_q8_K.qs[QK_K]','line_number':3842,'multiline':False]['text':' load 2bits*16*8 from block_q2_K.qs[QK_K/4]','line_number':3852,'multiline':False]['text':' isuml = q8[l] * ((q2[l] >> shift) & 3) in 8bits*16*8 to 16bits*8*8','line_number':3864,'multiline':False]['text':' isum += (x[i].scales[is++] & 0xF) * isuml in 16bits*8*8 to 32bits*4*8','line_number':3874,'multiline':False]['text':' isum in 32bits*4*2','line_number':3897,'multiline':False]['text':' sumf += dall * isum - dmin * summs in 32bits','line_number':3902,'multiline':False]['text':' load Q2','line_number':3948,'multiline':False]['text':' duplicate scale elements for product','line_number':3956,'multiline':False]['text':' load Q8','line_number':3967,'multiline':False]['text':' TODO: optimize this','line_number':4122,'multiline':False]['text':' TODO: optimize this','line_number':4174,'multiline':False]['text':' load Q2','line_number':4246,'multiline':False]['text':' load Q8, and take product with Q2','line_number':4254,'multiline':False]['text':' Set up scales','line_number':4359,'multiline':False]['text':' Set up scales','line_number':4460,'multiline':False]['text':' high bit','line_number':4473,'multiline':False]['text':' integer accumulator','line_number':4476,'multiline':False]['text':' load low 2 bits','line_number':4483,'multiline':False]['text':' prepare low and high bits','line_number':4486,'multiline':False]['text':' load Q8 quants','line_number':4503,'multiline':False]['text':' Dot product: we multiply the 2 low bits and 1 high bit part separately, so we can use _mm256_maddubs_epi16,','line_number':4509,'multiline':False]['text':' and then subtract. The high bit part has the 2 already subtracted (and so, it is zero if the high bit was not set,','line_number':4510,'multiline':False]['text':' and 2 if the high bit was set)','line_number':4511,'multiline':False]['text':' multiply with scales','line_number':4527,'multiline':False]['text':' accumulate','line_number':4533,'multiline':False]['text':' multiply with block scale and accumulate','line_number':4540,'multiline':False]['text':' Set up scales','line_number':4565,'multiline':False]['text':' high bit *128*2 from block_q3_K.hmask[QK_K/8]','line_number':4577,'multiline':False]['text':' integer accumulator','line_number':4581,'multiline':False]['text':' load low 2 bits *64*2 from block_q3_K.qs[QK_K/4]','line_number':4586,'multiline':False]['text':' prepare low and high bits','line_number':4590,'multiline':False]['text':' load Q8 quants from block_q8_K.qs[QK_K]','line_number':4613,'multiline':False]['text':' Dot product: we multiply the 2 low bits and 1 high bit part separately, so we can use _mm256_maddubs_epi16,','line_number':4623,'multiline':False]['text':' and then subtract. The high bit part has the 2 already subtracted (and so, it is zero if the high bit was not set,','line_number':4624,'multiline':False]['text':' and 2 if the high bit was set)','line_number':4625,'multiline':False]['text':' multiply with scales','line_number':4653,'multiline':False]['text':' accumulate','line_number':4671,'multiline':False]['text':' multiply with block scale and accumulate','line_number':4681,'multiline':False]['text':' load Q3','line_number':4723,'multiline':False]['text':' compute mask for subtraction','line_number':4731,'multiline':False]['text':' load Q8 and take product with Q3','line_number':4752,'multiline':False]['text':' retrieve lane to multiply with scale','line_number':4760,'multiline':False]['text':' scalar version','line_number':4790,'multiline':False]['text':' This function is written like this so the compiler can manage to vectorize most of it','line_number':4791,'multiline':False]['text':' Using -Ofast, GCC and clang manage to produce code that is within a factor of 2 or so from the','line_number':4792,'multiline':False]['text':' manually vectorized version above. Every other version I tried would run at least 4 times slower.','line_number':4793,'multiline':False]['text':' The ideal situation would be if we could just write the code once, and the compiler would','line_number':4794,'multiline':False]['text':' automatically produce the best possible set of machine instructions, instead of us having to manually','line_number':4795,'multiline':False]['text':' write vectorized versions for AVX, ARM_NEON, etc.','line_number':4796,'multiline':False]['text':' load low 2 bits','line_number':4968,'multiline':False]['text':' prepare low and high bits','line_number':4971,'multiline':False]['text':' load Q8 quants','line_number':4976,'multiline':False]['text':' Dot product: we multiply the 2 low bits and 1 high bit part separately, so we can use _mm256_maddubs_epi16,','line_number':4980,'multiline':False]['text':' and then subtract. The high bit part has the 2 already subtracted (and so, it is zero if the high bit was not set,','line_number':4981,'multiline':False]['text':' and 2 if the high bit was set)','line_number':4982,'multiline':False]['text':' multiply with scales','line_number':4992,'multiline':False]['text':' multiply with block scale and accumulate','line_number':4998,'multiline':False]['text':' load low 2 bits','line_number':5044,'multiline':False]['text':' prepare low and high bits','line_number':5047,'multiline':False]['text':' load Q8 quants','line_number':5053,'multiline':False]['text':' Dot product: we multiply the 2 low bits and 1 high bit part separately, so we can use _mm_maddubs_epi16,','line_number':5057,'multiline':False]['text':' and then subtract. The high bit part has the 2 already subtracted (and so, it is zero if the high bit was not set,','line_number':5058,'multiline':False]['text':' and 2 if the high bit was set)','line_number':5059,'multiline':False]['text':' multiply with scales','line_number':5075,'multiline':False]['text':' multiply with block scale and accumulate','line_number':5085,'multiline':False]['text':' load qh','line_number':5116,'multiline':False]['text':' extend and combine both qh_x1 and qh_x2','line_number':5122,'multiline':False]['text':' load Q3','line_number':5130,'multiline':False]['text':' load Q8 and take product with Q3','line_number':5143,'multiline':False]['text':' load Q4','line_number':5508,'multiline':False]['text':' load Q8 and multiply it with lower Q4 nibble','line_number':5511,'multiline':False]['text':' load Q8 and multiply it with upper Q4 nibble','line_number':5519,'multiline':False]['text':' load Q4','line_number':5801,'multiline':False]['text':' load Q8 and multiply it with lower Q4 nibble','line_number':5804,'multiline':False]['text':' load Q8 and multiply it with upper Q4 nibble','line_number':5811,'multiline':False]['text':' TODO','line_number':5993,'multiline':False]['text':' load Q5 and Q8','line_number':6200,'multiline':False]['text':' compute mask for addition','line_number':6205,'multiline':False]['text':' load qh','line_number':6499,'multiline':False]['text':' combine both qh_1 and qh_2','line_number':6505,'multiline':False]['text':' load q5','line_number':6518,'multiline':False]['text':' load Q8 and multiply it with Q5','line_number':6532,'multiline':False]['text':'const int8x16_t  m32s = vdupq_n_s8(32);','line_number':6610,'multiline':False]['text':'q6bytes.val[0] = vsubq_s8(vreinterpretq_s8_u8(vorrq_u8(vandq_u8(q6bits.val[0], m4b), q6h.val[0])), m32s);','line_number':6652,'multiline':False]['text':'q6bytes.val[1] = vsubq_s8(vreinterpretq_s8_u8(vorrq_u8(vandq_u8(q6bits.val[1], m4b), q6h.val[1])), m32s);','line_number':6653,'multiline':False]['text':'q6bytes.val[2] = vsubq_s8(vreinterpretq_s8_u8(vorrq_u8(vandq_u8(q6bits.val[2], m4b), q6h.val[2])), m32s);','line_number':6654,'multiline':False]['text':'q6bytes.val[3] = vsubq_s8(vreinterpretq_s8_u8(vorrq_u8(vandq_u8(q6bits.val[3], m4b), q6h.val[3])), m32s);','line_number':6655,'multiline':False]['text':'q6bytes.val[0] = vsubq_s8(vreinterpretq_s8_u8(vorrq_u8(vshrq_n_u8(q6bits.val[0], 4), q6h.val[0])), m32s);','line_number':6697,'multiline':False]['text':'q6bytes.val[1] = vsubq_s8(vreinterpretq_s8_u8(vorrq_u8(vshrq_n_u8(q6bits.val[1], 4), q6h.val[1])), m32s);','line_number':6698,'multiline':False]['text':'q6bytes.val[2] = vsubq_s8(vreinterpretq_s8_u8(vorrq_u8(vshrq_n_u8(q6bits.val[2], 4), q6h.val[2])), m32s);','line_number':6699,'multiline':False]['text':'q6bytes.val[3] = vsubq_s8(vreinterpretq_s8_u8(vorrq_u8(vshrq_n_u8(q6bits.val[3], 4), q6h.val[3])), m32s);','line_number':6700,'multiline':False]['text':'for (int l = 0; l < 4; ++l) {','line_number':6714,'multiline':False]['text':'    const int32x4_t p = vdotq_s32(vzero, q6bytes.val[l], q8bytes.val[l]);','line_number':6715,'multiline':False]['text':'    isum += vaddvq_s32(p) * *scale++;','line_number':6716,'multiline':False]['text':'}','line_number':6717,'multiline':False]['text':'sum += isum * d_all * y[i].d;','line_number':6735,'multiline':False]['text':' load qh','line_number':6962,'multiline':False]['text':' load Q6','line_number':6965,'multiline':False]['text':' load Q8 and take product','line_number':6989,'multiline':False]['text':' load Q6','line_number':7296,'multiline':False]['text':' load qh','line_number':7300,'multiline':False]['text':' load Q8 and take product','line_number':7321,'multiline':False]