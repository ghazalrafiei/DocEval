['text':' We could add more debugging bits here.','line_number':41,'multiline':False]['text':' Right now, this backend can be used to check for and error on','line_number':42,'multiline':False]['text':' custom dispatcher ops that have incorrect schemas.','line_number':43,'multiline':False]['text':' used boxed call to discard inputs when they are no longer needed','line_number':56,'multiline':False]['text':' Useful for debugging purpose','line_number':65,'multiline':False]['text':' aot_eager uses AOT Autograd backend with nop compiler. It is helpful in debugging.','line_number':66,'multiline':False]['text':' Uses TorchInductor AOT Autograd decomps and partitioner to isolate aot vs','line_number':77,'multiline':False]['text':' inductor problems.','line_number':78,'multiline':False]['text':' aot_eager_decomp_partition just replaces the inductor compiler with nop to help','line_number':79,'multiline':False]['text':' isolate inductor vs aot_eager errors','line_number':80,'multiline':False]['text':' these are taken from memory_efficient_fusion()','line_number':82,'multiline':False]['text':' NB: lambda here is to delay import of inductor','line_number':85,'multiline':False]['text':' AOT Autograd with torchscript backend. Default partitioner.','line_number':97,'multiline':False]['text':' aot_ts uses torchscript backend. We can use this with both nnc and nvfuser','line_number':98,'multiline':False]['text':' by using the relevant fuser with torch.jit.fuser(...)','line_number':99,'multiline':False]['text':' These buggy backends are used for inducing bugs so that we can test','line_number':103,'multiline':False]['text':' our repro extraction / minifier scripts','line_number':104,'multiline':False]['text':' Require at least one non-trivial thing in the graph,','line_number':146,'multiline':False]['text':' see https://github.com/pytorch/pytorch/issues/102898','line_number':147,'multiline':False]['text':' Type is GraphCompileReason but doesn't matter for this purpose','line_number':171,'multiline':False]