['text':' Back compat .guards api','line_number':139,'multiline':False]['text':' Indicates if this was a graph compile reason due to graph break.','line_number':157,'multiline':False]['text':' if verify_correctness=True','line_number':200,'multiline':False]['text':' TODO: replace `same` function with the one in testing','line_number':205,'multiline':False]['text':' Map from graph input's `Source` to its `VariableTracker` to','line_number':247,'multiline':False]['text':' de-duplicate graph inputs by source and reuse the tracker','line_number':248,'multiline':False]['text':' TODO: maybe should just pass the entire f_code in here?  Not','line_number':256,'multiline':False]['text':' sure...','line_number':257,'multiline':False]['text':' tracked_fakes says where any tensor that was wrapped to fake came','line_number':264,'multiline':False]['text':' from.  It is similar to GraphArg, in that all GraphArgs will get','line_number':265,'multiline':False]['text':' will get added to TrackedFakes, but TrackedFakes also contains','line_number':266,'multiline':False]['text':' GraphArgs that got pruned, and things like Tensor attributes which','line_number':267,'multiline':False]['text':' aren't explicit graph inputs.  Used by shape guard','line_number':268,'multiline':False]['text':' List of symbols for which we have exact bindings in the arguments','line_number':271,'multiline':False]['text':' already','line_number':272,'multiline':False]['text':' Reference Cycle!','line_number':276,'multiline':False]['text':' Share a reference to the list of TrackedFake.','line_number':277,'multiline':False]['text':'','line_number':278,'multiline':False]['text':' ShapeEnv needs this in order to be able to reproduce the call','line_number':279,'multiline':False]['text':' to produce_guards at an arbitrary time point. That is because','line_number':280,'multiline':False]['text':' TrackedFake instances may have its metadata changed throughout','line_number':281,'multiline':False]['text':' the program execution.','line_number':282,'multiline':False]['text':' In export mode, we force the shape_env to strictly disallow any constraining','line_number':289,'multiline':False]['text':' of the user marked dynamic dims','line_number':290,'multiline':False]['text':' TODO (tmanlaibaatar) Remove this once we always lift params and buffers','line_number':293,'multiline':False]['text':' Map each tensor id to a list of sources. This is necessary because','line_number':299,'multiline':False]['text':' tensor ids cannot be recovered from tracked fakes (in general).','line_number':300,'multiline':False]['text':' We use this map to interpret (i.e., check for violations of) constraints,','line_number':301,'multiline':False]['text':' specifically equality constraints, which have shared tensor ids in them.','line_number':302,'multiline':False]['text':' This map should also be generally useful, e.g., for (de)serialization.','line_number':303,'multiline':False]['text':' Stores the full fqn of a param or buffer to the relevant source.','line_number':307,'multiline':False]['text':' used to track nodes that are added between calls of copy_graphstate','line_number':312,'multiline':False]['text':' and restore_graphstate','line_number':313,'multiline':False]['text':' A list of register_finalizer_fns to apply to the output graph module','line_number':316,'multiline':False]['text':' Not checkpointed','line_number':319,'multiline':False]['text':' Given a source, what are the user stacks of all locations that','line_number':326,'multiline':False]['text':' accessed it?','line_number':327,'multiline':False]['text':'','line_number':328,'multiline':False]['text':' For efficiency, we only populate this:','line_number':329,'multiline':False]['text':'   - During export, and','line_number':330,'multiline':False]['text':'   - If the source could potentially lead to a spurious export input','line_number':331,'multiline':False]['text':'','line_number':332,'multiline':False]['text':' Feel free to populate this more frequently if other use-cases arise,','line_number':333,'multiline':False]['text':' but be aware that we have to generate full stacks for each','line_number':334,'multiline':False]['text':' recording!','line_number':335,'multiline':False]['text':' Tracks if the output graph has a user defined allowed function in the','line_number':344,'multiline':False]['text':' graph. This is used later to determine if we should fallback to eager','line_number':345,'multiline':False]['text':' for certain exceptions. THe idea is that if the user has applied','line_number':346,'multiline':False]['text':' allow_in_graph, they would like to see the error instead of falling','line_number':347,'multiline':False]['text':' back for backend errors.','line_number':348,'multiline':False]['text':' Tracks a list of called ops that were not tagged with "pt2_compliant_tag".','line_number':351,'multiline':False]['text':' This information is useful for logging.','line_number':352,'multiline':False]['text':' Tracks a list of called custom ops that were tagged with "pt2_compliant_tag".','line_number':355,'multiline':False]['text':' This information is useful for logging.','line_number':356,'multiline':False]['text':' We save the global torch state here to be restored in case of graph','line_number':359,'multiline':False]['text':' breaks. The relevant issue is seen here','line_number':360,'multiline':False]['text':' https://github.com/pytorch/pytorch/pull/100570#issuecomment-1543427086','line_number':361,'multiline':False]['text':' where inlining of a function changes the global state (because of the','line_number':362,'multiline':False]['text':' presence of torch.no_grad) and there is a graph break.','line_number':363,'multiline':False]['text':' This gets its own helper function so guards DEBUG logs are more','line_number':366,'multiline':False]['text':' informative','line_number':367,'multiline':False]['text':' Register a SHAPE_ENV guard to make sure we setup shape guards','line_number':369,'multiline':False]['text':' that show up in ShapeEnv','line_number':370,'multiline':False]['text':' Helper to tell if we are inside the higher order operator tracing.','line_number':404,'multiline':False]['text':' TODO(rzou): can delete after we refactor speculate_subgraph to use nested GraphTracer.','line_number':411,'multiline':False]['text':' If you are here, and you're looking for create_graph_input,','line_number':424,'multiline':False]['text':' to avoid ambiguity, please call one of the following:','line_number':425,'multiline':False]['text':' - self.current_tracer.create_graph_input','line_number':426,'multiline':False]['text':' - self.root_tracer.create_graph_input','line_number':427,'multiline':False]['text':' See NOTE [HigherOrderOperator tracing design] for more context.','line_number':428,'multiline':False]['text':' Lineage MUST stay preserved','line_number':444,'multiline':False]['text':' FX deepcopy doesn't work for a partially created graph, so just remove new nodes','line_number':565,'multiline':False]['text':' placeholders here may have been lazily added by existing objects','line_number':570,'multiline':False]['text':' Erasing node alone does not remove the meta information','line_number':573,'multiline':False]['text':' So, remove the help tensor explicitly','line_number':574,'multiline':False]['text':' Insert implicit size vars as necessary.  With dynamic shapes, we','line_number':583,'multiline':False]['text':' maintain the invariant that every sizevar gets a direct SymInt input','line_number':584,'multiline':False]['text':' into the graph.  This means downstream graph transforms can assume','line_number':585,'multiline':False]['text':' every size variable is explicitly bound and accessible, instead of','line_number':586,'multiline':False]['text':' having to pull it out implicitly from tensors.','line_number':587,'multiline':False]['text':' TODO: don't readd symint if we already have it in graph','line_number':602,'multiline':False]['text':' (this is harmless because we do remove the unused ones later)','line_number':603,'multiline':False]['text':' create a new unique name','line_number':667,'multiline':False]['text':' Strip the guard lookup L/G access','line_number':669,'multiline':False]['text':' e.g. replace abc.xyz[123].qkv with abc.xyz_123.qkv','line_number':671,'multiline':False]['text':' e.g. replace abc.xyz_123.qkv with abc_xyz_123_qkv','line_number':673,'multiline':False]['text':' For higher order ops, we don't want to insert the get_attr in','line_number':698,'multiline':False]['text':' innermost graph. Instead, we want to raise the params/buffers','line_number':699,'multiline':False]['text':' as inputs to the higher-order graph, and register them as','line_number':700,'multiline':False]['text':' get_attrs in the root tracer.','line_number':701,'multiline':False]['text':' Note that Dynamo will still call lift_tracked_freevar_to_input','line_number':703,'multiline':False]['text':' when these inputs are encountered for the inner graph. The','line_number':704,'multiline':False]['text':' only difference is what happens at the root tracer for','line_number':705,'multiline':False]['text':' nn.Parameters vs free inputs. The free inputs are registered','line_number':706,'multiline':False]['text':' as placeholders in the root graph, whereas the nn.Parameters','line_number':707,'multiline':False]['text':' are registered as get_attr nodes in the root graph.','line_number':708,'multiline':False]['text':' HACKY CODE REGION BEGIN','line_number':737,'multiline':False]['text':' WE ARE PIGGYBACKING ON EXISTING INFRA TO REGISTER ATTRS','line_number':738,'multiline':False]['text':' This ultimately gets written to self.nn_modules, which is unfortunate','line_number':739,'multiline':False]['text':' Attrs that are tenors and symints and such need to be migrated to have their','line_number':740,'multiline':False]['text':' own storage','line_number':741,'multiline':False]['text':' alas, this is like this for now','line_number':742,'multiline':False]['text':' HACKY CODE REGION END','line_number':752,'multiline':False]['text':' it already exists','line_number':764,'multiline':False]['text':' annoying, but there are cases when we do not have parameters','line_number':781,'multiline':False]['text':' see test_nn_moduledict_contains','line_number':782,'multiline':False]['text':' prefix instructions (Python 3.11+)','line_number':817,'multiline':False]['text':' Add all the local vars to the "stack" so restore at the end','line_number':843,'multiline':False]['text':' NB: Typically (i.e., for graph compile from RETURN_VALUE),','line_number':848,'multiline':False]['text':' symbolic_locals will be empty at this point, as prune_dead_locals','line_number':849,'multiline':False]['text':' will clear out all of symbolic_locals because RETURN_VALUE is the','line_number':850,'multiline':False]['text':' last instruction and no more locals are used.  The fanciness here','line_number':851,'multiline':False]['text':' is only needed for partial graphs.','line_number':852,'multiline':False]['text':' Note! this explicitly uses .local_name for matching','line_number':854,'multiline':False]['text':' Failure to do so will cause spurious registrations in val_to_names.','line_number':855,'multiline':False]['text':' This will in turn result in spurious variables showing up in the graph.','line_number':856,'multiline':False]['text':' This was very tricky to debug. For an example, dump the graph at call_user_compiler','line_number':857,'multiline':False]['text':' while running test_subgraphs.py','line_number':858,'multiline':False]['text':' no need to restore initial state','line_number':860,'multiline':False]['text':' to handle random calls','line_number':868,'multiline':False]['text':' optimization to generate better code in a common case','line_number':904,'multiline':False]['text':' one more time now that we have established tempvars','line_number':917,'multiline':False]['text':' restore all the live local vars','line_number':942,'multiline':False]['text':' Set to state prior to tracing the graph','line_number':1011,'multiline':False]['text':' Reset to state at the current time (e.g. before calling the user compiler)','line_number':1015,'multiline':False]['text':' NB: deferred runtime asserts can keep graphargs live, so make sure','line_number':1041,'multiline':False]['text':' those are inserted before pruning','line_number':1042,'multiline':False]['text':' free a bit of memory','line_number':1047,'multiline':False]['text':' TODO(voz): The way export uses gm, and fake tensors, is not supported with us resetting','line_number':1064,'multiline':False]['text':' TODO(voz): Ostensibily, this should be scoped and','line_number':1068,'multiline':False]['text':' restore back to old_fake_mode, but doing so currently violates','line_number':1069,'multiline':False]['text':' a lot of fake_tensor ownership assumptions and runs afoul of detect_fake_mode','line_number':1070,'multiline':False]['text':' TODO: Why isn't this stored in meta :think:','line_number':1111,'multiline':False]['text':' The backend compiler has requested that we skip the frame, instead of','line_number':1142,'multiline':False]['text':' aborting execution.','line_number':1143,'multiline':False]['text':' Miniature DCE pass, but only for obviously trivial operations','line_number':1171,'multiline':False]['text':' I'm not really sure why you need to delete these from the','line_number':1190,'multiline':False]['text':' node since the node is going to get removed','line_number':1191,'multiline':False]['text':' Don't delete symbol bindings yet','line_number':1200,'multiline':False]['text':' Register the free symbols as uses','line_number':1208,'multiline':False]['text':' After removing unused graphargs, prune unused binds_symbol','line_number':1215,'multiline':False]['text':' Make sure we delete later occurrences of the same symbol','line_number':1222,'multiline':False]['text':' TODO: this is a generic pass that should live outside of Dynamo','line_number':1225,'multiline':False]['text':' TODO: Request simplification on runtime asserts before emitting them','line_number':1235,'multiline':False]['text':' We are going to mutate the dict','line_number':1247,'multiline':False]['text':' Identify what symbols we need to reify.  This isn't strictly needed','line_number':1258,'multiline':False]['text':' but helps reduce churn on the graph','line_number':1259,'multiline':False]['text':' Placeholders can match symbols, but when we destructure them','line_number':1268,'multiline':False]['text':' with size we have to make sure we insert the nodes after all','line_number':1269,'multiline':False]['text':' the placeholders','line_number':1270,'multiline':False]['text':' For every new unbacked symbol, we need an fx.Node representing','line_number':1279,'multiline':False]['text':' precisely this value.  There are a few places where the unbacked','line_number':1280,'multiline':False]['text':' symbol could have come from, and we will check them to setup','line_number':1281,'multiline':False]['text':' these nodes.','line_number':1282,'multiline':False]['text':'','line_number':1283,'multiline':False]['text':' For a case like item(), this is trivial (no new node is added.)','line_number':1284,'multiline':False]['text':'','line_number':1285,'multiline':False]['text':' For nonzero(), we need to add something like i0 = out.size(0)','line_number':1286,'multiline':False]['text':'','line_number':1287,'multiline':False]['text':' We could end up with duplicate nodes this way but it is not a','line_number':1288,'multiline':False]['text':' big deal.','line_number':1289,'multiline':False]['text':'','line_number':1290,'multiline':False]['text':' We also do this to setup backed SymInts, but those are all going','line_number':1291,'multiline':False]['text':' to be matched from placeholders','line_number':1292,'multiline':False]['text':' Need to process ALL free symbols, not just unbacked ones','line_number':1324,'multiline':False]['text':' Convert the sympy expression into a sequence of FX','line_number':1332,'multiline':False]['text':' nodes','line_number':1333,'multiline':False]['text':' TODO: use ra.msg here, but it's pretty','line_number':1342,'multiline':False]['text':' useless right now','line_number':1343,'multiline':False]['text':' There is a reference cycle between tracer and OutputGraph, causing','line_number':1362,'multiline':False]['text':' some of the tensor objects to be held alive for longer than necessary.','line_number':1363,'multiline':False]['text':' Optimization: Overload resolution is expensive.','line_number':1422,'multiline':False]['text':' If there's only one overload, we know what it will resolve to.','line_number':1423,'multiline':False]['text':' The export is only ever set for the ROOT tracer.  It controls','line_number':1473,'multiline':False]['text':' whether or not certain inputs are allowed to be added or not.','line_number':1474,'multiline':False]['text':' Look at call sites of create_graph_input to see how it is used.','line_number':1475,'multiline':False]['text':' Map from graph input name to its placeholder proxy object, where the','line_number':1479,'multiline':False]['text':' map's keys give all current placeholder node names and can be used to','line_number':1480,'multiline':False]['text':' create unique node names','line_number':1481,'multiline':False]['text':' Node => computed real value (see utils.get_real_value)','line_number':1483,'multiline':False]['text':' SubgraphTracers can be nested. See NOTE [HigherOrderOperator tracing design]','line_number':1486,'multiline':False]['text':' A dict mapping previously free variables (Proxy objects)','line_number':1488,'multiline':False]['text':' to new Proxy objects that wrap inputs to this subgraph.','line_number':1489,'multiline':False]['text':'','line_number':1490,'multiline':False]['text':' This dict serves two purposes:','line_number':1491,'multiline':False]['text':' - Proxies are associated with VariableTrackers. If we see','line_number':1492,'multiline':False]['text':' the same VariableTracker twice (and it is a free variable),','line_number':1493,'multiline':False]['text':' then we want to use the same Proxy in the current subgraph to','line_number':1494,'multiline':False]['text':' record the tracing.','line_number':1495,'multiline':False]['text':' - If we are tracing a HigherOrderOperator's body_fn, then we','line_number':1496,'multiline':False]['text':' need to keep track of what free variables were lifted so we can','line_number':1497,'multiline':False]['text':' rewrite the HigherOrderOperator call using the traced body_fn.','line_number':1498,'multiline':False]['text':' Dicts maintain the order of args for the HigherOrderOperator call.','line_number':1499,'multiline':False]['text':' Each SubgraphTracer is associated with a source target, which indicates','line_number':1507,'multiline':False]['text':' which operator this subgraph is attached to. We compute a source_fn_stack','line_number':1508,'multiline':False]['text':' based on the source target. For the root tracer, it's set to [].','line_number':1509,'multiline':False]['text':' This is useful for debugging and transforming the exported graph.','line_number':1510,'multiline':False]['text':' NOTE: [Nested SubgraphTracer and free_variable handling]','line_number':1528,'multiline':False]['text':' --------------------------------------------------------','line_number':1529,'multiline':False]['text':' Read NOTE [HigherOrderOperator tracing design] first.','line_number':1530,'multiline':False]['text':'','line_number':1531,'multiline':False]['text':' Let's say we're in the middle of introspecting the body of a possibly','line_number':1532,'multiline':False]['text':' nested HigherOrderOperator, and we see a free variable.','line_number':1533,'multiline':False]['text':'','line_number':1534,'multiline':False]['text':' There are two cases:','line_number':1535,'multiline':False]['text':' 1. We see a free variable that is already tracked by Dynamo.','line_number':1536,'multiline':False]['text':' 2. We see a free variable that has not been tracked by Dynamo','line_number':1537,'multiline':False]['text':'','line_number':1538,'multiline':False]['text':' In case 1, we call `maybe_lift_tracked_freevar_to_input` (below)','line_number':1539,'multiline':False]['text':' which will lift the freevar to be an input of this subgraph','line_number':1540,'multiline':False]['text':' and also recursively lift it to be an input on the parent(s).','line_number':1541,'multiline':False]['text':'','line_number':1542,'multiline':False]['text':' In case 2, before the call to `create_proxy`, the InstructionTranslator','line_number':1543,'multiline':False]['text':' will see the freevar when it gets loaded by Python bytecode.','line_number':1544,'multiline':False]['text':' E.g. for Python 3.11 the bytecodes that may do this are LOAD_DEREF or','line_number':1545,'multiline':False]['text':' LOAD_GLOBAL.','line_number':1546,'multiline':False]['text':' There, the InstructionTranslator asks Dynamo to begin tracking the','line_number':1547,'multiline':False]['text':' freevar by building a new Variable.','line_number':1548,'multiline':False]['text':' Building a new Variable automatically lifts the freevar to be an','line_number':1549,'multiline':False]['text':' input of the root SubgraphTracer.','line_number':1550,'multiline':False]['text':'','line_number':1551,'multiline':False]['text':' The implications for the code below are:','line_number':1552,'multiline':False]['text':' - We will always be in Case 1 when we get to this code.','line_number':1553,'multiline':False]['text':' - Any "free variable" we encounter here is guaranteed to already be','line_number':1554,'multiline':False]['text':'   bound, that is, it is either a graph input of the root graph, or','line_number':1555,'multiline':False]['text':'   some local variable of the root graph or a subgraph.','line_number':1556,'multiline':False]['text':' - The additional work we need to do here is *only* that we need to','line_number':1557,'multiline':False]['text':'   lift this free variable into inputs (recursively) of each nested','line_number':1558,'multiline':False]['text':'   higher-order-op subgraph until we hit the subgraph where the free','line_number':1559,'multiline':False]['text':'   variable is bound','line_number':1560,'multiline':False]['text':' append stack trace to fx node','line_number':1574,'multiline':False]['text':' log detailed location of line of code in 3.11','line_number':1577,'multiline':False]['text':' update reference to original meta if we're tracing a new code object','line_number':1599,'multiline':False]['text':' For modules we store the class','line_number':1629,'multiline':False]['text':' preserve original meta if it is available','line_number':1637,'multiline':False]['text':' For modules we store the class','line_number':1673,'multiline':False]['text':' Reverse the frame_summaries, such that the innermost frame is at the last','line_number':1686,'multiline':False]['text':' official from_list stub doesn't have new-style type','line_number':1689,'multiline':False]['text':' Note: we did not override erase_node since','line_number':1712,'multiline':False]['text':' we call self.graph.erase_node elsewhere','line_number':1713,'multiline':False]['text':' For the case where user.graph == self.graph, that is a real bug and will raise','line_number':1718,'multiline':False]['text':' properly.','line_number':1719,'multiline':False]['text':' This is a nested graph, which needs to be deleted.','line_number':1721,'multiline':False]['text':' If we do not do this, we will raise on attempting to remove this.','line_number':1722,'multiline':False]['text':' As we only get here during restoration cleanup, this is sound.','line_number':1723,'multiline':False]['text':' when before=True, we will insert this input before the most recent','line_number':1730,'multiline':False]['text':' inserted proxy.  This is a hack to get around an ordering problem,','line_number':1731,'multiline':False]['text':' where we first insert a tensor argument, and then insert bindings','line_number':1732,'multiline':False]['text':' for SymInts that may occur in the tensor argument.','line_number':1733,'multiline':False]['text':' Remove this if https://github.com/pytorch/pytorch/issues/99007 gets','line_number':1734,'multiline':False]['text':' fixed.','line_number':1735,'multiline':False]['text':' In eager, we are generally OK with adding graph inputs whenever we','line_number':1747,'multiline':False]['text':' want, because we take care of writing the bytecode that knows how','line_number':1748,'multiline':False]['text':' to source all the inputs.','line_number':1749,'multiline':False]['text':'','line_number':1750,'multiline':False]['text':' In export, this is bad, because you want a self-contained export','line_number':1751,'multiline':False]['text':' object which only depends on the inputs you explicitly passed to it.','line_number':1752,'multiline':False]['text':' So we are a bit more strict about what sources can become inputs','line_number':1753,'multiline':False]['text':' in export','line_number':1754,'multiline':False]['text':' unique','line_number':1761,'multiline':False]['text':' See NOTE: [Nested SubgraphTracer and free_variable handling] for more details','line_number':1788,'multiline':False]['text':' You're doing something wrong if we are the root SubgraphTracer because','line_number':1790,'multiline':False]['text':' Dynamo adds tensors to graph inputs before creating a proxy for them.','line_number':1791,'multiline':False]['text':' Proxys are associated with VariableTracker.','line_number':1795,'multiline':False]['text':' It is possible that we've already lifted the Proxy to be an input.','line_number':1796,'multiline':False]['text':' If that is the case, just return the already lifted Proxy.','line_number':1797,'multiline':False]['text':' NOTE: [HigherOrderOperator tracing design]','line_number':1820,'multiline':False]['text':' Ignoring HigherOrderOperators for a moment,','line_number':1821,'multiline':False]['text':' OutputGraph represents the graph being built by Dynamo that may be compiled','line_number':1822,'multiline':False]['text':' and executed. It holds a root SubgraphTracer where the FX graph is built.','line_number':1823,'multiline':False]['text':'','line_number':1824,'multiline':False]['text':' HigherOrderOperators are operators that take functions as their arguments.','line_number':1825,'multiline':False]['text':' When Dynamo encounters a HigherOrderOperator, then it attempts to introspect','line_number':1826,'multiline':False]['text':' the function passed to it (call this the "body function"), capture it into a','line_number':1827,'multiline':False]['text':' GraphModule, and rewrite the call to the HigherOrderOperator to use the','line_number':1828,'multiline':False]['text':' GraphModule.','line_number':1829,'multiline':False]['text':'','line_number':1830,'multiline':False]['text':' The way we handle the capture of body functions is through having','line_number':1831,'multiline':False]['text':' (possibly nested) SubgraphTracers, one per body function.','line_number':1832,'multiline':False]['text':'','line_number':1833,'multiline':False]['text':' Mechanically, we do the introspection by:','line_number':1834,'multiline':False]['text':' - Creating a new SubgraphTracer via OutputGraph.subtracer','line_number':1835,'multiline':False]['text':' - Executing the body function.','line_number':1836,'multiline':False]['text':' This constructs the graph of the body function in the new SubgraphTracer','line_number':1837,'multiline':False]['text':' while modifying the state of the OutputGraph. For example:','line_number':1838,'multiline':False]['text':' - the OutputGraph can receive new GraphArgs (if we discover any new','line_number':1839,'multiline':False]['text':'   untracked Tensors)','line_number':1840,'multiline':False]['text':' - side effects from the body function get accumulated into','line_number':1841,'multiline':False]['text':'   OutputGraph.side_effects','line_number':1842,'multiline':False]['text':' - guards produced by the body function get accumulated into OutputGraph.guards','line_number':1843,'multiline':False]['text':'','line_number':1844,'multiline':False]['text':' The traced function has some special properties that make it easier for us','line_number':1845,'multiline':False]['text':' to transform later down the line:','line_number':1846,'multiline':False]['text':' - we lift all free variables to being inputs.','line_number':1847,'multiline':False]['text':'','line_number':1848,'multiline':False]['text':' If the introspection fails (due to the existence of graph breaks), then','line_number':1849,'multiline':False]['text':' we roll back the current OutputGraph state and graph break on the','line_number':1850,'multiline':False]['text':' HigherOrderOperator.','line_number':1851,'multiline':False]