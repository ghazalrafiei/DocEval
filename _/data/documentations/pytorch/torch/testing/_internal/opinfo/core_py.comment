['text':' Reasonable testing sizes for dimensions','line_number':36,'multiline':False]['text':' Unique value to distinguish default from anything else','line_number':42,'multiline':False]['text':' Extension of getattr to support qualified names','line_number':46,'multiline':False]['text':' e.g. _getattr_qual(torch, 'linalg.norm') -> torch.linalg.norm','line_number':47,'multiline':False]['text':' Validate dtypes','line_number':96,'multiline':False]['text':' Support callables over kwargs to determine if the decorator is active.','line_number':108,'multiline':False]['text':' FIXME','line_number':117,'multiline':False]['text':' Note: historically the 'input' kwarg had to be a Tensor or TensorList, but we are trying','line_number':118,'multiline':False]['text':'   to support scalar inputs, too. Some tests still depend on 'input' being a Tensor','line_number':119,'multiline':False]['text':'   or TensorList, however.','line_number':120,'multiline':False]['text':' input is the first input to the op and is typically either a Tensor or TensorList (Sequence[Tensor]).','line_number':144,'multiline':False]['text':' This follows the typical pattern where for Tensor inputs op(t, ...) = t.op(...).','line_number':145,'multiline':False]['text':' Allow calling either as SampleInput(input, args=args, kwargs=kwargs), or as','line_number':148,'multiline':False]['text':' SampleInput(input, *args, **kwargs) but not to mix the two forms','line_number':149,'multiline':False]['text':' Specifies if `self.input` is broadcasted or not,','line_number':178,'multiline':False]['text':' given that the operator supports broadcasting.','line_number':179,'multiline':False]['text':' This field is used to verify the behavior for inplace variant.','line_number':180,'multiline':False]['text':'','line_number':181,'multiline':False]['text':' If a SampleInput is marked with `broadcasts_input=True`,','line_number':182,'multiline':False]['text':' it is verified that we get a `RuntimeError` with this sample,','line_number':183,'multiline':False]['text':' and inplace variant. Also inplace grad{grad} tests are skipped,','line_number':184,'multiline':False]['text':' for such inputs (as they will error out otherwise).','line_number':185,'multiline':False]['text':' Helper function to return the details of the SampleInput as `str`','line_number':202,'multiline':False]['text':' It consolidates all the fields of SampleInput and allows,','line_number':203,'multiline':False]['text':' formatting the fields like `input`, `args`, etc with `formatter`','line_number':204,'multiline':False]['text':' callable to customize the representation.','line_number':205,'multiline':False]['text':' Look at `summary` method for example.','line_number':206,'multiline':False]['text':' Returns the SampleInput details in a more','line_number':221,'multiline':False]['text':' friendly format.','line_number':222,'multiline':False]['text':' It formats `Tensor` and `TensorList`','line_number':223,'multiline':False]['text':' in a more condensed representation.','line_number':224,'multiline':False]['text':' Format any instance of `Tensor` (standalone, in list, or in dict)','line_number':226,'multiline':False]['text':' by Tensor[TensorShape]','line_number':227,'multiline':False]['text':' Eg. Tensor with shape (3, 4) is formatted as Tensor[3, 4]','line_number':228,'multiline':False]['text':' NB: sparse CSR tensors annoyingly return is_sparse=False','line_number':234,'multiline':False]['text':' Handle list, tuple','line_number':243,'multiline':False]['text':' Applies the transform f(t) -> t to each tensor and dtype in the SampleInput','line_number':250,'multiline':False]['text':' Note the transformed SampleInput assumes metadata like output_process_fn_grad is still valid!','line_number':276,'multiline':False]['text':' Returns the NumPy version of the sample input object in the form of a tuple: (input, args, kwargs)','line_number':286,'multiline':False]['text':' Converts tensors to ndarrays by calling .detach().cpu().numpy() on them','line_number':287,'multiline':False]['text':' Converts dtypes by remapping them using torch_to_numpy_dtype_dict','line_number':288,'multiline':False]['text':' Note [OpInfos]','line_number':348,'multiline':False]['text':' ~~~~~~~~~~~~~~','line_number':349,'multiline':False]['text':'','line_number':350,'multiline':False]['text':' The majority of this note was written shortly after the PyTorch 1.9 release.','line_number':351,'multiline':False]['text':' If you notice it's out-of-date or think it could be improved then please','line_number':352,'multiline':False]['text':' file an issue.','line_number':353,'multiline':False]['text':'','line_number':354,'multiline':False]['text':' See also: the OpInfo tracker (https://github.com/pytorch/pytorch/issues/54261)','line_number':355,'multiline':False]['text':' See also: "Writing Test Templates" in common_device_type.py to learn how to','line_number':356,'multiline':False]['text':'   parametrize a test template using OpInfos.','line_number':357,'multiline':False]['text':' See also: PyTorch's GitHub wiki on running and writing tests','line_number':358,'multiline':False]['text':'   https://github.com/pytorch/pytorch/wiki/Running-and-writing-tests','line_number':359,'multiline':False]['text':' See also: ModuleInfos, OpInfo's sister class, defined in common_modules.py','line_number':360,'multiline':False]['text':'','line_number':361,'multiline':False]['text':' An OpInfo is a collection of metadata related to a PyTorch operator. This','line_number':362,'multiline':False]['text':'   metadata is used to generate tests that validate properties of the operator,','line_number':363,'multiline':False]['text':'   like if it implements the correct gradient formula.','line_number':364,'multiline':False]['text':'','line_number':365,'multiline':False]['text':' WHY OPINFOS?','line_number':366,'multiline':False]['text':' ~~~~~~~~~~~~','line_number':367,'multiline':False]['text':'','line_number':368,'multiline':False]['text':' OpInfos are principally intended to do three things:','line_number':369,'multiline':False]['text':'','line_number':370,'multiline':False]['text':'   1) to allow systematic testing over all PyTorch's operators','line_number':371,'multiline':False]['text':'   2) to simplify operating testing by autogenerating many tests','line_number':372,'multiline':False]['text':'   3) to allow systems (like autograd, torchscript, fx, nnc...) to test','line_number':373,'multiline':False]['text':'        against every PyTorch operator','line_number':374,'multiline':False]['text':'','line_number':375,'multiline':False]['text':' All these goals are still a work in progress. Not every operator has an','line_number':376,'multiline':False]['text':'   OpInfo, and some operator tests that could be automatically generated','line_number':377,'multiline':False]['text':'   still have to be written manually.','line_number':378,'multiline':False]['text':'','line_number':379,'multiline':False]['text':' It's helpful to understand that OpInfos are both about test simplification and','line_number':380,'multiline':False]['text':'   modularity. PyTorch is a complicated framework with many interrelated systems,','line_number':381,'multiline':False]['text':'   too many for any one person to keep track of. An OpInfo can be thought of as the','line_number':382,'multiline':False]['text':'   interface between an operator implementer and those other systems. Instead of','line_number':383,'multiline':False]['text':'   requiring the implementer of torch.foo understand how to test its forward','line_number':384,'multiline':False]['text':'   mode AD or NNC support that's typically handled automatically just by','line_number':385,'multiline':False]['text':'   defining an OpInfo.','line_number':386,'multiline':False]['text':'','line_number':387,'multiline':False]['text':' It's often surprising to OpInfo writers that just implementing an OpInfo','line_number':388,'multiline':False]['text':'   typically can't verify an operator is actually implemented correctly:','line_number':389,'multiline':False]['text':'','line_number':390,'multiline':False]['text':' "If an OpInfo doesn't validate my op works as expected, what's the point','line_number':391,'multiline':False]['text':'     of it?"','line_number':392,'multiline':False]['text':'','line_number':393,'multiline':False]['text':' But the point of is the above. OpInfos are intended to let you focus on testing','line_number':394,'multiline':False]['text':'   the operator logic you're familiar with instead of having to write tests for','line_number':395,'multiline':False]['text':'   how the operator interacts with each of PyTorch's many systems.','line_number':396,'multiline':False]['text':'','line_number':397,'multiline':False]['text':' And, OK, it turns out that SOMETIMES just writing an OpInfo DOES','line_number':398,'multiline':False]['text':'   validate your op works as expected, but that's only in special','line_number':399,'multiline':False]['text':'   cases. See below for details.','line_number':400,'multiline':False]['text':'','line_number':401,'multiline':False]['text':' WHAT'S AN OPINFO?','line_number':402,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~','line_number':403,'multiline':False]['text':'','line_number':404,'multiline':False]['text':' So what is an OpInfo? It's a Python class that describes an operator's properties,','line_number':405,'multiline':False]['text':'   like which dtypes it supports on the CPU and whether it has any aliases.','line_number':406,'multiline':False]['text':'   These properties can be divided into three categories:','line_number':407,'multiline':False]['text':'','line_number':408,'multiline':False]['text':'   1) Metadata describing the operator, like the operator's name and if it','line_number':409,'multiline':False]['text':'     "supports" the out kwarg.','line_number':410,'multiline':False]['text':'   2) Test directives, like "skips" that tell the test suite to skip some','line_number':411,'multiline':False]['text':'     tests.','line_number':412,'multiline':False]['text':'   3) A "sample inputs" function that generates valid inputs for the operator.','line_number':413,'multiline':False]['text':'','line_number':414,'multiline':False]['text':' OpInfo attributes are described in more detail below.','line_number':415,'multiline':False]['text':'','line_number':416,'multiline':False]['text':' THE SAMPLE INPUTS FUNCTION','line_number':417,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':418,'multiline':False]['text':'','line_number':419,'multiline':False]['text':' The "sample inputs" function merits special elaboration. This function is','line_number':420,'multiline':False]['text':'   crucial to testing with OpInfos. A typical OpInfo test has to treat the operator','line_number':421,'multiline':False]['text':'   as a black box. There's no structure for the test to understand or exploit.','line_number':422,'multiline':False]['text':'   Without "sample inputs" it wouldn't even know how to call the OpInfo's','line_number':423,'multiline':False]['text':'   operator. The sample input function saves the day by providing different','line_number':424,'multiline':False]['text':'   "SampleInputs" that can be used to call the operator. A sample input','line_number':425,'multiline':False]['text':'   function should have the following signature:','line_number':426,'multiline':False]['text':'','line_number':427,'multiline':False]['text':'   def sample_inputs_foo(op_info, device, dtype, requires_grad, **kwargs):','line_number':428,'multiline':False]['text':'','line_number':429,'multiline':False]['text':'   And should return an iterable of SampleInputs (see the class description','line_number':430,'multiline':False]['text':'   above). Each SampleInput defines an "input", "args", "kwargs", an','line_number':431,'multiline':False]['text':'   "output_process_fn_grad" function, the "broadcasts_input" bool and a','line_number':432,'multiline':False]['text':'   "name".','line_number':433,'multiline':False]['text':'','line_number':434,'multiline':False]['text':'   All the "sample_inputs" functions are invoked within a `torch.no_grad()`','line_number':435,'multiline':False]['text':'   environment for efficiency and correctness. As such remember to set the','line_number':436,'multiline':False]['text':'   "requires_grad" flag on the inputs **after** performing any transformations','line_number':437,'multiline':False]['text':'   on them.','line_number':438,'multiline':False]['text':'','line_number':439,'multiline':False]['text':' The "input" is the first argument to the operator, or the tensor that','line_number':440,'multiline':False]['text':'   the method or inplace variants of the operator should be called on, and','line_number':441,'multiline':False]['text':'   should be on the requested device, of the requested dtype, and its','line_number':442,'multiline':False]['text':'   requires_grad attribute should be set to the requires_grad argument.','line_number':443,'multiline':False]['text':'','line_number':444,'multiline':False]['text':' "args" should contain positional arguments, and "kwargs" keyword arguments.','line_number':445,'multiline':False]['text':'','line_number':446,'multiline':False]['text':' "output_process_fn_grad" has an interesting name. It's a function that maps','line_number':447,'multiline':False]['text':'   the operator's output (when given the input, args, and kwargs) to the','line_number':448,'multiline':False]['text':'   portion of the output to gradcheck. For example, consider an operator','line_number':449,'multiline':False]['text':'   like torch.linalg.slogdet','line_number':450,'multiline':False]['text':'   (https://pytorch.org/docs/master/generated/torch.linalg.slogdet.html).','line_number':451,'multiline':False]['text':'   This operator returns a tuple of two tensors, but the first tensor','line_number':452,'multiline':False]['text':'   cannot be backwarded through. Its "output_process_fn_grad" filters','line_number':453,'multiline':False]['text':'   this output tuple to just the second argument, which we can call backward','line_number':454,'multiline':False]['text':'   on. Functions that produce a single tensor can ignore this argument.','line_number':455,'multiline':False]['text':'','line_number':456,'multiline':False]['text':' "broadcasts_input" is a bool indicated if the SampleInput causes the operator','line_number':457,'multiline':False]['text':'   to broadcast the "input" argument. This is important for tests to understand','line_number':458,'multiline':False]['text':'   because inplace variants of operations throw a runtime error if they','line_number':459,'multiline':False]['text':'   would broadcast their input arguments, so tests that work with inplace','line_number':460,'multiline':False]['text':'   variants filter SampleInputs that broadcast their input.','line_number':461,'multiline':False]['text':'','line_number':462,'multiline':False]['text':' "name" is a string that's just used for debugging. It appears when printing','line_number':463,'multiline':False]['text':'   the SampleInput.','line_number':464,'multiline':False]['text':'','line_number':465,'multiline':False]['text':' Sample inputs are designed to be used with many tests, some','line_number':466,'multiline':False]['text':'   that are very time consuming, so they should be a small','line_number':467,'multiline':False]['text':'   set with small tensors. An elaborated set of sample inputs','line_number':468,'multiline':False]['text':'   can be specified using the "reference_inputs_func" attribute.','line_number':469,'multiline':False]['text':'   The "reference inputs" for an operation are an extended','line_number':470,'multiline':False]['text':'   set of sample inputs that can more exhausively test an','line_number':471,'multiline':False]['text':'   operator. They are used by only a few tests that are careful','line_number':472,'multiline':False]['text':'   not to take too long to run. Adding reference inputs','line_number':473,'multiline':False]['text':'   is highly encouraged!','line_number':474,'multiline':False]['text':'','line_number':475,'multiline':False]['text':' THE (OPTIONAL) ERROR INPUTS FUNCTION','line_number':476,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':477,'multiline':False]['text':'','line_number':478,'multiline':False]['text':' OpInfos may optionally specify "error inputs" through an error function. If','line_number':479,'multiline':False]['text':'   specified test_errors in test_ops.py will call the op with these inputs','line_number':480,'multiline':False]['text':'   and validate that the desired error is thrown.','line_number':481,'multiline':False]['text':'','line_number':482,'multiline':False]['text':' Error inputs automate a common testing pattern where multiple inputs are','line_number':483,'multiline':False]['text':'   passed to an operation and the errors they thrown are reviewed. Tests','line_number':484,'multiline':False]['text':'   written in this style should be ported to the new OpInfo pattern.','line_number':485,'multiline':False]['text':'','line_number':486,'multiline':False]['text':' Error inputs are specified using the ErrorInputs class, which contains','line_number':487,'multiline':False]['text':'   a SampleInput (see above) and data about the expected error.','line_number':488,'multiline':False]['text':'','line_number':489,'multiline':False]['text':' OPINFO FILE ORGANIZATION','line_number':490,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~','line_number':491,'multiline':False]['text':'','line_number':492,'multiline':False]['text':' All OpInfos are currently defined in this file. Most OpInfo tests are defined','line_number':493,'multiline':False]['text':'   in test_ops.py, but some system-specific tests are defined in those','line_number':494,'multiline':False]['text':'   systems' test files, and subclass-specific tests are defined in the test','line_number':495,'multiline':False]['text':'   file that corresponds to that subclass (see the below).','line_number':496,'multiline':False]['text':'   Expect a reorganization in the future.','line_number':497,'multiline':False]['text':'','line_number':498,'multiline':False]['text':' WHAT'S TESTED?','line_number':499,'multiline':False]['text':' ~~~~~~~~~~~~~~','line_number':500,'multiline':False]['text':'','line_number':501,'multiline':False]['text':' Every OpInfo in the op_db sequence has the following properties validated in','line_number':502,'multiline':False]['text':' test_ops.py:','line_number':503,'multiline':False]['text':'','line_number':504,'multiline':False]['text':'   - that its supported dtypes are specified correctly','line_number':505,'multiline':False]['text':'   - that the operation produces the same results when called with noncontiguous inputs','line_number':506,'multiline':False]['text':'   - that it supports the out= argument properly (if it allows out=),','line_number':507,'multiline':False]['text':'       see https://github.com/pytorch/pytorch/wiki/Developer-FAQ#how-does-out-work-in-pytorch','line_number':508,'multiline':False]['text':'   - that it works with the conjugate view bit properly','line_number':509,'multiline':False]['text':'   - that its function, method, and inplace variants perform the same operation','line_number':510,'multiline':False]['text':'       (that is, that torch.add, torch.Tensor.add, and torch.Tensor.add_ all','line_number':511,'multiline':False]['text':'       do the same thing).','line_number':512,'multiline':False]['text':'   - that its inplace variant preserves the input's storage','line_number':513,'multiline':False]['text':'   - that its gradient formula is implemented correctly, and that it supports','line_number':514,'multiline':False]['text':'       gradgrad and complex grad and gradgrad and forward mode AD properly for','line_number':515,'multiline':False]['text':'       the op's function and inplace variants (method variants are skipped','line_number':516,'multiline':False]['text':'       to reduce test time).','line_number':517,'multiline':False]['text':'   - that the operation performs the same operation when traced or scripted','line_number':518,'multiline':False]['text':'       using the jit','line_number':519,'multiline':False]['text':'   - that the operation is autodifferentiated by the jit as expected','line_number':520,'multiline':False]['text':'   - that the operator's aliases, if any, perform the same operation and that','line_number':521,'multiline':False]['text':'       the jit understands the alias','line_number':522,'multiline':False]['text':'   - that the operator throws the correct errors (if error_inputs is defined)','line_number':523,'multiline':False]['text':'   - that the operator produces the same results as a NumPy reference (if ref is defined)','line_number':524,'multiline':False]['text':'   - that the operator produces the same results as a NumPy reference on an extended','line_number':525,'multiline':False]['text':'       set of "reference inputs" (if both ref and reference_inputs_func are defined)','line_number':526,'multiline':False]['text':'       (NOTE: elementwise unary and elementwise binary OpInfos do this even if only','line_number':527,'multiline':False]['text':'         ref is defined, because they effectively autogenerate reference inputs)','line_number':528,'multiline':False]['text':'   - that the operator works on different CUDA devices','line_number':529,'multiline':False]['text':'','line_number':530,'multiline':False]['text':' Additional OpInfo tests are in test_jit_fuser_te.py, test_fx_experimental.py,','line_number':531,'multiline':False]['text':'   and test_fx.py. These tests validate that operators work with NNC and FX','line_number':532,'multiline':False]['text':'   as expected.','line_number':533,'multiline':False]['text':'','line_number':534,'multiline':False]['text':' For performance, some of the above tests may only run on the first','line_number':535,'multiline':False]['text':'   SampleInput returned by an OpInfo's sample input function.','line_number':536,'multiline':False]['text':'','line_number':537,'multiline':False]['text':' In addition to these tests, some subclasses (discussed in the next section)','line_number':538,'multiline':False]['text':'   define additional tests.','line_number':539,'multiline':False]['text':'','line_number':540,'multiline':False]['text':' Critically, as mentioned above, what's not necessarily tested is that the operator','line_number':541,'multiline':False]['text':'   works as expected. When implementing an OpInfo an engineer must still','line_number':542,'multiline':False]['text':'   typically write one or more tests validating the operator's behavior.','line_number':543,'multiline':False]['text':'   The exception to this is if reference testing is sufficient, or if','line_number':544,'multiline':False]['text':'   the operation belongs to an OpInfo subclass that has more exhaustive','line_number':545,'multiline':False]['text':'   operator testing. Elementwise unary and elementwise binary operators,','line_number':546,'multiline':False]['text':'   in particular, usually don't require additional testing beyond','line_number':547,'multiline':False]['text':'   writing an Opinfo.','line_number':548,'multiline':False]['text':'','line_number':549,'multiline':False]['text':'','line_number':550,'multiline':False]['text':' OPINFO (SUB)CLASSES','line_number':551,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~','line_number':552,'multiline':False]['text':'','line_number':553,'multiline':False]['text':' In addition to the OpInfo base class there are several specialized OpInfo','line_number':554,'multiline':False]['text':'   subclasses. For example, the UnaryUfuncInfo subclass is used for','line_number':555,'multiline':False]['text':'   unary elementwise operations. These operations have a common structure','line_number':556,'multiline':False]['text':'   that test_unary_ufuncs.py exploits with additional automated testing.','line_number':557,'multiline':False]['text':'   The automated testing in test_unary_ufuncs.py is so thorough, comparing','line_number':558,'multiline':False]['text':'   the operator to a NumPy reference function on a plethora of values, that','line_number':559,'multiline':False]['text':'   just implementing an OpInfo for a unary elementwise operation is often','line_number':560,'multiline':False]['text':'   sufficient testing.','line_number':561,'multiline':False]['text':'','line_number':562,'multiline':False]['text':' The ForeachFuncInfo is another OpInfo subclass that is hyper-specialized to a','line_number':563,'multiline':False]['text':'   very unique class of operations. These OpInfos aren't included in the','line_number':564,'multiline':False]['text':'   op_db sequence and have their own tests.','line_number':565,'multiline':False]['text':'','line_number':566,'multiline':False]['text':' Other OpInfo subclasses, like SpectralFuncInfo, are just for convenience','line_number':567,'multiline':False]['text':' when writing OpInfos.','line_number':568,'multiline':False]['text':'','line_number':569,'multiline':False]['text':' TESTING A NEW OPERATOR','line_number':570,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~','line_number':571,'multiline':False]['text':'','line_number':572,'multiline':False]['text':' If you're adding a new operator to any of the following namespaces:','line_number':573,'multiline':False]['text':'   - torch','line_number':574,'multiline':False]['text':'   - torch.fft','line_number':575,'multiline':False]['text':'   - torch.linalg,','line_number':576,'multiline':False]['text':'   - torch.special','line_number':577,'multiline':False]['text':'   - torch.nn.functional','line_number':578,'multiline':False]['text':' then you should typically add an OpInfo for it.','line_number':579,'multiline':False]['text':'','line_number':580,'multiline':False]['text':' As mentioned a couple times above, implementing an OpInfo is not','line_number':581,'multiline':False]['text':'   usually sufficient testing (unless the operator is a unary or binary elementwise','line_number':582,'multiline':False]['text':'   operator). The OpInfo will only test the properties described in the','line_number':583,'multiline':False]['text':'   "WHAT'S TESTED" section. It DOES NOT necessarily verify that the operator is','line_number':584,'multiline':False]['text':'   implemented correctly.','line_number':585,'multiline':False]['text':'','line_number':586,'multiline':False]['text':' TIPS FOR WRITING AN OPINFO AND OPINFO TESTS','line_number':587,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':588,'multiline':False]['text':'','line_number':589,'multiline':False]['text':' Writing an OpInfo can be a little daunting. Since the point of an OpInfo is to','line_number':590,'multiline':False]['text':'   be consumed by a variety of systems it can be hard to understand how to','line_number':591,'multiline':False]['text':'   deal with test failures or how to set the OpInfo metadata properly.','line_number':592,'multiline':False]['text':'','line_number':593,'multiline':False]['text':' Before adding an OpInfo it helps to look at other OpInfos. A sample inputs','line_number':594,'multiline':False]['text':'   function must be defined, and the operator's dtypes must be specified.','line_number':595,'multiline':False]['text':'   Once that's done you should run the operator's tests in test_ops.py','line_number':596,'multiline':False]['text':'   (these can be filtered using the "-k" argument in pytest). Tests that','line_number':597,'multiline':False]['text':'   fail should provide an error message that describes what to change about','line_number':598,'multiline':False]['text':'   your OpInfo. You don't need to worry about changing an OpInfo's default','line_number':599,'multiline':False]['text':'   values unless a test yells at you.','line_number':600,'multiline':False]['text':'','line_number':601,'multiline':False]['text':' Similarly, if you're writing a test that consumes OpInfos then it's critical','line_number':602,'multiline':False]['text':'   your test provides a clear error message describing what to do when it','line_number':603,'multiline':False]['text':'   fails. You should not assume the OpInfo implementer is familiar with your','line_number':604,'multiline':False]['text':'   system.','line_number':605,'multiline':False]['text':'','line_number':606,'multiline':False]['text':' If you see a confusing error message while developing an OpInfo then please','line_number':607,'multiline':False]['text':'   file an issue describing what happened.','line_number':608,'multiline':False]['text':'','line_number':609,'multiline':False]['text':' This trial-and-error approach to writing an OpInfo can be frustrating,','line_number':610,'multiline':False]['text':'   but it's probably necessary as long as OpInfos don't require','line_number':611,'multiline':False]['text':'   learning about all the systems that consume them. One thing that can help','line_number':612,'multiline':False]['text':'   is the get_supported_dtypes() function defined in utils.py. This','line_number':613,'multiline':False]['text':'   function can be used to programmatically specify the dtypes an operator','line_number':614,'multiline':False]['text':'   supports, and is especially useful if writing an OpInfo on a machine','line_number':615,'multiline':False]['text':'   without a CUDA device. See its documentation for more details.','line_number':616,'multiline':False]['text':'','line_number':617,'multiline':False]['text':' THE FUTURE OF OPINFOS AND OPINFO TESTING','line_number':618,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':619,'multiline':False]['text':'','line_number':620,'multiline':False]['text':' In the future we expect OpInfo coverage to improve and cover','line_number':621,'multiline':False]['text':'   the great majority of PyTorch's (public) operators.','line_number':622,'multiline':False]['text':'','line_number':623,'multiline':False]['text':' Classes and methods for the operator database','line_number':626,'multiline':False]['text':' the string name of the function','line_number':631,'multiline':False]['text':' An optional reference function that accepts ndarrays (AKA "NumPy arrays").','line_number':634,'multiline':False]['text':' If given, the op will be compared with its reference on each of its sample inputs.','line_number':635,'multiline':False]['text':' the following metadata describes the operator, its variants, and its aliases, if any','line_number':638,'multiline':False]['text':' iterable of aliases, e.g. ("absolute",) for torch.abs','line_number':640,'multiline':False]['text':' additional string to include in the test name','line_number':643,'multiline':False]['text':' this is useful when an op needs multiple OpInfos,','line_number':644,'multiline':False]['text':' like divide does, often because it's really several','line_number':645,'multiline':False]['text':' different ops behind the scenes','line_number':646,'multiline':False]['text':' the function variant of the operation, populated as torch.<name> if None','line_number':649,'multiline':False]['text':' allows the method variant of this operation to be specified as follows:','line_number':652,'multiline':False]['text':' - if _NOTHING (default), then the OpInfo attempts to discover the variant using its name','line_number':653,'multiline':False]['text':' - if None, then the OpInfo explicitly specifies is has no associated method','line_number':654,'multiline':False]['text':' - if a Callable, then that callable should be the method associated with this operation','line_number':655,'multiline':False]['text':' allows the inplace variant of this operation to be specified as follows:','line_number':658,'multiline':False]['text':' - if _NOTHING (default), then the OpInfo attempts to discover the variant using its name','line_number':659,'multiline':False]['text':' - if None, then the OpInfo explicitly specifies is has no associated inplace variant','line_number':660,'multiline':False]['text':' - if a Callable, then that callable should be the inplace variant associated with this operation','line_number':661,'multiline':False]['text':' allows the operator variant of this operation to be specified as follows:','line_number':664,'multiline':False]['text':' - if _NOTHING (default), then the OpInfo attempts to discover the variant using its name','line_number':665,'multiline':False]['text':' - if None, then the OpInfo explicitly specifies is has no associated operator','line_number':666,'multiline':False]['text':' - if a Callable, then that callable should be the operator associated with this operation','line_number':667,'multiline':False]['text':' allows the inplace operator variant of this operation to be specified as follows:','line_number':670,'multiline':False]['text':' - if _NOTHING (default), then the OpInfo attempts to discover the variant using its name','line_number':671,'multiline':False]['text':' - if None, then the OpInfo explicitly specifies is has no associated inplace operator','line_number':672,'multiline':False]['text':' - if a Callable, then that callable should be the inplace operator associated with this operation','line_number':673,'multiline':False]['text':' the following metadata are test directives for skipping or modifying tests','line_number':676,'multiline':False]['text':' information about which tests to skip','line_number':678,'multiline':False]['text':' decorators to apply to generated tests','line_number':681,'multiline':False]['text':' the following are pointers to functions to generate certain classes of inputs','line_number':684,'multiline':False]['text':' function to generate sample inputs with strided layouts','line_number':686,'multiline':False]['text':' function to generate a more thorough set of samples inputs with strided layouts','line_number':689,'multiline':False]['text':' function to generate inputs that will throw errors','line_number':692,'multiline':False]['text':' function to generate sparse (coo, csr, csc, bsr, bsc) inputs that will throw errors','line_number':695,'multiline':False]['text':' function to generate sample inputs with sparse coo layouts','line_number':698,'multiline':False]['text':' function to generate sample inputs with sparse csr layouts','line_number':701,'multiline':False]['text':' function to generate sample inputs with sparse csc layouts','line_number':704,'multiline':False]['text':' function to generate sample inputs with sparse bsr layouts','line_number':707,'multiline':False]['text':' function to generate sample inputs with sparse bsc layouts','line_number':710,'multiline':False]['text':' the following metadata relates to dtype support and is tested for correctness in test_ops.py','line_number':713,'multiline':False]['text':' dtypes this function works with on the CPU,','line_number':715,'multiline':False]['text':' inherited by other device types that don't specify their own dtypes','line_number':716,'multiline':False]['text':' the following dtypesIf... options override the dtypes value on their respective device types','line_number':719,'multiline':False]['text':' dtypes this function is expected to work with on CUDA','line_number':721,'multiline':False]['text':' dtypes this function is expected to work with on ROCM','line_number':724,'multiline':False]['text':' backward dtypes this function is expected to work with','line_number':727,'multiline':False]['text':' backward dtypes this function is expected to work with on CUDA','line_number':730,'multiline':False]['text':' backward dtypes this function is expected to work with on ROCM','line_number':733,'multiline':False]['text':' the following metadata describes the operators out= support','line_number':736,'multiline':False]['text':' whether the op supports the out kwarg','line_number':738,'multiline':False]['text':' defaults to True, if the op does not allow the out kwarg or','line_number':739,'multiline':False]['text':' supports it incorrectly then test_out in test_ops.py should fail','line_number':740,'multiline':False]['text':' the following metadata relates to autograd support','line_number':743,'multiline':False]['text':' whether the operation supports backward mode AD','line_number':744,'multiline':False]['text':' if true, gradient correctness is tested in test_ops.py','line_number':745,'multiline':False]['text':' using the op's sample inputs','line_number':746,'multiline':False]['text':' whether the op supports second order gradients','line_number':749,'multiline':False]['text':' if true, gradgrad correctness is tested in test_ops.py','line_number':750,'multiline':False]['text':' defaults to support_autograd's value','line_number':751,'multiline':False]['text':' TODO: rename this to supports_bwgrad_bwgrad to be consistent with below','line_number':752,'multiline':False]['text':' whether the ops supports second order gradients via','line_number':755,'multiline':False]['text':' forward-over-reverse. If True, forward-over-reverse gradgrad correctness','line_number':756,'multiline':False]['text':' is tested. If False, test that forward grad is not implemented.','line_number':757,'multiline':False]['text':' Defaults to False.','line_number':758,'multiline':False]['text':' whether the operation supports inplace autograd','line_number':761,'multiline':False]['text':' if true, tested in test_ops.py','line_number':762,'multiline':False]['text':' defaults to supports_autograd's value','line_number':763,'multiline':False]['text':' Whether the operation support forward mode AD','line_number':766,'multiline':False]['text':' If the value is True, we check that the gradients are correct','line_number':767,'multiline':False]['text':' If the value is False, we test that forward grad is not implemented','line_number':768,'multiline':False]['text':' Whether the operation has a varargs variant','line_number':771,'multiline':False]['text':' (e.g. functions like ones, zeros, methods like view, permute)','line_number':772,'multiline':False]['text':' wrapper function for gradcheck','line_number':775,'multiline':False]['text':' whether to check batched grad when doing gradcheck','line_number':778,'multiline':False]['text':' defaults to support_autograd's value','line_number':779,'multiline':False]['text':' whether to check batched grad grad when doing gradgradcheck','line_number':782,'multiline':False]['text':' default's to support_gradgrad's value','line_number':783,'multiline':False]['text':' whether to check batched forward grad when doing gradcheck','line_number':786,'multiline':False]['text':' defaults to the value of `supports_forward_ad`','line_number':787,'multiline':False]['text':' whether to check batched forward grad when doing gradcheck','line_number':790,'multiline':False]['text':' defaults to the value of `check_batched_forward_grad`','line_number':791,'multiline':False]['text':' tolerance for nondeterminism while performing gradcheck','line_number':794,'multiline':False]['text':' Whether to use the fast implmentation for gradcheck/gradgradcheck.','line_number':797,'multiline':False]['text':' When set to None, defers to the default value provided by the wrapper','line_number':798,'multiline':False]['text':' function around gradcheck (testing._internal.common_utils.gradcheck)','line_number':799,'multiline':False]['text':' the following metadata relates to JIT support and is tested for correctness in test_ops.py','line_number':802,'multiline':False]['text':' name of the corresponding aten:: operator','line_number':804,'multiline':False]['text':' if this is a composite implicit autograd op, the decomposed op','line_number':807,'multiline':False]['text':' name of the corresponding aten:: operator for backwards','line_number':810,'multiline':False]['text':' if a op's aten::node is expected to be symbolically autodiffed','line_number':813,'multiline':False]['text':' a list of strings with node names that are expected to be in a','line_number':816,'multiline':False]['text':' DifferentiableGraph when autodiffed. Ex: ['aten::add', 'aten::mm'],','line_number':817,'multiline':False]['text':' default is populated to be ['aten::(name of Python operator)']','line_number':818,'multiline':False]['text':' a list of strings with node names that are expected to be in FusionGroups','line_number':821,'multiline':False]['text':' inside of DifferentiableGraphs when this operation is autodiffed.','line_number':822,'multiline':False]['text':' Ex: ['aten::add', 'aten::mm'], defaults to an empty list','line_number':823,'multiline':False]['text':' Note: currently no ops use fusible nodes','line_number':824,'multiline':False]['text':' the following metadata relates to sparse support and is used in test_sparse.py','line_number':827,'multiline':False]['text':' whether the op supports sparse coo inputs, defaults to False','line_number':829,'multiline':False]['text':' TODO: rename supports_sparse to supports_sparse_coo','line_number':830,'multiline':False]['text':' only run tracing tests','line_number':833,'multiline':False]['text':' if the operator can be traced','line_number':836,'multiline':False]['text':' the following metadata relates to sparse compressed support and','line_number':839,'multiline':False]['text':' is used in test_sparse_csr.py and test_sparse.py','line_number':840,'multiline':False]['text':' whether the op supports sparse csr inputs, defaults to False','line_number':842,'multiline':False]['text':' whether the op supports sparse csc inputs, defaults to False','line_number':844,'multiline':False]['text':' whether the op supports sparse bsr inputs, defaults to False','line_number':846,'multiline':False]['text':' whether the op supports sparse bsc inputs, defaults to False','line_number':848,'multiline':False]['text':' whether the op promotes integer inputs to float','line_number':851,'multiline':False]['text':' the following metadata relates to complex support and is checked in test_ops.py','line_number':854,'multiline':False]['text':' assert that jit shape analysis fully propagates shape','line_number':860,'multiline':False]['text':' the following metadata relates to ExpandedWeights support and is checked in test_expanded_weights.py','line_number':863,'multiline':False]['text':' Validates the dtypes are generated from the dispatch-related functions','line_number':876,'multiline':False]['text':' Attribute to verify dynamic_dtypes are used.','line_number':883,'multiline':False]['text':' Make sure `dtyesIfCUDA` is dynamic, if dynamic dispatch is used for CPU','line_number':889,'multiline':False]['text':' This is because, below we set dtypesIfCUDA to dtypes if they are None.','line_number':890,'multiline':False]['text':' NOTE: backward dtypes must be acquired before forward dtypes','line_number':900,'multiline':False]['text':'   since they fallback to explicit (not implicit!) specifications of','line_number':901,'multiline':False]['text':'   forward dtypes','line_number':902,'multiline':False]['text':' NOTE: if the op is unspecified it is assumed to be under the torch namespace','line_number':944,'multiline':False]['text':' attributes like real, imag are not callable','line_number':951,'multiline':False]['text':' Note: operator.i<op> will use operator.<op> and assign the result to the lhs when no','line_number':963,'multiline':False]['text':' __i<op>__ method is found. This results in the appearance of an inplace operator variant which','line_number':964,'multiline':False]['text':' does not have the correct inplace behavior. To avoid this, we guard automatic detection of the inplace','line_number':965,'multiline':False]['text':' operator with a check that an inplace variant exists.','line_number':966,'multiline':False]['text':' Specifying sample inputs function without specifying the','line_number':977,'multiline':False]['text':' corresponding layout support implies the layout support:','line_number':978,'multiline':False]['text':' We run the sampling functions without tracking the gradiends of the creation of inputs','line_number':1004,'multiline':False]['text':' Autograd support','line_number':1030,'multiline':False]['text':' Autograd flags that depend on backward AD only','line_number':1032,'multiline':False]['text':' - If setting has been explicitly set, raise error if inconsistent','line_number':1033,'multiline':False]['text':' Autograd flags that depend on both forward AD and backward AD','line_number':1090,'multiline':False]['text':' type: ignore[assignment]','line_number':1106,'multiline':False]['text':' Note: it is assumed that the input here is either a tensor or tensorlist','line_number':1159,'multiline':False]['text':' map torch.sparse_coo to OpInfo.supports_sparse:','line_number':1229,'multiline':False]['text':' Test default dim and keepdim','line_number':1378,'multiline':False]['text':' Test reducing inner and outer most dimensions','line_number':1381,'multiline':False]['text':' Test reducing middle dimension','line_number':1385,'multiline':False]['text':' Test reducing all dimensions','line_number':1390,'multiline':False]['text':' Test reducing both first and last dimensions','line_number':1393,'multiline':False]['text':' Test reducing every other dimension starting with the second','line_number':1397,'multiline':False]['text':' TODO(@heitorschueroff) Once all reduction operators are using','line_number':1405,'multiline':False]['text':' ReductionOpInfo use op_info.supports_multiple_dims directly.','line_number':1406,'multiline':False]['text':' TODO(@heitorschueroff) Once all reduction operators are using ReductionOpInfo','line_number':1409,'multiline':False]['text':' use op_info.generate_args_kwargs directly.','line_number':1410,'multiline':False]['text':' NOTE [Reductions]:','line_number':1426,'multiline':False]['text':'','line_number':1427,'multiline':False]['text':' For testing purposes, we relax the definition of a reduction operator','line_number':1428,'multiline':False]['text':' as defined in the docstring below. We do this to capture operators with','line_number':1429,'multiline':False]['text':' a similar API so they can be tested automatically. However...','line_number':1430,'multiline':False]['text':'','line_number':1431,'multiline':False]['text':' Strictly speaking a reduction operator is an operator that can reduce an','line_number':1432,'multiline':False]['text':' array to a single scalar value and that can be computed from the partial','line_number':1433,'multiline':False]['text':' result of reducing subarrays. This usually means that the reduction operation','line_number':1434,'multiline':False]['text':' should be commutative and associative. This definition is important when it','line_number':1435,'multiline':False]['text':' comes to implementation as it determines how a reduction can be parallelized.','line_number':1436,'multiline':False]['text':'','line_number':1437,'multiline':False]['text':' For example, many summary statistics such as median, mode and quantile cannot','line_number':1438,'multiline':False]['text':' be computed from partial results because these are sorting and counting based','line_number':1439,'multiline':False]['text':' algorithms that need information that would be lost in the reduced value.','line_number':1440,'multiline':False]['text':' The identity value for the operator if it has one.','line_number':1469,'multiline':False]['text':' The nan policy for the operator if it implements one.','line_number':1471,'multiline':False]['text':' - propagate: NaN values are propagated to the output','line_number':1472,'multiline':False]['text':' - omit: NaN values are discarded during the reduction','line_number':1473,'multiline':False]['text':' Whether the operator supports reducing multiple dimensions.','line_number':1475,'multiline':False]['text':' Whether the operator promotes integral to floating point dtypes.','line_number':1477,'multiline':False]['text':' Whether the operator promotes all integral dtypes to int64.','line_number':1479,'multiline':False]['text':' If a specific dtype is given, then the operator always returns that','line_number':1481,'multiline':False]['text':' dtype irrespective of the input dtype. If None, the operator returns','line_number':1482,'multiline':False]['text':' the dtype according to the type promotion rules above.','line_number':1483,'multiline':False]['text':' Casts complex results to real (e.g. linalg.norm or torch.var)','line_number':1485,'multiline':False]['text':' ReductionOpInfo tests generate their own input, dim and keepdim','line_number':1487,'multiline':False]['text':' arguments and call this function to generate tuples of extra args and','line_number':1488,'multiline':False]['text':' kwargs to use when calling the op. This is required for operators that','line_number':1489,'multiline':False]['text':' have other required parameters besides the input tensor.','line_number':1490,'multiline':False]['text':' Options from the OpInfo base class','line_number':1495,'multiline':False]['text':' These are mutually exclusive options','line_number':1501,'multiline':False]['text':' Default sample_inputs_func for ReductionOpInfo which augments sample','line_number':1507,'multiline':False]['text':' inputs from sample_inputs_reduction with the args and kwargs from','line_number':1508,'multiline':False]['text':' generate_args_kwargs. This is only used if sample_inputs_func is None.','line_number':1509,'multiline':False]['text':' Override OpInfo defaults and call base class __init__','line_number':1515,'multiline':False]['text':' The base reference input generation for elementwise binary operations','line_number':1529,'multiline':False]['text':' Note that these references inputs use scalars for the SampleInput.input value,','line_number':1570,'multiline':False]['text':'   and many tests require SampleInput.input be a tensor or a list of tensors','line_number':1571,'multiline':False]['text':' yields "normal" samples','line_number':1586,'multiline':False]['text':' yields noncontiguous samples','line_number':1589,'multiline':False]['text':' A functional that extends an elementwise binary operator's bespoke error inputs','line_number':1610,'multiline':False]['text':'   with generic error inputs for the class of elementwise binary operations','line_number':1611,'multiline':False]['text':' The following functions and classes are for testing elementwise binary operators.','line_number':1635,'multiline':False]['text':' Returns a generator of pairs of contiguous tensors on the requested device','line_number':1638,'multiline':False]['text':'   and with the requested dtype.','line_number':1639,'multiline':False]['text':'','line_number':1640,'multiline':False]['text':' This function is intended to test the non-vectorized and vectorized code','line_number':1641,'multiline':False]['text':'   paths of elementwise binary functions, as well as their handling of odd tensor','line_number':1642,'multiline':False]['text':'   sizes (like zero-dim tensors and tensors with zero elements).','line_number':1643,'multiline':False]['text':'','line_number':1644,'multiline':False]['text':' Each iterable will include an a tensor with no elements,','line_number':1645,'multiline':False]['text':'   zero dim (scalar) tensors, small 1D tensors, a medium 1D tensor, and','line_number':1646,'multiline':False]['text':'   a large 2D tensor.','line_number':1647,'multiline':False]['text':' tensors with no elements','line_number':1652,'multiline':False]['text':' zero dim (scalar) tensor','line_number':1655,'multiline':False]['text':' small 1D tensor','line_number':1657,'multiline':False]['text':' medium 1D tensor','line_number':1659,'multiline':False]['text':' large 2D tensor','line_number':1661,'multiline':False]['text':' shape, strides, offset','line_number':1681,'multiline':False]['text':' Returns a generator of pairs of contiguous tensors on the requested device and with','line_number':1706,'multiline':False]['text':'   the requested dtype.','line_number':1707,'multiline':False]['text':'','line_number':1708,'multiline':False]['text':' Unlike the previous function, the values in these tensors are specified manually.','line_number':1709,'multiline':False]['text':' defines interesting values','line_number':1717,'multiline':False]['text':' Note the use of list is required here or the map generator will be','line_number':1746,'multiline':False]['text':'  emptied by the following product and it won't produce the desired cross-product','line_number':1747,'multiline':False]['text':' Note the use of list is required here or the map generator will be','line_number':1786,'multiline':False]['text':'  emptied by the following product and it won't produce the desired cross-product','line_number':1787,'multiline':False]['text':' Note the use of list is required here or the map generator will be','line_number':1817,'multiline':False]['text':'  emptied by the following product and it won't produce the desired cross-product','line_number':1818,'multiline':False]['text':' Test case for NaN propagation','line_number':1833,'multiline':False]['text':' Returns a generator of pairs of contiguous and noncontiguous tensors that','line_number':1849,'multiline':False]['text':'   require broadcasting','line_number':1850,'multiline':False]['text':' Returns a generator of pairs of contiguous tensors and scalars','line_number':1887,'multiline':False]['text':' Extends with scalar lhs','line_number':1905,'multiline':False]['text':' Returns a generator of pairs of contiguous tensors and 0d tensors and scalars and type promotion','line_number':1916,'multiline':False]['text':' add these samples only for logical and comparison ops, arithmetic ops are not happy about extremal scalars','line_number':1920,'multiline':False]['text':' this shape is big enough to trigger vectorization, and has non-vectorized tail','line_number':1937,'multiline':False]['text':' Extends with scalar lhs','line_number':1945,'multiline':False]['text':' Returns a generator of pairs of noncontiguous tensors','line_number':1950,'multiline':False]['text':' Generic noncontiguity','line_number':1962,'multiline':False]['text':' Transposed','line_number':1969,'multiline':False]['text':' More noncontiguity','line_number':1975,'multiline':False]['text':' Noncontiguous indices','line_number':1991,'multiline':False]['text':' Expanded tensors','line_number':2002,'multiline':False]['text':' Sample inputs for elementwise binary operators, like add','line_number':2015,'multiline':False]['text':' Metadata class for binary "universal functions (ufuncs)" that accept two','line_number':2055,'multiline':False]['text':' tensor and have common properties','line_number':2056,'multiline':False]['text':' Set to true if the op always returns bool tensors','line_number':2079,'multiline':False]['text':' Whether the operator allows Tensor x scalar inputs','line_number':2080,'multiline':False]['text':' Whether the operator allows scalar x tensor and tensor x scalar inputs','line_number':2081,'multiline':False]['text':' Whether the operator allows scalar x scalar inputs','line_number':2082,'multiline':False]['text':' Elementwise binary operations perform the equivalent of test_numpy_refs','line_number':2087,'multiline':False]['text':'   in test_binary_ufuncs, but with additional test granularity. So the','line_number':2088,'multiline':False]['text':'   generic test_ops.py test is skipped because it's redundant.','line_number':2089,'multiline':False]['text':' [lr]hs_make_tensor_kwargs are part of the OpInfo to be able to dynamically generate valid samples later on.','line_number':2106,'multiline':False]['text':' The following functions and classes are for testing elementwise unary operators.','line_number':2129,'multiline':False]['text':' Tensors with dim=2 for sparse compressed testing','line_number':2148,'multiline':False]['text':' Creates a 1D, empty, and scalar tensor','line_number':2161,'multiline':False]['text':' Replace values satisfying condition with a safe value. This is used to block','line_number':2176,'multiline':False]['text':' out values the could cause singularity like tan(pi/2)','line_number':2177,'multiline':False]['text':' Helper to create a unary elementwise tensor with valid inputs','line_number':2183,'multiline':False]['text':' Restricts the values in the tensor to the domain of the','line_number':2199,'multiline':False]['text':' given elementwise unary operator','line_number':2200,'multiline':False]['text':' short-circuits for boolean tensors','line_number':2202,'multiline':False]['text':' Special-cases bool','line_number':2233,'multiline':False]['text':' Empty sizes','line_number':2249,'multiline':False]['text':' Generic noncontiguity','line_number':2311,'multiline':False]['text':' Transposed','line_number':2315,'multiline':False]['text':' Expanded tensors','line_number':2319,'multiline':False]['text':' shape, strides, offset','line_number':2333,'multiline':False]['text':' Reuses the elementwise binary generators for consistency','line_number':2353,'multiline':False]['text':' TODO: in the future generalize the reference generators to handle n-ary elementwise operations','line_number':2354,'multiline':False]['text':' yields "normal" samples','line_number':2387,'multiline':False]['text':' yields noncontiguous samples','line_number':2390,'multiline':False]['text':' Metadata class for unary "universal functions (ufuncs)" that accept a single','line_number':2403,'multiline':False]['text':' tensor and have common properties like:','line_number':2404,'multiline':False]['text':' the string name of the function','line_number':2420,'multiline':False]['text':' the [low, high) domain of the function','line_number':2423,'multiline':False]['text':' whether the op correctly handles extremal values (like nan/inf)','line_number':2424,'multiline':False]['text':' whether the op correctly handles large float values (like 1e20)','line_number':2425,'multiline':False]['text':' op supports casting from complex input to real output safely eg. angle','line_number':2426,'multiline':False]['text':' Filters values in the range of the domain specified above but that should not be tested','line_number':2430,'multiline':False]['text':' test_unary_ufuncs.py generates its own inputs to test the consistency','line_number':2448,'multiline':False]['text':' of the operator on sliced tensors, non-contig tensors, etc.','line_number':2449,'multiline':False]['text':' `sample_kwargs` is a utility function to provide kwargs','line_number':2450,'multiline':False]['text':' along with those inputs if required (eg. clamp).','line_number':2451,'multiline':False]['text':' It should return two dictionaries, first holding kwarg for','line_number':2452,'multiline':False]['text':' torch operator and second one for reference NumPy operator.','line_number':2453,'multiline':False]['text':' Epsilon to ensure grad and gradgrad checks don't test values','line_number':2456,'multiline':False]['text':'   outside a function's domain.','line_number':2457,'multiline':False]['text':' cuFFT supports powers of 2 for half and complex half precision','line_number':2475,'multiline':False]['text':' NOTE: For hfft, hfft2, hfftn, irfft, irfft2, irfftn with default args','line_number':2476,'multiline':False]['text':' where output_size n=2*(input_size - 1), we make sure that logical fft size is a power of two','line_number':2477,'multiline':False]['text':' Adjusting the limits because the test would be flaky due to over-saturation of float16','line_number':2496,'multiline':False]['text':' See: https://github.com/pytorch/pytorch/pull/81416','line_number':2497,'multiline':False]['text':' Metadata class for Fast Fourier Transforms in torch.fft.','line_number':2560,'multiline':False]['text':' the string name of the function','line_number':2566,'multiline':False]['text':' Reference implementation (probably in np.fft namespace)','line_number':2568,'multiline':False]['text':' the string name of the function','line_number':2604,'multiline':False]['text':' a reference function','line_number':2606,'multiline':False]['text':' mutually exclusive from same_size and zero_size, which are all or nothing','line_number':2636,'multiline':False]['text':' interweave some empty tensors + have the last 2 tensors be empty (see #100701)','line_number':2655,'multiline':False]['text':' get torch inplace reference function','line_number':2673,'multiline':False]['text':' note(crcrpar): `foreach_method` for `"zero"` is `None` but `None` would call','line_number':2712,'multiline':False]['text':' `_getattr_qual` in `OpInfo.__post_init__` which should fail since `_foreach_zero`','line_number':2713,'multiline':False]['text':' is not defined at the moment. Thus to skip the qualification, set a similar torch','line_number':2714,'multiline':False]['text':' function.','line_number':2715,'multiline':False]['text':' because minimum ref does not support inplace or scalar','line_number':2746,'multiline':False]['text':' because maximum ref does not support inplace or scalar','line_number':2750,'multiline':False]['text':' new_arg = arg - diag(arg) + I','line_number':2793,'multiline':False]