['text':' noqa: F403','line_number':8,'multiline':False]['text':' Simplifying assumption: we assume that the batch dim is always the left-most','line_number':16,'multiline':False]['text':' dim, and the ragged dim is always the second dim.','line_number':17,'multiline':False]['text':' ex: (2, 3, 4) -> (1, 2, 3)','line_number':35,'multiline':False]['text':' ex: (0, 1, 4) -> (0, 3)','line_number':36,'multiline':False]['text':' This logic needs to be done after we canonicalize dims but before we','line_number':40,'multiline':False]['text':' map to inner dims so we can print a nicer error message.','line_number':41,'multiline':False]['text':' special case: ellipses allows for any number of unchecked args at the end','line_number':61,'multiline':False]['text':' ops with "jt" require contiguous JT only','line_number':76,'multiline':False]['text':' ops with "jt_all" can accept all kinds of JT','line_number':79,'multiline':False]['text':' Calling into .shape here','line_number':114,'multiline':False]['text':' returns True if the raggedness-relevant portions of the NT shape','line_number':122,'multiline':False]['text':' match those of the specified size','line_number':123,'multiline':False]['text':' Note: [ Squeezing leading ones ]','line_number':130,'multiline':False]['text':'','line_number':131,'multiline':False]['text':' Squeeze leading ones from t.','line_number':132,'multiline':False]['text':'','line_number':133,'multiline':False]['text':' We want:','line_number':134,'multiline':False]['text':'   (B, j0, ?, ?) + (1, 1, ?, ?) -> (B, j0, ?, ?)','line_number':135,'multiline':False]['text':'   (B, j0, ?, ?) + (1, 1, 1, ?, ?) -> (1, B, j0, ?, ?)  (not yet supported)','line_number':136,'multiline':False]['text':'','line_number':137,'multiline':False]['text':' 1) Squeeze extra ones and grab values from NT','line_number':138,'multiline':False]['text':'   (1, 1, ?, ?) -> (?, ?)   and   (sum(*), ?, ?) -> (B, j0, ?, ?)','line_number':139,'multiline':False]['text':' 2) Do dense broadcasting:','line_number':140,'multiline':False]['text':'   (sum(*), ?, ?) + (?, ?) -> (sum(*), ?, ?)','line_number':141,'multiline':False]['text':' 3) Construct nested tensor','line_number':142,'multiline':False]['text':'   (sum(*), ?, ?) -> (B, j0, ?, ?)','line_number':143,'multiline':False]['text':'','line_number':144,'multiline':False]['text':' If unsqueezing on the 0th dim becomes supported, we would unsqueeze','line_number':145,'multiline':False]['text':' at step (4) and we would need to update this function to record how','line_number':146,'multiline':False]['text':' many ones we unsqueezed.','line_number':147,'multiline':False]['text':' Handle pointwise fallbacks','line_number':184,'multiline':False]['text':' Assume there aren't additional tensors that aren't the "unary/binary" args','line_number':186,'multiline':False]['text':' a is NT, b is NT','line_number':219,'multiline':False]['text':' ex: (B, j0, D) + (B, j0, D)','line_number':221,'multiline':False]['text':' ex: (B, j0, D) + (B, j0, 1)','line_number':222,'multiline':False]['text':' either a is NT or b is NT at this point','line_number':228,'multiline':False]['text':' === Handle broadcasting across the batch / ragged dims ===','line_number':232,'multiline':False]['text':' Easy case: take advantage of pre-existing broadcasting logic','line_number':234,'multiline':False]['text':' ex: (B, j0, ?, ?) + (?) -> (B, j0, ?, ?)','line_number':235,'multiline':False]['text':' ex: (B, j0, ?, ?) + (?, ?) -> (B, j0, ?, ?)','line_number':236,'multiline':False]['text':' ex: (B, j0, ?, ?) + (1, 1, ?, ?) -> (B, j0, ?, ?)','line_number':237,'multiline':False]['text':' See Note: [ Squeezing leading ones ]','line_number':239,'multiline':False]['text':' Harder case: do manual broadcasting over unbound components','line_number':247,'multiline':False]['text':' when NT dim == non-NT dim','line_number':248,'multiline':False]['text':' ex: (B, j0, D_0, D_1) + (B, 1, D_0, D_1) -> (B, j0, D_0, D_1)','line_number':249,'multiline':False]['text':' ex: (B, j0, D_0, D_1) + (1, 1, D_0, D_1) -> should','line_number':251,'multiline':False]['text':' be (B, j0, D_0, D_1) but not yet supported','line_number':252,'multiline':False]['text':' need to use offsets to broadcast across ragged dim properly','line_number':258,'multiline':False]['text':' NB: inefficient fallback here; Triton codegen can help this','line_number':259,'multiline':False]['text':' TODO: Make this work with autograd','line_number':260,'multiline':False]['text':' ex: (B, j0, D_0, D_1) + (A, B, 1, D_0, D_1) -> error because this breaks the invariant','line_number':267,'multiline':False]['text':' that ragged dim is wrt left-most batch dim','line_number':268,'multiline':False]['text':' SDPA has special kernels that handle nested tensors.','line_number':273,'multiline':False]['text':' Dispatch to the correct implementation here','line_number':274,'multiline':False]['text':' Handle flatten() here because it's CompositeImplicit.','line_number':278,'multiline':False]['text':' If created from narrow() check for lengths','line_number':360,'multiline':False]['text':' If jagged dim is not 1 it's not contiguous','line_number':364,'multiline':False]['text':' NYI: gradient for bias, need to reduce over ragged dim','line_number':410,'multiline':False]['text':' don't change layout','line_number':421,'multiline':False]['text':' NB: Purposefully keep offsets on the old device.','line_number':425,'multiline':False]['text':' TODO: Figure out how to handle this better','line_number':484,'multiline':False]['text':' keep_dim is required to keep it in jagged format','line_number':485,'multiline':False]['text':' Note that this specializes on the length of the offsets','line_number':534,'multiline':False]['text':' Account for collapsed jagged dim','line_number':569,'multiline':False]['text':' Convert any non-nested to nested','line_number':583,'multiline':False]['text':' Account for collapsed jagged dim','line_number':589,'multiline':False]['text':' BMM with equivalent ragged dims between the two inputs','line_number':612,'multiline':False]['text':' sum_dim_IntList can produce a NT or a T depending on whether the ragged dims','line_number':701,'multiline':False]['text':' are reduced away.','line_number':702,'multiline':False]['text':' Don't wrap because we reduced away the raggedness','line_number':715,'multiline':False]['text':' To support the SDPA API, inputs need to have the ragged idx transposed to dim 2','line_number':740,'multiline':False]['text':' instead of 1, although the internal Flash and mem-effn implementations will','line_number':741,'multiline':False]['text':' use the inputs with raggedness in dim 1.','line_number':742,'multiline':False]['text':' Ensure specified size still includes batch and ragged dims','line_number':776,'multiline':False]['text':' Ensure we're not trying to normalize over the ragged dim','line_number':796,'multiline':False]['text':' NB: mean expects dim as a single item list of ints for some reason','line_number':874,'multiline':False]['text':' guaranteed this is non-empty if we got here','line_number':886,'multiline':False]['text':' guaranteed this is non-empty if we got here','line_number':920,'multiline':False]