['text':' Ideally we would parameterize `DataLoader` by the return type of `collate_fn`, but there is currently no way to have that','line_number':51,'multiline':False]['text':' type parameter set to a default value if the user doesn't pass in a custom 'collate_fn'.','line_number':52,'multiline':False]['text':' See https://github.com/python/mypy/issues/3737.','line_number':53,'multiline':False]['text':' These functions used to be defined in this file. However, it was moved to','line_number':57,'multiline':False]['text':' _utils/collate.py. Although it is rather hard to access this from user land','line_number':58,'multiline':False]['text':' (one has to explicitly directly `import torch.utils.data.dataloader`), there','line_number':59,'multiline':False]['text':' probably is user code out there using it. This aliasing maintains BC in this','line_number':60,'multiline':False]['text':' aspect.','line_number':61,'multiline':False]['text':' To distribute elements across distributed process evenly, we should shard data on distributed','line_number':107,'multiline':False]['text':' processes first then shard on worker processes','line_number':108,'multiline':False]['text':' For BC, use default SHARDING_PRIORITIES','line_number':111,'multiline':False]['text':' Adds forward compatibilities so classic DataLoader can work with DataPipes:','line_number':265,'multiline':False]['text':'   _DataPipeSerializationWrapper container makes it easier to serialize without redefining pickler','line_number':266,'multiline':False]['text':' Arg-check dataset related before checking samplers because we want to','line_number':272,'multiline':False]['text':' tell users that iterable-style datasets are incompatible with custom','line_number':273,'multiline':False]['text':' samplers first, so that they don't learn that this combo doesn't work','line_number':274,'multiline':False]['text':' after spending time fixing the custom sampler errors.','line_number':275,'multiline':False]['text':' NOTE [ Custom Samplers and IterableDataset ]','line_number':278,'multiline':False]['text':'','line_number':279,'multiline':False]['text':' `IterableDataset` does not support custom `batch_sampler` or','line_number':280,'multiline':False]['text':' `sampler` since the key is irrelevant (unless we support','line_number':281,'multiline':False]['text':' generator-style dataset one day...).','line_number':282,'multiline':False]['text':'','line_number':283,'multiline':False]['text':' For `sampler`, we always create a dummy sampler. This is an','line_number':284,'multiline':False]['text':' infinite sampler even when the dataset may have an implemented','line_number':285,'multiline':False]['text':' finite `__len__` because in multi-process data loading, naive','line_number':286,'multiline':False]['text':' settings will return duplicated data (which may be desired), and','line_number':287,'multiline':False]['text':' thus using a sampler with length matching that of dataset will','line_number':288,'multiline':False]['text':' cause data lost (you may have duplicates of the first couple','line_number':289,'multiline':False]['text':' batches, but never see anything afterwards). Therefore,','line_number':290,'multiline':False]['text':' `Iterabledataset` always uses an infinite sampler, an instance of','line_number':291,'multiline':False]['text':' `_InfiniteConstantSampler` defined above.','line_number':292,'multiline':False]['text':'','line_number':293,'multiline':False]['text':' A custom `batch_sampler` essentially only controls the batch size.','line_number':294,'multiline':False]['text':' However, it is unclear how useful it would be since an iterable-style','line_number':295,'multiline':False]['text':' dataset can handle that within itself. Moreover, it is pointless','line_number':296,'multiline':False]['text':' in multi-process data loading as the assignment order of batches','line_number':297,'multiline':False]['text':' to workers is an implementation detail so users can not control','line_number':298,'multiline':False]['text':' how to batchify each worker's iterable. Thus, we disable this','line_number':299,'multiline':False]['text':' option. If this turns out to be useful in future, we can re-enable','line_number':300,'multiline':False]['text':' this, and support custom samplers that specify the assignments to','line_number':301,'multiline':False]['text':' specific workers.','line_number':302,'multiline':False]['text':' We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.','line_number':306,'multiline':False]['text':' See NOTE [ Custom Samplers and IterableDataset ]','line_number':312,'multiline':False]['text':' See NOTE [ Custom Samplers and IterableDataset ]','line_number':316,'multiline':False]['text':' auto_collation with custom batch_sampler','line_number':331,'multiline':False]['text':' no auto_collation','line_number':339,'multiline':False]['text':' give default samplers','line_number':344,'multiline':False]['text':' See NOTE [ Custom Samplers and IterableDataset ]','line_number':346,'multiline':False]['text':' map-style','line_number':348,'multiline':False]['text':' type: ignore[arg-type]','line_number':350,'multiline':False]['text':' type: ignore[arg-type]','line_number':352,'multiline':False]['text':' auto_collation without custom batch_sampler','line_number':355,'multiline':False]['text':' See NOTE [ IterableDataset and __len__ ]','line_number':374,'multiline':False]['text':' type: ignore[attr-defined]','line_number':380,'multiline':False]['text':' We quote '_BaseDataLoaderIter' since it isn't defined yet and the definition can't be moved up','line_number':424,'multiline':False]['text':' since '_BaseDataLoaderIter' references 'DataLoader'.','line_number':425,'multiline':False]['text':' When using a single worker the returned iterator should be','line_number':427,'multiline':False]['text':' created everytime to avoid resetting its state','line_number':428,'multiline':False]['text':' However, in the case of a multiple workers iterator','line_number':429,'multiline':False]['text':' the iterator is only created once in the lifetime of the','line_number':430,'multiline':False]['text':' DataLoader object so that workers can be reused','line_number':431,'multiline':False]['text':' The actual sampler used for generating indices for `_DatasetFetcher`','line_number':447,'multiline':False]['text':' (see _utils/fetch.py) to read data at each time. This would be','line_number':448,'multiline':False]['text':' `.batch_sampler` if in auto-collation mode, and `.sampler` otherwise.','line_number':449,'multiline':False]['text':' We can't change `.sampler` and `.batch_sampler` attributes for BC','line_number':450,'multiline':False]['text':' reasons.','line_number':451,'multiline':False]['text':' NOTE [ IterableDataset and __len__ ]','line_number':459,'multiline':False]['text':'','line_number':460,'multiline':False]['text':' For `IterableDataset`, `__len__` could be inaccurate when one naively','line_number':461,'multiline':False]['text':' does multi-processing data loading, since the samples will be duplicated.','line_number':462,'multiline':False]['text':' However, no real use case should be actually using that behavior, so','line_number':463,'multiline':False]['text':' it should count as a user error. We should generally trust user','line_number':464,'multiline':False]['text':' code to do the proper thing (e.g., configure each replica differently','line_number':465,'multiline':False]['text':' in `__iter__`), and give us the correct `__len__` if they choose to','line_number':466,'multiline':False]['text':' implement it (this will still throw if the dataset does not implement','line_number':467,'multiline':False]['text':' a `__len__`).','line_number':468,'multiline':False]['text':'','line_number':469,'multiline':False]['text':' To provide a further warning, we track if `__len__` was called on the','line_number':470,'multiline':False]['text':' `DataLoader`, save the returned value in `self._len_called`, and warn','line_number':471,'multiline':False]['text':' if the iterator ends up yielding more than this number of samples.','line_number':472,'multiline':False]['text':' Cannot statically verify that dataset is Sized','line_number':474,'multiline':False]['text':' type: ignore[assignment, arg-type]','line_number':475,'multiline':False]['text':' IterableDataset doesn't allow custom sampler or batch_sampler','line_number':476,'multiline':False]['text':' This function check whether the dataloader's worker number is rational based on','line_number':487,'multiline':False]['text':' current system's resource. Current rule is that if the number of workers this','line_number':488,'multiline':False]['text':' Dataloader will create is bigger than the number of logical cpus that is allowed to','line_number':489,'multiline':False]['text':' use, than we will pop up a warning to let user pay attention.','line_number':490,'multiline':False]['text':'','line_number':491,'multiline':False]['text':' eg. If current system has 2 physical CPUs with 16 cores each. And each core support 2','line_number':492,'multiline':False]['text':'     threads, then the total logical cpus here is 2 * 16 * 2 = 64. Let's say current','line_number':493,'multiline':False]['text':'     DataLoader process can use half of them which is 32, then the rational max number of','line_number':494,'multiline':False]['text':'     worker that initiated from this process is 32.','line_number':495,'multiline':False]['text':'     Now, let's say the created DataLoader has num_works = 40, which is bigger than 32.','line_number':496,'multiline':False]['text':'     So the warning message is triggered to notify the user to lower the worker number if','line_number':497,'multiline':False]['text':'     necessary.','line_number':498,'multiline':False]['text':'','line_number':499,'multiline':False]['text':'','line_number':500,'multiline':False]['text':' [Note] Please note that this function repects `cpuset` only when os.sched_getaffinity is','line_number':501,'multiline':False]['text':'        available (available in most of Linux system, but not OSX and Windows).','line_number':502,'multiline':False]['text':'        When os.sched_getaffinity is not available, os.cpu_count() is called instead, but','line_number':503,'multiline':False]['text':'        it doesn't repect cpuset.','line_number':504,'multiline':False]['text':'        We don't take threading into account since each worker process is single threaded','line_number':505,'multiline':False]['text':'        at this time.','line_number':506,'multiline':False]['text':'','line_number':507,'multiline':False]['text':'        We don't set any threading flags (eg. OMP_NUM_THREADS, MKL_NUM_THREADS, etc)','line_number':508,'multiline':False]['text':'        other than `torch.set_num_threads` to 1 in the worker process, if the passing','line_number':509,'multiline':False]['text':'        in functions use 3rd party modules that rely on those threading flags to determine','line_number':510,'multiline':False]['text':'        how many thread to create (eg. numpy, etc), then it is caller's responsibility to','line_number':511,'multiline':False]['text':'        set those flags correctly.','line_number':512,'multiline':False]['text':' try to compute a suggested max number of worker based on system's resource','line_number':534,'multiline':False]['text':' os.cpu_count() could return Optional[int]','line_number':544,'multiline':False]['text':' get cpu count first and check None in order to satisfy mypy check','line_number':545,'multiline':False]['text':' for other backends, pin_memory_device need to set. if not set','line_number':585,'multiline':False]['text':' default behaviour is CUDA device. if pin_memory_device is selected','line_number':586,'multiline':False]['text':' and pin_memory is not set, the default behaviour false.','line_number':587,'multiline':False]['text':' may raise StopIteration','line_number':621,'multiline':False]['text':' TODO(https://github.com/pytorch/pytorch/issues/76750)','line_number':629,'multiline':False]['text':' type: ignore[call-arg]','line_number':630,'multiline':False]['text':' TODO: add limited pickling support for sharing an iterator','line_number':650,'multiline':False]['text':' across multiple threads for HOGWILD.','line_number':651,'multiline':False]['text':' Probably the best way to do this is by moving the sample pushing','line_number':652,'multiline':False]['text':' to a separate thread and then just sharing the data queue','line_number':653,'multiline':False]['text':' but signalling the end is tricky without a non-blocking API','line_number':654,'multiline':False]['text':' Adds forward compatibilities so classic DataLoader can work with DataPipes:','line_number':664,'multiline':False]['text':'   Taking care of distributed sharding','line_number':665,'multiline':False]['text':' For BC, use default SHARDING_PRIORITIES','line_number':667,'multiline':False]['text':' may raise StopIteration','line_number':674,'multiline':False]['text':' may raise StopIteration','line_number':675,'multiline':False]['text':' NOTE [ Data Loader Multiprocessing Shutdown Logic ]','line_number':684,'multiline':False]['text':'','line_number':685,'multiline':False]['text':' Preliminary:','line_number':686,'multiline':False]['text':'','line_number':687,'multiline':False]['text':' Our data model looks like this (queues are indicated with curly brackets):','line_number':688,'multiline':False]['text':'','line_number':689,'multiline':False]['text':'                main process                              ||','line_number':690,'multiline':False]['text':'                     |                                    ||','line_number':691,'multiline':False]['text':'               {index_queue}                              ||','line_number':692,'multiline':False]['text':'                     |                                    ||','line_number':693,'multiline':False]['text':'              worker processes                            ||     DATA','line_number':694,'multiline':False]['text':'                     |                                    ||','line_number':695,'multiline':False]['text':'            {worker_result_queue}                         ||     FLOW','line_number':696,'multiline':False]['text':'                     |                                    ||','line_number':697,'multiline':False]['text':'      pin_memory_thread of main process                   ||   DIRECTION','line_number':698,'multiline':False]['text':'                     |                                    ||','line_number':699,'multiline':False]['text':'               {data_queue}                               ||','line_number':700,'multiline':False]['text':'                     |                                    ||','line_number':701,'multiline':False]['text':'                data output                               \/','line_number':702,'multiline':False]['text':'','line_number':703,'multiline':False]['text':' P.S. `worker_result_queue` and `pin_memory_thread` part may be omitted if','line_number':704,'multiline':False]['text':'      `pin_memory=False`.','line_number':705,'multiline':False]['text':'','line_number':706,'multiline':False]['text':'','line_number':707,'multiline':False]['text':' Terminating multiprocessing logic requires very careful design. In','line_number':708,'multiline':False]['text':' particular, we need to make sure that','line_number':709,'multiline':False]['text':'','line_number':710,'multiline':False]['text':'   1. The iterator gracefully exits the workers when its last reference is','line_number':711,'multiline':False]['text':'      gone or it is depleted.','line_number':712,'multiline':False]['text':'','line_number':713,'multiline':False]['text':'      In this case, the workers should be gracefully exited because the','line_number':714,'multiline':False]['text':'      main process may still need to continue to run, and we want cleaning','line_number':715,'multiline':False]['text':'      up code in the workers to be executed (e.g., releasing GPU memory).','line_number':716,'multiline':False]['text':'      Naturally, we implement the shutdown logic in `__del__` of','line_number':717,'multiline':False]['text':'      DataLoaderIterator.','line_number':718,'multiline':False]['text':'','line_number':719,'multiline':False]['text':'      We delay the discussion on the logic in this case until later.','line_number':720,'multiline':False]['text':'','line_number':721,'multiline':False]['text':'   2. The iterator exits the workers when the loader process and/or worker','line_number':722,'multiline':False]['text':'      processes exits normally or with error.','line_number':723,'multiline':False]['text':'','line_number':724,'multiline':False]['text':'      We set all workers and `pin_memory_thread` to have `daemon=True`.','line_number':725,'multiline':False]['text':'','line_number':726,'multiline':False]['text':'      You may ask, why can't we make the workers non-daemonic, and','line_number':727,'multiline':False]['text':'      gracefully exit using the same logic as we have in `__del__` when the','line_number':728,'multiline':False]['text':'      iterator gets deleted (see 1 above)?','line_number':729,'multiline':False]['text':'','line_number':730,'multiline':False]['text':'      First of all, `__del__` is **not** guaranteed to be called when','line_number':731,'multiline':False]['text':'      interpreter exits. Even if it is called, by the time it executes,','line_number':732,'multiline':False]['text':'      many Python core library resources may already be freed, and even','line_number':733,'multiline':False]['text':'      simple things like acquiring an internal lock of a queue may hang.','line_number':734,'multiline':False]['text':'      Therefore, in this case, we actually need to prevent `__del__` from','line_number':735,'multiline':False]['text':'      being executed, and rely on the automatic termination of daemonic','line_number':736,'multiline':False]['text':'      children.','line_number':737,'multiline':False]['text':'','line_number':738,'multiline':False]['text':'      Thus, we register an `atexit` hook that sets a global flag','line_number':739,'multiline':False]['text':'      `_utils.python_exit_status`. Since `atexit` hooks are executed in the','line_number':740,'multiline':False]['text':'      reverse order of registration, we are guaranteed that this flag is','line_number':741,'multiline':False]['text':'      set before library resources we use are freed (which, at least in','line_number':742,'multiline':False]['text':'      CPython, is done via an `atexit` handler defined in','line_number':743,'multiline':False]['text':'      `multiprocessing/util.py`','line_number':744,'multiline':False]['text':'      https://github.com/python/cpython/blob/c606624af8d4cb3b4a052fb263bb983b3f87585b/Lib/multiprocessing/util.py#L320-L362','line_number':745,'multiline':False]['text':'      registered when an object requiring this mechanism is first','line_number':746,'multiline':False]['text':'      created, e.g., `mp.Queue`','line_number':747,'multiline':False]['text':'      https://github.com/python/cpython/blob/c606624af8d4cb3b4a052fb263bb983b3f87585b/Lib/multiprocessing/context.py#L100-L103','line_number':748,'multiline':False]['text':'      https://github.com/python/cpython/blob/c606624af8d4cb3b4a052fb263bb983b3f87585b/Lib/multiprocessing/queues.py#L29','line_number':749,'multiline':False]['text':'      )','line_number':750,'multiline':False]['text':'','line_number':751,'multiline':False]['text':'      So in `__del__`, we check if `_utils.python_exit_status` is set or','line_number':752,'multiline':False]['text':'      `None` (freed), and perform no-op if so.','line_number':753,'multiline':False]['text':'','line_number':754,'multiline':False]['text':'      However, simply letting library clean-up codes run can also be bad,','line_number':755,'multiline':False]['text':'      because such codes (i.e., `multiprocessing.util._exit_function()`)','line_number':756,'multiline':False]['text':'      include join putting threads for `mp.Queue`, which can be blocking.','line_number':757,'multiline':False]['text':'      Hence, the main process putting threads are called with','line_number':758,'multiline':False]['text':'      `cancel_join_thread` at creation.  See later section','line_number':759,'multiline':False]['text':'      [ 3b. A process won't hang when putting into a queue; ]','line_number':760,'multiline':False]['text':'      for more details.','line_number':761,'multiline':False]['text':'','line_number':762,'multiline':False]['text':'      Here are two example cases where library clean-up codes can run','line_number':763,'multiline':False]['text':'      before `__del__` is called:','line_number':764,'multiline':False]['text':'','line_number':765,'multiline':False]['text':'        1. If we hold onto a reference to the iterator, it more often','line_number':766,'multiline':False]['text':'           than not tries to do `multiprocessing` library cleaning before','line_number':767,'multiline':False]['text':'           clearing the alive referenced objects (https://github.com/pytorch/pytorch/issues/48666)','line_number':768,'multiline':False]['text':'           and thus prevents our cleaning-up code to run first.','line_number':769,'multiline':False]['text':'','line_number':770,'multiline':False]['text':'        2. A similar issue araises when a `DataLoader` is used in a subprocess.','line_number':771,'multiline':False]['text':'           When a process ends, it shuts the all its daemonic children','line_number':772,'multiline':False]['text':'           down with a SIGTERM (instead of joining them without a timeout).','line_number':773,'multiline':False]['text':'           Simiarly for threads, but by a different mechanism. This fact,','line_number':774,'multiline':False]['text':'           together with a few implementation details of multiprocessing, forces','line_number':775,'multiline':False]['text':'           us to make workers daemonic. All of our problems arise when a','line_number':776,'multiline':False]['text':'           DataLoader is used in a subprocess, and are caused by multiprocessing','line_number':777,'multiline':False]['text':'           code which looks more or less like this:','line_number':778,'multiline':False]['text':'','line_number':779,'multiline':False]['text':'               try:','line_number':780,'multiline':False]['text':'                   your_function_using_a_dataloader()','line_number':781,'multiline':False]['text':'               finally:','line_number':782,'multiline':False]['text':'                   multiprocessing.util._exit_function()','line_number':783,'multiline':False]['text':'','line_number':784,'multiline':False]['text':'           The joining/termination mentioned above happens inside','line_number':785,'multiline':False]['text':'           `_exit_function()`. Now, if `your_function_using_a_dataloader()`','line_number':786,'multiline':False]['text':'           throws, the stack trace stored in the exception will prevent the','line_number':787,'multiline':False]['text':'           frame which uses `DataLoaderIter` to be freed. If the frame has any','line_number':788,'multiline':False]['text':'           reference to the `DataLoaderIter` (e.g., in a method of the iter),','line_number':789,'multiline':False]['text':'           its  `__del__`, which starts the shutdown procedure, will not be','line_number':790,'multiline':False]['text':'           called. That, in turn, means that workers aren't notified. Attempting','line_number':791,'multiline':False]['text':'           to join in `_exit_function` will then result in a hang.','line_number':792,'multiline':False]['text':'','line_number':793,'multiline':False]['text':'           For context, `_exit_function` is also registered as an `atexit` call.','line_number':794,'multiline':False]['text':'           So it is unclear to me (@ssnl) why this is needed in a finally block.','line_number':795,'multiline':False]['text':'           The code dates back to 2008 and there is no comment on the original','line_number':796,'multiline':False]['text':'           PEP 371 or patch https://bugs.python.org/issue3050 (containing both','line_number':797,'multiline':False]['text':'           the finally block and the `atexit` registration) that explains this.','line_number':798,'multiline':False]['text':'','line_number':799,'multiline':False]['text':'','line_number':800,'multiline':False]['text':'      Finally, another choice is to just shutdown workers with logic in 1','line_number':801,'multiline':False]['text':'      above whenever we see an error in `next`. This isn't ideal because','line_number':802,'multiline':False]['text':'        a. It prevents users from using try-catch to resume data loading.','line_number':803,'multiline':False]['text':'        b. It doesn't prevent hanging if users have references to the','line_number':804,'multiline':False]['text':'           iterator.','line_number':805,'multiline':False]['text':'','line_number':806,'multiline':False]['text':'   3. All processes exit if any of them die unexpectedly by fatal signals.','line_number':807,'multiline':False]['text':'','line_number':808,'multiline':False]['text':'      As shown above, the workers are set as daemonic children of the main','line_number':809,'multiline':False]['text':'      process. However, automatic cleaning-up of such child processes only','line_number':810,'multiline':False]['text':'      happens if the parent process exits gracefully (e.g., not via fatal','line_number':811,'multiline':False]['text':'      signals like SIGKILL). So we must ensure that each process will exit','line_number':812,'multiline':False]['text':'      even the process that should send/receive data to/from it were','line_number':813,'multiline':False]['text':'      killed, i.e.,','line_number':814,'multiline':False]['text':'','line_number':815,'multiline':False]['text':'        a. A process won't hang when getting from a queue.','line_number':816,'multiline':False]['text':'','line_number':817,'multiline':False]['text':'           Even with carefully designed data dependencies (i.e., a `put()`','line_number':818,'multiline':False]['text':'           always corresponding to a `get()`), hanging on `get()` can still','line_number':819,'multiline':False]['text':'           happen when data in queue is corrupted (e.g., due to','line_number':820,'multiline':False]['text':'           `cancel_join_thread` or unexpected exit).','line_number':821,'multiline':False]['text':'','line_number':822,'multiline':False]['text':'           For child exit, we set a timeout whenever we try to get data','line_number':823,'multiline':False]['text':'           from `data_queue`, and check the workers' status on each timeout','line_number':824,'multiline':False]['text':'           and error.','line_number':825,'multiline':False]['text':'           See `_DataLoaderiter._get_batch()` and','line_number':826,'multiline':False]['text':'           `_DataLoaderiter._try_get_data()` for details.','line_number':827,'multiline':False]['text':'','line_number':828,'multiline':False]['text':'           Additionally, for child exit on non-Windows platforms, we also','line_number':829,'multiline':False]['text':'           register a SIGCHLD handler (which is supported on Windows) on','line_number':830,'multiline':False]['text':'           the main process, which checks if any of the workers fail in the','line_number':831,'multiline':False]['text':'           (Python) handler. This is more efficient and faster in detecting','line_number':832,'multiline':False]['text':'           worker failures, compared to only using the above mechanism.','line_number':833,'multiline':False]['text':'           See `DataLoader.cpp` and `_utils/signal_handling.py` for details.','line_number':834,'multiline':False]['text':'','line_number':835,'multiline':False]['text':'           For `.get()` calls where the sender(s) is not the workers, we','line_number':836,'multiline':False]['text':'           guard them with timeouts, and check the status of the sender','line_number':837,'multiline':False]['text':'           when timeout happens:','line_number':838,'multiline':False]['text':'             + in the workers, the `_utils.worker.ManagerWatchdog` class','line_number':839,'multiline':False]['text':'               checks the status of the main process.','line_number':840,'multiline':False]['text':'             + if `pin_memory=True`, when getting from `pin_memory_thread`,','line_number':841,'multiline':False]['text':'               check `pin_memory_thread` status periodically until `.get()`','line_number':842,'multiline':False]['text':'               returns or see that `pin_memory_thread` died.','line_number':843,'multiline':False]['text':'','line_number':844,'multiline':False]['text':'        b. A process won't hang when putting into a queue;','line_number':845,'multiline':False]['text':'','line_number':846,'multiline':False]['text':'           We use `mp.Queue` which has a separate background thread to put','line_number':847,'multiline':False]['text':'           objects from an unbounded buffer array. The background thread is','line_number':848,'multiline':False]['text':'           daemonic and usually automatically joined when the process','line_number':849,'multiline':False]['text':'           *exits*.','line_number':850,'multiline':False]['text':'','line_number':851,'multiline':False]['text':'           In case that the receiver has ended abruptly while','line_number':852,'multiline':False]['text':'           reading from the pipe, the join will hang forever.  The usual','line_number':853,'multiline':False]['text':'           solution for this in Python is calling  `q.cancel_join_thread`,','line_number':854,'multiline':False]['text':'           which prevents automatically joining it when finalizing','line_number':855,'multiline':False]['text':'           (exiting).','line_number':856,'multiline':False]['text':'','line_number':857,'multiline':False]['text':'           Nonetheless, `cancel_join_thread` must only be called when the','line_number':858,'multiline':False]['text':'           queue is **not** going to be read from or write into by another','line_number':859,'multiline':False]['text':'           process, because it may hold onto a lock or leave corrupted data','line_number':860,'multiline':False]['text':'           in the queue, leading other readers/writers to hang.','line_number':861,'multiline':False]['text':'','line_number':862,'multiline':False]['text':'           Hence,','line_number':863,'multiline':False]['text':'             + For worker processes, we only do so (for their output','line_number':864,'multiline':False]['text':'               queues, i.e., `worker_result_queue`) before exiting.','line_number':865,'multiline':False]['text':'             + For `pin_memory_thread`, its output queue `data_queue` is a','line_number':866,'multiline':False]['text':'               `queue.Queue` that does blocking `put` if the queue is full.','line_number':867,'multiline':False]['text':'               So there is no above problem, but as a result, in','line_number':868,'multiline':False]['text':'               `_pin_memory_loop`, we do need to  wrap the `put` in a loop','line_number':869,'multiline':False]['text':'               that breaks not only upon success, but also when the main','line_number':870,'multiline':False]['text':'               process stops reading, i.e., is shutting down.','line_number':871,'multiline':False]['text':'             + For loader process, we `cancel_join_thread()` for all','line_number':872,'multiline':False]['text':'               `_index_queues` because the whole purpose of workers and','line_number':873,'multiline':False]['text':'               `pin_memory_thread` is to serve the loader process.  If','line_number':874,'multiline':False]['text':'               loader process is already exiting, we don't really care if','line_number':875,'multiline':False]['text':'               the queues are corrupted.','line_number':876,'multiline':False]['text':'','line_number':877,'multiline':False]['text':'','line_number':878,'multiline':False]['text':' Now let's get back to 1:','line_number':879,'multiline':False]['text':'   how we gracefully exit the workers when the last reference to the','line_number':880,'multiline':False]['text':'   iterator is gone.','line_number':881,'multiline':False]['text':'','line_number':882,'multiline':False]['text':' To achieve this, we implement the following logic along with the design','line_number':883,'multiline':False]['text':' choices mentioned above:','line_number':884,'multiline':False]['text':'','line_number':885,'multiline':False]['text':' `workers_done_event`:','line_number':886,'multiline':False]['text':'   A `multiprocessing.Event` shared among the main process and all worker','line_number':887,'multiline':False]['text':'   processes. This is used to signal the workers that the iterator is','line_number':888,'multiline':False]['text':'   shutting down. After it is set, they will not send processed data to','line_number':889,'multiline':False]['text':'   queues anymore, and only wait for the final `None` before exiting.','line_number':890,'multiline':False]['text':'   `done_event` isn't strictly needed. I.e., we can just check for `None`','line_number':891,'multiline':False]['text':'   from the input queue, but it allows us to skip wasting resources','line_number':892,'multiline':False]['text':'   processing data if we are already shutting down.','line_number':893,'multiline':False]['text':'','line_number':894,'multiline':False]['text':' `pin_memory_thread_done_event`:','line_number':895,'multiline':False]['text':'   A `threading.Event` for a similar purpose to that of','line_number':896,'multiline':False]['text':'   `workers_done_event`, but is for the `pin_memory_thread`. The reason','line_number':897,'multiline':False]['text':'   that separate events are needed is that `pin_memory_thread` reads from','line_number':898,'multiline':False]['text':'   the output queue of the workers. But the workers, upon seeing that','line_number':899,'multiline':False]['text':'   `workers_done_event` is set, only wants to see the final `None`, and is','line_number':900,'multiline':False]['text':'   not required to flush all data in the output queue (e.g., it may call','line_number':901,'multiline':False]['text':'   `cancel_join_thread` on that queue if its `IterableDataset` iterator','line_number':902,'multiline':False]['text':'   happens to exhaust coincidentally, which is out of the control of the','line_number':903,'multiline':False]['text':'   main process). Thus, since we will exit `pin_memory_thread` before the','line_number':904,'multiline':False]['text':'   workers (see below), two separete events are used.','line_number':905,'multiline':False]['text':'','line_number':906,'multiline':False]['text':' NOTE: In short, the protocol is that the main process will set these','line_number':907,'multiline':False]['text':'       `done_event`s and then the corresponding processes/threads a `None`,','line_number':908,'multiline':False]['text':'       and that they may exit at any time after receiving the `None`.','line_number':909,'multiline':False]['text':'','line_number':910,'multiline':False]['text':' NOTE: Using `None` as the final signal is valid, since normal data will','line_number':911,'multiline':False]['text':'       always be a 2-tuple with the 1st element being the index of the data','line_number':912,'multiline':False]['text':'       transferred (different from dataset index/key), and the 2nd being','line_number':913,'multiline':False]['text':'       either the dataset key or the data sample (depending on which part','line_number':914,'multiline':False]['text':'       of the data model the queue is at).','line_number':915,'multiline':False]['text':'','line_number':916,'multiline':False]['text':' [ worker processes ]','line_number':917,'multiline':False]['text':'   While loader process is alive:','line_number':918,'multiline':False]['text':'     Get from `index_queue`.','line_number':919,'multiline':False]['text':'       If get anything else,','line_number':920,'multiline':False]['text':'          Check `workers_done_event`.','line_number':921,'multiline':False]['text':'            If set, continue to next iteration','line_number':922,'multiline':False]['text':'                    i.e., keep getting until see the `None`, then exit.','line_number':923,'multiline':False]['text':'            Otherwise, process data:','line_number':924,'multiline':False]['text':'                If is fetching from an `IterableDataset` and the iterator','line_number':925,'multiline':False]['text':'                    is exhausted, send an `_IterableDatasetStopIteration`','line_number':926,'multiline':False]['text':'                    object to signal iteration end. The main process, upon','line_number':927,'multiline':False]['text':'                    receiving such an object, will send `None` to this','line_number':928,'multiline':False]['text':'                    worker and not use the corresponding `index_queue`','line_number':929,'multiline':False]['text':'                    anymore.','line_number':930,'multiline':False]['text':'       If timed out,','line_number':931,'multiline':False]['text':'          No matter `workers_done_event` is set (still need to see `None`)','line_number':932,'multiline':False]['text':'          or not, must continue to next iteration.','line_number':933,'multiline':False]['text':'   (outside loop)','line_number':934,'multiline':False]['text':'   If `workers_done_event` is set,  (this can be False with `IterableDataset`)','line_number':935,'multiline':False]['text':'     `data_queue.cancel_join_thread()`.  (Everything is ending here:','line_number':936,'multiline':False]['text':'                                          main process won't read from it;','line_number':937,'multiline':False]['text':'                                          other workers will also call','line_number':938,'multiline':False]['text':'                                          `cancel_join_thread`.)','line_number':939,'multiline':False]['text':'','line_number':940,'multiline':False]['text':' [ pin_memory_thread ]','line_number':941,'multiline':False]['text':'   # No need to check main thread. If this thread is alive, the main loader','line_number':942,'multiline':False]['text':'   # thread must be alive, because this thread is set as daemonic.','line_number':943,'multiline':False]['text':'   While `pin_memory_thread_done_event` is not set:','line_number':944,'multiline':False]['text':'     Get from `worker_result_queue`.','line_number':945,'multiline':False]['text':'       If timed out, continue to get in the next iteration.','line_number':946,'multiline':False]['text':'       Otherwise, process data.','line_number':947,'multiline':False]['text':'       While `pin_memory_thread_done_event` is not set:','line_number':948,'multiline':False]['text':'         Put processed data to `data_queue` (a `queue.Queue` with blocking put)','line_number':949,'multiline':False]['text':'         If timed out, continue to put in the next iteration.','line_number':950,'multiline':False]['text':'         Otherwise, break, i.e., continuing to the out loop.','line_number':951,'multiline':False]['text':'','line_number':952,'multiline':False]['text':'   NOTE: we don't check the status of the main thread because','line_number':953,'multiline':False]['text':'           1. if the process is killed by fatal signal, `pin_memory_thread`','line_number':954,'multiline':False]['text':'              ends.','line_number':955,'multiline':False]['text':'           2. in other cases, either the cleaning-up in __del__ or the','line_number':956,'multiline':False]['text':'              automatic exit of daemonic thread will take care of it.','line_number':957,'multiline':False]['text':'              This won't busy-wait either because `.get(timeout)` does not','line_number':958,'multiline':False]['text':'              busy-wait.','line_number':959,'multiline':False]['text':'','line_number':960,'multiline':False]['text':' [ main process ]','line_number':961,'multiline':False]['text':'   In the DataLoader Iter's `__del__`','line_number':962,'multiline':False]['text':'     b. Exit `pin_memory_thread`','line_number':963,'multiline':False]['text':'          i.   Set `pin_memory_thread_done_event`.','line_number':964,'multiline':False]['text':'          ii   Put `None` in `worker_result_queue`.','line_number':965,'multiline':False]['text':'          iii. Join the `pin_memory_thread`.','line_number':966,'multiline':False]['text':'          iv.  `worker_result_queue.cancel_join_thread()`.','line_number':967,'multiline':False]['text':'','line_number':968,'multiline':False]['text':'     c. Exit the workers.','line_number':969,'multiline':False]['text':'          i.   Set `workers_done_event`.','line_number':970,'multiline':False]['text':'          ii.  Put `None` in each worker's `index_queue`.','line_number':971,'multiline':False]['text':'          iii. Join the workers.','line_number':972,'multiline':False]['text':'          iv.  Call `.cancel_join_thread()` on each worker's `index_queue`.','line_number':973,'multiline':False]['text':'','line_number':974,'multiline':False]['text':'        NOTE: (c) is better placed after (b) because it may leave corrupted','line_number':975,'multiline':False]['text':'              data in `worker_result_queue`, which `pin_memory_thread`','line_number':976,'multiline':False]['text':'              reads from, in which case the `pin_memory_thread` can only','line_number':977,'multiline':False]['text':'              happen at timing out, which is slow. Nonetheless, same thing','line_number':978,'multiline':False]['text':'              happens if a worker is killed by signal at unfortunate times,','line_number':979,'multiline':False]['text':'              but in other cases, we are better off having a non-corrupted','line_number':980,'multiline':False]['text':'              `worker_result_queue` for `pin_memory_thread`.','line_number':981,'multiline':False]['text':'','line_number':982,'multiline':False]['text':'   NOTE: If `pin_memory=False`, there is no `pin_memory_thread` and (b)','line_number':983,'multiline':False]['text':'         can be omitted','line_number':984,'multiline':False]['text':'','line_number':985,'multiline':False]['text':' NB: `done_event`s isn't strictly needed. E.g., we can just check for','line_number':986,'multiline':False]['text':'     `None` from `index_queue`, but it allows us to skip wasting resources','line_number':987,'multiline':False]['text':'     processing indices already in `index_queue` if we are already shutting','line_number':988,'multiline':False]['text':'     down.','line_number':989,'multiline':False]['text':' Adds forward compatibilities so classic DataLoader can work with DataPipes:','line_number':1006,'multiline':False]['text':'   Additional worker init function will take care of sharding in MP and Distributed','line_number':1007,'multiline':False]['text':' No certainty which module multiprocessing_context is','line_number':1012,'multiline':False]['text':' type: ignore[var-annotated]','line_number':1013,'multiline':False]['text':' No certainty which module multiprocessing_context is','line_number':1021,'multiline':False]['text':' type: ignore[var-annotated]','line_number':1022,'multiline':False]['text':' Need to `cancel_join_thread` here!','line_number':1023,'multiline':False]['text':' See sections (2) and (3b) above.','line_number':1024,'multiline':False]['text':' NB: Process.start() actually take some time as it needs to','line_number':1034,'multiline':False]['text':'     start a process and pass the arguments over via a pipe.','line_number':1035,'multiline':False]['text':'     Therefore, we only add a worker to self._workers list after','line_number':1036,'multiline':False]['text':'     it started, so that we do not call .join() if program dies','line_number':1037,'multiline':False]['text':'     before it starts, and __del__ tries to join but will get:','line_number':1038,'multiline':False]['text':'     AssertionError: can only join a started process.','line_number':1039,'multiline':False]['text':' Queue is not type-annotated','line_number':1047,'multiline':False]['text':' type: ignore[var-annotated]','line_number':1048,'multiline':False]['text':' type: ignore[attr-defined]','line_number':1050,'multiline':False]['text':' choose cuda for default','line_number':1055,'multiline':False]['text':' Similar to workers (see comment above), we only register','line_number':1063,'multiline':False]['text':' pin_memory_thread once it is started.','line_number':1064,'multiline':False]['text':' type: ignore[assignment]','line_number':1067,'multiline':False]['text':' In some rare cases, persistent workers (daemonic processes)','line_number':1069,'multiline':False]['text':' would be terminated before `__del__` of iterator is invoked','line_number':1070,'multiline':False]['text':' when main process exits','line_number':1071,'multiline':False]['text':' It would cause failure when pin_memory_thread tries to read','line_number':1072,'multiline':False]['text':' corrupted data from worker_result_queue','line_number':1073,'multiline':False]['text':' atexit is used to shutdown thread and child processes in the','line_number':1074,'multiline':False]['text':' right sequence before main process exits','line_number':1075,'multiline':False]['text':' .pid can be None only before process is spawned (not the case, so ignore)','line_number':1081,'multiline':False]['text':' type: ignore[misc]','line_number':1082,'multiline':False]['text':' idx of the next task to be sent to workers','line_number':1089,'multiline':False]['text':' idx of the next task to be returned in __next__','line_number':1090,'multiline':False]['text':' information about data not yet yielded, i.e., tasks w/ indices in range [rcvd_idx, send_idx).','line_number':1091,'multiline':False]['text':' map: task idx => - (worker_id,)        if data isn't fetched (outstanding)','line_number':1092,'multiline':False]['text':'                  \ (worker_id, data)   if data is already fetched (out-of-order)','line_number':1093,'multiline':False]['text':' always equal to count(v for v in task_info.values() if len(v) == 1)','line_number':1095,'multiline':False]['text':' A list of booleans representing whether each worker still has work to','line_number':1096,'multiline':False]['text':' do, i.e., not having exhausted its iterable dataset object. It always','line_number':1097,'multiline':False]['text':' contains all `True`s if not using an iterable-style dataset','line_number':1098,'multiline':False]['text':' (i.e., if kind != Iterable).','line_number':1099,'multiline':False]['text':' Not that this indicates that a worker still has work to do *for this epoch*.','line_number':1100,'multiline':False]['text':' It does not mean that a worker is dead. In case of `_persistent_workers`,','line_number':1101,'multiline':False]['text':' the worker will be reset to available in the next epoch.','line_number':1102,'multiline':False]['text':' Reset the worker queue cycle so it resumes next epoch at worker 0','line_number':1104,'multiline':False]['text':' We resume the prefetching in case it was enabled','line_number':1106,'multiline':False]['text':' prime the prefetch loop','line_number':1116,'multiline':False]['text':' Tries to fetch data from `self._data_queue` once for a given timeout.','line_number':1121,'multiline':False]['text':' This can also be used as inner loop of fetching without timeout, with','line_number':1122,'multiline':False]['text':' the sender status as the loop condition.','line_number':1123,'multiline':False]['text':'','line_number':1124,'multiline':False]['text':' This raises a `RuntimeError` if any worker died expectedly. This error','line_number':1125,'multiline':False]['text':' can come from either the SIGCHLD handler in `_utils/signal_handling.py`','line_number':1126,'multiline':False]['text':' (only for non-Windows platforms), or the manual check below on errors','line_number':1127,'multiline':False]['text':' and timeouts.','line_number':1128,'multiline':False]['text':'','line_number':1129,'multiline':False]['text':' Returns a 2-tuple:','line_number':1130,'multiline':False]['text':'   (bool: whether successfully get data, any: data if successful else None)','line_number':1131,'multiline':False]['text':' At timeout and error, we manually check whether any worker has','line_number':1136,'multiline':False]['text':' failed. Note that this is the only mechanism for Windows to detect','line_number':1137,'multiline':False]['text':' worker failures.','line_number':1138,'multiline':False]['text':' Raise an exception if we are this close to the FDs limit.','line_number':1152,'multiline':False]['text':' Apparently, trying to open only one file is not a sufficient','line_number':1153,'multiline':False]['text':' test.','line_number':1154,'multiline':False]['text':' See NOTE [ DataLoader on Linux and open files limit ]','line_number':1155,'multiline':False]['text':' NOTE [ DataLoader on Linux and open files limit ]','line_number':1169,'multiline':False]['text':'','line_number':1170,'multiline':False]['text':' On Linux when DataLoader is used with multiprocessing we pass the data between','line_number':1171,'multiline':False]['text':' the root process and the workers through SHM files. We remove those files from','line_number':1172,'multiline':False]['text':' the filesystem as soon as they are created and keep them alive by','line_number':1173,'multiline':False]['text':' passing around their file descriptors through AF_UNIX sockets. (See','line_number':1174,'multiline':False]['text':' docs/source/multiprocessing.rst and 'Multiprocessing Technical Notes` in','line_number':1175,'multiline':False]['text':' the wiki (https://github.com/pytorch/pytorch/wiki).)','line_number':1176,'multiline':False]['text':'','line_number':1177,'multiline':False]['text':' This sometimes leads us to exceeding the open files limit. When that happens,','line_number':1178,'multiline':False]['text':' and the offending file descriptor is coming over a socket, the `socket` Python','line_number':1179,'multiline':False]['text':' package silently strips the file descriptor from the message, setting only the','line_number':1180,'multiline':False]['text':' `MSG_CTRUNC` flag (which might be a bit misleading since the manpage says that','line_number':1181,'multiline':False]['text':' it _indicates that some control data were discarded due to lack of space in','line_number':1182,'multiline':False]['text':' the buffer for ancillary data_). This might reflect the C implementation of','line_number':1183,'multiline':False]['text':' AF_UNIX sockets.','line_number':1184,'multiline':False]['text':'','line_number':1185,'multiline':False]['text':' This behaviour can be reproduced with the script and instructions at the','line_number':1186,'multiline':False]['text':' bottom of this note.','line_number':1187,'multiline':False]['text':'','line_number':1188,'multiline':False]['text':' When that happens, the standard Python `multiprocessing` (and not','line_number':1189,'multiline':False]['text':' `torch.multiprocessing`) raises a `RuntimeError: received 0 items of ancdata`','line_number':1190,'multiline':False]['text':'','line_number':1191,'multiline':False]['text':' Sometimes, instead of the FD being stripped, you may get an `OSError:','line_number':1192,'multiline':False]['text':' Too many open files`, both in the script below and in DataLoader. However,','line_number':1193,'multiline':False]['text':' this is rare and seems to be nondeterministic.','line_number':1194,'multiline':False]['text':'','line_number':1195,'multiline':False]['text':'','line_number':1196,'multiline':False]['text':'   #!/usr/bin/env python3','line_number':1197,'multiline':False]['text':'   import sys','line_number':1198,'multiline':False]['text':'   import socket','line_number':1199,'multiline':False]['text':'   import os','line_number':1200,'multiline':False]['text':'   import array','line_number':1201,'multiline':False]['text':'   import shutil','line_number':1202,'multiline':False]['text':'   import socket','line_number':1203,'multiline':False]['text':'','line_number':1204,'multiline':False]['text':'','line_number':1205,'multiline':False]['text':'   if len(sys.argv) != 4:','line_number':1206,'multiline':False]['text':'       print("Usage: ", sys.argv[0], " tmp_dirname iteration (send|recv)")','line_number':1207,'multiline':False]['text':'       sys.exit(1)','line_number':1208,'multiline':False]['text':'','line_number':1209,'multiline':False]['text':'   if __name__ == '__main__':','line_number':1210,'multiline':False]['text':'       dirname = sys.argv[1]','line_number':1211,'multiline':False]['text':'       sock_path = dirname + "/sock"','line_number':1212,'multiline':False]['text':'       iterations = int(sys.argv[2])','line_number':1213,'multiline':False]['text':'       def dummy_path(i):','line_number':1214,'multiline':False]['text':'           return dirname + "/" + str(i) + ".dummy"','line_number':1215,'multiline':False]['text':'','line_number':1216,'multiline':False]['text':'','line_number':1217,'multiline':False]['text':'       if sys.argv[3] == 'send':','line_number':1218,'multiline':False]['text':'           while not os.path.exists(sock_path):','line_number':1219,'multiline':False]['text':'               pass','line_number':1220,'multiline':False]['text':'           client = socket.socket(socket.AF_UNIX, socket.SOCK_DGRAM)','line_number':1221,'multiline':False]['text':'           client.connect(sock_path)','line_number':1222,'multiline':False]['text':'           for i in range(iterations):','line_number':1223,'multiline':False]['text':'               fd = os.open(dummy_path(i), os.O_WRONLY | os.O_CREAT)','line_number':1224,'multiline':False]['text':'               ancdata = array.array('i', [fd])','line_number':1225,'multiline':False]['text':'               msg = bytes([i % 256])','line_number':1226,'multiline':False]['text':'               print("Sending fd ", fd, " (iteration #", i, ")")','line_number':1227,'multiline':False]['text':'               client.sendmsg([msg], [(socket.SOL_SOCKET, socket.SCM_RIGHTS, ancdata)])','line_number':1228,'multiline':False]['text':'','line_number':1229,'multiline':False]['text':'','line_number':1230,'multiline':False]['text':'       else:','line_number':1231,'multiline':False]['text':'           assert sys.argv[3] == 'recv'','line_number':1232,'multiline':False]['text':'','line_number':1233,'multiline':False]['text':'           if os.path.exists(dirname):','line_number':1234,'multiline':False]['text':'               raise Exception("Directory exists")','line_number':1235,'multiline':False]['text':'','line_number':1236,'multiline':False]['text':'           os.mkdir(dirname)','line_number':1237,'multiline':False]['text':'','line_number':1238,'multiline':False]['text':'           print("Opening socket...")','line_number':1239,'multiline':False]['text':'           server = socket.socket(socket.AF_UNIX, socket.SOCK_DGRAM)','line_number':1240,'multiline':False]['text':'           server.bind(sock_path)','line_number':1241,'multiline':False]['text':'','line_number':1242,'multiline':False]['text':'           print("Listening...")','line_number':1243,'multiline':False]['text':'           for i in range(iterations):','line_number':1244,'multiline':False]['text':'               a = array.array('i')','line_number':1245,'multiline':False]['text':'               msg, ancdata, flags, addr = server.recvmsg(1, socket.CMSG_SPACE(a.itemsize))','line_number':1246,'multiline':False]['text':'               assert(len(ancdata) == 1)','line_number':1247,'multiline':False]['text':'               cmsg_level, cmsg_type, cmsg_data = ancdata[0]','line_number':1248,'multiline':False]['text':'               a.frombytes(cmsg_data)','line_number':1249,'multiline':False]['text':'               print("Received fd ", a[0], " (iteration #", i, ")")','line_number':1250,'multiline':False]['text':'','line_number':1251,'multiline':False]['text':'           shutil.rmtree(dirname)','line_number':1252,'multiline':False]['text':'','line_number':1253,'multiline':False]['text':' Steps to reproduce:','line_number':1254,'multiline':False]['text':'','line_number':1255,'multiline':False]['text':' 1. Run two shells and set lower file descriptor limit in the receiving one:','line_number':1256,'multiline':False]['text':' (shell1) ulimit -n 1020','line_number':1257,'multiline':False]['text':' (shell2) ulimit -n 1022','line_number':1258,'multiline':False]['text':'','line_number':1259,'multiline':False]['text':' 2. Run the script above with the `recv` option in the first shell','line_number':1260,'multiline':False]['text':' (shell1) ./test_socket.py sock_tmp 1017 recv','line_number':1261,'multiline':False]['text':'','line_number':1262,'multiline':False]['text':' 3. Run the script with the `send` option in the second shell:','line_number':1263,'multiline':False]['text':' (shell2) ./test_socket.py sock_tmp 1017 send','line_number':1264,'multiline':False]['text':' Fetches data from `self._data_queue`.','line_number':1267,'multiline':False]['text':'','line_number':1268,'multiline':False]['text':' We check workers' status every `MP_STATUS_CHECK_INTERVAL` seconds,','line_number':1269,'multiline':False]['text':' which we achieve by running `self._try_get_data(timeout=MP_STATUS_CHECK_INTERVAL)`','line_number':1270,'multiline':False]['text':' in a loop. This is the only mechanism to detect worker failures for','line_number':1271,'multiline':False]['text':' Windows. For other platforms, a SIGCHLD handler is also used for','line_number':1272,'multiline':False]['text':' worker failure detection.','line_number':1273,'multiline':False]['text':'','line_number':1274,'multiline':False]['text':' If `pin_memory=True`, we also need check if `pin_memory_thread` had','line_number':1275,'multiline':False]['text':' died at timeouts.','line_number':1276,'multiline':False]['text':' while condition is false, i.e., pin_memory_thread died.','line_number':1289,'multiline':False]['text':' In this case, `self._data_queue` is a `queue.Queue`,. But we don't','line_number':1291,'multiline':False]['text':' need to call `.task_done()` because we don't use `.join()`.','line_number':1292,'multiline':False]['text':' If the worker responsible for `self._rcvd_idx` has already ended','line_number':1301,'multiline':False]['text':' and was unable to fulfill this task (due to exhausting an `IterableDataset`),','line_number':1302,'multiline':False]['text':' we try to advance `self._rcvd_idx` to find the next valid index.','line_number':1303,'multiline':False]['text':'','line_number':1304,'multiline':False]['text':' This part needs to run in the loop because both the `self._get_data()`','line_number':1305,'multiline':False]['text':' call and `_IterableDatasetStopIteration` check below can mark','line_number':1306,'multiline':False]['text':' extra worker(s) as dead.','line_number':1307,'multiline':False]['text':' has data or is still active','line_number':1311,'multiline':False]['text':' no valid `self._rcvd_idx` is found (i.e., didn't break)','line_number':1316,'multiline':False]['text':' Now `self._rcvd_idx` is the batch index we want to fetch','line_number':1321,'multiline':False]['text':' Check if the next sample has already been generated','line_number':1323,'multiline':False]['text':' Check for _IterableDatasetStopIteration','line_number':1332,'multiline':False]['text':' store out-of-order samples','line_number':1342,'multiline':False]['text':' find the next active worker, if any','line_number':1355,'multiline':False]['text':' not found (i.e., didn't break)','line_number':1360,'multiline':False]['text':' Mark a worker as having finished its work e.g., due to','line_number':1376,'multiline':False]['text':' exhausting an `IterableDataset`. This should be used only when this','line_number':1377,'multiline':False]['text':' `_MultiProcessingDataLoaderIter` is going to continue running.','line_number':1378,'multiline':False]['text':' Signal termination to that specific worker.','line_number':1382,'multiline':False]['text':' Indicate that no more data will be put on this queue by the current','line_number':1384,'multiline':False]['text':' process.','line_number':1385,'multiline':False]['text':' Note that we don't actually join the worker here, nor do we remove the','line_number':1388,'multiline':False]['text':' worker's pid from C side struct because (1) joining may be slow, and','line_number':1389,'multiline':False]['text':' (2) since we don't join, the worker may still raise error, and we','line_number':1390,'multiline':False]['text':' prefer capturing those, rather than ignoring them, even though they','line_number':1391,'multiline':False]['text':' are raised after the worker has finished its job.','line_number':1392,'multiline':False]['text':' Joinning is deferred to `_shutdown_workers`, which it is called when','line_number':1393,'multiline':False]['text':' all workers finish their jobs (e.g., `IterableDataset` replicas) or','line_number':1394,'multiline':False]['text':' when this iterator is garbage collected.','line_number':1395,'multiline':False]['text':' Called when shutting down this `_MultiProcessingDataLoaderIter`.','line_number':1402,'multiline':False]['text':' See NOTE [ Data Loader Multiprocessing Shutdown Logic ] for details on','line_number':1403,'multiline':False]['text':' the logic of this function.','line_number':1404,'multiline':False]['text':' See (2) of the note. If Python is shutting down, do no-op.','line_number':1406,'multiline':False]['text':' Normal exit when last reference is gone / iterator is depleted.','line_number':1408,'multiline':False]['text':' See (1) and the second half of the note.','line_number':1409,'multiline':False]['text':' Normal exit when last reference is gone / iterator is depleted.','line_number':1413,'multiline':False]['text':' See (1) and the second half of the note.','line_number':1414,'multiline':False]['text':' Exit `pin_memory_thread` first because exiting workers may leave','line_number':1416,'multiline':False]['text':' corrupted data in `worker_result_queue` which `pin_memory_thread`','line_number':1417,'multiline':False]['text':' reads from.','line_number':1418,'multiline':False]['text':' Use hasattr in case error happens before we set the attribute.','line_number':1420,'multiline':False]['text':' Send something to pin_memory_thread in case it is waiting','line_number':1422,'multiline':False]['text':' so that it can wake up and check `pin_memory_thread_done_event`','line_number':1423,'multiline':False]['text':' Exit workers now.','line_number':1429,'multiline':False]['text':' Get number of workers from `len(self._workers)` instead of','line_number':1432,'multiline':False]['text':' `self._num_workers` in case we error before starting all','line_number':1433,'multiline':False]['text':' workers.','line_number':1434,'multiline':False]['text':' If we are using workers_status with persistent_workers','line_number':1435,'multiline':False]['text':' we have to shut it down because the worker is paused','line_number':1436,'multiline':False]['text':' We should be able to join here, but in case anything went','line_number':1440,'multiline':False]['text':' wrong, we set a timeout and if the workers fail to join,','line_number':1441,'multiline':False]['text':' they are killed in the `finally` block.','line_number':1442,'multiline':False]['text':' Even though all this function does is putting into queues that','line_number':1448,'multiline':False]['text':' we have called `cancel_join_thread` on, weird things can','line_number':1449,'multiline':False]['text':' happen when a worker is killed by a signal, e.g., hanging in','line_number':1450,'multiline':False]['text':' `Event.set()`. So we need to guard this with SIGCHLD handler,','line_number':1451,'multiline':False]['text':' and remove pids from the C side data structure only at the','line_number':1452,'multiline':False]['text':' end.','line_number':1453,'multiline':False]['text':'','line_number':1454,'multiline':False]['text':' FIXME: Unfortunately, for Windows, we are missing a worker','line_number':1455,'multiline':False]['text':'        error detection mechanism here in this function, as it','line_number':1456,'multiline':False]['text':'        doesn't provide a SIGCHLD handler.','line_number':1457,'multiline':False]['text':' Existing mechanisms try to make the workers exit','line_number':1463,'multiline':False]['text':' peacefully, but in case that we unfortunately reach','line_number':1464,'multiline':False]['text':' here, which we shouldn't, (e.g., pytorch/pytorch#39570),','line_number':1465,'multiline':False]['text':' we kill the worker.','line_number':1466,'multiline':False]['text':' staticmethod is used to remove reference to `_MultiProcessingDataLoaderIter`','line_number':1469,'multiline':False]