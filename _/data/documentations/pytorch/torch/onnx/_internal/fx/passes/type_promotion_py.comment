['text':' Owner(s): ["module: onnx"]','line_number':1,'multiline':False]['text':' Imported to resolve beartype issue when type checking node.Argument.','line_number':29,'multiline':False]['text':' noqa: F401','line_number':30,'multiline':False]['text':' TODO(bowbao): move to type utils.','line_number':38,'multiline':False]['text':' Make this abstract as well because subclass needs to override __eq__().','line_number':90,'multiline':False]['text':' A class that overrides __eq__() and does not define __hash__() will have its __hash__() implicitly set to None.','line_number':91,'multiline':False]['text':' Ref: https://docs.python.org/3/reference/datamodel.html#object.__hash__','line_number':92,'multiline':False]['text':' This always returns a module. If the module does not exist it will be created.','line_number':107,'multiline':False]['text':' true_divide','line_number':256,'multiline':False]['text':' trunc_divide','line_number':262,'multiline':False]['text':' floor_divide','line_number':266,'multiline':False]['text':' Inspecting code, this can only happen when `promotion_kind` is `KEEP_PROMOTED_TYPE`.','line_number':316,'multiline':False]['text':' Hence set same as computation_dtype.','line_number':317,'multiline':False]['text':' Preserves uint8 -- probably a legacy mask thing','line_number':348,'multiline':False]['text':' The below logic is copied from `torch/_refs/__init__.py` reduction ops impl.','line_number':371,'multiline':False]['text':' NOTE: [Update type promotion rule]','line_number':382,'multiline':False]['text':' BELOW TABLE IS GENERATED FROM `TypePromotionRuleSetGenerator.generate_from_torch_refs`.','line_number':383,'multiline':False]['text':' DO NOT EDIT MANUALLY !!!','line_number':384,'multiline':False]['text':' For missing rules or discrepancies, please','line_number':385,'multiline':False]['text':' 1. Run `pytest test/onnx/test_fx_type_promotion.py` to validate if the generated rule set is current.','line_number':386,'multiline':False]['text':'    If it is not, update with new generated set.','line_number':387,'multiline':False]['text':' 2. If discrepancies still exist, consider debugging torch._refs or report a bug.','line_number':388,'multiline':False]['text':' 3. If rules are still missing, add them to `_EXTRA_TYPE_PROMOTION_RULE_SET` or report a bug.','line_number':389,'multiline':False]['text':' Check `TypePromotionRule` class for how each rule is defined and used.','line_number':390,'multiline':False]['text':' Manually curated extra type promotion rules. Please see NOTE [Update type promotion rule]','line_number':1057,'multiline':False]['text':' before adding new rules.','line_number':1058,'multiline':False]['text':' torch._refs skips type promotion decoration for `clamp_min` and `clamp_max` since','line_number':1060,'multiline':False]['text':' the call is routed to the decorated `aten.clamp` op.','line_number':1061,'multiline':False]['text':' torch.ops.aten.div.Tensor_mode applies different type promotion rules','line_number':1076,'multiline':False]['text':' depending on the value of the `mode` argument.','line_number':1077,'multiline':False]['text':' Manually curating reduction ops since the logic is written inside the op reference','line_number':1079,'multiline':False]['text':' implementation.','line_number':1080,'multiline':False]['text':' torch.ops.aten.mean is a special case that does not need type promotion.','line_number':1093,'multiline':False]['text':' TODO(bowbao): diagnostic.emit and diagnostic.set_message api.','line_number':1279,'multiline':False]['text':' Utilize the dispatch mechanism to find the compatible op overload.','line_number':1348,'multiline':False]['text':' Update interpreter env state with new output value.','line_number':1389,'multiline':False]['text':' With explicit type promotion, the expected result dtype may not be','line_number':1453,'multiline':False]['text':' the same as the computation dtype. This is referred to as "op math".','line_number':1454,'multiline':False]['text':' We need to explicitly cast the output back to the expected dtype.','line_number':1455,'multiline':False]['text':' See more about "op math" topic at `_prims_common.elementwise_dtypes`.','line_number':1456,'multiline':False]['text':' Promote tensor to dtype.','line_number':1507,'multiline':False]['text':' Promote Sym number to tensor of dtype.','line_number':1534,'multiline':False]['text':' Promote number to tensor of dtype.','line_number':1561,'multiline':False]['text':' The op should have overload that supports tensor for this arg, otherwise','line_number':1562,'multiline':False]['text':' the type promotion rule should not suggest promoting this arg.','line_number':1563,'multiline':False]['text':' If the placeholder is not used, we can safely ignore it and put','line_number':1699,'multiline':False]['text':' None as placeholder.','line_number':1700,'multiline':False]