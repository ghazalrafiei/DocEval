['text':' EDITING THIS FILE? READ THIS FIRST!','line_number':1,'multiline':False]['text':' see Note [Edit Symbolic Files] in README.md','line_number':2,'multiline':False]['text':' This file exports ONNX ops for opset 13','line_number':4,'multiline':False]['text':' Convert to multiple slice nodes iff number of splits and number of outputs are statically known.','line_number':80,'multiline':False]['text':' split_sizes is a list of same length as _outputs','line_number':96,'multiline':False]['text':' To make the first slice in the below loop work,','line_number':217,'multiline':False]['text':' we pad a zero to the first position so that it will be the initial start of slice.','line_number':218,'multiline':False]['text':' Loop inputs','line_number':223,'multiline':False]['text':' Loop outputs','line_number':246,'multiline':False]['text':' scalar tensor','line_number':265,'multiline':False]['text':' Emitted from `torch.nonzero(x, as_tuple=True)`','line_number':315,'multiline':False]['text':' Assumes that torch.where's first argument takes only Bool and Byte tensors.','line_number':325,'multiline':False]['text':' NOTE: (0, 127) is allowed as special case. PyTorch restricts activations to be in the range (0, 127).','line_number':348,'multiline':False]['text':'   https://github.com/pytorch/pytorch/blob/b34b192d6b97325c9f78e5995c48c8498ede34bd/torch/ao/quantization/observer.py#L1422','line_number':349,'multiline':False]['text':' ONNX defines zero_point to be int8 or uint8','line_number':356,'multiline':False]['text':' NOTE: (0, 127) is allowed as special case. PyTorch restricts activations to be in the range (0, 127).','line_number':383,'multiline':False]['text':'   https://github.com/pytorch/pytorch/blob/b34b192d6b97325c9f78e5995c48c8498ede34bd/torch/ao/quantization/observer.py#L1422','line_number':384,'multiline':False]['text':' all-reduce path','line_number':417,'multiline':False]['text':' Ported from','line_number':480,'multiline':False]['text':' https://github.com/microsoft/onnxscript/blob/6b1b81700b4523f31d8c6d3321e5d8ef5d42b764/onnxscript/function_libs/torch_aten/ops/core.py#L6097','line_number':481,'multiline':False]['text':' NOTE: Supporting aten::unflatten before opset13 needs helper function to adjust ONNX op changes in Concat, Slice, ...','line_number':482,'multiline':False]['text':' dim could be negative','line_number':494,'multiline':False]['text':' TODO: So far we don"t have a module using this method. We"ll keep','line_number':549,'multiline':False]['text':' this as a constant unless we see a request of dynamics in any','line_number':550,'multiline':False]['text':' user's modules.','line_number':551,'multiline':False]['text':' 1. If dims is shorter than self.shape pad dims with 1','line_number':565,'multiline':False]['text':' 2. If dims is longer than self.shape pad self.shape with 1','line_number':583,'multiline':False]['text':' if dim is None flatten','line_number':619,'multiline':False]['text':' By default, use the flattened input array, and return a flat output array','line_number':620,'multiline':False]['text':' Handle cases where dim is negative','line_number':647,'multiline':False]['text':' Check if all indices should be repeated the same number of times.','line_number':656,'multiline':False]['text':' If input size is dynamic or repeats vector is dynamic','line_number':663,'multiline':False]['text':' Check if repeats is dynamic','line_number':668,'multiline':False]['text':' As repeats is dynamic, we use a where node as a substitute for the if statement','line_number':669,'multiline':False]['text':' If repests_dim = 1, expand repeats otherwise use original tensor','line_number':670,'multiline':False]['text':' There are cases when the repeats are 1-d tensor with multiple repeats, but dim','line_number':679,'multiline':False]['text':' provided along one of the dynamic axes provided. A simple example would be','line_number':680,'multiline':False]['text':' input.shape -> [1, 1, *] where * represents the dynamic axes, and dim = 2','line_number':681,'multiline':False]['text':' Now, repeat interleaving can be performed in pytorch when the value of * matches','line_number':682,'multiline':False]['text':' with the number of elements in repeat, for example if * -> 2, number of repeats','line_number':683,'multiline':False]['text':' should be 2 as well.','line_number':684,'multiline':False]['text':' Create a loop to iterate over each value along the dimension','line_number':698,'multiline':False]['text':' and perform individual interleaving using the repeats tensor','line_number':699,'multiline':False]['text':' Loop is of the following pattern','line_number':700,'multiline':False]['text':' input (trip_count, cond)','line_number':701,'multiline':False]['text':'   int trip_count = ...;','line_number':702,'multiline':False]['text':'   bool cond = ...;','line_number':703,'multiline':False]['text':'   for (int i=0; i < trip_count && cond; ++i) {','line_number':704,'multiline':False]['text':'     cond = ...;','line_number':705,'multiline':False]['text':'   }','line_number':706,'multiline':False]['text':' Loop conditions','line_number':708,'multiline':False]['text':' Create an empty sequence to store final expansions','line_number':713,'multiline':False]['text':' Loop inputs','line_number':716,'multiline':False]['text':' Loop outputs','line_number':742,'multiline':False]['text':' Replace negative indexing when rank is known','line_number':759,'multiline':False]['text':' Create appropriate mask','line_number':770,'multiline':False]['text':' dim1 and dim2 appended as a dimension at the end of the shape','line_number':774,'multiline':False]['text':' Multiply input and mask to calculate values along diagonal','line_number':784,'multiline':False]['text':' The mask consists of one values where diagonal values are to be calculated','line_number':785,'multiline':False]['text':' For example:','line_number':786,'multiline':False]['text':' [[1.1, 1.2, 1.3],   *    [[1, 0, 0]   =   [[1.1, 0, 0],','line_number':787,'multiline':False]['text':'  [2.1, 2.2, 2.3],         [0, 1, 0]        [0, 2.2, 0],','line_number':788,'multiline':False]['text':'  [3.1, 3.2, 3.3]]         [0, 0, 1]]       [0, 0, 3.3]]','line_number':789,'multiline':False]['text':' Calculate gather indices based on offset and dims','line_number':793,'multiline':False]['text':' If offset is greater than zero, set offset to zero as this aids in','line_number':794,'multiline':False]['text':' calculation of selection window','line_number':795,'multiline':False]['text':' Calculate which diagonal values to select','line_number':812,'multiline':False]['text':' For example, in cases with offsets:','line_number':813,'multiline':False]['text':' [[0, 1.1, 0]','line_number':814,'multiline':False]['text':'  [0, 0, 2.2]]','line_number':815,'multiline':False]['text':' we need to select the last two columns, so we create a tensor','line_number':816,'multiline':False]['text':' with all columns that are to be selected','line_number':817,'multiline':False]['text':' So in this example, it is [1, 2]','line_number':818,'multiline':False]['text':' There might be cases where offset value is greater than number of rows/columns','line_number':839,'multiline':False]['text':' and might cause the diagonal to overrun and as a result of this, diag_size would be zero.','line_number':840,'multiline':False]['text':' For example, if','line_number':841,'multiline':False]['text':'       offset = 9, dim1_size = 2 (columns), dim2_size = 4 (rows)','line_number':842,'multiline':False]['text':'       diag_size = max(min(2, (4-9)), 0) = 0, based on calculation above','line_number':843,'multiline':False]['text':' Cases with diagonal overrun always result in diag_size = max(0, -ve value) = 0','line_number':844,'multiline':False]['text':' In cases without diagonal overrun, we select the appropriate rows/columns along which we','line_number':845,'multiline':False]['text':' are calculating diagonal values. In cases with diagonal overrun, we return a tensor which has','line_number':846,'multiline':False]['text':' the dimension of the row/column where overrun occurred as 0-dim, as we are essentially','line_number':847,'multiline':False]['text':' returning an empty tensor','line_number':848,'multiline':False]['text':' Quantized ops','line_number':875,'multiline':False]