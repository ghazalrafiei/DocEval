['text':' Monkey-patch graph manipulation methods on Graph, used for the ONNX symbolics','line_number':13,'multiline':False]['text':' EDITING THIS FILE? READ THIS FIRST!','line_number':24,'multiline':False]['text':' see Note [Edit Symbolic Files] in README.md','line_number':25,'multiline':False]['text':' This file exports ONNX ops for opset 10','line_number':27,'multiline':False]['text':' Opset 10 is supported by ONNX release 1.5.0','line_number':28,'multiline':False]['text':' release on 04/24/19','line_number':29,'multiline':False]['text':' Integer division does trunction rounding','line_number':107,'multiline':False]['text':' Division is negative if: self < 0 != other < 0','line_number':109,'multiline':False]['text':' For negative numbers with self % other != 0, subtract 1 to round down instead of up','line_number':113,'multiline':False]['text':' C,H,W -> N,C,H,W and N=1','line_number':149,'multiline':False]['text':' For MaxPool','line_number':177,'multiline':False]['text':' type: ignore[assignment]','line_number':193,'multiline':False]['text':' type: ignore[operator, assignment]','line_number':196,'multiline':False]['text':' type: ignore[operator, assignment]','line_number':198,'multiline':False]['text':' 2D padding','line_number':200,'multiline':False]['text':' type: ignore[operator, assignment]','line_number':201,'multiline':False]['text':' 3D padding','line_number':203,'multiline':False]['text':' type: ignore[operator, assignment]','line_number':204,'multiline':False]['text':' When padding is already done for all dimensions,','line_number':206,'multiline':False]['text':' we don't need to double it','line_number':207,'multiline':False]['text':' eg: (1, 1, 1, 1, 1, 1)','line_number':208,'multiline':False]['text':' type: ignore[assignment]','line_number':209,'multiline':False]['text':' type: ignore[assignment]','line_number':216,'multiline':False]['text':' C,H,W -> N,C,H,W and N=1','line_number':235,'multiline':False]['text':' For AvgPool','line_number':365,'multiline':False]['text':' type: ignore[assignment]','line_number':377,'multiline':False]['text':' type: ignore[operator, assignment]','line_number':382,'multiline':False]['text':' type: ignore[operator, assignment]','line_number':384,'multiline':False]['text':' type: ignore[operator, assignment]','line_number':386,'multiline':False]['text':' type: ignore[assignment]','line_number':393,'multiline':False]['text':' Convert input param into a 1D torch.Value.','line_number':526,'multiline':False]['text':' Check if slice is a no-op','line_number':549,'multiline':False]['text':' aten::slice(Tensor self, int dim, int? start=None, int? end=None, int step=1) -> Tensor','line_number':570,'multiline':False]['text':' aten::slice(t[] l, int? start=None, int? end=None, int step=1) -> t[]','line_number':573,'multiline':False]['text':' aten::embedding_bag returns a tuple of 4 elements: output, offset2bag, bag_size, max_indices.','line_number':686,'multiline':False]['text':' But the last three outputs are not used in torch.nn.EmbeddingBag or torch.nn.functional.embedding_bag.','line_number':687,'multiline':False]['text':' NOTE: (0, 127) is a special case. PyTorch restricts activations to be in the range (0, 127).','line_number':707,'multiline':False]['text':'   https://github.com/pytorch/pytorch/blob/b34b192d6b97325c9f78e5995c48c8498ede34bd/torch/ao/quantization/observer.py#L1422','line_number':708,'multiline':False]['text':' Avoid exporter generating double type','line_number':732,'multiline':False]['text':' TODO(justinchuby): Extract all the cast ops into a helper function.','line_number':763,'multiline':False]['text':' Cannot create a int type tensor with inf/nan values, so we simply','line_number':781,'multiline':False]['text':' return the original tensor','line_number':782,'multiline':False]['text':' For None values of posinf, neginf we use the greatest/lowest finite','line_number':796,'multiline':False]['text':' value representable by inputâ€™s dtype.','line_number':797,'multiline':False]['text':' Quantized symbolics ---------------------------------------------------------','line_number':830,'multiline':False]['text':' https://github.com/pytorch/pytorch/wiki/PyTorch-ONNX-exporter#quantized-model-export','line_number':831,'multiline':False]['text':' Support starts from opset 10 because `DequantizeLinear` and `QuantizeLinear` were','line_number':832,'multiline':False]['text':' introduced in opset version 10.','line_number':833,'multiline':False]