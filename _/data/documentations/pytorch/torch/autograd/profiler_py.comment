['text':' Available in Python >= 3.2','line_number':51,'multiline':False]['text':' type: ignore[no-redef]','line_number':56,'multiline':False]['text':' global python state - whether profiler is currently enabled','line_number':72,'multiline':False]['text':' useful for fast python checks to reduce latency','line_number':73,'multiline':False]['text':' type: ignore[union-attr]','line_number':350,'multiline':False]['text':' type: ignore[union-attr]','line_number':352,'multiline':False]['text':' result.events() has most of the events - PyTorch op-level and device-level events','line_number':387,'multiline':False]['text':' Create and return FunctionEvent list','line_number':420,'multiline':False]['text':' find the corresponding memory allocation events','line_number':435,'multiline':False]['text':' Check if we have CUDA time as a fallback','line_number':482,'multiline':False]['text':' associate CUDA kernels and CUDA runtime (CPU) with CPU events','line_number':494,'multiline':False]['text':' make sure that 'thread' of a CPU Kineto (e.g. CUDA Runtime) event is associated','line_number':509,'multiline':False]['text':' with the 'thread' of the corresponding linked PyTorch event to properly track','line_number':510,'multiline':False]['text':' parents and children','line_number':511,'multiline':False]['text':' not outputting in the trace','line_number':519,'multiline':False]['text':' no duration','line_number':522,'multiline':False]['text':' RecordScope::FUNCTION','line_number':526,'multiline':False]['text':' output top-level memory events','line_number':538,'multiline':False]['text':' Whether or not we should run record function's end callbacks when exiting.','line_number':596,'multiline':False]['text':' TODO: TorchScript ignores standard type annotation here','line_number':598,'multiline':False]['text':' self.record: Optional["torch.classes.profiler._RecordFunction"] = None','line_number':599,'multiline':False]['text':' Local variable is needed by TorchScript to refine Optional[T] to T','line_number':614,'multiline':False]['text':' TODO: Too slow with __torch_function__ handling enabled','line_number':618,'multiline':False]['text':' See https://github.com/pytorch/pytorch/issues/76410','line_number':619,'multiline':False]['text':' Throw if we have already attached a callback onto the future.','line_number':643,'multiline':False]['text':' We are scheduling to run this RecordFunction's end callbacks when the','line_number':647,'multiline':False]['text':' passed in future completes, so don't run end callbacks on exit.','line_number':648,'multiline':False]['text':' Local variable is needed by TorchScript to refine Optional[T] to T','line_number':651,'multiline':False]['text':' TODO: Too slow with __torch_function__ handling enabled','line_number':655,'multiline':False]['text':' See https://github.com/pytorch/pytorch/issues/76410','line_number':656,'multiline':False]['text':' Parse strings table','line_number':890,'multiline':False]['text':' First, find all functions and create FunctionEvents for them','line_number':895,'multiline':False]['text':' missing a node_id when calling FunctionEvent. This is just to ensure','line_number':912,'multiline':False]['text':' that pytorch doesn't crash when creating a FunctionEvent() object','line_number':913,'multiline':False]['text':' TODO: find in sqlite database','line_number':918,'multiline':False]['text':' Now, correlate all kernels with FunctionEvents','line_number':922,'multiline':False]['text':' 211 is cudaKernelLaunch for cuda >= 9.2','line_number':940,'multiline':False]