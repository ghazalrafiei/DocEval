['text':' Lazy state initialization','line_number':60,'multiline':False]['text':' note(crcrpar): [special device hosting for step]','line_number':62,'multiline':False]['text':' Deliberately host `step` and `mu_product` on CPU if capturable is False.','line_number':63,'multiline':False]['text':' This is because kernel launches are costly on CUDA and XLA.','line_number':64,'multiline':False]['text':' Exponential moving average of gradient values','line_number':73,'multiline':False]['text':' Exponential moving average of squared gradient values','line_number':75,'multiline':False]['text':' kwonly args with defaults are not supported by functions compiled with torchscript issue #70627','line_number':196,'multiline':False]['text':' setting this as kwarg for now as functional API is compiled by torch/distributed/optim','line_number':197,'multiline':False]['text':' If compiling, the compiler will handle cudagraph checks, see note [torch.compile x capturable]','line_number':282,'multiline':False]['text':' update step','line_number':288,'multiline':False]['text':' Perform stepweight decay','line_number':300,'multiline':False]['text':' calculate the momentum cache \mu^{t} and \mu^{t+1}','line_number':305,'multiline':False]['text':' update mu_product','line_number':309,'multiline':False]['text':' decay the first and second moment running average coefficient','line_number':312,'multiline':False]['text':' Make autograd track the operations','line_number':319,'multiline':False]['text':' by updating the grad and exp_avg directly and not using the','line_number':320,'multiline':False]['text':' scalar "value" argument of addcdiv.','line_number':321,'multiline':False]['text':' If compiling, the compiler will handle cudagraph checks, see note [torch.compile x capturable]','line_number':357,'multiline':False]['text':' handle complex','line_number':368,'multiline':False]['text':' Update steps','line_number':372,'multiline':False]['text':' If steps are on CPU, foreach will fall back to the slow path, which is a for-loop calling t.add(1) over','line_number':373,'multiline':False]['text':' and over. 1 will then be wrapped into a Tensor over and over again, which is slower than if we just','line_number':374,'multiline':False]['text':' wrapped it once now. The alpha is required to assure we go to the right overload.','line_number':375,'multiline':False]['text':' Perform stepweight decay','line_number':383,'multiline':False]['text':' Decay the first and second moment running average coefficient','line_number':388,'multiline':False]['text':' mus will be beta1 * (1 - 0.5 * 0.96 ** (step * momentum_decay))','line_number':397,'multiline':False]['text':' mu_nexts will be beta1 * (1 - 0.5 * 0.96 ** ((step + 1) * momentum_decay))','line_number':404,'multiline':False]['text':' save peak memory as we don't need exponent anymore','line_number':411,'multiline':False]['text':' foreach_sub doesn't allow a scalar as the first arg','line_number':415,'multiline':False]['text':' update mu_products','line_number':425,'multiline':False]['text':' explicitly delete bias_correction refs to save memory','line_number':431,'multiline':False]['text':' Build up the step_size multiplier for grad, reusing mus' memory','line_number':435,'multiline':False]['text':' foreach_sub doesn't allow a scalar as the first arg','line_number':438,'multiline':False]['text':' - lr * (1 - mu) / (1 - mu_product)','line_number':442,'multiline':False]['text':' explicitly delete denom to save memory','line_number':444,'multiline':False]['text':' Build up the step_size multiplier for exp_avg, reusing mu_nexts' memory','line_number':447,'multiline':False]['text':' foreach_sub doesn't allow a scalar as the first arg, but it's okay because','line_number':450,'multiline':False]['text':' we need a negative here anyway','line_number':451,'multiline':False]['text':' - lr * mu_next / (1 - mu_product * mu_next)','line_number':454,'multiline':False]['text':' explicitly delete denom to save memory','line_number':456,'multiline':False]['text':' we cannot inplace into step_size_grads cuz it is a list of ScalarTensors','line_number':459,'multiline':False]['text':' and mul'ing with grouped_grads will result in a list of bigger Tensors','line_number':460,'multiline':False]['text':' finally, update params','line_number':464,'multiline':False]