['text':' for other gpu types, assume Ampere','line_number':37,'multiline':False]['text':'###################################################################################################################','line_number':56,'multiline':False]['text':' The following code and constants are adapted from https://github.com/NVIDIA/nccl/blob/master/src/graph/tuning.cc #','line_number':57,'multiline':False]['text':'###################################################################################################################','line_number':58,'multiline':False]['text':' The ordering and enum values here matches original in','line_number':73,'multiline':False]['text':' https://github.com/NVIDIA/nccl/blob/0b083e52096c387bad7a5c5c65b26a9dca54de8c/src/include/devcomm.h#L28','line_number':74,'multiline':False]['text':' For difference between these protocols, see https://github.com/NVIDIA/nccl/issues/281#issuecomment-571816990','line_number':75,'multiline':False]['text':' Low-latency','line_number':76,'multiline':False]['text':' LL128 = 1   # Low-latency 128-byte','line_number':77,'multiline':False]['text':' SIMPLE = 2','line_number':78,'multiline':False]['text':' Latencies in us','line_number':81,'multiline':False]['text':' len(NCCL_ALGO) x len(NCCL_PROTO)','line_number':82,'multiline':False]['text':' Tree','line_number':85,'multiline':False]['text':' LL','line_number':87,'multiline':False]['text':' Ring','line_number':89,'multiline':False]['text':' LL','line_number':91,'multiline':False]['text':' Latencies in us','line_number':96,'multiline':False]['text':' len(NCCL_HW) x len(NCCL_ALGO) x len(NCCL_PROTO)','line_number':97,'multiline':False]['text':' NVLINK','line_number':100,'multiline':False]['text':' Tree (LL)','line_number':102,'multiline':False]['text':' Ring (LL)','line_number':103,'multiline':False]['text':' PCI','line_number':105,'multiline':False]['text':' Tree (LL)','line_number':107,'multiline':False]['text':' Ring (LL)','line_number':108,'multiline':False]['text':' NET','line_number':110,'multiline':False]['text':' Tree (LL)','line_number':112,'multiline':False]['text':' Ring (LL)','line_number':113,'multiline':False]['text':' LL128 max BW per channel','line_number':119,'multiline':False]['text':' Volta-N1/Intel-N2/Intel-N4','line_number':122,'multiline':False]['text':' Ampere-N1/AMD-N2/AMD-N4','line_number':128,'multiline':False]['text':' avg of ring & tree','line_number':131,'multiline':False]['text':' Hopper-N1/AMD-N2/AMD-N4','line_number':134,'multiline':False]['text':' avg of ring & tree','line_number':137,'multiline':False]['text':' Convert bytes to GB','line_number':160,'multiline':False]['text':' Currently assumes each node has 8 gpus. And when >1 node is used, assumes each node uses all 8 gpus.','line_number':163,'multiline':False]['text':' TODO: Need to find a way to get accurate "gpus per node" and "# nodes" info.','line_number':164,'multiline':False]['text':' type: ignore[attr-defined]','line_number':166,'multiline':False]['text':' this is total # of gpus globally that participate in this collective op','line_number':168,'multiline':False]['text':' Assumes ring algorithm','line_number':173,'multiline':False]['text':' =============== bandwidth computation ===============','line_number':178,'multiline':False]['text':' First compute bandwidth in GB/s; then at the end, convert it to GB/ns','line_number':179,'multiline':False]['text':' LL: for single node, we look at GPU type; for multi-node, we look at CPU type','line_number':186,'multiline':False]['text':' NOTE: each step of ring algorithm is synchronized,','line_number':190,'multiline':False]['text':' and is bottlenecked by the slowest link which is the inter-node interconnect.','line_number':191,'multiline':False]['text':' hence when nNodes >= 2, bw is inter-node bandwidth.','line_number':192,'multiline':False]['text':' NOTE: the original code in https://github.com/NVIDIA/nccl/blob/master/src/graph/tuning.cc','line_number':193,'multiline':False]['text':' have this as `if nNodes <= 2` which seems wrong. Corrected it here.','line_number':194,'multiline':False]['text':' Assume # channels is 2','line_number':196,'multiline':False]['text':' Various model refinements','line_number':199,'multiline':False]['text':' Convert bus BW to algorithm BW (tensor bytes / algoBW = actual execution time)','line_number':211,'multiline':False]['text':' Convert GB/s to GB/ns','line_number':214,'multiline':False]['text':' =============== latency computation ===============','line_number':217,'multiline':False]['text':' First compute latency in us; then at the end, convert it to ns','line_number':229,'multiline':False]['text':' Inter-node rings still have to launch nsteps * net overhead.','line_number':234,'multiline':False]['text':' getNetOverhead(comm);','line_number':237,'multiline':False]['text':' Convert us to ns','line_number':240,'multiline':False]['text':' =============== final result ===============','line_number':243,'multiline':False]['text':'###############################################################################################################','line_number':248,'multiline':False]['text':' The above code and constants are adapted from https://github.com/NVIDIA/nccl/blob/master/src/graph/tuning.cc #','line_number':249,'multiline':False]['text':'###############################################################################################################','line_number':250,'multiline':False]