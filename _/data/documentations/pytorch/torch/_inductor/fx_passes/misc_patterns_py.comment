['text':' medium priority','line_number':19,'multiline':False]['text':' workaround https://github.com/pytorch/pytorch/issues/97894','line_number':22,'multiline':False]['text':' These patterns do 2 things','line_number':27,'multiline':False]['text':' 1. Since we know that index is completely unique, we can codegen it using','line_number':28,'multiline':False]['text':' stores instead of atomic adds, which is quite a bit faster.','line_number':29,'multiline':False]['text':' 2. Also, since we are guaranteed that they are completely within bounds,','line_number':30,'multiline':False]['text':' we can use unsafe indexing and skip debug asserts','line_number':31,'multiline':False]['text':' callable -> tuple of replaceable args e.g. ["axis"]','line_number':82,'multiline':False]['text':' only applies to torch ops; e.g. torch.stack(axis=1) works, torch.ops.aten.stack(axis=1) doesn't.','line_number':94,'multiline':False]