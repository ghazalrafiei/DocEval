['text':' Remove unwanted decompositions included via the core ATen decompositions from','line_number':72,'multiline':False]['text':' the Inductor decomp table.','line_number':73,'multiline':False]['text':' See comments in torch/_decomp/decompositions.py','line_number':76,'multiline':False]['text':' inductor lowers this directly','line_number':79,'multiline':False]['text':' inductor lowers this directly','line_number':80,'multiline':False]['text':' inductor lowers this directly','line_number':81,'multiline':False]['text':' inductor lowers this directly','line_number':82,'multiline':False]['text':' inductor lowers this directly','line_number':83,'multiline':False]['text':' TODO: for now, inductor doesn't handle asserts','line_number':96,'multiline':False]['text':' because the condition is symbool -> tensor in the graph.','line_number':97,'multiline':False]['text':' Following `assert_async_msg_decomp` and implement as non-op.','line_number':103,'multiline':False]['text':' Not really sure how to put this into the main library.  PrimTorch wants','line_number':133,'multiline':False]['text':' empty_permuted to go to the prim, and typically users don't really want','line_number':134,'multiline':False]['text':' to decompose to empty_strided (but inductor is OK with it, because we are','line_number':135,'multiline':False]['text':' cool with strides and everything goes to empty_strided)','line_number':136,'multiline':False]['text':' Our matrix vector multiplies only achieve peak bandwidth with coordinate descent tuning.','line_number':222,'multiline':False]['text':' todo: Look into why and fix it (hopefully)','line_number':223,'multiline':False]['text':' special case for cat'ing with an empty tensor -','line_number':246,'multiline':False]['text':' just drop the 'empty' inputs so they don't confuse the logic below.','line_number':247,'multiline':False]['text':' on the first call, when we remove empty tensors, we redispatch recursively','line_number':255,'multiline':False]['text':' when no 'filtering' has occurred, we raise to prevent infinite recursion (no more decomposition needed)','line_number':257,'multiline':False]['text':' when x is real number','line_number':268,'multiline':False]['text':'   if x >= 0, return 0','line_number':269,'multiline':False]['text':'   if x < 0, return pi','line_number':270,'multiline':False]['text':'   if x is nan, return nan','line_number':271,'multiline':False]['text':' TODO: _to_copy tensor to stride permutation','line_number':358,'multiline':False]['text':' The difference between quantize_per_tensor.default and quantize_per_tensor.tensor is','line_number':438,'multiline':False]['text':' scale and zero_point is scalar or scalar tensor','line_number':439,'multiline':False]['text':' The difference between dequantize_per_tensor.default and dequantize_per_tensor.tensor is','line_number':457,'multiline':False]['text':' scale and zero_point is scalar or scalar tensor','line_number':458,'multiline':False]['text':' We do not expand the grid (_expand_grid=False) on cpu for performance reasons','line_number':523,'multiline':False]['text':' Experimenting locally it was found that compiled CUDA code is accelerated by ~5x','line_number':524,'multiline':False]['text':' and CPU code by ~2x on bicubic mode, if we expand the grid from (N, H, W, 2) into (N, C, H, W, 2)','line_number':525,'multiline':False]['text':' However, this leads to a slowdown around ~0.8x on CPU bilinear mode, channels first.','line_number':526,'multiline':False]['text':' Thus we apply this hack to not expand the grid for this case.','line_number':527,'multiline':False]['text':' This two-step algorithm is the same as eager CUDA, for eager CPU we','line_number':616,'multiline':False]['text':' use a 1-shot serial iteration.','line_number':617,'multiline':False]