['text':' namespace','line_number':20,'multiline':False]['text':' helper to determine if an optional tensor argument/value passed in is','line_number':22,'multiline':False]['text':' statically defined (neither a None constant nor a Optional[Tensor] type)','line_number':23,'multiline':False]['text':' return yes, no, or no value if we can't tell','line_number':24,'multiline':False]['text':' As of now, we do the decomposition for batchnorm/layernorm on GPU device','line_number':45,'multiline':False]['text':' only','line_number':46,'multiline':False]['text':' If we can't determine if weight and bias is defined statically there's','line_number':52,'multiline':False]['text':' really no point in decomposing normalization into simpler ops, since it','line_number':53,'multiline':False]['text':' won't get fused into a single kernel.','line_number':54,'multiline':False]['text':'const_inputs=','line_number':98,'multiline':True]['text':' For the case where we have an addmm where alpha and beta are Attributes','line_number':99,'multiline':False]['text':' and both of those scalars are equal to 1.0, decompose this into an mm','line_number':100,'multiline':False]['text':' followed by an add so that it can go through the existing optimization','line_number':101,'multiline':False]['text':' (batchmm)','line_number':102,'multiline':False]['text':' Set the output of the decomposed graph to have the same output type as','line_number':114,'multiline':False]['text':' the original op otherwise the canonicalized graph will have TensorType','line_number':115,'multiline':False]['text':' as the output of this node which is incorrect','line_number':116,'multiline':False]['text':' inline the compiled decomposed batchnorm','line_number':139,'multiline':False]['text':' post processing the graph','line_number':144,'multiline':False]['text':' inline the compiled decomposed layernorm','line_number':174,'multiline':False]['text':' post processing the graph','line_number':179,'multiline':False]['text':' we only re-run those passes when the graph get decomposed','line_number':227,'multiline':False]['text':' namespace jit','line_number':234,'multiline':False]['text':' namespace torch','line_number':235,'multiline':False]