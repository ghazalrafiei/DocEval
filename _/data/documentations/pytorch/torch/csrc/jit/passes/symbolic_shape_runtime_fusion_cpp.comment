['text':' Inserts the Compute for Each Symbolic Shape in the TensorExpr Graph','line_number':21,'multiline':False]['text':' and returns back a map from Symbolic Shape Value to its runtime Value *','line_number':22,'multiline':False]['text':' in the runtime guard, strides are serialized as one flat','line_number':116,'multiline':False]['text':' vector. stride_inputs_offset indexes into that vector','line_number':117,'multiline':False]['text':' where the strides of this tensor begin','line_number':118,'multiline':False]['text':' Transposed Contiguous depends on prior dim and contiguous depends on next','line_number':131,'multiline':False]['text':' dim, so to avoid a mutual dependence check that the next dim is Stride','line_number':132,'multiline':False]['text':' Contiguous','line_number':133,'multiline':False]['text':' TODO: channels last 3d','line_number':148,'multiline':False]['text':' Todo: incorporate in codegen','line_number':160,'multiline':False]['text':' We only try to maintain output striding for channels last tensors,','line_number':164,'multiline':False]['text':' otherwise we defer to contiguous','line_number':165,'multiline':False]['text':' TODO: channels last 3d','line_number':166,'multiline':False]['text':' Generalize Complete Shapes inputs to Symbolic Shapes.','line_number':173,'multiline':False]['text':' Dimensions of value 1 will be preserved, otherwise','line_number':174,'multiline':False]['text':' dimensions with the same value will be bucketed to the same','line_number':175,'multiline':False]['text':' symbolic shape.','line_number':176,'multiline':False]['text':' E.g. Tensor(5, 3), Tensor(3, 1) -> Tensor(SS(-1), SS(-2)), Tensor(SS(-2), 1)','line_number':177,'multiline':False]['text':' Also summarize input striding behavior. The Size information is stored on the','line_number':178,'multiline':False]['text':' type, The striding is returned. See StrideInput for description of stride','line_number':179,'multiline':False]['text':' specializations','line_number':180,'multiline':False]['text':' copy the constant and insert that copy into the parent graph.','line_number':236,'multiline':False]['text':' add a new input to the te subgraph and replace the uses of the','line_number':240,'multiline':False]['text':' constant with this input.','line_number':241,'multiline':False]['text':' add the copy as input to the te node','line_number':246,'multiline':False]['text':' Move constant tensors from the subgraph to the outer scope.','line_number':261,'multiline':False]['text':' This is necessary because symbolic shape analysis does not handle the','line_number':262,'multiline':False]['text':' case of broadcast(constant, symbolic_shape) well and that results in poor','line_number':263,'multiline':False]['text':' performance.','line_number':264,'multiline':False]['text':' Generalize Inputs','line_number':267,'multiline':False]['text':' Get output striding behavior','line_number':274,'multiline':False]['text':' Try To Propagate Shapes','line_number':287,'multiline':False]['text':' Insert Guard','line_number':297,'multiline':False]['text':' TODO: share more logic with tensorexpr_fuser ?','line_number':340,'multiline':False]['text':' Fixup types of the subgraph inputs','line_number':352,'multiline':False]['text':' We only check inputs of the guarded nodes','line_number':357,'multiline':False]['text':' prim::TensorExprDynamicGuard nodes look like the following:','line_number':368,'multiline':False]['text':'   %types_match : bool = prim::TypeCheck[attr:types](%inp1 : Tensor, %inp2 :','line_number':369,'multiline':False]['text':'   Tensor)','line_number':370,'multiline':False]['text':' The input tensors are checked against the expected types on attr::types','line_number':371,'multiline':False]['text':' Omitting refining the input Tensors for now because they are not actually','line_number':372,'multiline':False]['text':' used within tensorexpr/kernel.cpp (only the inputs to the Graph are, not','line_number':373,'multiline':False]['text':' the inputs to the node) and we would have to redo the mapping to compute','line_number':374,'multiline':False]['text':' symbolic shapes','line_number':375,'multiline':False]['text':' Insert if','line_number':385,'multiline':False]['text':' Fill in the false block. It should contain the unoptimized','line_number':398,'multiline':False]['text':' copy of the fused subgraph.','line_number':399,'multiline':False]['text':' types get copied to the fallback graph, so remove specializations before','line_number':407,'multiline':False]['text':' replacing','line_number':408,'multiline':False]['text':' Fill in the true block. It has all inputs type-checked and its','line_number':412,'multiline':False]['text':' body should be the fusion group node.','line_number':413,'multiline':False]['text':' Insert Symbolic Shapes Compute and add as inputs to TE Node/Graph','line_number':420,'multiline':False]['text':' symbolic_shape_inputs will be a list of each symbolic shape,','line_number':421,'multiline':False]['text':' and the last N inputs to TE Graph/Node will be the N','line_number':422,'multiline':False]['text':' symbolic shape values','line_number':423,'multiline':False]['text':' only in SR flow do we check for values on the stack and','line_number':463,'multiline':False]['text':' forward them along as tensor outputs','line_number':464,'multiline':False]['text':' TODO: - refactor and make explicit part of TE Kernel api','line_number':465,'multiline':False]['text':' Create a TensorExprDynamicGroup node','line_number':468,'multiline':False]['text':' This operator is inserted at the end of the fallback block computing outputs','line_number':477,'multiline':False]['text':' for the fusion group. We convert block1():','line_number':478,'multiline':False]['text':'   %14 : Tensor = aten::mul(%0, %1)','line_number':479,'multiline':False]['text':'   %15 : Tensor = aten::mul(%0, %14)','line_number':480,'multiline':False]['text':'   -> (%15, %14)','line_number':481,'multiline':False]['text':' return (%3, %4)','line_number':482,'multiline':False]['text':' to','line_number':483,'multiline':False]['text':' block1():','line_number':484,'multiline':False]['text':'   %14 : Tensor = aten::mul(%0, %1)','line_number':485,'multiline':False]['text':'   %15 : Tensor = aten::mul(%0, %14)','line_number':486,'multiline':False]['text':'   %16 : Tensor, %17 : Tensor = prim::StaticRuntimeCopyOuts(%15, %14)','line_number':487,'multiline':False]['text':'   -> (%16, %17)','line_number':488,'multiline':False]['text':' Every output of the block is added as an input, and for each input there is','line_number':489,'multiline':False]['text':' a StaticRuntimeCopyOuts output. SR invokes the composed operator first with','line_number':490,'multiline':False]['text':' no tensors on the stack, in which case the Op will just return back the','line_number':491,'multiline':False]['text':' inputs. Second it invokes it with pre-allocated tensors, one for each output','line_number':492,'multiline':False]['text':' of the Fusion group, which is the same number of outputs of the fallback','line_number':493,'multiline':False]['text':' block. In this case we copy over the values of the inputs to pre-allocated','line_number':494,'multiline':False]['text':' tensors','line_number':495,'multiline':False]['text':' Note: this logic is meant to reflect the invocation of the TE Kernel','line_number':496,'multiline':False]['text':' and `runWithAllocatedOutputs` in tensorexpr_fuser.cpp','line_number':497,'multiline':False]['text':' uncommon case - first run','line_number':502,'multiline':False]['text':' On each invocation of this guard, we need to check all of the static','line_number':528,'multiline':False]['text':' information (dtype/device/requires grad/contiguity/static dims),','line_number':529,'multiline':False]['text':' and also the that the symbolic shape dimensions are observed.','line_number':530,'multiline':False]['text':' For any symbolic dimension we need to set its value on its first','line_number':531,'multiline':False]['text':' use and for all subsequent uses check that the values are equal','line_number':532,'multiline':False]['text':' Each inputs expected # of dims','line_number':539,'multiline':False]['text':' A flattened vector of all the expected values for all','line_number':542,'multiline':False]['text':' tensor dims. A positive value corresponds to a static','line_number':543,'multiline':False]['text':' shape to check and a negative value corresponds to symbolic','line_number':544,'multiline':False]['text':' dimension index to check','line_number':545,'multiline':False]['text':' Each inputs expected scalar types','line_number':548,'multiline':False]['text':' Map from symbolic dimension value to its set's index','line_number':551,'multiline':False]['text':' we should just be fusing fusion groups with a single device','line_number':555,'multiline':False]['text':' and with tensors not requiring grad','line_number':556,'multiline':False]['text':' flattened vector of each inputs striding behavior','line_number':561,'multiline':False]['text':' use index for set if it exists, otherwise extend the vector','line_number':587,'multiline':False]['text':' of sym shapes by 1','line_number':588,'multiline':False]['text':' TODO: potential optimization - if there is a Symbolic','line_number':597,'multiline':False]['text':' Sym with only one use we dont need to test anything','line_number':598,'multiline':False]['text':' each invocation we need to reset what value of each symbolic','line_number':615,'multiline':False]['text':' symbol is.','line_number':616,'multiline':False]['text':' TODO: could this be a reference and not allocated on','line_number':617,'multiline':False]['text':' each invocation or would that mess up with multithreaded','line_number':618,'multiline':False]['text':' inference since we are writing to it?','line_number':619,'multiline':False]['text':' TODO - smallvector here ?','line_number':620,'multiline':False]['text':' Tensors natively store whether they are contiguous','line_number':644,'multiline':False]['text':' in the default memory format or in channels last,','line_number':645,'multiline':False]['text':' so it is more efficient to query whether they follow this','line_number':646,'multiline':False]['text':' property than iterating over dimensions and checking yourself','line_number':647,'multiline':False]['text':' TODO: 5D channels last','line_number':656,'multiline':False]['text':' flattened sym indices start at -1,','line_number':692,'multiline':False]['text':' so -1 -> index 0, -2 -> index 1','line_number':693,'multiline':False]['text':' sym symbol already seen, check value','line_number':697,'multiline':False]['text':' not seen, write value','line_number':704,'multiline':False]['text':' This implementation creates a Code object and InterpreterState on every','line_number':727,'multiline':False]['text':' call to TensorExprDynamicGroup, which affects performance. Ideally, we','line_number':728,'multiline':False]['text':' should be reusing Code and InterpreterState across calls to this op.','line_number':729,'multiline':False]['text':' But that is resulting in a "No frames found" error.','line_number':730,'multiline':False]['text':' TODO: Improve the performance of this by figuring out a better approach.','line_number':731,'multiline':False]['text':' NB: this is only run in SR, which is single-threaded','line_number':732,'multiline':False]['text':' namespace jit','line_number':746,'multiline':False]['text':' namespace torch','line_number':747,'multiline':False]