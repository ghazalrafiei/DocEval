['text':' namespace','line_number':119,'multiline':False]['text':' Tracing annotates the resulting graph with shape information. In many case,','line_number':192,'multiline':False]['text':' user applies different input shapes to traced graph. It is on the user to','line_number':193,'multiline':False]['text':' know it is correct to do so. The quantized module needs to be clean up and','line_number':194,'multiline':False]['text':' To prevent the JIT optimizations from leveraging the annotated shape info,','line_number':195,'multiline':False]['text':' clear shape information in the graph.','line_number':196,'multiline':False]['text':' Tracing annotates the resulting graph with shape information. In many case,','line_number':214,'multiline':False]['text':' user applies different input shapes to traced graph. It is on the user to','line_number':215,'multiline':False]['text':' know it is correct to do so. The quantized module needs to be clean up and','line_number':216,'multiline':False]['text':' To prevent the JIT optimizations from leveraging the annotated shape info,','line_number':217,'multiline':False]['text':' clear shape information in the graph.','line_number':218,'multiline':False]['text':' Doing some AOT optimizations here','line_number':235,'multiline':False]['text':' Of all CSE seems to be required otherwise in some experiments','line_number':236,'multiline':False]['text':' serialized model is incorrect. As in it cannot be deserialized','line_number':237,'multiline':False]['text':' Rest are included as canonical optimizations that are not for inference','line_number':238,'multiline':False]['text':' Now we have:','line_number':252,'multiline':False]['text':' 1. Inserted quantized weights packed params','line_number':253,'multiline':False]['text':' 2. Inserted packed params to module','line_number':254,'multiline':False]['text':' 3. Inserted quantized op','line_number':255,'multiline':False]['text':' The next thing we need is:','line_number':256,'multiline':False]['text':' 1. Replicate this method in quantize_forward','line_number':257,'multiline':False]['text':' 2. Remove SetAttr for fp weights that are reset by quantize_forward','line_number':258,'multiline':False]['text':' 3. Remove SetAttr node which will subsequently optimize away the nodes','line_number':259,'multiline':False]['text':'    producing packed_params','line_number':260,'multiline':False]['text':' 4. Modify quantized_forward to remove all the nodes except for SetAttrs','line_number':261,'multiline':False]['text':' removeWeightSetAttrs(module, quantized_method_name);','line_number':263,'multiline':False]['text':' Removing packed params is not sufficient since that does not do DCE','line_number':267,'multiline':False]['text':' for observer node's getatts and callmethods because callmethods have side','line_number':268,'multiline':False]['text':' effects','line_number':269,'multiline':False]['text':' This step removed the return output from the graph and subsequent','line_number':271,'multiline':False]['text':' DCE removes all the ops. After that only remaining things should be','line_number':272,'multiline':False]['text':' packed_params','line_number':273,'multiline':False]['text':' namespace jit','line_number':278,'multiline':False]['text':' namespace torch','line_number':279,'multiline':False]