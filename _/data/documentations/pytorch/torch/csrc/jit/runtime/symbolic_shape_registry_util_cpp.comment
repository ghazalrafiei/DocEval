['text':' clang-format off','line_number':11,'multiline':False]['text':' TODO: uncomment when we properly support pow','line_number':42,'multiline':False]['text':' "aten::pow.Tensor_Tensor(Tensor self, Tensor exponent) -> Tensor",','line_number':43,'multiline':False]['text':' "aten::pow.Scalar(Scalar self, Tensor exponent) -> Tensor",','line_number':44,'multiline':False]['text':' TODO: support clamp_min, clamp_max','line_number':45,'multiline':False]['text':' "aten::masked_fill.Scalar(Tensor self, Tensor mask, Scalar value) -> Tensor",','line_number':46,'multiline':False]['text':' "aten::masked_fill.Tensor(Tensor self, Tensor mask, Tensor value) -> Tensor", TODO: requires 0-dim Tensor','line_number':47,'multiline':False]['text':' "aten::remainder.Scalar(Tensor self, Scalar other) -> Tensor",','line_number':48,'multiline':False]['text':' TODO: uncomment once we can handle rand+broadcasts','line_number':49,'multiline':False]['text':' "aten::rand_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor",','line_number':50,'multiline':False]['text':' TODO: enable other min/max variants, operators that can be both','line_number':113,'multiline':False]['text':' elementwise or reductions:','line_number':114,'multiline':False]['text':' TODO: enable slice, shape inference is not implemented for this op yet','line_number':121,'multiline':False]['text':' clang-format on','line_number':123,'multiline':False]['text':' namespace torch::jit','line_number':127,'multiline':False]