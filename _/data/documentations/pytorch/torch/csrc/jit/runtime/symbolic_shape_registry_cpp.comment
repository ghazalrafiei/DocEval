['text':' split here to satisfy MSVC++','line_number':18,'multiline':False]['text':' https://docs.microsoft.com/en-us/cpp/error-messages/compiler-errors-1/compiler-error-c2026?view=msvc-170','line_number':19,'multiline':False]['text':' mapping function schema to shape compute graphs allows multiple functions to','line_number':43,'multiline':False]['text':' share the same shape compute graph, which is memory efficient and also will','line_number':44,'multiline':False]['text':' help speed up shape analysis by caching the result of running consecutive ops','line_number':45,'multiline':False]['text':' for a particular set of inputs with the same graph, e.g. running a series','line_number':46,'multiline':False]['text':' of pointwise ops','line_number':47,'multiline':False]['text':' we need a map from schema to shape compute graph, because the aten schema','line_number':48,'multiline':False]['text':' is not recoverable from the shape compute graph, since the shape compute','line_number':49,'multiline':False]['text':' graph replaces Tensor inputs with List[int] and there are operators like Conv','line_number':50,'multiline':False]['text':' which natively have List[int] inputs','line_number':51,'multiline':False]['text':' TODO: consider storing shape compute graph directly on operator,','line_number':52,'multiline':False]['text':' and merge into native_functions.yaml','line_number':53,'multiline':False]['text':' wrapped in function so that operators get registered before map is','line_number':55,'multiline':False]['text':' initialized','line_number':56,'multiline':False]['text':' Conditionally defined ops not yet supported in python serialized','line_number':57,'multiline':False]['text':' operators','line_number':58,'multiline':False]['text':' clang-format off','line_number':60,'multiline':False]['text':' clang-format on','line_number':67,'multiline':False]['text':' CompilationUnit that holds all these Functions and keeps them alive.','line_number':77,'multiline':False]['text':' Need to check that all args are the same except for the first, which','line_number':86,'multiline':False]['text':' is almost the same except for the Alias info','line_number':87,'multiline':False]['text':' Could use alias db here as well but would have to warn because it's','line_number':142,'multiline':False]['text':' imprecise','line_number':143,'multiline':False]['text':' allow extra unused arguments to map multiple functions to e.g. unary','line_number':164,'multiline':False]['text':' ATEN operators can return multiple unboxed values, this in contrast to','line_number':225,'multiline':False]['text':' functions defined in TorchScript or User-Registered Operators','line_number':226,'multiline':False]['text':' Which must use a Tuple','line_number':227,'multiline':False]['text':' Here, modify the shape graph of aten operators with multiple outputs','line_number':228,'multiline':False]['text':' so that they correspond to each other','line_number':229,'multiline':False]['text':' NB: we lint the shape functions registered in source','line_number':265,'multiline':False]['text':' in a test file','line_number':266,'multiline':False]['text':' LintShapeComputeGraph(schema_string, graph);','line_number':267,'multiline':False]['text':' allow extra unused arguments to map multiple functions to e.g. unary','line_number':271,'multiline':False]['text':' Register the inplace variant if any for functions with common shape forms','line_number':319,'multiline':False]['text':' Now register the bounded schemas','line_number':339,'multiline':False]['text':' Reset the cache and compilation unit so that we don't get weird errors','line_number':371,'multiline':False]['text':' in later tests when one of the shape functions is invalid.','line_number':372,'multiline':False]['text':' anonymous namespace','line_number':378,'multiline':False]['text':' TODO: other checks ? list ops which we don't symbolically optimize, etc ?','line_number':445,'multiline':False]['text':' namespace torch::jit','line_number':448,'multiline':False]