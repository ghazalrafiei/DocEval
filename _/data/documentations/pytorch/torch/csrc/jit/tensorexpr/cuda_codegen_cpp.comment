['text':' A RAII wrapper to manage a variable and name pair in the look-up table.','line_number':29,'multiline':False]['text':' TODO: move this to a more shared place.','line_number':30,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':99,'multiline':False]['text':' TODO: This isn't right if there's a thread index at a higher level','line_number':101,'multiline':False]['text':' than this.','line_number':102,'multiline':False]['text':' Recurse first.','line_number':120,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':130,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':142,'multiline':False]['text':' extents must be positive so if the current extent is 1 then even if the','line_number':146,'multiline':False]['text':' stop is symbolic it's the max.','line_number':147,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':159,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':171,'multiline':False]['text':' extents must be positive so if the current extent is 1 then even if the','line_number':175,'multiline':False]['text':' stop is symbolic it's the max.','line_number':176,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':186,'multiline':False]['text':' TODO: this should be merged with the storage flattener.','line_number':188,'multiline':False]['text':' TODO: handle dynamic shapes here.','line_number':203,'multiline':False]['text':' do nothing','line_number':221,'multiline':False]['text':' get type of resulting expression.','line_number':250,'multiline':False]['text':' since kAbs's func_name is `abs`, prefix `f` for floating point','line_number':261,'multiline':False]['text':' TODO: find a better metric in using ldg or not. Support different dtypes.','line_number':283,'multiline':False]['text':' Detects whether the load target is also a store target.','line_number':284,'multiline':False]['text':' TODO: this is currently too wide. It detects whether a store-target','line_number':285,'multiline':False]['text':' exists within the program. In fact, this check is only necessary within a','line_number':286,'multiline':False]['text':' kernel.','line_number':287,'multiline':False]['text':' There's no __ldg overload for bool or half.','line_number':295,'multiline':False]['text':' Cuda __ldg can only be applied on read-only buffers.','line_number':300,'multiline':False]['text':' TODO: maybe this should be a more shared location?','line_number':307,'multiline':False]['text':' TODO: investigate how "ExprPtr" can be implicitly converted to "ExprHandle"','line_number':308,'multiline':False]['text':' as a bool.','line_number':309,'multiline':False]['text':' The fast path. Checks if the pointers are the same.','line_number':311,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':322,'multiline':False]['text':' Thread locals never need to be atomic.','line_number':355,'multiline':False]['text':' TODO: this checks that the metavars occur directly as an index, but this','line_number':383,'multiline':False]['text':' is pessimistic, blockIdx.x + 1 is fine too if there is no overlapping.','line_number':384,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':385,'multiline':False]['text':' All metavars accounted for.','line_number':394,'multiline':False]['text':' atomicAdd only works on global and shared memory','line_number':425,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':490,'multiline':False]['text':' Look at the declaration of this variable for more details.','line_number':494,'multiline':False]['text':' also check indices','line_number':510,'multiline':False]['text':' We just did the prioritize load, let's fold in the Cast.','line_number':542,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':550,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':572,'multiline':False]['text':' TODO: For now, we are not moving the loads with the IfThenElse.','line_number':622,'multiline':False]['text':' Eventually, we should switch to a more generic structure like:','line_number':623,'multiline':False]['text':' int v2 = IfThenElse(cond, true_v, false_v) + 2 ->','line_number':624,'multiline':False]['text':'','line_number':625,'multiline':False]['text':' int v;','line_number':626,'multiline':False]['text':' if (cond) {','line_number':627,'multiline':False]['text':'   v = true_v;','line_number':628,'multiline':False]['text':' } else {','line_number':629,'multiline':False]['text':'   v = false_v;','line_number':630,'multiline':False]['text':' }','line_number':631,'multiline':False]['text':' int v2 = v + 2;','line_number':632,'multiline':False]['text':' Extents must be positive, assume >= 1.','line_number':683,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':684,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':692,'multiline':False]['text':' Extents must be positive, assume >= 1.','line_number':702,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':703,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':711,'multiline':False]['text':' Recurse into body block.','line_number':716,'multiline':False]['text':' pop the internal reach off the stack.','line_number':719,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':720,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':733,'multiline':False]['text':' Here's we're slicing the Block's contents into segments that should have','line_number':744,'multiline':False]['text':' the same launch reach. Segments are comprised of all statements that aren't','line_number':745,'multiline':False]['text':' loops - which are their own segments. Some operations, such as threading','line_number':746,'multiline':False]['text':' and memory ops should never be masked and so also get their own segment.','line_number':747,'multiline':False]['text':' Likewise, Allocate and Free should never be masked.','line_number':754,'multiline':False]['text':' If the current stmt *was* a loop, it's a segment boundary.','line_number':759,'multiline':False]['text':' if the current segment should not be masked, it's a segment boundary on','line_number':765,'multiline':False]['text':' the far side as well.','line_number':766,'multiline':False]['text':' We are max extent in all dimensions, so need no masks at this level.','line_number':776,'multiline':False]['text':' flatten inner segments.','line_number':778,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':779,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':790,'multiline':False]['text':' We never mask loops, they'll mask their contents.','line_number':794,'multiline':False]['text':' If we get here, we must mask since we're not full reach and our direct','line_number':801,'multiline':False]['text':' child isn't a For.','line_number':802,'multiline':False]['text':' threads inside blocks.','line_number':804,'multiline':False]['text':' Mask it against the current dimensions.','line_number':809,'multiline':False]['text':' Mask it against the current dimensions.','line_number':822,'multiline':False]['text':' TODO: handle multiple kernels.','line_number':879,'multiline':False]['text':' TODO: handle dynamic dimension.','line_number':880,'multiline':False]['text':' TODO: call nvrtc.','line_number':881,'multiline':False]['text':' TODO: merge HasRand with CudaAnalysis.','line_number':882,'multiline':False]['text':' Check whether the statement uses the Half type, if so add the','line_number':894,'multiline':False]['text':' half_support_literal.','line_number':895,'multiline':False]['text':' CUDA has a default limit of threads per block (=flat work group size)','line_number':924,'multiline':False]['text':' of 1024, but ROCm uses 256 by default. At the time of writing','line_number':925,'multiline':False]['text':' (#45506), I am unaware of a stricter limit that TensorExpr imposes','line_number':926,'multiline':False]['text':' (maybe for perf),so I use 1024 as maximum flat work group size.','line_number':927,'multiline':False]['text':' We put a minimum value of 1, this is also used by hip (ROCm 3.8) in','line_number':928,'multiline':False]['text':' the __launch_bound__ implementation. The arguments for the attribute','line_number':929,'multiline':False]['text':' are (min, max), for details see the documentation at','line_number':930,'multiline':False]['text':' https://clang.llvm.org/docs/AttributeReference.html#amdgpu-flat-work-group-size','line_number':931,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':935,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':949,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':951,'multiline':False]['text':' TODO: switch to kUint64 when it is available.','line_number':954,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':968,'multiline':False]['text':' The registerizer might insert half-type scalars, we don't want this.','line_number':988,'multiline':False]['text':' Check that all block extents had been set.','line_number':999,'multiline':False]['text':' Precompute block and thread extents for call_with_numel().  If','line_number':1008,'multiline':False]['text':' precomputation can't be done (block/thread extents aren't','line_number':1009,'multiline':False]['text':' constant), then disallow call_with_numel.','line_number':1010,'multiline':False]['text':' We assume block_extents[0] is output.numel()/thread_block_size_.','line_number':1024,'multiline':False]['text':' Disable call_with_numel.','line_number':1027,'multiline':False]['text':' Build an LLVM based eval expression for the extents','line_number':1031,'multiline':False]['text':' We need to extract the args that are used in the thread and block extents','line_number':1035,'multiline':False]['text':' from bufferArgs and only use those for the `ExprEval` below. Without this,','line_number':1036,'multiline':False]['text':' bufferArgs might contain arbitrary types that are not handled by LLVM and','line_number':1037,'multiline':False]['text':' hence would result in an error.','line_number':1038,'multiline':False]['text':' In CUDA we need to pass pointers to pointers for buffers, thus we need to','line_number':1105,'multiline':False]['text':' go over args and add an extra indirection for such non-scalar','line_number':1106,'multiline':False]['text':' arguments.','line_number':1107,'multiline':False]['text':' Why? See some details here:','line_number':1108,'multiline':False]['text':' https://stackoverflow.com/questions/34388712/cannot-understand-how-jcuda-culaunchkernel-work','line_number':1109,'multiline':False]['text':' NOLINTNEXTLINE: const_cast','line_number':1113,'multiline':False]['text':' TODO: move as much of this into the constructors.','line_number':1146,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1156,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1158,'multiline':False]['text':' evaluate all the block/thread extents into values','line_number':1161,'multiline':False]['text':' TODO: eventually, codegen these calculations and make them part of the','line_number':1162,'multiline':False]['text':' module.','line_number':1163,'multiline':False]['text':' invocation of block_extents_eval_ isn't thread safe and this function','line_number':1178,'multiline':False]['text':' may be invoked by multiple threads','line_number':1179,'multiline':False]['text':' Skip launching the kernel if there are no elements to process.','line_number':1197,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1204,'multiline':False]['text':' If the kernel has a rand call in it, add two extra arguments for random','line_number':1206,'multiline':False]['text':' seed and offset.','line_number':1207,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1211,'multiline':False]['text':' In CUDA we need to pass pointers to pointers for buffers, thus we need to','line_number':1214,'multiline':False]['text':' go over raw_args and add an extra indirection for such non-scalar','line_number':1215,'multiline':False]['text':' arguments.','line_number':1216,'multiline':False]['text':' Why? See some details here:','line_number':1217,'multiline':False]['text':' https://stackoverflow.com/questions/34388712/cannot-understand-how-jcuda-culaunchkernel-work','line_number':1218,'multiline':False]['text':' TODO: total hack. Switch to numel when it is available.','line_number':1228,'multiline':False]['text':' Launch the kernels','line_number':1246,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1273,'multiline':False]['text':' Note: hacked at::DeviceGuard since at::DeviceGuard was failing to work','line_number':1299,'multiline':False]['text':' properly in some scenarios','line_number':1300,'multiline':False]['text':' Acquires device and NVRTC properties (for compile arch and occupancy','line_number':1305,'multiline':False]['text':' calculations)','line_number':1306,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1307,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1309,'multiline':False]['text':' Creates the NVRTC program','line_number':1314,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1315,'multiline':False]['text':' CUDA 11.1 allows going directly to SASS (sm_) instead of PTX (compute_)','line_number':1328,'multiline':False]['text':' which gives better backwards compatibility to work on older driver,','line_number':1329,'multiline':False]['text':' (since older driver doesn't necessarily recognize PTX emitted by new','line_number':1330,'multiline':False]['text':' toolkit);','line_number':1331,'multiline':False]['text':' Meanwhile, for forward compatibility (future device with','line_number':1332,'multiline':False]['text':' `compile_to_sass==false`), since SASS are not necessarily compatible,','line_number':1333,'multiline':False]['text':' we fallback to PTX instead.','line_number':1334,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1340,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1347,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1350,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1362,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1364,'multiline':False]['text':' compile_to_sass determines whether we are generating SASS or PTX, hence','line_number':1367,'multiline':False]['text':' the different API.','line_number':1368,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':1382,'multiline':False]['text':' namespace torch::jit::tensorexpr','line_number':1397,'multiline':False]