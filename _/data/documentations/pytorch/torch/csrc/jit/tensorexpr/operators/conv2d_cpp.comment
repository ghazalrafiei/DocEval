['text':' TODO','line_number':54,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':81,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':88,'multiline':False]['text':' TODO','line_number':126,'multiline':False]['text':' namespace','line_number':150,'multiline':False]['text':' Do not rewrite for cases where native is faster than mkldnn','line_number':341,'multiline':False]['text':' Conditions are from: aten/src/ATen/native/Convolution.cpp:use_mkldnn','line_number':342,'multiline':False]['text':' Generate TE for depthwise convolutions.','line_number':377,'multiline':False]['text':' Once we have a performant TE representation for conv2d, we could use it','line_number':384,'multiline':False]['text':' here instead of the external call!','line_number':385,'multiline':False]['text':' namespace tensorexpr','line_number':492,'multiline':False]['text':' namespace jit','line_number':493,'multiline':False]['text':' namespace torch','line_number':494,'multiline':False]