['text':' TODO: remove, debugging only','line_number':17,'multiline':False]['text':' Returns the "map size" for this run, which is the common size for all','line_number':27,'multiline':False]['text':' intermediate tensors.','line_number':28,'multiline':False]['text':' TODO: this keeps reallocating map_size at every iteration, but we know','line_number':33,'multiline':False]['text':' exactly how much storage do we need, so this could be fixed in-place at','line_number':34,'multiline':False]['text':' every step. We're just missing a few functions for ATen, but the fix','line_number':35,'multiline':False]['text':' should be straightforward.','line_number':36,'multiline':False]['text':' Note: left unitialized since empty shape is broadcastable to any shape','line_number':37,'multiline':False]['text':' Tries to determine a map size for the instantiated kernel (see above)','line_number':69,'multiline':False]['text':' Short-circuits on size mismatch','line_number':73,'multiline':False]['text':' Note: this checks that group_map_size is defined AND equal to map_size','line_number':89,'multiline':False]['text':' Arguments are expanded to a common shape, referred to as the "map size,"','line_number':98,'multiline':False]['text':' (see above).','line_number':99,'multiline':False]['text':' Note: Arguments are mutated by this call, although map_size is restored','line_number':100,'multiline':False]['text':' to its original value.','line_number':101,'multiline':False]['text':'dry_run=','line_number':140,'multiline':True]['text':' Note: assumes that inputs are 32-bit addressable','line_number':143,'multiline':False]['text':' Note: Assumes that after at::chunk, all inputs are the same size','line_number':153,'multiline':False]['text':' Tries to compress sizes and strides according to cont. Emits the result t','line_number':163,'multiline':False]['text':' c_sizes, c_strides and throws an error on failure (if can't compress)','line_number':164,'multiline':False]['text':' Launches the requested fusion on the given device with the given inputs.','line_number':191,'multiline':False]['text':' Output pointers are stored in outputs (to be put on the stack later).','line_number':192,'multiline':False]['text':' Fails if fusion and given inputs disagree','line_number':199,'multiline':False]['text':' Computes number of flattened inputs and outputs','line_number':202,'multiline':False]['text':' Fails if the elements of the first (any) tensor are not expressable as','line_number':210,'multiline':False]['text':' a 32-bit integer.','line_number':211,'multiline':False]['text':' Note: this code assumes that inputs are 32-bit addressable','line_number':212,'multiline':False]['text':' Note: this code assumes that all inputs are of the same size','line_number':213,'multiline':False]['text':' Computes map_size, numel from the first input','line_number':216,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':218,'multiline':False]['text':' compute number of scalar inputs and convert them to float','line_number':230,'multiline':False]['text':' Computes the storage needed to store TensorInfo structs for inputs and','line_number':238,'multiline':False]['text':' outputs.','line_number':239,'multiline':False]['text':' A vector of arguments to the kernel (numel, *input_desc_s, *output_desc_s)','line_number':248,'multiline':False]['text':' NOTE: this is the compressed dim','line_number':258,'multiline':False]['text':' We'd overflow the space otherwise','line_number':259,'multiline':False]['text':' Asserts that t's dims can be compressed in the same way as in desc','line_number':268,'multiline':False]['text':' (that's what the kernel assumes), and appends it to the arguments vector.','line_number':269,'multiline':False]['text':' Adds (flattened) input arguments','line_number':274,'multiline':False]['text':' Adds scalar arguments','line_number':291,'multiline':False]['text':' Adds (flattened) output arguments','line_number':296,'multiline':False]['text':' because the concatenated_output stays live, the underlying data','line_number':313,'multiline':False]['text':' in this view remains live through the end of this function','line_number':314,'multiline':False]['text':' so there is not need to hold onto this tensor','line_number':315,'multiline':False]['text':' Skip launching the kernel for zero-element tensor inputs','line_number':322,'multiline':False]['text':' launches are skipped, empty zero-sized output is returned','line_number':323,'multiline':False]['text':' Short-circuits if fusion isn't enabled','line_number':330,'multiline':False]['text':' Acquires the FusionSpec','line_number':334,'multiline':False]['text':' Acquires inputs from stack','line_number':338,'multiline':False]['text':' we know that tensor inputs are first','line_number':342,'multiline':False]['text':' Determines device to dispatch to.','line_number':351,'multiline':False]['text':' If there's a device mismatch in the inputs or if one of the input is a','line_number':353,'multiline':False]['text':' sparse tensor, we use the fallback (which should give a nice error','line_number':354,'multiline':False]['text':' message).','line_number':355,'multiline':False]['text':' Sparse tensor could not by supported by CUDA fusion, so we bail out.','line_number':357,'multiline':False]['text':' Attempts to run fallback if device fusion is disabled','line_number':363,'multiline':False]['text':' Validates sizes and expands inputs as needed','line_number':371,'multiline':False]['text':' Tries to run fallback if map size can't be computed','line_number':374,'multiline':False]['text':'dry_run=','line_number':382,'multiline':True]['text':' Retrieves the kernel, compiling (and caching) if necessary','line_number':384,'multiline':False]['text':' Launches fusion','line_number':398,'multiline':False]['text':' Updates stack','line_number':402,'multiline':False]['text':' namespace fuser','line_number':412,'multiline':False]['text':' namespace jit','line_number':413,'multiline':False]['text':' namespace torch','line_number':414,'multiline':False]