['text':' namespace','line_number':31,'multiline':False]['text':' Counter for number of kernels compiled, used for debugging and','line_number':62,'multiline':False]['text':' creating arbitrary kernel names.','line_number':63,'multiline':False]['text':' If the given node is used once by a chunk node, returns that node.','line_number':79,'multiline':False]['text':' Returns nullptr otherwise.','line_number':80,'multiline':False]['text':' We only have as many chunk descriptors as tensor inputs,','line_number':93,'multiline':False]['text':' furthermore we know that the tensor inputs are in the','line_number':94,'multiline':False]['text':' beginning of the fusion group's inputs.','line_number':95,'multiline':False]['text':' Run a DFS traversal to find all inputs that affect a given output value','line_number':108,'multiline':False]['text':' Here we assume that only tensor inputs are used in','line_number':117,'multiline':False]['text':' the computation of the outputs.','line_number':118,'multiline':False]['text':' This is currently true, as the only inputs will be','line_number':119,'multiline':False]['text':' sizes (for _grad_sum_to_size as the derivative','line_number':120,'multiline':False]['text':' of broadcasts), which will only be used after','line_number':121,'multiline':False]['text':' the fusion kernel, and Tensors.','line_number':122,'multiline':False]['text':' This needs to be revisited when you start allowing','line_number':123,'multiline':False]['text':' other things e.g. nonconstant scalars.','line_number':124,'multiline':False]['text':'bool inserted = ','line_number':131,'multiline':True]['text':' Convert Value* into offsets into the graph's input list','line_number':137,'multiline':False]['text':' Performs "upfront" compilation where storage is known but shapes are not.','line_number':166,'multiline':False]['text':' Currently identifies how to expand all tensors so that all intermediate','line_number':167,'multiline':False]['text':' tensors are the same shape, simplifying code generation.','line_number':168,'multiline':False]['text':' Broadcast groups and chunks are identified without shape information','line_number':169,'multiline':False]['text':' using logical properties of how each works. In particular, tensors','line_number':170,'multiline':False]['text':' are always expandable to the outputs of pointwise operations they','line_number':171,'multiline':False]['text':' or their descendants are involved in, which means that in a DAG of','line_number':172,'multiline':False]['text':' pointwise operations all tensors are expandable to the (single) output.','line_number':173,'multiline':False]['text':' Note: The logic is slightly complicated by concatenation and chunking.','line_number':174,'multiline':False]['text':' Don't re-register the fusion if we can use a pre-existing one','line_number':183,'multiline':False]['text':' Unconditionally create and register the fusion','line_number':189,'multiline':False]['text':' This is necessary to support our global disable fusions flag: if someone','line_number':190,'multiline':False]['text':' runs some code under no-fusions mode and then runs some code with fusions','line_number':191,'multiline':False]['text':' enabled, the second time around the returned spec from the cache should','line_number':192,'multiline':False]['text':' be a valid spec (must have had upfrontCompilation run on it).','line_number':193,'multiline':False]['text':' TODO: can't get rid of this use of TensorType','line_number':214,'multiline':False]['text':' until we switch to ProfilingGraphExecutor, so we don't have to','line_number':215,'multiline':False]['text':' run PropagateInputShapes below','line_number':216,'multiline':False]['text':' TODO: nDim is bad, as it is collapsed','line_number':221,'multiline':False]['text':' Creates chunk and flattened input descriptions','line_number':226,'multiline':False]['text':' Creates output, concat, and flattened output descriptions','line_number':253,'multiline':False]['text':' Creates output description','line_number':258,'multiline':False]['text':' Creates concat and flattened output descriptions (relies on output desc)','line_number':270,'multiline':False]['text':' namespace fuser','line_number':300,'multiline':False]['text':' namespace jit','line_number':301,'multiline':False]['text':' namespace torch','line_number':302,'multiline':False]