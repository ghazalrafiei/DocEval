['text':' Assigns a "key" to the given fusion_group that it can use to run its','line_number':17,'multiline':False]['text':' fusion later (via runFusion() below).','line_number':18,'multiline':False]['text':' Runs the fusion corresponding to the given key on the inputs','line_number':21,'multiline':False]['text':' found on the stack. Outputs are placed on the same stack.','line_number':22,'multiline':False]['text':' In some cases a fusion cannot be run and a fallback path where','line_number':23,'multiline':False]['text':' PyTorch's interpreter runs the graph instead is attempted.','line_number':24,'multiline':False]['text':' True if the respective devices can fuse, false otherwise','line_number':27,'multiline':False]['text':' Sets whether fusion on the CPU is allowed (disabled by default due to','line_number':31,'multiline':False]['text':' flakiness)','line_number':32,'multiline':False]['text':' Sets whether fusion on CPU must use LLVM Codegen and not SimplieIREval','line_number':35,'multiline':False]['text':' Sets whether fusion on the GPU is allowed (enabled by default)','line_number':38,'multiline':False]['text':' Treats the given graph as a fusion group and launches it on the','line_number':41,'multiline':False]['text':' specified device with the given inputs.','line_number':42,'multiline':False]['text':' Returns the outputs.','line_number':43,'multiline':False]['text':' Treats the given graph as a fusion group and returns the generated code.','line_number':48,'multiline':False]['text':' namespace jit','line_number':55,'multiline':False]['text':' namespace torch','line_number':56,'multiline':False]