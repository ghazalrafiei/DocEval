['text':' Pickled objects are stored in a form compatible with Python pickling.','line_number':25,'multiline':False]['text':' In torchscript List[T]/Dict[K, V] are statically typed and contain','line_number':26,'multiline':False]['text':' dynamic type tags that allow T, K, and V to be recovered. But this','line_number':27,'multiline':False]['text':' info is not stored in the Python pickling information. However, we','line_number':28,'multiline':False]['text':' can recover this information from the static type of the top-level','line_number':29,'multiline':False]['text':' object being unpickled, because we have a record of the type of the','line_number':30,'multiline':False]['text':' objects it contains as attributes.','line_number':31,'multiline':False]['text':' `IfPossible` - we can only do this recovery when we have an object as','line_number':32,'multiline':False]['text':' the top-level unpickled thing (which is guaranteed for Modules, but','line_number':33,'multiline':False]['text':' not for torch.load/torch.save). Otherwise we do not know the types','line_number':34,'multiline':False]['text':' of the contained objects and cannot restore the tags.','line_number':35,'multiline':False]['text':' ensure we only scan each pointer value once, otherwise this','line_number':46,'multiline':False]['text':' can become exponential (and if we allow recursive data in the future,','line_number':47,'multiline':False]['text':' it would not terminiate).','line_number':48,'multiline':False]['text':' no op, there is nothing to tag','line_number':89,'multiline':False]['text':' TODO: Can this really show up though? :think:','line_number':92,'multiline':False]['text':' no op, there is nothing to tag','line_number':94,'multiline':False]['text':' no op, there is nothing to tag','line_number':98,'multiline':False]['text':' no op, there is nothing to tag','line_number':102,'multiline':False]['text':' TODO(gmagogsfm): Implement serialization/deserialization of Enum.','line_number':107,'multiline':False]['text':' specialized lists do not need their type refined, so we can exit','line_number':137,'multiline':False]['text':' early here','line_number':138,'multiline':False]['text':' in both cases the dynamic type is a class, and we are going to tag with','line_number':163,'multiline':False]['text':' the dynamic type','line_number':164,'multiline':False]['text':' note: intentionally using the dynamic type,','line_number':168,'multiline':False]['text':' the static type is potentially less accurate','line_number':169,'multiline':False]['text':' namespace','line_number':190,'multiline':False]['text':' See [type tag serialization]','line_number':213,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':223,'multiline':False]['text':' Pickle floats are big endian, so reverse the bytes','line_number':226,'multiline':False]['text':' Expect a PROTO opcode and protocol number at the start of blob','line_number':242,'multiline':False]['text':' emplace_back on bool vectors does not exist on some systems','line_number':273,'multiline':False]['text':' avoid it by calling push_back for bool','line_number':274,'multiline':False]['text':' note we cannot use toIntList, toDoubleList because during unpickling the','line_number':290,'multiline':False]['text':' lists are not yet tagged','line_number':291,'multiline':False]['text':' we only need one object, since tuples are not mutable.','line_number':305,'multiline':False]['text':' Mark location of the container ivalue in the stack','line_number':324,'multiline':False]['text':' Only read LONG1s with 8 as the length','line_number':349,'multiline':False]['text':' Module name, it's not needed for anything','line_number':533,'multiline':False]['text':' pop empty tuple, the actual action is stored in the globals_stack_','line_number':540,'multiline':False]['text':' because we have NEWOBJ do nothing, BUILD and REDUCE end up doing','line_number':543,'multiline':False]['text':' the same thing','line_number':544,'multiline':False]['text':' stack is: <functor_idx> <functor_arg>','line_number':547,'multiline':False]['text':' extract <functor_idx> and remove from the stack:','line_number':548,'multiline':False]['text':' stack is: <functor_arg>','line_number':557,'multiline':False]['text':' remap device location if it's not meta','line_number':575,'multiline':False]['text':' for torch.package logic where storage may be loaded already','line_number':582,'multiline':False]['text':' If there are no elements in the tensor, there's no point in','line_number':590,'multiline':False]['text':' reading a zero (0) byte file from the input stream and paying','line_number':591,'multiline':False]['text':' that cost.','line_number':592,'multiline':False]['text':'allocator=','line_number':600,'multiline':True]['text':'resizable=','line_number':601,'multiline':True]['text':' NB: we didn't set any allocator for the','line_number':601,'multiline':False]['text':' tensor','line_number':602,'multiline':False]['text':' At this OpCode, stack looks like','line_number':635,'multiline':False]['text':' | Stack Bottom |','line_number':636,'multiline':False]['text':' | ......       |','line_number':637,'multiline':False]['text':' | Dict         | -> (stack_size - 3)','line_number':638,'multiline':False]['text':' | Key          | -> (stack_size - 2)','line_number':639,'multiline':False]['text':' | Value        | -> (stack_size - 1)','line_number':640,'multiline':False]['text':' See [NOTE] skip_next_read_global','line_number':674,'multiline':False]['text':' Pass through to the correct handler','line_number':677,'multiline':False]['text':' Corresponds to the type of `Tensor` being unpickled','line_number':679,'multiline':False]['text':' TODO [unpickler refactor] __main__ isn't used by the pickler anymore, this','line_number':690,'multiline':False]['text':' is only here for bc-compatibility reasons','line_number':691,'multiline':False]['text':' Pop reduce arg off the stack','line_number':712,'multiline':False]['text':' If we haven't injected a custom way of retrieving types from','line_number':733,'multiline':False]['text':' names, use a barebones type parser.','line_number':734,'multiline':False]['text':' TODO: Use lookahead to avoid creating the tuple and immediately','line_number':741,'multiline':False]['text':' destroying it here','line_number':742,'multiline':False]['text':' Unpickle a list specialization (e.g. List[Tensor], List[int], ...)','line_number':759,'multiline':False]['text':' Pop reduce arg off the stack','line_number':761,'multiline':False]['text':' Unpickle a tensor','line_number':772,'multiline':False]['text':' Unpickle a Tensor with Python attributes or','line_number':778,'multiline':False]['text':' a Subclassed Tensor.','line_number':779,'multiline':False]['text':' collections.OrderedDict is used in tensor serialization for a tensor's','line_number':795,'multiline':False]['text':' backward hooks (but they are not actually saved with this Pickler)','line_number':796,'multiline':False]['text':' drop the Tuple that was argument to OrderedDict, and replace it','line_number':798,'multiline':False]['text':' with None OrderedDicts only appear in tensor deserialization and','line_number':799,'multiline':False]['text':' their value is never used','line_number':800,'multiline':False]['text':' Try to manually resolve several global enums','line_number':820,'multiline':False]['text':' NOTE: this does not put a global into the global table,','line_number':821,'multiline':False]['text':' like the other branches here because no REDUCE or BUILD will','line_number':822,'multiline':False]['text':' be called on this value. Instead, we just put it on the stack','line_number':823,'multiline':False]['text':' and return early','line_number':824,'multiline':False]['text':' Otherwise, global is a class/object type.','line_number':875,'multiline':False]['text':' backwards hooks is empty','line_number':974,'multiline':False]['text':' Handle if math_bits were pickled.','line_number':981,'multiline':False]['text':' See `args` of _reduce_ex_internal','line_number':982,'multiline':False]['text':' for a regular tensor (final else case).','line_number':983,'multiline':False]['text':' Tensors pickled before this patch didn't','line_number':984,'multiline':False]['text':' have this argument for storing MathBits,','line_number':985,'multiline':False]['text':' in that case, we do nothing.','line_number':986,'multiline':False]['text':' NOTE: `math_bits` is the 7th arg.','line_number':987,'multiline':False]['text':' NOTE: This is only meant for regular tensor and not quantized','line_number':988,'multiline':False]['text':'       which also has 7 args serialized.','line_number':989,'multiline':False]['text':' [NOTE] skip_next_read_global','line_number':1000,'multiline':False]['text':' When rebuilding Tensor with Python Attr or Subclassed Tensor,','line_number':1001,'multiline':False]['text':' we receive `(func, type(self), args, state)` on stack for','line_number':1002,'multiline':False]['text':' `rebuildTensorFromTypeV2`.','line_number':1003,'multiline':False]['text':' Thus next call to readGlobal corresponds to `func` which is','line_number':1004,'multiline':False]['text':' the function to rebuild the base tensor.','line_number':1005,'multiline':False]['text':' The call after `func` to readGlobal corresponds to `type` of the','line_number':1006,'multiline':False]['text':' Tensor where we raise warning if the type is not `torch.Tensor`.','line_number':1007,'multiline':False]['text':' args is a tuple with following data','line_number':1011,'multiline':False]['text':'  (function to rebuild base tensor, type of tensor,','line_number':1012,'multiline':False]['text':'   arguments to construct base tensor, Python State (as dict))','line_number':1013,'multiline':False]['text':' This calls the function to rebuild the','line_number':1023,'multiline':False]['text':' base tensor.','line_number':1024,'multiline':False]['text':' Eg. `rebuildTensor`, `rebuildSpareTensor`.','line_number':1025,'multiline':False]['text':' It is the same as how rref is unpickled in python,','line_number':1035,'multiline':False]['text':' see PyRRef::unpickle','line_number':1036,'multiline':False]['text':' const reference will extend the lifetime of the temporary variable','line_number':1045,'multiline':False]['text':' First, read any partial from buffer (may be 0).','line_number':1075,'multiline':False]['text':' We explicitly assume that sz > buffer_remaining_,','line_number':1076,'multiline':False]['text':' and that sz is never bigger than buffer_.size().','line_number':1077,'multiline':False]['text':' Full read into the buffer. The calls here all explicitly','line_number':1084,'multiline':False]['text':' assume that one buffer will be enough for any sz.','line_number':1085,'multiline':False]['text':' assignment (0'ed from read)','line_number':1092,'multiline':False]['text':' Read a number of bytes from the input stream','line_number':1096,'multiline':False]['text':' Fast-path: entirely in buffer.','line_number':1106,'multiline':False]['text':' If the string is smallish, do a full buffer read,','line_number':1111,'multiline':False]['text':' and read out of that buffer.','line_number':1112,'multiline':False]['text':' Otherwise, for larger strings, read what we can from','line_number':1116,'multiline':False]['text':' the buffer, and then read directly to the destination.','line_number':1117,'multiline':False]['text':' buffer_pos_ has no meaning with buffer_remaining_ == 0.','line_number':1130,'multiline':False]['text':' Pop all the list items off of the stack and append them to the list at','line_number':1174,'multiline':False]['text':' the corresponding MARK','line_number':1175,'multiline':False]['text':' Read a newline terminated string','line_number':1188,'multiline':False]['text':' read up to newline and we are done.','line_number':1197,'multiline':False]['text':' read whole buffer, refill','line_number':1204,'multiline':False]['text':' Simple check just in case there is no terminating '\n'','line_number':1206,'multiline':False]['text':' namespace torch::jit','line_number':1222,'multiline':False]