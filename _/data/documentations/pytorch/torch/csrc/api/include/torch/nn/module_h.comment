['text':'/ The base class for all modules in PyTorch.','line_number':22,'multiline':False]['text':'/','line_number':23,'multiline':False]['text':'/ \rst','line_number':24,'multiline':False]['text':'/ .. note::','line_number':25,'multiline':False]['text':'/   The design and implementation of this class is largely based on the Python','line_number':26,'multiline':False]['text':'/   API. You may want to consult the python documentation for','line_number':27,'multiline':False]['text':'/   :py:class:`pytorch:torch.nn.Module` for further clarification on certain','line_number':28,'multiline':False]['text':'/   methods or behavior.','line_number':29,'multiline':False]['text':'/ \endrst','line_number':30,'multiline':False]['text':'/','line_number':31,'multiline':False]['text':'/ A `Module` is an abstraction over the implementation of some function or','line_number':32,'multiline':False]['text':'/ algorithm, possibly associated with some persistent data. A `Module` may','line_number':33,'multiline':False]['text':'/ contain further `Module`s ("submodules"), each with their own','line_number':34,'multiline':False]['text':'/ implementation, persistent data and further submodules. `Module`s can thus','line_number':35,'multiline':False]['text':'/ be said to form a recursive tree structure. A `Module` is registered as a','line_number':36,'multiline':False]['text':'/ submodule to another `Module` by calling `register_module()`, typically from','line_number':37,'multiline':False]['text':'/ within a parent module's constructor.','line_number':38,'multiline':False]['text':'/','line_number':39,'multiline':False]['text':'/ A distinction is made between three kinds of persistent data that may be','line_number':40,'multiline':False]['text':'/ associated with a `Module`:','line_number':41,'multiline':False]['text':'/','line_number':42,'multiline':False]['text':'/ 1. *Parameters*: tensors that record gradients, typically weights updated','line_number':43,'multiline':False]['text':'/    during the backward step (e.g. the `weight` of a `Linear` module),','line_number':44,'multiline':False]['text':'/ 2. *Buffers*: tensors that do not record gradients, typically updated during','line_number':45,'multiline':False]['text':'/    the forward step, such as running statistics (e.g. `mean` and `variance`','line_number':46,'multiline':False]['text':'/    in the `BatchNorm` module),','line_number':47,'multiline':False]['text':'/ 3. Any additional state, not necessarily tensors, required for the','line_number':48,'multiline':False]['text':'/    implementation or configuration of a `Module`.','line_number':49,'multiline':False]['text':'/','line_number':50,'multiline':False]['text':'/ The first two kinds of state are special in that they may be registered','line_number':51,'multiline':False]['text':'/ with the `Module` system to allow convenient access and batch configuration.','line_number':52,'multiline':False]['text':'/ For example, registered parameters in any `Module` may be iterated over via','line_number':53,'multiline':False]['text':'/ the `parameters()` accessor. Further, changing the data type of a `Module`'s','line_number':54,'multiline':False]['text':'/ registered parameters can be done conveniently via `Module::to()`, e.g.','line_number':55,'multiline':False]['text':'/ `module->to(torch::kCUDA)` to move all parameters to GPU memory. Lastly,','line_number':56,'multiline':False]['text':'/ registered parameters and buffers are handled specially during a `clone()`','line_number':57,'multiline':False]['text':'/ operation, which performs a deepcopy of a cloneable `Module` hierarchy.','line_number':58,'multiline':False]['text':'/','line_number':59,'multiline':False]['text':'/ Parameters are registered with a `Module` via `register_parameter`. Buffers','line_number':60,'multiline':False]['text':'/ are registered separately via `register_buffer`. These methods are part of','line_number':61,'multiline':False]['text':'/ the public API of `Module` and are typically invoked from within a','line_number':62,'multiline':False]['text':'/ concrete `Module`s constructor.','line_number':63,'multiline':False]['text':'/ Tells the base `Module` about the name of the submodule.','line_number':77,'multiline':False]['text':'/ Constructs the module without immediate knowledge of the submodule's name.','line_number':80,'multiline':False]['text':'/ The name of the submodule is inferred via RTTI (if possible) the first','line_number':81,'multiline':False]['text':'/ time `.name()` is invoked.','line_number':82,'multiline':False]['text':'/ Returns the name of the `Module`.','line_number':91,'multiline':False]['text':'/','line_number':92,'multiline':False]['text':'/ A `Module` has an associated `name`, which is a string representation of','line_number':93,'multiline':False]['text':'/ the kind of concrete `Module` it represents, such as `"Linear"` for the','line_number':94,'multiline':False]['text':'/ `Linear` module. Under most circumstances, this name is automatically','line_number':95,'multiline':False]['text':'/ inferred via runtime type information (RTTI). In the unusual circumstance','line_number':96,'multiline':False]['text':'/ that you have this feature disabled, you may want to manually name your','line_number':97,'multiline':False]['text':'/ `Module`s by passing the string name to the `Module` base class'','line_number':98,'multiline':False]['text':'/ constructor.','line_number':99,'multiline':False]['text':'/ Performs a recursive deep copy of the module and all its registered','line_number':102,'multiline':False]['text':'/ parameters, buffers and submodules.','line_number':103,'multiline':False]['text':'/','line_number':104,'multiline':False]['text':'/ Optionally, this method sets the current device','line_number':105,'multiline':False]['text':'/ to the one supplied before cloning. If no device is given, each','line_number':106,'multiline':False]['text':'/ parameter and buffer will be moved to the device of its source.','line_number':107,'multiline':False]['text':'/','line_number':108,'multiline':False]['text':'/ \rst','line_number':109,'multiline':False]['text':'/ .. attention::','line_number':110,'multiline':False]['text':'/   Attempting to call the `clone()` method inherited from the base `Module`','line_number':111,'multiline':False]['text':'/   class (the one documented here) will fail. To inherit an actual','line_number':112,'multiline':False]['text':'/   implementation of `clone()`, you must subclass `Cloneable`. `Cloneable`','line_number':113,'multiline':False]['text':'/   is templatized on the concrete module type, and can thus properly copy a','line_number':114,'multiline':False]['text':'/   `Module`. This method is provided on the base class' API solely for an','line_number':115,'multiline':False]['text':'/   easier-to-use polymorphic interface.','line_number':116,'multiline':False]['text':'/ \endrst','line_number':117,'multiline':False]['text':'/ Applies the `function` to the `Module` and recursively to every submodule.','line_number':121,'multiline':False]['text':'/ The function must accept a `Module&`.','line_number':122,'multiline':False]['text':'/','line_number':123,'multiline':False]['text':'/ \rst','line_number':124,'multiline':False]['text':'/ .. code-block:: cpp','line_number':125,'multiline':False]['text':'/   MyModule module;','line_number':126,'multiline':False]['text':'/   module->apply([](nn::Module& module) {','line_number':127,'multiline':False]['text':'/     std::cout << module.name() << std::endl;','line_number':128,'multiline':False]['text':'/   });','line_number':129,'multiline':False]['text':'/ \endrst','line_number':130,'multiline':False]['text':'/ Applies the `function` to the `Module` and recursively to every submodule.','line_number':133,'multiline':False]['text':'/ The function must accept a `const Module&`.','line_number':134,'multiline':False]['text':'/','line_number':135,'multiline':False]['text':'/ \rst','line_number':136,'multiline':False]['text':'/ .. code-block:: cpp','line_number':137,'multiline':False]['text':'/   MyModule module;','line_number':138,'multiline':False]['text':'/   module->apply([](const nn::Module& module) {','line_number':139,'multiline':False]['text':'/     std::cout << module.name() << std::endl;','line_number':140,'multiline':False]['text':'/   });','line_number':141,'multiline':False]['text':'/ \endrst','line_number':142,'multiline':False]['text':'/ Applies the `function` to the `Module` and recursively to every submodule.','line_number':145,'multiline':False]['text':'/ The function must accept a `const std::string&` for the key of the module,','line_number':146,'multiline':False]['text':'/ and a `Module&`. The key of the module itself is the empty string. If','line_number':147,'multiline':False]['text':'/ `name_prefix` is given, it is prepended to every key as','line_number':148,'multiline':False]['text':'/ `<name_prefix>.<key>` (and just `name_prefix` for the module itself).','line_number':149,'multiline':False]['text':'/','line_number':150,'multiline':False]['text':'/ \rst','line_number':151,'multiline':False]['text':'/ .. code-block:: cpp','line_number':152,'multiline':False]['text':'/   MyModule module;','line_number':153,'multiline':False]['text':'/   module->apply([](const std::string& key, nn::Module& module) {','line_number':154,'multiline':False]['text':'/     std::cout << key << ": " << module.name() << std::endl;','line_number':155,'multiline':False]['text':'/   });','line_number':156,'multiline':False]['text':'/ \endrst','line_number':157,'multiline':False]['text':'/ Applies the `function` to the `Module` and recursively to every submodule.','line_number':162,'multiline':False]['text':'/ The function must accept a `const std::string&` for the key of the module,','line_number':163,'multiline':False]['text':'/ and a `const Module&`. The key of the module itself is the empty string.','line_number':164,'multiline':False]['text':'/ If `name_prefix` is given, it is prepended to every key as','line_number':165,'multiline':False]['text':'/ `<name_prefix>.<key>` (and just `name_prefix` for the module itself).','line_number':166,'multiline':False]['text':'/','line_number':167,'multiline':False]['text':'/ \rst','line_number':168,'multiline':False]['text':'/ .. code-block:: cpp','line_number':169,'multiline':False]['text':'/   MyModule module;','line_number':170,'multiline':False]['text':'/   module->apply([](const std::string& key, const nn::Module& module) {','line_number':171,'multiline':False]['text':'/     std::cout << key << ": " << module.name() << std::endl;','line_number':172,'multiline':False]['text':'/   });','line_number':173,'multiline':False]['text':'/ \endrst','line_number':174,'multiline':False]['text':'/ Applies the `function` to the `Module` and recursively to every submodule.','line_number':179,'multiline':False]['text':'/ The function must accept a `const std::shared_ptr<Module>&`.','line_number':180,'multiline':False]['text':'/','line_number':181,'multiline':False]['text':'/ \rst','line_number':182,'multiline':False]['text':'/ .. code-block:: cpp','line_number':183,'multiline':False]['text':'/   MyModule module;','line_number':184,'multiline':False]['text':'/   module->apply([](const std::shared_ptr<nn::Module>& module) {','line_number':185,'multiline':False]['text':'/     std::cout << module->name() << std::endl;','line_number':186,'multiline':False]['text':'/   });','line_number':187,'multiline':False]['text':'/ \endrst','line_number':188,'multiline':False]['text':'/ Applies the `function` to the `Module` and recursively to every submodule.','line_number':191,'multiline':False]['text':'/ The function must accept a `const std::string&` for the key of the module,','line_number':192,'multiline':False]['text':'/ and a `const std::shared_ptr<Module>&`. The key of the module itself is','line_number':193,'multiline':False]['text':'/ the empty string. If `name_prefix` is given, it is prepended to every key','line_number':194,'multiline':False]['text':'/ as','line_number':195,'multiline':False]['text':'/ `<name_prefix>.<key>` (and just `name_prefix` for the module itself).','line_number':196,'multiline':False]['text':'/','line_number':197,'multiline':False]['text':'/ \rst','line_number':198,'multiline':False]['text':'/ .. code-block:: cpp','line_number':199,'multiline':False]['text':'/   MyModule module;','line_number':200,'multiline':False]['text':'/   module->apply([](const std::string& key,','line_number':201,'multiline':False]['text':'/                    const std::shared_ptr<nn::Module>& module) {','line_number':202,'multiline':False]['text':'/     std::cout << key << ": " << module->name() << std::endl;','line_number':203,'multiline':False]['text':'/   });','line_number':204,'multiline':False]['text':'/ \endrst','line_number':205,'multiline':False]['text':'/ Returns the parameters of this `Module` and if `recurse` is true, also','line_number':210,'multiline':False]['text':'/ recursively of every submodule.','line_number':211,'multiline':False]['text':'/ Returns an `OrderedDict` with the parameters of this `Module` along with','line_number':214,'multiline':False]['text':'/ their keys, and if `recurse` is true also recursively of every submodule.','line_number':215,'multiline':False]['text':'/ Returns the buffers of this `Module` and if `recurse` is true, also','line_number':218,'multiline':False]['text':'/ recursively of every submodule.','line_number':219,'multiline':False]['text':'/ Returns an `OrderedDict` with the buffers of this `Module` along with','line_number':222,'multiline':False]['text':'/ their keys, and if `recurse` is true also recursively of every submodule.','line_number':223,'multiline':False]['text':'/ Returns the submodules of this `Module` (the entire submodule hierarchy)','line_number':226,'multiline':False]['text':'/ and if `include_self` is true, also inserts a `shared_ptr` to this module','line_number':227,'multiline':False]['text':'/ in the first position.','line_number':228,'multiline':False]['text':'/','line_number':229,'multiline':False]['text':'/ \rst','line_number':230,'multiline':False]['text':'/ .. warning::','line_number':231,'multiline':False]['text':'/   Only pass `include_self` as `true` if this `Module` is stored in a','line_number':232,'multiline':False]['text':'/   `shared_ptr`! Otherwise an exception will be thrown. You may still call','line_number':233,'multiline':False]['text':'/   this method with `include_self` set to false if your `Module` is not','line_number':234,'multiline':False]['text':'/   stored in a `shared_ptr`.','line_number':235,'multiline':False]['text':'/ \endrst','line_number':236,'multiline':False]['text':'/ Returns an `OrderedDict` of the submodules of this `Module` (the entire','line_number':239,'multiline':False]['text':'/ submodule hierarchy) and their keys, and if `include_self` is true, also','line_number':240,'multiline':False]['text':'/ inserts a `shared_ptr` to this module in the first position. If','line_number':241,'multiline':False]['text':'/ `name_prefix` is given, it is prepended to every key as','line_number':242,'multiline':False]['text':'/ `<name_prefix>.<key>` (and just `name_prefix` for the module itself).','line_number':243,'multiline':False]['text':'/','line_number':244,'multiline':False]['text':'/ \rst','line_number':245,'multiline':False]['text':'/ .. warning::','line_number':246,'multiline':False]['text':'/   Only pass `include_self` as `true` if this `Module` is stored in a','line_number':247,'multiline':False]['text':'/   `shared_ptr`! Otherwise an exception will be thrown. You may still call','line_number':248,'multiline':False]['text':'/   this method with `include_self` set to false if your `Module` is not','line_number':249,'multiline':False]['text':'/   stored in a `shared_ptr`.','line_number':250,'multiline':False]['text':'/ \endrst','line_number':251,'multiline':False]['text':'/ Returns the direct submodules of this `Module`.','line_number':256,'multiline':False]['text':'/ Returns an `OrderedDict` of the direct submodules of this `Module` and','line_number':259,'multiline':False]['text':'/ their keys.','line_number':260,'multiline':False]['text':'/ Enables "training" mode.','line_number':263,'multiline':False]['text':'/ Calls train(false) to enable "eval" mode.','line_number':266,'multiline':False]['text':'/ Do not override this method, override `train()` instead.','line_number':267,'multiline':False]['text':'/ True if the module is in training mode.','line_number':270,'multiline':False]['text':'/','line_number':271,'multiline':False]['text':'/ Every `Module` has a boolean associated with it that determines whether','line_number':272,'multiline':False]['text':'/ the `Module` is currently in *training* mode (set via `.train()`) or in','line_number':273,'multiline':False]['text':'/ *evaluation* (inference) mode (set via `.eval()`). This property is','line_number':274,'multiline':False]['text':'/ exposed via `is_training()`, and may be used by the implementation of a','line_number':275,'multiline':False]['text':'/ concrete module to modify its runtime behavior. See the `BatchNorm` or','line_number':276,'multiline':False]['text':'/ `Dropout` modules for examples of `Module`s that use different code paths','line_number':277,'multiline':False]['text':'/ depending on this property.','line_number':278,'multiline':False]['text':'/ Recursively casts all parameters to the given `dtype` and `device`.','line_number':281,'multiline':False]['text':'/','line_number':282,'multiline':False]['text':'/ If `non_blocking` is true and the source is in pinned memory and','line_number':283,'multiline':False]['text':'/ destination is on the GPU or vice versa, the copy is performed','line_number':284,'multiline':False]['text':'/ asynchronously with respect to the host. Otherwise, the argument has no','line_number':285,'multiline':False]['text':'/ effect.','line_number':286,'multiline':False]['text':'/ Recursively casts all parameters to the given dtype.','line_number':292,'multiline':False]['text':'/','line_number':293,'multiline':False]['text':'/ If `non_blocking` is true and the source is in pinned memory and','line_number':294,'multiline':False]['text':'/ destination is on the GPU or vice versa, the copy is performed','line_number':295,'multiline':False]['text':'/ asynchronously with respect to the host. Otherwise, the argument has no','line_number':296,'multiline':False]['text':'/ effect.','line_number':297,'multiline':False]['text':'/ Recursively moves all parameters to the given device.','line_number':300,'multiline':False]['text':'/','line_number':301,'multiline':False]['text':'/ If `non_blocking` is true and the source is in pinned memory and','line_number':302,'multiline':False]['text':'/ destination is on the GPU or vice versa, the copy is performed','line_number':303,'multiline':False]['text':'/ asynchronously with respect to the host. Otherwise, the argument has no','line_number':304,'multiline':False]['text':'/ effect.','line_number':305,'multiline':False]['text':'/ Recursively zeros out the `grad` value of each registered parameter.','line_number':308,'multiline':False]['text':'/ Attempts to cast this `Module` to the given `ModuleType`.','line_number':311,'multiline':False]['text':'/','line_number':312,'multiline':False]['text':'/ This method is useful when calling `apply()`.','line_number':313,'multiline':False]['text':'/ \rst','line_number':314,'multiline':False]['text':'/ .. code-block:: cpp','line_number':315,'multiline':False]['text':'/','line_number':316,'multiline':False]['text':'/   void initialize_weights(nn::Module& module) {','line_number':317,'multiline':False]['text':'/     torch::NoGradGuard no_grad;','line_number':318,'multiline':False]['text':'/     if (auto* linear = module.as<nn::Linear>()) {','line_number':319,'multiline':False]['text':'/       linear->weight.normal_(0.0, 0.02);','line_number':320,'multiline':False]['text':'/     }','line_number':321,'multiline':False]['text':'/   }','line_number':322,'multiline':False]['text':'/','line_number':323,'multiline':False]['text':'/   MyModule module;','line_number':324,'multiline':False]['text':'/   module->apply(initialize_weights);','line_number':325,'multiline':False]['text':'/ \endrst','line_number':326,'multiline':False]['text':'/ Attempts to cast this `Module` to the given `ModuleType`.','line_number':330,'multiline':False]['text':'/','line_number':331,'multiline':False]['text':'/ This method is useful when calling `apply()`.','line_number':332,'multiline':False]['text':'/ \rst','line_number':333,'multiline':False]['text':'/ .. code-block:: cpp','line_number':334,'multiline':False]['text':'/   void initialize_weights(nn::Module& module) {','line_number':335,'multiline':False]['text':'/     torch::NoGradGuard no_grad;','line_number':336,'multiline':False]['text':'/     if (auto* linear = module.as<nn::Linear>()) {','line_number':337,'multiline':False]['text':'/       linear->weight.normal_(0.0, 0.02);','line_number':338,'multiline':False]['text':'/     }','line_number':339,'multiline':False]['text':'/   }','line_number':340,'multiline':False]['text':'/','line_number':341,'multiline':False]['text':'/   MyModule module;','line_number':342,'multiline':False]['text':'/   module->apply(initialize_weights);','line_number':343,'multiline':False]['text':'/ \endrst','line_number':344,'multiline':False]['text':'/ Attempts to cast this `Module` to the given `ModuleType`.','line_number':348,'multiline':False]['text':'/','line_number':349,'multiline':False]['text':'/ This method is useful when calling `apply()`.','line_number':350,'multiline':False]['text':'/ \rst','line_number':351,'multiline':False]['text':'/ .. code-block:: cpp','line_number':352,'multiline':False]['text':'/','line_number':353,'multiline':False]['text':'/   void initialize_weights(nn::Module& module) {','line_number':354,'multiline':False]['text':'/     torch::NoGradGuard no_grad;','line_number':355,'multiline':False]['text':'/     if (auto* linear = module.as<nn::Linear>()) {','line_number':356,'multiline':False]['text':'/       linear->weight.normal_(0.0, 0.02);','line_number':357,'multiline':False]['text':'/     }','line_number':358,'multiline':False]['text':'/   }','line_number':359,'multiline':False]['text':'/','line_number':360,'multiline':False]['text':'/   MyModule module;','line_number':361,'multiline':False]['text':'/   module.apply(initialize_weights);','line_number':362,'multiline':False]['text':'/ \endrst','line_number':363,'multiline':False]['text':'/ Attempts to cast this `Module` to the given `ModuleType`.','line_number':369,'multiline':False]['text':'/','line_number':370,'multiline':False]['text':'/ This method is useful when calling `apply()`.','line_number':371,'multiline':False]['text':'/ \rst','line_number':372,'multiline':False]['text':'/ .. code-block:: cpp','line_number':373,'multiline':False]['text':'/','line_number':374,'multiline':False]['text':'/   void initialize_weights(nn::Module& module) {','line_number':375,'multiline':False]['text':'/     torch::NoGradGuard no_grad;','line_number':376,'multiline':False]['text':'/     if (auto* linear = module.as<nn::Linear>()) {','line_number':377,'multiline':False]['text':'/       linear->weight.normal_(0.0, 0.02);','line_number':378,'multiline':False]['text':'/     }','line_number':379,'multiline':False]['text':'/   }','line_number':380,'multiline':False]['text':'/','line_number':381,'multiline':False]['text':'/   MyModule module;','line_number':382,'multiline':False]['text':'/   module.apply(initialize_weights);','line_number':383,'multiline':False]['text':'/ \endrst','line_number':384,'multiline':False]['text':'/ Serializes the `Module` into the given `OutputArchive`.','line_number':390,'multiline':False]['text':'/','line_number':391,'multiline':False]['text':'/ If the `Module` contains unserializable submodules (e.g.','line_number':392,'multiline':False]['text':'/ `nn::Functional`), those submodules are skipped when serializing.','line_number':393,'multiline':False]['text':'/ Deserializes the `Module` from the given `InputArchive`.','line_number':396,'multiline':False]['text':'/','line_number':397,'multiline':False]['text':'/ If the `Module` contains unserializable submodules (e.g.','line_number':398,'multiline':False]['text':'/ `nn::Functional`), we don't check the existence of those submodules in the','line_number':399,'multiline':False]['text':'/ `InputArchive` when deserializing.','line_number':400,'multiline':False]['text':'/ Streams a pretty representation of the `Module` into the given `stream`.','line_number':403,'multiline':False]['text':'/ By default, this representation will be the name of the module (taken from','line_number':404,'multiline':False]['text':'/ `name()`), followed by a recursive pretty print of all of the `Module`'s','line_number':405,'multiline':False]['text':'/ submodules.','line_number':406,'multiline':False]['text':'/','line_number':407,'multiline':False]['text':'/ Override this method to change the pretty print. The input','line_number':408,'multiline':False]['text':'/ `stream` should be returned from the method, to allow easy chaining.','line_number':409,'multiline':False]['text':'/ Returns whether the `Module` is serializable.','line_number':412,'multiline':False]['text':'/ Registers a parameter with this `Module`.','line_number':415,'multiline':False]['text':'/','line_number':416,'multiline':False]['text':'/ A parameter should be any gradient-recording tensor used in the','line_number':417,'multiline':False]['text':'/ implementation of your `Module`. Registering it makes it available to','line_number':418,'multiline':False]['text':'/ methods such as `parameters()`, `clone()` or `to().`','line_number':419,'multiline':False]['text':'/','line_number':420,'multiline':False]['text':'/ Note that registering an undefined Tensor (e.g.','line_number':421,'multiline':False]['text':'/ `module.register_parameter("param", Tensor())`) is allowed, and is','line_number':422,'multiline':False]['text':'/ equivalent to `module.register_parameter("param", None)` in Python API.','line_number':423,'multiline':False]['text':'/','line_number':424,'multiline':False]['text':'/ \rst','line_number':425,'multiline':False]['text':'/ .. code-block:: cpp','line_number':426,'multiline':False]['text':'/','line_number':427,'multiline':False]['text':'/   MyModule::MyModule() {','line_number':428,'multiline':False]['text':'/     weight_ = register_parameter("weight", torch::randn({A, B}));','line_number':429,'multiline':False]['text':'/   }','line_number':430,'multiline':False]['text':'/ \endrst','line_number':431,'multiline':False]['text':'/ Registers a buffer with this `Module`.','line_number':437,'multiline':False]['text':'/','line_number':438,'multiline':False]['text':'/ A buffer is intended to be state in your module that does not record','line_number':439,'multiline':False]['text':'/ gradients, such as running statistics. Registering it makes it available','line_number':440,'multiline':False]['text':'/ to methods such as `buffers()`, `clone()` or `to().','line_number':441,'multiline':False]['text':'/','line_number':442,'multiline':False]['text':'/ \rst','line_number':443,'multiline':False]['text':'/ .. code-block:: cpp','line_number':444,'multiline':False]['text':'/','line_number':445,'multiline':False]['text':'/   MyModule::MyModule() {','line_number':446,'multiline':False]['text':'/     mean_ = register_buffer("mean", torch::empty({num_features_}));','line_number':447,'multiline':False]['text':'/   }','line_number':448,'multiline':False]['text':'/ \endrst','line_number':449,'multiline':False]['text':'/ Registers a submodule with this `Module`.','line_number':452,'multiline':False]['text':'/','line_number':453,'multiline':False]['text':'/ Registering a module makes it available to methods such as `modules()`,','line_number':454,'multiline':False]['text':'/ `clone()` or `to()`.','line_number':455,'multiline':False]['text':'/','line_number':456,'multiline':False]['text':'/ \rst','line_number':457,'multiline':False]['text':'/ .. code-block:: cpp','line_number':458,'multiline':False]['text':'/','line_number':459,'multiline':False]['text':'/   MyModule::MyModule() {','line_number':460,'multiline':False]['text':'/     submodule_ = register_module("linear", torch::nn::Linear(3, 4));','line_number':461,'multiline':False]['text':'/   }','line_number':462,'multiline':False]['text':'/ \endrst','line_number':463,'multiline':False]['text':'/ Registers a submodule with this `Module`.','line_number':469,'multiline':False]['text':'/','line_number':470,'multiline':False]['text':'/ This method deals with `ModuleHolder`s.','line_number':471,'multiline':False]['text':'/','line_number':472,'multiline':False]['text':'/ Registering a module makes it available to methods such as `modules()`,','line_number':473,'multiline':False]['text':'/ `clone()` or `to()`.','line_number':474,'multiline':False]['text':'/','line_number':475,'multiline':False]['text':'/ \rst','line_number':476,'multiline':False]['text':'/ .. code-block:: cpp','line_number':477,'multiline':False]['text':'/','line_number':478,'multiline':False]['text':'/   MyModule::MyModule() {','line_number':479,'multiline':False]['text':'/     submodule_ = register_module("linear", torch::nn::Linear(3, 4));','line_number':480,'multiline':False]['text':'/   }','line_number':481,'multiline':False]['text':'/ \endrst','line_number':482,'multiline':False]['text':'/ Replaces a registered submodule with this `Module`.','line_number':488,'multiline':False]['text':'/','line_number':489,'multiline':False]['text':'/ This takes care of the registration, if you used submodule members, you','line_number':490,'multiline':False]['text':'/ should','line_number':491,'multiline':False]['text':'  assign the submodule as well, i.e. use as','line_number':492,'multiline':False]['text':'/     module->submodule_ = module->replace_module("linear",','line_number':493,'multiline':False]['text':'/     torch::nn::Linear(3, 4));','line_number':494,'multiline':False]['text':'/ It only works when a module of the name is already registered.','line_number':495,'multiline':False]['text':'/','line_number':496,'multiline':False]['text':'/ This is useful for replacing a module after initialization, e.g.','line_number':497,'multiline':False]['text':'/ for finetuning.','line_number':498,'multiline':False]['text':'/ Replaces a registered submodule with this `Module`.','line_number':504,'multiline':False]['text':'/ This method deals with `ModuleHolder`s.','line_number':505,'multiline':False]['text':'/','line_number':506,'multiline':False]['text':'/ This takes care of the registration, if you used submodule members, you','line_number':507,'multiline':False]['text':'/ should','line_number':508,'multiline':False]['text':'  assign the submodule as well, i.e. use as','line_number':509,'multiline':False]['text':'/     module->submodule_ = module->replace_module("linear", linear_holder);','line_number':510,'multiline':False]['text':'/ It only works when a module of the name is already registered.','line_number':511,'multiline':False]['text':'/','line_number':512,'multiline':False]['text':'/ This is useful for replacing a module after initialization, e.g.','line_number':513,'multiline':False]['text':'/ for finetuning.','line_number':514,'multiline':False]['text':'/ Unregisters a submodule from this `Module`. If there is no such module','line_number':520,'multiline':False]['text':'/ with `name` an exception is thrown.','line_number':521,'multiline':False]['text':'/ The following three functions allow a module with default arguments in its','line_number':525,'multiline':False]['text':'/ forward method to be used in a Sequential module.','line_number':526,'multiline':False]['text':'/ You should NEVER override these functions manually. Instead, you should','line_number':527,'multiline':False]['text':'/ use the `FORWARD_HAS_DEFAULT_ARGS` macro.','line_number':528,'multiline':False]['text':'/ The registered parameters of this `Module`.','line_number':550,'multiline':False]['text':'/ Inorder to access parameters_ in ParameterDict and ParameterList','line_number':551,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-non-private-member-variables-in-classes)','line_number':552,'multiline':False]['text':' Friend classes.','line_number':556,'multiline':False]['text':'/ Pretty prints the given `Module` into the `ostream`.','line_number':564,'multiline':False]['text':' data parallel using this method to configure gradient edges during the','line_number':569,'multiline':False]['text':' replicate step.','line_number':570,'multiline':False]['text':' Private methods.','line_number':577,'multiline':False]['text':'/ Used in the implementation of `Cloneable`.','line_number':579,'multiline':False]['text':'/ The implementation of the various `to()` methods.','line_number':582,'multiline':False]['text':'/ Implements pretty printing the module hierarchy.','line_number':586,'multiline':False]['text':'/ Applies the `function` to every submodule recursively, starting at this','line_number':591,'multiline':False]['text':'/ `Module`'s children (thus not including the module itself).','line_number':592,'multiline':False]['text':'/ Returns a shared_ptr to `this` in a safe (checked) way.','line_number':597,'multiline':False]['text':'/ The registered buffers of this `Module`.','line_number':600,'multiline':False]['text':'/ The registered (direct) submodules of this `Module`.','line_number':603,'multiline':False]['text':'/ The module's name (e.g. "LSTM").','line_number':606,'multiline':False]['text':'/ Whether the module is in training mode.','line_number':609,'multiline':False]['text':'/ Serialize a `Module` pointer into an `OutputArchive`.','line_number':613,'multiline':False]['text':'/ Deserializes a `Module` from an `InputArchive`.','line_number':618,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ nn::Module ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':623,'multiline':False]['text':' Use the contained type of the `ModuleHolder`, e.g. `LinearImpl` for','line_number':627,'multiline':False]['text':' `Linear`, since `LinearImpl` inherits `nn::Module`.','line_number':628,'multiline':False]['text':' Use the contained type of the `ModuleHolder`, e.g. `LinearImpl` for','line_number':634,'multiline':False]['text':' `Linear`, since `LinearImpl` inherits `nn::Module`.','line_number':635,'multiline':False]['text':' First call `to()` on every child module.','line_number':687,'multiline':False]['text':' Then move every parameter to the new dtype/device.','line_number':691,'multiline':False]['text':'recurse=','line_number':692,'multiline':True]['text':' Then move every buffer to the new dtype/device.','line_number':695,'multiline':False]['text':'recurse=','line_number':696,'multiline':True]['text':' namespace nn','line_number':701,'multiline':False]['text':' namespace torch','line_number':702,'multiline':False]