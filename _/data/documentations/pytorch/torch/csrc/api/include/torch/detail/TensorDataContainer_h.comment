['text':' FIXME: There is no `operator<<` overload for `at::kBFloat16` type,','line_number':31,'multiline':False]['text':' and we need to convert it to `float` type using `operator float()` function','line_number':32,'multiline':False]['text':' defined in `c10/util/BFloat16.h`.','line_number':33,'multiline':False]['text':' Tracking issue: https://github.com/pytorch/pytorch/issues/28845','line_number':34,'multiline':False]['text':' C++ `torch::tensor` with an integer type or an `at::ArrayRef` /','line_number':42,'multiline':False]['text':' `std::vector` / (nested) braced-init-list of integer types always','line_number':43,'multiline':False]['text':' produces a tensor of dtype `at::kLong` (aka. int64_t), matching Python','line_number':44,'multiline':False]['text':' `torch.tensor` behavior.','line_number':45,'multiline':False]['text':' C++ `torch::tensor` with a floating-point type or an `at::ArrayRef` /','line_number':48,'multiline':False]['text':' `std::vector` / (nested) braced-init-list of floating-point types always','line_number':49,'multiline':False]['text':' produces a tensor of dtype `torch::get_default_dtype()`, matching Python','line_number':50,'multiline':False]['text':' `torch.tensor` behavior.','line_number':51,'multiline':False]['text':' We use `TensorDataContainer` to support converting the following data','line_number':58,'multiline':False]['text':' container types into the equivalent Tensor:','line_number':59,'multiline':False]['text':'','line_number':60,'multiline':False]['text':' 1. Arbitrarily nested braced-init-list (e.g. `{{1, 2}, {3, 4}}`).','line_number':61,'multiline':False]['text':' 2. `at::ArrayRef` of supported tensor data types.','line_number':62,'multiline':False]['text':' 3. `std::vector` of supported tensor data types.','line_number':63,'multiline':False]['text':'','line_number':64,'multiline':False]['text':' At any time, a `TensorDataContainer` object represents one of the following:','line_number':65,'multiline':False]['text':'','line_number':66,'multiline':False]['text':' 1. A scalar with value `scalar()` and type `scalar_type()`.','line_number':67,'multiline':False]['text':' 2. A Tensor represented in `std::initializer_list<TensorDataContainer>` form,','line_number':68,'multiline':False]['text':'    with value `init_list()`, Tensor scalar type `scalar_type()`, and Tensor','line_number':69,'multiline':False]['text':'    sizes `sizes()`.','line_number':70,'multiline':False]['text':' 3. A Tensor represented in `at::Tensor` form, with value `tensor()`, scalar','line_number':71,'multiline':False]['text':' type `scalar_type()`,','line_number':72,'multiline':False]['text':'    and Tensor sizes `sizes()`.','line_number':73,'multiline':False]['text':'','line_number':74,'multiline':False]['text':' All the infrastructure here is mostly to support converting an arbitrarily','line_number':75,'multiline':False]['text':' nested braced-init-list to the equivalent Tensor successfully. Consider the','line_number':76,'multiline':False]['text':' following example:','line_number':77,'multiline':False]['text':'','line_number':78,'multiline':False]['text':' `torch::tensor({{1}, {2}})`','line_number':79,'multiline':False]['text':'','line_number':80,'multiline':False]['text':' this will call into the `torch::tensor` function:','line_number':81,'multiline':False]['text':'','line_number':82,'multiline':False]['text':' `at::Tensor tensor(detail::TensorDataContainer tensor_data_container, const','line_number':83,'multiline':False]['text':' at::TensorOptions& options = {})`','line_number':84,'multiline':False]['text':'','line_number':85,'multiline':False]['text':' the compiler will first try to convert `{{1}, {2}}` to `TensorDataContainer`','line_number':86,'multiline':False]['text':' type:','line_number':87,'multiline':False]['text':'','line_number':88,'multiline':False]['text':' `TensorDataContainer({{1}, {2}})`','line_number':89,'multiline':False]['text':'','line_number':90,'multiline':False]['text':' which matches to the','line_number':91,'multiline':False]['text':' `TensorDataContainer(std::initializer_list<TensorDataContainer>)`','line_number':92,'multiline':False]['text':' constructor, and in an attempt to convert `{1}` and `{2}` to','line_number':93,'multiline':False]['text':' `TensorDataContainer`, it calls the following:','line_number':94,'multiline':False]['text':'','line_number':95,'multiline':False]['text':' `TensorDataContainer({1})`  (same call path happens for `{2}`, and we'll just','line_number':96,'multiline':False]['text':' focus on `{1}` here)','line_number':97,'multiline':False]['text':'','line_number':98,'multiline':False]['text':' At this point, theoretically there are two plausible ways for `{1}` to be','line_number':99,'multiline':False]['text':' matched to one of the constructors of `TensorDataContainer`:','line_number':100,'multiline':False]['text':'','line_number':101,'multiline':False]['text':' 1. It can be a list-initialization of a scalar value, thus matching','line_number':102,'multiline':False]['text':' `TensorDataContainer(int value)`.','line_number':103,'multiline':False]['text':' 2. It can be converted to `std::initializer_list<TensorDataContainer>`, thus','line_number':104,'multiline':False]['text':' matching','line_number':105,'multiline':False]['text':'    `TensorDataContainer(std::initializer_list<TensorDataContainer>)`.','line_number':106,'multiline':False]['text':'','line_number':107,'multiline':False]['text':' How does the compiler decide which one to choose? According to','line_number':108,'multiline':False]['text':' `https://en.cppreference.com/w/cpp/language/list_initialization`,','line_number':109,'multiline':False]['text':' braced-init-list always prefers the constructor that takes','line_number':110,'multiline':False]['text':' `std::initializer_list`. Hence we happily move forward with constructor #2,','line_number':111,'multiline':False]['text':' and it calls the following:','line_number':112,'multiline':False]['text':'','line_number':113,'multiline':False]['text':' `TensorDataContainer(1)`','line_number':114,'multiline':False]['text':'','line_number':115,'multiline':False]['text':' Now it matches `TensorDataContainer(int value)`, which stores `1` as a scalar','line_number':116,'multiline':False]['text':' value. All is good.','line_number':117,'multiline':False]['text':' NOTE: For tensors with zero-size dimensions (e.g. `torch::tensor({{},','line_number':119,'multiline':False]['text':' {}})`), the innermost empty braced-init-list `{}` matches the default','line_number':120,'multiline':False]['text':' constructor of the innermost `TensorDataContainer`.','line_number':121,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':122,'multiline':False]['text':' NOTE: In Python, the dtype of tensors with zero-size dimensions (e.g.','line_number':125,'multiline':False]['text':' `torch.tensor([[], []])`) depends on the value of','line_number':126,'multiline':False]['text':' `torch.get_default_dtype()`, and we should do the same for the C++','line_number':127,'multiline':False]['text':' equivalent.','line_number':128,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':137,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':139,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':142,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':186,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':188,'multiline':False]['text':' NOTE: We need to handle `std::vector` explicitly instead of relying on an','line_number':192,'multiline':False]['text':' implicit conversion to `at::ArrayRef`, otherwise the following error can be','line_number':193,'multiline':False]['text':' thrown when calling `torch::tensor(std::vector<int>({1, 2}))`:','line_number':194,'multiline':False]['text':' ```','line_number':195,'multiline':False]['text':' error: no matching function for call to 'tensor(const std::vector<int>&)'','line_number':196,'multiline':False]['text':' no known conversion for argument 1 from 'const std::vector<int>' to','line_number':197,'multiline':False]['text':' 'torch::detail::TensorDataContainer'','line_number':198,'multiline':False]['text':' ```','line_number':199,'multiline':False]['text':'','line_number':200,'multiline':False]['text':' NOTE: `torch::tensor(std::vector<bool>)` is not supported for now, because','line_number':201,'multiline':False]['text':' ArrayRef<bool> cannot be constructed from a std::vector<bool> bitfield.','line_number':202,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':206,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':208,'multiline':False]['text':' NOTE: Here we explicitly choose to initialize the tensor on CPU first,','line_number':262,'multiline':False]['text':' fill each element of the tensor, and then move the tensor to the','line_number':263,'multiline':False]['text':' desired device. For CUDA device, this approach only involves 1 CUDA','line_number':264,'multiline':False]['text':' kernel launch, and is much faster than initializing the tensor on CUDA','line_number':265,'multiline':False]['text':' first and then filling each element of it (which involves `N` CUDA','line_number':266,'multiline':False]['text':' kernel launches where `N` is the number of the elements in the tensor).','line_number':267,'multiline':False]['text':' namespace detail','line_number':370,'multiline':False]['text':' namespace torch','line_number':372,'multiline':False]