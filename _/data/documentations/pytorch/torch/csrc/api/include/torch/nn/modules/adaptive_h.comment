['text':'/ The output of a single invocation of an AdaptiveLogSoftmaxWithLoss','line_number':14,'multiline':False]['text':'/ module's `forward()` method.','line_number':15,'multiline':False]['text':'/ Tensor containing computed target log probabilities for each example','line_number':19,'multiline':False]['text':'/ Scalar representing the computed negative log likelihood loss','line_number':22,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ AdaptiveLogSoftmaxWithLoss','line_number':26,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':27,'multiline':False]['text':'/ Efficient softmax approximation as described in','line_number':29,'multiline':False]['text':'/ `Efficient softmax approximation for GPUs`_ by Edouard Grave, Armand Joulin,','line_number':30,'multiline':False]['text':'/ Moustapha Cissé, David Grangier, and Hervé Jégou.','line_number':31,'multiline':False]['text':'/ See','line_number':32,'multiline':False]['text':'/ https://pytorch.org/docs/master/nn.html#torch.nn.AdaptiveLogSoftmaxWithLoss','line_number':33,'multiline':False]['text':'/ to learn about the exact behavior of this module.','line_number':34,'multiline':False]['text':'/','line_number':35,'multiline':False]['text':'/ See the documentation for `torch::nn::AdaptiveLogSoftmaxWithLossOptions`','line_number':36,'multiline':False]['text':'/ class to learn what constructor arguments are supported for this module.','line_number':37,'multiline':False]['text':'/','line_number':38,'multiline':False]['text':'/ Example:','line_number':39,'multiline':False]['text':'/ ```','line_number':40,'multiline':False]['text':'/ AdaptiveLogSoftmaxWithLoss model(AdaptiveLogSoftmaxWithLossOptions(8, 10,','line_number':41,'multiline':False]['text':'/ {4, 8}).div_value(2.).head_bias(true));','line_number':42,'multiline':False]['text':'/ ```','line_number':43,'multiline':False]['text':'/ Pretty prints the `AdaptiveLogSoftmaxWithLoss` module into the given','line_number':65,'multiline':False]['text':'/ `stream`.','line_number':66,'multiline':False]['text':'/ Given input tensor, and output of `head`, computes the log of the full','line_number':69,'multiline':False]['text':'/ distribution','line_number':70,'multiline':False]['text':'/ Computes log probabilities for all n_classes','line_number':73,'multiline':False]['text':'/ This is equivalent to `log_pob(input).argmax(1)` but is more efficient in','line_number':76,'multiline':False]['text':'/ some cases','line_number':77,'multiline':False]['text':'/ The options with which this `Module` was constructed','line_number':80,'multiline':False]['text':'/ Cutoffs used to assign targets to their buckets. It should be an ordered','line_number':83,'multiline':False]['text':'/ Sequence of integers sorted in the increasing order','line_number':84,'multiline':False]['text':'/ Number of clusters','line_number':89,'multiline':False]['text':'/ Output size of head classifier','line_number':92,'multiline':False]['text':'/ A `ModuleHolder` subclass for `AdaptiveLogSoftmaxWithLossImpl`.','line_number':100,'multiline':False]['text':'/ See the documentation for `AdaptiveLogSoftmaxWithLossImpl` class to learn','line_number':101,'multiline':False]['text':'/ what methods it provides, and examples of how to use','line_number':102,'multiline':False]['text':'/ `AdaptiveLogSoftmaxWithLoss` with','line_number':103,'multiline':False]['text':'/ `torch::nn::AdaptiveLogSoftmaxWithLossOptions`. See the documentation for','line_number':104,'multiline':False]['text':'/ `ModuleHolder` to learn about PyTorch's module storage semantics.','line_number':105,'multiline':False]['text':' namespace nn','line_number':108,'multiline':False]['text':' namespace torch','line_number':109,'multiline':False]