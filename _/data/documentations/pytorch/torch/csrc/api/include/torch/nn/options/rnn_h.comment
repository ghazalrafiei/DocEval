['text':'/ Common options for RNN, LSTM and GRU modules.','line_number':13,'multiline':False]['text':'/ The number of features of a single sample in the input sequence `x`.','line_number':28,'multiline':False]['text':'/ The number of features in the hidden state `h`.','line_number':30,'multiline':False]['text':'/ The number of recurrent layers (cells) to use.','line_number':32,'multiline':False]['text':'/ Whether a bias term should be added to all linear operations.','line_number':34,'multiline':False]['text':'/ If true, the input sequence should be provided as `(batch, sequence,','line_number':36,'multiline':False]['text':'/ features)`. If false (default), the expected layout is `(sequence, batch,','line_number':37,'multiline':False]['text':'/ features)`.','line_number':38,'multiline':False]['text':'/ If non-zero, adds dropout with the given probability to the output of each','line_number':40,'multiline':False]['text':'/ RNN layer, except the final layer.','line_number':41,'multiline':False]['text':'/ Whether to make the RNN bidirectional.','line_number':43,'multiline':False]['text':'/ Cell projection dimension. If 0, projections are not added. Can only be','line_number':45,'multiline':False]['text':'/ used for LSTMs.','line_number':46,'multiline':False]['text':' namespace detail','line_number':50,'multiline':False]['text':'/ Options for the `RNN` module.','line_number':52,'multiline':False]['text':'/','line_number':53,'multiline':False]['text':'/ Example:','line_number':54,'multiline':False]['text':'/ ```','line_number':55,'multiline':False]['text':'/ RNN model(RNNOptions(128,','line_number':56,'multiline':False]['text':'/ 64).num_layers(3).dropout(0.2).nonlinearity(torch::kTanh));','line_number':57,'multiline':False]['text':'/ ```','line_number':58,'multiline':False]['text':'/ The number of expected features in the input `x`','line_number':64,'multiline':False]['text':'/ The number of features in the hidden state `h`','line_number':66,'multiline':False]['text':'/ Number of recurrent layers. E.g., setting ``num_layers=2``','line_number':68,'multiline':False]['text':'/ would mean stacking two RNNs together to form a `stacked RNN`,','line_number':69,'multiline':False]['text':'/ with the second RNN taking in outputs of the first RNN and','line_number':70,'multiline':False]['text':'/ computing the final results. Default: 1','line_number':71,'multiline':False]['text':'/ The non-linearity to use. Can be either ``torch::kTanh`` or','line_number':73,'multiline':False]['text':'/ ``torch::kReLU``. Default: ``torch::kTanh``','line_number':74,'multiline':False]['text':'/ If ``false``, then the layer does not use bias weights `b_ih` and `b_hh`.','line_number':76,'multiline':False]['text':'/ Default: ``true``','line_number':77,'multiline':False]['text':'/ If ``true``, then the input and output tensors are provided','line_number':79,'multiline':False]['text':'/ as `(batch, seq, feature)`. Default: ``false``','line_number':80,'multiline':False]['text':'/ If non-zero, introduces a `Dropout` layer on the outputs of each','line_number':82,'multiline':False]['text':'/ RNN layer except the last layer, with dropout probability equal to','line_number':83,'multiline':False]['text':'/ `dropout`. Default: 0','line_number':84,'multiline':False]['text':'/ If ``true``, becomes a bidirectional RNN. Default: ``false``','line_number':86,'multiline':False]['text':'/ Options for the `LSTM` module.','line_number':90,'multiline':False]['text':'/','line_number':91,'multiline':False]['text':'/ Example:','line_number':92,'multiline':False]['text':'/ ```','line_number':93,'multiline':False]['text':'/ LSTM model(LSTMOptions(2,','line_number':94,'multiline':False]['text':'/ 4).num_layers(3).batch_first(false).bidirectional(true));','line_number':95,'multiline':False]['text':'/ ```','line_number':96,'multiline':False]['text':'/ The number of expected features in the input `x`','line_number':100,'multiline':False]['text':'/ The number of features in the hidden state `h`','line_number':102,'multiline':False]['text':'/ Number of recurrent layers. E.g., setting ``num_layers=2``','line_number':104,'multiline':False]['text':'/ would mean stacking two LSTMs together to form a `stacked LSTM`,','line_number':105,'multiline':False]['text':'/ with the second LSTM taking in outputs of the first LSTM and','line_number':106,'multiline':False]['text':'/ computing the final results. Default: 1','line_number':107,'multiline':False]['text':'/ If ``false``, then the layer does not use bias weights `b_ih` and `b_hh`.','line_number':109,'multiline':False]['text':'/ Default: ``true``','line_number':110,'multiline':False]['text':'/ If ``true``, then the input and output tensors are provided','line_number':112,'multiline':False]['text':'/ as (batch, seq, feature). Default: ``false``','line_number':113,'multiline':False]['text':'/ If non-zero, introduces a `Dropout` layer on the outputs of each','line_number':115,'multiline':False]['text':'/ LSTM layer except the last layer, with dropout probability equal to','line_number':116,'multiline':False]['text':'/ `dropout`. Default: 0','line_number':117,'multiline':False]['text':'/ If ``true``, becomes a bidirectional LSTM. Default: ``false``','line_number':119,'multiline':False]['text':'/ Cell projection dimension. If 0, projections are not added','line_number':121,'multiline':False]['text':'/ Options for the `GRU` module.','line_number':125,'multiline':False]['text':'/','line_number':126,'multiline':False]['text':'/ Example:','line_number':127,'multiline':False]['text':'/ ```','line_number':128,'multiline':False]['text':'/ GRU model(GRUOptions(2,','line_number':129,'multiline':False]['text':'/ 4).num_layers(3).batch_first(false).bidirectional(true));','line_number':130,'multiline':False]['text':'/ ```','line_number':131,'multiline':False]['text':'/ The number of expected features in the input `x`','line_number':135,'multiline':False]['text':'/ The number of features in the hidden state `h`','line_number':137,'multiline':False]['text':'/ Number of recurrent layers. E.g., setting ``num_layers=2``','line_number':139,'multiline':False]['text':'/ would mean stacking two GRUs together to form a `stacked GRU`,','line_number':140,'multiline':False]['text':'/ with the second GRU taking in outputs of the first GRU and','line_number':141,'multiline':False]['text':'/ computing the final results. Default: 1','line_number':142,'multiline':False]['text':'/ If ``false``, then the layer does not use bias weights `b_ih` and `b_hh`.','line_number':144,'multiline':False]['text':'/ Default: ``true``','line_number':145,'multiline':False]['text':'/ If ``true``, then the input and output tensors are provided','line_number':147,'multiline':False]['text':'/ as (batch, seq, feature). Default: ``false``','line_number':148,'multiline':False]['text':'/ If non-zero, introduces a `Dropout` layer on the outputs of each','line_number':150,'multiline':False]['text':'/ GRU layer except the last layer, with dropout probability equal to','line_number':151,'multiline':False]['text':'/ `dropout`. Default: 0','line_number':152,'multiline':False]['text':'/ If ``true``, becomes a bidirectional GRU. Default: ``false``','line_number':154,'multiline':False]['text':'/ Common options for RNNCell, LSTMCell and GRUCell modules','line_number':160,'multiline':False]['text':' namespace detail','line_number':173,'multiline':False]['text':'/ Options for the `RNNCell` module.','line_number':175,'multiline':False]['text':'/','line_number':176,'multiline':False]['text':'/ Example:','line_number':177,'multiline':False]['text':'/ ```','line_number':178,'multiline':False]['text':'/ RNNCell model(RNNCellOptions(20,','line_number':179,'multiline':False]['text':'/ 10).bias(false).nonlinearity(torch::kReLU));','line_number':180,'multiline':False]['text':'/ ```','line_number':181,'multiline':False]['text':'/ The number of expected features in the input `x`','line_number':187,'multiline':False]['text':'/ The number of features in the hidden state `h`','line_number':189,'multiline':False]['text':'/ If ``false``, then the layer does not use bias weights `b_ih` and `b_hh`.','line_number':191,'multiline':False]['text':'/ Default: ``true``','line_number':192,'multiline':False]['text':'/ The non-linearity to use. Can be either ``torch::kTanh`` or','line_number':194,'multiline':False]['text':'/ ``torch::kReLU``. Default: ``torch::kTanh``','line_number':195,'multiline':False]['text':'/ Options for the `LSTMCell` module.','line_number':199,'multiline':False]['text':'/','line_number':200,'multiline':False]['text':'/ Example:','line_number':201,'multiline':False]['text':'/ ```','line_number':202,'multiline':False]['text':'/ LSTMCell model(LSTMCellOptions(20, 10).bias(false));','line_number':203,'multiline':False]['text':'/ ```','line_number':204,'multiline':False]['text':'/ The number of expected features in the input `x`','line_number':208,'multiline':False]['text':'/ The number of features in the hidden state `h`','line_number':210,'multiline':False]['text':'/ If ``false``, then the layer does not use bias weights `b_ih` and `b_hh`.','line_number':212,'multiline':False]['text':'/ Default: ``true``','line_number':213,'multiline':False]['text':'/ Options for the `GRUCell` module.','line_number':217,'multiline':False]['text':'/','line_number':218,'multiline':False]['text':'/ Example:','line_number':219,'multiline':False]['text':'/ ```','line_number':220,'multiline':False]['text':'/ GRUCell model(GRUCellOptions(20, 10).bias(false));','line_number':221,'multiline':False]['text':'/ ```','line_number':222,'multiline':False]['text':'/ The number of expected features in the input `x`','line_number':226,'multiline':False]['text':'/ The number of features in the hidden state `h`','line_number':228,'multiline':False]['text':'/ If ``false``, then the layer does not use bias weights `b_ih` and `b_hh`.','line_number':230,'multiline':False]['text':'/ Default: ``true``','line_number':231,'multiline':False]['text':' namespace nn','line_number':235,'multiline':False]['text':' namespace torch','line_number':236,'multiline':False]