['text':' Locking:','line_number':8,'multiline':False]['text':' We need to free PyCodeObjects when ~StackContext runs, but','line_number':9,'multiline':False]['text':' CUDACachingAllocator may hold its device lock when ~StackContext runs.','line_number':10,'multiline':False]['text':' Because the thread calling the allocator _may_ hold the GIL,','line_number':12,'multiline':False]['text':' attempting to lock the GIL in ~StackContext can deadlock:','line_number':13,'multiline':False]['text':' T0: GIL Lock -> Call Allocator    ->| Waiting Device Lock','line_number':14,'multiline':False]['text':' T1: Call Allocator -> Device Lock ->| Waiting GIL Lock','line_number':15,'multiline':False]['text':' Instead the destructor defers freeing stack frames by putting them in','line_number':16,'multiline':False]['text':' to_free_frames. We still need a lock to manage this vector, but','line_number':17,'multiline':False]['text':' we can ensure an overall lock ordering of GIL -> device_lock ->','line_number':18,'multiline':False]['text':' to_free_frames_mutex because ::gather is called outside of the device lock.','line_number':19,'multiline':False]['text':' find all the additional frames associated with inductor generated','line_number':95,'multiline':False]['text':' code','line_number':96,'multiline':False]['text':' namespace','line_number':113,'multiline':False]['text':' we dedup repeated to_symbolize objects to prevent','line_number':117,'multiline':False]['text':' creating a bunch of duplicated frame objects','line_number':118,'multiline':False]['text':' namespace torch','line_number':171,'multiline':False]