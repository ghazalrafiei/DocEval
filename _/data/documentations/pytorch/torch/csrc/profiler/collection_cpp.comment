['text':' NOLINTNEXTLINE(cppcoreguidelines-slicing)','line_number':55,'multiline':False]['text':' ============================================================================','line_number':64,'multiline':False]['text':' == PyTorch Ops =============================================================','line_number':65,'multiline':False]['text':' ============================================================================','line_number':66,'multiline':False]['text':' namespace','line_number':97,'multiline':False]['text':' ----------------------------','line_number':99,'multiline':False]['text':' |  Input / Output encoder  |','line_number':100,'multiline':False]['text':' ----------------------------','line_number':101,'multiline':False]['text':' Scalars are small enough that they are stored in ivalues without an','line_number':108,'multiline':False]['text':' extra memory alloc','line_number':109,'multiline':False]['text':' TODO: further optimize this by maybe giving Profiler access to the','line_number':110,'multiline':False]['text':' guts of IValue.','line_number':111,'multiline':False]['text':' TODO fix nested and symbolic sizes','line_number':130,'multiline':False]['text':' Only Strided layout tensors have strides','line_number':137,'multiline':False]['text':' Scalar list can be very long. If a list is too long, we shouldn't','line_number':147,'multiline':False]['text':' collect it. This function checks whether the list is a scalar list','line_number':148,'multiline':False]['text':' and whether its length is sufficiently short.','line_number':149,'multiline':False]['text':' This function returns a lambda which is is a custom-iterator-like getter.','line_number':171,'multiline':False]['text':' Each invocation of the lambda returns input values for one op.','line_number':172,'multiline':False]['text':'','line_number':173,'multiline':False]['text':' io_type is used to filter the ivalues between 'Shapes' and 'Concrete Args'.','line_number':174,'multiline':False]['text':' Shapes are used to represent the shapes of tensors. We save only the shapes','line_number':175,'multiline':False]['text':'   of the tensors because tensors can be large.','line_number':176,'multiline':False]['text':' Concrete args are separated to clarify that they are the actual values.','line_number':177,'multiline':False]['text':' This marks the end of this op.','line_number':245,'multiline':False]['text':' ---------------------------------------------------','line_number':273,'multiline':False]['text':' |  Correlation ID tracking (OpList & EventBlock)  |','line_number':274,'multiline':False]['text':' ---------------------------------------------------','line_number':275,'multiline':False]['text':' ---------------------------------','line_number':303,'multiline':False]['text':' |  Collection (Observer logic)  |','line_number':304,'multiline':False]['text':' ---------------------------------','line_number':305,'multiline':False]['text':' backward nodes source range corresponds to the forward node','line_number':326,'multiline':False]['text':' TODO: consider using C++ stack trace','line_number':327,'multiline':False]['text':' Record NCCL metadata for specific CPU ops','line_number':342,'multiline':False]['text':' ---------------','line_number':373,'multiline':False]['text':' |  Collation  |','line_number':374,'multiline':False]['text':' ---------------','line_number':375,'multiline':False]['text':' namespace','line_number':399,'multiline':False]['text':' Plumb Autograd info to the top level annotation.','line_number':406,'multiline':False]['text':' `AccumulateGrad` is an important marker for profile analysis; however the','line_number':420,'multiline':False]['text':' annotation relies on `c10::demangle` which is platform dependent. In','line_number':421,'multiline':False]['text':' particular, Windows will add a "struct " prefix.','line_number':422,'multiline':False]['text':' TODO: CTAD will take care of template args when we move to C++17','line_number':436,'multiline':False]['text':'start_time_ns_=','line_number':480,'multiline':True]['text':'start_tid_=','line_number':481,'multiline':True]['text':'kineto_info_=','line_number':482,'multiline':True]['text':'extra_fields_=','line_number':483,'multiline':True]['text':'name_=','line_number':485,'multiline':True]['text':'duration_ns_=','line_number':486,'multiline':True]['text':'in_tree_building_=','line_number':488,'multiline':True]['text':' See `RecordQueue::getSubqueue()` for an overview of this cache.','line_number':493,'multiline':False]['text':' The astute observer will note that this leaves a dangling reference; nothing','line_number':499,'multiline':False]['text':' in the teardown of `RecordQueue` or `ThreadLocalSubqueue` clears this value.','line_number':500,'multiline':False]['text':' (And the raw pointer in `SubQueueThreadCache` will not extend the lifetime','line_number':501,'multiline':False]['text':' of `*ref_`.) This is safe, however, because `getSubqueue` will check','line_number':502,'multiline':False]['text':' `sub_queue_cache_.key_` before attempting to access `ref_`, and if `key_`','line_number':503,'multiline':False]['text':' does not match the RecordQueue's *unique* `id_` it will evict','line_number':504,'multiline':False]['text':' `sub_queue_cache_` and fall back to a different mechanism.','line_number':505,'multiline':False]['text':' namespace','line_number':549,'multiline':False]['text':' In rare cases we're willing to tolerate ops which are missing an end time','line_number':597,'multiline':False]['text':' so long as they can borrow their parent's end time. A consequence of this,','line_number':598,'multiline':False]['text':' however, is that `endTimeNS` may not make sense until tree construction is','line_number':599,'multiline':False]['text':' complete.','line_number':600,'multiline':False]['text':' In the most common case, a thread will want to write to the same sub-queue','line_number':653,'multiline':False]['text':' that it wrote to last call. The only time that isn't true is if:','line_number':654,'multiline':False]['text':'  A) The profiler context has ended and we are in a new one.','line_number':655,'multiline':False]['text':'  B) Two profilers are active in different TLS contexts, and this thread','line_number':656,'multiline':False]['text':'     is a worker helping with intra-op parallelism.','line_number':657,'multiline':False]['text':' Since we expect this to be the OVERWHELMINGLY common case (>99%), we add a','line_number':658,'multiline':False]['text':' special thread_local cache so that we can skip the overall `flat_hash_map`','line_number':659,'multiline':False]['text':' (and corresponding lock).','line_number':660,'multiline':False]['text':' Assumption: Total threads number will not exceed 2^16-1, and total ops will','line_number':691,'multiline':False]['text':' not exceed 2^48 -1.','line_number':692,'multiline':False]['text':' act is backward op.','line_number':707,'multiline':False]['text':' If there are multiple events that match this sequence/tid pair, we','line_number':718,'multiline':False]['text':' should delete this entry in the map to avoid inserting multiple "end"','line_number':719,'multiline':False]['text':' flow events.','line_number':720,'multiline':False]['text':' act is forward op.','line_number':724,'multiline':False]['text':' Assumption: Among all ops with same sequence number,','line_number':727,'multiline':False]['text':' the one with biggest start time is most likely launching backward op.','line_number':728,'multiline':False]['text':' Now the sequence number is only incremented on creating a "Node"','line_number':733,'multiline':False]['text':' object for backward pass, by calling','line_number':734,'multiline':False]['text':' "at::sequence_number::get_and_increment()". Among all ops with same','line_number':735,'multiline':False]['text':' sequence number, the one with biggest startTime is the one launching','line_number':736,'multiline':False]['text':' backward op.','line_number':737,'multiline':False]['text':' USE_KINETO','line_number':744,'multiline':False]['text':' USE_KINETO','line_number':751,'multiline':False]['text':' startThreadId_seqNum to pointer of activity.','line_number':754,'multiline':False]['text':' Low-16bits of startThreadId and low-48bits seqNum are concatenated into','line_number':755,'multiline':False]['text':' one uint64_t variable as key.','line_number':756,'multiline':False]['text':' add information about an associated forward op, if a sequence number','line_number':770,'multiline':False]['text':' is available (e.g. during training)','line_number':771,'multiline':False]['text':' We need to visit the events in chronological order.','line_number':781,'multiline':False]['text':' So we sort them by end_time_ns_ before processing.','line_number':782,'multiline':False]['text':' USE_KINETO','line_number':801,'multiline':False]['text':' Generate Kineto events for each event recorded by the PyTorch profiler.','line_number':814,'multiline':False]['text':' There is a longstanding regression for initializing','line_number':829,'multiline':False]['text':' on-demand Kineto activity handling. Enabling this path','line_number':830,'multiline':False]['text':' for Profiler API could cause side effects as much has changed since.','line_number':831,'multiline':False]['text':' Make a surgical fix here until we holistically assess the on-demand','line_number':832,'multiline':False]['text':' vs API path framentation, which has been snowballing in complexity','line_number':833,'multiline':False]['text':' and thus flakiness.','line_number':834,'multiline':False]['text':' Kineto adds the events that it collected.','line_number':845,'multiline':False]['text':' There are two mechanisms that we use to connect Profiler and Kineto events.','line_number':850,'multiline':False]['text':' The first is the correlation ID. The profiler pushes a unique integer at the','line_number':851,'multiline':False]['text':' start of an op and pops it at the end. Kineto then associates the events','line_number':852,'multiline':False]['text':' that it collects with that correlation ID and sets the linked activity of','line_number':853,'multiline':False]['text':' the events that it collected to point to the profiler op.','line_number':854,'multiline':False]['text':'','line_number':855,'multiline':False]['text':' However, this is not a sufficient description because it does not retain','line_number':856,'multiline':False]['text':' dependency information between kineto ops. Consider a call to `torch.add`.','line_number':857,'multiline':False]['text':' Three events will be collected:','line_number':858,'multiline':False]['text':'   `aten::add`          (TorchOp, collected by profiler)','line_number':859,'multiline':False]['text':'   `cudaLaunchKernel`   (CUDA runtime event, collected by Kineto)','line_number':860,'multiline':False]['text':'   `at::vectorized_...` (GPU kernel, collected by Kineto)','line_number':861,'multiline':False]['text':' If we only relied on correlation IDs we would set both Kineto events as','line_number':862,'multiline':False]['text':' children of the `at::add`, rather than the correct','line_number':863,'multiline':False]['text':'   `at::add -> cudaLaunchKernel -> at::vectorized_...`','line_number':864,'multiline':False]['text':'','line_number':865,'multiline':False]['text':' Kineto surfaces this information through a second concept called a "flow".','line_number':866,'multiline':False]['text':' In this example, the `cudaLaunchKernel` event is the start of a flow and the','line_number':867,'multiline':False]['text':' GPU kernel has the same flow id but is not a start event. Thus, when merging','line_number':868,'multiline':False]['text':' the Kineto events into the call tree we first add all events which are flow','line_number':869,'multiline':False]['text':' start nodes. We then merge the rest, trying to pair them with flow starts','line_number':870,'multiline':False]['text':' and falling back to correlation ID if necessary. For any nodes without','line_number':871,'multiline':False]['text':' linked events the caller is determined using the normal tree construction','line_number':872,'multiline':False]['text':' algorithm.','line_number':873,'multiline':False]['text':' First check the map.','line_number':907,'multiline':False]['text':' Then fallback to the encoded metadata.','line_number':913,'multiline':False]['text':' And finally give up.','line_number':921,'multiline':False]['text':' Match profiler events with the corresponding kineto events. Kineto may','line_number':926,'multiline':False]['text':' have moved or copied the activities, so we have to recover the','line_number':927,'multiline':False]['text':' relationship between `libkineto::ITraceActivity` and `Result`.','line_number':928,'multiline':False]['text':' Kineto is inconsistent with types, so we have to cast to int32.','line_number':949,'multiline':False]['text':' Placeholder','line_number':956,'multiline':False]['text':'id=','line_number':963,'multiline':True]['text':'type=','line_number':964,'multiline':True]['text':'start=','line_number':965,'multiline':True]['text':' NB: It's tempting to set `event->kineto_activity_`; however we can only','line_number':967,'multiline':False]['text':' guarantee that the events we passed to Kineto are of type','line_number':968,'multiline':False]['text':' `GenericTraceActivity`. Others may derive from ITraceActivity and thus','line_number':969,'multiline':False]['text':' are not safe to cast.','line_number':970,'multiline':False]['text':' Until we are very sure that we can reassociate kineto and profiler','line_number':977,'multiline':False]['text':' events we need to be very defensive.','line_number':978,'multiline':False]['text':' First pass: Collect start events and set parent to linked event.','line_number':1034,'multiline':False]['text':' USE_ROCM','line_number':1047,'multiline':False]['text':' USE_ROCM','line_number':1049,'multiline':False]['text':' Second pass','line_number':1057,'multiline':False]['text':' Flow takes priority over linked event.','line_number':1061,'multiline':False]['text':' If a parent was set we have to do some bookkeeping.','line_number':1068,'multiline':False]['text':' Set TIDs now that we have established lineage.','line_number':1078,'multiline':False]['text':' In on demand mode kineto is directly controlled by other machinery.','line_number':1108,'multiline':False]['text':' pass','line_number':1134,'multiline':False]['text':' Kineto builds subtrees using correlation ids and flows, so some Kineto','line_number':1148,'multiline':False]['text':' events are already marked finished before the main tree building','line_number':1149,'multiline':False]['text':' algorithm. It's fine to ignore them; the root event of these subtrees','line_number':1150,'multiline':False]['text':' not a Kineto op and will be handled normally.','line_number':1151,'multiline':False]['text':' We use min time to indicate the lack of a termination event, so if we','line_number':1183,'multiline':False]['text':' encounter such a case we don't push to `end_events_`.','line_number':1184,'multiline':False]['text':' This event was marked finished by a previous `pop_event` call.','line_number':1193,'multiline':False]['text':' Stack replay loop.','line_number':1215,'multiline':False]['text':' Cleanup remaining exit events.','line_number':1225,'multiline':False]['text':'*
 * Adjust r's duration to be the max of its current duration and the sum of all
 * of its children's adjusted durations (keeping its start time the same)
 * (adjust all child durations recursively)
 ','line_number':1234,'multiline':True]['text':' Pass- Allocation events can't have children','line_number':1259,'multiline':False]['text':'*
 * 1) Adjust r's start time to be [new_start_time] (also adjusting end time and
      keeping duration the same)
 * 2) Recursively adjust r's children's start times, making them line up such
      that the last one ends at the same time as r
 * 3) Return r's final end time
 ','line_number':1276,'multiline':True]['text':' Adjust start time (keeping duration constant)','line_number':1288,'multiline':False]['text':' Pass- We don't need to manually adjust end time for Vulkan events','line_number':1295,'multiline':False]['text':' Pass- No duration or end time to adjust','line_number':1298,'multiline':False]['text':'*
 * Adjust timestamps and durations of nodes in [out] such that
 *  - Vulkan event timelines are synchronized with CPU event times
 *  - Parent event timelines fully contain their child timelines
 *  - No overlaps in timelines for nodes at the same depth
 ','line_number':1324,'multiline':True]['text':' Only begin traversal for root nodes.','line_number':1337,'multiline':False]['text':' namespace','line_number':1350,'multiline':False]['text':'start_time_ns_=','line_number':1379,'multiline':True]['text':'start_tid_=','line_number':1380,'multiline':True]['text':'kineto_info_=','line_number':1381,'multiline':True]['text':'extra_fields_=','line_number':1382,'multiline':True]['text':'start_time_ns_=','line_number':1394,'multiline':True]['text':'start_tid_=','line_number':1395,'multiline':True]['text':'kineto_info_=','line_number':1396,'multiline':True]['text':'extra_fields_=','line_number':1397,'multiline':True]['text':' Reset these so that second build_tree can happen','line_number':1425,'multiline':False]['text':' namespace','line_number':1450,'multiline':False]['text':' namespace','line_number':1469,'multiline':False]['text':' namespace','line_number':1488,'multiline':False]['text':' namespace impl','line_number':1502,'multiline':False]['text':' namespace profiler','line_number':1503,'multiline':False]['text':' namespace torch','line_number':1504,'multiline':False]