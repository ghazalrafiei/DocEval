['text':' WorkEntry is the state associated with a single MPI run instance.','line_number':28,'multiline':False]['text':' It include the source Tensor list and destination Tensor list, as well as','line_number':29,'multiline':False]['text':' The actual run function that will operate either on src or dst or both.','line_number':30,'multiline':False]['text':' Not copyable','line_number':42,'multiline':False]['text':' Not copy assignable','line_number':44,'multiline':False]['text':' For input and output tensors (in-place), we will always use src','line_number':47,'multiline':False]['text':' Copy of user provided outputs.','line_number':50,'multiline':False]['text':' src rank returned, for recv only','line_number':53,'multiline':False]['text':' ProcessGroupMPI implements MPI bindings for c10d.','line_number':58,'multiline':False]['text':'','line_number':59,'multiline':False]['text':' All functions on this class are expected to be called in the same','line_number':60,'multiline':False]['text':' order across processes in the group. This is the only way that we','line_number':61,'multiline':False]['text':' can guarantee to match up the same calls across processes.','line_number':62,'multiline':False]['text':'','line_number':63,'multiline':False]['text':' All MPI functions provided by this class is asynchronously scheduled on a','line_number':64,'multiline':False]['text':' Worker thread. Therefore, ProcessGroupMPI requires the MPI implementation','line_number':65,'multiline':False]['text':' that is used to have a minimum thread support value of MPI_THREAD_SERIALIZED.','line_number':66,'multiline':False]['text':' That is, The process may be multi-threaded, and multiple threads may make','line_number':67,'multiline':False]['text':' MPI calls, but only one at a time: MPI calls are not made concurrently from','line_number':68,'multiline':False]['text':' two distinct threads (all MPI calls are serialized). However, with','line_number':69,'multiline':False]['text':' MPI_THREAD_SERIALIZED, ProcessGroupMPI will only support a singe process','line_number':70,'multiline':False]['text':' group. In other words, no more than 1 process group can be created globally.','line_number':71,'multiline':False]['text':'','line_number':72,'multiline':False]['text':' If you would like to use multiple ProcessGroupMPI, it requires your MPI','line_number':73,'multiline':False]['text':' implementation to have a thread support value of MPI_THREAD_MULTIPLE, that','line_number':74,'multiline':False]['text':' is, multiple threads may call MPI, with no restriction.','line_number':75,'multiline':False]['text':'','line_number':76,'multiline':False]['text':' Also note that ProcessGroupMPI only supports a single Tensor operation. In','line_number':77,'multiline':False]['text':' other words, the size of the input Tensor vector should always be 1.','line_number':78,'multiline':False]['text':'','line_number':79,'multiline':False]['text':' CUDA tensor can be supported if the MPI used is CUDA-aware MPI, and','line_number':80,'multiline':False]['text':' ProcessGroupMPI will automatically detect this support.','line_number':81,'multiline':False]['text':' Constructor will spawn up the worker thread loop','line_number':143,'multiline':False]['text':' Abort the MPI program, needs to be called when exception is detected','line_number':148,'multiline':False]['text':' Creating a new ProcessGroupMPI, will initialize MPI if not initialized','line_number':231,'multiline':False]['text':' Worker thread loop','line_number':238,'multiline':False]['text':' Helper function that is called by the destructor','line_number':240,'multiline':False]['text':' Global states','line_number':258,'multiline':False]['text':' namespace c10d','line_number':269,'multiline':False]['text':' USE_C10D_MPI','line_number':271,'multiline':False]