['text':'*
 * This is a handwritten file that accompanies codegenerated header
 * LazyShapeDtype.h
 *
 * The purpose of these shape/dtype inference methods are to fill gaps
 * where we do not yet have structured kernels in pytorch core.  Ops
 * for which there _are_ structured kernels can use meta::op() to infer
 * shape/dtype, and codegen makes use of this.  Ops for which there are not
 * yet structured kernels can still be used with lazy_tensor codegen, but
 * require manual intervention to implement compute_shape_{op} and
 * compute_dtype_{op}.
 *
 * READ THIS!
 *
 * 1. Beware: Tech Debt!
 * ---------------------
 * These functions are tech debt.  We want to delete them all and use structured
 * kernels instead, but it's a lot faster to write these so we're decoupling the
 * two efforts to move fast for adding support for codegenned Lazy Tensor ops.
 *
 * Codegenned Lazy Tensor ops with handwritten shape formulae are still better
 * than fully handwritten Lazy Tensor ops (which also have handwritten shape
 * formulae).
 *
 * 2. Structured Kernels For The Win
 * ---------------------------------
 * Long term, more and more ops should be supported as 'structured kernels'.
 * Consider doing your part and porting an op.  As ops get ported over, the
 * codegen will automatically notice and stop generating declarations for these
 * shape formulae, so we'll need to manually clean up the unused functions in
 * this file, or somehow automate that.
 *
 * https://dev-discuss.pytorch.org/t/slides-from-structured-kernel-presentation/179
 *
 * 3. How to figure out the shape/dtype
 * ------------------------------------
 * Unfortunately there isn't a one-stop-shop for learning the output shape
 * formulae for all operators.  This is partly because some operators are not
 * part of our 'public' API, including backward operators which users don't
 * directly invoke.
 *
 * Check our opinfo registry:
 *  https://github.com/pytorch/pytorch/blob/13b859983183ea9938deb5030ac9a0747841f0a8/torch/csrc/jit/runtime/symbolic_shape_registry.cpp
 *
 * Read the manual (for ops that are 1:1 with python frontend):
 *  https://pytorch.org/docs/stable/generated/torch.trace.html
 *
 ','line_number':1,'multiline':True]['text':' Copied from ATen/native/utils/ParamUtils.h, which aparently I can't include','line_number':75,'multiline':False]['text':' from here?','line_number':76,'multiline':False]['text':' It seems more common to not use parameters than to use them, so disable','line_number':94,'multiline':False]['text':' unused-parameter warning','line_number':95,'multiline':False]['text':' shape inference code copied from RangeFactories.cpp arange_out function','line_number':105,'multiline':False]['text':' Note: AT_DISPATCH_ALL_TYPES_AND is just a macro that defines the correct','line_number':106,'multiline':False]['text':' c++ scalar_t type depending on out tensor','line_number':107,'multiline':False]['text':' Note: acc_type further defines an accumulataion type depending on the','line_number':111,'multiline':False]['text':' scalar_t and whether its on cuda vs cpu.','line_number':112,'multiline':False]['text':' we use double precision for (start - end) / step','line_number':118,'multiline':False]['text':' to compute size_d for consistency across devices.','line_number':119,'multiline':False]['text':' The problem with using accscalar_t is that accscalar_t might be','line_number':120,'multiline':False]['text':' float32 on gpu for a float32 scalar_t, but double on cpu for the','line_number':121,'multiline':False]['text':' same, and the effective output size starts differing on CPU vs GPU','line_number':122,'multiline':False]['text':' because of precision issues, which we dont want. the corner-case we','line_number':123,'multiline':False]['text':' do want to take into account is int64_t, which has higher precision','line_number':124,'multiline':False]['text':' than double NOLINTNEXTLINE(bugprone-branch-clone)','line_number':125,'multiline':False]['text':' From torch.arange docs:','line_number':159,'multiline':False]['text':' dtype (torch.dtype, optional) â€“ the desired data type of returned tensor.','line_number':160,'multiline':False]['text':' Default: if None, uses a global default (see','line_number':161,'multiline':False]['text':' torch.set_default_dtype()). If dtype is not given, infer the data','line_number':162,'multiline':False]['text':' type from the other input arguments. If any of start, end, or stop are','line_number':163,'multiline':False]['text':' floating-point, the dtype is inferred to be the default dtype, see','line_number':164,'multiline':False]['text':' get_default_dtype(). Otherwise, the dtype is inferred to be torch.int64.','line_number':165,'multiline':False]['text':' Based on aten/src/ATen/native/ConstantPadNd.cpp::constant_pad_nd','line_number':215,'multiline':False]['text':' TODO(whc) not sure whether to return 2 shapes here, or a 3rd one that is','line_number':278,'multiline':False]['text':' empty','line_number':279,'multiline':False]['text':' at::convolution performs parameter expansion before running kernels on','line_number':299,'multiline':False]['text':' expanded parameters we must do the same.  Shape formulae access differnent','line_number':300,'multiline':False]['text':' dimensions of e.g. output_padding, but output_padding may be passed in as a','line_number':301,'multiline':False]['text':' scalar.  Sadly, accessing output_padding[1] in this case gives incorrect','line_number':302,'multiline':False]['text':' results rather than indexing error','line_number':303,'multiline':False]['text':' Based on aten/src/ATen/native/Embedding.cpp::embedding.','line_number':386,'multiline':False]['text':' Based on aten/src/ATen/native/Embedding.cpp::embedding_dense_backward_cpu.','line_number':422,'multiline':False]['text':' -1 can't be specified for non-existing dimensions','line_number':458,'multiline':False]['text':' Based on definition of','line_number':482,'multiline':False]['text':' https://pytorch.org/docs/stable/generated/torch.index_select.html. Promote','line_number':483,'multiline':False]['text':' Rank 0 index tensor to a 1 * 1 tensor.','line_number':484,'multiline':False]['text':' TODO(whc) support cat in codegen and move this to compute_*_cat functions','line_number':507,'multiline':False]['text':' A separate mean and var needs to be kept for each channel.','line_number':544,'multiline':False]['text':' A separate mean and var needs to be kept for each channel.','line_number':585,'multiline':False]['text':' `weight` and `bias` are vectors of length C (number of channels)`','line_number':591,'multiline':False]['text':' Copied from aten/src/ATen/native/layer_norm.cpp::layer_norm_cpu_out.','line_number':608,'multiline':False]['text':' Suppress unused variable warning','line_number':618,'multiline':False]['text':' It's undocumented, but torch::sum promotes all integral types to int64_t by','line_number':724,'multiline':False]['text':' default','line_number':725,'multiline':False]['text':'includeBool','line_number':726,'multiline':True]['text':' assumes self.shape is {*, n, n} and returns shape *','line_number':757,'multiline':False]['text':' Doesn't check input dtype, but output dtype either matches it,','line_number':760,'multiline':False]['text':' or the actual slogdet operation will throw if it's an unsupported type.','line_number':761,'multiline':False]['text':' Sign and det outputs hold the same shape, dtype.','line_number':762,'multiline':False]['text':' The `grad_output` tensor is really the input to this kernel, and while its','line_number':803,'multiline':False]['text':' shape may vary following the logic of the forward output, the output of','line_number':804,'multiline':False]['text':' this kernel should have fixed shapes matching the inputs to the forward','line_number':805,'multiline':False]['text':' kernel.','line_number':806,'multiline':False]['text':' assumes self.shape is {*, n, n} and returns shape *','line_number':811,'multiline':False]['text':' Doesn't check input dtype, but output dtype either matches it,','line_number':814,'multiline':False]['text':' or the actual logdet operation will throw if it's an unsupported type','line_number':815,'multiline':False]['text':' Based on definition of','line_number':820,'multiline':False]['text':' aten/src/ATen/native/Activation.cpp::log_sigmoid_forward_out_cpu.','line_number':821,'multiline':False]['text':' Based on definition of','line_number':831,'multiline':False]['text':' aten/src/ATen/native/Activation.cpp::log_sigmoid_backward_cpu*.','line_number':832,'multiline':False]['text':' Based on definition of','line_number':842,'multiline':False]['text':' aten/src/ATen/native/LossNLL2d.cpp:nll_loss2d_forward_cpu','line_number':843,'multiline':False]['text':' from `aten/src/ATen/native/cpu/GridSamplerKernel.cpp','line_number':867,'multiline':False]['text':' from `aten/src/ATen/native/cpu/GridSamplerKernel.cpp','line_number':883,'multiline':False]['text':' Checks based on `aten/src/ATen/native/AdaptiveAveragePooling.cpp`','line_number':898,'multiline':False]['text':' and on `aten/src/ATen/native/cpu/AdaptiveAvgPoolKernel.cpp`','line_number':899,'multiline':False]['text':' Checks based on `aten/src/ATen/native/AdaptiveAveragePooling.cpp`','line_number':943,'multiline':False]['text':' Checks based on `aten/src/ATen/native/AdaptiveAveragePooling.cpp`','line_number':975,'multiline':False]['text':' and on `aten/src/ATen/native/cpu/AdaptiveAvgPoolKernel.cpp`','line_number':976,'multiline':False]['text':' Checks based on `aten/src/ATen/native/AdaptiveAveragePooling.cpp`','line_number':1026,'multiline':False]['text':' Copied from 'check_stack_inputs' in TensorShape.cpp','line_number':1100,'multiline':False]['text':' Non-Native Ops','line_number':1155,'multiline':False]['text':' View Ops','line_number':1184,'multiline':False]['text':'dtype=','line_number':1277,'multiline':True]['text':'layout=','line_number':1278,'multiline':True]['text':'device=','line_number':1279,'multiline':True]['text':'pin_memory=','line_number':1280,'multiline':True]['text':'dtype=','line_number':1284,'multiline':True]['text':'layout=','line_number':1285,'multiline':True]['text':'device=','line_number':1286,'multiline':True]['text':'pin_memory=','line_number':1287,'multiline':True]['text':'dtype=','line_number':1302,'multiline':True]['text':'layout=','line_number':1303,'multiline':True]['text':'device=','line_number':1304,'multiline':True]['text':'pin_memory=','line_number':1305,'multiline':True]['text':'dtype=','line_number':1309,'multiline':True]['text':'layout=','line_number':1310,'multiline':True]['text':'device=','line_number':1311,'multiline':True]['text':'pin_memory=','line_number':1312,'multiline':True]['text':'dtype=','line_number':1328,'multiline':True]['text':'layout=','line_number':1329,'multiline':True]['text':'device=','line_number':1330,'multiline':True]['text':'pin_memory=','line_number':1331,'multiline':True]['text':'dtype=','line_number':1335,'multiline':True]['text':'layout=','line_number':1336,'multiline':True]['text':'device=','line_number':1337,'multiline':True]['text':'pin_memory=','line_number':1338,'multiline':True]['text':'dtype=','line_number':1354,'multiline':True]['text':'layout=','line_number':1355,'multiline':True]['text':'device=','line_number':1356,'multiline':True]['text':'pin_memory=','line_number':1357,'multiline':True]['text':'dtype=','line_number':1361,'multiline':True]['text':'layout=','line_number':1362,'multiline':True]['text':'device=','line_number':1363,'multiline':True]['text':'pin_memory=','line_number':1364,'multiline':True]['text':' Restore unused-parameters warnings','line_number':1387,'multiline':False]['text':' namespace lazy','line_number':1390,'multiline':False]['text':' namespace torch','line_number':1391,'multiline':False]