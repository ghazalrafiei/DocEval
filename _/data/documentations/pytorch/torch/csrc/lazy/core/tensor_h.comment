['text':' This is the core lazy tensor data structure where all the tensor data is','line_number':24,'multiline':False]['text':' held. The lazy tensor is nothing more than a shared pointer to a Data','line_number':25,'multiline':False]['text':' object.','line_number':26,'multiline':False]['text':' TODO(alanwaketan): Remove this ctor. This is a','line_number':40,'multiline':False]['text':' temporary ctor to ease XLA LTC migration. It depends on','line_number':41,'multiline':False]['text':' XLA's Functionalization integration.','line_number':42,'multiline':False]['text':' The default ctor previously created a null LazyTensor (one with no 'data'','line_number':63,'multiline':False]['text':' obj). Creating a null LazyTensor is no longer possible, since the same can','line_number':64,'multiline':False]['text':' be achieved by creating a null LazyTensorPtr and it is way too confusing to','line_number':65,'multiline':False]['text':' have to check both lazy_tensor_ptr && *lazy_tensor_ptr, so everywhere that','line_number':66,'multiline':False]['text':' used to rely on a LazyTensor obj with a null Data can now rely on a null','line_number':67,'multiline':False]['text':' LazyTensorPtr instead.','line_number':68,'multiline':False]['text':' Override it to use your own Shape.','line_number':79,'multiline':False]['text':' Override it to use your own graph executor.','line_number':82,'multiline':False]['text':' Assigns the tensor value to the lazy tensor.','line_number':87,'multiline':False]['text':' Override it to use your own type conversion.','line_number':96,'multiline':False]['text':' Fetches the data behind the tensor. If the tensor has a graph defining','line_number':104,'multiline':False]['text':' its current value, executes the graph and fetches the data result.','line_number':105,'multiline':False]['text':' Fetches the current value of the data, which can be missing (nullptr)','line_number':108,'multiline':False]['text':' in case the tensor has a graph defining its current value,','line_number':109,'multiline':False]['text':' Retrieves the current IR Node, or nullptr in case no active IR Node is','line_number':115,'multiline':False]['text':' available.','line_number':116,'multiline':False]['text':' Retrieves the IR Node representing this LazyTensor. One will be created if','line_number':119,'multiline':False]['text':' missing. Note that although this is a const API, it actually changes the','line_number':120,'multiline':False]['text':' internal state ofthe object.','line_number':121,'multiline':False]['text':' Applies the queue of operations in preparation for using the data.','line_number':133,'multiline':False]['text':' Override it to use your own graph executor.','line_number':134,'multiline':False]['text':' Override it to set extra information.','line_number':137,'multiline':False]['text':' We build a graph accumulating operations, but at a given point we','line_number':145,'multiline':False]['text':' need to force a rendering, otherwise the graph can grow without control.','line_number':146,'multiline':False]['text':' Think:','line_number':147,'multiline':False]['text':'   for i in range(0, 100000):','line_number':148,'multiline':False]['text':'     a = a + b','line_number':149,'multiline':False]['text':' Override it to instantiate your own data.','line_number':152,'multiline':False]['text':' Utils to convert at::Tensor to LazyTensor, and vice versa.','line_number':169,'multiline':False]['text':' Section 0: c10::Tensorlist ==> lazy::TensorList','line_number':171,'multiline':False]['text':' note: GetTensorList is not totally parallel to GetLtcTensor; A TensorList','line_number':172,'multiline':False]['text':' skips','line_number':173,'multiline':False]['text':'       the LazyTensor wrappers, assuming that the list of underlying IR nodes','line_number':174,'multiline':False]['text':'       is actually more useful for downstream computations.  TBD.','line_number':175,'multiline':False]['text':' Section 1: at::Tensor => LazyTensor.','line_number':178,'multiline':False]['text':' Extracts the LazyTensor out of an at::Tensor. Returns a null LazyTensor','line_number':179,'multiline':False]['text':' if the tensor is not a lazy tensor.','line_number':180,'multiline':False]['text':' Extracts the LazyTensor out of an at::Tensor. Throws an exception','line_number':183,'multiline':False]['text':' if the tensor is not a lazy tensor.','line_number':184,'multiline':False]['text':' Same as above, applied to a list of tensors.','line_number':187,'multiline':False]['text':' If tensor is a lazy tensor type, returns the LazyTensor embedded within it,','line_number':191,'multiline':False]['text':' otherwise creates a new lazy tensor type with tensor as data.','line_number':192,'multiline':False]['text':' Section 2: LazyTensor => at::Tensor.','line_number':201,'multiline':False]['text':' Creates an ATen tensor from an LazyTensor.','line_number':202,'multiline':False]['text':' Note [Lazy Tensor Functionalization]','line_number':206,'multiline':False]['text':' The functionalization pass is implemented by wrapping all TensorImpl','line_number':207,'multiline':False]['text':' objects in C++ with an extra FunctionalTensorWrapper object,','line_number':208,'multiline':False]['text':' that knows how to perform functionalization','line_number':209,'multiline':False]['text':'','line_number':210,'multiline':False]['text':' Certain functions in the aten API serve as entry/exit points for','line_number':211,'multiline':False]['text':' functionalization, where we need to perform the wrapping/unwrapping:','line_number':212,'multiline':False]['text':' - aten::to.device','line_number':213,'multiline':False]['text':' - aten::empty','line_number':214,'multiline':False]['text':' Given a non-lazy tensor, this function creates a lazy tensor on the specified','line_number':216,'multiline':False]['text':' (lazy) device. The functionalize_output determines whether or not we should','line_number':217,'multiline':False]['text':' wrap the output in a "functional wrapper".','line_number':218,'multiline':False]['text':'','line_number':219,'multiline':False]['text':' How do you know whether to pass true/false for functionalize_output?','line_number':220,'multiline':False]['text':'','line_number':221,'multiline':False]['text':' Case 1: nonlazy -> lazy','line_number':222,'multiline':False]['text':'   If you're implementing a function that takes in nonlazy tensors and returns','line_number':223,'multiline':False]['text':'   lazy tensors, then you should think of that function as an "entrypoint" to','line_number':224,'multiline':False]['text':'   functionalization, and use functionalize_output=true Examples include:','line_number':225,'multiline':False]['text':'   - factory functions (the LTC kernel for at::empty)','line_number':226,'multiline':False]['text':'   - CPU -> Lazy device converions (the LTC kernel for at::to_device)','line_number':227,'multiline':False]['text':'','line_number':228,'multiline':False]['text':' Case 2: lazy -> lazy','line_number':229,'multiline':False]['text':'   If you're implementing a function that takes in lazy tensors and returns','line_number':230,'multiline':False]['text':'   lazy tensors,','line_number':231,'multiline':False]['text':'   **but** requires creating lazy tensors internally,','line_number':232,'multiline':False]['text':'   then you can assume that the current function is running inside of some','line_number':233,'multiline':False]['text':'   outer context where functionalization is already running, that will take','line_number':234,'multiline':False]['text':'   care of doing the wrapping for you, and use functionalize_output=true','line_number':235,'multiline':False]['text':'   Examples include:','line_number':236,'multiline':False]['text':'   - CPU fallback (takes in lazy tensors, converts to cpu, calls kernel,','line_number':237,'multiline':False]['text':'   converts returns back to lazy tensors).','line_number':238,'multiline':False]['text':' namespace lazy','line_number':258,'multiline':False]['text':' namespace torch','line_number':259,'multiline':False]