['text':' WARNING: Be careful when adding new includes here. This header will be used','line_number':13,'multiline':False]['text':' in model.so, and should not refer to any aten/c10 headers except the stable','line_number':14,'multiline':False]['text':' C ABI defined in torch/csrc/inductor/aoti_torch/c/shim.h. The same rule','line_number':15,'multiline':False]['text':' applies to other files under torch/csrc/inductor/aoti_runtime/.','line_number':16,'multiline':False]['text':' At codegen time, we write out a binary file called constants.bin.','line_number':36,'multiline':False]['text':' We then turn the raw binary to an object file that exposes this','line_number':37,'multiline':False]['text':' symbol and link it into the final .so.','line_number':38,'multiline':False]['text':' For information on the binary format, see `man objcopy`, under','line_number':39,'multiline':False]['text':' the "binary-architecture" flag:','line_number':40,'multiline':False]['text':' https://man7.org/linux/man-pages/man1/objcopy.1.html','line_number':41,'multiline':False]['text':' todo: use #embed in C++ 23 once available','line_number':42,'multiline':False]['text':' USE_CUDA','line_number':61,'multiline':False]['text':' anonymous namespace','line_number':63,'multiline':False]['text':' RAIIAtenTensorHandle steals the tensor objects created by the libtorch C ABI','line_number':91,'multiline':False]['text':' Steal the ownership from another RAIIAtenTensorHandle using std::move','line_number':98,'multiline':False]['text':' Steal the ownership from raw AtenTensorHandle','line_number':102,'multiline':False]['text':' Return a raw AtenTensorHandle to be used by aoti_torch functions','line_number':110,'multiline':False]['text':' Note: this function does NOT transfer the ownership of the handle','line_number':111,'multiline':False]['text':' Shouldn't be called.','line_number':188,'multiline':False]['text':' Steal the ownership from raw AtenTensorHandle to RAIIAtenTensorHandle','line_number':192,'multiline':False]['text':' Defines the base class for AOTInductorModel, which is generated by the','line_number':205,'multiline':False]['text':' AOTInductor cpp codegen. Since we do not need dynamic dispatch, we rely','line_number':206,'multiline':False]['text':' on curiously recurring template pattern (CRTP) to save some runtime','line_number':207,'multiline':False]['text':' v-table overhead. The generated AOTInductorModel is specialized with','line_number':208,'multiline':False]['text':' methods such as run_impl.','line_number':209,'multiline':False]['text':' USE_CUDA','line_number':225,'multiline':False]['text':' USE_CUDA','line_number':237,'multiline':False]['text':' array of input AtenTensorHandle; handles','line_number':247,'multiline':False]['text':' are stolen; the array itself is borrowed','line_number':248,'multiline':False]['text':' array for writing output AtenTensorHandle; handles','line_number':250,'multiline':False]['text':' will be stolen by the caller; the array itself is','line_number':251,'multiline':False]['text':' borrowed','line_number':252,'multiline':False]['text':' !USE_CUDA','line_number':265,'multiline':False]['text':' USE_CUDA','line_number':270,'multiline':False]['text':' Create at::Tensor from copied memory.','line_number':295,'multiline':False]['text':' should be the same as was used for constant_blob_','line_number':308,'multiline':False]['text':' USE_CUDA','line_number':311,'multiline':False]['text':' Copy data to GPU memory','line_number':346,'multiline':False]['text':' TODO: Handle shared storage case.','line_number':347,'multiline':False]['text':' !USE_CUDA','line_number':354,'multiline':False]['text':' get pointer to constant which is packed in model during compile time.','line_number':355,'multiline':False]['text':' USE_CUDA','line_number':357,'multiline':False]['text':' Compute required blob size with 64-alignment if on GPU.','line_number':365,'multiline':False]['text':' USE_CUDA','line_number':376,'multiline':False]['text':' This function allows us to update the constants_ that is used to look up','line_number':465,'multiline':False]['text':' the corresponding constant tensor during runtime.','line_number':466,'multiline':False]['text':'/ Returns true if the model is complete.','line_number':472,'multiline':False]['text':' !USE_CUDA','line_number':489,'multiline':False]['text':' USE_CUDA','line_number':491,'multiline':False]['text':'/ Synchronizes completion event.','line_number':494,'multiline':False]['text':' USE_CUDA','line_number':502,'multiline':False]['text':' Holds the blob storage for constants' at::Tensor for CUDA.','line_number':529,'multiline':False]['text':' USE_CUDA','line_number':531,'multiline':False]['text':' A directory with CUDA binary files, e.g. compiled kernels, etc.','line_number':533,'multiline':False]['text':' Record if the model finishes an inference run so that its owning','line_number':536,'multiline':False]['text':' AOTModelContainer can re-use this instance.','line_number':537,'multiline':False]['text':' !USE_CUDA','line_number':540,'multiline':False]['text':' Generated model uses this device index to create CUDA guards.','line_number':544,'multiline':False]['text':' Codegen-ed classes can derive from this to keep pointers to loaded kernels.','line_number':548,'multiline':False]['text':' array of input AtenTensorHandle; handles','line_number':563,'multiline':False]['text':' are stolen; the array itself is borrowed','line_number':564,'multiline':False]['text':' array for writing output AtenTensorHandle; handles','line_number':566,'multiline':False]['text':' will be stolen by the caller; the array itself is','line_number':567,'multiline':False]['text':' borrowed','line_number':568,'multiline':False]['text':' USE_CUDA','line_number':607,'multiline':False]['text':' namespace aot_inductor','line_number':609,'multiline':False]['text':' namespace torch','line_number':610,'multiline':False]