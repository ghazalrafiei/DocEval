['text':' This header defines a stable C API for certain ATen functionality in','line_number':7,'multiline':False]['text':' libtorch. The AOTInductor compiled model.so will only refer to this header','line_number':8,'multiline':False]['text':' instead of other headers from aten/c10, which means it will NOT be able to','line_number':9,'multiline':False]['text':' directly use any data structures or call functions from libtorch.','line_number':10,'multiline':False]['text':'','line_number':11,'multiline':False]['text':' What problems are we trying to solve here?  Direct use of aten/c10 APIs','line_number':12,'multiline':False]['text':' means use of C++ APIs on a library that doesn't have any ABI compatibility','line_number':13,'multiline':False]['text':' guarantees.  However, we want model.so to remain usable across updates','line_number':14,'multiline':False]['text':' to the PyTorch C++ libraries, which requires a stable ABI.  By introducing','line_number':15,'multiline':False]['text':' a C shim layer, we can minimize the surface that will cause breakage. The','line_number':16,'multiline':False]['text':' corresponding software stack can be illustrated as follows:','line_number':17,'multiline':False]['text':'','line_number':18,'multiline':False]['text':' |--------------------------------|','line_number':19,'multiline':False]['text':' |     inference service code     |','line_number':20,'multiline':False]['text':' |--------------------------------|','line_number':21,'multiline':False]['text':' |           model.so             |','line_number':22,'multiline':False]['text':' |--------------|-----------------|','line_number':23,'multiline':False]['text':' |           <c shim>             |','line_number':24,'multiline':False]['text':' |          libtorch.so           |','line_number':25,'multiline':False]['text':' |--------------------------------|','line_number':26,'multiline':False]['text':'','line_number':27,'multiline':False]['text':' The general guidelines for the C API:','line_number':28,'multiline':False]['text':'','line_number':29,'multiline':False]['text':'  - No exceptions, return an explicit error code to be checked at call site','line_number':30,'multiline':False]['text':'  - Only pointers (AtenTensorHandle counts), integers and floats in headers','line_number':31,'multiline':False]['text':'','line_number':32,'multiline':False]['text':' If you want to make changes to this header, you MUST MAINTAIN ABI','line_number':33,'multiline':False]['text':' compatibility.  Typically, this means you will have to add a _v2 version','line_number':34,'multiline':False]['text':' of a function that you, e.g., want to add a new function parameter to, and','line_number':35,'multiline':False]['text':' maintain the old and new versions of the APIs until all old model.so','line_number':36,'multiline':False]['text':' go out of use.','line_number':37,'multiline':False]['text':' !__GNUC__','line_number':41,'multiline':False]['text':' !_WIN32','line_number':44,'multiline':False]['text':' _WIN32','line_number':46,'multiline':False]['text':' __GNUC__','line_number':47,'multiline':False]['text':' AtenTensorHandle represents an abstract notion of Tensor that can be passed','line_number':53,'multiline':False]['text':' between model.so and libtorch.so.  The contents of the structure itself','line_number':54,'multiline':False]['text':' are private; model.so is not allowed to access any fields directly, it must','line_number':55,'multiline':False]['text':' go through functions defined in this ABI.  Under the hood, this is','line_number':56,'multiline':False]['text':' represented as at::Tensor*, but we reserve the right to change this (and in','line_number':57,'multiline':False]['text':' fact, we probably should change it to at::TensorImpl* at least).','line_number':58,'multiline':False]['text':'','line_number':59,'multiline':False]['text':' An AtenTensorHandle can be owning (please check the API reference for exact','line_number':60,'multiline':False]['text':' ownership/borrow semantics).  If you have an owning AtenTensorHandle','line_number':61,'multiline':False]['text':' in model.so, you are obligated to aoti_torch_delete_tensor_object when you','line_number':62,'multiline':False]['text':' are done.  You can use the helper C++ class RAIIAtenTensorHandle','line_number':63,'multiline':False]['text':' (see aot_runtime/model.h) to ensure the deallocator is called in RAII style','line_number':64,'multiline':False]['text':' (note that RAIIAtenTensorHandle is private to model.so, and never crosses','line_number':65,'multiline':False]['text':' the ABI boundary.)','line_number':66,'multiline':False]['text':' Getter functions for retrieving various constants from the runtime, that','line_number':77,'multiline':False]['text':' can subsequently be passed to other aoti_* functions.  By hiding these','line_number':78,'multiline':False]['text':' behind functions, the precise value of device/dtype is NOT part of the','line_number':79,'multiline':False]['text':' ABI contract.  (In practice, aten/c10 is pretty good about not renumbering','line_number':80,'multiline':False]['text':' these, so we probably could later switch to having these in the ABI, if','line_number':81,'multiline':False]['text':' desired for perf reasons.)','line_number':82,'multiline':False]['text':' Free the tensor object','line_number':102,'multiline':False]['text':' Get a pointer to the underlying storage data','line_number':106,'multiline':False]['text':' returns borrowed reference','line_number':109,'multiline':False]['text':' Get the nbytes of the underlying storage','line_number':112,'multiline':False]['text':' returns borrowed reference','line_number':124,'multiline':False]['text':' returns borrowed reference','line_number':132,'multiline':False]['text':' This function will create a new tensor object and its pointer is returned','line_number':160,'multiline':False]['text':' through *out. The caller is responsible for wrapping the tensor pointer','line_number':161,'multiline':False]['text':' with RAIIAtenTensorHandle which will call aoti_torch_delete_tensor_object','line_number':162,'multiline':False]['text':' when going out of scope.','line_number':163,'multiline':False]['text':' returns new reference','line_number':170,'multiline':False]['text':' This function will create a new tensor object and its pointer is returned','line_number':173,'multiline':False]['text':' through *out. The caller is responsible for wrapping the tensor pointer','line_number':174,'multiline':False]['text':' with RAIIAtenTensorHandle which will call aoti_torch_delete_tensor_object','line_number':175,'multiline':False]['text':' when going out of scope.','line_number':176,'multiline':False]['text':' returns new reference','line_number':184,'multiline':False]['text':' returns new reference','line_number':196,'multiline':False]['text':' This version is deprecated. We will remove it later','line_number':199,'multiline':False]['text':' returns new reference','line_number':208,'multiline':False]['text':' returns new reference','line_number':209,'multiline':False]['text':' returns new reference','line_number':210,'multiline':False]['text':' returns new reference','line_number':211,'multiline':False]['text':' returns new reference','line_number':214,'multiline':False]['text':' returns new reference','line_number':215,'multiline':False]['text':' returns new reference','line_number':216,'multiline':False]['text':' returns new reference','line_number':228,'multiline':False]['text':' returns new reference','line_number':229,'multiline':False]['text':' returns new reference','line_number':230,'multiline':False]['text':' returns new reference','line_number':231,'multiline':False]['text':' returns new reference','line_number':234,'multiline':False]['text':' returns new reference','line_number':235,'multiline':False]['text':' returns new reference','line_number':236,'multiline':False]['text':' optional argument','line_number':254,'multiline':False]['text':' returns new reference','line_number':265,'multiline':False]['text':' This function will create a new uninitialized tensor object','line_number':268,'multiline':False]['text':' and its pointer is returned through *ret.','line_number':269,'multiline':False]['text':' Make the tensor referred to by dst an alias for the tensor referred','line_number':276,'multiline':False]['text':' to by src. The two tensors must still be deleted with','line_number':277,'multiline':False]['text':' aoti_torch_delete_tensor separately (or not) as before the call.','line_number':278,'multiline':False]['text':' This function will create a new tensor object and its pointer is returned','line_number':282,'multiline':False]['text':' through *ret. The caller is responsible for wrapping the tensor pointer','line_number':283,'multiline':False]['text':' with RAIIAtenTensorHandle which will call aoti_torch_delete_tensor_object','line_number':284,'multiline':False]['text':' when going out of scope.','line_number':285,'multiline':False]['text':' returns new reference','line_number':333,'multiline':False]['text':' See `ProxyExecutor Design Note` in ir.py for more details','line_number':340,'multiline':False]['text':' extern "C"','line_number':350,'multiline':False]['text':' REVIEW: bfloat16 and half don't seem to actually build? Do I have','line_number':361,'multiline':False]['text':' the wrong types?','line_number':362,'multiline':False]['text':'  DEFINE_DTYPE_SPECIALIZATION(__bfloat16, bfloat16)','line_number':363,'multiline':False]['text':'  DEFINE_DTYPE_SPECIALIZATION(half, float16)','line_number':364,'multiline':False]['text':' AOTI_TORCH_SHIM','line_number':376,'multiline':False]