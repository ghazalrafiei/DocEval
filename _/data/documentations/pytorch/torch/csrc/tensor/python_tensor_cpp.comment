['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-c-arrays,cppcoreguidelines-avoid-magic-numbers,modernize-avoid-c-arrays)','line_number':40,'multiline':False]['text':' TODO: Deprecate this instancecheck entirely.  It's here to make','line_number':95,'multiline':False]['text':' instanceof(t, torch.FloatTensor) work, but we are not going to keep','line_number':96,'multiline':False]['text':' adding torch.QuantizedIntTensor classes for every new tensor type','line_number':97,'multiline':False]['text':' we add...','line_number':98,'multiline':False]['text':' NB: This is a little unfortunate, in that if I do an isinstance check','line_number':104,'multiline':False]['text':' against torch.cuda.FloatTensor, this will immediately initialize CUDA.','line_number':105,'multiline':False]['text':' I originally thought that it would not be possible for aten_type_ to','line_number':106,'multiline':False]['text':' be nullptr if you had a tensor of some type, in which case you can','line_number':107,'multiline':False]['text':' skip initializing aten_type(), but TestAutograd.test_type_conversions','line_number':108,'multiline':False]['text':' seems to violate this property (for whatever reason.)','line_number':109,'multiline':False]['text':'','line_number':110,'multiline':False]['text':' TODO: Stop using legacyExtractDispatchKey here (probably need to build','line_number':111,'multiline':False]['text':' in instanceof checking to Tensor class itself)','line_number':112,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-c-arrays,cppcoreguidelines-avoid-non-const-global-variables,modernize-avoid-c-arrays)','line_number':162,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-c-arrays,cppcoreguidelines-avoid-non-const-global-variables,modernize-avoid-c-arrays)','line_number':169,'multiline':False]['text':' tp_name ','line_number':180,'multiline':True]['text':' tp_basicsize ','line_number':181,'multiline':True]['text':' NOLINTNEXTLINE(misc-redundant-expression)','line_number':185,'multiline':False]['text':' tp_name ','line_number':196,'multiline':True]['text':' tp_basicsize ','line_number':197,'multiline':True]['text':' NOTE: we don't use the typical static declaration of PyTypeObject because','line_number':204,'multiline':False]['text':' we need to initialize as many types as there are VariableType instances.','line_number':205,'multiline':False]['text':' We copy the basic object fields from a prototype definition and initialize','line_number':206,'multiline':False]['text':' the remaining fields below.','line_number':207,'multiline':False]['text':' Subclassing from torch.<ScalarType>Tensor isn't supported.','line_number':209,'multiline':False]['text':' (Py_TPFLAGS_BASETYPE omitted). Subclassing torch.Tensor still allowed.','line_number':210,'multiline':False]['text':' This field is lazily initialized from backend and scalar_type','line_number':262,'multiline':False]['text':' A note about the lifetime of the various PyTensorType: normally','line_number':305,'multiline':False]['text':' PyTypeObject instances are statically allocated, but we want to create them','line_number':306,'multiline':False]['text':' dynamically at init time, because their exact number depends on','line_number':307,'multiline':False]['text':' torch::utils::all_declared_types(). The memory for each PyTensorType is','line_number':308,'multiline':False]['text':' allocated by initialize_aten_types() and never freed: technically it's a','line_number':309,'multiline':False]['text':' leak, but it's not a problem since we want them to be alive for the whole','line_number':310,'multiline':False]['text':' time of the process anyway.','line_number':311,'multiline':False]['text':'','line_number':312,'multiline':False]['text':' An alternative is to use a std::vector<PyTensorType> instead, and let','line_number':313,'multiline':False]['text':' std::vector to manage the lifetime of its items. This is problematic','line_number':314,'multiline':False]['text':' though, because it means that the memory of PyTensorType is deallocated at','line_number':315,'multiline':False]['text':' some point during the exit: if by chance we have another global destructor','line_number':316,'multiline':False]['text':' and/or atexit() function which tries to access the PyTensorTypes, we risk','line_number':317,'multiline':False]['text':' an use-after-free error. This happens for example if we embed CPython and','line_number':318,'multiline':False]['text':' call Py_Finalize inside an atexit() function which was registered before','line_number':319,'multiline':False]['text':' importing torch.','line_number':320,'multiline':False]['text':' Try setting default storage in python first as it's the only operation that','line_number':351,'multiline':False]['text':' can fail','line_number':352,'multiline':False]['text':' includes CUDA types even when PyTorch is not built with CUDA','line_number':366,'multiline':False]['text':' Initialize the at::Type* pointers, name, and properties of the PyTensorType','line_number':383,'multiline':False]['text':' vector. After this call, the vector must not be resized.','line_number':384,'multiline':False]['text':' Initialize the Python metaclass for the torch.FloatTensor, etc. types.','line_number':387,'multiline':False]['text':' The metaclass handles __instancecheck__ checks and binds the dtype property','line_number':388,'multiline':False]['text':' on the type objects.','line_number':389,'multiline':False]['text':' Get the tp_dict of the Variable class. We copy function definitions','line_number':392,'multiline':False]['text':' onto each Tensor type object so that they can be accessed via e.g.','line_number':393,'multiline':False]['text':' `torch.FloatTensor.add`.','line_number':394,'multiline':False]['text':' Initialize each Python type object torch.FloatTensor, torch.DoubleTensor,','line_number':397,'multiline':False]['text':' etc.','line_number':398,'multiline':False]['text':' Add the type objects to their corresponding modules. e.g. torch.FloatTensor','line_number':404,'multiline':False]['text':' is added to the `torch` module as `FloatTensor`. Also add all the type','line_number':405,'multiline':False]['text':' objects to the set torch._tensor_classes.','line_number':406,'multiline':False]['text':'backend=','line_number':469,'multiline':True]['text':' namespace tensors','line_number':484,'multiline':False]['text':' namespace torch','line_number':485,'multiline':False]