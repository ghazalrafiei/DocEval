['text':' Get the return type of the forward function of the custom Function class X','line_number':33,'multiline':False]['text':'/ To use custom autograd operations, implement a Function subclass with','line_number':37,'multiline':False]['text':'/ static forward and backward functions:','line_number':38,'multiline':False]['text':'/','line_number':39,'multiline':False]['text':'/ `forward` can take as many arguments as you want and should return either a','line_number':40,'multiline':False]['text':'/ variable list or a Variable. Use of any direct Variable arguments will be','line_number':41,'multiline':False]['text':'/ registered in the graph but no vectors/sets or any other data structures','line_number':42,'multiline':False]['text':'/ will be traversed. You can use c10::optional<Tensor> as one of the arguments','line_number':43,'multiline':False]['text':'/ and it will be registered as a variable in the graph if the argument has a','line_number':44,'multiline':False]['text':'/ value. It should take a pointer to `torch::autograd::AutogradContext` as the','line_number':45,'multiline':False]['text':'/ first argument. Variables can be saved in the `ctx` using','line_number':46,'multiline':False]['text':'/ `ctx->save_for_backward`','line_number':47,'multiline':False]['text':'/ (see `torch::autograd::AutogradContext::save_for_backward`) and other data','line_number':48,'multiline':False]['text':'/ can be saved in the `ctx->saved_data` map','line_number':49,'multiline':False]['text':'/ (see `torch::autograd::AutogradContext::saved_data`)','line_number':50,'multiline':False]['text':'/ in the form of `<std::string, at::IValue>` pairs.','line_number':51,'multiline':False]['text':'/','line_number':52,'multiline':False]['text':'/ `backward` should take a pointer to `torch::autograd::AutogradContext`','line_number':53,'multiline':False]['text':'/ and a variable list containing as many Variables as there were outputs from','line_number':54,'multiline':False]['text':'/ `forward` as arguments. It should return as many Variables as there were','line_number':55,'multiline':False]['text':'/ inputs with each of them containing the gradient w.r.t. its corresponding','line_number':56,'multiline':False]['text':'/ input. Variables saved in `forward` can be accessed with','line_number':57,'multiline':False]['text':'/ `ctx->get_saved_variables` (see','line_number':58,'multiline':False]['text':'/ `torch::autograd::AutogradContext::get_saved_variables`) and other saved','line_number':59,'multiline':False]['text':'/ data can be accessed from `ctx->saved_data`.','line_number':60,'multiline':False]['text':'/','line_number':61,'multiline':False]['text':'/ For example:','line_number':62,'multiline':False]['text':'/ ```','line_number':63,'multiline':False]['text':'/ class MyFunction : public Function<MyFunction> {','line_number':64,'multiline':False]['text':'/   public:','line_number':65,'multiline':False]['text':'/   static variable_list forward(AutogradContext *ctx, int n, Variable var) {','line_number':66,'multiline':False]['text':'/      // Save data for backward in context','line_number':67,'multiline':False]['text':'/      ctx->saved_data["n"] = n;','line_number':68,'multiline':False]['text':'/      var.mul_(2);','line_number':69,'multiline':False]['text':'/      // Mark var as modified by inplace operation','line_number':70,'multiline':False]['text':'/      ctx->mark_dirty({var});','line_number':71,'multiline':False]['text':'/      return {var};','line_number':72,'multiline':False]['text':'/   }','line_number':73,'multiline':False]['text':'/','line_number':74,'multiline':False]['text':'/   static variable_list backward(AutogradContext *ctx, variable_list','line_number':75,'multiline':False]['text':'/   grad_output) {','line_number':76,'multiline':False]['text':'/      // Use data saved in forward','line_number':77,'multiline':False]['text':'/      auto n = ctx->saved_data["n"].toInt();','line_number':78,'multiline':False]['text':'/      return {grad_output[0]*n};','line_number':79,'multiline':False]['text':'/   }','line_number':80,'multiline':False]['text':'/ };','line_number':81,'multiline':False]['text':'/ ```','line_number':82,'multiline':False]['text':'/','line_number':83,'multiline':False]['text':'/ To use `MyFunction`:','line_number':84,'multiline':False]['text':'/ ```','line_number':85,'multiline':False]['text':'/ Variable x;','line_number':86,'multiline':False]['text':'/ auto y = MyFunction::apply(6, x);','line_number':87,'multiline':False]['text':'/ // Example backward call','line_number':88,'multiline':False]['text':'/ y[0].sum().backward();','line_number':89,'multiline':False]['text':'/ ```','line_number':90,'multiline':False]['text':' We need to use a different template parameter than T here because T will','line_number':93,'multiline':False]['text':' inherit from Function, and when Function<T> is instantiated, T::forward','line_number':94,'multiline':False]['text':' is not declared yet.','line_number':95,'multiline':False]['text':' The enable_if check is to ensure that the user doesn't explicitly provide','line_number':96,'multiline':False]['text':' the parameter X.','line_number':97,'multiline':False]['text':'/ Context to save information during `forward` that can be accessed in','line_number':103,'multiline':False]['text':'/ `backward` in custom autograd operations (see `torch::autograd::Function`','line_number':104,'multiline':False]['text':'/ for details).','line_number':105,'multiline':False]['text':'/ Can be used to save non-variable data for `backward`.','line_number':111,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-non-private-member-variables-in-classes)','line_number':112,'multiline':False]['text':'/ Saves the list of variables for a future call to `backward`. This','line_number':115,'multiline':False]['text':'/ should be called at most once from inside of `forward`.','line_number':116,'multiline':False]['text':'/ Marks variables in the list as modified in an in-place operation. This','line_number':118,'multiline':False]['text':'/ should be called at most once from inside of `forward` and all arguments','line_number':119,'multiline':False]['text':'/ should be inputs.','line_number':120,'multiline':False]['text':'/ Marks outputs in the list as not requiring gradients. This should be','line_number':122,'multiline':False]['text':'/ called at most once from inside of `forward` and all arguments should be','line_number':123,'multiline':False]['text':'/ outputs.','line_number':124,'multiline':False]['text':' Sets whether undefined output grad tensors should be expanded to tensors','line_number':126,'multiline':False]['text':' full of zeros before calling backward function. Default value is true.','line_number':127,'multiline':False]['text':'/ Get the list of variables that were saved in `forward` using','line_number':130,'multiline':False]['text':'/ `save_for_backward()`. Before returning them to the user, a check is made','line_number':131,'multiline':False]['text':'/ to ensure that they were not modified by any in-place operations.','line_number':132,'multiline':False]['text':'/ Expose the Node's `task_should_compute_output` method to the cpp','line_number':137,'multiline':False]['text':'/ custom autograd Function as `needs_input_grad`.','line_number':138,'multiline':False]['text':' The CppNode in the autograd graph that owns this AutogradContext. We need a','line_number':149,'multiline':False]['text':' weak_ptr to avoid a refcycle. Since grad_fn_ owns this AutogradContext, it','line_number':150,'multiline':False]['text':' will always be alive when we want to use it.','line_number':151,'multiline':False]['text':' CppNode<T> is the Node in the autograd graph that represents the user defined','line_number':175,'multiline':False]['text':' backward function for Function<T>. Calls to CppNode::apply are forward to','line_number':176,'multiline':False]['text':' T::backward().','line_number':177,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':198,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':233,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':254,'multiline':False]['text':' Function support for functorch is handled in Python.','line_number':270,'multiline':False]['text':' Here we are dealing with a (C++) Function, which is not supported.','line_number':271,'multiline':False]['text':' Let's raise an error instead of being silently incorrect.','line_number':272,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':277,'multiline':False]['text':' TODO Add tracing here','line_number':283,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':286,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':301,'multiline':False]['text':' wrapped_outputs will be a variable_list so, convert it to the correct','line_number':343,'multiline':False]['text':' return type. Only Variable and variable_list are accepted as return types.','line_number':344,'multiline':False]['text':' The logic here is the same as PyNode::apply, so changes to it should be done','line_number':348,'multiline':False]['text':' in both the places','line_number':349,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':354,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':356,'multiline':False]['text':' Acquire lock to here protect thread safety on custom C++ Autograd Node','line_number':367,'multiline':False]['text':' This is needed for the custom Autograd Node since we don't know if the','line_number':368,'multiline':False]['text':' user defined Node will write to the shared data during backward.','line_number':369,'multiline':False]['text':' see Note [Thread Safety on Autograd Node]','line_number':370,'multiline':False]['text':' Returning too many results is ok, but only as long as they're all','line_number':378,'multiline':False]['text':' undefined. Truncate the result vector in that case.','line_number':379,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':399,'multiline':False]['text':' lock to ensure thread safety, see [Thread Safety on Autograd Node]','line_number':421,'multiline':False]['text':' namespace autograd','line_number':437,'multiline':False]['text':' namespace torch','line_number':438,'multiline':False]