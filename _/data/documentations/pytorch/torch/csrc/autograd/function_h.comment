['text':' Custom deleter to prevent stack overflows.','line_number':42,'multiline':False]['text':' Guard that sets and restores the evaluating node','line_number':45,'multiline':False]['text':' Return the Node currently being evaluated (if any)','line_number':55,'multiline':False]['text':' This is only set during the backward pass while a Node is being','line_number':56,'multiline':False]['text':' executed.','line_number':57,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':60,'multiline':False]['text':'                               Node','line_number':61,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':62,'multiline':False]['text':' A `Node` is an abstract class that represents an operation taking zero','line_number':63,'multiline':False]['text':' or more input `Variable`s and producing zero or more output `Variable`s. All','line_number':64,'multiline':False]['text':' functions in PyTorch's autograd machinery derive from this class and','line_number':65,'multiline':False]['text':' override its `apply` method. Instances of such subclasses will then be','line_number':66,'multiline':False]['text':' invokeable via the call operator.','line_number':67,'multiline':False]['text':'','line_number':68,'multiline':False]['text':'                    Nodes in the Autograd Graph','line_number':69,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':70,'multiline':False]['text':' When viewing the autograd system as a graph, `Node`s are the vertices or','line_number':71,'multiline':False]['text':' nodes, connected to each other via (directed) `Edge`s, which themselves are','line_number':72,'multiline':False]['text':' represented via (`Node`, input_nr) pairs. `Variable`s are the outputs to','line_number':73,'multiline':False]['text':' and inputs of `Node`s, and travel between these edges during execution','line_number':74,'multiline':False]['text':' of the graph. When two or more `Edge`s (from different sources) point at the','line_number':75,'multiline':False]['text':' same input to a `Node`, the values produced along all of these edges are','line_number':76,'multiline':False]['text':' implicitly summed prior to being forwarded to the target `Node`.','line_number':77,'multiline':False]['text':'','line_number':78,'multiline':False]['text':'                              Hierarchy','line_number':79,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':80,'multiline':False]['text':' Subclasses usually represent differentiable functions as well as their','line_number':81,'multiline':False]['text':' gradient operators. Note, however, that due to the very general definition','line_number':82,'multiline':False]['text':' of a `Node` taking *zero* or more inputs and producing *zero* or more','line_number':83,'multiline':False]['text':' outputs, uses of `Node`s are flexible and extend beyond purely','line_number':84,'multiline':False]['text':' mathematical operations. For example, the `AccumulateGrad` function is a','line_number':85,'multiline':False]['text':' *sink*: it takes one input, but produces no outputs, instead accumulating','line_number':86,'multiline':False]['text':' the input as a side effect. At the other extreme, the `GraphRoot` function','line_number':87,'multiline':False]['text':' receives no inputs from other functions, but produces multiple outputs.','line_number':88,'multiline':False]['text':'','line_number':89,'multiline':False]['text':'                              Interface','line_number':90,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':91,'multiline':False]['text':' The most important method on `Node` is the call operator, which takes in','line_number':92,'multiline':False]['text':' a list of variables and produces a list of variables. The precise size of','line_number':93,'multiline':False]['text':' these lists can be determined with `num_inputs()` and `num_outputs()`.','line_number':94,'multiline':False]['text':' `Node`s are stitched together via their `next_edge` interface, which let','line_number':95,'multiline':False]['text':' you manipulate the set of outgoing edges of a `Node`. You can add an','line_number':96,'multiline':False]['text':' edge with `add_next_edge()`, retrieve an edge with `next_edge(index)` and','line_number':97,'multiline':False]['text':' iterate over them via the `next_edges()` method. Other methods exist for','line_number':98,'multiline':False]['text':' integration with the JIT and other parts of PyTorch. Every `Node` has a','line_number':99,'multiline':False]['text':' *sequence number* that increases monotonically in the order of `Node`','line_number':100,'multiline':False]['text':' construction. It can be retrieved via the `sequence_nr()` method. Note that','line_number':101,'multiline':False]['text':' this sequence number is *thread local*. This means that when `Node`s','line_number':102,'multiline':False]['text':' `A`, `B` and `C` are created consecutively in the same thread, their','line_number':103,'multiline':False]['text':' sequence numbers will be ordered `A` < `B` < `C`. If, however, `A` and `B`','line_number':104,'multiline':False]['text':' are created in one thread and `C` is created in a new thread, there are *no','line_number':105,'multiline':False]['text':' guarantees* w.r.t. the ordering of `C` relative to `A` or `B`.','line_number':106,'multiline':False]['text':' See NOTE [ Sequence Number] for more details on the usages of sequence','line_number':107,'multiline':False]['text':' number.','line_number':108,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':109,'multiline':False]['text':'/ Construct a new `Node` with the given `next_edges`','line_number':112,'multiline':False]['text':' If anomaly mode is enabled and graph is constructed, then assign the','line_number':122,'multiline':False]['text':' currently evaluating node as the parent of this node.','line_number':123,'multiline':False]['text':' A parent is a Node where this Node is created.','line_number':124,'multiline':False]['text':' We are tracking the parents to track multiple backward operations.','line_number':125,'multiline':False]['text':' Store the thread_id of the forward operator.','line_number':129,'multiline':False]['text':' See NOTE [ Sequence Numbers ]','line_number':130,'multiline':False]['text':'sequence_nr=','line_number':136,'multiline':True]['text':'/ Nodes are neither copyable nor moveable.','line_number':139,'multiline':False]['text':'/ Evaluates the function on the given inputs and returns the result of the','line_number':149,'multiline':False]['text':'/ function call.','line_number':150,'multiline':False]['text':' In the first iteration of named tensors, autograd ignores names and','line_number':152,'multiline':False]['text':' operates on unnamed tensors. In the long term, autograd should','line_number':153,'multiline':False]['text':' probably operate with names.','line_number':154,'multiline':False]['text':' Keep track of backward pass for rocblas.','line_number':158,'multiline':False]['text':' Using sequence number and thread id to correlate with','line_number':166,'multiline':False]['text':' the forward pass function','line_number':167,'multiline':False]['text':' Graph Connectivity API','line_number':185,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':186,'multiline':False]['text':' Inputs. NOTE: inputs of the grad_fn correspond to Tensor outputs of the','line_number':188,'multiline':False]['text':' forward function.','line_number':189,'multiline':False]['text':' Marker for expected undefined input','line_number':191,'multiline':False]['text':'/ Adds the type and shape metadata for a new input. Returns the index of','line_number':194,'multiline':False]['text':'/ of the new input.','line_number':195,'multiline':False]['text':'/ Adds a placeholder for an input that will not be used.','line_number':214,'multiline':False]['text':' Danger: not thread safe, caller must protect with lock','line_number':229,'multiline':False]['text':'*
   * Note: Function Streams
   * A function's stream (for a given device type) is the stream of the first
   * element of its input buffer on a device of that type.
   *
   * If all elements are on the same device they MUST share a stream. If
   * elements are on different devices (across multiple GPUs, for example)
   * they may have different streams.
   ','line_number':234,'multiline':True]['text':' Outputs ("Next Edges")','line_number':256,'multiline':False]['text':' Miscellaneous Methods','line_number':306,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':307,'multiline':False]['text':'/ NOTE [ Sequence Number]','line_number':309,'multiline':False]['text':'/','line_number':310,'multiline':False]['text':'/ The sequence_nr has two main usages in autograd:','line_number':311,'multiline':False]['text':'/','line_number':312,'multiline':False]['text':'/ 1) Helps determine the node's execution priority in the engine.','line_number':313,'multiline':False]['text':'/    All else being equal, nodes with higher priority numbers are executed','line_number':314,'multiline':False]['text':'/    first. Thus, nodes corresponding to ops executed later are the first to','line_number':315,'multiline':False]['text':'/    be executed in the backward pass. One caveat is that we prioritize','line_number':316,'multiline':False]['text':'/    AccumulateGrad nodes by explicitly setting its sequence_nr to be','line_number':317,'multiline':False]['text':'/    UINT64_MAX.','line_number':318,'multiline':False]['text':'/ 2) The sequence number of this `Node` is paired with with thread_id it was','line_number':319,'multiline':False]['text':'/ created in','line_number':320,'multiline':False]['text':'/    as a unique identifier by the profiler to annotate recorded events.','line_number':321,'multiline':False]['text':'/    The purpose of this is to help users (and possibly programs)','line_number':322,'multiline':False]['text':'/    interpreting the profiler's output to correlate backward nodes with its','line_number':323,'multiline':False]['text':'/    forward ops. We need both sequence_nr and thread_id to identify a node','line_number':324,'multiline':False]['text':'/    because sequence_nr is thread_local, i.e., starts counting up from zero','line_number':325,'multiline':False]['text':'/    in a new thread','line_number':326,'multiline':False]['text':' NOTE [ Topological Number ]','line_number':335,'multiline':False]['text':'','line_number':336,'multiline':False]['text':' topological_nr is used to prune branches in the DAG during autograd','line_number':337,'multiline':False]['text':' discovery as maintaining topological_nr helps us check in O(1) if there','line_number':338,'multiline':False]['text':' does NOT exist a directed path between two nodes.','line_number':339,'multiline':False]['text':'','line_number':340,'multiline':False]['text':' The topological order number of this `Node` representing the length of the','line_number':341,'multiline':False]['text':' longest possible path from this Node to any leaf node. If you are leaf','line_number':342,'multiline':False]['text':' node, aka AccumulateGrad, this will be zero. This value has the property','line_number':343,'multiline':False]['text':' that For every pair of nodes X, Y in G, existence of a directed path from X','line_number':344,'multiline':False]['text':' to Y implies topo_nr(X) > topo_nr(Y). The converse is not true, however, so','line_number':345,'multiline':False]['text':' we cannot prove existence of a path from X to Y, only non-existence.','line_number':346,'multiline':False]['text':'','line_number':347,'multiline':False]['text':' One assumption we make when using topo_nr is that once a node','line_number':348,'multiline':False]['text':' has been used, i.e., has a parent node, its own topo_nr does not change','line_number':349,'multiline':False]['text':' we have added some checks with the `has_parent_` field to enforce this.','line_number':350,'multiline':False]['text':'','line_number':351,'multiline':False]['text':' What NOT to do:','line_number':352,'multiline':False]['text':'','line_number':353,'multiline':False]['text':'   1) 2 -> 1 -> 0               In this diagram we label nodes with their','line_number':354,'multiline':False]['text':'   topo_nr.','line_number':355,'multiline':False]['text':'      2 -> 1 -> 0               We have two simple graphs that can each','line_number':356,'multiline':False]['text':'      arise from','line_number':357,'multiline':False]['text':'                                `t.exp().exp()`, for example.','line_number':358,'multiline':False]['text':'   2)        2 -> 1 -> 0','line_number':359,'multiline':False]['text':'            /','line_number':360,'multiline':False]['text':'      2 -> 1 -> 0               We add 2 as a next edge to 1 even though 1','line_number':361,'multiline':False]['text':'      already','line_number':362,'multiline':False]['text':'                                has a parent.','line_number':363,'multiline':False]['text':'   3)        2 -> 1 -> 0','line_number':364,'multiline':False]['text':'            /','line_number':365,'multiline':False]['text':'      2 -> 3 -> 0               2 < 3, yet there exists a path from 2 to 3!','line_number':366,'multiline':False]['text':'','line_number':367,'multiline':False]['text':' assigning a node as a parent to this node','line_number':373,'multiline':False]['text':'/ Id of the thread that created Node','line_number':376,'multiline':False]['text':'/ Returns the name of the dynamic type of the function, for debugging.','line_number':381,'multiline':False]['text':'/ The difference between functions `should_compute_output` and','line_number':384,'multiline':False]['text':'/ `task_should_compute_output`:','line_number':385,'multiline':False]['text':'/ - `should_compute_output` should only be used during graph construction','line_number':386,'multiline':False]['text':'/ and takes into account only requires_grad information','line_number':387,'multiline':False]['text':'/ - `task_should_compute_output` should only be called during the backward','line_number':388,'multiline':False]['text':'/ pass (unless called directly through grad_fn) and takes into account the','line_number':389,'multiline':False]['text':'/ current graph task.  Specifically, the autograd engine trims unnecessary','line_number':390,'multiline':False]['text':'/ edges when `inputs` are specified, and during backward untrimmed nodes','line_number':391,'multiline':False]['text':'/ left on the graph can/should check `task_should_compute_output` to see if','line_number':392,'multiline':False]['text':'/ any outgoing edges have been trimmed by the engine. If that is the case,','line_number':393,'multiline':False]['text':'/ gradient computation wrt those edges can be omitted.','line_number':394,'multiline':False]['text':'/','line_number':395,'multiline':False]['text':'/ Returns true if the particular output edge is active, and that particular','line_number':396,'multiline':False]['text':'/ output of this function should be computed.','line_number':397,'multiline':False]['text':'/ Returns true if any of the output edges in any of the ranges are active.','line_number':403,'multiline':False]['text':'/ Same as the above `should_compute_output` function but will also','line_number':414,'multiline':False]['text':'/ check whether this edge is needed within the current graph task.','line_number':415,'multiline':False]['text':' this edge is not needed for the current graph_task','line_number':424,'multiline':False]['text':'/ Returns true if any of the output edges in any of the ranges are active','line_number':432,'multiline':False]['text':'/ and should be computed in the current graph task.','line_number':433,'multiline':False]['text':'/ Returns the `PyObject` stored for this `Node` (for Python','line_number':445,'multiline':False]['text':'/ interaction).','line_number':446,'multiline':False]['text':'/ Sets the `PyObject` stored for this `Node` (for Python interaction).','line_number':451,'multiline':False]['text':'/ Returns the anomaly metadata stored for this `Node`.','line_number':456,'multiline':False]['text':'/ If none exist, creates a new empty one.','line_number':457,'multiline':False]['text':' Hook API','line_number':460,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':461,'multiline':False]['text':' Use the raw pointer as the unique key to identify this hook. This key','line_number':465,'multiline':False]['text':' can then be used in del_post_hook(key) to remove this hook.','line_number':466,'multiline':False]['text':' delete a post hook matching the key','line_number':475,'multiline':False]['text':' Customization Points for Subclasses','line_number':535,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':536,'multiline':False]['text':'/ Releases saved variables if the operation won't be reused.','line_number':538,'multiline':False]['text':'/ Called before an apply if `release_variables()` is going to be called.','line_number':541,'multiline':False]['text':'/ Allows larger ops like `InterpreterAutogradFunction` to incrementally','line_number':542,'multiline':False]['text':'/ release variables as they run.','line_number':543,'multiline':False]['text':'/ Returns true if this function is traceable. An op is traceable if all','line_number':546,'multiline':False]['text':'/ operations happening within `apply()` are performed on autograd','line_number':547,'multiline':False]['text':'/ `Variables` (i.e. apply mostly instantiates and applies other functions).','line_number':548,'multiline':False]['text':'/ A `Node` is said to pass state transparently to backward, if the','line_number':553,'multiline':False]['text':'/ state consists only of (Saved)Variables and only non-variable objects','line_number':554,'multiline':False]['text':'/ that parameterize the operation in some way that defines the graph','line_number':555,'multiline':False]['text':'/ structure AND the backward function is traceable. In particular,','line_number':556,'multiline':False]['text':'/ parametrization MUST NOT depend on the data of any `Variable`.','line_number':557,'multiline':False]['text':'/ TODO: it might be possible to handle cases where backward is','line_number':558,'multiline':False]['text':'/ non-traceable but state passing could be considered transparent. This','line_number':559,'multiline':False]['text':'/ will probably depend on saved_variable_list being mutable.','line_number':560,'multiline':False]['text':'/ NOTE: this value matters only if is_traceable() returns false.','line_number':561,'multiline':False]['text':' see [Note: Compiled Autograd]','line_number':566,'multiline':False]['text':' Used by compiled autograd to','line_number':567,'multiline':False]['text':'   1) Extract tensors/symint args','line_number':568,'multiline':False]['text':'   2) Collect node information for specialization and caching','line_number':569,'multiline':False]['text':' Implementations in subclasses should call args.collect() with all node','line_number':570,'multiline':False]['text':' attrs. These functions are only called durring backward.','line_number':571,'multiline':False]['text':' Used by compiled autograd to call apply() with different saved tensors','line_number':577,'multiline':False]['text':' Implementations should call saved.before() on all attrs, then apply(), then','line_number':578,'multiline':False]['text':' saved.after() on all attrs in the same order.','line_number':579,'multiline':False]['text':'/ Performs the `Node`'s actual operation.','line_number':588,'multiline':False]['text':'/ Calls `apply()`, but instruments it with tracing machinery.','line_number':591,'multiline':False]['text':' Sequence number used to correlate backward nodes with forward ops in the','line_number':594,'multiline':False]['text':' profiler and provide determinism in the engine.','line_number':595,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-const-or-ref-data-members)','line_number':596,'multiline':False]['text':' See NOTE [ Topological Number ]','line_number':599,'multiline':False]['text':' Tracks whether this node has been added as the next_edge of another node','line_number':602,'multiline':False]['text':' via set_next_edge(s), which always calls topological_nr() of all its','line_number':603,'multiline':False]['text':' children See NOTE [ Topological Number ] for why we need this.','line_number':604,'multiline':False]['text':' Id of the thread that created the instance','line_number':607,'multiline':False]['text':' Note [Thread Safety on Autograd Node]','line_number':610,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':611,'multiline':False]['text':' Autograd Engine let the owning thread which calls Engine::execute to drive','line_number':612,'multiline':False]['text':' the GraphTask execution, there might be cases that part of the GraphTask is','line_number':613,'multiline':False]['text':' shared across different `backward()` or `grad()` calls, i.e. fork new','line_number':614,'multiline':False]['text':' threads in the middle of the forward and call `backward()` separately from','line_number':615,'multiline':False]['text':' different threads. We need to protect the thread safety on NodeTask to','line_number':616,'multiline':False]['text':' prevent data racing on shared variables read/write.','line_number':617,'multiline':False]['text':'','line_number':618,'multiline':False]['text':' NB: This is only needed for Autograd Nodes that runs on CPU, technically','line_number':619,'multiline':False]['text':' "CUDA", "XLA" nodes don't need locking because device threads are always','line_number':620,'multiline':False]['text':' single threaded.','line_number':621,'multiline':False]['text':'','line_number':622,'multiline':False]['text':' Here we add a thread mutex to help protect the Node's thread safety, so','line_number':623,'multiline':False]['text':' that different threads cannot race the shared data when executing the same','line_number':624,'multiline':False]['text':' NodeTask from multiple CPU threads. It IS the user/developer responsibility','line_number':625,'multiline':False]['text':' to take advantage of this mutex to protect the thread safety of their','line_number':626,'multiline':False]['text':' autograd Node. The general strategy of thread safety on autograd Node:','line_number':627,'multiline':False]['text':'','line_number':628,'multiline':False]['text':' 1. User should lock the mutex during Node::release_variables() if the Node','line_number':629,'multiline':False]['text':' needs','line_number':630,'multiline':False]['text':'    to release the variables on the fly, this serve the purpose that when we','line_number':631,'multiline':False]['text':'    release saved_variables from one thread, no other threads can release','line_number':632,'multiline':False]['text':'    the saved variables concurrently. call the Node::apply(),','line_number':633,'multiline':False]['text':' 2. User should lock the mutex during Node::apply(), this is to ensure Node','line_number':634,'multiline':False]['text':' that','line_number':635,'multiline':False]['text':'    writing to the shared variable are not racing across threads (i.e.','line_number':636,'multiline':False]['text':'    AccumulateGrad and custom C++ Autograd Node if writing to shared','line_number':637,'multiline':False]['text':'    variables )','line_number':638,'multiline':False]['text':' 3. item 2 and item 3 should work together so that when we release saved','line_number':639,'multiline':False]['text':' variables','line_number':640,'multiline':False]['text':'    from one thread, no other threads can call Node::apply(), this ensures','line_number':641,'multiline':False]['text':'    the variable references from other threads aren't dangling.','line_number':642,'multiline':False]['text':' 4. if the Node don't release any variables and no shared data read/write in','line_number':643,'multiline':False]['text':' the Node','line_number':644,'multiline':False]['text':'    i.e. purely functional, user don't need to lock the mutex','line_number':645,'multiline':False]['text':'','line_number':646,'multiline':False]['text':' This way we could protect the thread safety on Autograd Node, but we could','line_number':647,'multiline':False]['text':' still not protect the thread safety on Node pre/post C++ hooks (python','line_number':648,'multiline':False]['text':' hooks are automatically thread safe), we rely on the user to write thread','line_number':649,'multiline':False]['text':' safe C++ hooks if they want the hook to be correctly applied in','line_number':650,'multiline':False]['text':' multithreading environment.','line_number':651,'multiline':False]['text':' weak reference','line_number':655,'multiline':False]['text':' NOTE [Hooks ordering]','line_number':658,'multiline':False]['text':' We have 3 separate fields for pre hooks registered to the autograd nodes','line_number':659,'multiline':False]['text':' because the conditions under which they execute are different, and we','line_number':660,'multiline':False]['text':' want more fine-grained control over the order in which different types','line_number':661,'multiline':False]['text':' of hooks are executed.','line_number':662,'multiline':False]['text':' - pre_hooks  are only executed when the node itself is executed','line_number':663,'multiline':False]['text':' - tensor_pre_hook is executed as long as the engine traverses over it','line_number':664,'multiline':False]['text':'   even if that node won't be executed.','line_number':665,'multiline':False]['text':' - retains_grad_hook are like tensor_pre_hooks except they are always','line_number':666,'multiline':False]['text':'   ordered after all other tensor pre hooks','line_number':667,'multiline':False]['text':'/ See Node::is_traceable() for definition.','line_number':676,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':684,'multiline':False]['text':'                       Associated Free Nodes','line_number':685,'multiline':False]['text':'~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':686,'multiline':False]['text':' Implementation of `collect_next_edges` (see below).','line_number':689,'multiline':False]['text':' namespace detail','line_number':711,'multiline':False]['text':'/ Create an `Edge` between the given `variable` and the `function`, which is','line_number':713,'multiline':False]['text':'/ assumed to be the gradient function of this variable (i.e. the function','line_number':714,'multiline':False]['text':'/ through which this variable is backpropagated during the backward pass).','line_number':715,'multiline':False]['text':'/ This sets the `grad_fn` property of the `variable`. This function assumes','line_number':716,'multiline':False]['text':'/ that the `Variable` is a new input to the gradient function and its','line_number':717,'multiline':False]['text':'/ `input_nr` thus equal to `function->num_inputs()`. Additionally, it','line_number':718,'multiline':False]['text':'/ increments the `Node`'s number of inputs by one. Approximately','line_number':719,'multiline':False]['text':'/ equivalent to `variable.set_gradient_edge(function,','line_number':720,'multiline':False]['text':'/ function->add_input_metadata(variable.dispatch_type(), variable.sizes()))`.','line_number':721,'multiline':False]['text':'/ If you don't want the `Node`'s `num_inputs` to be incremented, use','line_number':722,'multiline':False]['text':'/ `set_gradient_edge` directly.','line_number':723,'multiline':False]['text':' Copy before move.','line_number':727,'multiline':False]['text':'/ Return true if any of the variables in the list require a gradient.','line_number':732,'multiline':False]['text':'/ Return the next edges of all the given variables, or tuples of variables.','line_number':740,'multiline':False]['text':' implicit ','line_number':750,'multiline':True]['text':' namespace autograd','line_number':760,'multiline':False]['text':' namespace torch','line_number':761,'multiline':False]