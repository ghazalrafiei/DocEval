['text':' Copyright (c) Facebook, Inc. and its affiliates.','line_number':1,'multiline':False]['text':' All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' This source code is licensed under the BSD-style license found in the','line_number':4,'multiline':False]['text':' LICENSE file in the root directory of this source tree.','line_number':5,'multiline':False]['text':' We currently convert all SymInt to proxies before we use them.','line_number':50,'multiline':False]['text':' This could plausibly be handled at the Dynamo level.','line_number':51,'multiline':False]['text':' ensure we cannot collide with other properties','line_number':69,'multiline':False]['text':' We DO want to clobber proxies whenever we run an inplace operation','line_number':80,'multiline':False]['text':' on a tensor, and it affects the metadata on the proxy.','line_number':81,'multiline':False]['text':' NB: Never clobber pre-existing proxy.  Although the proxies','line_number':84,'multiline':False]['text':' are in principle equivalent, when we do graph partitioning','line_number':85,'multiline':False]['text':' we need there not to be spurious dependencies on tangent inputs.','line_number':86,'multiline':False]['text':' This works because primals get their SymInts set first, and','line_number':87,'multiline':False]['text':' THEN later we allocate tangent inputs.  Make sure if a SymInt','line_number':88,'multiline':False]['text':' is derivable from a primal that we use that.','line_number':89,'multiline':False]['text':' the default argument is what to return if the slot is not set.','line_number':98,'multiline':False]['text':' the transform argument is handy if you need to extract a subfield from','line_number':99,'multiline':False]['text':' the successfully looked up result (but NOT the default.)','line_number':100,'multiline':False]['text':' NB: Kinda hacky, but we should try to get val as the metadata','line_number':126,'multiline':False]['text':' everywhere','line_number':127,'multiline':False]['text':' TODO: This doesn't properly track storages.  A more robust','line_number':128,'multiline':False]['text':' approach would be to maintain a per-trace FakeTensorMode and','line_number':129,'multiline':False]['text':' from_real_tensor to create fake values (don't forget to','line_number':130,'multiline':False]['text':' snapshot_fake)','line_number':131,'multiline':False]['text':' What invariants do we have for the 'val' set on the FX node?  It has accurate','line_number':140,'multiline':False]['text':' metadata... but only for metadata that exists "below" all other subsystems','line_number':141,'multiline':False]['text':' (most notably autograd, but also vmap, functorch transforms, etc).  This means','line_number':142,'multiline':False]['text':' you can get the dtype, shape, stride, storage, but you CANNOT get requires_grad,','line_number':143,'multiline':False]['text':' grad_fn, _base (_base actually may be set due to recursive call to','line_number':144,'multiline':False]['text':' ADInplaceOrView, but you shouldn't rely on it.)','line_number':145,'multiline':False]['text':' Best effort tensor_meta setting; prefer using val!','line_number':148,'multiline':False]['text':' The basic idea is that we need to associate each tensor/SymInt','line_number':169,'multiline':False]['text':' with a Proxy.  How do we setup this association?  We just store','line_number':170,'multiline':False]['text':' the proxy on the proxy slot of the object, keyed on the tracer','line_number':171,'multiline':False]['text':' (so that if we have multiple tracers at the same time, they','line_number':172,'multiline':False]['text':' don't clobber each other.)','line_number':173,'multiline':False]['text':' NB: eagerly set meta here, so that the numbering is in order','line_number':190,'multiline':False]['text':' example use case: allreduce_ returns ([tensor], work)','line_number':197,'multiline':False]['text':' In theory we could support const-prop when proxy-tensor-tracing','line_number':201,'multiline':False]['text':' operators that returns dicts of tensors, but we have no use case','line_number':202,'multiline':False]['text':' for it today (since the only op we currently trace that can','line_number':203,'multiline':False]['text':' return a dict is triton_kernel_wrapper_functional/mutation,','line_number':204,'multiline':False]['text':' which does not participate in const-prop)','line_number':205,'multiline':False]['text':' example use case: triton_kernel_wrapper takes arguments as kwargs','line_number':211,'multiline':False]['text':' intentionally pass on primitives','line_number':215,'multiline':False]['text':' TODO: figure out if this API generally makes sense and bake it into the','line_number':231,'multiline':False]['text':' library','line_number':232,'multiline':False]['text':' NB: we REQUIRE all symints to be tracked','line_number':248,'multiline':False]['text':' If there are any tensor subclasses, we need to handle those tensor subclasses first','line_number':269,'multiline':False]['text':' TODO: we could use types to test this','line_number':270,'multiline':False]['text':' For pre-autograd tracing, we do not want to run CompositeImplicit decomps.','line_number':279,'multiline':False]['text':' If there are SymInts, we also should not consider this constant.','line_number':291,'multiline':False]['text':' However, fake tensor handling of SymInts is sufficiently broken that','line_number':292,'multiline':False]['text':' I couldn't write a test for this case','line_number':293,'multiline':False]['text':' TODO: maybe constant SymInts should also be allowed?  Not sure if','line_number':296,'multiline':False]['text':' this can happen','line_number':297,'multiline':False]['text':' Check if all of the Tensor inputs are constants','line_number':302,'multiline':False]['text':' If any of the Tensor inputs are "real" (not FakeTensor), we may','line_number':309,'multiline':False]['text':' incorrectly burn in constants by allowing this access.  Raise','line_number':310,'multiline':False]['text':' an error in this case','line_number':311,'multiline':False]['text':' When we trace through a torch.tensor invocation, you never actually','line_number':325,'multiline':False]['text':' see a torch.ops.aten.tensor call. Instead, the way this function is','line_number':326,'multiline':False]['text':' implemented internally is that we allocate a plain tensor (this is','line_number':327,'multiline':False]['text':' *guaranteed* to be a plain tensor, we disable all modes when doing','line_number':328,'multiline':False]['text':' so), and then call at::lift_fresh on it (to give modes a chance to do','line_number':329,'multiline':False]['text':' their stuff).  Furthermore, the tensor argument to lift_fresh is guaranteed','line_number':330,'multiline':False]['text':' to be freshly allocated, so we want lift_fresh to be a no-op (directly','line_number':331,'multiline':False]['text':' returning the input argument).','line_number':332,'multiline':False]['text':'','line_number':333,'multiline':False]['text':' Here is the basic problem: when we trace this sequence of executions','line_number':334,'multiline':False]['text':' into an FX graph, what happens to this call sequence?  Traditionally,','line_number':335,'multiline':False]['text':' tensor constants get interned as buffers on the FX GraphModule.  But','line_number':336,'multiline':False]['text':' this is dangerous.  Consider:','line_number':337,'multiline':False]['text':'','line_number':338,'multiline':False]['text':'       x = torch.tensor(1)','line_number':339,'multiline':False]['text':'       x.add_(2)','line_number':340,'multiline':False]['text':'','line_number':341,'multiline':False]['text':' Naively, this traces into:','line_number':342,'multiline':False]['text':'','line_number':343,'multiline':False]['text':'       t = self._tensor_constant0  # initialized to torch.tensor(1)','line_number':344,'multiline':False]['text':'       x = torch.ops.aten.lift_fresh(t)','line_number':345,'multiline':False]['text':'       x.add_(2)','line_number':346,'multiline':False]['text':'','line_number':347,'multiline':False]['text':' If lift_fresh returns t directly, the subsequent add_ call will','line_number':348,'multiline':False]['text':' modify the tensor constant. Really, the problem is we've violated','line_number':349,'multiline':False]['text':' the invariant the argument to lift is fresh.  So what we should','line_number':350,'multiline':False]['text':' preserve the invariant by replacing lift_fresh with lift_fresh_copy:','line_number':351,'multiline':False]['text':'','line_number':352,'multiline':False]['text':'       t = self._tensor_constant0  # initialized to torch.tensor(1)','line_number':353,'multiline':False]['text':'       x = torch.ops.aten.lift_fresh_copy(t)','line_number':354,'multiline':False]['text':'       x.add_(2)','line_number':355,'multiline':False]['text':'','line_number':356,'multiline':False]['text':' This is what the overload modification does.','line_number':357,'multiline':False]['text':' This makes DCE marginally less likely to DCE inplace operations.','line_number':364,'multiline':False]['text':' It is not strictly necessary','line_number':365,'multiline':False]['text':' Kind of a hacky way to test if an op is in-place or not','line_number':366,'multiline':False]['text':' e.g., c10d::allreduce_ returns a list of tensors as the first element','line_number':369,'multiline':False]['text':' in the output.','line_number':370,'multiline':False]['text':' In some circumstances, we will be tracing in a situation where a tensor','line_number':378,'multiline':False]['text':' is *statically* known to be a constant (currently, this only happens if','line_number':379,'multiline':False]['text':' you run torch.tensor; deterministic factory functions like torch.arange','line_number':380,'multiline':False]['text':' don't get this treatment).  When the tensor in question is small, it's','line_number':381,'multiline':False]['text':' helpful to due constant propagation in case we call item() (in which','line_number':382,'multiline':False]['text':' case we can return the constant value that is known, rather than give','line_number':383,'multiline':False]['text':' an error.)  The logic here tests if constant propagation is possible','line_number':384,'multiline':False]['text':' (because all of the inputs are constant).  If so, we disable fake tensor','line_number':385,'multiline':False]['text':' mode (if it is on) and do true compute on the constant.','line_number':386,'multiline':False]['text':'','line_number':387,'multiline':False]['text':' It's worth highlighting that we're making a policy decision here.','line_number':388,'multiline':False]['text':' There is a potential that the tensor is actually quite large, and we','line_number':389,'multiline':False]['text':' don't actually want to run the compute.  The tensor being quite large','line_number':390,'multiline':False]['text':' is one of the reasons why factory functions don't get this treatment','line_number':391,'multiline':False]['text':' (since they can be quite large; if a parameter is initialized to a','line_number':392,'multiline':False]['text':' constant value it will be!)  Similarly, there is also a potential','line_number':393,'multiline':False]['text':' to run an operator that blows up the size of a small tensor; we don't','line_number':394,'multiline':False]['text':' protect against this case, but we could force, e.g., only single','line_number':395,'multiline':False]['text':' element constant computation by testing the numel of the result before','line_number':396,'multiline':False]['text':' propagating const-ness.  Similarly, we don't require the constant to','line_number':397,'multiline':False]['text':' live on CPU, but we could.','line_number':398,'multiline':False]['text':' If this is a lift, the input tensor is guaranteed to be a','line_number':403,'multiline':False]['text':' constant, so we keep a copy of the original argument along so','line_number':404,'multiline':False]['text':' we can query it if we're asked to item() it at some later point','line_number':405,'multiline':False]['text':' NB: do NOT include factories as constants','line_number':415,'multiline':False]['text':' type: ignore[var-annotated]','line_number':432,'multiline':False]['text':' In general, we don't want to make modules leaves. In principle, users of','line_number':434,'multiline':False]['text':' this tracer might want to override this in order to turn a couple specific','line_number':435,'multiline':False]['text':' modules into leaves in the traced graph.','line_number':436,'multiline':False]['text':' We don't want to turn getattr calls into proxies. So we just return the actual value.','line_number':442,'multiline':False]['text':' This is a shim around the existng per-dispatch-key-mode logic.','line_number':490,'multiline':False]['text':' I'll delete the per-dispatch-key-mode logic in a followup PR','line_number':491,'multiline':False]['text':' During pre_dispatch, pop off of the PreDispatch mode stack','line_number':493,'multiline':False]['text':' During normal tracing, pop off of the dedicated proxy mode stack','line_number':500,'multiline':False]['text':' This mode is **only** used for pre_dispatch tracing.','line_number':551,'multiline':False]['text':' In particular, we need to make sure that autograd/autocast API's','line_number':552,'multiline':False]['text':' that do not desugar into dispatcher operators stay in the graph.','line_number':553,'multiline':False]['text':' Don't actually run the function! We just want to trace the calls','line_number':568,'multiline':False]['text':' into a graph. We don't actualy want to change global autograd state.','line_number':569,'multiline':False]['text':' Indicates to our torch_dispatch dispatching infra that','line_number':585,'multiline':False]['text':' this is an "infra" mode with lower dispatching precedence.','line_number':586,'multiline':False]['text':' Every time we enter a mode, we maintain a stack telling us what the previous','line_number':588,'multiline':False]['text':' ProxyTorchDispatchMode state was (if there was any).','line_number':589,'multiline':False]['text':' This lets us properly reset the state on exit.','line_number':590,'multiline':False]['text':' sym mode first, then us...','line_number':599,'multiline':False]['text':' Stash and store the previous proxy mode (there may or may not be one)','line_number':603,'multiline':False]['text':' ...exit us first, then sym mode','line_number':610,'multiline':False]['text':' Re-enable the previous proxy mode, if there was one.','line_number':613,'multiline':False]['text':' When false, we don't trace operations.  If you do this, you MUST','line_number':638,'multiline':False]['text':' call track_tensor/track_tensor_tree on all results of the operation','line_number':639,'multiline':False]['text':' to ensure we can adequately track the results','line_number':640,'multiline':False]['text':' func doesn't have a __torch_function__ that Proxy can interpose, so','line_number':658,'multiline':False]['text':' we gotta do it manually','line_number':659,'multiline':False]['text':' Peephole optimize multiply by one','line_number':669,'multiline':False]['text':' NB: be careful not to trigger guards here!','line_number':670,'multiline':False]['text':' For speed, we assume there are no nested data structures','line_number':677,'multiline':False]['text':' (otherwise we could use tree_map)','line_number':678,'multiline':False]['text':' We also assume there are no keyword arguments.','line_number':679,'multiline':False]['text':' If func returned a constant, we don't need to trace; we have','line_number':683,'multiline':False]['text':' determined that the result is constant (no matter if the inputs','line_number':684,'multiline':False]['text':' were symbolic) and it is no longer necessary to trace the','line_number':685,'multiline':False]['text':' computation.  This could occur if func triggered some guards.','line_number':686,'multiline':False]['text':' Delays tracing out the proxies on this op until we actually need it','line_number':688,'multiline':False]['text':' TODO: I'm not sure what the point of this class is; you can just','line_number':695,'multiline':False]['text':' make_fx through a regular Interpreter','line_number':696,'multiline':False]['text':' Blegh','line_number':702,'multiline':False]['text':' type: ignore[attr-defined]','line_number':703,'multiline':False]['text':' type: ignore[attr-defined]','line_number':704,'multiline':False]['text':' TODO handle case where the first character of target is '*'','line_number':714,'multiline':False]['text':' call_function, call_method, call_module get traced automatically by the outer mode.','line_number':723,'multiline':False]['text':' Should enter the mode at least once for being able to restore it later','line_number':734,'multiline':False]['text':' See: https://github.com/pytorch/pytorch/pull/82549#discussion_r934782025','line_number':735,'multiline':False]['text':' make_fx doesn't support kwargs, so we need to do this flattening','line_number':741,'multiline':False]['text':' and then unflatten the args before calling func','line_number':742,'multiline':False]['text':' Avoid importing sympy at a module level','line_number':775,'multiline':False]['text':' type: ignore[attr-defined]','line_number':778,'multiline':False]['text':' pre-autograd tracing uses per-dispatch-key modes,','line_number':811,'multiline':False]['text':' which requires the python dispatcher','line_number':812,'multiline':False]['text':' TODO: it would be nice to line these up with the names','line_number':832,'multiline':False]['text':' FX will choose for the placeholders, but we don't','line_number':833,'multiline':False]['text':' actually know what the names will be at this point yet','line_number':834,'multiline':False]['text':' NB: the Source here is actually meaningless','line_number':835,'multiline':False]['text':' type: ignore[attr-defined]','line_number':840,'multiline':False]['text':' NB: don't match on bools','line_number':841,'multiline':False]['text':' FX doesn't support varargs, so we gotta fake up a wrapper','line_number':857,'multiline':False]['text':' TODO: Would be nice to fix this at the source...','line_number':858,'multiline':False]['text':' We disable the autocast cache as the autocast cache causes type conversions on parameters to','line_number':863,'multiline':False]['text':' check a cache, which introduces untracked tensors into the graph','line_number':864,'multiline':False]['text':'','line_number':865,'multiline':False]['text':' We also disable tracing by any other tensor proxy-based tracers except the current. The','line_number':866,'multiline':False]['text':' purpose of `make_fx` is to produce graphmodules as a side effect; its internal execution is','line_number':867,'multiline':False]['text':' thus irrelevant to any external functional trace.','line_number':868,'multiline':False]['text':' TODO: kind of a bad way to do it, should maybe figure out a better way','line_number':873,'multiline':False]['text':' type: ignore[assignment]','line_number':875,'multiline':False]['text':' enable_current=True is now a no-op, since only one proxy mode','line_number':891,'multiline':False]['text':' can live on the stack at a time.','line_number':892,'multiline':False]['text':' We should kill this API in a future PR.','line_number':893,'multiline':False]['text':' Only one proxy_mode can be "active" at a time.','line_number':896,'multiline':False]['text':' So we simply remove our active mode.','line_number':897,'multiline':False]