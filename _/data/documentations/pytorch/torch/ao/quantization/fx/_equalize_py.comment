['text':' Calculate the shape needed to reshape the equalization scale later (needed for Conv layers)','line_number':81,'multiline':False]['text':' Reshape the equalization scale along axis=1 so that it can be','line_number':91,'multiline':False]['text':' multiplied with the input along axis=1','line_number':92,'multiline':False]['text':' Calculate qparams for the scaled min/max inputs','line_number':107,'multiline':False]['text':' Scale the input by the equalization scale located at the same column','line_number':108,'multiline':False]['text':' index','line_number':109,'multiline':False]['text':' Replace all 'inf', 'nan', 0's with 1s to prevent errors','line_number':202,'multiline':False]['text':'##############################################################################','line_number':271,'multiline':False]['text':' Functions for equalization during convert                                   #','line_number':272,'multiline':False]['text':'##############################################################################','line_number':273,'multiline':False]['text':' Find the op node that comes directly after the input equalization observer','line_number':287,'multiline':False]['text':' If the op_node is a nn.Linear layer, then it must have a','line_number':296,'multiline':False]['text':' WeightEqualizationObserver configuration','line_number':297,'multiline':False]['text':' type: ignore[assignment]','line_number':300,'multiline':False]['text':' Locate the following nn.ReLU or F.relu node if it exists','line_number':347,'multiline':False]['text':' Locate the following output observer if it exists.','line_number':352,'multiline':False]['text':' We will skip the relu node if it exists.','line_number':353,'multiline':False]['text':' type: ignore[index]','line_number':426,'multiline':False]['text':' Scale the weights for input-weight equalization','line_number':431,'multiline':False]['text':' If the following layer needs to be equalized then we will multiply its scale','line_number':432,'multiline':False]['text':' Scale the weights by the reciprocal of the equalization scale','line_number':436,'multiline':False]['text':' Reshape the equalization scale so that we can multiply it to the weight along axis=1','line_number':437,'multiline':False]['text':' Multiply the weights row wise by the next equalization scale','line_number':445,'multiline':False]['text':' Reshape the equalization scale so that we can multiply it to the weight along axis=0','line_number':446,'multiline':False]['text':' Multiply the bias element wise by the next equalization scale','line_number':452,'multiline':False]['text':' Reshape the equalization scale so that we can multiply it element-wise to the bias','line_number':458,'multiline':False]['text':' From the given op_node, the path looks like:','line_number':475,'multiline':False]['text':'   get_attr(weight) -> weight_quant_obs -> weight_eq_obs -> op_node','line_number':476,'multiline':False]['text':' So we want to trace back from the op_node to get the equalization observer','line_number':477,'multiline':False]['text':' node, then the quantization observer node, and then finally the weight','line_number':478,'multiline':False]['text':' node which contains the weight values.','line_number':479,'multiline':False]['text':' Get the equalization observer node','line_number':481,'multiline':False]['text':' Get the quantization observer node','line_number':486,'multiline':False]['text':' Get the get_attr(weight) node','line_number':493,'multiline':False]['text':' Scale the weights for input-weight equalization','line_number':502,'multiline':False]['text':' If the following layer needs to be equalized then we will multiply its scale','line_number':503,'multiline':False]['text':' Reshape the equalization scale so that we can multiply it to the weight along axis=1','line_number':504,'multiline':False]['text':' Multiply the weights row wise by the next equalization scale','line_number':512,'multiline':False]['text':' Reshape the equalization scale so that we can multiply it to the weight along axis=1','line_number':513,'multiline':False]['text':' Multiply the bias element wise by the next equalization scale','line_number':520,'multiline':False]['text':' Find the node containing the weight values','line_number':523,'multiline':False]['text':' Reshape the equalization scale so that we can multiply it element-wise to the bias','line_number':533,'multiline':False]['text':' type: ignore[operator]','line_number':553,'multiline':False]['text':' For all of the current node's users, replace the current node with','line_number':559,'multiline':False]['text':' the input quantization observer node','line_number':560,'multiline':False]['text':' Erase the InputEqualizationObserver node','line_number':565,'multiline':False]['text':' Calibrate the weight equalization observer since it has just','line_number':588,'multiline':False]['text':' been created','line_number':589,'multiline':False]['text':' type: ignore[index]','line_number':591,'multiline':False]['text':' Calculate and set the equalization scale values','line_number':597,'multiline':False]['text':' If the previous node is a layer that needs to be equalized, then','line_number':662,'multiline':False]['text':' we will remove the current node because we do not need to add any','line_number':663,'multiline':False]['text':' equalization nodes between two layers that need to be equalized','line_number':664,'multiline':False]['text':' Before: linear1/relu (prev_node) -> output_quant_obs1 (inp_quant_obs_node) -> input_eq_obs2 (node) -> linear2','line_number':666,'multiline':False]['text':' After: linear1/relu (prev_node) -> output_quant_obs1 (inp_quant_obs_node) -> linear2','line_number':667,'multiline':False]['text':' Update the following input quantization observer's min/max values','line_number':672,'multiline':False]['text':' Remove the InputEqualization node and add a mul operator before','line_number':675,'multiline':False]['text':' the quantization observer node that appears before the equalization node','line_number':676,'multiline':False]['text':' Before: x -> input_quant_obs -> input_eq_obs -> linear','line_number':677,'multiline':False]['text':' After: x -> mul -> input_quant_obs -> linear','line_number':678,'multiline':False]['text':' Create a node containing the equalization scale','line_number':680,'multiline':False]['text':' Create a node multiplying the input with the equalization scale','line_number':687,'multiline':False]['text':' Set the mul nod to be the input_quant_obs_node's input instead of','line_number':692,'multiline':False]['text':' the previous node','line_number':693,'multiline':False]['text':' type: ignore[assignment]','line_number':703,'multiline':False]['text':' Scale the weight nodes','line_number':706,'multiline':False]['text':' Clear the quantization observer's min/max values so that they','line_number':717,'multiline':False]['text':' can get updated later based on the new scale values','line_number':718,'multiline':False]['text':' Erase the weight equalization observer node','line_number':721,'multiline':False]['text':' Calculate the equalization scale, update the observers with the scaled','line_number':734,'multiline':False]['text':' inputs, and scale the weight','line_number':735,'multiline':False]['text':'##############################################################################','line_number':742,'multiline':False]['text':' Functions for running the equalized model on the Numeric Suite              #','line_number':743,'multiline':False]['text':'##############################################################################','line_number':744,'multiline':False]['text':' Construct a dictionary mapping layer names to the SQNR values','line_number':787,'multiline':False]['text':' Sort the layer_sqnr_dictionary values and get the layers with the lowest','line_number':811,'multiline':False]['text':' SQNR values (aka highest quantization errors)','line_number':812,'multiline':False]['text':' Constructs an equalization_qconfig_dict that specifies to only equalize','line_number':816,'multiline':False]['text':' the layers with the highest quantization errors','line_number':817,'multiline':False]