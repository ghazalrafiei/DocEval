['text':' TODO(future PR): allow customizations','line_number':24,'multiline':False]['text':' TODO(future PR): reuse existing quantization mappings','line_number':25,'multiline':False]['text':' TODO(future PR): add the rest of modules and ops here','line_number':26,'multiline':False]['text':' add every bidirectional pair','line_number':31,'multiline':False]['text':' call_function or call_module type, example: F.linear or nn.Conv2d','line_number':41,'multiline':False]['text':' call_method name, example: "dequantize"','line_number':42,'multiline':False]['text':' call_method name and first argument, example: ("to", torch.float16)','line_number':43,'multiline':False]['text':' Possible syntaxes:','line_number':65,'multiline':False]['text':' * single op: torch.nn.Conv2d','line_number':66,'multiline':False]['text':' * multiple ops: (torch.nn.ReLU, torch.nn.Conv2d)','line_number':67,'multiline':False]['text':' For fusions, we only care about patterns composed of multiple ops.','line_number':68,'multiline':False]['text':' TODO(future PR): allow customizations from default patterns.','line_number':69,'multiline':False]['text':' TODO: this is a temporary hack to flatten the patterns from quantization so','line_number':74,'multiline':False]['text':' that it works with the ns matcher function, maybe we should use `_is_match`','line_number':75,'multiline':False]['text':' in torch.ao.quantization.fx.match_utils to match the patterns','line_number':76,'multiline':False]['text':' flatten the pattern with form (nn.ReLU, (nn.BatchNorm2d, nn.Conv2d))','line_number':79,'multiline':False]['text':' Only patterns of multiple ops are fusions, ignore','line_number':82,'multiline':False]['text':' patterns which contain a single ops (they get matched','line_number':83,'multiline':False]['text':' without caring about fusions).','line_number':84,'multiline':False]['text':' type: ignore[arg-type]','line_number':86,'multiline':False]['text':' For each pattern, add additional patterns with observers and','line_number':88,'multiline':False]['text':' fake quants at the end.','line_number':89,'multiline':False]['text':' TODO(future PR): if needed, implement matching for a node','line_number':90,'multiline':False]['text':'   having multiple output observers.','line_number':91,'multiline':False]['text':' type: ignore[arg-type]','line_number':97,'multiline':False]['text':' After this point, results contains values such as','line_number':100,'multiline':False]['text':' [..., ((torch.nn.Relu, torch.nn.Conv2d), 0), ...]','line_number':101,'multiline':False]['text':' Patterns for matching fp16 emulation are not specified in the quantization','line_number':103,'multiline':False]['text':' fusion mappings.  For now, define them here.','line_number':104,'multiline':False]['text':' linear-relu fp16 emulation:','line_number':107,'multiline':False]['text':' fp16_to_fp32 -> linear -> relu -> fp32_to_fp16','line_number':108,'multiline':False]['text':' Conv-BN fusion (this happens outside of quantization patterns,','line_number':110,'multiline':False]['text':' which is why it is defined separately here).','line_number':111,'multiline':False]['text':' type: ignore[arg-type]','line_number':120,'multiline':False]['text':' type: ignore[arg-type]','line_number':121,'multiline':False]['text':' type: ignore[arg-type]','line_number':122,'multiline':False]['text':' each node can only belong to one matched pattern','line_number':139,'multiline':False]