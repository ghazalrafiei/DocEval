['text':' Note: adding the mypy ignore on _get_softmax_dim seems less bad','line_number':179,'multiline':False]['text':' than making `_get_softmax_dim` an official API.','line_number':180,'multiline':False]['text':' type: ignore[attr-defined]','line_number':181,'multiline':False]['text':' The whole flow is float -> observed -> quantized','line_number':207,'multiline':False]['text':' This class does observed -> quantized only','line_number':208,'multiline':False]['text':' Remove the parameters for the bias_k and bias_v to quantize them','line_number':220,'multiline':False]['text':' TODO: This is a potential source of accuracy drop.','line_number':221,'multiline':False]['text':'       quantized cat takes the scale and zp of the first','line_number':222,'multiline':False]['text':'       element, which might lose the precision in the bias_k','line_number':223,'multiline':False]['text':'       and the bias_v (which are cat'ed with k/v being first).','line_number':224,'multiline':False]['text':' noqa: B010','line_number':230,'multiline':False]['text':' noqa: B010','line_number':237,'multiline':False]