['text':' no deviation yet','line_number':17,'multiline':False]['text':' deviated this iteration; currently issuing warnings','line_number':18,'multiline':False]['text':' deviated in a previous iteration','line_number':19,'multiline':False]['text':' Tracks the (static) pre-forward order for execution order validation','line_number':37,'multiline':False]['text':' and forward prefetching','line_number':38,'multiline':False]['text':' Tracks the post-forward order for pre-backward prefetching','line_number':40,'multiline':False]['text':' Gives the max number of backward/forward prefetched all-gathers by a','line_number':44,'multiline':False]['text':' single module','line_number':45,'multiline':False]['text':' Data structures for execution order validation','line_number':49,'multiline':False]['text':' Names are prefixed from the root module','line_number':54,'multiline':False]['text':' Current index in the pre-forward execution order','line_number':56,'multiline':False]['text':' Fix an order over the handles, which should be the same across ranks','line_number':74,'multiline':False]['text':' TODO (awgu): We can broadcast the metadata of rank 0's `all_handles`','line_number':80,'multiline':False]['text':' to check that all ranks have the same handles in the same order.','line_number':81,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/79620','line_number':82,'multiline':False]['text':' Only record the first usage of a handles key','line_number':142,'multiline':False]['text':' Fix the order after the first iteration and only record the first','line_number':164,'multiline':False]['text':' usage of a handles key','line_number':165,'multiline':False]['text':' Do not check order in eval mode since the post-backward callback does','line_number':186,'multiline':False]['text':' not run so it cannot be used to mark the end of an iteration','line_number':187,'multiline':False]['text':' guaranteed to be non-CPU','line_number':195,'multiline':False]['text':' type: ignore[arg-type, call-overload]','line_number':203,'multiline':False]['text':' type: ignore[arg-type, call-overload]','line_number':204,'multiline':False]['text':' Copy entire tensor from D2H once to avoid per element D2H copies','line_number':210,'multiline':False]['text':' Check that all ranks plan to all-gather the same number of','line_number':212,'multiline':False]['text':' parameters','line_number':213,'multiline':False]['text':' TODO (awgu): Since every module has at most one handle in the','line_number':214,'multiline':False]['text':' current implementation, this should never raise the error.','line_number':215,'multiline':False]['text':' mypy','line_number':216,'multiline':False]['text':' TODO(voz): Don't graph break on this - dynamo hates the n1 != n2','line_number':218,'multiline':False]['text':' tensor comparison control flow.','line_number':219,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/107055','line_number':220,'multiline':False]['text':' type: ignore[call-overload]','line_number':233,'multiline':False]['text':' type: ignore[arg-type]','line_number':236,'multiline':False]['text':' Copy entire tensor from D2H once to avoid per element D2H copies','line_number':240,'multiline':False]['text':' Check that all ranks plan to all-gather the same index parameters','line_number':242,'multiline':False]['text':' TODO(voz): Don't graph break on this - dynamo hates the i1 != i2','line_number':244,'multiline':False]['text':' tensor comparison control flow.','line_number':245,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/107055','line_number':246,'multiline':False]['text':' Only issue warnings on the first deviating iteration and stop','line_number':270,'multiline':False]['text':' checking thereafter to avoid flooding the console','line_number':271,'multiline':False]['text':' non-`None` means we should warn','line_number':274,'multiline':False]['text':' This iteration sees extra all-gather(s) compared to the first','line_number':276,'multiline':False]