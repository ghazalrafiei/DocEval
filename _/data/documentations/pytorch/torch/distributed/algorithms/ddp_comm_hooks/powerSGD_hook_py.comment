['text':' Normalize the i'th column.','line_number':47,'multiline':False]['text':' If no epsilon is added here, division by zero may be caused by vanishing gradients.','line_number':49,'multiline':False]['text':' This epsilon is not needed if the input batch of matrices covers the gradients of at least one entire layer','line_number':50,'multiline':False]['text':' in the neural network.','line_number':51,'multiline':False]['text':' Note that col ** 2 can underflow/overflow if we use FP16.','line_number':53,'multiline':False]['text':' May need to consider multiplying a scaling factor and dividing it later, or using bfloat16 instead.','line_number':54,'multiline':False]['text':' Recover the values from NaNs to 0s.','line_number':62,'multiline':False]['text':' Project it on the rest and remove it.','line_number':66,'multiline':False]['text':' noqa: B950','line_number':89,'multiline':False]['text':' noqa: B950','line_number':145,'multiline':False]['text':' The fields below are the hyperparameters that often need to be tuned by the user.','line_number':149,'multiline':False]['text':' The fields below are the hyperparameters that seldom need be tuned by the user.','line_number':152,'multiline':False]['text':' The fields below are the binary hyperparameters recommended to be turned on for performance and accuracy.','line_number':155,'multiline':False]['text':' The fields below are internal state.','line_number':159,'multiline':False]['text':' The fields below are for recording compression stats.','line_number':165,'multiline':False]['text':' Deferring PowerSGD compression util step 'start_powerSGD_iter' can have two advantages:','line_number':202,'multiline':False]['text':' 1) It turns out that PowerSGD may lead to a non-trivial accuracy loss,','line_number':203,'multiline':False]['text':' even if the matrix approximation rank is increased to a large value.','line_number':204,'multiline':False]['text':' To mitigate the accuracy loss, a simple yet effective way is mixing vanilla allreduce','line_number':205,'multiline':False]['text':' (or a more conservative compression such as FP16 compression) with PowerSGD.','line_number':206,'multiline':False]['text':' 2) There is an internal optimization of rebuilding buckets process in DDP,','line_number':207,'multiline':False]['text':' in order to save the memory space.','line_number':208,'multiline':False]['text':' This step takes place after the first iteration.','line_number':209,'multiline':False]['text':' However, this means that the shape of input bucketized tensors is subject to change,','line_number':210,'multiline':False]['text':' which will complicate the implementations of error feedback and warm-up.','line_number':211,'multiline':False]['text':' Running vanilla allreduce in the first few iterations can avoid this complexity.','line_number':212,'multiline':False]['text':' Error feedback is usually crucial for both for convergence and generalization,','line_number':220,'multiline':False]['text':' because PowerSGD is a biased compressor,','line_number':221,'multiline':False]['text':' i.e., compressing and decompressing a random gradient does not yield the original in expectation.','line_number':222,'multiline':False]['text':' This mechanism requires a temporary copy of the input gradients,','line_number':223,'multiline':False]['text':' so it increases the peak memory consumption by the size of the gradient tensor.','line_number':224,'multiline':False]['text':' However, if the target matrices are known to be exactly low-ranked (instead of just low stable rank),','line_number':225,'multiline':False]['text':' sometimes it is possible to converge to the optima without error feedback.','line_number':226,'multiline':False]['text':' See: http://proceedings.mlr.press/v54/yurtsever17a/yurtsever17a.pdf','line_number':227,'multiline':False]['text':' Warm-start reuses P(s) and Q(s) from the previous iteration.','line_number':229,'multiline':False]['text':' This can improve the approximation quality and hence improve the accuracy.','line_number':230,'multiline':False]['text':' Additionally, by avoiding the initialization of these low-rank tensors at every step,','line_number':231,'multiline':False]['text':' this can also accelerate training.','line_number':232,'multiline':False]['text':' However, this is at the cost of extra memory.','line_number':233,'multiline':False]['text':' Can use a very small value to prevent div-by-zero error caused by orthogonalization of vanishing gradients.','line_number':235,'multiline':False]['text':' The purpose of this RNG is to generate different random seeds for initializing Q across iterations,','line_number':237,'multiline':False]['text':' but in the same order for all the DDP replicas.','line_number':238,'multiline':False]['text':' Different random seeds across iterations indicate different 'projections' of the gradients at different SGD steps.','line_number':239,'multiline':False]['text':' If the same random projection is used,','line_number':240,'multiline':False]['text':' there will be differences between the gradients that are never synchronized.','line_number':241,'multiline':False]['text':' Since there is only a single state instance for all the input buckets,','line_number':244,'multiline':False]['text':' need to maintain a dictionary that maps each bucket index to the local error.','line_number':245,'multiline':False]['text':' Iteration/step in the training loop.','line_number':249,'multiline':False]['text':' Compression stats accumulators','line_number':251,'multiline':False]['text':' We'll report compression stats every 'compression_stats_logging_frequency' iterations','line_number':254,'multiline':False]['text':' Note that we always report compression stats at least once.','line_number':255,'multiline':False]['text':' Batching tensors with same shape can increase parallelism in compression / decompression computation.','line_number':260,'multiline':False]['text':' This requires a larger bucket size to make more same-shaped tensor to appear in one bucket, however','line_number':261,'multiline':False]['text':' this may reduce the overlap between computation and communication, and increase the memory footprint','line_number':262,'multiline':False]['text':' due to stacking tensors.','line_number':263,'multiline':False]['text':' Turn on if compression / decompression computation is a bottleneck.','line_number':264,'multiline':False]['text':' Since bucket 0 is the last bucket to allreduce in an iteration.','line_number':295,'multiline':False]['text':' Only increase `iter` when bucket 0 is processed.','line_number':296,'multiline':False]['text':' noqa: B950','line_number':314,'multiline':False]['text':' noqa: B950','line_number':385,'multiline':False]['text':' The input tensor is a flattened 1D tensor.','line_number':390,'multiline':False]['text':' Run vanilla allreduce in the first `start_powerSGD_iter` iterations.','line_number':393,'multiline':False]['text':' Apply PowerSGD after `start_powerSGD_iter` iterations.','line_number':398,'multiline':False]['text':' Incorporate the error from the previous state into the gradients.','line_number':402,'multiline':False]['text':' Keep a copy of the input tensor,','line_number':418,'multiline':False]['text':' so that we can compute the local error caused by compression later,','line_number':419,'multiline':False]['text':' by comparing this copy and the input tensor updated after decompression.','line_number':420,'multiline':False]['text':' Unflatten the input tensor into per-parameter tensors, for layer-wise compression.','line_number':423,'multiline':False]['text':' Step I: Divide all the tensors into two groups,','line_number':426,'multiline':False]['text':' one will be compressed before allreduce and the other will be directly allreduced without compression.','line_number':427,'multiline':False]['text':' Step II: Handle uncompressed tensors.','line_number':450,'multiline':False]['text':' Allocate contiguous memory for these tensors to allreduce efficiently.','line_number':451,'multiline':False]['text':' Step III: Handle the tensors that should be compressed.','line_number':458,'multiline':False]['text':' Allocate contiguous memory for Ps and Qs to allreduce efficiently.','line_number':459,'multiline':False]['text':' If warm-start is enabled, reuse Ps and Qs from the previous iteration if possible.','line_number':460,'multiline':False]['text':' The memory spaces of Ps and Qs need to be allocated in the first iteration when PowerSGD is applied.','line_number':461,'multiline':False]['text':' If warm-start is disabled, low-rank tensors will be initialized at every step.','line_number':465,'multiline':False]['text':' Only log this if warm-start to avoid spamming.','line_number':466,'multiline':False]['text':' Batch tensors to compress by shape.','line_number':479,'multiline':False]['text':' This function decides whether to batch tensors with same shape or not according to the argument,','line_number':484,'multiline':False]['text':' so the following process could share the same code.','line_number':485,'multiline':False]['text':' Use the original tensor to avoid copy.','line_number':491,'multiline':False]['text':' Create Ps and Qs that point to the allocated memory.','line_number':499,'multiline':False]['text':' If warm-start is enabled, reuse Qs from the previous iteration if possible and skip filling random values.','line_number':522,'multiline':False]['text':' The exception is the first iteration when PowerSGD is applied.','line_number':523,'multiline':False]['text':' Fork this RNG to avoid changing the seed globally and affecting the random sampling anywhere else in the training.','line_number':529,'multiline':False]['text':' The seed makes sure that the initial random values are the same across all the DDP replicas.','line_number':530,'multiline':False]['text':' This seed should differ at every step.','line_number':531,'multiline':False]['text':' Since it is very slow to fork RNG state across all the CUDA devices,','line_number':532,'multiline':False]['text':' only fork on CPU and then move the generated tensor to the CUDA device (by overwriting q).','line_number':533,'multiline':False]['text':' Compute Ps.','line_number':545,'multiline':False]['text':' This allreduce is only applied to uncompressed tensors,','line_number':549,'multiline':False]['text':' so it should have been kicked off before the above computation on the compressed tensors to hide more communication costs.','line_number':550,'multiline':False]['text':' However, this somehow requires a separate future chain at this time.','line_number':551,'multiline':False]['text':' Since these Ps will be orthogonalized later, no need to divide them by world size.','line_number':565,'multiline':False]['text':' Compute Qs.','line_number':579,'multiline':False]['text':' TODO: The above procedure does two matmul+allreduce steps per iteration --','line_number':583,'multiline':False]['text':' one left multiplication and one right multiplication.','line_number':584,'multiline':False]['text':' For warm-start, can take one such step at a time, and alternate between them.','line_number':585,'multiline':False]['text':' Allreduce Qs.','line_number':587,'multiline':False]['text':' Copy batched tensors back to original buffer.','line_number':602,'multiline':False]['text':' Skip tensor with batch_size == 1 since itself is the original tensor.','line_number':606,'multiline':False]['text':' Memorize the local errors.','line_number':616,'multiline':False]['text':' noqa: B950','line_number':691,'multiline':False]['text':' The input tensor is a flattened 1D tensor.','line_number':696,'multiline':False]['text':' Run vanilla allreduce in the first `start_powerSGD_iter` iterations.','line_number':699,'multiline':False]['text':' Apply PowerSGD after `start_powerSGD_iter` iterations.','line_number':704,'multiline':False]['text':' View the input tensor as a 2D square-shape tensor, and pad 0s if necessary.','line_number':709,'multiline':False]['text':' Incorporate the error from the previous state into the gradients.','line_number':720,'multiline':False]['text':' Keep a copy of the input tensor,','line_number':735,'multiline':False]['text':' so that we can compute the local error caused by compression later,','line_number':736,'multiline':False]['text':' by comparing this copy and the input tensor updated after decompression.','line_number':737,'multiline':False]['text':' Reuse P and Q from the previous iteration if possible.','line_number':741,'multiline':False]['text':' The memory spaces of P and Q need to be allocated in the first iteration when PowerSGD is applied.','line_number':742,'multiline':False]['text':' If warm-start is disabled, low-rank tensors will be initialized at every step.','line_number':744,'multiline':False]['text':' Only log this if warm-start to avoid spamming.','line_number':745,'multiline':False]['text':' Fork this RNG to avoid changing the seed globally and affecting the random sampling','line_number':756,'multiline':False]['text':' anywhere else in the training.','line_number':757,'multiline':False]['text':' The seed makes sure that the initial random values are the same across all the DDP replicas.','line_number':758,'multiline':False]['text':' This seed should differ at every step.','line_number':759,'multiline':False]['text':' Since it is very slow to fork RNG state across all the CUDA devices,','line_number':760,'multiline':False]['text':' only fork on CPU and then move the generated tensor to the CUDA device.','line_number':761,'multiline':False]['text':' TODO: The above procedure does two matmul+allreduce steps per iteration --','line_number':802,'multiline':False]['text':' one left multiplication and one right multiplication.','line_number':803,'multiline':False]['text':' For warm-start, can take one such step at a time, and alternate between them.','line_number':804,'multiline':False]['text':' Memorize the local errors.','line_number':823,'multiline':False]['text':' Removing this seemingly unnecessary sync somehow may cause failures.','line_number':825,'multiline':False]['text':' See: https://github.com/pytorch/pytorch/pull/54838','line_number':826,'multiline':False]