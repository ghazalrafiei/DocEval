['text':'/ \file','line_number':3,'multiline':False]['text':'/','line_number':4,'multiline':False]['text':'/ This header provides an API for extending PyTorch's core library','line_number':5,'multiline':False]['text':'/ of operators with user defined operators and data types.  This','line_number':6,'multiline':False]['text':'/ API can be used in a few ways:','line_number':7,'multiline':False]['text':'/','line_number':8,'multiline':False]['text':'/ * You can define new custom operators and classes with TORCH_LIBRARY(),','line_number':9,'multiline':False]['text':'/   making them available for use in both eager Python as well as in','line_number':10,'multiline':False]['text':'/   TorchScript. This API is modeled off of pybind11's `PYBIND11_MODULE`','line_number':11,'multiline':False]['text':'/   macro, as the provided functionality is similar (pybind11 lets you bind','line_number':12,'multiline':False]['text':'/   C++ to Python only; `torch/library.h` lets you bind C++ simultaneously to','line_number':13,'multiline':False]['text':'/   Python and TorchScript).','line_number':14,'multiline':False]['text':'/','line_number':15,'multiline':False]['text':'/ * You can override existing operators with TORCH_LIBRARY_IMPL(),','line_number':16,'multiline':False]['text':'/   providing a new implementation for these operators for a custom','line_number':17,'multiline':False]['text':'/   backend (e.g., XLA).  When you pass operators with tensors of your custom','line_number':18,'multiline':False]['text':'/   backend, your overridden implementations will be called instead','line_number':19,'multiline':False]['text':'/   of the standard implementations.','line_number':20,'multiline':False]['text':'/','line_number':21,'multiline':False]['text':'/ * You can use both capabilities at the same time, allowing you','line_number':22,'multiline':False]['text':'/   to write custom operators that register CPU/CUDA/Autograd','line_number':23,'multiline':False]['text':'/   implementations without having to write the boilerplate','line_number':24,'multiline':False]['text':'/   conditionals yourself.','line_number':25,'multiline':False]['text':'/','line_number':26,'multiline':False]['text':'/ For a tutorial style introduction to the library API, check','line_number':27,'multiline':False]['text':'/ out the [Extending TorchScript with Custom C++','line_number':28,'multiline':False]['text':'/ Operators](https://pytorch.org/tutorials/advanced/torch_script_custom_ops.html)','line_number':29,'multiline':False]['text':'/ tutorial.','line_number':30,'multiline':False]['text':'/','line_number':31,'multiline':False]['text':'/ ```','line_number':32,'multiline':False]['text':'/ // Define a library whose operators live in the namespace 'myops'.','line_number':33,'multiline':False]['text':'/ // You must define all of the operators for this library in','line_number':34,'multiline':False]['text':'/ // this namespace.','line_number':35,'multiline':False]['text':'/ TORCH_LIBRARY(myops, m) {','line_number':36,'multiline':False]['text':'/   // Define a operator with exactly one implementation for all backends.','line_number':37,'multiline':False]['text':'/   m.def("add(Tensor self, Tensor other) -> Tensor", &add_impl);','line_number':38,'multiline':False]['text':'/','line_number':39,'multiline':False]['text':'/   // Define a schema for an operator, but provide no implementation','line_number':40,'multiline':False]['text':'/   // (use this syntax if you want to use the dispatcher)','line_number':41,'multiline':False]['text':'/   m.def("mul(Tensor self, Tensor other) -> Tensor");','line_number':42,'multiline':False]['text':'/','line_number':43,'multiline':False]['text':'/   // Provide an implementation for a defined operator (you can','line_number':44,'multiline':False]['text':'/   // provide multiple; one per backend).  The dispatcher takes care of','line_number':45,'multiline':False]['text':'/   // calling the correct implementation depending on if we get a CPU','line_number':46,'multiline':False]['text':'/   // tensor or a CUDA tensor','line_number':47,'multiline':False]['text':'/   m.impl("mul", torch::kCPU, &mul_cpu_impl);','line_number':48,'multiline':False]['text':'/   m.impl("mul", torch::kCUDA, &mul_cuda_impl);','line_number':49,'multiline':False]['text':'/ }','line_number':50,'multiline':False]['text':'/','line_number':51,'multiline':False]['text':'/ // Define implementations for operators for a non-standard backend,','line_number':52,'multiline':False]['text':'/ // e.g., XLA (valid values are entries of DispatchKey).  This can','line_number':53,'multiline':False]['text':'/ // be used to define operators in a different file than the initial','line_number':54,'multiline':False]['text':'/ // TORCH_LIBRARY definition (e.g., if it is in an external library)','line_number':55,'multiline':False]['text':'/ TORCH_LIBRARY_IMPL(myops, XLA, m) {','line_number':56,'multiline':False]['text':'/   m.impl("mul", &mul_xla_impl);','line_number':57,'multiline':False]['text':'/ }','line_number':58,'multiline':False]['text':'/ ```','line_number':59,'multiline':False]['text':' Just for inferFunctionSchemaFromFunctor','line_number':67,'multiline':False]['text':'*
 * The NoInferSchemaTag is a type name used to indicate that this call to the
 * CppFunction constructor should not trigger schema inference from functor.
 * Schema inference from functor utilizes template meta-programming, and is
 * costly from a size perspective. Ideally, one would expect that the schema
 * inference would require very little binary size since most of the
 * computation can be done by the compiler at build time, but that isn't
 * necessarily the case.
 *
 * Schema inference is elided only for mobile use-cases where we don't need
 * the additional runtime cost or size overhead on client devices.
 *
 ','line_number':74,'multiline':True]['text':' For multipy/torchdeploy use case','line_number':92,'multiline':False]['text':'/ Represents a C++ function that implements an operator.  Most users won't','line_number':100,'multiline':False]['text':'/ interact directly with this class, except via error messages: the','line_number':101,'multiline':False]['text':'/ constructors this function define the set of permissible "function"-like','line_number':102,'multiline':False]['text':'/ things you can bind via the interface.','line_number':103,'multiline':False]['text':'/','line_number':104,'multiline':False]['text':'/ This class erases the type of the passed in function, but durably records','line_number':105,'multiline':False]['text':'/ the type via an inferred schema for the function.','line_number':106,'multiline':False]['text':' TODO: This is morally the same thing as KernelRegistrationConfig, but it's','line_number':108,'multiline':False]['text':' opaque to the user.','line_number':109,'multiline':False]['text':'/ This overload accepts function pointers, e.g., `CppFunction(&add_impl)`','line_number':112,'multiline':False]['text':'/ This overload accepts compile time function pointers, e.g.,','line_number':125,'multiline':False]['text':'/ `CppFunction(TORCH_FN(add_impl))`','line_number':126,'multiline':False]['text':'/ This overload accepts lambdas, e.g., `CppFunction([](const Tensor& self) {','line_number':140,'multiline':False]['text':'/ ... })`','line_number':141,'multiline':False]['text':'/ This overload accepts function pointers, e.g., `CppFunction(&add_impl,','line_number':156,'multiline':False]['text':'/ NoInferSchemaTag())`','line_number':157,'multiline':False]['text':' TODO: Don't go through WrapRuntimeKernelFunctor','line_number':167,'multiline':False]['text':'/ This overload accepts compile time function pointers, e.g.,','line_number':172,'multiline':False]['text':'/ `CppFunction(TORCH_FN(add_impl), NoInferSchemaTag())`','line_number':173,'multiline':False]['text':' TODO: Don't go through WrapRuntimeKernelFunctor','line_number':184,'multiline':False]['text':'/ This overload accepts lambdas, e.g., `CppFunction([](const Tensor& self) {','line_number':189,'multiline':False]['text':'/ ... }. NoInferSchemaTag())`','line_number':190,'multiline':False]['text':' TODO: Don't go through WrapRuntimeKernelFunctor','line_number':201,'multiline':False]['text':'/ \private','line_number':213,'multiline':False]['text':'/ Creates a function from a type-erased boxed kernel.','line_number':214,'multiline':False]['text':' cpp_signature ','line_number':218,'multiline':True]['text':' not known for boxed functions','line_number':218,'multiline':False]['text':' schema ','line_number':219,'multiline':True]['text':'/ This creates a fallthrough function.  Fallthrough functions','line_number':222,'multiline':False]['text':'/ immediately redispatch to the next available dispatch key,','line_number':223,'multiline':False]['text':'/ but are implemented more efficiently than a hand written','line_number':224,'multiline':False]['text':'/ function done in the same way.','line_number':225,'multiline':False]['text':'/ \private','line_number':230,'multiline':False]['text':'/','line_number':231,'multiline':False]['text':'/ Creates a function that raises an error saying that named tensors','line_number':232,'multiline':False]['text':'/ are not supported when called.','line_number':233,'multiline':False]['text':'/ Create a function from a boxed kernel function with signature','line_number':238,'multiline':False]['text':'/ `void(const OperatorHandle&, Stack*)`; i.e., they receive a','line_number':239,'multiline':False]['text':'/ stack of arguments in a boxed calling convention, rather than','line_number':240,'multiline':False]['text':'/ in the native C++ calling convention.  Boxed functions are','line_number':241,'multiline':False]['text':'/ typically only used to register backend fallbacks via','line_number':242,'multiline':False]['text':'/ torch::Library::fallback().','line_number':243,'multiline':False]['text':' Variant that takes in a boxed kernel function with a plumbed','line_number':249,'multiline':False]['text':' DispatchKeySet. See Note [Plumbing Keys Through The Dispatcher] for','line_number':250,'multiline':False]['text':' details.','line_number':251,'multiline':False]['text':'/ Create a function from a boxed kernel functor which defines','line_number':257,'multiline':False]['text':'/ `operator()(const OperatorHandle&, DispatchKeySet, Stack*)`','line_number':258,'multiline':False]['text':'/ (receiving arguments from boxed calling convention) and inherits','line_number':259,'multiline':False]['text':'/ from `c10::OperatorKernel`.  Unlike makeFromBoxedFunction, functions','line_number':260,'multiline':False]['text':'/ registered in this way can also carry additional state which','line_number':261,'multiline':False]['text':'/ is managed by the functor; this is useful if you're writing an','line_number':262,'multiline':False]['text':'/ adapter to some other implementation, e.g., a Python callable, which','line_number':263,'multiline':False]['text':'/ is dynamically associated with the registered kernel.','line_number':264,'multiline':False]['text':'/ Create a function from an unboxed kernel function.','line_number':272,'multiline':False]['text':'/ This is typically used to register common operators.','line_number':273,'multiline':False]['text':'/ Create a function from a compile time unboxed kernel function pointer.','line_number':283,'multiline':False]['text':'/ This is typically used to register common operators.','line_number':284,'multiline':False]['text':'/ Compile time function pointers can be used to allow the compiler','line_number':285,'multiline':False]['text':'/ to optimize (e.g. inline) calls to it.','line_number':286,'multiline':False]['text':' The "setter" for dispatch_key_','line_number':308,'multiline':False]['text':' The only class which actually pulls out values from CppFunction (does so','line_number':312,'multiline':False]['text':' destructively, felt too lazy to write accessors that I don't even','line_number':313,'multiline':False]['text':' want users to use)','line_number':314,'multiline':False]['text':'/ \defgroup torch-dispatch-overloads torch::dispatch overloads','line_number':323,'multiline':False]['text':'/ Create a torch::CppFunction which is associated with a specific','line_number':325,'multiline':False]['text':'/ dispatch key.  torch::CppFunctions that are tagged with a','line_number':326,'multiline':False]['text':'/ c10::DispatchKey don't get invoked unless the dispatcher determines','line_number':327,'multiline':False]['text':'/ that this particular c10::DispatchKey is the one that should be','line_number':328,'multiline':False]['text':'/ dispatched to.','line_number':329,'multiline':False]['text':'/','line_number':330,'multiline':False]['text':'/ This function is generally not used directly, instead, prefer using','line_number':331,'multiline':False]['text':'/ TORCH_LIBRARY_IMPL(), which will implicitly set the c10::DispatchKey','line_number':332,'multiline':False]['text':'/ for all registration calls inside of its body.','line_number':333,'multiline':False]['text':'/','line_number':334,'multiline':False]['text':'/ \ingroup torch-dispatch-overloads','line_number':335,'multiline':False]['text':'/ Convenience overload of dispatch() which accepts c10::DeviceType','line_number':347,'multiline':False]['text':'/','line_number':348,'multiline':False]['text':'/ \ingroup torch-dispatch-overloads','line_number':349,'multiline':False]['text':' This list is synchronized with the k-constants in c10/core/DeviceType.h','line_number':354,'multiline':False]['text':'/ \defgroup torch-schema-overloads torch::schema overloads','line_number':393,'multiline':False]['text':'/ Construct a c10::FunctionSchema from a string, with an explicitly','line_number':395,'multiline':False]['text':'/ specified c10::AliasAnalysisKind.  Ordinarily, schemas are simply','line_number':396,'multiline':False]['text':'/ passed in as strings, but if you need to specify a custom alias','line_number':397,'multiline':False]['text':'/ analysis, you can replace the string with a call to this function.','line_number':398,'multiline':False]['text':'/','line_number':399,'multiline':False]['text':'/ ```','line_number':400,'multiline':False]['text':'/ // Default alias analysis (FROM_SCHEMA)','line_number':401,'multiline':False]['text':'/ m.def("def3(Tensor self) -> Tensor");','line_number':402,'multiline':False]['text':'/ // Pure function alias analysis','line_number':403,'multiline':False]['text':'/ m.def(torch::schema("def3(Tensor self) -> Tensor",','line_number':404,'multiline':False]['text':'/ c10::AliasAnalysisKind::PURE_FUNCTION));','line_number':405,'multiline':False]['text':'/ ```','line_number':406,'multiline':False]['text':'/','line_number':407,'multiline':False]['text':'/ \ingroup torch-schema-overloads','line_number':408,'multiline':False]['text':'/ Function schemas can be directly constructed from string literals.','line_number':415,'multiline':False]['text':'/','line_number':416,'multiline':False]['text':'/ \ingroup torch-schema-overloads','line_number':417,'multiline':False]['text':'/ \private','line_number':422,'multiline':False]['text':'/','line_number':423,'multiline':False]['text':'/ Already constructed function schemas are accepted if they are','line_number':424,'multiline':False]['text':'/ rvalues.','line_number':425,'multiline':False]['text':'/','line_number':426,'multiline':False]['text':'/ \ingroup torch-schema-overloads','line_number':427,'multiline':False]['text':' namespace detail','line_number':454,'multiline':False]['text':' Note [Selective build]','line_number':456,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~','line_number':457,'multiline':False]['text':' In some settings, especially mobile, it is important to avoid compiling any','line_number':458,'multiline':False]['text':' references to functions that you aren't actually going to use, so that they','line_number':459,'multiline':False]['text':' can be eliminated by the linker.  We call this capability "selective build".','line_number':460,'multiline':False]['text':'','line_number':461,'multiline':False]['text':' A very easy way to implement selective build which results in a lot of','line_number':462,'multiline':False]['text':' boilerplate is to just add ifdef's around every registration call, but this','line_number':463,'multiline':False]['text':' means you have to write a lot of extra lines of code at every registration','line_number':464,'multiline':False]['text':' site, and it also means you have to define some munging scheme to map','line_number':465,'multiline':False]['text':' operators to macros.','line_number':466,'multiline':False]['text':'','line_number':467,'multiline':False]['text':' Instead of doing this, we have a different mechanism centered around the','line_number':468,'multiline':False]['text':' concept of a SelectiveStr.  A selective name is like a const char* string,','line_number':469,'multiline':False]['text':' except it also carries at compile time a boolean saying whether or not a','line_number':470,'multiline':False]['text':' registration should actually happen or not.  We then have extra overloads','line_number':471,'multiline':False]['text':' which bypass registration entirely if a selective name is disabled.  We do a','line_number':472,'multiline':False]['text':' constexpr test to see if a operator should be enabled or not; this is','line_number':473,'multiline':False]['text':' currently implemented in ATen/core/op_registration/op_allowlist.h','line_number':474,'multiline':False]['text':' dummy class for non selected custom torchbind classes','line_number':478,'multiline':False]['text':' A SelectiveStr is like a const char*, except that it also comes','line_number':489,'multiline':False]['text':' with a type brand that says whether or not the name is enabled or','line_number':490,'multiline':False]['text':' not.  If the string is disabled, then (at compile time) we DON'T generate','line_number':491,'multiline':False]['text':' a registration call for it.  This class is not intended to be called','line_number':492,'multiline':False]['text':' directly; use TORCH_SELECTIVE_NAME or TORCH_SELECTIVE_SCHEMA macros below','line_number':493,'multiline':False]['text':' to create it.','line_number':494,'multiline':False]['text':' namespace detail','line_number':514,'multiline':False]['text':'/ This object provides the API for defining operators and providing','line_number':516,'multiline':False]['text':'/ implementations at dispatch keys.  Typically, a torch::Library','line_number':517,'multiline':False]['text':'/ is not allocated directly; instead it is created by the','line_number':518,'multiline':False]['text':'/ TORCH_LIBRARY() or TORCH_LIBRARY_IMPL() macros.','line_number':519,'multiline':False]['text':'/','line_number':520,'multiline':False]['text':'/ Most methods on torch::Library return a reference to itself,','line_number':521,'multiline':False]['text':'/ supporting method chaining.','line_number':522,'multiline':False]['text':'/','line_number':523,'multiline':False]['text':'/ ```','line_number':524,'multiline':False]['text':'/ // Examples:','line_number':525,'multiline':False]['text':'/','line_number':526,'multiline':False]['text':'/ TORCH_LIBRARY(torchvision, m) {','line_number':527,'multiline':False]['text':'/    // m is a torch::Library','line_number':528,'multiline':False]['text':'/    m.def("roi_align", ...);','line_number':529,'multiline':False]['text':'/    ...','line_number':530,'multiline':False]['text':'/ }','line_number':531,'multiline':False]['text':'/','line_number':532,'multiline':False]['text':'/ TORCH_LIBRARY_IMPL(aten, XLA, m) {','line_number':533,'multiline':False]['text':'/    // m is a torch::Library','line_number':534,'multiline':False]['text':'/    m.impl("add", ...);','line_number':535,'multiline':False]['text':'/    ...','line_number':536,'multiline':False]['text':'/ }','line_number':537,'multiline':False]['text':'/ ```','line_number':538,'multiline':False]['text':'/','line_number':539,'multiline':False]['text':'/ \private','line_number':542,'multiline':False]['text':'/','line_number':543,'multiline':False]['text':'/ Which type of macro produced this Library','line_number':544,'multiline':False]['text':' from TORCH_LIBRARY (no qualifier)','line_number':546,'multiline':False]['text':'/ \private','line_number':551,'multiline':False]['text':'/','line_number':552,'multiline':False]['text':'/ Use TORCH_LIBRARY() or TORCH_LIBRARY_IMPL() instead of using these','line_number':553,'multiline':False]['text':'/ constructors directly','line_number':554,'multiline':False]['text':' Some notes about the API design here.  We had the following constraints:','line_number':567,'multiline':False]['text':'','line_number':568,'multiline':False]['text':'  - We need to support multiple "types" of arguments for schema and','line_number':569,'multiline':False]['text':'    functions (e.g., unnamed lambda types, regular functions, const char*,','line_number':570,'multiline':False]['text':'    fully instantiated schemas)','line_number':571,'multiline':False]['text':'  - We don't want to write exponentially many overloads','line_number':572,'multiline':False]['text':'  - We don't want to rely on implicit conversion to a common type,','line_number':573,'multiline':False]['text':'    because the C++ compiler will only be willing to do a single','line_number':574,'multiline':False]['text':'    implicit conversion (reducing the set of valid types which you','line_number':575,'multiline':False]['text':'    can invoke with); also error messages are worse when an implicit','line_number':576,'multiline':False]['text':'    conversion is not selected (as the compiler will not explain','line_number':577,'multiline':False]['text':'    why it didn't select an implicit conversion; this is different','line_number':578,'multiline':False]['text':'    from overloads where it will explain each candidate overload and','line_number':579,'multiline':False]['text':'    why it didn't apply)','line_number':580,'multiline':False]['text':'','line_number':581,'multiline':False]['text':' To solve all of these constraints at the same time, we use a trick taken','line_number':582,'multiline':False]['text':' from the pybind11 library: template over the argument in the user visible','line_number':583,'multiline':False]['text':' API, and inside of the templated function explicitly call an overloaded','line_number':584,'multiline':False]['text':' function to resolve the argument to a real type.  You get the good error','line_number':585,'multiline':False]['text':' messages from overloads, but at the same time you only need to write the','line_number':586,'multiline':False]['text':' overload for any given argument type once.','line_number':587,'multiline':False]['text':'/ Declare an operator with a schema, but don't provide any implementations','line_number':589,'multiline':False]['text':'/ for it.  You're expected to then provide implementations using the','line_number':590,'multiline':False]['text':'/ impl() method.  All template arguments are inferred.','line_number':591,'multiline':False]['text':'/','line_number':592,'multiline':False]['text':'/ \param raw_schema The schema of the operator to be defined.','line_number':593,'multiline':False]['text':'/     Typically, this is a `const char*` string literal, but any type','line_number':594,'multiline':False]['text':'/     accepted by torch::schema() is accepted here.','line_number':595,'multiline':False]['text':'/','line_number':596,'multiline':False]['text':'/ ```','line_number':597,'multiline':False]['text':'/ // Example:','line_number':598,'multiline':False]['text':'/ TORCH_LIBRARY(myops, m) {','line_number':599,'multiline':False]['text':'/   m.def("add(Tensor self, Tensor other) -> Tensor");','line_number':600,'multiline':False]['text':'/ }','line_number':601,'multiline':False]['text':'/ ```','line_number':602,'multiline':False]['text':'/ Declares that for all operators that are subsequently def'ed, their','line_number':613,'multiline':False]['text':'/ abstract impls may be found in the given Python module (pymodule).','line_number':614,'multiline':False]['text':'/ This registers some help text that is used if the abstract impl','line_number':615,'multiline':False]['text':'/ cannot be found.','line_number':616,'multiline':False]['text':'/','line_number':617,'multiline':False]['text':'/ Args:','line_number':618,'multiline':False]['text':'/ - pymodule: the python module','line_number':619,'multiline':False]['text':'/ - context: We may include this in the error message.','line_number':620,'multiline':False]['text':'/ Define an operator for a schema and then register an implementation for','line_number':626,'multiline':False]['text':'/ it.  This is typically what you would use if you aren't planning','line_number':627,'multiline':False]['text':'/ on making use of the dispatcher to structure your operator','line_number':628,'multiline':False]['text':'/ implementation.  It's roughly equivalent to calling def() and','line_number':629,'multiline':False]['text':'/ then impl(), but if you omit the schema of the operator, we will','line_number':630,'multiline':False]['text':'/ infer it from the type of your C++ function.  All template','line_number':631,'multiline':False]['text':'/ arguments are inferred.','line_number':632,'multiline':False]['text':'/','line_number':633,'multiline':False]['text':'/ \param raw_name_or_schema The schema of the operator to be','line_number':634,'multiline':False]['text':'/   defined, or just the name of the operator if the schema is to be','line_number':635,'multiline':False]['text':'/   inferred from `raw_f`.  Typically a `const char*` literal.','line_number':636,'multiline':False]['text':'/ \param raw_f The C++ function that implements this operator.','line_number':637,'multiline':False]['text':'/   Any valid constructor of torch::CppFunction is accepted here;','line_number':638,'multiline':False]['text':'/   typically you provide a function pointer or lambda.','line_number':639,'multiline':False]['text':'/','line_number':640,'multiline':False]['text':'/ ```','line_number':641,'multiline':False]['text':'/ // Example:','line_number':642,'multiline':False]['text':'/ TORCH_LIBRARY(myops, m) {','line_number':643,'multiline':False]['text':'/   m.def("add", add_fn);','line_number':644,'multiline':False]['text':'/ }','line_number':645,'multiline':False]['text':'/ ```','line_number':646,'multiline':False]['text':'/ Register an implementation for an operator.  You may register multiple','line_number':657,'multiline':False]['text':'/ implementations for a single operator at different dispatch keys','line_number':658,'multiline':False]['text':'/ (see torch::dispatch()).  Implementations must have a corresponding','line_number':659,'multiline':False]['text':'/ declaration (from def()), otherwise they are invalid.  If you plan','line_number':660,'multiline':False]['text':'/ to register multiple implementations, DO NOT provide a function','line_number':661,'multiline':False]['text':'/ implementation when you def() the operator.','line_number':662,'multiline':False]['text':'/','line_number':663,'multiline':False]['text':'/ \param name The name of the operator to implement.  Do NOT provide','line_number':664,'multiline':False]['text':'/   schema here.','line_number':665,'multiline':False]['text':'/ \param raw_f The C++ function that implements this operator.  Any','line_number':666,'multiline':False]['text':'/   valid constructor of torch::CppFunction is accepted here;','line_number':667,'multiline':False]['text':'/   typically you provide a function pointer or lambda.','line_number':668,'multiline':False]['text':'/','line_number':669,'multiline':False]['text':'/ ```','line_number':670,'multiline':False]['text':'/ // Example:','line_number':671,'multiline':False]['text':'/ TORCH_LIBRARY_IMPL(myops, CUDA, m) {','line_number':672,'multiline':False]['text':'/   m.impl("add", add_cuda);','line_number':673,'multiline':False]['text':'/ }','line_number':674,'multiline':False]['text':'/ ```','line_number':675,'multiline':False]['text':' TODO: need to raise an error when you impl a function that has a','line_number':681,'multiline':False]['text':' catch all def','line_number':682,'multiline':False]['text':' Note: This overload is needed only for C10_MOBILE, since the automatically','line_number':692,'multiline':False]['text':' defined copy constructor for the CppFunction doesn't have the additional','line_number':693,'multiline':False]['text':' NoInferSchemaTag argument. We define the overload for the impl() function','line_number':694,'multiline':False]['text':' to accept a CppFunction&& argument. The already constructed CppFunction','line_number':695,'multiline':False]['text':' object may or may not have the inferred schema, but it doesn't matter','line_number':696,'multiline':False]['text':' for our purposes since if it already has the inferred schema, then we','line_number':697,'multiline':False]['text':' might as well just pass it through directly.','line_number':698,'multiline':False]['text':'','line_number':699,'multiline':False]['text':' TODO: need to raise an error when you impl a function that has a','line_number':702,'multiline':False]['text':' catch all def','line_number':703,'multiline':False]['text':' Helper for getting an OperatorName for a const char*.  You probably','line_number':709,'multiline':False]['text':' don't need this.','line_number':710,'multiline':False]['text':'/ \private','line_number':713,'multiline':False]['text':'/','line_number':714,'multiline':False]['text':'/ Convenience overload for directly specifying the dispatch key when','line_number':715,'multiline':False]['text':'/ impl().  You probably don't need this; instead, prefer specifying','line_number':716,'multiline':False]['text':'/ the dispatch key for the entire block in TORCH_LIBRARY_IMPL()','line_number':717,'multiline':False]['text':'name','line_number':725,'multiline':True]['text':'raw_f','line_number':725,'multiline':True]['text':' These overloads cover cases when a SelectiveStr (see Note [Selective','line_number':732,'multiline':False]['text':' build]) has been disabled at compile time.  In that case, don't generate','line_number':733,'multiline':False]['text':' any code referencing the passed in functions at all.','line_number':734,'multiline':False]['text':'raw_f','line_number':742,'multiline':True]['text':'raw_f','line_number':752,'multiline':True]['text':'key','line_number':758,'multiline':True]['text':'raw_f','line_number':759,'multiline':True]['text':'name','line_number':764,'multiline':True]['text':'raw_f','line_number':765,'multiline':True]['text':'name','line_number':788,'multiline':True]['text':'raw_f','line_number':789,'multiline':True]['text':'/ Register a fallback implementation for all operators which will be used','line_number':796,'multiline':False]['text':'/ if there is not a specific implementation for an operator available.','line_number':797,'multiline':False]['text':'/ There MUST be a DispatchKey associated with a fallback; e.g.,','line_number':798,'multiline':False]['text':'/ only call this from TORCH_LIBRARY_IMPL() with namespace `_`.','line_number':799,'multiline':False]['text':'/','line_number':800,'multiline':False]['text':'/ \param raw_f The function that implements the fallback.  Unboxed','line_number':801,'multiline':False]['text':'/   functions typically do not work as fallback functions, as','line_number':802,'multiline':False]['text':'/   fallback functions must work for every operator (even though','line_number':803,'multiline':False]['text':'/   they have varying type signatures).  Typical arguments are','line_number':804,'multiline':False]['text':'/   CppFunction::makeFallthrough() or','line_number':805,'multiline':False]['text':'/   CppFunction::makeFromBoxedFunction()','line_number':806,'multiline':False]['text':'/','line_number':807,'multiline':False]['text':'/ ```','line_number':808,'multiline':False]['text':'/ // Example:','line_number':809,'multiline':False]['text':'/','line_number':810,'multiline':False]['text':'/ TORCH_LIBRARY_IMPL(_, AutogradXLA, m) {','line_number':811,'multiline':False]['text':'/   // If there is not a kernel explicitly registered','line_number':812,'multiline':False]['text':'/   // for AutogradXLA, fallthrough to the next','line_number':813,'multiline':False]['text':'/   // available kernel','line_number':814,'multiline':False]['text':'/   m.fallback(torch::CppFunction::makeFallthrough());','line_number':815,'multiline':False]['text':'/ }','line_number':816,'multiline':False]['text':'/','line_number':817,'multiline':False]['text':'/ // See aten/src/ATen/core/dispatch/backend_fallback_test.cpp','line_number':818,'multiline':False]['text':'/ // for a full example of boxed fallback','line_number':819,'multiline':False]['text':'/ ```','line_number':820,'multiline':False]['text':' These overloads enable the use of selective build on classes registered','line_number':830,'multiline':False]['text':' within a library. The API is the same as before with 1 minor change.','line_number':831,'multiline':False]['text':' Instead of m.class_<foo>("foo") you instead do','line_number':832,'multiline':False]['text':' m.class_<foo>(TORCH_SELECTIVE_CLASS("foo"))','line_number':833,'multiline':False]['text':' Non-user visible actual implementations of functions.  These aren't','line_number':852,'multiline':False]['text':' public because we only implement & qualifier and not && qualifier','line_number':853,'multiline':False]['text':' namespace detail','line_number':892,'multiline':False]['text':' namespace torch','line_number':894,'multiline':False]['text':' NB: The EXACT NAMING of the initializer functions (e.g.,','line_number':896,'multiline':False]['text':' TORCH_LIBRARY_init_aten) matters for the code analyzer;','line_number':897,'multiline':False]['text':' see the regexes at tools/code_analyzer/run_analyzer.sh','line_number':898,'multiline':False]['text':'/ Macro for defining a function that will be run at static','line_number':900,'multiline':False]['text':'/ initialization time to define a library of operators in the','line_number':901,'multiline':False]['text':'/ namespace `ns` (must be a valid C++ identifier, no quotes).','line_number':902,'multiline':False]['text':'/ Use this macro when you want to define a new set of custom operators','line_number':903,'multiline':False]['text':'/ that do not already exist in PyTorch.','line_number':904,'multiline':False]['text':'/','line_number':905,'multiline':False]['text':'/ Example usage:','line_number':906,'multiline':False]['text':'/','line_number':907,'multiline':False]['text':'/ ```','line_number':908,'multiline':False]['text':'/ TORCH_LIBRARY(myops, m) {','line_number':909,'multiline':False]['text':'/   // m is a torch::Library; methods on it will define','line_number':910,'multiline':False]['text':'/   // operators in the myops namespace','line_number':911,'multiline':False]['text':'/   m.def("add", add_impl);','line_number':912,'multiline':False]['text':'/ }','line_number':913,'multiline':False]['text':'/ ```','line_number':914,'multiline':False]['text':'/','line_number':915,'multiline':False]['text':'/ The `m` argument is bound to a torch::Library that is used to','line_number':916,'multiline':False]['text':'/ register operators.  There may only be one TORCH_LIBRARY()','line_number':917,'multiline':False]['text':'/ for any given namespace.','line_number':918,'multiline':False]['text':'/ \private','line_number':930,'multiline':False]['text':'/','line_number':931,'multiline':False]['text':'/ This macro is a version of TORCH_LIBRARY() that doesn't enforce that there','line_number':932,'multiline':False]['text':'/ is only one library (it is a "fragment").  This is used inside the','line_number':933,'multiline':False]['text':'/ PerOpRegistration.cpp file, as well as in places where all op registrations','line_number':934,'multiline':False]['text':'/ within the same namespace cannot be easily put into one macro block','line_number':935,'multiline':False]['text':'/ (this is mostly the case for custom ops in fbcode that were ported from','line_number':936,'multiline':False]['text':'/ the old API)','line_number':937,'multiline':False]['text':'/ \private','line_number':940,'multiline':False]['text':'/','line_number':941,'multiline':False]['text':'/ The above macro requires an extra unique identifier (uid) to prevent','line_number':942,'multiline':False]['text':'/ variable name collisions This can happen if TORCH_LIBRARY_FRAGMENT is called','line_number':943,'multiline':False]['text':'/ multiple times with the same namespace in the same translation unit. Note','line_number':944,'multiline':False]['text':'/ that the TORCH_LIBRARY variant doesn't run into this problem, because it','line_number':945,'multiline':False]['text':'/ enforces that it can only be called once for a given namespace.','line_number':946,'multiline':False]['text':'/ Macro for defining a function that will be run at static','line_number':961,'multiline':False]['text':'/ initialization time to define operator overrides for dispatch key','line_number':962,'multiline':False]['text':'/ `k` (must be an unqualified enum member of c10::DispatchKey) in','line_number':963,'multiline':False]['text':'/ namespace `ns` (must be a valid C++ identifer, no quotes).  Use this','line_number':964,'multiline':False]['text':'/ macro when you want to implement a preexisting set of custom','line_number':965,'multiline':False]['text':'/ operators on a new dispatch key (e.g., you want to provide CUDA','line_number':966,'multiline':False]['text':'/ implementations of already existing operators).  One common usage','line_number':967,'multiline':False]['text':'/ pattern is to use TORCH_LIBRARY() to define schema for all new','line_number':968,'multiline':False]['text':'/ operators you want to define, and then use several','line_number':969,'multiline':False]['text':'/ TORCH_LIBRARY_IMPL() blocks to provide implementations of the','line_number':970,'multiline':False]['text':'/ operator for CPU, CUDA and Autograd.','line_number':971,'multiline':False]['text':'/','line_number':972,'multiline':False]['text':'/ In some cases, you need to define something that applies to all namespaces,','line_number':973,'multiline':False]['text':'/ not just one namespace (usually a fallback).  In that case, use the reserved','line_number':974,'multiline':False]['text':'/ namespace _, e.g.,','line_number':975,'multiline':False]['text':'/','line_number':976,'multiline':False]['text':'/ ```','line_number':977,'multiline':False]['text':'/ TORCH_LIBRARY_IMPL(_, XLA, m) {','line_number':978,'multiline':False]['text':'/    m.fallback(xla_fallback);','line_number':979,'multiline':False]['text':'/ }','line_number':980,'multiline':False]['text':'/ ```','line_number':981,'multiline':False]['text':'/','line_number':982,'multiline':False]['text':'/ Example usage:','line_number':983,'multiline':False]['text':'/','line_number':984,'multiline':False]['text':'/ ```','line_number':985,'multiline':False]['text':'/ TORCH_LIBRARY_IMPL(myops, CPU, m) {','line_number':986,'multiline':False]['text':'/   // m is a torch::Library; methods on it will define','line_number':987,'multiline':False]['text':'/   // CPU implementations of operators in the myops namespace.','line_number':988,'multiline':False]['text':'/   // It is NOT valid to call torch::Library::def()','line_number':989,'multiline':False]['text':'/   // in this context.','line_number':990,'multiline':False]['text':'/   m.impl("add", add_cpu_impl);','line_number':991,'multiline':False]['text':'/ }','line_number':992,'multiline':False]['text':'/ ```','line_number':993,'multiline':False]['text':'/','line_number':994,'multiline':False]['text':'/ If ``add_cpu_impl`` is an overloaded function, use a','line_number':995,'multiline':False]['text':'/ ``static_cast`` to specify which overload you want','line_number':996,'multiline':False]['text':'/ (by providing the full type).','line_number':997,'multiline':False]['text':'/','line_number':998,'multiline':False]['text':' NB: if the dispatch key is not whitelisted, we simply omit the Library','line_number':999,'multiline':False]['text':' call entirely','line_number':1000,'multiline':False]['text':'/ \private','line_number':1003,'multiline':False]['text':'/','line_number':1004,'multiline':False]['text':'/ The above macro requires an extra unique identifier (uid) to prevent','line_number':1005,'multiline':False]['text':'/ variable name collisions. This can happen if TORCH_LIBRARY_IMPL is called','line_number':1006,'multiline':False]['text':'/ multiple times with the same namespace and dispatch key in the same','line_number':1007,'multiline':False]['text':'/ translation unit.','line_number':1008,'multiline':False]['text':' These are variants of the macros above which are to be used for testing (they','line_number':1025,'multiline':False]['text':' don't setup the static initializer, so you can control the visibility of','line_number':1026,'multiline':False]['text':' the allocated library yourself).','line_number':1027,'multiline':False]['text':'','line_number':1028,'multiline':False]['text':' DO NOT use these in production code, they are NOT understood by the','line_number':1029,'multiline':False]['text':' code analyzer and will be incorrectly analyzed in those situations.','line_number':1030,'multiline':False]['text':'/ \private','line_number':1032,'multiline':False]['text':'/ \private','line_number':1035,'multiline':False]['text':' Make the custom class API visible, so it is available from','line_number':1044,'multiline':False]['text':' torch::Library.','line_number':1045,'multiline':False]