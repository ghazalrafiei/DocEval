['text':' Experimental module containing prototype Python references for existing','line_number':50,'multiline':False]['text':'   PyTorch operations.','line_number':51,'multiline':False]['text':'','line_number':54,'multiline':False]['text':' Elementwise Unary References','line_number':55,'multiline':False]['text':'','line_number':56,'multiline':False]['text':' "cbrt",  # No corresponding torch operation','line_number':65,'multiline':False]['text':' TODO: model kwargs','line_number':114,'multiline':False]['text':'','line_number':129,'multiline':False]['text':' Elementwise Binary References','line_number':130,'multiline':False]['text':'','line_number':131,'multiline':False]['text':' 'ldexp',','line_number':159,'multiline':False]['text':' 'max', # implement with reductions','line_number':169,'multiline':False]['text':' 'min', # implement with reductions','line_number':171,'multiline':False]['text':' 'polar',  # abs, cos, sin','line_number':176,'multiline':False]['text':'','line_number':188,'multiline':False]['text':' Elementwise Ternary References','line_number':189,'multiline':False]['text':'','line_number':190,'multiline':False]['text':'','line_number':194,'multiline':False]['text':' Conditional references','line_number':195,'multiline':False]['text':'','line_number':196,'multiline':False]['text':'','line_number':200,'multiline':False]['text':' Data conversion and movement references','line_number':201,'multiline':False]['text':'','line_number':202,'multiline':False]['text':' TODO: add OpInfo (or implement .to)','line_number':204,'multiline':False]['text':'','line_number':207,'multiline':False]['text':' Reduction ops','line_number':208,'multiline':False]['text':'','line_number':209,'multiline':False]['text':'','line_number':226,'multiline':False]['text':' Linear algebra ops','line_number':227,'multiline':False]['text':'','line_number':228,'multiline':False]['text':'','line_number':230,'multiline':False]['text':' View & Shape Ops','line_number':231,'multiline':False]['text':'','line_number':232,'multiline':False]['text':' alias for transpose','line_number':279,'multiline':False]['text':'','line_number':300,'multiline':False]['text':' Tensor Creation','line_number':301,'multiline':False]['text':'','line_number':302,'multiline':False]['text':'','line_number':326,'multiline':False]['text':' Test-related functions','line_number':327,'multiline':False]['text':'','line_number':328,'multiline':False]['text':'','line_number':331,'multiline':False]['text':' Statistical operations','line_number':332,'multiline':False]['text':'','line_number':333,'multiline':False]['text':'','line_number':335,'multiline':False]['text':' Misc','line_number':336,'multiline':False]['text':'','line_number':337,'multiline':False]['text':' type: ignore[attr-defined]','line_number':345,'multiline':False]['text':' Note that the docstrings for the public methods from this file are in','line_number':348,'multiline':False]['text':' torch/_torch_docs.py','line_number':349,'multiline':False]['text':' Short-circuits on no input','line_number':379,'multiline':False]['text':' Type checking','line_number':383,'multiline':False]['text':' TODO: make common validations available as utils','line_number':384,'multiline':False]['text':' Computes common shape','line_number':388,'multiline':False]['text':' Computes common shape','line_number':412,'multiline':False]['text':' Utilities should come BEFORE this import','line_number':438,'multiline':False]['text':'','line_number':441,'multiline':False]['text':' Elementwise unary references','line_number':442,'multiline':False]['text':'','line_number':443,'multiline':False]['text':' TODO: add type promotion support','line_number':448,'multiline':False]['text':' type: ignore[union-attr]','line_number':494,'multiline':False]['text':' nb. We use the name of the first argument used in the unary references','line_number':504,'multiline':False]['text':' We access the __all__ attribute of the module where fn is defined','line_number':513,'multiline':False]['text':' There may be a cleaner way of doing this...','line_number':514,'multiline':False]['text':' type: ignore[union-attr]','line_number':517,'multiline':False]['text':' Fill has its own implementation because it has a value parameter','line_number':626,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':627,'multiline':False]['text':' imag does not use _make_elementwise_unary_reference because it does not support out','line_number':668,'multiline':False]['text':' CompositeImplicitAutograd','line_number':679,'multiline':False]['text':' alias','line_number':724,'multiline':False]['text':' type: ignore[has-type]','line_number':725,'multiline':False]['text':' CompositeImplicitAutograd','line_number':730,'multiline':False]['text':' TODO: if this is special maybe it should be defined there and imported here?','line_number':738,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':771,'multiline':False]['text':' type: ignore[return-value]','line_number':781,'multiline':False]['text':' type: ignore[call-overload]','line_number':826,'multiline':False]['text':' type: ignore[call-overload]','line_number':827,'multiline':False]['text':' type: ignore[call-overload]','line_number':828,'multiline':False]['text':' positive does not use _make_elementwise_unary_reference because it does not support out','line_number':850,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':851,'multiline':False]['text':' real does not use _make_elementwise_unary_reference because it does not support out','line_number':860,'multiline':False]['text':' TODO: round takes additional kwargs','line_number':873,'multiline':False]['text':' TODO: this does need a decomp, but kwarg handling is needed','line_number':876,'multiline':False]['text':' Autograd note: This will give the right first derivative at zero (by chance),','line_number':916,'multiline':False]['text':' but not the right second derivative','line_number':917,'multiline':False]['text':' CompositeImplicitAutograd,','line_number':936,'multiline':False]['text':' TODO: register this as a real ref/decomposition once TorchInductor supports complex!','line_number':957,'multiline':False]['text':' Add has its own implementation because it has an alpha argument','line_number':1051,'multiline':False]['text':' type: ignore[union-attr]','line_number':1071,'multiline':False]['text':' complex =  _make_elementwise_binary_reference(prims.complex, type_promotion_kind=ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)','line_number':1148,'multiline':False]['text':' type: ignore[return-value,union-attr]','line_number':1192,'multiline':False]['text':' type: ignore[return-value]','line_number':1194,'multiline':False]['text':' type: ignore[arg-type]','line_number':1196,'multiline':False]['text':' Float power has its own implementation because it has unique type promotion.','line_number':1208,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':1209,'multiline':False]['text':' Handles type promotion','line_number':1220,'multiline':False]['text':' Float power has the following contiguous cast behavior to be','line_number':1228,'multiline':False]['text':' consistent with its C++ impl','line_number':1229,'multiline':False]['text':' >>> a = torch.tensor(-0.2500, dtype=torch.float64)','line_number':1237,'multiline':False]['text':' tensor(-0.250000000000000, dtype=torch.float64)','line_number':1238,'multiline':False]['text':'','line_number':1239,'multiline':False]['text':' >>> b = torch.tensor(-0.0010, dtype=torch.float64)','line_number':1240,'multiline':False]['text':' tensor(-0.001000000000000, dtype=torch.float64)','line_number':1241,'multiline':False]['text':'','line_number':1242,'multiline':False]['text':' Note: In this case, casting float to double will expand the float mantissa with zeros,','line_number':1243,'multiline':False]['text':' while creating a double generates a distinct mantissa.','line_number':1244,'multiline':False]['text':' >>> torch.tensor(-0.001).to(dtype=torch.float64)','line_number':1245,'multiline':False]['text':' tensor(-0.001000000047497, dtype=torch.float64)','line_number':1246,'multiline':False]['text':'','line_number':1247,'multiline':False]['text':' Floor Division','line_number':1248,'multiline':False]['text':' The difference is caused because torch.remainder(a, b) = -0.001.','line_number':1249,'multiline':False]['text':'','line_number':1250,'multiline':False]['text':' >>> torch.floor(torch.true_divide(a, b))','line_number':1251,'multiline':False]['text':' tensor(250., dtype=torch.float64)','line_number':1252,'multiline':False]['text':'','line_number':1253,'multiline':False]['text':' >>> torch.div(a, b, rounding_mode='floor')','line_number':1254,'multiline':False]['text':' tensor(249., dtype=torch.float64)','line_number':1255,'multiline':False]['text':'','line_number':1256,'multiline':False]['text':' Definition: a // b = (a - remainder(a, b)) / b','line_number':1257,'multiline':False]['text':' >>> torch.true_divide(torch.sub(a, torch.remainder(a, b)), b)','line_number':1258,'multiline':False]['text':' tensor(249., dtype=torch.float64)','line_number':1259,'multiline':False]['text':'','line_number':1260,'multiline':False]['text':' For reference, see CPython's implementation:','line_number':1261,'multiline':False]['text':' https://github.com/python/cpython/blob/ace008c531dd685a30c1dd68f9b5ba35f20171cf/Objects/floatobject.c#L636','line_number':1262,'multiline':False]['text':' Wrap scalars because some references only accept tensor arguments.','line_number':1273,'multiline':False]['text':' Convert truncation to flooring:','line_number':1306,'multiline':False]['text':' Ensure that the remainder has the same sign as denominator','line_number':1315,'multiline':False]['text':' Map quotient to nearest integer value','line_number':1321,'multiline':False]['text':' If quotient is zero, copy signbit from true_divide quotient','line_number':1329,'multiline':False]['text':' If denominator is zero, then follow true_divide behavior','line_number':1332,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':1449,'multiline':False]['text':' Note: In case of zero tolerances the closeness inequality degenerates to an equality check.','line_number':1463,'multiline':False]['text':' In this case, the short-circuit prevents false positives as detailed in the paragraph below.','line_number':1464,'multiline':False]['text':' Note [closeness error computation]','line_number':1468,'multiline':False]['text':' atol and rtol are provided as doubles, so the computation','line_number':1469,'multiline':False]['text':' rtol * other will produce a float or complex tensor.','line_number':1470,'multiline':False]['text':' When the difference (self - other) is compared to it then the','line_number':1471,'multiline':False]['text':' tensor representing the difference will also be cast to float or complex.','line_number':1472,'multiline':False]['text':' However, since (self - other) in uint8 is very likely to produce a','line_number':1473,'multiline':False]['text':' negative value, this moves the cast forward so the difference is','line_number':1474,'multiline':False]['text':' always computed in a float or complex type.','line_number':1475,'multiline':False]['text':' If the values of the integer tensors cannot be exactly represented','line_number':1476,'multiline':False]['text':' by the default scalar type then this may cause an incorrect result.','line_number':1477,'multiline':False]['text':' Computes finite closeness','line_number':1485,'multiline':False]['text':' promoting to int32 to maintain 100% consistency with C++ and to','line_number':1500,'multiline':False]['text':' prevent overflow in case of int8 and int16','line_number':1501,'multiline':False]['text':' Avoid division by zero in case gcd(0, 0) == 0','line_number':1508,'multiline':False]['text':' Nb. this implementation does not distribute the gradients evenly when a == b','line_number':1528,'multiline':False]['text':' are you wondering what this bunch of codes are for? edge cases!','line_number':1536,'multiline':False]['text':' the type for full_like does not include tensor yet','line_number':1544,'multiline':False]['text':' type: ignore[call-overload]','line_number':1546,'multiline':False]['text':' Nb. this implementation does not distribute the gradients evenly when a == b','line_number':1561,'multiline':False]['text':' TODO: skip unnecessary conversion of long to float','line_number':1600,'multiline':False]['text':' reverse sub','line_number':1666,'multiline':False]['text':' TODO: consider refactoring this with add impl','line_number':1679,'multiline':False]['text':' sub has its own implementation because it has an alpha argument','line_number':1680,'multiline':False]['text':' type: ignore[union-attr]','line_number':1700,'multiline':False]['text':' Carefully not to use prims.mul if b is a scalar / symint.','line_number':1708,'multiline':False]['text':' prims.mul always returns a tensor,','line_number':1709,'multiline':False]['text':' which will mess with type promotion.','line_number':1710,'multiline':False]['text':' CompositeImplicitAutograd','line_number':1720,'multiline':False]['text':' Operations like eq and log do not handle scalar values, so we convert them to scalar_tensors.','line_number':1739,'multiline':False]['text':' mypy: expected "Tensor"','line_number':1745,'multiline':False]['text':' CompositeImplicitAutograd','line_number':1754,'multiline':False]['text':'','line_number':1767,'multiline':False]['text':' Elementwise Ternary References','line_number':1768,'multiline':False]['text':'','line_number':1769,'multiline':False]['text':' no scalars allowed, see add','line_number':1789,'multiline':False]['text':' no scalars allowed, see add','line_number':1816,'multiline':False]['text':' NOTE: grad behavior with implementation `where` is not consistent on `nan`','line_number':1837,'multiline':False]['text':' type: ignore[arg-type]','line_number':1843,'multiline':False]['text':' we should also propagate `nan` coming from boundaries. However, that's','line_number':1844,'multiline':False]['text':' not necessary since `ge` would already `False` when either operands has','line_number':1845,'multiline':False]['text':' a `nan`. So this line below is redundant','line_number':1846,'multiline':False]['text':'   `condition = bitwise_and(condition, bitwise_not(isnan(min)))`','line_number':1847,'multiline':False]['text':' type: ignore[arg-type]','line_number':1848,'multiline':False]['text':' same as above, no need to adjust `nan` from `max`','line_number':1851,'multiline':False]['text':' type: ignore[arg-type]','line_number':1852,'multiline':False]['text':' type: ignore[arg-type]','line_number':1853,'multiline':False]['text':' type: ignore[arg-type]','line_number':1864,'multiline':False]['text':' type: ignore[arg-type]','line_number':1873,'multiline':False]['text':'','line_number':1876,'multiline':False]['text':' Conditional references','line_number':1877,'multiline':False]['text':'','line_number':1878,'multiline':False]['text':' https://pytorch.org/docs/stable/generated/torch.where.html','line_number':1881,'multiline':False]['text':' TODO: implement alternate where','line_number':1882,'multiline':False]['text':'','line_number':1909,'multiline':False]['text':' Data Movement References','line_number':1910,'multiline':False]['text':'','line_number':1911,'multiline':False]['text':' NOTE: explicit conversion is necessary for bool!','line_number':1937,'multiline':False]['text':' See https://github.com/pytorch/pytorch/issues/78071','line_number':1938,'multiline':False]['text':' fast path when `to` returns an alias to input. This mimics the same function in aten','line_number':1943,'multiline':False]['text':' not using non_blocking','line_number':1952,'multiline':False]['text':' is_pinned issue #84925','line_number':1959,'multiline':False]['text':' and (pin_memory is None or pin_memory == a.is_pinned())','line_number':1960,'multiline':False]['text':' is_pinned issue #84925','line_number':2036,'multiline':False]['text':' pin_memory = other.is_pinned()','line_number':2037,'multiline':False]['text':' remove to_kwargs that is already present in `a`','line_number':2049,'multiline':False]['text':' "device" option could be passed a str instead torch.device','line_number':2052,'multiline':False]['text':' this also handles {"memory_format": None}','line_number':2069,'multiline':False]['text':' handled dispatch via positional arguments','line_number':2075,'multiline':False]['text':' TODO: is_pinned is not currently supported in refs or fake_tensor','line_number':2079,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/84925','line_number':2080,'multiline':False]['text':' short-circuit to `prims.convert_element_type` when `to` is just a dtype change','line_number':2090,'multiline':False]['text':' is_pinned issue #84925','line_number':2097,'multiline':False]['text':' and ("pin_memory" not in kwargs)','line_number':2098,'multiline':False]['text':' TODO: non_blocking should be handled by `copy_to`','line_number':2103,'multiline':False]['text':'','line_number':2108,'multiline':False]['text':' Reduction references','line_number':2109,'multiline':False]['text':'','line_number':2110,'multiline':False]['text':' to handle min/argmin that accept single dim only','line_number':2118,'multiline':False]['text':' should be specified for ops that support it','line_number':2121,'multiline':False]['text':' it is usually SAME, but I want','line_number':2124,'multiline':False]['text':' ref writers to actually think about what to put here','line_number':2125,'multiline':False]['text':' TODO - this is true for eager mode currently, but it's wrong behavior for complex norms','line_number':2135,'multiline':False]['text':' type: ignore[assignment]','line_number':2143,'multiline':False]['text':' type: ignore[assignment]','line_number':2154,'multiline':False]['text':' type: ignore[arg-type]','line_number':2168,'multiline':False]['text':' Saves Python all','line_number':2195,'multiline':False]['text':' Saves Python any','line_number':2214,'multiline':False]['text':' Preserves uint8 -- probably a legacy mask thing','line_number':2231,'multiline':False]['text':' reduces over all dimensions if dim=() is passed','line_number':2254,'multiline':False]['text':' In ATen scalar tensors are sent through sum and the result is returned as','line_number':2277,'multiline':False]['text':' type promoted','line_number':2278,'multiline':False]['text':' reduces over all dimensions if dim=() is passed','line_number':2306,'multiline':False]['text':' reduces over all dimensions if dim=() is passed','line_number':2328,'multiline':False]['text':' reduces over all dimensions if dim=() is passed','line_number':2352,'multiline':False]['text':' There's the following overload of torch.var:','line_number':2369,'multiline':False]['text':' var(Tensor self, bool unbiased=True) -> (Tensor, Tensor)','line_number':2370,'multiline':False]['text':' We need to explicitly convert bool dims to unbiased arg','line_number':2371,'multiline':False]['text':' reduces over all dimensions if dim=() is passed','line_number':2390,'multiline':False]['text':' reduces over all dimensions if dim=() is passed','line_number':2439,'multiline':False]['text':' can't use out wrapper because of this argument','line_number':2445,'multiline':False]['text':' type: ignore[assignment]','line_number':2468,'multiline':False]['text':' type: ignore[arg-type]','line_number':2469,'multiline':False]['text':' type: ignore[assignment]','line_number':2473,'multiline':False]['text':' type: ignore[arg-type]','line_number':2477,'multiline':False]['text':' Integers are accepted for booleans','line_number':2547,'multiline':False]['text':' This means NaNs from self are dropped if beta is zero','line_number':2573,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':2579,'multiline':False]['text':' Helper function with assert to avoid MyPy error','line_number':2593,'multiline':False]['text':' of incompatible type passed to unsqueeze','line_number':2594,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':2603,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':2618,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':2670,'multiline':False]['text':' match logic in legacy_cat_wrap_dim','line_number':2706,'multiline':False]['text':' Filters tensors with one dimension of length zero','line_number':2715,'multiline':False]['text':' TODO: fix this to work with meta tensors','line_number':2720,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':2737,'multiline':False]['text':' This replicates at::constant_pad_nd, defined in ATen/native/PadNd.cpp','line_number':2754,'multiline':False]['text':' if none of the pads are positive we can just return the result','line_number':2787,'multiline':False]['text':' torch.fill isn't typed to allow complex values','line_number':2815,'multiline':False]['text':' type: ignore[arg-type]','line_number':2816,'multiline':False]['text':' NOTE: cannot use utils.extract_shape_from_varargs here','line_number':2855,'multiline':False]['text':' because that also validates the shape, but the shape','line_number':2856,'multiline':False]['text':' given to expand may be "invalid"','line_number':2857,'multiline':False]['text':' At this point shape must be valid','line_number':2878,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':2886,'multiline':False]['text':' Note: flatten, unlike other shape operators, returns the input tensor on a no-op (unless','line_number':2912,'multiline':False]['text':' a 0D tensor is flattened, in which case it's returned in 1D)','line_number':2913,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':2914,'multiline':False]['text':' Short-circuits on no-op','line_number':2919,'multiline':False]['text':' Tries to take a view','line_number':2923,'multiline':False]['text':' TODO: we could look at directing collapse_view to skip its meta function here (unsafe_collapse_view)','line_number':2924,'multiline':False]['text':' Makes a copy if it can't make a view','line_number':2929,'multiline':False]['text':' type: ignore[assignment]','line_number':2938,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':2943,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':2951,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':2959,'multiline':False]['text':' Supports Tensor overload that was added for XLA:','line_number':2963,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/31558','line_number':2964,'multiline':False]['text':' type: ignore[assignment]','line_number':2970,'multiline':False]['text':' type: ignore[arg-type]','line_number':2977,'multiline':False]['text':' type: ignore[arg-type]','line_number':2983,'multiline':False]['text':' TODO: This must return a sparse tensor if the input is sparse, but refs have','line_number':2989,'multiline':False]['text':' no sparse support. See narrow_copy_sparse in core.','line_number':2990,'multiline':False]['text':' to avoid mypy error for var_mean','line_number':3014,'multiline':False]['text':' add all specified dimensions','line_number':3023,'multiline':False]['text':' num_channels / num_groups and flattened inner dimension are the reduction axes','line_number':3051,'multiline':False]['text':' type: ignore[assignment]','line_number':3073,'multiline':False]['text':' type: ignore[assignment]','line_number':3074,'multiline':False]['text':' type: ignore[assignment]','line_number':3075,'multiline':False]['text':' remove broadcast dimensions from mean and rstd','line_number':3077,'multiline':False]['text':' torch.Size([1, 2, 3]) == [1, 2, 3] evaluates to False','line_number':3099,'multiline':False]['text':' while torch.Size([1, 2, 3]) == (1, 2, 3) is True','line_number':3100,'multiline':False]['text':' therefore we use tuple(normalized_shape)','line_number':3101,'multiline':False]['text':' type: ignore[union-attr]','line_number':3106,'multiline':False]['text':' type: ignore[union-attr]','line_number':3114,'multiline':False]['text':' type: ignore[assignment]','line_number':3146,'multiline':False]['text':' type: ignore[assignment]','line_number':3148,'multiline':False]['text':' type: ignore[assignment]','line_number':3149,'multiline':False]['text':' TODO: Adding this as a meta function causes functorch tests to fail when compiled with debug mode.','line_number':3153,'multiline':False]['text':' test/test_eager_transforms.py::TestFunctionalizeCPU::test_functionalize_fx_transpose_simple_cpu','line_number':3154,'multiline':False]['text':' For half and bfloat16, calculate norm in float precision then cast','line_number':3186,'multiline':False]['text':' normalization factor to half','line_number':3187,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':3203,'multiline':False]['text':' type: ignore[union-attr]','line_number':3221,'multiline':False]['text':' type: ignore[union-attr]','line_number':3277,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':3311,'multiline':False]['text':' type: ignore[union-attr]','line_number':3329,'multiline':False]['text':' type: ignore[union-attr]','line_number':3340,'multiline':False]['text':' Get the new shape and stride after applying unfold to an input tensor','line_number':3466,'multiline':False]['text':' return an empty tensor if one of the repeat_shape dimensions is zero','line_number':3517,'multiline':False]['text':' repeat each dimension by using unfold_copy operation','line_number':3530,'multiline':False]['text':' derive permute order by sorting urtensor strides','line_number':3535,'multiline':False]['text':' add new and expand dimensions according to urtensor','line_number':3540,'multiline':False]['text':' clone tensor to concretize expanded dimensions','line_number':3543,'multiline':False]['text':' transpose axis so strides are in sorted order','line_number':3546,'multiline':False]['text':' reshape to get contiguous tensor with correct target shape','line_number':3549,'multiline':False]['text':' Creates a valid shape','line_number':3554,'multiline':False]['text':' Reshape may be given a shape with a -1 length','line_number':3556,'multiline':False]['text':' This indicates that the dimension's length should be inferred','line_number':3557,'multiline':False]['text':' Short-circuits if shape is the same','line_number':3560,'multiline':False]['text':' Special-cases tensors with no elements','line_number':3564,'multiline':False]['text':' Special-cases reshaping zero dim tensors','line_number':3568,'multiline':False]['text':' Special-cases reshaping to zero dim tensors','line_number':3576,'multiline':False]['text':' Handles general case: a 1+D tensor reshaped into a distinct 1+D shape','line_number':3584,'multiline':False]['text':' NOTE [Reshape Algorithm]','line_number':3586,'multiline':False]['text':' This algorithm works by attempting to greedily construct the desired dimensions in','line_number':3587,'multiline':False]['text':' the output shape, left to right. It does this by, conceptually, accumulating','line_number':3588,'multiline':False]['text':' dimensions of the original tensor, also left to right, until the dimension','line_number':3589,'multiline':False]['text':' can be constructed using prims.split_dim.','line_number':3590,'multiline':False]['text':' The algorithm also has special handling for tail squeezes/unsqueezes, like','line_number':3591,'multiline':False]['text':' if a reshape from (5, 5) to (5, 5, 1) or vice versa.','line_number':3592,'multiline':False]['text':'','line_number':3593,'multiline':False]['text':' This algorithm does not flatten the original tensor and then split dims as appropriate','line_number':3594,'multiline':False]['text':' because that would create copies more often than this algorithm. flatten is the only','line_number':3595,'multiline':False]['text':' operation below which can create a view or a copy, and while it prefers creating','line_number':3596,'multiline':False]['text':' views it may sometimes create a copy if the tensor's strides do not permit a view.','line_number':3597,'multiline':False]['text':' As a result, this algorithm tries to minimize flattening.','line_number':3598,'multiline':False]['text':'','line_number':3599,'multiline':False]['text':' Note that a better version of this algorithm may exist. Regions which could be','line_number':3600,'multiline':False]['text':' flattened without creating a copy can be identified in advance, and that might','line_number':3601,'multiline':False]['text':' allow fewer flatten calls or faster short-circuiting to make a copy.','line_number':3602,'multiline':False]['text':' Handles tail unsqueezes','line_number':3606,'multiline':False]['text':' NOTE: using split_dim instead of unsqueeze may seem silly here,','line_number':3610,'multiline':False]['text':' but it's necessary to get the strides correct','line_number':3611,'multiline':False]['text':' Skips dimensions that are already the correct length','line_number':3616,'multiline':False]['text':' Gathers enough original dimensions such that this new dimension can be created','line_number':3621,'multiline':False]['text':' Note that this accumulation will terminate because we've verified a and the shape','line_number':3622,'multiline':False]['text':' specify the same number of elements above','line_number':3623,'multiline':False]['text':' NOTE: in this case multiple dimensions must be flatten to create the desired dimension','line_number':3630,'multiline':False]['text':' This flattening is why reshape sometimes creates a copy -- because flattening','line_number':3631,'multiline':False]['text':' may return a view of a copy','line_number':3632,'multiline':False]['text':' Checks if collapse can be a view and short-circuits to copying reshape if it can't','line_number':3634,'multiline':False]['text':' Splits the (possibly flattened) dimension to create the desired dim length','line_number':3647,'multiline':False]['text':' Squeezes tail','line_number':3653,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':3661,'multiline':False]['text':' NOTE: shape is a vararg because Tensor.reshape can be called with as','line_number':3662,'multiline':False]['text':' Tensor.reshape(a, b, c) or Tensor.reshape((a, b, c)) Function call','line_number':3663,'multiline':False]['text':' torch.reshape doesn't support unpacked shapes','line_number':3664,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':3669,'multiline':False]['text':' ATen specifies int[1] type for shifts and dims which expands integers to tuples of length 1','line_number':3681,'multiline':False]['text':' Avoid modulo by zero','line_number':3687,'multiline':False]['text':' Keeping this as ref for now as FakeTensor runs into some issues with complex tensors','line_number':3689,'multiline':False]['text':' Takes care of the case when dims is not specified (default)','line_number':3702,'multiline':False]['text':' By default, the tensor is flattened before shifting, after which the original shape is restored','line_number':3703,'multiline':False]['text':' This path is taken when only one dimension is rolled','line_number':3716,'multiline':False]['text':' For example to get `first_dim_rolled` above','line_number':3717,'multiline':False]['text':' Do this after the initial checks to be compatible with the behavior in','line_number':3739,'multiline':False]['text':' core.','line_number':3740,'multiline':False]['text':' Rotation direction is from the second towards the first axis for k < 0','line_number':3747,'multiline':False]['text':' Refs need sparse support to check other condition','line_number':3772,'multiline':False]['text':' and not tensors[0].is_sparse:','line_number':3773,'multiline':False]['text':' If dim == tensors[0].ndim, view cannot efficiently handle it','line_number':3780,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':3784,'multiline':False]['text':' type: ignore[return-value]','line_number':3801,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':3804,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':3814,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':3822,'multiline':False]['text':' Treat scalars as elements of \R^1','line_number':3857,'multiline':False]['text':' type: ignore[union-attr]','line_number':3894,'multiline':False]['text':' type: ignore[arg-type]','line_number':3896,'multiline':False]['text':' type: ignore[arg-type]','line_number':3899,'multiline':False]['text':' index_copy has some unnecessary preconditions when x is a scalar. We do this to work through them','line_number':3902,'multiline':False]['text':' index_copy does not broadcast on value so we have to do it manually','line_number':3905,'multiline':False]['text':' type: ignore[operator]','line_number':3910,'multiline':False]['text':' The clone is necessary so that it returns a fresh tensor rather than a view','line_number':3915,'multiline':False]['text':' index_fill preserves the strides. index_copy always returns contiguous tensors','line_number':3917,'multiline':False]['text':' index_add always returns a new contiguous tensor','line_number':3934,'multiline':False]['text':' type: ignore[arg-type]','line_number':3936,'multiline':False]['text':' Treat scalars as elements of \R^1','line_number':3951,'multiline':False]['text':' We cannot use x[idx] here as it accesses item() (??), hence this awkward construction','line_number':3952,'multiline':False]['text':' Short-circuits if the tensor has no dimensions','line_number':3968,'multiline':False]['text':' Note: squeeze does not modify tensors when the given dim is not a dimension of length 1','line_number':3973,'multiline':False]['text':' Note: does not work with TensorMetas because of data-dependent control-flow','line_number':3986,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':3987,'multiline':False]['text':' If indices_or_sections is a tensor, it must be a CPU Long tensor','line_number':3998,'multiline':False]['text':' Case 0 -- indices_or_sections is an integer or a scalar tensor n and a is split along dim into n parts of equal-ish length','line_number':4010,'multiline':False]['text':' type: ignore[assignment]','line_number':4015,'multiline':False]['text':' Case 1 -- indices_or_sections is a sequence of integers or a 1D tensor describing the splits','line_number':4040,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':4060,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':4102,'multiline':False]['text':' as per the docs, exchanging dims is equivalent to changing the sign of','line_number':4234,'multiline':False]['text':' offset','line_number':4235,'multiline':False]['text':' convert from negative dims','line_number':4240,'multiline':False]['text':' as per the docs, the size of last dim is placed at dim1 and dim2','line_number':4249,'multiline':False]['text':' add padding to match the new size','line_number':4253,'multiline':False]['text':' make sure the diagonal always has the same size','line_number':4259,'multiline':False]['text':' preserve original data, but place 1 at dim1 and move last dim to dim2','line_number':4262,'multiline':False]['text':' generate ranges shifting indices based on offset','line_number':4265,'multiline':False]['text':' broadcast','line_number':4271,'multiline':False]['text':' aten.diag_embed always returns a new contiguous tensor','line_number':4276,'multiline':False]['text':' contiguous() is needed to correctly model the output stride','line_number':4277,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':4328,'multiline':False]['text':' TODO: Add sparse support','line_number':4344,'multiline':False]['text':' if a.is_sparse:','line_number':4345,'multiline':False]['text':'     sparse_dim = a.sparse_dim()','line_number':4346,'multiline':False]['text':'     dense_dim = a.dense_dim()','line_number':4347,'multiline':False]['text':'     if not (sparse_dim <= 2 and dense_dim == 0):','line_number':4348,'multiline':False]['text':'         raise RuntimeError(','line_number':4349,'multiline':False]['text':'             f"t() expects a tensor with <= 2 sparse and 0 dense dimensions, but got {sparse_dim} sparse and"','line_number':4350,'multiline':False]['text':'             f"{dense_dim} dense dimensions"','line_number':4351,'multiline':False]['text':'         )','line_number':4352,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':4360,'multiline':False]['text':' n != 2 && n != 0 is deprecated in regular PyTorch.','line_number':4362,'multiline':False]['text':' type: ignore[misc]','line_number':4380,'multiline':False]['text':' Aliases for transpose','line_number':4391,'multiline':False]['text':' We implement all the kwargs of a reduction. ATen just handles dtype','line_number':4422,'multiline':False]['text':' nb. This decomposition may not be as efficient as a backend-specific implementation','line_number':4423,'multiline':False]['text':' Note: although squeeze is documented as having the out= kwarg it doesn't','line_number':4459,'multiline':False]['text':' Note that unsqueeze canonicalizes with rank + 1 because it allows','line_number':4462,'multiline':False]['text':' a new innermost dimension to be specified','line_number':4463,'multiline':False]['text':' NOTE: shape is a vararg because Tensor.reshape can be called with as','line_number':4469,'multiline':False]['text':' Tensor.view(a, b, c) or Tensor.view((a, b, c)) Function call torch.view','line_number':4470,'multiline':False]['text':' doesn't support unpacked shapes','line_number':4471,'multiline':False]['text':' TODO: Turn this into a decomposition (currently fails on reshape meta tests)','line_number':4472,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':4478,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':4483,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':4488,'multiline':False]['text':' missing ref impl. for aten.gather','line_number':4489,'multiline':False]['text':' memory_format == torch.channels_last','line_number':4548,'multiline':False]['text':' memory_format == torch.preserve_format','line_number':4798,'multiline':False]['text':' identity perm is [2, 1, 0]','line_number':4802,'multiline':False]['text':' Case: torch.arange(5)','line_number':4835,'multiline':False]['text':' For int64 we truncate arguments to int before calculating length, but','line_number':4874,'multiline':False]['text':' other integral dtypes we don't. Weird... but needed to match ATen shapes.','line_number':4875,'multiline':False]['text':' Uses floordiv to avoid ceil in inductor.','line_number':4877,'multiline':False]['text':' type: ignore[arg-type]','line_number':4920,'multiline':False]['text':' mypy','line_number':4923,'multiline':False]['text':' We implement it this way for numerical stability. We assume (in the stability optimisation)','line_number':4924,'multiline':False]['text':' that 0 <= weight <= 1. We take the abs to deal with complex numbers','line_number':4925,'multiline':False]['text':' We want to perform operations near zero, which is where floating points are most precise','line_number':4926,'multiline':False]['text':' thus, we perform the following optimisation:','line_number':4927,'multiline':False]['text':' If weight.abs() >= 0.5:','line_number':4928,'multiline':False]['text':'    return (1 - weight) * (start - end) + end','line_number':4929,'multiline':False]['text':' make sure the decomposition output's stride is same as non-decomposition path.','line_number':4934,'multiline':False]['text':' steps does not participate in the computation of the dtype','line_number':4983,'multiline':False]['text':' for mypy','line_number':4989,'multiline':False]['text':' type: ignore[arg-type]','line_number':4999,'multiline':False]['text':' type: ignore[arg-type]','line_number':5002,'multiline':False]['text':' type: ignore[arg-type]','line_number':5004,'multiline':False]['text':' Perform in arange in int because some backends like ATen or Triton do not support all the dtypes','line_number':5006,'multiline':False]['text':' type: ignore[arg-type]','line_number':5007,'multiline':False]['text':' Small types need to be computed in higher precision as this is, at heart, an associative scan','line_number':5009,'multiline':False]['text':' We implement torch.lerp without performing rg / (steps - 1) explicitly','line_number':5020,'multiline':False]['text':' With this we get out[0] == start, out[-1] == end','line_number':5021,'multiline':False]['text':' type: ignore[arg-type,operator]','line_number':5025,'multiline':False]['text':' type: ignore[arg-type,operator]','line_number':5026,'multiline':False]['text':' type: ignore[return-value]','line_number':5028,'multiline':False]['text':' NB: NumPy doesn't have this cast','line_number':5048,'multiline':False]['text':' torch.linspace will update the correct dtype','line_number':5072,'multiline':False]['text':' for mypy','line_number':5076,'multiline':False]['text':' type: ignore[misc]','line_number':5079,'multiline':False]['text':' type: ignore[arg-type]','line_number':5080,'multiline':False]['text':' type: ignore[arg-type]','line_number':5081,'multiline':False]['text':' type: ignore[arg-type]','line_number':5082,'multiline':False]['text':' type: ignore[arg-type,return-value]','line_number':5089,'multiline':False]['text':' This ref simultaneously handles two overloads (see stubs above)','line_number':5107,'multiline':False]['text':' The `indexing` argument is currently optional for torch.meshgrid, but we','line_number':5108,'multiline':False]['text':' plan to make the argument required: https://github.com/pytorch/pytorch/issues/50276','line_number':5109,'multiline':False]['text':' type: ignore[union-attr]','line_number':5123,'multiline':False]['text':' type: ignore[union-attr]','line_number':5127,'multiline':False]['text':' mypy','line_number':5147,'multiline':False]['text':' mypy','line_number':5156,'multiline':False]['text':' Swap outputs if we originally swapped at the beginning','line_number':5162,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':5168,'multiline':False]['text':' Converts to list to produce a compatible error message with core PyTorch,','line_number':5182,'multiline':False]['text':' which prints sequences in square brackets.','line_number':5183,'multiline':False]['text':' type: ignore[arg-type]','line_number':5185,'multiline':False]['text':' type: ignore[arg-type]','line_number':5187,'multiline':False]['text':' type: ignore[arg-type]','line_number':5188,'multiline':False]['text':' type: ignore[arg-type]','line_number':5189,'multiline':False]['text':' type: ignore[arg-type]','line_number':5194,'multiline':False]['text':' type: ignore[arg-type]','line_number':5195,'multiline':False]['text':' See above on why this converts to list in error messages.','line_number':5200,'multiline':False]['text':' type: ignore[arg-type]','line_number':5203,'multiline':False]['text':' type: ignore[arg-type]','line_number':5207,'multiline':False]['text':' source index','line_number':5212,'multiline':False]['text':' check if the destination index is in the mapping','line_number':5214,'multiline':False]['text':' insert source index if found','line_number':5217,'multiline':False]['text':' insert source index sequentially, skipping indices from the mapping','line_number':5220,'multiline':False]['text':' NOTE: for convenience, shape can be a tuple of ints or a tuple containing a tuple of ints','line_number':5231,'multiline':False]['text':' Layout == strided, pin_memory is False','line_number':5244,'multiline':False]['text':' TODO: unused','line_number':5271,'multiline':False]['text':' TODO: Use requires_grad.  All refs taking the requires_grad kwarg must','line_number':5298,'multiline':False]['text':' return a leaf tensor.','line_number':5299,'multiline':False]['text':' result.requires_grad_(requires_grad)','line_number':5300,'multiline':False]['text':' type: ignore[arg-type]','line_number':5329,'multiline':False]['text':'','line_number':5445,'multiline':False]['text':' Randomness References','line_number':5446,'multiline':False]['text':'','line_number':5447,'multiline':False]['text':' NOTE: Could not use value = item(value) as it resulted in','line_number':5478,'multiline':False]['text':' RuntimeError: Cannot cast FakeTensor(cpu) to number','line_number':5479,'multiline':False]['text':' `masked_fill` allows cpu scalar to be moved to cuda and xpu but not otherwise.','line_number':5485,'multiline':False]['text':' only downcasting from complex to lower type is not allowed.','line_number':5494,'multiline':False]['text':' We allow casting `value` to lower type for other case','line_number':5495,'multiline':False]['text':' Eg. float -> int.','line_number':5496,'multiline':False]['text':' Ref: https://github.com/pytorch/pytorch/issues/79195','line_number':5497,'multiline':False]['text':' Since `where` allows type-promotion,','line_number':5503,'multiline':False]['text':' cast value to correct type before passing to `where`','line_number':5504,'multiline':False]['text':' type: ignore[arg-type]','line_number':5506,'multiline':False]['text':' aten.mask_fill always return a new contiguous tensor','line_number':5508,'multiline':False]['text':' contiguous() is needed to correctly model the output stride','line_number':5509,'multiline':False]['text':' type: ignore[arg-type]','line_number':5517,'multiline':False]['text':' CompositeImplicitAutograd - don't register decomp','line_number':5522,'multiline':False]['text':' Shape check','line_number':5544,'multiline':False]['text':' Short-circuits if there are no elements to validate','line_number':5552,'multiline':False]['text':' type: ignore[return-value]','line_number':5556,'multiline':False]['text':' In these cases we compute the "Frobenius norm"','line_number':5569,'multiline':False]['text':' Here we either call the nuclear norm, or we call matrix_norm with some arguments','line_number':5577,'multiline':False]['text':' that will throw an error','line_number':5578,'multiline':False]['text':' aten.triu always returns a new contiguous tensor','line_number':5622,'multiline':False]['text':' contiguous() is needed to correctly model the output stride','line_number':5623,'multiline':False]['text':' aten.tril always returns a new contiguous tensor','line_number':5639,'multiline':False]['text':' contiguous() is needed to correctly model the output stride','line_number':5640,'multiline':False]['text':' This is based on get_tril_size in aten/src/ATen/native/TensorFactories.h','line_number':5644,'multiline':False]['text':' The components of the matrix that belong to the lower triangle with offset','line_number':5645,'multiline':False]['text':' form a pentagon that can be broken down into a top trapezoid and a bottom','line_number':5646,'multiline':False]['text':' rectangle. For the implementation of tril_indices, we need the sizes of','line_number':5647,'multiline':False]['text':' both of these, as well as the length of the top side of the trapezoid.','line_number':5648,'multiline':False]['text':' Number of elements in top trapezoid','line_number':5658,'multiline':False]['text':' Number of elements in bottom rectangle','line_number':5660,'multiline':False]['text':' This is based on tril_indices_cuda in aten/src/ATen/native/cuda/TensorFactories.cu','line_number':5683,'multiline':False]['text':' first we do the indices for top trapezoid','line_number':5705,'multiline':False]['text':' then bottom rectangle','line_number':5713,'multiline':False]['text':' Similar to _get_tril_sizes above, but here there is a top trapezoid and','line_number':5723,'multiline':False]['text':' a bottom rectangle instead. Note that you can't reduce this to','line_number':5724,'multiline':False]['text':' _get_tril_sizes(col, row, -offset) because that would correspond to','line_number':5725,'multiline':False]['text':' decomposing into a left trapezoid and right rectangle.','line_number':5726,'multiline':False]['text':' Number of elements in top rectangle','line_number':5733,'multiline':False]['text':' Number of elements in bottom trapezoid','line_number':5736,'multiline':False]['text':' indices for top rectangle','line_number':5765,'multiline':False]['text':' bottom trapezoid','line_number':5770,'multiline':False]['text':' We are trying to find the bucket (defined by pairs of consecutive elements of `boundaries`)','line_number':5805,'multiline':False]['text':' each element of `a` belongs to. We use binary search to achieve logarithimic complexity,','line_number':5806,'multiline':False]['text':' but each step of the search is done "in parallel" over all elements of `a`','line_number':5807,'multiline':False]['text':' can't use int32 as indexes, so we have to do all computations with int64 and convert at the end','line_number':5808,'multiline':False]['text':' Max depth of the binary search','line_number':5811,'multiline':False]['text':' Since we can't break out of the loop at different points for different elements of a,','line_number':5812,'multiline':False]['text':' we just do the max amount of iterations that binary search requires and add condition','line_number':5813,'multiline':False]['text':' tensor (cond_update below) to stop updating once the search terminates','line_number':5814,'multiline':False]['text':' For first iteration through loop we can skip some checks, we have separate implementation','line_number':5816,'multiline':False]['text':' start might end up pointing to 1 past the end, we guard against that','line_number':5831,'multiline':False]['text':' If right is true, the buckets are closed on the *left*','line_number':5834,'multiline':False]['text':' (i.e., we are doing the equivalent of std::upper_bound in C++)','line_number':5835,'multiline':False]['text':' Otherwise they are closed on the right (std::lower_bound)','line_number':5836,'multiline':False]['text':' TODO: fix inductor rand_like for integer, bool dtypes','line_number':5898,'multiline':False]['text':' TODO: add support for functionalization aten.normal_functional','line_number':5932,'multiline':False]['text':' NOTE: the device and dtype will be ignored when shape is None','line_number':5933,'multiline':False]['text':' The decomposition fails if you do self.conj()... not sure why','line_number':6080,'multiline':False]['text':' inplace','line_number':6084,'multiline':False]['text':' xref: isStorage in torch/csrc/DynamicTypes.cpp','line_number':6182,'multiline':False]['text':' xref: compute_sizes in torch/csrc/utils/tensor_new.cpp','line_number':6187,'multiline':False]['text':' TODO: this is inaccurate, we actually test PySequence_Check','line_number':6192,'multiline':False]['text':' noqa: TRY200','line_number':6205,'multiline':False]['text':' xref: infer_scalar_type in torch/csrc/utils/tensor_new.cpp','line_number':6213,'multiline':False]['text':' careful!','line_number':6217,'multiline':False]['text':' TODO: this is inaccurate, we actually test PySequence_Check','line_number':6233,'multiline':False]['text':' match NumPy semantics, except use default tensor type instead of','line_number':6237,'multiline':False]['text':' double.','line_number':6238,'multiline':False]['text':' TODO: test this','line_number':6243,'multiline':False]['text':' recurse!','line_number':6248,'multiline':False]['text':' this won't change (unless we hit undefined, but that will','line_number':6254,'multiline':False]['text':' fail later)','line_number':6255,'multiline':False]['text':' Analogous to recursive_store','line_number':6261,'multiline':False]['text':' xref: recursive_store in torch/csrc/utils/tensor_new.cpp','line_number':6262,'multiline':False]['text':' xref: internal_new_from_data in torch/csrc/utils/tensor_new.cpp','line_number':6280,'multiline':False]['text':' TODO','line_number':6307,'multiline':False]['text':' TODO: test for numpy input with PyArray_Check','line_number':6311,'multiline':False]['text':' NB: Don't need to avoid tracing, as we aren't going to do any manual','line_number':6317,'multiline':False]['text':' pointer filling tricks','line_number':6318,'multiline':False]['text':' In the C implementation, we would directly start poking the memory','line_number':6325,'multiline':False]['text':' of a freshly allocated CPU tensor.  Here, we're going to do an','line_number':6326,'multiline':False]['text':' alternate, heinously slow implementation: turn each individual','line_number':6327,'multiline':False]['text':' scalar into a tensor, and then repeatedly cat them together','line_number':6328,'multiline':False]['text':' NB: lift_fresh is not needed, because we built the tensor from scalars','line_number':6333,'multiline':False]['text':' guaranteeing a fresh tensor in this case','line_number':6334,'multiline':False]['text':' xref: tensor_ctor in torch/csrc/utils/tensor_new.cpp','line_number':6338,'multiline':False]['text':' TODO (or not): support names kwarg','line_number':6340,'multiline':False]['text':' device="cpu" because that's what you get with torch.tensor(2) no','line_number':6348,'multiline':False]['text':' device by default','line_number':6349,'multiline':False]['text':' TODO: use torch.get_default_tensor_type','line_number':6350,'multiline':False]['text':' Views','line_number':6364,'multiline':False]['text':' We can't model these as above, as the pattern of doing `op(a, out=a)` does not work for a view function','line_number':6365,'multiline':False]['text':' given that it does not reshape the input (it just copies the result into it)','line_number':6366,'multiline':False]['text':' squeeze_ = _make_inplace(squeeze)','line_number':6368,'multiline':False]['text':' t_ = _make_inplace(t)','line_number':6369,'multiline':False]['text':' transpose_ = _make_inplace(transpose)','line_number':6370,'multiline':False]['text':' unsqueeze_ = _make_inplace(unsqueeze)','line_number':6371,'multiline':False]