['text':' Used for testing the HigherOrderOperator mechanism','line_number':13,'multiline':False]['text':' Dynamo already traces the body of HigherOrderOp beforehand when it','line_number':19,'multiline':False]['text':' so no need to trace into it.','line_number':20,'multiline':False]['text':' noqa: F401','line_number':21,'multiline':False]['text':' use_reentrant is set to False because this op is going to be traced.','line_number':54,'multiline':False]['text':' And we ensure that AOT Autograd traces through the non reentrant','line_number':55,'multiline':False]['text':' version of checkpointing.','line_number':56,'multiline':False]['text':' Using interpreter allows preservation of metadata through torch.compile stack.','line_number':61,'multiline':False]['text':' `preserve_rng_state` is not a regular kwarg','line_number':115,'multiline':False]['text':' use_reentrant is set to False because this op is going to be traced.','line_number':139,'multiline':False]['text':' And we ensure that AOT Autograd traces through the non reentrant','line_number':140,'multiline':False]['text':' version of checkpointing.','line_number':141,'multiline':False]['text':' preserve_rng_state is set to False because we want to prevent AOTAutograd from tracing through','line_number':143,'multiline':False]['text':' `torch.random.fork_rng` op (which is not supported yet under CUDA).','line_number':144,'multiline':False]['text':' This doesn't mean that we don't preserve RNG state. Instead, we will always preserve RNG state','line_number':145,'multiline':False]['text':' regardless of this flag (by doing RNG functionalization via `replace_random_passes` in Inductor','line_number':146,'multiline':False]['text':' instead of in AOTAutograd).','line_number':147,'multiline':False]['text':' We first tag all nodes as "recompute" in this graph, and then we undo the "recompute" tag','line_number':150,'multiline':False]['text':' for specific nodes in _CachingTorchDispatchMode in torch/utils/checkpoint.py.','line_number':151,'multiline':False]['text':' Using interpreter allows preservation of metadata through torch.compile stack.','line_number':153,'multiline':False]['text':' Using interpreter allows preservation of metadata through torch.compile stack.','line_number':158,'multiline':False]['text':' TODO: We want to use the same `checkpoint(Interpreter(gmod).run, *args, **kwargs)` here','line_number':159,'multiline':False]['text':' as the `context_fn != None` case, but that depends on in-place op support in TorchDispatchMode + torch.compile.','line_number':160,'multiline':False]['text':' (for details on in-place op issue, run `test_compile_selective_checkpoint_inplace_op` unit test)','line_number':161,'multiline':False]