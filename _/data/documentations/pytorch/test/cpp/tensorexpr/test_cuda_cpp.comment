['text':' TODO: move gpu support into PaddedBuffer','line_number':66,'multiline':False]['text':' TODO: move gpu support into PaddedBuffer','line_number':132,'multiline':False]['text':' floating types.','line_number':157,'multiline':False]['text':' integer types.','line_number':162,'multiline':False]['text':' TODO: move gpu support into PaddedBuffer','line_number':196,'multiline':False]['text':' TODO: move gpu support into PaddedBuffer','line_number':354,'multiline':False]['text':' The test adds the following code for trivial reduction:','line_number':443,'multiline':False]['text':' for (const auto bidx : c10::irange(1)) { // blockIdx.x','line_number':444,'multiline':False]['text':'   for (const auto tidx : c10::irange(1)) { // threadIdx.x','line_number':445,'multiline':False]['text':'     output[0] = 0.f;','line_number':446,'multiline':False]['text':'     for (const auto i1 : c10::irange(1024)) {','line_number':447,'multiline':False]['text':'       output[0] = output[0] + data[i1];','line_number':448,'multiline':False]['text':'     }','line_number':449,'multiline':False]['text':'   }','line_number':450,'multiline':False]['text':' }','line_number':451,'multiline':False]['text':' This test does the following reduction:','line_number':507,'multiline':False]['text':' clang-format off','line_number':508,'multiline':False]['text':'   for b in 0..1 // block-idx','line_number':509,'multiline':False]['text':'    for t in 0..1024: // thread-idx','line_number':510,'multiline':False]['text':'      if t < 1:','line_number':511,'multiline':False]['text':'        b[0] = 0','line_number':512,'multiline':False]['text':'    // implied sync_threads','line_number':513,'multiline':False]['text':'    for t in 0..1024: // thread-idx','line_number':514,'multiline':False]['text':'      b[0] = b[0] + a[t] // implied atomic','line_number':515,'multiline':False]['text':' clang-format on','line_number':516,'multiline':False]['text':'  for t in 0..1024: // thread-idx','line_number':525,'multiline':False]['text':'    if t < 1:','line_number':526,'multiline':False]['text':'      b[0] = 0','line_number':527,'multiline':False]['text':'  for t in 0..1024: // thread-idx','line_number':535,'multiline':False]['text':'    b[0] = b[0] + a[t] // implied atomic','line_number':536,'multiline':False]['text':' This test does the following reduction:','line_number':584,'multiline':False]['text':'','line_number':585,'multiline':False]['text':' for k in 0..1: // block-idx','line_number':586,'multiline':False]['text':'   a[0] = 0','line_number':587,'multiline':False]['text':'   for n in 0..2:','line_number':588,'multiline':False]['text':'     a[0] = a[0] + n','line_number':589,'multiline':False]['text':'   for m in 0..1024: // thread-idx','line_number':590,'multiline':False]['text':'     b[m] = m','line_number':591,'multiline':False]['text':'   a[1] = 1','line_number':592,'multiline':False]['text':'   for l in 0..2:','line_number':593,'multiline':False]['text':'     a[1] = a[1] + n','line_number':594,'multiline':False]['text':'','line_number':595,'multiline':False]['text':'  note that the statements not covered by thread-idx are supposed to be','line_number':596,'multiline':False]['text':'  covered by its own thread-idx','line_number':597,'multiline':False]['text':'   a[0] = 0','line_number':608,'multiline':False]['text':'   for n in 0..2:','line_number':609,'multiline':False]['text':'     a[0] = a[0] + n','line_number':610,'multiline':False]['text':'   for m in 0..1024: // thread-idx','line_number':617,'multiline':False]['text':'     b[m] = m','line_number':618,'multiline':False]['text':'   a[1] = 1','line_number':624,'multiline':False]['text':'   for l in 0..2:','line_number':625,'multiline':False]['text':'     a[1] = a[1] + l','line_number':626,'multiline':False]['text':' TODO: add check of the generated code.','line_number':657,'multiline':False]['text':' FIXME: this test is flaky in CI.','line_number':681,'multiline':False]['text':' This test does the following:','line_number':682,'multiline':False]['text':'  for k in 0..1:  // block-idx','line_number':683,'multiline':False]['text':'    alloc(c, 64)','line_number':684,'multiline':False]['text':'    for n in 0..64:  // thread-idx','line_number':685,'multiline':False]['text':'      c(n) = 0','line_number':686,'multiline':False]['text':'    for m in 0..128:','line_number':687,'multiline':False]['text':'      for n in 0..64:  // thread_idx','line_number':688,'multiline':False]['text':'        c(n) = c(n) + a(k, m, n)','line_number':689,'multiline':False]['text':'    b(k) = 0','line_number':690,'multiline':False]['text':'    for n in 0..64:  // thread_idx','line_number':691,'multiline':False]['text':'      b(k) = b(k) + c(n)','line_number':692,'multiline':False]['text':'    free(c)','line_number':693,'multiline':False]['text':' alloc(c, 64);','line_number':714,'multiline':False]['text':'    for n in 0..64:  // thread-idx','line_number':720,'multiline':False]['text':'      c(n) = 0','line_number':721,'multiline':False]['text':'  for m in 0..128:','line_number':728,'multiline':False]['text':'    for n in 0..64:  // thread_idx','line_number':729,'multiline':False]['text':'      c(n) = c(n) + a(k, m, n)','line_number':730,'multiline':False]['text':'    b(k) = 0','line_number':741,'multiline':False]['text':'    for n in 0..64:  // thread_idx','line_number':742,'multiline':False]['text':'      b(k) = b(k) + c(n)','line_number':743,'multiline':False]['text':'    free(c)','line_number':755,'multiline':False]['text':' TODO: check the generated code for correctness.','line_number':763,'multiline':False]['text':' Check the c write is not masked, but the d write is.','line_number':769,'multiline':False]['text':' This test does the following:','line_number':819,'multiline':False]['text':'  for k in 0..1:  // block-idx','line_number':820,'multiline':False]['text':'    b(k) = 0','line_number':821,'multiline':False]['text':'    for n in 0..64:  // thread-idx','line_number':822,'multiline':False]['text':'      alloc(c, 1)','line_number':823,'multiline':False]['text':'      c(0) = 0','line_number':824,'multiline':False]['text':'      for m in 0..128:','line_number':825,'multiline':False]['text':'        c(0) = c(0) + a(k, m, n)','line_number':826,'multiline':False]['text':'      b(k) = b(k) + c(0)','line_number':827,'multiline':False]['text':'      free(c)','line_number':828,'multiline':False]['text':'    b(k) = 0','line_number':848,'multiline':False]['text':' alloc(c, 1);','line_number':854,'multiline':False]['text':' c(0) = 0','line_number':859,'multiline':False]['text':'      for m in 0..128:','line_number':864,'multiline':False]['text':'        c(0) = c(0) + a(k, m, n)','line_number':865,'multiline':False]['text':'      b(k) = b(k) + c(0)','line_number':874,'multiline':False]['text':'      free(c)','line_number':882,'multiline':False]['text':' Check the types used by the Max are Float.','line_number':1001,'multiline':False]['text':' Check the types used by the Max are Float.','line_number':1052,'multiline':False]['text':' Sanity Cbeck;','line_number':1062,'multiline':False]['text':'
   * for (const auto i : c10::irange(12)) {
   *   c[i] = (i < 10 ? a[i] + b[i] : b[i]);
   * }
   ','line_number':1105,'multiline':True]['text':'/ Tests the case where there are two loops which have different extents bound','line_number':1168,'multiline':False]['text':'/ to the same block dimension. We must mask the smaller extent loop body.','line_number':1169,'multiline':False]['text':' Check the c write is not masked, but the d write is.','line_number':1194,'multiline':False]['text':' Sanity check that the kernel works.','line_number':1209,'multiline':False]['text':'/ Tests the case with two loops, which have different extents that are bound','line_number':1264,'multiline':False]['text':'/ to the same thread dimension. This is the same as the above - the smaller','line_number':1265,'multiline':False]['text':'/ rank write should be masked. But this time we also need to syncthreads.','line_number':1266,'multiline':False]['text':' Check the c write is masked, but the d write is not.','line_number':1291,'multiline':False]['text':'/ Tests the case where there are two loops, and each is bound to a different','line_number':1361,'multiline':False]['text':'/ block dimension. In this case all writes should be masked since they occur','line_number':1362,'multiline':False]['text':'/ in distinct dimensions.','line_number':1363,'multiline':False]['text':' Note: this is an extremely dumb pattern which we should never see, but is a','line_number':1364,'multiline':False]['text':' useful edge case to make sure we've got things covered.','line_number':1365,'multiline':False]['text':' Write to c should be masked against y, write to d against x.','line_number':1390,'multiline':False]['text':'/ Tests the case where both the blockDim and threadDim are bound to different','line_number':1459,'multiline':False]['text':'/ loops. In this instance both stores should be masked since they are','line_number':1460,'multiline':False]['text':'/ distinct.','line_number':1461,'multiline':False]['text':' Note: this is an extremely dumb pattern which we should never see, but is a','line_number':1462,'multiline':False]['text':' useful edge case to make sure we've got things covered.','line_number':1463,'multiline':False]['text':'/ Tests the case where the loopnest has two loops of depth two: each with the','line_number':1557,'multiline':False]['text':'/ outer loop bound to blockDim.x and the inner loop bound to threadDim.x. In','line_number':1558,'multiline':False]['text':'/ this case all writes with a rank smaller than the max should be masked.','line_number':1559,'multiline':False]['text':' The write to D should be masked, but not the write to C.','line_number':1590,'multiline':False]['text':' Tests the case where loop extents are symbolic and not known at compile time.','line_number':1682,'multiline':False]['text':' In this case both stores must be masked against the extent of the other loop,','line_number':1683,'multiline':False]['text':' incase it is larger.','line_number':1684,'multiline':False]['text':' Since we don't know which is bigger (A_SIZE or B_SIZE) we must mask both.','line_number':1715,'multiline':False]['text':' Tests the case where two loops are fused at a common parent loop, which is','line_number':1812,'multiline':False]['text':' bound to the block dimension. Internally the inner loops have different','line_number':1813,'multiline':False]['text':' extents but are bound to the same thread dimension. The smaller loop should','line_number':1814,'multiline':False]['text':' be masked.','line_number':1815,'multiline':False]['text':' Can't build this using Compute and transforms yet.','line_number':1825,'multiline':False]['text':' The write to D should be masked, but not the write to C.','line_number':1861,'multiline':False]['text':' Tests the case with two loops fused into a common parent, which is not bound','line_number':1950,'multiline':False]['text':' to any block or thread dimension - however it's two inner loops are bound to','line_number':1951,'multiline':False]['text':' the first thread dimensions. This should work just like the MaskThreadDim','line_number':1952,'multiline':False]['text':' test where the bigger loop is unmasked but the smaller is masked.','line_number':1953,'multiline':False]['text':' Can't build this using Compute and transforms yet.','line_number':1963,'multiline':False]['text':' The other loop remains the D write is masked.','line_number':1998,'multiline':False]['text':' Tests the case with two loop nests, each of which bound to the same block','line_number':2088,'multiline':False]['text':' size, but with internal loops bound to different thread rank (ie x and y). In','line_number':2089,'multiline':False]['text':' this case both bodies must be masked against the other dimension being > 0.','line_number':2090,'multiline':False]['text':' Note: this is a bit degenerate no one would actually write this for perf.','line_number':2091,'multiline':False]['text':' Both stores masked against the other thread dim < 1.','line_number':2122,'multiline':False]['text':' Tests the case with two loop nests, each bound to both Block and Thread but','line_number':2214,'multiline':False]['text':' the second loop is smaller in both cases - the second store must be masked','line_number':2215,'multiline':False]['text':' for both the block and thread dimension.','line_number':2216,'multiline':False]['text':' The write to D should be masked twice, but not the write to C.','line_number':2248,'multiline':False]['text':' namespace jit','line_number':2341,'multiline':False]['text':' namespace torch','line_number':2342,'multiline':False]