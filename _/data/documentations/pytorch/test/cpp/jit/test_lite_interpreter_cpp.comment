['text':' Tests go in torch::jit','line_number':26,'multiline':False]['text':' NOLINT (use =delete in gtest)','line_number':72,'multiline':False]['text':' test invoking a method with default parameter','line_number':74,'multiline':False]['text':' inner method call with default parameter (gets inlined)','line_number':79,'multiline':False]['text':' simple method call','line_number':86,'multiline':False]['text':' (keep linter happy)','line_number':98,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-magic-numbers,modernize-use-emplace)','line_number':132,'multiline':False]['text':' std::cout << output_m.toStringRef() << "\n"','line_number':202,'multiline':False]['text':'           << output_bc.toStringRef() << std::endl;','line_number':203,'multiline':False]['text':'
  // temporarily disabled
  script::Module m("m");
  m.define(R"JIT(
  def forward(self, x):
      result = [1, 2]
      result.append(3)
      return result
  )JIT");
  std::stringstream ss;
  m._save_for_mobile(ss);
  mobile::Module bc = _load_for_mobile(ss);
  std::vector<torch::jit::IValue> inputs({torch::ones({})});
  auto output = bc.get_method("forward")(inputs);
  AT_ASSERT(output.toIntList()[2] == 3);
  ','line_number':263,'multiline':True]['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':298,'multiline':False]['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':325,'multiline':False]['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':393,'multiline':False]['text':' Check to see if it is a custom class.','line_number':426,'multiline':False]['text':' If it's not a custom class, assume it's another namespace','line_number':431,'multiline':False]['text':' NOLINTNEXTLINE(performance-move-const-arg)','line_number':432,'multiline':False]['text':' namespace','line_number':463,'multiline':False]['text':' NOLINTNEXTLINE(performance-unnecessary-copy-initialization)','line_number':512,'multiline':False]['text':'*
 * The test below is disarmed for FB internal xplat builds since
 * BUCK requires us to pass in the script_module_v4.ptl file in
 * as a resource dependency of the build rule for this file, and
 * we would need to access it via the C++ Resources API instead
 * of directly reading from disk (which is what the open source
 * build/run does).
 ','line_number':535,'multiline':True]['text':' !defined(FB_XPLAT_BUILD)','line_number':553,'multiline':False]['text':' Load and run the backport model, then compare the result with expect','line_number':604,'multiline':False]['text':' result','line_number':605,'multiline':False]['text':' Load and run the backport model, then compare the result with expect','line_number':621,'multiline':False]['text':' result','line_number':622,'multiline':False]['text':' Backport script_module_v5.ptl to an older version','line_number':640,'multiline':False]['text':' Verify all candidate to_version work as expected. All backport to version','line_number':644,'multiline':False]['text':' larger than minimum_to_version should success.','line_number':645,'multiline':False]['text':' Do not declare std::stringstream oss outside of the while loop as','line_number':647,'multiline':False]['text':' oss.clear() doesn't reset the stream content, only clears out error state','line_number':648,'multiline':False]['text':' flag in stringstream causing a problematic stream. Instead, it's cleaner','line_number':649,'multiline':False]['text':' and safer to just declare a new std::stringstream one and swap them.','line_number':650,'multiline':False]['text':' Check backport model version','line_number':656,'multiline':False]['text':' Load and run the backport model, then compare the result with expect','line_number':661,'multiline':False]['text':' result','line_number':662,'multiline':False]['text':'  backport to minimum version - 1 should fail','line_number':671,'multiline':False]['text':' namespace','line_number':677,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-magic-numbers)','line_number':682,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-magic-numbers)','line_number':684,'multiline':False]['text':'extra_files=','line_number':721,'multiline':True]['text':'save_mobile_debug_info=','line_number':722,'multiline':True]['text':'use_flatbuffer=','line_number':723,'multiline':True]['text':' "cpu" False, False, True, tensor(1), "abc", 2, False)','line_number':732,'multiline':False]['text':' flatbuffer starts at 9','line_number':746,'multiline':False]['text':' !defined(FB_XPLAT_BUILD)','line_number':748,'multiline':False]['text':' Ballpark estimate of the minimal number of ops; just used to','line_number':752,'multiline':False]['text':' verify API returns a reasonably large number.','line_number':753,'multiline':False]['text':' test trivial success case','line_number':758,'multiline':False]['text':' test trivial failure due to ops','line_number':776,'multiline':False]['text':' test trivial failure due to bytecode greater than max supported bytecode','line_number':796,'multiline':False]['text':' version','line_number':797,'multiline':False]['text':' test trivial failure due to bytecode less than min supported bytecode','line_number':811,'multiline':False]['text':' version','line_number':812,'multiline':False]['text':' test trivial failure due to type','line_number':826,'multiline':False]['text':' test trivial failure due to operator version','line_number':840,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-magic-numbers,modernize-use-emplace)','line_number':863,'multiline':False]['text':' save m in training mode to make sure that mobile eval() will correctly','line_number':868,'multiline':False]['text':' change back to eval mode','line_number':869,'multiline':False]['text':' A simple example to show a simple bytecode that can be used independent of','line_number':1094,'multiline':False]['text':' PyTorch TorchScript serialization (unpickler, etc) and operator library.','line_number':1095,'multiline':False]['text':' It has basic control flow (if, else) and basic data orchestration (list','line_number':1096,'multiline':False]['text':' construction). The original PyTorch program:','line_number':1097,'multiline':False]['text':'  class Module(torch.nn.Module):','line_number':1099,'multiline':False]['text':'','line_number':1100,'multiline':False]['text':'    def __init__(self):','line_number':1101,'multiline':False]['text':'      super().__init__()','line_number':1102,'multiline':False]['text':'','line_number':1103,'multiline':False]['text':'    def forward(self, x: int, h: int, xfirst: bool):','line_number':1104,'multiline':False]['text':'      if xfirst:','line_number':1105,'multiline':False]['text':'        return [x, h]','line_number':1106,'multiline':False]['text':'      else:','line_number':1107,'multiline':False]['text':'        return [h, x]','line_number':1108,'multiline':False]['text':' 1. Prepare for the bytecode. In reality it can be from a customized','line_number':1110,'multiline':False]['text':' deserializer.','line_number':1111,'multiline':False]['text':' empty for this example','line_number':1130,'multiline':False]['text':' empty for this example','line_number':1131,'multiline':False]['text':' 2. Parse the function','line_number':1134,'multiline':False]['text':' 3. Prepare for inputs and run the function','line_number':1148,'multiline':False]['text':' Note that the first input is reserved for Module object.','line_number':1149,'multiline':False]['text':' Since this is a function test and Module object is not required,','line_number':1150,'multiline':False]['text':' a dummy IValue (0) is added here.','line_number':1151,'multiline':False]['text':' A simple example to show a simple bytecode that can be used independent of','line_number':1166,'multiline':False]['text':' PyTorch TorchScript serialization (unpickler, etc) and operator library.','line_number':1167,'multiline':False]['text':' It has one operator and we should be able to register it. The original','line_number':1168,'multiline':False]['text':' PyTorch program:','line_number':1169,'multiline':False]['text':' class Add(torch.nn.Module):','line_number':1171,'multiline':False]['text':'     def __init__(self):','line_number':1172,'multiline':False]['text':'         super().__init__()','line_number':1173,'multiline':False]['text':'     def forward(self, a, b):','line_number':1175,'multiline':False]['text':'         return a + b','line_number':1176,'multiline':False]['text':' 1. Prepare for the bytecode. In reality it can be from a customized','line_number':1178,'multiline':False]['text':' deserializer.','line_number':1179,'multiline':False]['text':' 2. Parse the function','line_number':1194,'multiline':False]['text':' 3. Prepare for inputs and run the function','line_number':1211,'multiline':False]['text':' Note that the first input is reserved for Module object.','line_number':1212,'multiline':False]['text':' Since this is a function test and Module object is not required,','line_number':1213,'multiline':False]['text':' a dummy IValue (0) is added here.','line_number':1214,'multiline':False]['text':' a more stable matrix','line_number':1262,'multiline':False]['text':' namespace','line_number':1267,'multiline':False]['text':' Test with different number of specified arguments.','line_number':1271,'multiline':False]['text':' Arguments not specified take default value.','line_number':1272,'multiline':False]['text':'  bytecode with one specified argument:','line_number':1277,'multiline':False]['text':'  (6,','line_number':1278,'multiline':False]['text':'      ('__torch__.m.forward',','line_number':1279,'multiline':False]['text':'          (('instructions',','line_number':1280,'multiline':False]['text':'              (('STOREN', 1, 2),','line_number':1281,'multiline':False]['text':'                  ('DROPR', 1, 0),','line_number':1282,'multiline':False]['text':'                  ('MOVE', 2, 0),','line_number':1283,'multiline':False]['text':'                  ('OP', 0, 0),','line_number':1284,'multiline':False]['text':'                  ('RET', 0, 0))),','line_number':1285,'multiline':False]['text':'              ('operators', (('aten::linalg_pinv', '', 1),)),','line_number':1286,'multiline':False]['text':'              ('constants', (False, 1e-15)), # default constants are not','line_number':1287,'multiline':False]['text':'              used','line_number':1288,'multiline':False]['text':'              ('types', ()),','line_number':1289,'multiline':False]['text':'              ('register_size', 2)),','line_number':1290,'multiline':False]['text':'          (('arguments',','line_number':1291,'multiline':False]['text':'              ((('name', 'self'), ('type', '__torch__.m'), ('default_value',','line_number':1292,'multiline':False]['text':'              None)),','line_number':1293,'multiline':False]['text':'                  (('name', 'input'), ('type', 'Tensor'), ('default_value',','line_number':1294,'multiline':False]['text':'                  None)))),','line_number':1295,'multiline':False]['text':'              ('returns',','line_number':1296,'multiline':False]['text':'                  ((('name', ''), ('type', 'Tensor'), ('default_value',','line_number':1297,'multiline':False]['text':'                  None)),)))))','line_number':1298,'multiline':False]['text':'  bytecode with 2 specified argument:','line_number':1300,'multiline':False]['text':'  (6,','line_number':1301,'multiline':False]['text':'      ('__torch__.m.forward',','line_number':1302,'multiline':False]['text':'          (('instructions',','line_number':1303,'multiline':False]['text':'              (('STOREN', 1, 2),','line_number':1304,'multiline':False]['text':'                  ('DROPR', 1, 0),','line_number':1305,'multiline':False]['text':'                  ('MOVE', 2, 0),','line_number':1306,'multiline':False]['text':'                  ('LOADC', 1, 0), # added LOADC for specified argument','line_number':1307,'multiline':False]['text':'                  ('OP', 0, 0),','line_number':1308,'multiline':False]['text':'                  ('RET', 0, 0))),','line_number':1309,'multiline':False]['text':'              ('operators', (('aten::linalg_pinv', '', 2),)),','line_number':1310,'multiline':False]['text':'              ('constants', (False, 1e-05)), # updated constant table','line_number':1311,'multiline':False]['text':'              ('types', ()),','line_number':1312,'multiline':False]['text':'              ('register_size', 2)),','line_number':1313,'multiline':False]['text':'          (('arguments',','line_number':1314,'multiline':False]['text':'              ((('name', 'self'), ('type', '__torch__.m'), ('default_value',','line_number':1315,'multiline':False]['text':'              None)),','line_number':1316,'multiline':False]['text':'                  (('name', 'input'), ('type', 'Tensor'), ('default_value',','line_number':1317,'multiline':False]['text':'                  None)))),','line_number':1318,'multiline':False]['text':'              ('returns',','line_number':1319,'multiline':False]['text':'                  ((('name', ''), ('type', 'Tensor'), ('default_value',','line_number':1320,'multiline':False]['text':'                  None)),)))))','line_number':1321,'multiline':False]['text':'  bytecode with 3 specified arguments:','line_number':1323,'multiline':False]['text':'  (6,','line_number':1324,'multiline':False]['text':'      ('__torch__.m.forward',','line_number':1325,'multiline':False]['text':'          (('instructions',','line_number':1326,'multiline':False]['text':'              (('STOREN', 1, 2),','line_number':1327,'multiline':False]['text':'                  ('DROPR', 1, 0),','line_number':1328,'multiline':False]['text':'                  ('MOVE', 2, 0),','line_number':1329,'multiline':False]['text':'                  ('LOADC', 1, 0),','line_number':1330,'multiline':False]['text':'                  ('LOADC', 0, 0),','line_number':1331,'multiline':False]['text':'                  ('OP', 0, 0),','line_number':1332,'multiline':False]['text':'                  ('RET', 0, 0))),','line_number':1333,'multiline':False]['text':'              ('operators', (('aten::linalg_pinv', '', 3),)),','line_number':1334,'multiline':False]['text':'              ('constants', (True, 1e-05)),','line_number':1335,'multiline':False]['text':'              ('types', ()),','line_number':1336,'multiline':False]['text':'              ('register_size', 2)),','line_number':1337,'multiline':False]['text':'          (('arguments',','line_number':1338,'multiline':False]['text':'              ((('name', 'self'), ('type', '__torch__.m'), ('default_value',','line_number':1339,'multiline':False]['text':'              None)),','line_number':1340,'multiline':False]['text':'                  (('name', 'input'), ('type', 'Tensor'), ('default_value',','line_number':1341,'multiline':False]['text':'                  None)))),','line_number':1342,'multiline':False]['text':'              ('returns',','line_number':1343,'multiline':False]['text':'                  ((('name', ''), ('type', 'Tensor'), ('default_value',','line_number':1344,'multiline':False]['text':'                  None)),)))))','line_number':1345,'multiline':False]['text':' The second argument is specified, but the value is the same as the default','line_number':1349,'multiline':False]['text':' value. It's treated as "not specified" since the value can be fetched from','line_number':1350,'multiline':False]['text':' schema.','line_number':1351,'multiline':False]['text':' a more stable matrix','line_number':1389,'multiline':False]['text':' Test with different number of specified arguments + out arg.','line_number':1397,'multiline':False]['text':' Arguments not specified take default value.','line_number':1398,'multiline':False]['text':' !defined(FB_XPLAT_BUILD)','line_number':1479,'multiline':False]['text':' __getattr__','line_number':1489,'multiline':False]['text':' __setattr__','line_number':1492,'multiline':False]['text':' namespace','line_number':1497,'multiline':False]['text':' Create 3 methods:','line_number':1500,'multiline':False]['text':'','line_number':1501,'multiline':False]['text':' 1. forward() returns a tensor with dtype=torch.int64 (4)','line_number':1502,'multiline':False]['text':' 2. forward2() returns a tensor with dtype=torch.float32 (6)','line_number':1503,'multiline':False]['text':' 3. forward3() returns a tensor with dtype=torch.float32 but','line_number':1504,'multiline':False]['text':'    the dtype is inferred by the input tensor's dtype','line_number':1505,'multiline':False]['text':'','line_number':1506,'multiline':False]['text':' If caching works correctly, then the result from the full-jit','line_number':1507,'multiline':False]['text':' module and the lite module will be the same. Otherwise, it','line_number':1508,'multiline':False]['text':' will be different if we don't correctly ignore the cache','line_number':1509,'multiline':False]['text':' entry for an operator that has a different number of','line_number':1510,'multiline':False]['text':' arguments.','line_number':1511,'multiline':False]['text':'     def call(x):','line_number':1536,'multiline':False]['text':'         return x + x','line_number':1537,'multiline':False]['text':'','line_number':1538,'multiline':False]['text':'     def forward(a):','line_number':1539,'multiline':False]['text':'         x = a + call(a)','line_number':1540,'multiline':False]['text':'         y = a + call(x)','line_number':1541,'multiline':False]['text':'         return y','line_number':1542,'multiline':False]['text':' NOLINT (use =delete in gtest)','line_number':1634,'multiline':False]['text':' test invoking a method with default parameter','line_number':1636,'multiline':False]['text':' inner method call with default parameter (gets inlined)','line_number':1641,'multiline':False]['text':' simple method call','line_number':1648,'multiline':False]['text':' The following test run in fbcode only','line_number':1671,'multiline':False]['text':'
  (('__torch__.MyModule.forward',
    (('instructions',
      (('STOREN', 1, 3),
       ('DROPR', 1, 0),
       ('LOAD', 2, 0),
       ('LOAD', 3, 0),
       ('OP', 0, 0),
       ('LOAD', 2, 0),
       ('LOAD', 3, 0),
       ('OP', 1, 0),
       ('MOVE', 2, 0),
       ('MOVE', 3, 0),
       ('OP', 2, 0),
       ('TUPLE_CONSTRUCT', 3, 0),
       ('RET', 0, 0))),
     ('operators',
      (('aten::div', 'Tensor'),
       ('aten::div', 'Tensor'),
       ('aten::div', 'Tensor'))),
     ('constants', ()),
     ('types', ()),
     ('register_size', 3))),)

  ','line_number':1676,'multiline':True]['text':' 3 operators will use upgrader','line_number':1708,'multiline':False]['text':'
  (('__torch__.MyModule.forward',
    (('instructions',
      (('STOREN', 1, 4),
       ('DROPR', 1, 0),
       ('MOVE', 2, 0),
       ('MOVE', 3, 0),
       ('MOVE', 4, 0),
       ('OP', 0, 0),
       ('RET', 0, 0))),
     ('operators', (('aten::div', 'out'),)),
     ('constants', ()),
     ('types', ()),
     ('register_size', 4))),)
  ','line_number':1724,'multiline':True]['text':' One operator will use upgrader','line_number':1747,'multiline':False]['text':' The out argument will be overwritten with the output','line_number':1757,'multiline':False]['text':'
  (('__torch__.MyModule.forward',
    (('instructions',
      (('STOREN', 1, 3),
       ('DROPR', 1, 0),
       ('MOVE', 2, 0),
       ('MOVE', 3, 0),
       ('OP', 0, 0),
       ('RET', 0, 0))),
     ('operators', (('aten::div_', 'Tensor'),)),
     ('constants', ()),
     ('types', ()),
     ('register_size', 3))),)
  ','line_number':1766,'multiline':True]['text':' One operator will use upgrader','line_number':1788,'multiline':False]['text':' The out argument will be overwritten with the output','line_number':1796,'multiline':False]['text':'
  (('__torch__.MyModuleFloat.forward',
    (('instructions',
    (('STOREN', 1, 3),
    ('DROPR', 1, 0),
    ('MOVE', 2, 0),
    ('MOVE', 3, 0),
    ('OP', 0, 0),
    ('RET', 0, 0))),
    ('operators', (('aten::div', 'Scalar'),)),
    ('constants', ()),
    ('types', ()),
    ('register_size', 3))),)
  ','line_number':1805,'multiline':True]['text':' One operator will use upgrader','line_number':1828,'multiline':False]['text':' The out argument will be overwritten with the output','line_number':1836,'multiline':False]['text':'
  (('__torch__.MyModuleFloat.forward',
    (('instructions',
      (('STOREN', 1, 3),
      ('DROPR', 1, 0),
      ('MOVE', 2, 0),
      ('OP', 0, 0),
      ('MOVE', 3, 0),
      ('OP', 1, 0),
      ('RET', 0, 0))),
    ('operators', (('aten::reciprocal', ''), ('aten::mul', 'Scalar'))),
    ('constants', ()),
    ('types', ()),
    ('register_size', 3))),)
  ','line_number':1845,'multiline':True]['text':' No operator will use upgrader','line_number':1868,'multiline':False]['text':' The out argument will be overwritten with the output','line_number':1877,'multiline':False]['text':'
  (('__torch__.MyModuleInt.forward',
  (('instructions',
    (('STOREN', 1, 3),
     ('DROPR', 1, 0),
     ('MOVE', 2, 0),
     ('OP', 0, 0),
     ('MOVE', 3, 0),
     ('OP', 1, 0),
     ('RET', 0, 0))),
   ('operators', (('aten::reciprocal', ''), ('aten::mul', 'Scalar'))),
   ('constants', ()),
   ('types', ()),
   ('register_size', 3))),)
  ','line_number':1886,'multiline':True]['text':' No operator will use upgrader','line_number':1909,'multiline':False]['text':' The out argument will be overwritten with the output','line_number':1917,'multiline':False]['text':'
  (('__torch__.MyModule.forward',
    (('instructions',
      (('STOREN', 1, 5),
      ('DROPR', 1, 0),
      ('LOAD', 2, 0),
      ('LOAD', 3, 0),
      ('OP', 0, 0),
      ('MOVE', 2, 0),
      ('LOAD', 4, 0),
      ('OP', 1, 0),
      ('LOAD', 3, 0),
      ('MOVE', 4, 0),
      ('OP', 2, 0),
      ('MOVE', 3, 0),
      ('MOVE', 5, 0),
      ('OP', 3, 0),
      ('TUPLE_CONSTRUCT', 4, 0),
      ('RET', 0, 0))),
    ('operators',
      (('aten::div', ''),
      ('aten::div', 'float'),
      ('aten::div', ''),
      ('aten::div', 'int'))),
    ('constants', ()),
    ('types', ()),
    ('register_size', 5))),)
  ','line_number':1926,'multiline':True]['text':' No operator will use upgrader','line_number':1961,'multiline':False]['text':' auto actual_output = output.toTensor();','line_number':1969,'multiline':False]['text':'
  (('__torch__.MyModuleInt.forward',
    (('instructions',
      (('STOREN', 1, 3),
      ('DROPR', 1, 0),
      ('MOVE', 2, 0),
      ('MOVE', 3, 0),
      ('OP', 0, 0),
      ('RET', 0, 0))),
    ('operators', (('aten::div', 'Scalar'),)),
    ('constants', ()),
    ('types', ()),
    ('register_size', 3))),)
  ','line_number':1980,'multiline':True]['text':' One operator will use upgrader','line_number':2002,'multiline':False]['text':' The out argument will be overwritten with the output','line_number':2010,'multiline':False]['text':'
  (('__torch__.MyModuleFloat.forward',
    (('instructions',
      (('STOREN', 1, 3),
      ('DROPR', 1, 0),
      ('MOVE', 2, 0),
      ('MOVE', 3, 0),
      ('OP', 0, 0),
      ('RET', 0, 0))),
    ('operators', (('aten::div_', 'Scalar'),)),
    ('constants', ()),
    ('types', ()),
    ('register_size', 3))),)
  ','line_number':2019,'multiline':True]['text':' One operator will use upgrader','line_number':2042,'multiline':False]['text':' The out argument will be overwritten with the output','line_number':2050,'multiline':False]['text':'
  (('__torch__.MyModuleInt.forward',
    (('instructions',
      (('STOREN', 1, 3),
       ('DROPR', 1, 0),
       ('MOVE', 2, 0),
       ('MOVE', 3, 0),
       ('OP', 0, 0),
       ('RET', 0, 0))),
     ('operators', (('aten::div_', 'Scalar'),)),
     ('constants', ()),
     ('types', ()),
     ('register_size', 3))),)
  ','line_number':2059,'multiline':True]['text':' One operator will use upgrader','line_number':2082,'multiline':False]['text':' The out argument will be overwritten with the output','line_number':2090,'multiline':False]['text':' !defined(FB_XPLAT_BUILD)','line_number':2094,'multiline':False]['text':'*
 * Enumerate all possible JIT types appearing in mobile runtime, and test
 * whether subtyping relation is preserved after one of the JIT types is
 * converted to DynamicType.
 *
 * We firstly enumerate all "base" types in a vector, and implement
 * expandTypes() to enumerate container types one "level" up for a given set
 * of types. We call expandTypes() twice to test types nested less or equal
 * to two levels. e.g. List[Optional[Tensor]], Optional[Dict[Int, Bool]], etc.
 ','line_number':2205,'multiline':True]['text':' namespace jit','line_number':2238,'multiline':False]['text':' namespace torch','line_number':2239,'multiline':False]