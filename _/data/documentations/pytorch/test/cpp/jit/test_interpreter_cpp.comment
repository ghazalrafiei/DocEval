['text':' NOLINTNEXTLINE(cppcoreguidelines-non-private-member-variables-in-classes)','line_number':19,'multiline':False]['text':' TypeCheck yields to true! Shape, grad and device matches.','line_number':42,'multiline':False]['text':' Size mismatch','line_number':56,'multiline':False]['text':' Gradient mismatch','line_number':68,'multiline':False]['text':' Scalar type mismatch','line_number':79,'multiline':False]['text':' Device mismatch','line_number':89,'multiline':False]['text':' TODO: These tests weren't doing anything.','line_number':95,'multiline':False]['text':' TEST(TypeCheckErrorTest, EmptyCheckRaises) {','line_number':96,'multiline':False]['text':'   // Test empty Typecheck raises an internal assertion','line_number':97,'multiline':False]['text':'   auto graph = std::make_shared<Graph>();','line_number':98,'multiline':False]['text':'   std::unordered_map<std::string, Value*> vmap;','line_number':99,'multiline':False]['text':'   EXPECT_ANY_THROW(parseIR(','line_number':100,'multiline':False]['text':'       R"IR(','line_number':101,'multiline':False]['text':' graph(%a.1 : Tensor,','line_number':102,'multiline':False]['text':'       %b.1 : Tensor):','line_number':103,'multiline':False]['text':'   %type_matched : bool = prim::TypeCheck()','line_number':104,'multiline':False]['text':'   return (%type_matched)','line_number':105,'multiline':False]['text':'   )IR",','line_number':106,'multiline':False]['text':'       &*graph,','line_number':107,'multiline':False]['text':'       vmap));','line_number':108,'multiline':False]['text':' }','line_number':109,'multiline':False]['text':' TODO: These tests weren't doing anything.','line_number':111,'multiline':False]['text':' TEST(TypeCheckErrorTest, WrongInputOutputCountRaises) {','line_number':112,'multiline':False]['text':'   // Test for assertion if num_inputs + 1 != num_outputs','line_number':113,'multiline':False]['text':'   auto graph = std::make_shared<Graph>();','line_number':114,'multiline':False]['text':'   std::unordered_map<std::string, Value*> vmap;','line_number':115,'multiline':False]['text':'   EXPECT_ANY_THROW(parseIR(','line_number':116,'multiline':False]['text':'       R"IR(','line_number':117,'multiline':False]['text':' graph(%a.1 : Tensor,','line_number':118,'multiline':False]['text':'       %b.1 : Tensor):','line_number':119,'multiline':False]['text':'   %type_matched : bool = prim::TypeCheck(%a.1)','line_number':120,'multiline':False]['text':'   return (%type_matched)','line_number':121,'multiline':False]['text':'   )IR",','line_number':122,'multiline':False]['text':'       &*graph,','line_number':123,'multiline':False]['text':'       vmap));','line_number':124,'multiline':False]['text':' }','line_number':125,'multiline':False]['text':' should never register it','line_number':160,'multiline':False]['text':' this should be 3 when the add_out flag is set to True','line_number':183,'multiline':False]['text':'
  TODO: there are some problem with C++ parsing script program involving
  fork. Use the test module below for now.
  issue about this: github.com/pytorch/pytorch/issues/46368
  The test module file is generated by following:
    class DemoModule(torch.nn.Module):
      def forward(self):
        r1 = torch.jit.fork(torch.mm, torch.rand(100,100),torch.rand(100,100))
        r2 = torch.jit.fork(torch.mm, torch.rand(100,100),torch.rand(100,100))
        return r1.wait() + r2.wait()
  demo = DemoModule()
  torch.jit.save(torch.jit.script(demo), 'test_interpreter_async.pt')
  ','line_number':188,'multiline':True]['text':' a dummy executor which actually use at::launch, but add up a counter','line_number':209,'multiline':False]['text':' NOLINTNEXTLINE(modernize-use-emplace)','line_number':217,'multiline':False]['text':' namespace jit','line_number':295,'multiline':False]['text':' namespace torch','line_number':296,'multiline':False]