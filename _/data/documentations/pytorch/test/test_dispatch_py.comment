['text':' Owner(s): ["module: dispatch"]','line_number':1,'multiline':False]['text':' TODO: Expand the dispatcher API to be a generic API for interfacing with','line_number':13,'multiline':False]['text':' the dispatcher from Python!','line_number':14,'multiline':False]['text':'','line_number':15,'multiline':False]['text':' These are exhaustive tests for commutativity of dispatch behavior.  If you're','line_number':16,'multiline':False]['text':' looking for more usage-info style tests, check op_registration_test.cpp','line_number':17,'multiline':False]['text':'','line_number':18,'multiline':False]['text':' Things not tested here:','line_number':19,'multiline':False]['text':'   - Listeners','line_number':20,'multiline':False]['text':'   - Top level namespace registrations','line_number':21,'multiline':False]['text':'   - Fallback','line_number':22,'multiline':False]['text':'   - Exotic overloads of CppFunction/schema','line_number':23,'multiline':False]['text':'','line_number':24,'multiline':False]['text':' Things not directly tested here:','line_number':25,'multiline':False]['text':'   - Internal state of Dispatcher makes sense.  This is indirectly','line_number':26,'multiline':False]['text':'     tested by the invariant testing','line_number':27,'multiline':False]['text':' mask out file:line info for in-tree backend fallback','line_number':48,'multiline':False]['text':' Check that the regular stuff is OK!','line_number':57,'multiline':False]['text':' You probably don't want to call this directly; if your constructors','line_number':60,'multiline':False]['text':' don't commute, you can still run commute with a fixed ctor_order','line_number':61,'multiline':False]['text':' so that you can test that the destructors still commute','line_number':62,'multiline':False]['text':' By allocating every test into a fresh namespace, this makes it less','line_number':85,'multiline':False]['text':' likely that a bug in the testing framework will result in tests','line_number':86,'multiline':False]['text':' interfering with each other','line_number':87,'multiline':False]['text':' Refs which retain the c10::Module object so we can explicitly control','line_number':95,'multiline':False]['text':' when each deregistration happens (deregistration occurs when the','line_number':96,'multiline':False]['text':' object gets deallocated).','line_number':97,'multiline':False]['text':' Keep track of the set "in effect" registrations','line_number':99,'multiline':False]['text':' double underscore to make it less likely we conflict with something','line_number':102,'multiline':False]['text':' else','line_number':103,'multiline':False]['text':' Normalize the test namespace so that expected outputs are stable','line_number':108,'multiline':False]['text':' In the order specified by ctor_order, run registrations','line_number':128,'multiline':False]['text':' It would be better to DEF here, but because we manage','line_number':131,'multiline':False]['text':' lifetime of multiple registrations with multiple Library','line_number':132,'multiline':False]['text':' references (refs), we can't deal with the strict checking','line_number':133,'multiline':False]['text':' from DEF.','line_number':134,'multiline':False]['text':' NB: this finally test asserts that if a registrations fails,','line_number':152,'multiline':False]['text':' the dispatcher is left in the same state *that it was before*!','line_number':153,'multiline':False]['text':' Destroy references first, as some test frameworks (like pytest)','line_number':162,'multiline':False]['text':' will retain references in the exception raised by assertTrue! EW!','line_number':163,'multiline':False]['text':' In the order specified by dtor_order, run deregistrations','line_number':169,'multiline':False]['text':' Trigger a destruction','line_number':171,'multiline':False]['text':' discard not remove, since we may not have actually deregistered','line_number':173,'multiline':False]['text':' anything if there was an error raised','line_number':174,'multiline':False]['text':' Operator registrations are commutative (as static initializers can','line_number':184,'multiline':False]['text':' run in any order) and invertible (by deregistration).  (Subject','line_number':185,'multiline':False]['text':' to some caveats: some legacy behavior in the system are not commutative--','line_number':186,'multiline':False]['text':' we want to get rid of these!)','line_number':187,'multiline':False]['text':'','line_number':188,'multiline':False]['text':' So while in principle we could simply test a set of operations','line_number':189,'multiline':False]['text':' by just running them one by one in the order specified by the user,','line_number':190,'multiline':False]['text':' we can get more assurance about these extra properties by doing','line_number':191,'multiline':False]['text':' more work:','line_number':192,'multiline':False]['text':'','line_number':193,'multiline':False]['text':' 1. Don't run the registrations once in a fixed order: run every possible','line_number':194,'multiline':False]['text':'    permutation.  Similarly, run every permutation of deregistration order.','line_number':195,'multiline':False]['text':'','line_number':196,'multiline':False]['text':' 2. Don't just check the end state of the dispatcher: for every','line_number':197,'multiline':False]['text':'    subset of operator registrations, ensure that the computed','line_number':198,'multiline':False]['text':'    intermediate state is path independent.  One thing to note:','line_number':199,'multiline':False]['text':'    in this function, we assume each operation is unique.  In general,','line_number':200,'multiline':False]['text':'    there may be duplicated registrations, but these are usually','line_number':201,'multiline':False]['text':'    idempotent or legacy.  We test for behavior here separately.','line_number':202,'multiline':False]['text':'','line_number':203,'multiline':False]['text':' NB: checking all permutations means this function is exponential in','line_number':204,'multiline':False]['text':' the length of ops!  So don't pass too many ops to this function!','line_number':205,'multiline':False]['text':' Return the "full" Result namedtuple after all operations are run.','line_number':221,'multiline':False]['text':' If this KeyErrors, that means that there did not exist any','line_number':222,'multiline':False]['text':' ordering of ctors which got us to the "end".  That's an','line_number':223,'multiline':False]['text':' error in test construction: it means you could have','line_number':224,'multiline':False]['text':' factored the test into two smaller ones.','line_number':225,'multiline':False]['text':' m.def("foo(Tensor x) -> Tensor")','line_number':230,'multiline':False]['text':' m.impl("test_def", [](const Tensor& x) { return x })','line_number':232,'multiline':False]['text':' m.impl("test_def", kCPU, [](const Tensor& x) { return x })','line_number':234,'multiline':False]['text':' m.impl("test_def", kAutograd, [](const Tensor& x) { return x })','line_number':236,'multiline':False]['text':' m.impl("test_def", kAutogradCPU, [](const Tensor& x) { return x })','line_number':238,'multiline':False]['text':' NB: an impl-impl mismatch is not reported eagerly; you'll find out','line_number':253,'multiline':False]['text':' about it because one of them won't match with def','line_number':254,'multiline':False]['text':' m.def("foo(Tensor x, Tensor y) -> Tensor")','line_number':256,'multiline':False]['text':' m.impl("foo", [](const Tensor & x) { return x })','line_number':258,'multiline':False]['text':' m.def("foo", [](const Tensor & x) { return x })','line_number':272,'multiline':False]['text':' m.impl("foo", torch::kCPU, [](const Tensor & x) { return x })','line_number':274,'multiline':False]['text':' m.impl("foo", torch::kAutograd, [](const Tensor & x) { return x })','line_number':276,'multiline':False]['text':' m.impl("foo", torch::kAutogradCPU, [](const Tensor & x) { return x })','line_number':278,'multiline':False]['text':' m.def("foo(Tensor x, Tensor y) -> Tensor")','line_number':294,'multiline':False]['text':' m.impl("foo", [](const Tensor& x) { return x })','line_number':306,'multiline':False]['text':' m.impl("foo", torch::kCPU, [](const Tensor& x) { return x })','line_number':308,'multiline':False]['text':' m.impl("foo", torch::kAutograd, [](const Tensor& x) { return x })','line_number':310,'multiline':False]['text':' m.impl("foo", torch::kAutogradCPU, [](const Tensor& x) { return x })','line_number':312,'multiline':False]['text':' m.def("foo", [](const Tensor & x) { return x })','line_number':326,'multiline':False]['text':' m.impl("foo", torch::kCPU, [](const Tensor & x) { return x })','line_number':328,'multiline':False]['text':' m.impl("foo", torch::kCUDA, [](const Tensor & x) { return x })','line_number':330,'multiline':False]['text':' m.impl("foo", torch::kAutograd, [](const Tensor & x) { return x })','line_number':332,'multiline':False]['text':' m.impl("foo", torch::kAutogradCPU, [](const Tensor & x) { return x })','line_number':334,'multiline':False]['text':' computed dispatch table is too big, so we only check on a few entries we're interested in.','line_number':350,'multiline':False]['text':' m.def("foo", [](const Tensor & x) { return x })','line_number':367,'multiline':False]['text':' m.impl("foo", torch::kCPU, [](const Tensor & x) { return x })','line_number':369,'multiline':False]['text':' computed dispatch table is too big, so we only check on a few entries we're interested in.','line_number':382,'multiline':False]['text':' m.def("foo(Tensor x) -> Tensor")','line_number':399,'multiline':False]['text':' m.impl("foo", torch::kCompositeImplicitAutograd, [](const Tensor & x) { return x })','line_number':401,'multiline':False]['text':' computed dispatch table is too big, so we only check on a few entries we're interested in.','line_number':413,'multiline':False]['text':' m.def("foo(Tensor x) -> Tensor")','line_number':430,'multiline':False]['text':' m.impl("foo", torch::kCPU, [](const Tensor & x) { return x })','line_number':432,'multiline':False]['text':' m.impl("foo", torch::kCompositeImplicitAutograd, [](const Tensor & x) { return x })','line_number':434,'multiline':False]['text':' computed dispatch table is too big, so we only check on a few entries we're interested in.','line_number':447,'multiline':False]['text':' m.def("foo(Tensor x) -> Tensor")','line_number':464,'multiline':False]['text':' m.impl("foo", torch::kAutograd, [](const Tensor & x) { return x })','line_number':466,'multiline':False]['text':' computed dispatch table is too big, so we only check on a few entries we're interested in.','line_number':478,'multiline':False]['text':' Now that catchAll maps to CompositeImplicitAutograd, registering to both','line_number':488,'multiline':False]['text':' catchAll and CompositeImplicitAutograd breaks commutativity.','line_number':489,'multiline':False]['text':' m.def("foo(Tensor x) -> Tensor")','line_number':492,'multiline':False]['text':' m.impl("foo", torch::kCPU, [](const Tensor & x) { return x })','line_number':494,'multiline':False]['text':' m.impl("foo", torch::kAutograd, [](const Tensor & x) { return x })','line_number':496,'multiline':False]['text':' m.impl("foo", torch::kCompositeImplicitAutograd, [](const Tensor & x) { return x })','line_number':498,'multiline':False]['text':' computed dispatch table is too big, so we only check on a few entries we're interested in.','line_number':512,'multiline':False]['text':' m.def("foo(Tensor x) -> Tensor")','line_number':528,'multiline':False]['text':' m.impl("foo", torch::kCompositeImplicitAutograd, [](const Tensor & x) { return x })','line_number':530,'multiline':False]['text':' m.impl("foo", torch::kFPGA, [](const Tensor & x) { return x })','line_number':532,'multiline':False]['text':' computed dispatch table is too big, so we only check on a few entries we're interested in.','line_number':545,'multiline':False]['text':' m.def("foo(Tensor x) -> Tensor")','line_number':562,'multiline':False]['text':' m.impl("foo", torch::kCPU, [](const Tensor & x) { return x })','line_number':564,'multiline':False]['text':' m.impl("foo", torch::kCompositeExplicitAutograd, [](const Tensor & x) { return x })','line_number':566,'multiline':False]['text':' computed dispatch table is too big, so we only check on a few entries we're interested in.','line_number':579,'multiline':False]['text':' m.def("foo(Tensor x) -> Tensor")','line_number':595,'multiline':False]['text':' m.impl("foo", torch::kCPU, [](const Tensor & x) { return x })','line_number':597,'multiline':False]['text':' m.impl("foo", torch::kAutograd, [](const Tensor & x) { return x })','line_number':599,'multiline':False]['text':' m.impl("foo", torch::kCompositeExplicitAutograd, [](const Tensor & x) { return x })','line_number':601,'multiline':False]['text':' computed dispatch table is too big, so we only check on a few entries we're interested in.','line_number':615,'multiline':False]['text':' m.def("foo(Tensor x) -> Tensor")','line_number':632,'multiline':False]['text':' m.impl("foo", torch::kCPU, [](const Tensor & x) { return x })','line_number':634,'multiline':False]['text':' m.impl("foo", torch::kAutograd, [](const Tensor & x) { return x })','line_number':636,'multiline':False]['text':' m.impl("foo", torch::kCompositeImplicitAutograd, [](const Tensor & x) { return x })','line_number':638,'multiline':False]['text':' m.impl("foo", torch::kCompositeExplicitAutograd, [](const Tensor & x) { return x })','line_number':640,'multiline':False]['text':' computed dispatch table is too big, so we only check on a few entries we're interested in.','line_number':655,'multiline':False]['text':' m.def("foo(Tensor x, Tensor y) -> Tensor")','line_number':671,'multiline':False]['text':' m.def("foo(Tensor x, Tensor y) -> Tensor")','line_number':673,'multiline':False]['text':' m.def(torch::schema(','line_number':685,'multiline':False]['text':'   "foo(Tensor x, Tensor y) -> Tensor",','line_number':686,'multiline':False]['text':'   AliasAnalysisKind::PURE))','line_number':687,'multiline':False]['text':' m.def(torch::schema("foo(Tensor x) -> Tensor",','line_number':700,'multiline':False]['text':'                     c10::AliasAnalysisKind::PURE_FUNCTION))','line_number':701,'multiline':False]['text':' RegisterOperators().op("foo(Tensor x) -> Tensor")','line_number':703,'multiline':False]['text':' m.def(torch::schema("foo(Tensor x) -> Tensor",','line_number':715,'multiline':False]['text':'                     c10::AliasAnalysisKind::PURE_FUNCTION))','line_number':716,'multiline':False]['text':' m.def(torch::schema("foo(Tensor x) -> Tensor",','line_number':718,'multiline':False]['text':'                     c10::AliasAnalysisKind::CONSERVATIVE))','line_number':719,'multiline':False]['text':' Not commutative','line_number':748,'multiline':False]['text':' Definition: a dangling impl happens when someone does an impl() on a','line_number':759,'multiline':False]['text':' function but not a def() for it. This is usually a bug, e.g. someone','line_number':760,'multiline':False]['text':' misspelled an operator name, or someone registered an impl for an op that','line_number':761,'multiline':False]['text':' no longer exists','line_number':762,'multiline':False]['text':' If bmm gets quantized support you need to update this to something','line_number':946,'multiline':False]['text':' else that is not implemented','line_number':947,'multiline':False]