['text':' Owner(s): ["module: tests"]','line_number':1,'multiline':False]['text':' For testing TestCase methods and torch.testing functions','line_number':33,'multiline':False]['text':' Ensure that assertEqual handles numpy arrays properly','line_number':35,'multiline':False]['text':' Capture the default error message by forcing TestCase.longMessage = False','line_number':60,'multiline':False]['text':' atol and rtol tests','line_number':106,'multiline':False]['text':' atol and rtol tests','line_number':144,'multiline':False]['text':' equal_nan = True tests','line_number':160,'multiline':False]['text':' atol and rtol tests','line_number':188,'multiline':False]['text':' atol and rtol tests','line_number':190,'multiline':False]['text':' Complex versions of float tests (real part)','line_number':193,'multiline':False]['text':' Complex versions of float tests (imaginary part)','line_number':203,'multiline':False]['text':' atol and rtol tests for isclose','line_number':217,'multiline':False]['text':' Complex-specific tests','line_number':219,'multiline':False]['text':' equal_nan = True tests','line_number':232,'multiline':False]['text':' Tests that isclose with rtol or atol values less than zero throws a','line_number':242,'multiline':False]['text':'   RuntimeError','line_number':243,'multiline':False]['text':' For values >= 2**53, integers differing by 1 can no longer differentiated by torch.float64 or lower precision','line_number':258,'multiline':False]['text':' floating point dtypes. Thus, even with rtol == 0 and atol == 0, these tensors would be considered close if','line_number':259,'multiline':False]['text':' they were not compared as integers.','line_number':260,'multiline':False]['text':' The following tests (test_cuda_assert_*) are added to ensure test suite terminates early','line_number':279,'multiline':False]['text':' when CUDA assert was thrown. Because all subsequent test will fail if that happens.','line_number':280,'multiline':False]['text':' These tests are slow because it spawn another process to run test suite.','line_number':281,'multiline':False]['text':' See: https://github.com/pytorch/pytorch/issues/49019','line_number':282,'multiline':False]['text':' test to ensure common_utils.py override has early termination for CUDA.','line_number':287,'multiline':False]['text':' should capture CUDA error','line_number':311,'multiline':False]['text':' should run only 1 test because it throws unrecoverable error.','line_number':313,'multiline':False]['text':' test to ensure common_device_type.py override has early termination for CUDA.','line_number':321,'multiline':False]['text':' should capture CUDA error','line_number':352,'multiline':False]['text':' should run only 1 test because it throws unrecoverable error.','line_number':354,'multiline':False]['text':' test to ensure common_distributed.py override should not early terminate CUDA.','line_number':362,'multiline':False]['text':' we are currently disabling CUDA early termination for distributed tests.','line_number':394,'multiline':False]['text':' This is only supported for CPU and CUDA','line_number':397,'multiline':False]['text':' Test the `get_supported_dtypes` helper function.','line_number':400,'multiline':False]['text':' We acquire the dtypes for few Ops dynamically and verify them against','line_number':401,'multiline':False]['text':' the correct statically described values.','line_number':402,'multiline':False]['text':' device_type ='cuda'','line_number':410,'multiline':False]['text':' Test environment variable selected device type test generator.','line_number':446,'multiline':False]['text':' Test without setting env var should run everything.','line_number':470,'multiline':False]['text':' Test with setting only_for should only run 1 test.','line_number':478,'multiline':False]['text':' Test with setting except_for should run 1 less device type from default.','line_number':483,'multiline':False]['text':' Test with setting both should throw exception','line_number':489,'multiline':False]['text':' tuple vs. tuple','line_number':508,'multiline':False]['text':' list vs. list','line_number':510,'multiline':False]['text':' tuple vs. list','line_number':512,'multiline':False]['text':' dict vs. dict','line_number':514,'multiline':False]['text':' OrderedDict vs. OrderedDict','line_number':516,'multiline':False]['text':' dict vs. OrderedDict','line_number':518,'multiline':False]['text':' list of tuples vs. tuple of lists','line_number':520,'multiline':False]['text':' list of dicts vs. tuple of OrderedDicts','line_number':522,'multiline':False]['text':' dict of lists vs. OrderedDict of tuples','line_number':524,'multiline':False]['text':' TODO: the code that this test was designed for was removed in https://github.com/pytorch/pytorch/pull/56058','line_number':715,'multiline':False]['text':'  We need to check if this test is still needed or if this behavior is now enabled by default.','line_number':716,'multiline':False]['text':' If the default tolerances where selected based on the promoted dtype, i.e. float64,','line_number':802,'multiline':False]['text':' these tensors wouldn't be considered close.','line_number':803,'multiline':False]['text':' Although it looks complicated, this regex just makes sure that the word 'nan' is not part of the error','line_number':937,'multiline':False]['text':' message. That would happen if the 0 / 0 is used for the mismatch computation although it matches.','line_number':938,'multiline':False]['text':' We are using integer bounds here, because otherwise it would be impossible to pass `low` and `high`','line_number':1538,'multiline':False]['text':' outside their valid range. Python uses 64bit floating point numbers and thus trying to do something like','line_number':1539,'multiline':False]['text':' `torch.ffinfo(torch.float64)max * 2` will always result in `inf`. On the flipside, Pythons `int` is','line_number':1540,'multiline':False]['text':' unbounded.','line_number':1541,'multiline':False]['text':' Due to its internals, `make_tensor` is not able to sample `torch.iinfo(torch.int64).max`','line_number':1569,'multiline':False]['text':' Test that decorators can be applied on a per-param basis.','line_number':1688,'multiline':False]['text':' Test that multiple per-param decorators compose correctly.','line_number':1707,'multiline':False]['text':' Decorator should be applied whenever either x == 2 or y == False.','line_number':1725,'multiline':False]['text':' Test that @modules errors out when used with instantiate_parametrized_tests().','line_number':1730,'multiline':False]['text':' Test that @ops errors out when used with instantiate_parametrized_tests().','line_number':1741,'multiline':False]['text':' Test that multiple decorators handling the same param errors out.','line_number':1752,'multiline':False]['text':' This test exists to protect against regressions in device / dtype test naming','line_number':1777,'multiline':False]['text':' due to parametrization logic.','line_number':1778,'multiline':False]['text':' If no param names are passed, ensure things still work without parametrization.','line_number':1802,'multiline':False]['text':' If no param values are passed, ensure a helpful error message is thrown.','line_number':1825,'multiline':False]['text':' In the wild, this could indicate reuse of an exhausted generator.','line_number':1826,'multiline':False]['text':' Reuse generator from first test function.','line_number':1836,'multiline':False]['text':' Test that decorators can be applied on a per-op / per-param basis.','line_number':2019,'multiline':False]['text':' Create a test op, OpInfo entry, and decorator to apply.','line_number':2021,'multiline':False]['text':' Test that decorators can be applied on a per-module / per-param basis.','line_number':2069,'multiline':False]['text':' Create a test module, ModuleInfo entry, and decorator to apply.','line_number':2071,'multiline':False]['text':' Test checks that @parametrize and @dtypes compose as expected when @parametrize','line_number':2143,'multiline':False]['text':' doesn't set dtype.','line_number':2144,'multiline':False]['text':' Test checks that @dtypes cannot be composed with parametrization decorators when they','line_number':2169,'multiline':False]['text':' also try to set dtype.','line_number':2170,'multiline':False]['text':' Verify proper error behavior with @ops + @dtypes, as both try to set dtype.','line_number':2183,'multiline':False]['text':' Test that multiple decorators handling the same param errors out.','line_number':2195,'multiline':False]['text':' Both @modules and @ops handle the dtype param.','line_number':2196,'multiline':False]['text':' On Windows, opening the subprocess with the default CWD makes `import torch`','line_number':2229,'multiline':False]['text':' fail, so just set CWD to this script's directory','line_number':2230,'multiline':False]['text':' deps on tensorboard','line_number':2236,'multiline':False]['text':' depps on etcd','line_number':2237,'multiline':False]['text':' depends on pycoreml','line_number':2238,'multiline':False]['text':' something weird','line_number':2239,'multiline':False]['text':' just fails','line_number':2240,'multiline':False]['text':' depends on pytorch_lightning, not user-facing','line_number':2241,'multiline':False]['text':' depends on onnx-script','line_number':2242,'multiline':False]['text':' depends on triton','line_number':2243,'multiline':False]['text':' depends on cutlass','line_number':2244,'multiline':False]['text':' See https://github.com/pytorch/pytorch/issues/77801','line_number':2246,'multiline':False]['text':' Distributed should be importable on Windows(except nn.api.), but not on Mac','line_number':2250,'multiline':False]['text':' And these both end up with transitive dependencies on distributed','line_number':2259,'multiline':False]['text':' Do not attempt to import executable modules','line_number':2271,'multiline':False]['text':' Calling logging.basicConfig, among other things, modifies the global','line_number':2306,'multiline':False]['text':' logging state. It is not OK to modify the global logging state on','line_number':2307,'multiline':False]['text':' `import torch` (or other submodules we own) because users do not expect it.','line_number':2308,'multiline':False]['text':' Check that the profiler is initialized at import time.','line_number':2324,'multiline':False]['text':' Construction with natural syntax','line_number':2334,'multiline':False]['text':' Construction with explicit args and kwargs','line_number':2340,'multiline':False]['text':' Construction with a mixed form will error','line_number':2346,'multiline':False]['text':' Mixing metadata into "natural" construction will error','line_number':2359,'multiline':False]['text':' But when only input is given, metadata is allowed for backward','line_number':2369,'multiline':False]['text':' compatibility','line_number':2370,'multiline':False]['text':' Tests that validate the various sample generating functions on each OpInfo.','line_number':2393,'multiline':False]['text':' Test op.sample_inputs doesn't generate multiple samples when called','line_number':2398,'multiline':False]['text':' Test op.reference_inputs doesn't generate multiple samples when called','line_number':2404,'multiline':False]['text':' Test op.error_inputs doesn't generate multiple inputs when called','line_number':2410,'multiline':False]