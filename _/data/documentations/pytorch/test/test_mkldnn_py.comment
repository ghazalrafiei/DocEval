['text':' Owner(s): ["module: mkldnn"]','line_number':1,'multiline':False]['text':' batched grad doesn't support mkldnn','line_number':30,'multiline':False]['text':' Comment the line below to find out the CI machines having MKL-DNN build disabled','line_number':37,'multiline':False]['text':' float/bfloat16/half cpu tensor to mkldnn tensortensor.','line_number':49,'multiline':False]['text':' not given dtype for to_dense, mkldnn tensor has same dtype with cpu tensor','line_number':54,'multiline':False]['text':' mkldnn float/bfloat tensor to cpu float or bfloat tensor','line_number':56,'multiline':False]['text':' bfloat cpu tensor to mkldnn float tensor or bfloat tensor.','line_number':74,'multiline':False]['text':' not given dtype for to_dense, mkldnn tensor has same dtype with cpu tensor','line_number':81,'multiline':False]['text':' mkldnn float/bfloat/half tensor to cpu float/bfloat/half tensor','line_number':83,'multiline':False]['text':' unsupported types and unsupported types with gpu','line_number':153,'multiline':False]['text':' supported type with gpu','line_number':161,'multiline':False]['text':' some factory functions','line_number':165,'multiline':False]['text':' padding','line_number':176,'multiline':False]['text':' stride','line_number':177,'multiline':False]['text':' dilation','line_number':178,'multiline':False]['text':' groups','line_number':179,'multiline':False]['text':' weight','line_number':180,'multiline':False]['text':' bias','line_number':181,'multiline':False]['text':' MKLDNN only supports float32','line_number':187,'multiline':False]['text':' because MKLDNN only supports float32, we need to lessen the precision.','line_number':193,'multiline':False]['text':' these numbers are just empirical results that seem to work.','line_number':194,'multiline':False]['text':' MKLDNN only supports float32','line_number':203,'multiline':False]['text':' because MKLDNN only supports float32, we need to lessen the precision.','line_number':209,'multiline':False]['text':' these numbers are just empirical results that seem to work.','line_number':210,'multiline':False]['text':' TODO: enable conv1d training.','line_number':255,'multiline':False]['text':' TODO: remove this when group depthwise is supported:','line_number':300,'multiline':False]['text':' test thnn impl','line_number':328,'multiline':False]['text':' conv1: mkldnn conv/deconv in contiguous memory format (nchw)','line_number':370,'multiline':False]['text':' conv2: mkldnn conv/deconv in channels last memory format (nhwc)','line_number':371,'multiline':False]['text':' when torch.ops.mkldnn._is_mkldnn_bf16_supported() or torch.ops.mkldnn._is_mkldnn_fp16_supported()','line_number':410,'multiline':False]['text':' returns false, bf16/fp16 CPU conv will fall back to thnn impl','line_number':411,'multiline':False]['text':' BF16/FP16 fallback implementations are divided into two parts im2col+gemm,','line_number':422,'multiline':False]['text':' and the number of data type conversions in the middle is more than that of onednn's direct conv,','line_number':423,'multiline':False]['text':' resulting in additional accuracy loss.','line_number':424,'multiline':False]['text':' when torch.ops.mkldnn._is_mkldnn_bf16_supported() or torch.ops.mkldnn._is_mkldnn_fp16_supported()','line_number':445,'multiline':False]['text':' returns false, bf16/fp16 CPU conv will fall back to thnn impl','line_number':446,'multiline':False]['text':' BF16/FP16 fallback implementations are divided into two parts col2im+gemm,','line_number':457,'multiline':False]['text':' and the number of data type conversions in the middle is more than that of onednn's direct conv,','line_number':458,'multiline':False]['text':' resulting in additional accuracy loss.','line_number':459,'multiline':False]['text':' conv: mkldnn tranpose conv fp32','line_number':485,'multiline':False]['text':' conv_ref: thnn transpose conv fp32','line_number':486,'multiline':False]['text':' contrive legacy conv2d module with a 5-d weight','line_number':539,'multiline':False]['text':' This test is to check whether 1D conv is supported for mkldnn tensor,','line_number':556,'multiline':False]['text':' which is exposed by Issue https://github.com/pytorch/pytorch/issues/68034.','line_number':557,'multiline':False]['text':' Only convert data to mkldnn, weight is Aten tensor','line_number':657,'multiline':False]['text':' OneDNN not support dilation max_pooling, will be avilabled in v2.0.','line_number':811,'multiline':False]['text':' 2d dilation case','line_number':815,'multiline':False]['text':' 3d dilation case','line_number':826,'multiline':False]['text':' TODO: support 3d batchnorm training.','line_number':972,'multiline':False]['text':' TODO: support none affine.','line_number':974,'multiline':False]['text':' TODO: support training','line_number':1014,'multiline':False]['text':' add','line_number':1050,'multiline':False]['text':' add_','line_number':1059,'multiline':False]['text':' add_out','line_number':1064,'multiline':False]['text':' add_out inplace case: first input','line_number':1071,'multiline':False]['text':' add_out inplace case: second input','line_number':1076,'multiline':False]['text':' mul','line_number':1091,'multiline':False]['text':' mul_','line_number':1108,'multiline':False]['text':' mul_out','line_number':1117,'multiline':False]['text':' unary ops work without modification','line_number':1134,'multiline':False]['text':' test whether share same memory for plain format tensor','line_number':1176,'multiline':False]['text':' construct an mkldnn blocked tensor with mkldnn conv2d','line_number':1185,'multiline':False]['text':' mkldnn tensor w/ blocked format','line_number':1190,'multiline':False]['text':' aten tensor w/ plain format','line_number':1192,'multiline':False]['text':' test whether share same memory','line_number':1222,'multiline':False]['text':' inplace','line_number':1349,'multiline':False]['text':' inplace','line_number':1361,'multiline':False]['text':' Dense tensor has impl of type `TensorImpl`, while MKL-DNN tensor has impl','line_number':1381,'multiline':False]['text':' of type `OpaqueTensorImpl<IDeepTensorWrapperPtr>`.','line_number':1382,'multiline':False]['text':' legacy constructor/new doesn't support mkldnn tensors','line_number':1407,'multiline':False]['text':' a2 is contiguous tensor but it's strides','line_number':1570,'multiline':False]['text':' is not default contiguous strides.','line_number':1571,'multiline':False]