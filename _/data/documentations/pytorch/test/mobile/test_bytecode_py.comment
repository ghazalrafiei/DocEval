['text':' Owner(s): ["oncall: mobile"]','line_number':1,'multiline':False]['text':' from torch.utils.mobile_optimizer import optimize_for_mobile','line_number':9,'multiline':False]['text':' script_module_v4.ptl and script_module_v5.ptl source code','line_number':22,'multiline':False]['text':' class TestModule(torch.nn.Module):','line_number':23,'multiline':False]['text':'     def __init__(self, v):','line_number':24,'multiline':False]['text':'         super().__init__()','line_number':25,'multiline':False]['text':'         self.x = v','line_number':26,'multiline':False]['text':'     def forward(self, y: int):','line_number':28,'multiline':False]['text':'         increment = torch.ones([2, 4], dtype=torch.float64)','line_number':29,'multiline':False]['text':'         return self.x + y + increment','line_number':30,'multiline':False]['text':' output_model_path = Path(tmpdirname, "script_module_v5.ptl")','line_number':32,'multiline':False]['text':' script_module = torch.jit.script(TestModule(1))','line_number':33,'multiline':False]['text':' optimized_scripted_module = optimize_for_mobile(script_module)','line_number':34,'multiline':False]['text':' exported_optimized_scripted_module = optimized_scripted_module._save_for_lite_interpreter(','line_number':35,'multiline':False]['text':'   str(output_model_path))','line_number':36,'multiline':False]['text':' The minimum version a model can be backported to','line_number':142,'multiline':False]['text':' Need to be updated when a bytecode version is completely retired','line_number':143,'multiline':False]['text':' Find the maximum version of the checked in models, start backporting to the minimum support version,','line_number':156,'multiline':False]['text':' and comparing the bytecode pkl content.','line_number':157,'multiline':False]['text':' It can't be merged to the test `test_all_backport_functions`, because optimization is dynamic and','line_number':158,'multiline':False]['text':' the content might change when optimize function changes. This test focuses','line_number':159,'multiline':False]['text':' on bytecode.pkl content validation. For the content validation, it is not byte to byte check, but','line_number':160,'multiline':False]['text':' regular expression matching. The wildcard can be used to skip some specific content comparison.','line_number':161,'multiline':False]['text':' Load model v5 and run forward method','line_number':167,'multiline':False]['text':' A temporary model file will be export to this path, and run through bytecode.pkl','line_number':171,'multiline':False]['text':' content check.','line_number':172,'multiline':False]['text':' Please run this test manually when working on backport.','line_number':195,'multiline':False]['text':' This test passes in OSS, but fails internally, likely due to missing step in build','line_number':196,'multiline':False]['text':' def test_all_backport_functions(self):','line_number':197,'multiline':False]['text':'     # Backport from the latest bytecode version to the minimum support version','line_number':198,'multiline':False]['text':'     # Load, run the backport model, and check version','line_number':199,'multiline':False]['text':'     class TestModule(torch.nn.Module):','line_number':200,'multiline':False]['text':'         def __init__(self, v):','line_number':201,'multiline':False]['text':'             super().__init__()','line_number':202,'multiline':False]['text':'             self.x = v','line_number':203,'multiline':False]['text':'         def forward(self, y: int):','line_number':205,'multiline':False]['text':'             increment = torch.ones([2, 4], dtype=torch.float64)','line_number':206,'multiline':False]['text':'             return self.x + y + increment','line_number':207,'multiline':False]['text':'     module_input = 1','line_number':209,'multiline':False]['text':'     expected_mobile_module_result = 3 * torch.ones([2, 4], dtype=torch.float64)','line_number':210,'multiline':False]['text':'     # temporary input model file and output model file will be exported in the temporary folder','line_number':212,'multiline':False]['text':'     with tempfile.TemporaryDirectory() as tmpdirname:','line_number':213,'multiline':False]['text':'         tmp_input_model_path = Path(tmpdirname, "tmp_script_module.ptl")','line_number':214,'multiline':False]['text':'         script_module = torch.jit.script(TestModule(1))','line_number':215,'multiline':False]['text':'         optimized_scripted_module = optimize_for_mobile(script_module)','line_number':216,'multiline':False]['text':'         exported_optimized_scripted_module = optimized_scripted_module._save_for_lite_interpreter(str(tmp_input_model_path))','line_number':217,'multiline':False]['text':'         current_from_version = _get_model_bytecode_version(tmp_input_model_path)','line_number':219,'multiline':False]['text':'         current_to_version = current_from_version - 1','line_number':220,'multiline':False]['text':'         tmp_output_model_path = Path(tmpdirname, "tmp_script_module_backport.ptl")','line_number':221,'multiline':False]['text':'         while current_to_version >= MINIMUM_TO_VERSION:','line_number':223,'multiline':False]['text':'             # Backport the latest model to `to_version` to a tmp file "tmp_script_module_backport"','line_number':224,'multiline':False]['text':'             backport_success = _backport_for_mobile(tmp_input_model_path, tmp_output_model_path, current_to_version)','line_number':225,'multiline':False]['text':'             assert(backport_success)','line_number':226,'multiline':False]['text':'             backport_version = _get_model_bytecode_version(tmp_output_model_path)','line_number':228,'multiline':False]['text':'             assert(backport_version == current_to_version)','line_number':229,'multiline':False]['text':'             # Load model and run forward method','line_number':231,'multiline':False]['text':'             mobile_module = _load_for_lite_interpreter(str(tmp_input_model_path))','line_number':232,'multiline':False]['text':'             mobile_module_result = mobile_module(module_input)','line_number':233,'multiline':False]['text':'             torch.testing.assert_close(mobile_module_result, expected_mobile_module_result)','line_number':234,'multiline':False]['text':'             current_to_version -= 1','line_number':235,'multiline':False]['text':'         # Check backport failure case','line_number':237,'multiline':False]['text':'         backport_success = _backport_for_mobile(tmp_input_model_path, tmp_output_model_path, MINIMUM_TO_VERSION - 1)','line_number':238,'multiline':False]['text':'         assert(not backport_success)','line_number':239,'multiline':False]['text':'         # need to clean the folder before it closes, otherwise will run into git not clean error','line_number':240,'multiline':False]['text':'         shutil.rmtree(tmpdirname)','line_number':241,'multiline':False]['text':' Check just the test_backport_bytecode_from_file_to_file mechanism but not the function implementations','line_number':243,'multiline':False]['text':' backport from file','line_number':252,'multiline':False]['text':' Load model v4 and run forward method','line_number':271,'multiline':False]['text':' Check just the _backport_for_mobile_to_buffer mechanism but not the function implementations','line_number':279,'multiline':False]['text':' Backport model to v4','line_number':286,'multiline':False]['text':' Check version of the model v4 from backport','line_number':291,'multiline':False]['text':' Load model v4 from backport and run forward method','line_number':296,'multiline':False]['text':' TODO update this to be more in the style of the above tests after a backport from 6 -> 5 exists','line_number':306,'multiline':False]