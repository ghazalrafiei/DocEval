['text':' Owner(s): ["module: nn"]','line_number':1,'multiline':False]['text':' WARNING: If you add a new top-level test case to this file, you MUST','line_number':21,'multiline':False]['text':' update test/run_test.py to list it, otherwise it will NOT be run in','line_number':22,'multiline':False]['text':' CI.','line_number':23,'multiline':False]['text':' divide by sqrt(d_head)','line_number':40,'multiline':False]['text':' assert s1 == s2','line_number':44,'multiline':False]['text':' batchmatmul over 4 dim matrix','line_number':61,'multiline':False]['text':' softmax over 4 dim matrix','line_number':73,'multiline':False]['text':' returns [batch_size, max_seq_len]','line_number':114,'multiline':False]['text':' result = reference','line_number':271,'multiline':False]['text':' result_weight = ref_attn_weight','line_number':275,'multiline':False]['text':' Test MultiheadAttention with add_zero_attn','line_number':310,'multiline':False]['text':' Test MultiheadAttention with add_bias_kv','line_number':311,'multiline':False]['text':' Test MultiheadAttention without masking','line_number':312,'multiline':False]['text':' Test MultiheadAttention with src lengths','line_number':313,'multiline':False]['text':' Test MultiheadAttention with static kv.','line_number':314,'multiline':False]['text':' Test MultiheadAttention with bias_kv and zero_attn.','line_number':315,'multiline':False]['text':' Test MultiheadAttention with all the argument.','line_number':316,'multiline':False]['text':' Test MultiheadAttention with all the argument.','line_number':318,'multiline':False]['text':' Test MultiheadAttention with all the argument.','line_number':319,'multiline':False]['text':' [N, T, D]','line_number':328,'multiline':False]['text':' [N, S, D]','line_number':329,'multiline':False]['text':' [N, S, D]','line_number':330,'multiline':False]['text':' [N, T, S]','line_number':331,'multiline':False]['text':' Generate 3D results','line_number':336,'multiline':False]['text':' [N * H, T, S]','line_number':337,'multiline':False]['text':' [N, T, D]','line_number':340,'multiline':False]['text':' output_2d in shape of [T, 1, D]','line_number':348,'multiline':False]['text':' Verify that bias=False applies to both in and out projection layers.','line_number':356,'multiline':False]['text':' Batched (3D) query cases','line_number':361,'multiline':False]['text':' 3D query, 2D key and 3D value','line_number':367,'multiline':False]['text':' 3D query, 3D key and 2D value','line_number':372,'multiline':False]['text':' 3D query, 3D key, 3D value and 1D key_padding_mask','line_number':377,'multiline':False]['text':' 3D query, 3D key, 3D value and 1D attn_mask','line_number':382,'multiline':False]['text':' Unbatched (2D) query cases','line_number':386,'multiline':False]['text':' 2D query, 3D key and 2D value','line_number':392,'multiline':False]['text':' 2D query, 3D key and 2D value','line_number':397,'multiline':False]['text':' 2D query, 2D key, 2D value and 1D key_padding_mask','line_number':402,'multiline':False]['text':' 2D query, 2D key, 2D value and 1D attn_mask','line_number':407,'multiline':False]['text':' 2D query, 2D key, 2D value and 3D incorrect attn_mask','line_number':412,'multiline':False]['text':' Give the test a chance to hit the fast path. (Right now, it','line_number':419,'multiline':False]['text':' won't, but gating may be less restricted in the future.)','line_number':420,'multiline':False]['text':' Batched (3D) query cases','line_number':428,'multiline':False]['text':' Currently, this case will just go to the slow path and get','line_number':433,'multiline':False]['text':' the usual message because it fails the requirement to be','line_number':434,'multiline':False]['text':' batched.','line_number':435,'multiline':False]['text':' 3D query, 2D key and 3D value','line_number':437,'multiline':False]['text':' Currently, this case will just go to the slow path and get','line_number':441,'multiline':False]['text':' the usual message because it fails the requirement to be','line_number':442,'multiline':False]['text':' batched.','line_number':443,'multiline':False]['text':' 3D query, 3D key and 2D value','line_number':445,'multiline':False]['text':' 3D query, 3D key, 3D value and 1D key_padding_mask','line_number':450,'multiline':False]['text':' 3D query, 3D key, 3D value and 1D attn_mask','line_number':456,'multiline':False]['text':' Unbatched (2D) query cases','line_number':460,'multiline':False]['text':' NOTE: error messages are the same as regular path because the fast path doesn't support 2D.','line_number':461,'multiline':False]['text':' 2D query, 3D key and 2D value','line_number':467,'multiline':False]['text':' 2D query, 3D key and 2D value','line_number':472,'multiline':False]['text':' 2D query, 2D key, 2D value and 1D key_padding_mask','line_number':477,'multiline':False]['text':' 2D query, 2D key, 2D value and 1D attn_mask','line_number':482,'multiline':False]['text':' 2D query, 2D key, 2D value and 3D incorrect attn_mask','line_number':487,'multiline':False]['text':' One tested platform (linux-bionic-py3.7-clang) has a torch_function for one','line_number':494,'multiline':False]['text':' or more of these. Take advantage of that to test the torch_function bailout.','line_number':495,'multiline':False]['text':' Just give up, they're all going to fail with the same message.','line_number':507,'multiline':False]['text':' Create masks of two different types','line_number':538,'multiline':False]['text':' We'll need expanded versions of the masks for masking out the outputs below','line_number':542,'multiline':False]['text':' Compute attention on the fast path','line_number':549,'multiline':False]['text':' Compute attention on the slow path','line_number':554,'multiline':False]['text':' Convert to batch-first','line_number':576,'multiline':False]['text':' Rows which are completely masked out are nan, we need to exclude them from comparison','line_number':578,'multiline':False]['text':' Create masks of two different types','line_number':603,'multiline':False]['text':' Compute attention on the fast path','line_number':610,'multiline':False]['text':' If mock was called, fastpath was taken','line_number':614,'multiline':False]['text':' With batch_first=True, we have the possibility of hitting','line_number':639,'multiline':False]['text':' the native fast path if we call .eval() and enable inference','line_number':640,'multiline':False]['text':' mode. Test both paths.','line_number':641,'multiline':False]['text':' fast path currently doesn't support weights','line_number':653,'multiline':False]['text':' Setting kdim == vdim == 2 means that vdim != embed_dim','line_number':683,'multiline':False]['text':' will cause the logic to use per-input project weights, thereby','line_number':684,'multiline':False]['text':' forcing self.in_proj_weight = None','line_number':685,'multiline':False]