['text':' Owner(s): ["module: dynamo"]','line_number':1,'multiline':False]['text':' flake8: noqa','line_number':2,'multiline':False]['text':' The following import pattern matters as `test_export.export` is patched','line_number':47,'multiline':False]['text':' in other files (like test_export_nonstrict.py). `torch.export.export`','line_number':48,'multiline':False]['text':' will invalidate the patch.','line_number':49,'multiline':False]['text':' Being able to export means shape is preserved as static','line_number':112,'multiline':False]['text':' No more inplace mutation','line_number':215,'multiline':False]['text':' There should be nonzero view nodes in the graph','line_number':224,'multiline':False]['text':' pass dynamic shapes of inputs [args]','line_number':400,'multiline':False]['text':' pass dynamic shapes of inputs [kwargs]','line_number':409,'multiline':False]['text':' pass dynamic shapes of inputs [partial, error]','line_number':421,'multiline':False]['text':' pass dynamic shapes of inputs [module]','line_number':439,'multiline':False]['text':' pass dynamic shapes of inputs [bounds, mostly shared]','line_number':450,'multiline':False]['text':' pass dynamic shapes of inputs [multiple, mostly distinct]','line_number':475,'multiline':False]['text':' pass dynamic shapes of inputs [dict]','line_number':496,'multiline':False]['text':' pass dynamic shapes of inputs [list]','line_number':517,'multiline':False]['text':' pass dynamic shapes of inputs [dataclass]','line_number':538,'multiline':False]['text':' pass dynamic shapes of inputs [distinct, error]','line_number':565,'multiline':False]['text':' pass dynamic shapes of inputs [specialized, error]','line_number':586,'multiline':False]['text':' pass dynamic shapes of inputs [guards, error]','line_number':607,'multiline':False]['text':' uniformly specify dynamic shapes for all inputs','line_number':645,'multiline':False]['text':' the pytree registration don't allow registering the same class twice','line_number':720,'multiline':False]['text':' Override the registration with keep none fields','line_number':725,'multiline':False]['text':' weight','line_number':799,'multiline':False]['text':' bias','line_number':800,'multiline':False]['text':' running_mean','line_number':813,'multiline':False]['text':' running_var','line_number':814,'multiline':False]['text':' num_batches_tracked','line_number':815,'multiline':False]['text':' Intentionally not wrapping `inp` in a tuple to trigger the error','line_number':938,'multiline':False]['text':' can't retrace with invalid inputs with respect to the original ExportedProgram','line_number':1315,'multiline':False]['text':' We cannot automatically infer a is a size here because view','line_number':1356,'multiline':False]['text':' accepts -1','line_number':1357,'multiline':False]['text':' We are specifying dynamism on the first kwarg even though user passed in','line_number':1662,'multiline':False]['text':' different order','line_number':1663,'multiline':False]['text':' This should work even if the kwarg order are flipped.','line_number':1668,'multiline':False]['text':' Mark the second input a[1] dynamic','line_number':1681,'multiline':False]['text':' This is actually correct because how make_fx modifies the buffer since','line_number':1736,'multiline':False]['text':' there is no functionalization.','line_number':1737,'multiline':False]['text':' This errors because dynamo adds an extra input','line_number':1768,'multiline':False]['text':' Put the inputs on a device','line_number':1782,'multiline':False]['text':' Put the inputs on a device','line_number':1810,'multiline':False]['text':' Manualy set the fake_device of fake tensors.','line_number':1815,'multiline':False]['text':' Need to set all the requires_grad of tensors to False, because fake_tensor with CUDA device','line_number':1820,'multiline':False]['text':' doesn't quite work well with aot_autograd right now due to some logic fails','line_number':1821,'multiline':False]['text':' the check in call getDeviceGuardImpl in InputMetadata.','line_number':1822,'multiline':False]['text':' We saw this pattern when users want to export','line_number':1841,'multiline':False]['text':' a graph that initlizes the states of a model.','line_number':1842,'multiline':False]['text':' (bs, n_heads, q_length, k_length)','line_number':1859,'multiline':False]['text':' res_ref = m(tensor_cpu, mask_cpu)','line_number':1869,'multiline':False]['text':' print("res_ref is: {}".format(res_ref), flush=True)','line_number':1870,'multiline':False]['text':' We do not need to normalize the key here because exported','line_number':2020,'multiline':False]['text':' program's state dict is able to contain the module information.','line_number':2021,'multiline':False]