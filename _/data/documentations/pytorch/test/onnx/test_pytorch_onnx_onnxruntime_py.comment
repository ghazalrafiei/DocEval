['text':' Owner(s): ["module: onnx"]','line_number':1,'multiline':False]['text':' Valid opset versions are defined in torch/onnx/_constants.py.','line_number':125,'multiline':False]['text':' Versions are intentionally set statically, to not be affected by changes elsewhere.','line_number':126,'multiline':False]['text':' Only support CPU version, since tracer is not working in GPU RNN.','line_number':325,'multiline':False]['text':' scripting prim::unchecked_cast prim::setattr','line_number':405,'multiline':False]['text':' noqa: RUF015','line_number':486,'multiline':False]['text':' User-defined class not supported','line_number':504,'multiline':False]['text':' Needs https://github.com/pytorch/rfcs/pull/21','line_number':573,'multiline':False]['text':' Without kwargs dict.','line_number':593,'multiline':False]['text':' With kwargs dict.','line_number':596,'multiline':False]['text':' tracing eliminates None inputs so it works differently. See _script version below.','line_number':602,'multiline':False]['text':' tracing is verified with different set of inputs. See above.','line_number':626,'multiline':False]['text':' Needs https://github.com/pytorch/rfcs/pull/21','line_number':664,'multiline':False]['text':' y disappears in tracing.','line_number':683,'multiline':False]['text':' tracing eliminates None inputs so it works differently. See _script version below.','line_number':687,'multiline':False]['text':' tracing means y is never used so it's removed from the exported model inputs,','line_number':708,'multiline':False]['text':' and we fail when trying to run ORT.','line_number':709,'multiline':False]['text':' tracing is verified with different set of inputs. See above.','line_number':713,'multiline':False]['text':' Optional supports None inputs','line_number':733,'multiline':False]['text':' NOTE: default value is not supported on ONNX, so torch and ONNX has','line_number':735,'multiline':False]['text':' different behavior','line_number':736,'multiline':False]['text':' tracing uses prim::ListUnpack to avoid onnx::SequenceConstruct','line_number':780,'multiline':False]['text':' tracing uses prim::ListUnpack to avoid onnx::SequenceConstruct','line_number':793,'multiline':False]['text':' Needs https://github.com/pytorch/rfcs/pull/21','line_number':813,'multiline':False]['text':' Needs https://github.com/pytorch/rfcs/pull/21','line_number':827,'multiline':False]['text':' tracing eliminates None inputs so it works differently. See _script version below.','line_number':842,'multiline':False]['text':' tracing is verified with different set of inputs. See above.','line_number':865,'multiline':False]['text':' export succeeds, but running ORT through run_test would fail because the exported model','line_number':893,'multiline':False]['text':' has the inputs flattened into 3 inputs.','line_number':894,'multiline':False]['text':' Testing edge cases','line_number':1032,'multiline':False]['text':' corner cases','line_number':1053,'multiline':False]['text':' Testing edge cases','line_number':1072,'multiline':False]['text':' Testing edge cases','line_number':1090,'multiline':False]['text':' Conversion of Transpose depends on input shape to be known.','line_number':1288,'multiline':False]['text':' The following test only works when onnx shape inference is enabled.','line_number':1289,'multiline':False]['text':' TODO: Enable after https://github.com/onnx/onnx/pull/5741 or after ONNX 1.15.1+ is released','line_number':1482,'multiline':False]['text':' TODO: Enable after https://github.com/onnx/onnx/pull/5741 or after ONNX 1.15.1+ is released','line_number':1491,'multiline':False]['text':' TODO: Enable after https://github.com/onnx/onnx/pull/5741 or after ONNX 1.15.1+ is released','line_number':1504,'multiline':False]['text':' TODO: Enable after https://github.com/onnx/onnx/pull/5741 or after ONNX 1.15.1+ is released','line_number':1518,'multiline':False]['text':' TODO: Enable after https://github.com/onnx/onnx/pull/5741 or after ONNX 1.15.1+ is released','line_number':1528,'multiline':False]['text':' TODO: Enable after https://github.com/onnx/onnx/pull/5741 or after ONNX 1.15.1+ is released','line_number':1542,'multiline':False]['text':' TODO: ceil_mode is not included in the test, because of','line_number':1588,'multiline':False]['text':' https://github.com/microsoft/onnxruntime/issues/16203','line_number':1589,'multiline':False]['text':' The ORT and PyTorch has different calculation for ceil_mode (the last value).','line_number':1590,'multiline':False]['text':' TODO: ceil_mode is not included in the test, because of','line_number':1609,'multiline':False]['text':' https://github.com/microsoft/onnxruntime/issues/16203','line_number':1610,'multiline':False]['text':' The ORT and PyTorch has different calculation for ceil_mode (the last value).','line_number':1611,'multiline':False]['text':' Operator rank mismatch between outputs of two branches for opsets below 11.','line_number':1680,'multiline':False]['text':' enumerate is creating a prim::min op in torch graph','line_number':1719,'multiline':False]['text':' In scripting the first transpose node do not carry shape and dtype info.','line_number':1836,'multiline':False]['text':' The following test only works when onnx shape inference is enabled.','line_number':1837,'multiline':False]['text':' Note: div cannot (generally) be exported via scripting','line_number':1909,'multiline':False]['text':' since its type promotion logic is dependent on knowing the scalar types','line_number':1910,'multiline':False]['text':' of the input tensors. That is, the ONNX graph is dependent on the','line_number':1911,'multiline':False]['text':' data type of the inputs. This makes it appropriate for tracing only.','line_number':1912,'multiline':False]['text':' In scripting x, y do not carry shape and dtype info.','line_number':1927,'multiline':False]['text':' The following test only works when onnx shape inference is enabled.','line_number':1928,'multiline':False]['text':' Add transpose to hide shape/type information','line_number':1932,'multiline':False]['text':' Otherwise shape and type are still avaiable from input.','line_number':1933,'multiline':False]['text':' 1. x,y are int, and output is float.','line_number':1941,'multiline':False]['text':'    This can be handled by the default case, where both are cast to float.','line_number':1942,'multiline':False]['text':'    It works even if type of x, y are unknown.','line_number':1943,'multiline':False]['text':' 2. x,y are int, and output is double.','line_number':1947,'multiline':False]['text':'    This can be handled by the default case, where both are cast to double.','line_number':1948,'multiline':False]['text':'    It works even if type of x, y are unknown.','line_number':1949,'multiline':False]['text':' 3. x is int, y is double, and output is double.','line_number':1953,'multiline':False]['text':'    This can only be handled when both type of x and y are known.','line_number':1954,'multiline':False]['text':' Torchscript doesn't support 1d index.','line_number':2044,'multiline':False]['text':' scripting tuple/list append','line_number':2068,'multiline':False]['text':' scripting tuple/list append','line_number':2111,'multiline':False]['text':' x.stride() not scriptable','line_number':2363,'multiline':False]['text':' Ellipses followed by tensor indexing not scriptable','line_number':2378,'multiline':False]['text':' Ellipses followed by tensor indexing not scriptable','line_number':2570,'multiline':False]['text':' mixed slice and select','line_number':2650,'multiline':False]['text':' Model not scriptable (output with shape doesn't match the broadcast shape)','line_number':2702,'multiline':False]['text':' Insert reshape node to ensure no shape/type info for','line_number':2732,'multiline':False]['text':' x in scripting, without onnx shape inference.','line_number':2733,'multiline':False]['text':' This randint call always returns 3','line_number':2767,'multiline':False]['text':' This randint call always returns 3','line_number':2777,'multiline':False]['text':' The resulting node's dtype should be double.','line_number':2802,'multiline':False]['text':' The resulting node's dtype should be double.','line_number':2815,'multiline':False]['text':' The resulting node's dtype should be double.','line_number':2864,'multiline':False]['text':' The resulting node's dtype should be double.','line_number':2877,'multiline':False]['text':' - cubic mode is not supported for opsets below 11;','line_number':3007,'multiline':False]['text':' - linear mode does not match for opsets below 11;','line_number':3008,'multiline':False]['text':' TODO: enable bicubic downsample when ORT precision loss fixed','line_number':3021,'multiline':False]['text':' TODO : enable when linear mode is implemented for 1d inputs in ORT','line_number':3026,'multiline':False]['text':' TODO : enable when linear mode is implemented for 3d inputs in ORT','line_number':3031,'multiline':False]['text':' test with align_corners if supported','line_number':3035,'multiline':False]['text':' the following cases, require dynamic sizes/scales,','line_number':3038,'multiline':False]['text':' which which is not supported for opset_version < 9','line_number':3039,'multiline':False]['text':' test with align_corners if supported','line_number':3042,'multiline':False]['text':' ONNX export failed on interpolate scripting because dynamic size not supported for opsets below 9.','line_number':3047,'multiline':False]['text':' Scripting supported for opsets > 8. See test_interpolate_upsample','line_number':3053,'multiline':False]['text':' testing whether it uses "half_pixel" or "pytorch_half_pixel"','line_number':3094,'multiline':False]['text':' see https://github.com/onnx/onnx/blob/main/docs/Operators.md#Resize','line_number':3095,'multiline':False]['text':' scripting raises OnnxRuntimeError','line_number':3153,'multiline':False]['text':' the arithmeticOps(Add\Sub\Mul\Div\Gemm\Pow\Mod) with low precision include unit8 will be failed in ORT','line_number':3295,'multiline':False]['text':' add to(dtype=torch.long) to avoid ORT output type does not match expected type.','line_number':3296,'multiline':False]['text':' will be fixed in ONNX version 14.','line_number':3297,'multiline':False]['text':' fmod was added in version 10','line_number':3378,'multiline':False]['text':' uint8 not implemented in ORT for Mul used in','line_number':3727,'multiline':False]['text':' exporting bitshift for opset_version < 10','line_number':3728,'multiline':False]['text':' When sorted=False, order of elements in the outout tensors','line_number':3859,'multiline':False]['text':' are not expected to match between PyTorch and ORT','line_number':3860,'multiline':False]['text':' Python builtin apply of FunctionMeta object is currently not supported in Torchscript.','line_number':3880,'multiline':False]['text':' Clip op min is an input since opset 11.','line_number':3881,'multiline':False]['text':' TODO(justinchuby): Remove reference to internal names in symbolic_helper','line_number':3905,'multiline':False]['text':' TODO(bowbao): There is a slight gap in today's test infrastructure','line_number':3971,'multiline':False]['text':' to directly test aten ops. OpInfo `torch.norm`` in `common_methods_invocations.py`','line_number':3972,'multiline':False]['text':' will not decompose to below aten op.','line_number':3973,'multiline':False]['text':' As layer_norm works on the last D dimension, please keep','line_number':3982,'multiline':False]['text':' this test case at least three dimension to prevent the','line_number':3983,'multiline':False]['text':' situation of axis=2 mapping to the same axis as axis=-2','line_number':3984,'multiline':False]['text':' Because ConstantOfShape op is not supported for opset < 9','line_number':4044,'multiline':False]['text':' Because ConstantOfShape op is not supported for opset < 9','line_number':4063,'multiline':False]['text':' Because ConstantOfShape op is not supported for opset < 9','line_number':4082,'multiline':False]['text':' Tests the case when scalar src (updates values) type is different','line_number':4114,'multiline':False]['text':' from self type. Happens only with scalar src - PyTorch does not','line_number':4115,'multiline':False]['text':' allow this when src is a tensor.','line_number':4116,'multiline':False]['text':' Scripting error: Cannot instantiate nn module','line_number':4338,'multiline':False]['text':' torch.nn.Embedding is converted to ONNX::Gather.','line_number':4344,'multiline':False]['text':' Constant folding will be triggerred for constant inputs.','line_number':4345,'multiline':False]['text':' This pattern is common for constant mask inputs in transformer models.','line_number':4346,'multiline':False]['text':' shape is of rank 0','line_number':4350,'multiline':False]['text':' shape is of rank 0','line_number':4365,'multiline':False]['text':' index_put is supported in opsets >= 11','line_number':4422,'multiline':False]['text':' torch.mean only supports float types','line_number':4487,'multiline':False]['text':' torch.mean only supports float types','line_number':4503,'multiline':False]['text':' ORT does not support double ReduceProd for double','line_number':4504,'multiline':False]['text':' torch.prod not implemented for Half','line_number':4509,'multiline':False]['text':' verify with different input of same batch size','line_number':4735,'multiline':False]['text':' verify with different input of different batch size','line_number':4759,'multiline':False]['text':' float equal added after opset 11','line_number':5248,'multiline':False]['text':' Argmin and Argmax with "select_last_index" is not supprted before opset 12','line_number':5373,'multiline':False]['text':' "select_last_index" was added in opset 12 to deal with corner case where the','line_number':5374,'multiline':False]['text':' same value appears multiple times in the tensor','line_number':5375,'multiline':False]['text':' input of rank 2','line_number':5636,'multiline':False]['text':' input of rank 3','line_number':5642,'multiline':False]['text':' addmm for 3-d inputs converts to onnx::MatMul','line_number':5650,'multiline':False]['text':' addmm for 2-d inputs converts to onnx::Gemm','line_number':5655,'multiline':False]['text':' addmm for 3-d inputs converts to onnx::MatMul','line_number':5674,'multiline':False]['text':' addmm for 2-d inputs converts to onnx::Gemm','line_number':5679,'multiline':False]['text':' flatten with 4d input','line_number':5691,'multiline':False]['text':' flatten with 0d input','line_number':5695,'multiline':False]['text':' flatten with 1d input','line_number':5699,'multiline':False]['text':' this will create prim::ListConstruct(x, y, z) + aten::__getitem__','line_number':5747,'multiline':False]['text':' torch.nonzero(x, as_tuple=True) is not scriptable.','line_number':5771,'multiline':False]['text':' scripting tests run for opsets > 11. See: test_split_script','line_number':5850,'multiline':False]['text':' Need onnx::Identity of sequence in opset 14','line_number':6200,'multiline':False]['text':' test with output indexing.','line_number':6388,'multiline':False]['text':' test split on specific dim.','line_number':6390,'multiline':False]['text':' test split on specific dim and output indexing.','line_number':6392,'multiline':False]['text':' test with out of bound end index (5).','line_number':6394,'multiline':False]['text':' Other test inputs to test dynamic behavior','line_number':6452,'multiline':False]['text':' Other test inputs to test dynamic behavior','line_number':6467,'multiline':False]['text':' Other test inputs to test dynamic behavior','line_number':6482,'multiline':False]['text':' Other test inputs to test dynamic behavior','line_number':6497,'multiline':False]['text':' Other test inputs to test dynamic behavior','line_number':6512,'multiline':False]['text':' Other test inputs to test dynamic behavior','line_number':6527,'multiline':False]['text':' torch.zeros/torch.ones with size tensor of dim != 0 not scriptable.','line_number':6596,'multiline':False]['text':' used in loop, altered.','line_number':6786,'multiline':False]['text':' not used in loop, should be altered.','line_number':6787,'multiline':False]['text':' used in loop, not be altered.','line_number':6788,'multiline':False]['text':' not used in loop, should not be altered.','line_number':6789,'multiline':False]['text':' TODO: value for a_ref is incorrect.','line_number':6809,'multiline':False]['text':' a_ref += torch.ones(12,)','line_number':6810,'multiline':False]['text':' Need onnx::Identity of sequence in opset 14','line_number':6891,'multiline':False]['text':' Sort with dynamic dim not supported in ONNX','line_number':6928,'multiline':False]['text':' Sort with dynamic dim not supported in ONNX','line_number':6941,'multiline':False]['text':' add is used for exporting full','line_number':7134,'multiline':False]['text':' 'scale' is exported as onnx float32 rank 0 tensor.','line_number':7155,'multiline':False]['text':' The following 'Mul' should NOT be promoted to float32.','line_number':7156,'multiline':False]['text':' MatMul long inputs is added in ONNX opset 9.','line_number':7260,'multiline':False]['text':' MatMul long inputs is added in ONNX opset 9.','line_number':7274,'multiline':False]['text':' SpectralNorm not TorchScript compatible.','line_number':7288,'multiline':False]['text':' error in propagate as assign input shape','line_number':7583,'multiline':False]['text':' scripting prim::Uninitialized, prim::dtype, prim::unchecked_cast','line_number':7644,'multiline':False]['text':' ONNX supports bfloat16 for opsets >= 13','line_number':7857,'multiline':False]['text':' Dynamic padding is added in opset 11','line_number':8195,'multiline':False]['text':' Test for different pad integer types','line_number':8197,'multiline':False]['text':' Test for different pad integer types','line_number':8217,'multiline':False]['text':' TODO: the logic in symbolic_opset9 doesn't handle script','line_number':8242,'multiline':False]['text':' onnx::Identity of sequence supported for ONNX opset >= 14','line_number':8414,'multiline':False]['text':' onnx::Identity of sequence supported for ONNX opset >= 14','line_number':8429,'multiline':False]['text':' onnx::Identity of sequence supported for ONNX opset >= 14','line_number':8449,'multiline':False]['text':' if x.size(0) != 3, ORT will throw type error.','line_number':8456,'multiline':False]['text':' onnx::Identity of sequence supported for ONNX opset >= 14','line_number':8471,'multiline':False]['text':' Sequence type as loop-carried dependencies only supported for ONNX opset >= 13','line_number':8495,'multiline':False]['text':' This test checks output scalar type in the ONNX graph should not be null','line_number':8691,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/28607','line_number':8692,'multiline':False]['text':' moveaxis is an alias of movedim; thus, mostly copied from `test_movedim`.','line_number':8786,'multiline':False]['text':' using test data containing default ignore_index=-100','line_number':9089,'multiline':False]['text':' using test data containing default ignore_index=-100','line_number':9110,'multiline':False]['text':' using test data containing default ignore_index=-100','line_number':9131,'multiline':False]['text':' using test data containing default ignore_index=-100','line_number':9152,'multiline':False]['text':' using test data containing default ignore_index=-100','line_number':9173,'multiline':False]['text':' Because where op is not supported for opset < 9.','line_number':9405,'multiline':False]['text':' Because where op is not supported for opset < 9.','line_number':9418,'multiline':False]['text':' ONNX IsInf op is added in opset 10.','line_number':9431,'multiline':False]['text':' ONNX IsNaN op is added in opset 9.','line_number':9449,'multiline':False]['text':' ONNX IsNaN, IsInf op is added in opset 9, 10 respectively.','line_number':9460,'multiline':False]['text':' scripting tests run for opsets > 11. See: test_where_condition_script','line_number':9739,'multiline':False]['text':' Scripting fails for add lists for opsets < 11. Chek test_derive_index_scripting','line_number':9835,'multiline':False]['text':' test that the model still runs with a different batch size','line_number':10142,'multiline':False]['text':' test that the model still runs with a different batch size','line_number':10218,'multiline':False]['text':' test that the model still runs with a different batch size','line_number':10368,'multiline':False]['text':' Quantize twice to test differnet branches','line_number':10411,'multiline':False]['text':' RuntimeError: Can't redefine method:','line_number':10423,'multiline':False]['text':' forward on class: __torch__.torch.nn.modules.linear.Linear','line_number':10424,'multiline':False]['text':' Fake quantize activation is a special case, as it restricts quantized range to be (0, 127),','line_number':10444,'multiline':False]['text':' while standard 8bit quantization range is (-128, 127) or (0, 255).','line_number':10445,'multiline':False]['text':' Set fixed weight, bias and inputs to test if ONNX handles the overflow correctly.','line_number':10446,'multiline':False]['text':' ensure there are no zeros in the input','line_number':10727,'multiline':False]['text':' dict_check=False,','line_number':11028,'multiline':False]['text':' TODO: Opset 16 RoiAlign result mismatch','line_number':11031,'multiline':False]['text':' NOTE: `is not None` and `assert` is for passing torchscript.','line_number':11319,'multiline':False]['text':' Workaround placeholder for TorchScript','line_number':11371,'multiline':False]['text':' generate empty prev_state, if None is provided','line_number':11401,'multiline':False]['text':' generate empty prev_state, if None is provided','line_number':11454,'multiline':False]['text':' generate empty prev_state, if None is provided','line_number':11521,'multiline':False]['text':' generate empty prev_state, if None is provided','line_number':11567,'multiline':False]['text':' generate empty prev_state, if None is provided','line_number':11614,'multiline':False]['text':' generate empty prev_state, if None is provided','line_number':11746,'multiline':False]['text':' ConstantOfShape is tested in test_embedding_bag','line_number':11855,'multiline':False]['text':' Tile is tested in test_repeat','line_number':11856,'multiline':False]['text':' test Shape, Reshape, Transpose, Gather','line_number':11857,'multiline':False]['text':' shape [4], ("batch", 3, 4, -1)','line_number':11860,'multiline':False]['text':' batch, 3, 4, 10/batch','line_number':11861,'multiline':False]['text':' test prim::ListConstruct for Reshape input 1','line_number':11885,'multiline':False]['text':' test Range','line_number':11900,'multiline':False]['text':' test NonZero','line_number':11933,'multiline':False]['text':' test If','line_number':11957,'multiline':False]['text':' test Range','line_number':11977,'multiline':False]['text':' NOTE: For quantization tests, choose scale and zero point carefully','line_number':12645,'multiline':False]['text':'       such that inputs and outputs do not always overflow/underflow.','line_number':12646,'multiline':False]['text':'       Otherwise test results could be inaccurate.','line_number':12647,'multiline':False]['text':' Set fixed weight to avoid flaky test.','line_number':12651,'multiline':False]['text':' Set non-zero bias.','line_number':12655,'multiline':False]['text':' Set fixed input to avoid flaky test.','line_number':12658,'multiline':False]['text':' Manually initialize model weight and bias to random numbers.','line_number':12667,'multiline':False]['text':' By default all zeros.','line_number':12668,'multiline':False]['text':' Manually initialize model weight and bias to random numbers.','line_number':12681,'multiline':False]['text':' By default all zeros.','line_number':12682,'multiline':False]['text':' Manually initialize model weight and bias to random numbers.','line_number':12696,'multiline':False]['text':' By default all zeros.','line_number':12697,'multiline':False]['text':' Manually initialize model weight and bias to random numbers.','line_number':12717,'multiline':False]['text':' By default all zeros.','line_number':12718,'multiline':False]['text':' Manually initialize model weight and bias to random numbers.','line_number':12731,'multiline':False]['text':' By default all zeros.','line_number':12732,'multiline':False]['text':' Manually initialize model weight and bias to random numbers.','line_number':12748,'multiline':False]['text':' By default all zeros.','line_number':12749,'multiline':False]['text':' Manually initialize model weight and bias to random numbers.','line_number':12764,'multiline':False]['text':' By default all zeros.','line_number':12765,'multiline':False]['text':' Manually initialize model weight and bias to random numbers.','line_number':12780,'multiline':False]['text':' By default all zeros.','line_number':12781,'multiline':False]['text':' Manually initialize model weight and bias to random numbers.','line_number':12797,'multiline':False]['text':' By default all zeros.','line_number':12798,'multiline':False]['text':' torch.jit.frontend.FrontendError: Cannot instantiate class 'QFunctional' in a script function:','line_number':12926,'multiline':False]['text':' torch.jit.frontend.FrontendError: Cannot instantiate class 'QFunctional' in a script function:','line_number':12979,'multiline':False]['text':' torch.jit.frontend.FrontendError:','line_number':12988,'multiline':False]['text':' Cannot instantiate class 'QFunctional' in a script function','line_number':12989,'multiline':False]['text':' Set fixed weight and bias to avoid flaky test.','line_number':13055,'multiline':False]['text':' Set fixed input to avoid flaky test.','line_number':13062,'multiline':False]['text':' Set fixed weight and bias to avoid flaky test.','line_number':13130,'multiline':False]['text':' Set fixed input to avoid flaky test.','line_number':13137,'multiline':False]['text':' Set fixed weight and bias to avoid flaky test.','line_number':13163,'multiline':False]['text':' Set fixed input to avoid flaky test.','line_number':13170,'multiline':False]['text':' Set fixed weight and bias to avoid flaky test.','line_number':13197,'multiline':False]['text':' Set fixed input to avoid flaky test.','line_number':13204,'multiline':False]['text':' Set fixed weight and bias to avoid flaky test.','line_number':13231,'multiline':False]['text':' Set fixed input to avoid flaky test.','line_number':13238,'multiline':False]['text':' Set fixed input to avoid flaky test.','line_number':13262,'multiline':False]['text':' Scale and Zero-point must be a scalar in ORT:optimization','line_number':13267,'multiline':False]['text':' ONNX Opset 16 GridSample with 5D volumetric input is not supported.','line_number':13395,'multiline':False]['text':' PyTorch grid_sample "bicubic" mode does not support 5D volumetric input.','line_number':13404,'multiline':False]['text':' Need scripting to preserve control flow for this test to be','line_number':13461,'multiline':False]['text':' meaningful.','line_number':13462,'multiline':False]['text':' Ensure condition is not constant','line_number':13472,'multiline':False]['text':' Both branches output types should match.','line_number':13483,'multiline':False]['text':' Ensure condition is not constant','line_number':13492,'multiline':False]['text':' exercise both Tensor.device (prim::device)','line_number':13521,'multiline':False]['text':' and torch.device (prim::Constant).','line_number':13522,'multiline':False]['text':' preserve control flow','line_number':13527,'multiline':False]['text':' In order for the ONNX model behavior to match the torch model, we','line_number':13531,'multiline':False]['text':' need to construct input that has the same device that is checked for','line_number':13532,'multiline':False]['text':' in forward(). In ONNX there is no such thing as a device, so the if','line_number':13533,'multiline':False]['text':' condition is always false.','line_number':13534,'multiline':False]['text':' Force dynamic axes so that the output shape depends on the input.','line_number':13536,'multiline':False]['text':' Otherwise the entire model will just return a constant and not have','line_number':13537,'multiline':False]['text':' any inputs.','line_number':13538,'multiline':False]['text':' 'print' has side effect calling 'resolve_conj' and 'resolve_neg'.','line_number':13564,'multiline':False]['text':' 'tolist' has side effect calling 'resolve_conj' and 'resolve_neg'.','line_number':13567,'multiline':False]['text':' Annotation added to pass torch script.','line_number':13568,'multiline':False]['text':' Input','line_number':13595,'multiline':False]['text':' Cannot export with older opsets because of "ConstantFill" op','line_number':13639,'multiline':False]['text':' ConstantFill was a temp op removed at opset 8. This is no longer supported by onnxruntime','line_number':13640,'multiline':False]['text':' There are still some issues prevent us from enabling script test for these scenarios:','line_number':13641,'multiline':False]['text':' test_gru_*:','line_number':13642,'multiline':False]['text':'   Operator aten::as_tensor is not supported by exporter yet.','line_number':13643,'multiline':False]['text':'       - https://msdata.visualstudio.com/Vienna/_workitems/edit/1055382','line_number':13644,'multiline':False]['text':'   Operator aten::_pack_padded_sequence is not supported by exporter yet.','line_number':13645,'multiline':False]['text':'       - https://msdata.visualstudio.com/Vienna/_workitems/edit/1055384','line_number':13646,'multiline':False]['text':' test_elman_*:','line_number':13647,'multiline':False]['text':' Compiling in script mode fails with errors like:','line_number':13648,'multiline':False]['text':'   torch.jit.frontend.UnsupportedNodeError: annotated assignments','line_number':13649,'multiline':False]['text':'   without assigned value aren't supported','line_number':13650,'multiline':False]['text':'       - https://msdata.visualstudio.com/Vienna/_workitems/edit/1160723','line_number':13651,'multiline':False]['text':' test_lstm_*:','line_number':13652,'multiline':False]['text':'   Compiling in script mode fails with errors like:','line_number':13653,'multiline':False]['text':'   RuntimeError: Arguments for call are not valid.','line_number':13654,'multiline':False]['text':'       - https://msdata.visualstudio.com/Vienna/_workitems/edit/1160723','line_number':13655,'multiline':False]