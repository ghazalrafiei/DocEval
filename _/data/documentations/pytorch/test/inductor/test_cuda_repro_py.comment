['text':' Owner(s): ["module: inductor"]','line_number':1,'multiline':False]['text':' noqa: TRY200','line_number':31,'multiline':False]['text':' https://github.com/pytorch/torchdynamo/issues/1681#issuecomment-1283433527','line_number':106,'multiline':False]['text':' TODO: Abstract this out, test more extensively','line_number':219,'multiline':False]['text':' Needed since everywhere else uses "inductor"','line_number':222,'multiline':False]['text':' https://github.com/pytorch/torchdynamo/issues/1850','line_number':290,'multiline':False]['text':' TODO: this is broken, fix later','line_number':299,'multiline':False]['text':' out = foo_opt(inpt)','line_number':300,'multiline':False]['text':' out.add_(2)','line_number':301,'multiline':False]['text':' self.assertEqual(out_ref, out)','line_number':305,'multiline':False]['text':' force autotune by setting save_cache_hook to False','line_number':391,'multiline':False]['text':' This minified testcase comes from detectron2_maskrcnn_r_50_fpn','line_number':439,'multiline':False]['text':' There was a false error from our size_assert code','line_number':440,'multiline':False]['text':' The indirect indexing via a scalar like below used to lead to','line_number':456,'multiline':False]['text':' bad triton code that made triton segfault when compiling.','line_number':457,'multiline':False]['text':' See https://github.com/pytorch/torchdynamo/issues/1515','line_number':458,'multiline':False]['text':' Repro from alibi relative encodings','line_number':573,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/96406','line_number':741,'multiline':False]['text':' Inductor claims the output layout of gelu's saved variable for','line_number':770,'multiline':False]['text':' backwards will be (4096, 4096, 1) but in actuality it is (4096,','line_number':771,'multiline':False]['text':' 2097152, 1).  Fortunately this doesn't actually matter in practice.','line_number':772,'multiline':False]['text':' NOTE: 6 dimensions is important! does not fail for 5 dimensions','line_number':832,'multiline':False]['text':' NOTE: tensors of all the same value are constant folded, so we','line_number':869,'multiline':False]['text':' need a tensor with two distinct values','line_number':870,'multiline':False]['text':' run it twice to test cuda graph issue','line_number':962,'multiline':False]['text':' run it twice to test cuda graph issue','line_number':982,'multiline':False]['text':' run it twice to test cuda graph issue','line_number':1047,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/104937','line_number':1053,'multiline':False]