['text':' Owner(s): ["module: inductor"]','line_number':1,'multiline':False]['text':' The dict value is match_nodes(computation_op+unary_op)','line_number':32,'multiline':False]['text':' The dict value is (match_count, match_nodes, inplace)','line_number':55,'multiline':False]['text':' call_function','line_number':57,'multiline':False]['text':' call_function','line_number':58,'multiline':False]['text':' call_method','line_number':59,'multiline':False]['text':' call_method','line_number':60,'multiline':False]['text':' call_function','line_number':61,'multiline':False]['text':' call_method','line_number':62,'multiline':False]['text':' call_method','line_number':63,'multiline':False]['text':' Skip due to reduce range setting for Quantization on preCI system.','line_number':191,'multiline':False]['text':' Add 1 for weight packing pass.','line_number':230,'multiline':False]['text':' Has extra dtype conversion nodes for autocast.','line_number':233,'multiline':False]['text':' only fuse for linear when the dtype is bf16','line_number':265,'multiline':False]['text':' packing pass + unary fusion.','line_number':268,'multiline':False]['text':' Add 1 for weight packing pass.','line_number':270,'multiline':False]['text':' Has extra dtype conversion nodes for autocast.','line_number':273,'multiline':False]['text':' packing pass.','line_number':292,'multiline':False]['text':' Add 1 for weight packing pass.','line_number':327,'multiline':False]['text':' Has extra dtype conversion nodes for autocast.','line_number':330,'multiline':False]['text':' addmm(mm) + (linear+add)','line_number':401,'multiline':False]['text':' view + linear + view(joint_graph+freeze pass)','line_number':406,'multiline':False]['text':' TODO - assert fusions work code','line_number':415,'multiline':False]['text':' llama pattern.','line_number':418,'multiline':False]['text':' 1. view(match_count=4, match_nodes=4).','line_number':433,'multiline':False]['text':' 2. mm to packed linear(match_count=2, match_nodes=2).','line_number':434,'multiline':False]['text':' 3. view+linear+view to linear(match_count=2, match_nodes=6).','line_number':435,'multiline':False]['text':' 4. linear+silu fusion(match_count=1, match_nodes=5)','line_number':436,'multiline':False]['text':' 5. linear+relu fusion(match_count=1, match_nodes=2)','line_number':437,'multiline':False]['text':' 1. Dequant-Conv2D pattern matched in QConv2D weight prepack * 1','line_number':460,'multiline':False]['text':'    int8_mixed_fp32: [convert_element_type_1, sub, mul_1, dequantize_per_channel, clone, convolution]','line_number':461,'multiline':False]['text':'    int8_mixed_bf16: [convert_element_type_1, sub, mul_1, optional(convert_element_type_4),','line_number':462,'multiline':False]['text':'     dequantize_per_channel, optional(convert_element_type_3), clone, convolution]','line_number':463,'multiline':False]['text':' 1. Dequant-Conv2D pattern matched in quantization weight prepack * 2','line_number':523,'multiline':False]['text':' 2. QConv2D Unary fusion in post-grad fusion pass * 2','line_number':527,'multiline':False]['text':' 1. Dequant-Conv2D pattern matched in quantization weight prepack * 4','line_number':627,'multiline':False]['text':' 2. Qconv2d Binary Unary fusion in post-grad fusion pass * 2','line_number':631,'multiline':False]['text':' Shouldn't hit conv binary fusion','line_number':704,'multiline':False]['text':' 1. Dequant-conv pattern matched in quantization weight prepack * 1','line_number':740,'multiline':False]['text':'    [convert_element_type_1, sub, mul_1, dequantize_per_channel, clone, convolution]','line_number':741,'multiline':False]['text':' 2. QConv2D Unary fusion in post-grad fusion pass * 1','line_number':748,'multiline':False]['text':'    [qconv2d_pointwise_default, div_1, round_2, add_1, clamp_min_1, clamp_max_1, convert_element_type_2]','line_number':749,'multiline':False]['text':' 1. Dequant-conv pattern matched in quantization weight prepack * 1','line_number':786,'multiline':False]['text':'    [convert_element_type_1, sub, mul_1, dequantize_per_channel, clone, convolution]','line_number':787,'multiline':False]['text':' 2. QConv2D Unary fusion in post-grad fusion pass * 1','line_number':791,'multiline':False]['text':'    [qconv2d_pointwise_default, relu, div_1, round_2, add_1, clamp_min_1, clamp_max_1, convert_element_type_2]','line_number':792,'multiline':False]['text':' 1. Dequant-conv pattern matched in quantization weight prepack * 2','line_number':868,'multiline':False]['text':'    [convert_element_type_1, sub, mul_1, dequantize_per_channel, clone, convolution]','line_number':869,'multiline':False]['text':' 2. Qconv2d Binary fusion in post-grad fusion pass * 1','line_number':876,'multiline':False]['text':'    [qconv2d_pointwise_default_1, convert_element_type_5, sub_2, mul_5, add_3, mul_6, round_4, add_4,','line_number':877,'multiline':False]['text':'     clamp_min_3, clamp_max_3, convert_element_type_6]','line_number':878,'multiline':False]['text':' 1. Dequant-conv pattern matched in quantization weight prepack * 2','line_number':928,'multiline':False]['text':'    [convert_element_type_1, sub, mul_1, dequantize_per_channel, clone, convolution]','line_number':929,'multiline':False]['text':' 2. Qconv2d Binary fusion in post-grad fusion pass * 1','line_number':936,'multiline':False]['text':'    [qconv2d_pointwise_default_1, convert_element_type_5, sub_2, mul_5, add_3, relu, mul_6, round_4, add_4,','line_number':937,'multiline':False]['text':'     clamp_min_3, clamp_max_3, convert_element_type_6]','line_number':938,'multiline':False]['text':' 1. Dequant pattern matcher for dequant promotion * 1','line_number':986,'multiline':False]['text':'    [convert_element_type_3, sub_1, mul_3]','line_number':987,'multiline':False]['text':' 2. Dequant-conv pattern matched in quantization weight prepack * 3','line_number':990,'multiline':False]['text':'    [convert_element_type_1, sub, mul_1, dequantize_per_channel, clone, convolution]','line_number':991,'multiline':False]['text':' 3. Qconv2d Binary fusion in post-grad fusion pass * 1','line_number':998,'multiline':False]['text':'    [qconv2d_pointwise_default_1, add_3]','line_number':999,'multiline':False]['text':' 1. dequant-linear pattern matched in quantization weight prepack','line_number':1093,'multiline':False]['text':' 2. QLinear Unary fusion in post-grad fusion pass','line_number':1097,'multiline':False]['text':' 1. Dequant pattern matcher for dequant promotion * 1','line_number':1169,'multiline':False]['text':' 2. dequant-linear pattern matched in quantization weight prepack * 3','line_number':1171,'multiline':False]['text':' 3. QLinear Unary fusion in post-grad fusion pass * 1','line_number':1175,'multiline':False]['text':' Totally 6 pattern_matcher_count, 31 pattern_matcher_nodes','line_number':1329,'multiline':False]['text':' 1. Pair of to_int8 and to_fp32 * 3, matched in pointless_convert pass at','line_number':1330,'multiline':False]['text':'    torch/_inductor/fx_passes/joint_graph.py: [convert_element_type, convert_element_type_1]','line_number':1331,'multiline':False]['text':' 2. Dequant-conv pattern matched in quantization weight prepack * 1','line_number':1332,'multiline':False]['text':'    [convert_element_type_1, sub, mul_1, dequantize_per_channel, clone, convolution]','line_number':1333,'multiline':False]['text':' 3. qconv2d_relu fusion in post-grad fusion pass * 1','line_number':1334,'multiline':False]['text':'    [qconv2d_pointwise_default, relu, mul_2, round_2, add_1, clamp_min_1, clamp_max_1, convert_element_type_2]','line_number':1335,'multiline':False]['text':' 4. qmaxpool2d * 1','line_number':1336,'multiline':False]['text':'    [convert_element_type_3, sub_1, mul_3, max_pool2d_with_indices, getitem, mul_4, round_3, add_2,','line_number':1337,'multiline':False]['text':'    clamp_min_2, clamp_max_2, convert_element_type_4]','line_number':1338,'multiline':False]['text':' Totally 10 pattern_matcher_count, 49 pattern_matcher_nodes','line_number':1418,'multiline':False]['text':' 1. Pair of to_int8 and to_fp32 * 5, matched in pointless_convert pass at','line_number':1419,'multiline':False]['text':'    torch/_inductor/fx_passes/joint_graph.py: [convert_element_type, convert_element_type_1]','line_number':1420,'multiline':False]['text':' 2. Dequant-conv pattern matched in quantization weight prepack * 2','line_number':1421,'multiline':False]['text':'    [convert_element_type_1, sub, mul_1, dequantize_per_channel, clone, convolution]','line_number':1422,'multiline':False]['text':' 3. qconv2d fusion in post-grad fusion pass * 2','line_number':1423,'multiline':False]['text':'    [qconv2d_pointwise_default, mul_2, round_2, add_1, clamp_min_1, clamp_max_1, convert_element_type_2]','line_number':1424,'multiline':False]['text':' 4. qcat * 1','line_number':1425,'multiline':False]['text':'    [convert_element_type_3, sub_1, mul_3, convert_element_type_7, sub_3, mul_7, cat, mul_8, round_5,','line_number':1426,'multiline':False]['text':'    add_4, clamp_min_4, clamp_max_4, convert_element_type_8]','line_number':1427,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/99841.','line_number':1436,'multiline':False]['text':' check works for min_value > max_value.','line_number':1451,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/99838.','line_number':1478,'multiline':False]['text':' Written buffer is graph input, we can't fuse inplace.','line_number':1527,'multiline':False]['text':' Written buffer is an alias tensor, we can't fuse inplace.','line_number':1539,'multiline':False]['text':' we don't support alpha !=1 case or other has different size with conv's output.','line_number':1568,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/100802.','line_number':1580,'multiline':False]['text':' we can't do the fusion when add's inputs are same tensor.','line_number':1581,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/101374.','line_number':1594,'multiline':False]['text':' we can't do the fusion when add's inputs are mixed dtype.','line_number':1595,'multiline':False]['text':' case1','line_number':1620,'multiline':False]['text':' case2:','line_number':1624,'multiline':False]['text':' case3:','line_number':1627,'multiline':False]['text':' We don't support conv_transpose2d for now.','line_number':1750,'multiline':False]['text':' llama pattern.','line_number':1767,'multiline':False]['text':' 1. view(match_count=4, match_nodes=4).','line_number':1782,'multiline':False]['text':' 2. mm to packed linear(match_count=2, match_nodes=2).','line_number':1783,'multiline':False]['text':' 3. view+linear+view to linear(match_count=2, match_nodes=6).','line_number':1784,'multiline':False]