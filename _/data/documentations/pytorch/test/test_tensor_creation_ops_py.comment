['text':' Owner(s): ["module: tensor creation"]','line_number':1,'multiline':False]['text':' TODO: replace with make_tensor','line_number':33,'multiline':False]['text':' work around torch.randn not being implemented for bfloat16','line_number':39,'multiline':False]['text':' Use extremal values','line_number':47,'multiline':False]['text':' TODO: replace with make_tensor','line_number':64,'multiline':False]['text':' Test suite for tensor creation ops','line_number':71,'multiline':False]['text':'','line_number':72,'multiline':False]['text':' Includes creation functions like torch.eye, random creation functions like','line_number':73,'multiline':False]['text':'   torch.rand, and *like functions like torch.ones_like.','line_number':74,'multiline':False]['text':' DOES NOT INCLUDE view ops, which are tested in TestViewOps (currently in','line_number':75,'multiline':False]['text':'   test_torch.py) OR numpy interop (which is also still tested in test_torch.py)','line_number':76,'multiline':False]['text':'','line_number':77,'multiline':False]['text':' See https://pytorch.org/docs/master/torch.html#creation-ops','line_number':78,'multiline':False]['text':' Note: no negative uint8 values','line_number':119,'multiline':False]['text':' Note: see https://github.com/pytorch/pytorch/issues/37398','line_number':122,'multiline':False]['text':' for why this is necessary.','line_number':123,'multiline':False]['text':' large tensor','line_number':162,'multiline':False]['text':' roll a loop until back where started','line_number':188,'multiline':False]['text':' multiple inverse loops','line_number':191,'multiline':False]['text':' test non-contiguous','line_number':195,'multiline':False]['text':' strided equivalent to numbers.as_strided(size=(4, 2), stride=(1, 4))','line_number':196,'multiline':False]['text':' test roll with no dimension specified','line_number':204,'multiline':False]['text':' test roll over multiple dimensions','line_number':209,'multiline':False]['text':' shifts/dims should align','line_number':217,'multiline':False]['text':' test bool tensor','line_number':221,'multiline':False]['text':' test complex tensor','line_number':227,'multiline':False]['text':' Basic sanity test','line_number':236,'multiline':False]['text':' Test offset','line_number':242,'multiline':False]['text':' Test where input has more than one dimension','line_number':248,'multiline':False]['text':' Noncontig input','line_number':254,'multiline':False]['text':' Complex number support','line_number':261,'multiline':False]['text':' Test pairs of different dtypes','line_number':326,'multiline':False]['text':' windows scipy block_diag returns int32 types','line_number':391,'multiline':False]['text':' FIXME: this is legacy behavior and should be removed','line_number':482,'multiline':False]['text':' when we support empty tensors with arbitrary sizes','line_number':483,'multiline':False]['text':' Case:','line_number':520,'multiline':False]['text':' Reference: https://github.com/pytorch/pytorch/issues/49878','line_number':521,'multiline':False]['text':' Test concat on dimension 0','line_number':553,'multiline':False]['text':' Note that there is no guarantee that slicing here will result in','line_number':557,'multiline':False]['text':' contiguous tensors','line_number':558,'multiline':False]['text':' If inputs are contiguous tensors, then fast concat paths will be invoked','line_number':562,'multiline':False]['text':' Test concat on dimension 1','line_number':565,'multiline':False]['text':' Note that the tensor in w_slices[] here may not be a contiguous','line_number':568,'multiline':False]['text':' tensor and we need to make sure this is not broken by fast concat','line_number':569,'multiline':False]['text':' If inputs are contiguous tensors, then fast concat paths will be invoked','line_number':573,'multiline':False]['text':' Finally, we need to make sure backward is not broken','line_number':576,'multiline':False]['text':' Integral types will not have grad','line_number':577,'multiline':False]['text':' All the new tensors should be contiguous here. Let us make sure','line_number':587,'multiline':False]['text':' to explicitly set them contiguous to enforce fast cat','line_number':588,'multiline':False]['text':' Size larger than grain size.','line_number':628,'multiline':False]['text':' discontiguous channels-last inputs','line_number':646,'multiline':False]['text':' Case 1: if out= is the correct shape then the memory format of out= is respected','line_number':665,'multiline':False]['text':' Case 2: if out= is not the correct shape then the output it is resized internally','line_number':676,'multiline':False]['text':' - For both CPU and CUDA variants, it only propagates memory format if all the tensors have','line_number':677,'multiline':False]['text':'   the same memory format, otherwise it just uses contiguous_format as a default','line_number':678,'multiline':False]['text':' a_cuda and b_cuda have different memory_format','line_number':681,'multiline':False]['text':' a_cuda and c_cuda have same memory_format','line_number':691,'multiline':False]['text':' Stack','line_number':701,'multiline':False]['text':' TODO: reconcile with other cat tests','line_number':709,'multiline':False]['text':' TODO: Compare with a NumPy reference instead of CPU','line_number':710,'multiline':False]['text':' TODO: update this test to compare against NumPy instead of CPU','line_number':733,'multiline':False]['text':' test half-to-even','line_number':738,'multiline':False]['text':' Note: This test failed on XLA since its test cases are created by empty_strided which','line_number':746,'multiline':False]['text':'       doesn't support overlapping sizes/strides in XLA impl','line_number':747,'multiline':False]['text':' Test like functions against tensoriterator based unary operator (exp) to','line_number':751,'multiline':False]['text':' make sure the returned tensor from like function follows the same stride propergation','line_number':752,'multiline':False]['text':' rule as what tensoriterator does for unary operator. The like function's  output strides','line_number':753,'multiline':False]['text':' is computed on CPU side always, no need to test GPU here.','line_number':754,'multiline':False]['text':' dense non-overlapping tensor,','line_number':772,'multiline':False]['text':' non-dense non-overlapping sliced tensor','line_number':773,'multiline':False]['text':' non-dense non-overlapping gapped tensor','line_number':774,'multiline':False]['text':' non-dense non-overlapping 0 strided tensor','line_number':775,'multiline':False]['text':' non-dense overlapping general tensor','line_number':776,'multiline':False]['text':' non-dense overlapping sliced tensor','line_number':777,'multiline':False]['text':' non-dense overlapping gapped tensor','line_number':778,'multiline':False]['text':' non-dense overlapping 0 strided tensor','line_number':779,'multiline':False]['text':' non-dense overlapping equal strides','line_number':780,'multiline':False]['text':' Test error for non-tuple argument','line_number':873,'multiline':False]['text':' Test error for a single array','line_number':877,'multiline':False]['text':' Test 0-D','line_number':881,'multiline':False]['text':' Create tensors with shape being different along one axis only','line_number':894,'multiline':False]['text':' Determine if input tensors have valid dimensions.','line_number':899,'multiline':False]['text':' Test whether all tensors have the same shape except in concatenating dimension','line_number':903,'multiline':False]['text':' Unless the number of dimensions is less than the corresponding at_least function dimension','line_number':904,'multiline':False]['text':' Since the original concatenating dimension would shift after applying at_least and would no','line_number':905,'multiline':False]['text':' longer be the concatenating dimension','line_number':906,'multiline':False]['text':' Special case for hstack is needed since hstack works differently when ndims is 1','line_number':910,'multiline':False]['text':' Valid dimensions, test against numpy','line_number':912,'multiline':False]['text':' Invalid dimensions, test for error','line_number':918,'multiline':False]['text':' Test torch.column_stack with combinations of 1D and 2D tensors input','line_number':932,'multiline':False]['text':' Test dimension change for 1D tensor of size (N) and 2D tensor of size (1, N)','line_number':951,'multiline':False]['text':' Test dimension change for 1D tensor of size (N), 2D tensor of size (1, N), and 3D tensor of size (1, N, 1)','line_number':966,'multiline':False]['text':' Test dimension change for 2D tensor of size (M, N) and 3D tensor of size (M, N, 1)','line_number':977,'multiline':False]['text':' Reference: https://github.com/pytorch/pytorch/issues/33111','line_number':999,'multiline':False]['text':' Checks that float->integer casts don't produce undefined behavior errors.','line_number':1015,'multiline':False]['text':' Note: In C++, casting from a floating value to an integral dtype','line_number':1016,'multiline':False]['text':' is undefined if the floating point value is not within the integral','line_number':1017,'multiline':False]['text':' dtype's dynamic range. This can (and should) cause undefined behavior','line_number':1018,'multiline':False]['text':' errors with UBSAN. These casts are deliberate in PyTorch, however, and','line_number':1019,'multiline':False]['text':' NumPy may have the same behavior.','line_number':1020,'multiline':False]['text':' Note: CUDA max float -> integer conversion is divergent on some dtypes','line_number':1030,'multiline':False]['text':' HIP min float -> int64 conversion is divergent','line_number':1035,'multiline':False]['text':' Note: CPU max float -> uint8 conversion is divergent','line_number':1040,'multiline':False]['text':' Note: numpy -2.0 or -1.5 -> uint8 conversion is undefined','line_number':1042,'multiline':False]['text':'       see https://github.com/pytorch/pytorch/issues/97794','line_number':1043,'multiline':False]['text':' Note: CUDA will fail this test on most dtypes, often dramatically.','line_number':1048,'multiline':False]['text':' TODO: re-enable this test','line_number':1056,'multiline':False]['text':' FIXME: Create an OpInfo-based tensor creation method test that verifies this for all tensor','line_number':1107,'multiline':False]['text':'   creation methods and verify all dtypes and layouts','line_number':1108,'multiline':False]['text':' TODO: update to work on CUDA, too','line_number':1117,'multiline':False]['text':' TODO: update to work on CUDA, too','line_number':1134,'multiline':False]['text':' test zero sized dimension','line_number':1198,'multiline':False]['text':' TODO: udpate to work on CUDA, too','line_number':1207,'multiline':False]['text':' method name, args','line_number':1212,'multiline':False]['text':' TODO: update to work on CUDA, too?','line_number':1229,'multiline':False]['text':' TODO: update to work on CUDA, too?','line_number':1252,'multiline':False]['text':' TODO: update to work on CUDA, too?','line_number':1276,'multiline':False]['text':' Shapes to the random tensors. Each line is a test case, and','line_number':1405,'multiline':False]['text':' each list within that line is the shape of a single','line_number':1406,'multiline':False]['text':' tensor. The shapes are restricted to 0D (represented by [])','line_number':1407,'multiline':False]['text':' and 1D tensors.','line_number':1408,'multiline':False]['text':' We also need to test the different indexing modes. We can't','line_number':1419,'multiline':False]['text':' just enumerate them because we don't presently support the','line_number':1420,'multiline':False]['text':' same modes as numpy.meshgrid, nor does our default','line_number':1421,'multiline':False]['text':' correspond to their default.','line_number':1422,'multiline':False]['text':'','line_number':1423,'multiline':False]['text':' TODO Eliminate this and replace it with a list of all','line_number':1424,'multiline':False]['text':' supported indexing modes when we have full compatibility.','line_number':1425,'multiline':False]['text':' No indexing in PyTorch corresponds to "ij" indexing in','line_number':1427,'multiline':False]['text':' NumPy.','line_number':1428,'multiline':False]['text':' No indexing in NumPy corresponds to "xy" indexing in','line_number':1431,'multiline':False]['text':' PyTorch.','line_number':1432,'multiline':False]['text':' "ij" and "xy" are implemented identically in both.','line_number':1435,'multiline':False]['text':' test 0 size input','line_number':1455,'multiline':False]['text':' test single input','line_number':1461,'multiline':False]['text':' test empty imput','line_number':1500,'multiline':False]['text':' Upcast','line_number':1537,'multiline':False]['text':' Downcast (sometimes)','line_number':1542,'multiline':False]['text':' This test is flaky with p<=(2/(ub-lb))^200=6e-36','line_number':1553,'multiline':False]['text':' Less strict checks because of rounding errors','line_number':1734,'multiline':False]['text':' TODO investigate rounding errors','line_number':1735,'multiline':False]['text':' Less strict checks because of rounding errors','line_number':1792,'multiline':False]['text':' TODO investigate rounding errors','line_number':1793,'multiline':False]['text':' TODO: this test should be updated','line_number':1827,'multiline':False]['text':' TODO: this test should be updated','line_number':1840,'multiline':False]['text':' TODO: this test should be updated','line_number':1892,'multiline':False]['text':' TODO: this test should be updated','line_number':1902,'multiline':False]['text':' TODO: this test should be updated','line_number':1931,'multiline':False]['text':' change the dtype, layout, device','line_number':1937,'multiline':False]['text':' leave them the same','line_number':1943,'multiline':False]['text':' TODO: this test should be updated','line_number':1951,'multiline':False]['text':' test boolean tensor','line_number':1958,'multiline':False]['text':' test chalf','line_number':1963,'multiline':False]['text':' TODO: this test should be updated','line_number':1967,'multiline':False]['text':' only floating-point types are supported as the default type','line_number':1980,'multiline':False]['text':' don't allow passing dtype to set_default_tensor_type','line_number':2001,'multiline':False]['text':' don't allow passing dtype to set_default_dtype','line_number':2004,'multiline':False]['text':' only floating-point types are supported as the default type','line_number':2006,'multiline':False]['text':' TODO: this test should be updated','line_number':2017,'multiline':False]['text':' Tensor constructor/new with Tensor argument shouldn't work with device specified','line_number':2028,'multiline':False]['text':' Tensor constructor/new with Tensor argument shouldn't work with device specified','line_number':2045,'multiline':False]['text':' TODO: this test should be updated','line_number':2061,'multiline':False]['text':' TODO: This test probably doesn't make too much sense now that','line_number':2065,'multiline':False]['text':' torch.tensor has been established for a while; it makes more','line_number':2066,'multiline':False]['text':' sense to test the legacy behavior in terms of the new behavior','line_number':2067,'multiline':False]['text':' test data','line_number':2069,'multiline':False]['text':' test copy','line_number':2077,'multiline':False]['text':' test copy with numpy','line_number':2087,'multiline':False]['text':' test boolean tensor','line_number':2095,'multiline':False]['text':' TODO: this test should be updated','line_number':2125,'multiline':False]['text':' test torch.tensor()','line_number':2138,'multiline':False]['text':' test tensor.new_tensor()','line_number':2143,'multiline':False]['text':' test torch.as_tensor()','line_number':2149,'multiline':False]['text':' not copy','line_number':2150,'multiline':False]['text':' copy and keep the graph','line_number':2151,'multiline':False]['text':' TODO: this test should be updated','line_number':2153,'multiline':False]['text':' np long, which can be 4 bytes (e.g. on windows)','line_number':2170,'multiline':False]['text':' TODO: this test should be updated','line_number':2183,'multiline':False]['text':' test data','line_number':2188,'multiline':False]['text':' test copy','line_number':2195,'multiline':False]['text':' test copy with numpy','line_number':2204,'multiline':False]['text':' TODO: this test should be updated','line_number':2235,'multiline':False]['text':' from python data','line_number':2238,'multiline':False]['text':' python data with heterogeneous types','line_number':2243,'multiline':False]['text':' python data with self-referential lists','line_number':2249,'multiline':False]['text':' from tensor (doesn't copy unless type is different)','line_number':2261,'multiline':False]['text':' doesn't copy','line_number':2271,'multiline':False]['text':' changing dtype causes copy','line_number':2279,'multiline':False]['text':' changing device causes copy','line_number':2286,'multiline':False]['text':' TODO: this test should be updated','line_number':2294,'multiline':False]['text':' Check range for non-contiguous tensors.','line_number':2305,'multiline':False]['text':' Check negative','line_number':2311,'multiline':False]['text':' Equal bounds','line_number':2317,'multiline':False]['text':' TODO: this test should be updated','line_number':2325,'multiline':False]['text':' TODO: this test should be updated','line_number':2332,'multiline':False]['text':' Use a larger number so vectorized code can be triggered','line_number':2335,'multiline':False]['text':' Vectorization on non-contiguous tensors','line_number':2341,'multiline':False]['text':' Check arange with only one argument','line_number':2347,'multiline':False]['text':' Check arange for non-contiguous tensors.','line_number':2352,'multiline':False]['text':' Check negative','line_number':2358,'multiline':False]['text':' Equal bounds','line_number':2364,'multiline':False]['text':' FloatTensor','line_number':2372,'multiline':False]['text':' DoubleTensor','line_number':2382,'multiline':False]['text':' Bool Input matching numpy semantics','line_number':2392,'multiline':False]['text':' Check that it's exclusive','line_number':2400,'multiline':False]['text':' NB: without the dtype, we'll infer output type to be int64','line_number':2422,'multiline':False]['text':' NB: without the dtype, we'll infer output type to be int64','line_number':2429,'multiline':False]['text':' Test Rounding Errors','line_number':2439,'multiline':False]['text':' check with step size','line_number':2450,'multiline':False]['text':' check that it holds a consistent output shape on precision-cornered step sizes','line_number':2462,'multiline':False]['text':' TODO: this test should be updated','line_number':2466,'multiline':False]['text':' end only','line_number':2470,'multiline':False]['text':' start, end, [step]','line_number':2479,'multiline':False]['text':' cannot call storage() on meta tensor','line_number':2499,'multiline':False]['text':' some of these cases are pretty strange, just verifying that if as_strided','line_number':2503,'multiline':False]['text':' allows them then empty_strided can as well.','line_number':2504,'multiline':False]['text':' as_strided checks the storage size is big enough to support such a strided tensor;','line_number':2507,'multiline':False]['text':' instead of repeating this calculation, we just use empty_strided which does the same','line_number':2508,'multiline':False]['text':' calculation when setting the storage size.','line_number':2509,'multiline':False]['text':' Some really weird cases','line_number':2529,'multiline':False]['text':' Make sure sizes and strides have the same length','line_number':2534,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/82416','line_number':2535,'multiline':False]['text':' Test the RuntimeError is raised when either m or n is a negative number','line_number':2578,'multiline':False]['text':' Test when the `m` parameter is not provided','line_number':2583,'multiline':False]['text':' Check eye_out outputs','line_number':2590,'multiline':False]['text':' Construct identity using diagonal and fill','line_number':2596,'multiline':False]['text':' Check eye_out outputs','line_number':2602,'multiline':False]['text':' RuntimeError: The tensor has a non-zero number of elements','line_number':2687,'multiline':False]['text':' Tests tensor and as_tensor','line_number':2693,'multiline':False]['text':' Note: warnings are suppressed (suppresses warnings)','line_number':2694,'multiline':False]['text':' Tests sparse ctor','line_number':2705,'multiline':False]['text':' NB: scipy always returns a float64 result','line_number':2734,'multiline':False]['text':' ensure we can create empty tensors from each factory function','line_number':2763,'multiline':False]['text':' step=2','line_number':2846,'multiline':False]['text':' small tensor','line_number':2861,'multiline':False]['text':' large tensor','line_number':2864,'multiline':False]['text':' Vectorization on non-contiguous tensors','line_number':2869,'multiline':False]['text':' int8 and uint8 are too small for this test','line_number':2870,'multiline':False]['text':' steps = 1','line_number':2877,'multiline':False]['text':' steps = 0','line_number':2880,'multiline':False]['text':' steps not provided','line_number':2883,'multiline':False]['text':' passed dtype can't be safely casted to inferred dtype','line_number':2887,'multiline':False]['text':' Check linspace for generating the correct output for each dtype.','line_number':2895,'multiline':False]['text':' If on GPU, allow for minor error depending on dtype.','line_number':2899,'multiline':False]['text':' Check linspace for generating with start > end.','line_number':2911,'multiline':False]['text':' Check for race condition (correctness when applied on a large tensor).','line_number':2916,'multiline':False]['text':' Check linspace for non-contiguous tensors.','line_number':2927,'multiline':False]['text':' Test deduction from input parameters.','line_number':2942,'multiline':False]['text':' Test deduction from input parameters.','line_number':2947,'multiline':False]['text':' The implementation of linspace+logspace goes through a different path','line_number':2950,'multiline':False]['text':' when the steps arg is equal to 0 or 1. For other values of `steps`','line_number':2951,'multiline':False]['text':' they call specialized linspace (or logspace) kernels.','line_number':2952,'multiline':False]['text':' NOTE [Linspace+Logspace precision override]','line_number':2955,'multiline':False]['text':' Our Linspace and logspace torch.half CUDA kernels are not very precise.','line_number':2956,'multiline':False]['text':' Since linspace/logspace are deterministic, we can compute an expected','line_number':2957,'multiline':False]['text':' amount of error (by testing without a precision override), adding a tiny','line_number':2958,'multiline':False]['text':' amount (EPS) to that, and using that value as the override.','line_number':2959,'multiline':False]['text':' Compares linspace device vs. cpu','line_number':2962,'multiline':False]['text':' See NOTE [Linspace+Logspace precision override]','line_number':2968,'multiline':False]['text':' Compares logspace device vs cpu','line_number':2981,'multiline':False]['text':' Compares logspace device vs cpu','line_number':2987,'multiline':False]['text':' See NOTE [Linspace+Logspace precision override]','line_number':2993,'multiline':False]['text':' See NOTE [Linspace+Logspace precision override]','line_number':3001,'multiline':False]['text':' steps not provided','line_number':3028,'multiline':False]['text':' passed dtype can't be safely casted to inferred dtype','line_number':3034,'multiline':False]['text':' Check precision - start, stop and base are chosen to avoid overflow','line_number':3042,'multiline':False]['text':' steps is chosen so that step size is not subject to rounding error','line_number':3043,'multiline':False]['text':' a tolerance is needed for gpu tests due to differences in computation','line_number':3044,'multiline':False]['text':' Check non-default base=2','line_number':3054,'multiline':False]['text':' Check logspace_ for generating with start > end.','line_number':3060,'multiline':False]['text':' Check logspace_ for non-contiguous tensors.','line_number':3064,'multiline':False]['text':' Tests bool fill value inference','line_number':3075,'multiline':False]['text':' Tests integer fill value inference','line_number':3079,'multiline':False]['text':' Tests float fill value inference','line_number':3083,'multiline':False]['text':' Tests complex inference','line_number':3087,'multiline':False]['text':' verifies dtype/out conflict throws a RuntimeError','line_number':3096,'multiline':False]['text':' verifies out dtype overrides inference','line_number':3100,'multiline':False]['text':' check that warning for numpy being not writable is suppressed','line_number':3104,'multiline':False]['text':' when a copy of it is being created.','line_number':3105,'multiline':False]['text':' see issue #47160','line_number':3106,'multiline':False]['text':' Class for testing random tensor creation ops, like torch.randint','line_number':3135,'multiline':False]['text':' TODO: add torch.complex64, torch.complex128','line_number':3139,'multiline':False]['text':' test empty mean/std','line_number':3226,'multiline':False]['text':' float std 0 with float mean','line_number':3244,'multiline':False]['text':' float std 0 with tensor mean','line_number':3251,'multiline':False]['text':' tensor std 0 with float mean','line_number':3259,'multiline':False]['text':' tensor std 0 with tensor mean','line_number':3267,'multiline':False]['text':' Ensure that normal raises appropriate error when `std` < 0','line_number':3289,'multiline':False]['text':' TODO: this test should be updated','line_number':3364,'multiline':False]['text':' (low,) and (low, high)','line_number':3368,'multiline':False]['text':' TODO: this test should be updated','line_number':3380,'multiline':False]['text':' TODO: This won't actually work for non-CUDA device','line_number':3439,'multiline':False]['text':' see https://github.com/pytorch/pytorch/issues/54282','line_number':3440,'multiline':False]['text':' Test core functionality. On CUDA, different value of n has different','line_number':3443,'multiline':False]['text':' code path','line_number':3444,'multiline':False]['text':' Ensure both integer and floating-point numbers are tested. Half follows an execution path that is','line_number':3446,'multiline':False]['text':' different from others on CUDA.','line_number':3447,'multiline':False]['text':' Large n for torch.half will raise an exception, do not test here.','line_number':3449,'multiline':False]['text':' Default type is long','line_number':3462,'multiline':False]['text':' randperm of 0 elements is an empty tensor','line_number':3466,'multiline':False]['text':' Test exceptions when n is too large for a floating point type','line_number':3473,'multiline':False]['text':' 2**53 + 1 is too large to run','line_number':3477,'multiline':False]['text':' No exception expected','line_number':3480,'multiline':False]['text':' Test non-contiguous tensors','line_number':3483,'multiline':False]['text':' Test exceptions when device and generator types are incompatible','line_number':3493,'multiline':False]['text':' n=0 is a special case that we don't need to use generator, thus no error even if','line_number':3499,'multiline':False]['text':' device and generator don't match','line_number':3500,'multiline':False]['text':' For cuda:0 to match cuda:1, we are making consistent device type matching','line_number':3510,'multiline':False]['text':' behavior just like torch.randint. Longer term, generator should ignore','line_number':3511,'multiline':False]['text':' device ordinal, since it's not used anyway.','line_number':3512,'multiline':False]['text':' implicitly on CPU','line_number':3526,'multiline':False]['text':' Class for testing *like ops, like torch.ones_like','line_number':3528,'multiline':False]['text':' TODO: this test should be updated','line_number':3532,'multiline':False]['text':' test boolean tensor','line_number':3539,'multiline':False]['text':' TODO: this test should be updated','line_number':3544,'multiline':False]['text':' Full-like precedence is the explicit dtype then the dtype of the "like"','line_number':3574,'multiline':False]['text':' tensor.','line_number':3575,'multiline':False]['text':' Tests for the `frombuffer` function (only work on CPU):','line_number':3585,'multiline':False]['text':'   Constructs tensors from Python objects that implement the buffer protocol,','line_number':3586,'multiline':False]['text':'   without copying data.','line_number':3587,'multiline':False]['text':' First call PyTorch's version in case of errors.','line_number':3606,'multiline':False]['text':' If this call exits successfully, the NumPy version must also do so.','line_number':3607,'multiline':False]['text':' Offset should be valid whenever there is, at least,','line_number':3638,'multiline':False]['text':' one remaining element','line_number':3639,'multiline':False]['text':' Count should be valid for any valid in the interval','line_number':3645,'multiline':False]['text':' [-1, len(input)], except for 0','line_number':3646,'multiline':False]['text':' Explicit default count [-1, 1, 2, ..., len]','line_number':3653,'multiline':False]['text':' Explicit default offset [0, 1, ..., len - 1]','line_number':3657,'multiline':False]['text':' All possible combinations of count and dtype aligned','line_number':3660,'multiline':False]['text':' offset for 'input'','line_number':3661,'multiline':False]['text':' count:[1, 2, ..., len - 1] x first:[0, 1, ..., len - count]','line_number':3662,'multiline':False]['text':' Empty array','line_number':3671,'multiline':False]['text':' Count equals 0','line_number':3676,'multiline':False]['text':' Offset negative and bigger than total length','line_number':3680,'multiline':False]['text':' Non-multiple offset with all elements','line_number':3688,'multiline':False]['text':' Count too big for each good first element','line_number':3695,'multiline':False]['text':' Modify the whole tensor','line_number':3707,'multiline':False]['text':' Modify the whole tensor from all valid offsets, given','line_number':3713,'multiline':False]['text':' a count value','line_number':3714,'multiline':False]['text':' Modify the first value in the array','line_number':3727,'multiline':False]['text':' Tests for the `asarray` function:','line_number':3752,'multiline':False]['text':'   Constructs tensors from a Python object that has one of the following','line_number':3753,'multiline':False]['text':'   characteristics:','line_number':3754,'multiline':False]['text':'       1. is a Tensor','line_number':3755,'multiline':False]['text':'       2. is a DLPack capsule','line_number':3756,'multiline':False]['text':'       3. implements the Python Buffer protocol','line_number':3757,'multiline':False]['text':'       4. is an arbitrary list','line_number':3758,'multiline':False]['text':'   The implementation itself is based on the Python Array API:','line_number':3759,'multiline':False]['text':'   https://data-apis.org/array-api/latest/API_specification/creation_functions.html','line_number':3760,'multiline':False]['text':' 1. The storage pointers should be equal only if 'is_alias' is set','line_number':3784,'multiline':False]['text':' 2. Comparison of the elements only takes place if the original','line_number':3790,'multiline':False]['text':' sequence and the resulting tensor have the same data type','line_number':3791,'multiline':False]['text':' 3. Given the specified target device, we first check whether','line_number':3799,'multiline':False]['text':' its type is the same, and then if its index is the same (if it','line_number':3800,'multiline':False]['text':' is not None)','line_number':3801,'multiline':False]['text':' Compare the target device type, and its index','line_number':3807,'multiline':False]['text':' 4. By default, 'requires_grad' is unset','line_number':3812,'multiline':False]['text':' Skipping 'meta' devices, since there's no point in comparing their','line_number':3833,'multiline':False]['text':' data pointer (which is basically the point here), since they all','line_number':3834,'multiline':False]['text':' return 0.','line_number':3835,'multiline':False]['text':' Skipping 'meta', since 'to_dlpack' does not work for them.','line_number':3846,'multiline':False]['text':' Copy is forced because of different device','line_number':3872,'multiline':False]['text':' Copy is forced because of different dtype','line_number':3878,'multiline':False]['text':' 'cloned' has 'grad_fn=<CloneBackwards>'','line_number':3973,'multiline':False]['text':' Autograd history shouldn't be retained when requires_grad is False','line_number':3980,'multiline':False]['text':' See issue: https://github.com/pytorch/pytorch/pull/71757','line_number':3992,'multiline':False]['text':' Scalars','line_number':3995,'multiline':False]['text':' Homogeneous Lists','line_number':3999,'multiline':False]['text':' Mixed Lists','line_number':4003,'multiline':False]['text':' With Complex','line_number':4008,'multiline':False]['text':' With Range','line_number':4010,'multiline':False]['text':' Regression test for https://github.com/pytorch/pytorch/issues/97021','line_number':4031,'multiline':False]['text':' Check the contents of the tensor.','line_number':4053,'multiline':False]['text':' The storage pointers should be equal','line_number':4064,'multiline':False]['text':' The storage pointers should not be equal','line_number':4068,'multiline':False]