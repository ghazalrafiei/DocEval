['text':' Owner(s): ["module: tests"]','line_number':1,'multiline':False]['text':' Refer [scipy reference filter]','line_number':56,'multiline':False]['text':' Filter operators for which the reference function','line_number':57,'multiline':False]['text':' is available in the current environment (for reference_numerics tests).','line_number':58,'multiline':False]['text':' Tests for unary "universal functions (ufuncs)" that accept a single','line_number':61,'multiline':False]['text':' tensor and have common properties like:','line_number':62,'multiline':False]['text':'   - they are elementwise functions','line_number':63,'multiline':False]['text':'   - the input shape is the output shape','line_number':64,'multiline':False]['text':'   - they typically have method and inplace variants','line_number':65,'multiline':False]['text':'   - they typically support the out kwarg','line_number':66,'multiline':False]['text':'   - they typically have NumPy or SciPy references','line_number':67,'multiline':False]['text':' See NumPy's universal function documentation','line_number':69,'multiline':False]['text':' (https://numpy.org/doc/1.18/reference/ufuncs.html) for more details','line_number':70,'multiline':False]['text':' about the concept of ufuncs.','line_number':71,'multiline':False]['text':' TODO: port test_unary_out_op_mem_overlap','line_number':74,'multiline':False]['text':' TODO: add test for inplace variants erroring on broadcasted inputs','line_number':75,'multiline':False]['text':' NOTE: the following two loops are separated for readability','line_number':87,'multiline':False]['text':' Skips the test if the difference is not representable,','line_number':93,'multiline':False]['text':'   which can occur if, for example, the difference is small','line_number':94,'multiline':False]['text':'   and the dtype is imprecise (like bfloat16 is)','line_number':95,'multiline':False]['text':' See above comment','line_number':114,'multiline':False]['text':' Helper for comparing torch tensors and numpy arrays','line_number':128,'multiline':False]['text':' TODO: should this or assertEqual also validate that strides are equal?','line_number':129,'multiline':False]['text':' Some NumPy functions return scalars, not arrays','line_number':135,'multiline':False]['text':' Handles exact dtype comparisons between arrays and tensors','line_number':139,'multiline':False]['text':' Allows array dtype to be float32 when comparing with bfloat16 tensors','line_number':145,'multiline':False]['text':'   since NumPy doesn't support the bfloat16 dtype','line_number':146,'multiline':False]['text':' Also ops like scipy.special.erf, scipy.special.erfc, etc, promote float16','line_number':147,'multiline':False]['text':' to float32','line_number':148,'multiline':False]['text':' Tests that the function and its (array-accepting) reference produce the same','line_number':177,'multiline':False]['text':'   values on given tensors','line_number':178,'multiline':False]['text':' NOTE: For these dtypes, PyTorch computes in the default scalar type (float)','line_number':189,'multiline':False]['text':' while NumPy computes in float16','line_number':190,'multiline':False]['text':' Ref: https://github.com/pytorch/pytorch/blob/master/torch/testing/_internal/common_utils.py#L1149','line_number':201,'multiline':False]['text':' Crafts a custom error message for smaller, printable tensors','line_number':244,'multiline':False]['text':' testing multi-outputs results','line_number':261,'multiline':False]['text':' Tests that the function and its (array-accepting) reference produce the same','line_number':264,'multiline':False]['text':'   values on a range of tensors, including empty tensors, scalar tensors,','line_number':265,'multiline':False]['text':'   1D tensors and a large 2D tensor with interesting and extremal values','line_number':266,'multiline':False]['text':'   and noncontiguities.','line_number':267,'multiline':False]['text':' Tests for testing (non)contiguity consistency','line_number':309,'multiline':False]['text':' Tests that computation on a multiple batches is the same as','line_number':426,'multiline':False]['text':' per-batch computation.','line_number':427,'multiline':False]['text':' Add extremal values.','line_number':446,'multiline':False]['text':' With args','line_number':454,'multiline':False]['text':' Out Variant','line_number':470,'multiline':False]['text':' sqrt Test Reference: https://github.com/pytorch/pytorch/pull/47424','line_number':525,'multiline':False]['text':' acos test reference: https://github.com/pytorch/pytorch/issue/42952','line_number':528,'multiline':False]['text':' Skip on Windows, as CUDA acos  returns conjugate value','line_number':529,'multiline':False]['text':' see https://github.com/pytorch/pytorch/issues/52299','line_number':530,'multiline':False]['text':' Based on SciPy test for the following special values.','line_number':544,'multiline':False]['text':' Reference:','line_number':545,'multiline':False]['text':' https://github.com/scipy/scipy/blob/3a8a3a1d4657254a6611e77e9c28feafa26e6645/scipy/special/tests/test_digamma.py#L22','line_number':546,'multiline':False]['text':' Tests pole behavior','line_number':576,'multiline':False]['text':' torch.frexp returns exponent in int32 to be compatible with np.frexp','line_number':606,'multiline':False]['text':' TODO resolve with opinfos','line_number':652,'multiline':False]['text':' test exceptions','line_number':662,'multiline':False]['text':' Constructs random complex values','line_number':670,'multiline':False]['text':' Tests function','line_number':688,'multiline':False]['text':' Tests float out','line_number':693,'multiline':False]['text':' Tests float out (resized out)','line_number':702,'multiline':False]['text':' Tests complex out','line_number':707,'multiline':False]['text':' Tests complex out (resized out)','line_number':713,'multiline':False]['text':' Tests long out behavior (expected failure)','line_number':718,'multiline':False]['text':' Tests inplace','line_number':723,'multiline':False]['text':' Note: angle does not have an in-place variant','line_number':737,'multiline':False]['text':' output is identical to input:','line_number':765,'multiline':False]['text':' output and input are independent:','line_number':767,'multiline':False]['text':' output partially overlaps with input:','line_number':769,'multiline':False]['text':' TODO: run on non-native device types','line_number':778,'multiline':False]['text':' TODO: opinfo hardshrink','line_number':888,'multiline':False]['text':' test default lambd=0.5','line_number':902,'multiline':False]['text':' test non-contiguous case','line_number':905,'multiline':False]['text':' Test for https://github.com/pytorch/pytorch/issues/17271','line_number':947,'multiline':False]['text':' This is pretty slow on my Macbook but it only takes a few','line_number':948,'multiline':False]['text':' seconds on a beefy Xeon server','line_number':949,'multiline':False]['text':' normal','line_number':967,'multiline':False]['text':' inplace','line_number':972,'multiline':False]['text':' normal','line_number':987,'multiline':False]['text':' inplace','line_number':993,'multiline':False]['text':' It is not obvious how to merge this into OpInfo becuase these inputs','line_number':1081,'multiline':False]['text':' succeed for gradcheck but are expected to fail for gradgradcheck','line_number':1082,'multiline':False]['text':' The derivative of sinc(x) at x=0 has to be special cased.','line_number':1085,'multiline':False]['text':' A naive computation will result in 0/0 -> NaN.','line_number':1086,'multiline':False]['text':' We also need to be careful when we are very close to 0, as the','line_number':1087,'multiline':False]['text':' derivative's denominator is squared, and there are some floats','line_number':1088,'multiline':False]['text':' that are positive and whose squares are zero.','line_number':1089,'multiline':False]['text':' The output values here were obtained using arbitrary precision math (mpmath)','line_number':1142,'multiline':False]['text':' and double checked with WolframAlpha.','line_number':1143,'multiline':False]['text':' Not using numpy's log1p here because by the time of writing this,','line_number':1144,'multiline':False]['text':' np.log1p has precision problems for small complex input values, see here:','line_number':1145,'multiline':False]['text':' https://github.com/numpy/numpy/issues/22609','line_number':1146,'multiline':False]['text':' test the extreme values','line_number':1159,'multiline':False]['text':' test the log1p individually','line_number':1179,'multiline':False]['text':' setting up atol == 0.0 because some part has very small values','line_number':1183,'multiline':False]['text':' test the log1p in tensor','line_number':1187,'multiline':False]['text':' do ops like threshold need a test_unary(_nonufunc) test suite?','line_number':1195,'multiline':False]['text':' 100 is wide enough to use AVX2 instructions for all types','line_number':1200,'multiline':False]['text':' for large number, it should approach 0.5','line_number':1217,'multiline':False]['text':' test for considerable ratio','line_number':1218,'multiline':False]['text':' contiguous/noncontiguous tests','line_number':1220,'multiline':False]['text':' test igamma for reasonable range of values','line_number':1239,'multiline':False]['text':' approx 0.018','line_number':1240,'multiline':False]['text':' approx 54.6','line_number':1241,'multiline':False]['text':' test igammac for reasonable range of values','line_number':1251,'multiline':False]['text':' approx 0.018','line_number':1252,'multiline':False]['text':' approx 54.6','line_number':1253,'multiline':False]['text':' (a    ,    x),       out','line_number':1270,'multiline':False]['text':' (a    ,    x),       out','line_number':1299,'multiline':False]['text':' Test by comparing to scipy','line_number':1317,'multiline':False]['text':' Casting down for dtype float16 is required since scipy upcasts to float32','line_number':1323,'multiline':False]['text':' i0 tests are broken up by the domain for which the function does not overflow for each dtype','line_number':1329,'multiline':False]['text':' This is done to ensure that the function performs well across all possible input values, without worrying','line_number':1330,'multiline':False]['text':' about inf or nan possibilities','line_number':1331,'multiline':False]['text':' This tests the domain for i0 for which float16 does not overflow','line_number':1340,'multiline':False]['text':' The domain is (-13.25, 13.25)','line_number':1341,'multiline':False]['text':' This tests the domain for i0 for which float32 and bfloat16 does not overflow','line_number':1348,'multiline':False]['text':' The domain is (-88.5, 88.5)','line_number':1349,'multiline':False]['text':' This tests the domain for i0 for which float64 does not overflow','line_number':1355,'multiline':False]['text':' The domain is (-709.75, 709.75)','line_number':1356,'multiline':False]['text':' Test by comparing to scipy','line_number':1374,'multiline':False]['text':' Casting down for dtype float16 is required since scipy upcasts to float32','line_number':1380,'multiline':False]['text':' NaN, inf, -inf are tested in reference_numerics tests.','line_number':1403,'multiline':False]['text':' Test by comparing to scipy','line_number':1417,'multiline':False]['text':' Skip testing NaN, inf, -inf since they are tested in reference_numerics tests.','line_number':1426,'multiline':False]['text':' Test by comparing with scipy','line_number':1436,'multiline':False]['text':' Skip testing NaN, inf, -inf since they are tested in reference_numerics tests.','line_number':1441,'multiline':False]['text':' TODO: allow large opinfo values to be opted-into via metadata','line_number':1447,'multiline':False]['text':' TODO: add signed zero testing to opinfos','line_number':1454,'multiline':False]['text':' Both abs(0.0) and abs(-0.0) should result in 0.0','line_number':1457,'multiline':False]['text':' pick a large enough number with remainder so that','line_number':1458,'multiline':False]['text':' both vectorized and nonvectorized op is tested','line_number':1459,'multiline':False]['text':' TODO: update to compare against NumPy by rationalizing with OpInfo','line_number':1466,'multiline':False]['text':' Both abs(0.0) and abs(-0.0) should result in 0.0','line_number':1470,'multiline':False]['text':' test non-boolean tensors as the `out=` parameters','line_number':1477,'multiline':False]['text':' boolean outputs are tested in the above testcases','line_number':1478,'multiline':False]['text':' nonzero with as_tuple returns a','line_number':1504,'multiline':False]['text':' tuple of len 1 for a zero-dim tensor.','line_number':1505,'multiline':False]['text':' This is done to match Numpy behavior.','line_number':1506,'multiline':False]['text':' TODO: rationalize with exp OpInfo','line_number':1518,'multiline':False]['text':' bfloat16 overflows','line_number':1530,'multiline':False]['text':' These are commented out because it cannot be consistently reproduced.','line_number':1543,'multiline':False]['text':' This is incorrect. It should be zero. Need fix!','line_number':1544,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/40590','line_number':1545,'multiline':False]['text':' self.assertNotEqual(inf_real_zero_imag_out.imag, 0)','line_number':1546,'multiline':False]['text':' This is incorrect. They should equal. Need fix!','line_number':1547,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/40590','line_number':1548,'multiline':False]['text':' with self.assertRaises(AssertionError):','line_number':1549,'multiline':False]['text':'     self.compare_with_numpy(torch.exp, np.exp, inf_real_zero_imag_in)','line_number':1550,'multiline':False]['text':' Ensure we are notified when NumPy changes its behavior','line_number':1561,'multiline':False]['text':' This is incorrect. Need fix! https://github.com/pytorch/pytorch/issues/40590','line_number':1570,'multiline':False]['text':' This is commented out because it cannot be consistently reproduced.','line_number':1571,'multiline':False]['text':' with self.assertRaises(AssertionError):','line_number':1572,'multiline':False]['text':'     self.compare_with_numpy(torch.exp, np.exp, inf_real_imag_in)','line_number':1573,'multiline':False]['text':' This is incorrect. It should be inf. Need fix! https://github.com/pytorch/pytorch/issues/40590','line_number':1585,'multiline':False]['text':' This is commented out because it cannot be consistently reproduced.','line_number':1586,'multiline':False]['text':' with self.assertRaises(AssertionError):','line_number':1587,'multiline':False]['text':'     self.compare_with_numpy(torch.exp, np.exp, inf_real_nan_imag_in)','line_number':1588,'multiline':False]['text':' Ensure we are notified when NumPy changes its behavior','line_number':1600,'multiline':False]