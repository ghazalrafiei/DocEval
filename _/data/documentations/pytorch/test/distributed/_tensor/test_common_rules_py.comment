['text':' Copyright (c) Meta Platforms, Inc. and affiliates','line_number':1,'multiline':False]['text':' Owner(s): ["oncall: distributed"]','line_number':2,'multiline':False]['text':' hard code world size to 4 as we need to test','line_number':22,'multiline':False]['text':' at least with 2d mesh','line_number':23,'multiline':False]['text':' plain einsum, mm','line_number':36,'multiline':False]['text':' propagate col-wise sharding','line_number':40,'multiline':False]['text':' propagate row-wise sharding','line_number':58,'multiline':False]['text':' generate partial','line_number':73,'multiline':False]['text':' addition','line_number':93,'multiline':False]['text':' broadcast addition','line_number':106,'multiline':False]['text':' broadcast to a common shape','line_number':124,'multiline':False]['text':' 2d mesh einop merge sharding','line_number':142,'multiline':False]['text':' if not turn on linearity, partial sum is not eligible to propagate, we return','line_number':184,'multiline':False]['text':' suggestion to reshard inputs with no partial sum (i.e. all_reduce one input)','line_number':185,'multiline':False]['text':' einop prop with linearity on mm, should give back suggestion','line_number':195,'multiline':False]['text':' on converting placements to partial','line_number':196,'multiline':False]['text':' mat2 mesh dim 1 should become partial now!','line_number':206,'multiline':False]['text':' einop prop with linearity on point-wise, should give back suggestion','line_number':209,'multiline':False]['text':' on converting placements to partial','line_number':210,'multiline':False]['text':' mat2 mesh dim 1 should become partial now!','line_number':231,'multiline':False]['text':' einop prop with multi sharding on same mesh dim','line_number':236,'multiline':False]['text':' ensure that the suggestion is to reshard the second','line_number':257,'multiline':False]['text':' arg by all_gather its tensor dim sharding','line_number':258,'multiline':False]['text':' propagate point-wise sharding with broadcasting','line_number':302,'multiline':False]['text':' propagate point-wise sharding','line_number':315,'multiline':False]['text':' adding a positional argument -1 to arg schema','line_number':325,'multiline':False]['text':' ensure that the suggestion from pointwise rules still have','line_number':332,'multiline':False]['text':' the positional args that are not DTensorSpec','line_number':333,'multiline':False]['text':' 2d mesh pointwise sharding','line_number':340,'multiline':False]['text':' basic case to test implicit broadcasting shape alignment','line_number':348,'multiline':False]['text':' more advanced case that needs reshard one input to align sharding','line_number':363,'multiline':False]['text':' ensure that the suggestion is to reshard the first','line_number':378,'multiline':False]['text':' arg by all_gather first tensor dim sharding','line_number':379,'multiline':False]['text':' 2d mesh pointwise sharding','line_number':386,'multiline':False]['text':' more advanced case that needs reshard one input to align sharding','line_number':394,'multiline':False]['text':' ensure that the suggestion is to reshard the second','line_number':409,'multiline':False]['text':' arg as we should enforce the sharding of the first arg','line_number':410,'multiline':False]