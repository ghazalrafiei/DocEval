['text':' Jacobians, Hessians, hvp, vhp, and more: composing functorch transforms','line_number':1,'multiline':False]['text':'# Computing the Jacobian','line_number':12,'multiline':False]['text':' feature vector','line_number':42,'multiline':False]['text':' show first row','line_number':66,'multiline':False]['text':' lets confirm both methods compute the same result','line_number':87,'multiline':False]['text':' confirm ','line_number':105,'multiline':False]['text':' note the change in input via argnums params of 0,1 to map to weight and bias','line_number':172,'multiline':False]['text':'# reverse-mode Jacobian (jacrev) vs forward-mode Jacobian (jacfwd)','line_number':176,'multiline':False]['text':' remember the general rule about taller vs wider...here we have a taller matrix:','line_number':209,'multiline':False]['text':'# Hessian computation with functorch.hessian','line_number':284,'multiline':False]['text':' lets reduce the size in order not to blow out colab. Hessians require significant memory:','line_number':303,'multiline':False]['text':'hess_revrev = jacrev(jacrev(predict, argnums=2), argnums=2)(weight, bias, x)','line_number':312,'multiline':False]['text':'# Batch Jacobian and Batch Hessian','line_number':330,'multiline':False]['text':'# Computing Hessian-vector products','line_number':394,'multiline':False]