['text':'!/usr/bin/env python3','line_number':1,'multiline':False]['text':' Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved','line_number':2,'multiline':False]['text':' step 0: compute the norms','line_number':59,'multiline':False]['text':' step 1: compute clipping factors','line_number':62,'multiline':False]['text':' step 2: clip','line_number':66,'multiline':False]['text':' step 3: add gaussian noise','line_number':71,'multiline':False]['text':' step 4: assign the new grads, delete the sample grads','line_number':79,'multiline':False]['text':' Step 1: compute per-sample-grads','line_number':97,'multiline':False]['text':' To use vmap+grad to compute per-sample-grads, the forward pass','line_number':99,'multiline':False]['text':' must be re-formulated on a single example.','line_number':100,'multiline':False]['text':' We use the `grad` operator to compute forward+backward on a single example,','line_number':101,'multiline':False]['text':' and finally `vmap` to do forward+backward on multiple examples.','line_number':102,'multiline':False]['text':' `grad(f)` is a functional API that returns a function `f'` that','line_number':110,'multiline':False]['text':' computes gradients by running both the forward and backward pass.','line_number':111,'multiline':False]['text':' We want to extract some intermediate','line_number':112,'multiline':False]['text':' values from the computation (i.e. the loss and output).','line_number':113,'multiline':False]['text':'','line_number':114,'multiline':False]['text':' To extract the loss, we use the `grad_and_value` API, that returns the','line_number':115,'multiline':False]['text':' gradient of the weights w.r.t. the loss and the loss.','line_number':116,'multiline':False]['text':'','line_number':117,'multiline':False]['text':' To extract the output, we use the `has_aux=True` flag.','line_number':118,'multiline':False]['text':' `has_aux=True` assumes that `f` returns a tuple of two values,','line_number':119,'multiline':False]['text':' where the first is to be differentiated and the second "auxiliary value"','line_number':120,'multiline':False]['text':' is not to be differentiated. `f'` returns the gradient w.r.t. the loss,','line_number':121,'multiline':False]['text':' the loss, and the auxiliary value.','line_number':122,'multiline':False]['text':' detaching weights since we don't need to track gradients outside of transforms','line_number':126,'multiline':False]['text':' and this is more performant','line_number':127,'multiline':False]['text':' Step 2: Clip the per-sample-grads, sum them to form grads, and add noise','line_number':137,'multiline':False]['text':' measure accuracy and record loss','line_number':146,'multiline':False]['text':' make sure we take a step after processing the last mini-batch in the','line_number':151,'multiline':False]['text':' epoch to ensure we start the next epoch with a clean state','line_number':152,'multiline':False]['text':' flake8: noqa: C901','line_number':192,'multiline':False]['text':' Store some logs','line_number':271,'multiline':False]['text':' remember best acc@1 and save checkpoint','line_number':284,'multiline':False]