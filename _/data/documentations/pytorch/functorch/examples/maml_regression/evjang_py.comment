['text':' Eric Jang originally wrote an implementation of MAML in JAX','line_number':1,'multiline':False]['text':' (https://github.com/ericjang/maml-jax).','line_number':2,'multiline':False]['text':' We translated his implementation from JAX to PyTorch.','line_number':3,'multiline':False]['text':' Select amplitude and phase for the task','line_number':49,'multiline':False]['text':' create_graph=True because computing grads here is part of the forward pass.','line_number':78,'multiline':False]['text':' We want to differentiate through the SGD update steps and get higher order','line_number':79,'multiline':False]['text':' derivatives in the backward pass.','line_number':80,'multiline':False]