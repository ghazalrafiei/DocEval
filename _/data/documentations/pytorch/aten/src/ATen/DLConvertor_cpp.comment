['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':18,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':25,'multiline':False]['text':' ROCM, if enabled will look like cuda to PyTorch','line_number':90,'multiline':False]['text':' while everyone else should see HIP','line_number':91,'multiline':False]['text':' if we are compiled under HIP, we cannot do cuda','line_number':118,'multiline':False]['text':' this looks funny, we need to return CUDA here to masquerade','line_number':126,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':231,'multiline':False]['text':' This function returns a shared_ptr to memory managed DLpack tensor','line_number':241,'multiline':False]['text':' constructed out of ATen tensor','line_number':242,'multiline':False]['text':' create a new tensor with possibly normalized strides','line_number':244,'multiline':False]['text':' gh-83069','line_number':245,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)','line_number':268,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)','line_number':271,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)','line_number':280,'multiline':False]['text':' namespace at','line_number':308,'multiline':False]