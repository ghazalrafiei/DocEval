['text':' Use this to define the prototype for a meta function.  There are two','line_number':14,'multiline':False]['text':' versions; one that takes one argument (just the operator name), or FUNC2','line_number':15,'multiline':False]['text':' variant that takes two arguments (operator name and overload name).','line_number':16,'multiline':False]['text':'','line_number':17,'multiline':False]['text':' Example usage:','line_number':18,'multiline':False]['text':'','line_number':19,'multiline':False]['text':'    TORCH_META_FUNC2(add, Tensor) (','line_number':20,'multiline':False]['text':'      const Tensor& self, const Tensor& other','line_number':21,'multiline':False]['text':'    ) {','line_number':22,'multiline':False]['text':'      ... compute sizes and options ...','line_number':23,'multiline':False]['text':'      set_output(sizes, options);','line_number':24,'multiline':False]['text':'    }','line_number':25,'multiline':False]['text':'','line_number':26,'multiline':False]['text':' These are versions of TORCH_META_FUNC(2) that include a precompute_out struct','line_number':31,'multiline':False]['text':' as a return value. They should be used when the kernel in question has','line_number':32,'multiline':False]['text':' precomputed values declared in native_functions.yaml and the corresponding','line_number':33,'multiline':False]['text':' implementation should return an instance of the aforementioned struct.','line_number':34,'multiline':False]['text':' Use this to create a precompute struct in a meta function.','line_number':41,'multiline':False]['text':' Use this to define the prototype for an implementation.  This takes only','line_number':46,'multiline':False]['text':' one argument, which is the name of the dispatch key entry you're','line_number':47,'multiline':False]['text':' implementing.','line_number':48,'multiline':False]['text':'','line_number':49,'multiline':False]['text':' Example usage:','line_number':50,'multiline':False]['text':'','line_number':51,'multiline':False]['text':'    TORCH_IMPL_FUNC(add_cpu) (','line_number':52,'multiline':False]['text':'      Tensor& result, const Tensor& self, const Tensor& other','line_number':53,'multiline':False]['text':'    ) {','line_number':54,'multiline':False]['text':'      ... do the actual implementation ...','line_number':55,'multiline':False]['text':'    }','line_number':56,'multiline':False]['text':'','line_number':57,'multiline':False]['text':' Base class for all structured kernel classes.  The set_output virtual','line_number':60,'multiline':False]['text':' method is varied depending whether or not the operator is','line_number':61,'multiline':False]['text':' functional/out/inplace, and could also be specialized for CPU/CUDA/etc','line_number':62,'multiline':False]['text':' (although presently it isn't).','line_number':63,'multiline':False]['text':'','line_number':64,'multiline':False]['text':' A notable subclass of this interface is TensorIteratorBase.','line_number':65,'multiline':False]['text':' Note: [set_output_*]','line_number':74,'multiline':False]['text':' See: https://github.com/pytorch/pytorch/issues/69813','line_number':75,'multiline':False]['text':' Whenever defining the output properties in the META function of a','line_number':76,'multiline':False]['text':' structured kernel (what was usually done with `set_output`), use one of','line_number':77,'multiline':False]['text':' these 3 variants, instead. In order to decide which variant to use, check','line_number':78,'multiline':False]['text':' the following decision tree:','line_number':79,'multiline':False]['text':'','line_number':80,'multiline':False]['text':' - Can the kernel you are going to implement support output tensors','line_number':81,'multiline':False]['text':'   with arbitrary strides?','line_number':82,'multiline':False]['text':'     |','line_number':83,'multiline':False]['text':'     -- YES: `set_output_raw_strided`','line_number':84,'multiline':False]['text':'     |','line_number':85,'multiline':False]['text':'     -- NO: Should the output tensor strides be contiguous?','line_number':86,'multiline':False]['text':'         |','line_number':87,'multiline':False]['text':'         -- YES: `set_output_contiguous`','line_number':88,'multiline':False]['text':'         |','line_number':89,'multiline':False]['text':'         -- NO: `set_output_strided`','line_number':90,'multiline':False]['text':'','line_number':91,'multiline':False]['text':' Use this function whenever the kernel requires specific strides for the','line_number':92,'multiline':False]['text':' output. If `strides` does not match the given output strides, proxy outputs','line_number':93,'multiline':False]['text':' will be created and passed to the IMPL function.','line_number':94,'multiline':False]['text':' Use this function whenever the kernel knows how to handle arbitrary strided','line_number':104,'multiline':False]['text':' outputs. This function has the same behavior as the old `set_output`: it','line_number':105,'multiline':False]['text':' will only re-stride if the given output was resized.','line_number':106,'multiline':False]['text':' Use this function if the kernel requires contiguous strides.','line_number':116,'multiline':False]['text':' Alias for `set_output_strided`, but with contiguous strides.','line_number':117,'multiline':False]['text':' Returns a reference to an undefined tensor if there is no presupplied','line_number':127,'multiline':False]['text':' output','line_number':128,'multiline':False]['text':' namespace impl','line_number':135,'multiline':False]['text':' namespace at','line_number':137,'multiline':False]