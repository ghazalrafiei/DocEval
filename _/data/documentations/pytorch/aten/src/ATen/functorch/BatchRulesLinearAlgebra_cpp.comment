['text':' Copyright (c) Facebook, Inc. and its affiliates.','line_number':1,'multiline':False]['text':' All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' This source code is licensed under the BSD-style license found in the','line_number':4,'multiline':False]['text':' LICENSE file in the root directory of this source tree.','line_number':5,'multiline':False]['text':' Note [Batching rules for matmul-like operators]','line_number':18,'multiline':False]['text':' at::matmul doesn't "de-expand" arguments to get better performance (maybe','line_number':19,'multiline':False]['text':' it should). In the batching rules for matmul-like operators (dot, mv, mm),','line_number':20,'multiline':False]['text':' we should be careful not to expand any unnecessary dimensions. i.e., if','line_number':21,'multiline':False]['text':' only one of the two arguments is a BatchedTensor, then we should try','line_number':22,'multiline':False]['text':' not to expand batch dimensions onto the other arg.','line_number':23,'multiline':False]['text':' NB: I wrote this like this because we *might* want its for a future matmul','line_number':39,'multiline':False]['text':' batch rule that isn't decomposed...','line_number':40,'multiline':False]['text':' "tv" = tensor @ vector','line_number':41,'multiline':False]['text':' See Note [Batching rules for matmul-like operators]','line_number':46,'multiline':False]['text':' B...OI, BI -> ...BOI, BI1 -> ...BO1 -> ...BO','line_number':47,'multiline':False]['text':' B...OI, I -> B...O','line_number':56,'multiline':False]['text':' ...OI, BI -> ...OI, IB -> OB','line_number':61,'multiline':False]['text':' AFAICT, nothing here can be batched. So we decompose :)','line_number':112,'multiline':False]['text':' Decomposition that is probably not very fast...','line_number':150,'multiline':False]['text':' Not a matrix means this is a batch of matrices','line_number':156,'multiline':False]['text':' LU and pivots's first {N-2} (for LU), {N-1} (for pivots) dimensions must match','line_number':285,'multiline':False]['text':' So if only one of them is being vmapped over, we must expand out that dimension.','line_number':286,'multiline':False]['text':' Now, {LU, pivots} and B's first dimensions are allowed to broadcast.','line_number':295,'multiline':False]['text':' The rest of the logic handles that.','line_number':296,'multiline':False]['text':'do_type_promotion=','line_number':319,'multiline':True]['text':' seems to be a bug','line_number':335,'multiline':False]['text':' vector case: B was a vector or batched vector','line_number':352,'multiline':False]['text':' not accurate but matches linalg error message','line_number':353,'multiline':False]['text':' matrix case: A and B are both matrices or batches of matrices','line_number':356,'multiline':False]['text':' basically binary pointwise helper but if B was a vector incoming, we must pad it to be 1 dim smaller than A','line_number':360,'multiline':False]['text':' NOTE [ solve_ex Batch Rule Contiguity ]','line_number':369,'multiline':False]['text':' A determines whether or not linalg_solve takes an optimized path. We need the check on A_ to match the one run on','line_number':370,'multiline':False]['text':' A as BatchedTensor since it might have been saved by autograd (specifically by the jvp) and the autograd behvaior','line_number':371,'multiline':False]['text':' differs based on whether or not the optimized path was taken','line_number':372,'multiline':False]['text':' match cross dimension checks','line_number':383,'multiline':False]['text':'do_type_promotion=','line_number':413,'multiline':True]['text':' because of ambiguity with vector case, lstsq can broadcast [1, 2] -> [batch_size, 2] but not [2] -> [batch_size, 2]','line_number':415,'multiline':False]['text':' so could unsqueeze if there's no bdim or just ensure_has_bdim','line_number':416,'multiline':False]['text':' everything but the 0th output are only sometimes computed. When they aren't, they're empty tensors without a bdim','line_number':423,'multiline':False]['text':' atol and rtol's dims must be broadcastable to the number of batch dims of input','line_number':441,'multiline':False]['text':' which is input's dim - 2 (input represents a batch of matrices, so 2 is for the matrix dimensions)','line_number':442,'multiline':False]['text':' pad all inputs to have the same number of (non-vmap) batch dimensions','line_number':452,'multiline':False]['text':' Define string constants with the function names. These will be used as template parameters','line_number':491,'multiline':False]['text':' C++ doesn't let us use string literals as template parameters, so we have to declare them as consts first','line_number':492,'multiline':False]['text':' What is going on with these macros?','line_number':493,'multiline':False]['text':' - clang-5 seems to require the constexpr','line_number':494,'multiline':False]['text':' - windows compiles with or without the constexpr, but the constexpr causes test problems','line_number':495,'multiline':False]['text':' - as a result we have some macro guards.','line_number':496,'multiline':False]['text':' These need to be outside. String constant must be declared outside of a macro to be used as template param','line_number':555,'multiline':False]['text':' custom dim error','line_number':584,'multiline':False]['text':' custom errors and sometimes empty return','line_number':585,'multiline':False]