['text':' Copyright (c) Facebook, Inc. and its affiliates.','line_number':1,'multiline':False]['text':' All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' This source code is licensed under the BSD-style license found in the','line_number':4,'multiline':False]['text':' LICENSE file in the root directory of this source tree.','line_number':5,'multiline':False]['text':' NB: assumes the batch dim is at the front of the tensor','line_number':45,'multiline':False]['text':' NB: assumes the batch dim is at the front of the tensor','line_number':56,'multiline':False]['text':' for ops that don't take in any tensors, don't hit same error','line_number':101,'multiline':False]['text':' Returned Tensor has one fewer dim','line_number':107,'multiline':False]['text':' NOTE: 0 % 0 leads to FPE','line_number':118,'multiline':False]['text':' split any size out of `0`-sized dim','line_number':122,'multiline':False]['text':' NOTE: 0 % 0 leads to FPE','line_number':137,'multiline':False]['text':' split any size out of `0`-sized dim','line_number':141,'multiline':False]['text':' compute max logical rank','line_number':177,'multiline':False]['text':' In the (0D, ND) case, type promotion semantics are different :/','line_number':185,'multiline':False]['text':' If the dimensions aren't aligned, we need to line them up.','line_number':197,'multiline':False]['text':' Tensor[B, 3] + Tensor[2, 5, 3] -> Tensor[B, 1, 1, 3] + Tensor[2, 5, 3]','line_number':198,'multiline':False]['text':' Note that only tensors that have a batch dim need to be modified.','line_number':199,'multiline':False]['text':' Tensor[B, 2, 3, 5] + Tensor[5] -> no changes needed','line_number':200,'multiline':False]