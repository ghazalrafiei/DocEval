['text':' Copyright (c) Facebook, Inc. and its affiliates.','line_number':1,'multiline':False]['text':' All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' This source code is licensed under the BSD-style license found in the','line_number':4,'multiline':False]['text':' LICENSE file in the root directory of this source tree.','line_number':5,'multiline':False]['text':' NOTE: [vmap plumbing]','line_number':11,'multiline':False]['text':'','line_number':12,'multiline':False]['text':' Here's how "batching rules" work.','line_number':13,'multiline':False]['text':' - we register kernels to the Batched key','line_number':14,'multiline':False]['text':' - these kernels have the same signatures as the original operators.','line_number':15,'multiline':False]['text':'   For example, at::sin(Tensor self) accepts a Tensor, and the batched kernel','line_number':16,'multiline':False]['text':'   must also accept a Tensor','line_number':17,'multiline':False]['text':' - However, it is more natural for users to write a batching rule like the','line_number':18,'multiline':False]['text':'   following: sin_batch_rule(Tensor self, optional<int> self_bdim)','line_number':19,'multiline':False]['text':' - There is some codegenerated layer (the "plumbing") that wraps the user','line_number':20,'multiline':False]['text':'   defined batching rule (e.g. sin_batch_rule) in a kernel that can be','line_number':21,'multiline':False]['text':'   registered to the Batched key.','line_number':22,'multiline':False]['text':'','line_number':23,'multiline':False]['text':' The plumbing is responsible for wrapping a batching rule into a form that may','line_number':24,'multiline':False]['text':' be registered as the kernel for the batched key.','line_number':25,'multiline':False]['text':' Create a BatchedTensor given a tensor, bdim, and level','line_number':31,'multiline':False]['text':' Given a Tensor that may or may not be a BatchedTensor, unwrap it.','line_number':34,'multiline':False]['text':' If `tensor` is not a BatchedTensor, or is a BatchedTensor but the level','line_number':35,'multiline':False]['text':' doesn't match, then this returns (tensor, nullopt).','line_number':36,'multiline':False]['text':' Otherwise, it returns (unwrap(tensor), bdim).','line_number':37,'multiline':False]['text':' Creates a vector of BatchedTensor','line_number':40,'multiline':False]['text':' Returns True if ANY tensor in tensors is batched at level','line_number':43,'multiline':False]['text':' Convenience helper. Returns true if any tensor is batched at level','line_number':49,'multiline':False]['text':' TODO: should really check this','line_number':59,'multiline':False]['text':' namespace at::functorch','line_number':63,'multiline':False]