['text':'*
 * Quantizer is the class for storing all the information
 * that's necessary to perform quantize and dequantize
 * operation.
 *
 * We might have different types of quantization schemes and this is
 * the base class for all quantizers.
 *
 * QTensorImpl will hold a pointer to Quantizer so that we can support
 * different quantization schemes on Tensor.
 *
 * For example, the most common quantization scheme, Affine Quantization,
 * requires scale and zero_point as parameters, we'll store scale and zero_point
 * inside the instance and we can use it to quantize a float Tensor or
 * dequantize a quantized Tensor.
 *
 * When you add new types of leaf Quantizer class, please also
 * make sure to add a corresponding QScheme enum since
 * they should have one to one mapping.
 *
 * Note about intrusive_ptr:
 * Quantized Tensor holds an intrusive_ptr to Quantizer, and multiple Tensor can
 * share the same Quantizer. Quantizer should be immutable.
 ','line_number':15,'multiline':True]['text':' Copied from torch/csrc/jit/ir/scope.h','line_number':44,'multiline':False]['text':' we are creating a new pointer','line_number':46,'multiline':False]['text':' from a raw `this` pointer','line_number':47,'multiline':False]['text':' so we need to bump the refcount','line_number':48,'multiline':False]['text':' to account for this ownership','line_number':49,'multiline':False]['text':'*
   * Each concrete Quantizer type should have a unique QScheme type.
   ','line_number':53,'multiline':True]['text':'*
   * quantize a float Tensor into a quantized Tensor.
   ','line_number':62,'multiline':True]['text':'*
   * dequantize a quantized Tensor into a float Tensor.
   ','line_number':67,'multiline':True]['text':'*
   * dequantize a quantized Tensor into a float Tensor, out= variant
   ','line_number':72,'multiline':True]['text':'*
   * Compare against `other` for equality.
   ','line_number':77,'multiline':True]['text':' namespace at','line_number':83,'multiline':False]