['text':' This logic is similar to autograd code for view backwards calls.','line_number':11,'multiline':False]['text':' We can't easily share it though, because (eventually) these functions','line_number':12,'multiline':False]['text':' will all call `permute/unsqueeze_copy()` instead of `permute/unsqueeze`.','line_number':13,'multiline':False]['text':' invert the permutation','line_number':16,'multiline':False]['text':' in NumPy it's not an error to unsqueeze a scalar, but we still need to avoided','line_number':48,'multiline':False]['text':' unsqueezing in the backward.','line_number':49,'multiline':False]['text':' Note [Functionalization Pass: View Inverses].','line_number':67,'multiline':False]['text':' This file contains the implementation of each "view inverse".','line_number':68,'multiline':False]['text':' These aren't really true inverses in the mathematically sense: each view inverse describes how to undo','line_number':69,'multiline':False]['text':' the original view (although it takes in different arguments).','line_number':70,'multiline':False]['text':'','line_number':71,'multiline':False]['text':' E.g. Below is an example of a program that has alias operations removed, and the role that view inverses play:','line_number':72,'multiline':False]['text':'','line_number':73,'multiline':False]['text':' normal program with views and mutations:','line_number':74,'multiline':False]['text':' view1 = input1.view_op(args...)','line_number':75,'multiline':False]['text':' view1.add_(1) (perform a mutation on the view, which should also modify input)','line_number':76,'multiline':False]['text':' version of the program with no aliasing, that instead uses view_inverse functions:','line_number':78,'multiline':False]['text':' view_copy1 = input1.view_copy_op(args...)','line_number':79,'multiline':False]['text':' view_copy1.add_(1) (perform a mutation on view_copy1. At this point, input1 is NOT modified)','line_number':80,'multiline':False]['text':' x = view_op_inverse(input1, view_copy1, args...)','line_number':81,'multiline':False]['text':'','line_number':82,'multiline':False]['text':' at this point, input1 and x should be equal','line_number':83,'multiline':False]['text':'','line_number':84,'multiline':False]['text':' Note that input1 is also passed as an argument to view_op_inverse in the above example.','line_number':85,'multiline':False]['text':' This isn't actually required for most view operators: it's only required for view ops','line_number':86,'multiline':False]['text':' where you can't figure out what the size of the base tensor is given just the view tensor and arguments.','line_number':87,'multiline':False]['text':' Examples are slice/select/scatter/squeeze/as_strided.','line_number':88,'multiline':False]['text':' We happen to be passing in the base tensor in all cases, mostly to make the codegen simpler.','line_number':89,'multiline':False]['text':' But you'll see below that the "base" argument is ignored by most view_inverse implementations.','line_number':90,'multiline':False]['text':' ----------------------------------------------------------','line_number':92,'multiline':False]['text':' Implementations of each view_inverse() function are below.','line_number':93,'multiline':False]['text':' One of these needs to be implemented for every existing non-composite view operator.','line_number':94,'multiline':False]['text':' The codegen automatically generates the corresponding function declaration.','line_number':95,'multiline':False]['text':' ----------------------------------------------------------','line_number':96,'multiline':False]['text':' Pessimism: we can't reapply views for as_strided_scatter.','line_number':141,'multiline':False]['text':' Pessimism: we can't reapply views for slice_scatter.','line_number':146,'multiline':False]['text':'always_return_non_view=','line_number':151,'multiline':True]['text':' Note that I'm directly calling reshape(), and ignoring the strides.','line_number':159,'multiline':False]['text':' _reshape_alias() isn't available from user code, and is an implementation detail of reshape().','line_number':160,'multiline':False]['text':' Specifically, passing in the strides directly can get us into trouble in cases like:','line_number':161,'multiline':False]['text':' b = a[0]; c = b.reshape(...); c.add_(1); print(a)','line_number':162,'multiline':False]['text':' When we eventually run the _reshape_alias_inverse() call here, if we were to pass in both sizes and strides,','line_number':163,'multiline':False]['text':' The call would fail because `mutated_view` doesn't have enough bytes of storage.','line_number':164,'multiline':False]['text':' Pessimism: we can't reapply views for slice_scatter.','line_number':173,'multiline':False]['text':' the functionalization pass doesn't care about autograd metadata - as a view, I think detach() is just an identity function','line_number':178,'multiline':False]['text':' Pessimism: we can't reapply views for slice_scatter.','line_number':187,'multiline':False]['text':' It would be nice if this logic could be re-used from autograd's split_backward(), but I don't think it can.','line_number':192,'multiline':False]['text':' For functionalization, we have only have one of the tensors from the TensorList outputed by split(), and we want to layer i','line_number':193,'multiline':False]['text':' on top of the base tensor.','line_number':194,'multiline':False]['text':' For autograd, we have all of the tensors outputted by split() and we just want to stack them.','line_number':195,'multiline':False]['text':' Pessimism: we can't reapply views for slice_scatter.','line_number':201,'multiline':False]['text':' Pessimism: we can't reapply views for slice_scatter.','line_number':214,'multiline':False]['text':' Pessimism: we can't reapply views for select_scatter.','line_number':306,'multiline':False]['text':' I think autograd and the functionalization pass want the exact same thing here, but need to test to confirm.','line_number':328,'multiline':False]['text':' unfold_backward() is safe to use here because it is NOT a view op.','line_number':329,'multiline':False]['text':' (note: technically, "reapply_views" won't do anything here and we'll have an extra memory copy.','line_number':330,'multiline':False]['text':' We'd need to add an aliasing version of unfold_backward to fix that though).','line_number':331,'multiline':False]['text':' namespace at::functionalization','line_number':350,'multiline':False]