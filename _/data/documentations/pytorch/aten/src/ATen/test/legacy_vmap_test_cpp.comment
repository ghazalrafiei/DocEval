['text':' NOLINTNEXTLINE(bugprone-argument-comment)','line_number':14,'multiline':False]['text':'lvl=','line_number':15,'multiline':True]['text':'dim=','line_number':15,'multiline':True]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':21,'multiline':False]['text':' Test multiple batch dims','line_number':26,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-argument-comment)','line_number':27,'multiline':False]['text':'lvl=','line_number':28,'multiline':True]['text':'dim=','line_number':28,'multiline':True]['text':' NOLINTNEXTLINE(bugprone-argument-comment)','line_number':29,'multiline':False]['text':'lvl=','line_number':30,'multiline':True]['text':'dim=','line_number':30,'multiline':True]['text':' Test vmap tensor dimensionality limit','line_number':37,'multiline':False]['text':' Should not throw','line_number':39,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-argument-comment)','line_number':41,'multiline':False]['text':'lvl=','line_number':42,'multiline':True]['text':'dim=','line_number':42,'multiline':True]['text':' Should throw','line_number':44,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto,bugprone-argument-comment)','line_number':47,'multiline':False]['text':'lvl=','line_number':48,'multiline':True]['text':'dim=','line_number':48,'multiline':True]['text':' Create a "scalar" BatchedTensor. Should not crash.','line_number':51,'multiline':False]['text':'lvl','line_number':52,'multiline':True]['text':'dim','line_number':52,'multiline':True]['text':' returns {{lvl=0,dim=0}, {lvl=1,dim=1}, ..., {lvl=kVmapNumLevels-1,dim=kVmapNumLevels-1}};','line_number':56,'multiline':False]['text':'dim=','line_number':60,'multiline':True]['text':' Should not throw','line_number':67,'multiline':False]['text':'lvl','line_number':69,'multiline':True]['text':'dim','line_number':69,'multiline':True]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':73,'multiline':False]['text':'lvl','line_number':75,'multiline':True]['text':'dim','line_number':75,'multiline':True]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':80,'multiline':False]['text':'lvl','line_number':82,'multiline':True]['text':'dim','line_number':82,'multiline':True]['text':' create a BatchedTensor with kVmapNumLevels levels.','line_number':86,'multiline':False]['text':' Should not throw','line_number':87,'multiline':False]['text':' create a BatchedTensor with kVmapNumLevels+1 levels.','line_number':92,'multiline':False]['text':'lvl','line_number':95,'multiline':True]['text':'dim','line_number':95,'multiline':True]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':96,'multiline':False]['text':' No batch dims','line_number':103,'multiline':False]['text':' Test wrap around','line_number':110,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':113,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':115,'multiline':False]['text':' test wrap_dim = False','line_number':118,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':119,'multiline':False]['text':'wrap_dim','line_number':120,'multiline':True]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':121,'multiline':False]['text':'wrap_dim','line_number':122,'multiline':True]['text':' Single batch dim at front','line_number':125,'multiline':False]['text':'lvl','line_number':126,'multiline':True]['text':'dim','line_number':126,'multiline':True]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':131,'multiline':False]['text':' Single batch dim in middle','line_number':135,'multiline':False]['text':'lvl','line_number':136,'multiline':True]['text':'dim','line_number':136,'multiline':True]['text':' Single batch dim at end','line_number':143,'multiline':False]['text':'lvl','line_number':144,'multiline':True]['text':'dim','line_number':144,'multiline':True]['text':' Multiple (2) batch dims at front','line_number':151,'multiline':False]['text':'lvl','line_number':154,'multiline':True]['text':'dim','line_number':154,'multiline':True]['text':'lvl','line_number':154,'multiline':True]['text':'dim','line_number':154,'multiline':True]['text':' Multiple (2) batch dims, misc places','line_number':160,'multiline':False]['text':'lvl','line_number':163,'multiline':True]['text':'dim','line_number':163,'multiline':True]['text':'lvl','line_number':163,'multiline':True]['text':'dim','line_number':163,'multiline':True]['text':' ActualDim on kVmapMaxTensorDims sized underlying tensor','line_number':171,'multiline':False]['text':'lvl','line_number':178,'multiline':True]['text':'dim','line_number':178,'multiline':True]['text':' Input is regular Tensor','line_number':190,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':192,'multiline':False]['text':' Input is BatchedTensor, Batch dims are already at the front','line_number':196,'multiline':False]['text':'lvl','line_number':198,'multiline':True]['text':'dim','line_number':198,'multiline':True]['text':'lvl','line_number':198,'multiline':True]['text':'dim','line_number':198,'multiline':True]['text':' Single batch dim, not at front','line_number':205,'multiline':False]['text':'lvl','line_number':207,'multiline':True]['text':'dim','line_number':207,'multiline':True]['text':' Multiple batch dims, not at front.','line_number':215,'multiline':False]['text':'lvl','line_number':217,'multiline':True]['text':'dim','line_number':217,'multiline':True]['text':'lvl','line_number':217,'multiline':True]['text':'dim','line_number':217,'multiline':True]['text':'lvl','line_number':217,'multiline':True]['text':'dim','line_number':217,'multiline':True]['text':' Edge case: kVmapNumLevels levels; batch dims are already at front.','line_number':225,'multiline':False]['text':' sizes=[2, 1, 3, 1, 1, 7, 1, 1, 1, 1, ...]','line_number':227,'multiline':False]['text':' bdims = {{lvl=0,dim=0,lvl=1,dim=1,...,{lvl=63,dim=63}}','line_number':233,'multiline':False]['text':' Edge case: kVmapNumLevels levels; batch dims are not at front','line_number':242,'multiline':False]['text':' sizes=[1, 3, 2, 1, 1, 7, 1, 1, 1, 1, ..., 1, 1, 5]','line_number':244,'multiline':False]['text':' The goal is to permute sizes such that the final sizes are:','line_number':251,'multiline':False]['text':' [2, 3, 5, 7, 1, 1, 1, 1, 1, ...]','line_number':252,'multiline':False]['text':' bdims = {{0, 2}, {1, 1}, {2, 63}, {3, 5}, {4, 0}, {5, 3}, {6, 4},','line_number':259,'multiline':False]['text':'          {7, 6}, {8, 7}, {9, 8}, ..., {63, 62}}','line_number':260,'multiline':False]['text':'dim=','line_number':265,'multiline':True]['text':' Positive dims','line_number':278,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':282,'multiline':False]['text':' Negative dims (testing wrap dim behavior)','line_number':285,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':289,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':299,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':301,'multiline':False]['text':' Simple case: single level','line_number':315,'multiline':False]['text':'levels = {2}','line_number':316,'multiline':True]['text':' Multiple levels','line_number':326,'multiline':False]['text':'levels = {1, 3, 4}','line_number':327,'multiline':True]['text':' Logical dimensions is [].','line_number':337,'multiline':False]['text':'levels = {2}','line_number':338,'multiline':True]['text':' Basic test for BatchedTensor::sum.','line_number':349,'multiline':False]['text':' NB: We don't need to write tests in C++ for batching rules if we can test them','line_number':350,'multiline':False]['text':' in Python via the vmap API. These are here to bootstrap that process.','line_number':351,'multiline':False]['text':' Simple: single batch dim, single reduce dim','line_number':354,'multiline':False]['text':'lvl','line_number':357,'multiline':True]['text':'dim','line_number':357,'multiline':True]['text':' single batch dim, -1 reduce dim handling','line_number':364,'multiline':False]['text':'lvl','line_number':367,'multiline':True]['text':'dim','line_number':367,'multiline':True]['text':' single batch dim, multiple reduce dim','line_number':374,'multiline':False]['text':'lvl','line_number':377,'multiline':True]['text':'dim','line_number':377,'multiline':True]['text':' multiple batch dim, multiple reduce dim','line_number':384,'multiline':False]['text':'lvl','line_number':387,'multiline':True]['text':'dim','line_number':387,'multiline':True]['text':'lvl','line_number':387,'multiline':True]['text':'dim','line_number':387,'multiline':True]['text':' Check that batch dims get moved to the front','line_number':407,'multiline':False]['text':' Check that batch dims become aligned (i.e. extra 1 dims get added)','line_number':419,'multiline':False]['text':' Check that the "example" gets padded with extra dims of size 1.','line_number':431,'multiline':False]['text':' Check batch dims get moved to front, batch dims get aligned,','line_number':443,'multiline':False]['text':' and the example gets padded correctly.','line_number':444,'multiline':False]['text':' Edge case: BatchedTensor "scalar" handling','line_number':459,'multiline':False]['text':' Edge case: Only one tensor is a "batchedtensor scalar"','line_number':470,'multiline':False]['text':' Check same example size','line_number':484,'multiline':False]['text':' BatchedTensor has higher example dim than non-batched-tensor','line_number':498,'multiline':False]['text':' BatchedTensor has lower example dim than non-batched-tensor','line_number':510,'multiline':False]['text':' Scalar handling','line_number':522,'multiline':False]['text':' inputs have all 64 levels','line_number':535,'multiline':False]['text':' inputs don't have all 64 levels, but results do.','line_number':544,'multiline':False]['text':' Construct y_bdims.','line_number':552,'multiline':False]['text':' Basic test for BatchedTensor::mul.','line_number':571,'multiline':False]['text':' batched * batched','line_number':574,'multiline':False]['text':'lvl','line_number':578,'multiline':True]['text':'dim','line_number':578,'multiline':True]['text':'lvl','line_number':579,'multiline':True]['text':'dim','line_number':579,'multiline':True]['text':' batched * unbatched','line_number':588,'multiline':False]['text':'lvl','line_number':592,'multiline':True]['text':'dim','line_number':592,'multiline':True]['text':' batched (level 1) * batched (level 2)','line_number':600,'multiline':False]['text':'lvl','line_number':604,'multiline':True]['text':'dim','line_number':604,'multiline':True]['text':'lvl','line_number':605,'multiline':True]['text':'dim','line_number':605,'multiline':True]['text':' We get a doubly wrapped BatchTensor...','line_number':608,'multiline':False]['text':' batched (level 2, 3, 4) * batched (level 3, 1, 2)','line_number':615,'multiline':False]['text':' Each BatchDim is constructed in {dim, level} format.','line_number':619,'multiline':False]['text':' The batching rule aligns dimensions in the order of their `level`.','line_number':626,'multiline':False]['text':' It just happened that we chose sizes to be in the same order as the level.','line_number':627,'multiline':False]['text':' test for BatchedTensor::size(int).','line_number':634,'multiline':False]['text':' Single batch dim at front','line_number':637,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':645,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':647,'multiline':False]['text':' multiple batch dims not at front','line_number':651,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':661,'multiline':False]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':663,'multiline':False]['text':' Basic test for BatchedTensor::expand','line_number':683,'multiline':False]['text':' Expand size is too small','line_number':686,'multiline':False]['text':'lvl','line_number':688,'multiline':True]['text':'dim','line_number':688,'multiline':True]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':689,'multiline':False]['text':' Expand size has same dimensionality as the logical dim','line_number':693,'multiline':False]['text':'lvl','line_number':695,'multiline':True]['text':'dim','line_number':695,'multiline':True]['text':' Expand size has same dimensionality as the logical dim, incorrect expand size','line_number':703,'multiline':False]['text':'lvl','line_number':705,'multiline':True]['text':'dim','line_number':705,'multiline':True]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':706,'multiline':False]['text':' Expand size has greater dimensionality as the logical dim','line_number':710,'multiline':False]['text':'lvl','line_number':712,'multiline':True]['text':'dim','line_number':712,'multiline':True]['text':' Expand size has greater dimensionality as the logical dim, incorrect expand size','line_number':720,'multiline':False]['text':'lvl','line_number':722,'multiline':True]['text':'dim','line_number':722,'multiline':True]['text':' NOLINTNEXTLINE(hicpp-avoid-goto,cppcoreguidelines-avoid-goto)','line_number':723,'multiline':False]['text':' logical dim is 0, expand size has same dimensionality as logical dim','line_number':727,'multiline':False]['text':' logical dim is 0, expand size has greater dimensionality than logical dim','line_number':736,'multiline':False]['text':' Basic test for BatchedTensor::unsqueeze','line_number':745,'multiline':False]['text':' Basic test','line_number':748,'multiline':False]['text':' NOLINT','line_number':749,'multiline':False]['text':'lvl','line_number':750,'multiline':True]['text':'dim','line_number':750,'multiline':True]['text':' Test with multiple levels','line_number':758,'multiline':False]['text':' NOLINT','line_number':759,'multiline':False]['text':' Negative dim','line_number':768,'multiline':False]['text':' NOLINT','line_number':769,'multiline':False]['text':'lvl','line_number':770,'multiline':True]['text':'dim','line_number':770,'multiline':True]['text':' Basic test for BatchedTensor::squeeze(dim)','line_number':778,'multiline':False]['text':' Basic test','line_number':781,'multiline':False]['text':' NOLINT','line_number':782,'multiline':False]['text':'lvl','line_number':783,'multiline':True]['text':'dim','line_number':783,'multiline':True]['text':' Test with multiple levels','line_number':791,'multiline':False]['text':' NOLINT','line_number':792,'multiline':False]['text':' Negative dim','line_number':801,'multiline':False]['text':' NOLINT','line_number':802,'multiline':False]['text':'lvl','line_number':803,'multiline':True]['text':'dim','line_number':803,'multiline':True]['text':' Basic test for BatchedTensor::transpose','line_number':811,'multiline':False]['text':' Basic test','line_number':814,'multiline':False]['text':' NOLINT','line_number':815,'multiline':False]['text':'lvl','line_number':816,'multiline':True]['text':'dim','line_number':816,'multiline':True]['text':' Test with multiple levels','line_number':824,'multiline':False]['text':' NOLINT','line_number':825,'multiline':False]['text':' Negative dims','line_number':834,'multiline':False]['text':' NOLINT','line_number':835,'multiline':False]['text':'lvl','line_number':836,'multiline':True]['text':'dim','line_number':836,'multiline':True]['text':' Basic test for BatchedTensor::permute','line_number':845,'multiline':False]['text':' Basic test','line_number':848,'multiline':False]['text':' NOLINT','line_number':849,'multiline':False]['text':'lvl','line_number':850,'multiline':True]['text':'dim','line_number':850,'multiline':True]['text':' Test with multiple levels','line_number':858,'multiline':False]['text':' NOLINT','line_number':859,'multiline':False]['text':' Negative dims','line_number':868,'multiline':False]['text':' NOLINT','line_number':869,'multiline':False]['text':'lvl','line_number':870,'multiline':True]['text':'dim','line_number':870,'multiline':True]['text':' Check that batch dims get moved to the front','line_number':892,'multiline':False]['text':'lvl','line_number':896,'multiline':True]['text':'dim','line_number':896,'multiline':True]['text':'lvl','line_number':896,'multiline':True]['text':'dim','line_number':896,'multiline':True]['text':'lvl','line_number':897,'multiline':True]['text':'dim','line_number':897,'multiline':True]['text':'lvl','line_number':897,'multiline':True]['text':'dim','line_number':897,'multiline':True]['text':' Check that batch dims become broadcasted and are present in all returns','line_number':904,'multiline':False]['text':'lvl','line_number':908,'multiline':True]['text':'dim','line_number':908,'multiline':True]['text':'lvl','line_number':908,'multiline':True]['text':'dim','line_number':908,'multiline':True]['text':'lvl','line_number':909,'multiline':True]['text':'dim','line_number':909,'multiline':True]['text':'lvl','line_number':909,'multiline':True]['text':'dim','line_number':909,'multiline':True]['text':' Check operation on tensors of different logical dims','line_number':916,'multiline':False]['text':'lvl','line_number':920,'multiline':True]['text':'dim','line_number':920,'multiline':True]['text':'lvl','line_number':921,'multiline':True]['text':'dim','line_number':921,'multiline':True]['text':' More complicated example with two tensors.','line_number':926,'multiline':False]['text':'lvl','line_number':930,'multiline':True]['text':'dim','line_number':930,'multiline':True]['text':'lvl','line_number':930,'multiline':True]['text':'dim','line_number':930,'multiline':True]['text':'lvl','line_number':931,'multiline':True]['text':'dim','line_number':931,'multiline':True]['text':'lvl','line_number':931,'multiline':True]['text':'dim','line_number':931,'multiline':True]['text':' Edge case: BatchedTensor "scalar" handling','line_number':941,'multiline':False]['text':'lvl','line_number':945,'multiline':True]['text':'dim','line_number':945,'multiline':True]['text':'lvl','line_number':946,'multiline':True]['text':'dim','line_number':946,'multiline':True]['text':'lvl','line_number':946,'multiline':True]['text':'dim','line_number':946,'multiline':True]['text':' Edge case: Only one tensor is a "batchedtensor scalar"','line_number':952,'multiline':False]['text':'lvl','line_number':956,'multiline':True]['text':'dim','line_number':956,'multiline':True]['text':'lvl','line_number':957,'multiline':True]['text':'dim','line_number':957,'multiline':True]['text':'lvl','line_number':957,'multiline':True]['text':'dim','line_number':957,'multiline':True]['text':' Check same example size','line_number':966,'multiline':False]['text':'lvl','line_number':970,'multiline':True]['text':'dim','line_number':970,'multiline':True]['text':'lvl','line_number':970,'multiline':True]['text':'dim','line_number':970,'multiline':True]['text':' BatchedTensor has higher example dim than non-batched-tensor','line_number':980,'multiline':False]['text':'lvl','line_number':984,'multiline':True]['text':'dim','line_number':984,'multiline':True]['text':'lvl','line_number':984,'multiline':True]['text':'dim','line_number':984,'multiline':True]['text':' BatchedTensor has lower example dim than non-batched-tensor','line_number':992,'multiline':False]['text':'lvl','line_number':996,'multiline':True]['text':'dim','line_number':996,'multiline':True]['text':'lvl','line_number':996,'multiline':True]['text':'dim','line_number':996,'multiline':True]['text':' Scalar handling','line_number':1004,'multiline':False]['text':'lvl','line_number':1008,'multiline':True]['text':'dim','line_number':1008,'multiline':True]['text':'lvl','line_number':1008,'multiline':True]['text':'dim','line_number':1008,'multiline':True]['text':' inputs have all 64 levels','line_number':1017,'multiline':False]['text':' inputs don't have all 64 levels, but results do.','line_number':1026,'multiline':False]['text':' Construct y_bdims.','line_number':1034,'multiline':False]['text':' Test with three (all batched) tensors','line_number':1054,'multiline':False]['text':'lvl','line_number':1060,'multiline':True]['text':'dim','line_number':1060,'multiline':True]['text':'lvl','line_number':1060,'multiline':True]['text':'dim','line_number':1060,'multiline':True]['text':'lvl','line_number':1061,'multiline':True]['text':'dim','line_number':1061,'multiline':True]['text':'lvl','line_number':1062,'multiline':True]['text':'dim','line_number':1062,'multiline':True]['text':' Test with three tensors, some batched, some unbatched','line_number':1072,'multiline':False]['text':'lvl','line_number':1078,'multiline':True]['text':'dim','line_number':1078,'multiline':True]['text':'lvl','line_number':1079,'multiline':True]['text':'dim','line_number':1079,'multiline':True]['text':'lvl','line_number':1079,'multiline':True]['text':'dim','line_number':1079,'multiline':True]['text':' namespace','line_number':1092,'multiline':False]