['text':' TODO: Add constructors for all of the descriptors','line_number':25,'multiline':False]['text':' The stride for a size-1 dimensions is not uniquely determined; in','line_number':39,'multiline':False]['text':' fact, it can be anything you want, because the fact that the','line_number':40,'multiline':False]['text':' tensor is size 1 at this dimension means that you will never actually','line_number':41,'multiline':False]['text':' try advancing your pointer by this stride.','line_number':42,'multiline':False]['text':'','line_number':43,'multiline':False]['text':' However, CuDNN has a much more stringent requirement on strides:','line_number':44,'multiline':False]['text':' if you are passing a contiguous input, it better be the case','line_number':45,'multiline':False]['text':' that the stride for dim i is the product of the sizes of dims','line_number':46,'multiline':False]['text':' i+1 to the end.  This stride is indeed uniquely determined.  This','line_number':47,'multiline':False]['text':' function modifies 'stride' in place so this invariant holds.','line_number':48,'multiline':False]['text':' A generic class for wrapping cuDNN descriptor types.  All you need','line_number':83,'multiline':False]['text':' is to give the underlying type the Descriptor_t points to (usually,','line_number':84,'multiline':False]['text':' if it's cudnnTensorDescriptor_t it points to cudnnTensorStruct),','line_number':85,'multiline':False]['text':' the constructor and the destructor.  Subclasses are responsible','line_number':86,'multiline':False]['text':' for defining a set() function to actually set the descriptor.','line_number':87,'multiline':False]['text':'','line_number':88,'multiline':False]['text':' Descriptors default construct to a nullptr, and have a descriptor','line_number':89,'multiline':False]['text':' initialized the first time you call set() or any other initializing','line_number':90,'multiline':False]['text':' function.','line_number':91,'multiline':False]['text':' TODO: Figure out why const-correctness doesn't work here','line_number':95,'multiline':False]['text':' Use desc() to access the underlying descriptor pointer in','line_number':97,'multiline':False]['text':' a read-only fashion.  Most client code should use this.','line_number':98,'multiline':False]['text':' If the descriptor was never initialized, this will return','line_number':99,'multiline':False]['text':' nullptr.','line_number':100,'multiline':False]['text':' Use mut_desc() to access the underlying descriptor pointer','line_number':104,'multiline':False]['text':' if you intend to modify what it points to (e.g., using','line_number':105,'multiline':False]['text':' cudnnSetFooDescriptor).  This will ensure that the descriptor','line_number':106,'multiline':False]['text':' is initialized.  Code in this file will use this function.','line_number':107,'multiline':False]['text':' Note [CuDNN broadcast padding]','line_number':131,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':132,'multiline':False]['text':' pad specifies the minimum dimensionality of the tensor descriptor','line_number':133,'multiline':False]['text':' we produce (it doesn't have anything to do with, e.g., convolution','line_number':134,'multiline':False]['text':' padding).  If 't' is lower-dimensional than 'pad', the remaining','line_number':135,'multiline':False]['text':' dimensions (on the right) are padded with ones.  This doesn't','line_number':136,'multiline':False]['text':' affect the underlying data layout.  This is particularly useful for','line_number':137,'multiline':False]['text':' dealing with a peculiarity of the CuDNN API, which is that broadcasting in CuDNN is','line_number':138,'multiline':False]['text':' done in two steps: first, the client code is expected to pad out','line_number':139,'multiline':False]['text':' (the dimensions) input tensors to be the same dimension as the','line_number':140,'multiline':False]['text':' target broadcast, and then second, CuDNN takes of actually','line_number':141,'multiline':False]['text':' broadcasting size 1 dimensions.','line_number':142,'multiline':False]['text':' aka dilation ','line_number':186,'multiline':True]['text':' See Note [behavior of cudnnFind and cudnnGet]','line_number':192,'multiline':False]['text':' Initialize a dropout descriptor's RNG state.','line_number':221,'multiline':False]['text':' WARNING: This function is very expensive, avoid calling this function!','line_number':222,'multiline':False]['text':' Restore a dropout descriptor given a dropout probability and existing RNG state.','line_number':233,'multiline':False]['text':' NB: The seed doesn't actually matter, so we give a dummy value','line_number':239,'multiline':False]['text':' seed ','line_number':240,'multiline':True]['text':' Restore a dropout descriptor corresponding to no dropout','line_number':243,'multiline':False]['text':' NB: seed doesn't matter when dropout = 0, because no random number','line_number':245,'multiline':False]['text':' initialization actually takes place when there is no dropout.','line_number':246,'multiline':False]['text':' NB: Empirically, cudnnSetDropoutDescriptor is cheap when','line_number':247,'multiline':False]['text':' dropout == 0','line_number':248,'multiline':False]['text':' dropout ','line_number':249,'multiline':True]['text':' state_size ','line_number':249,'multiline':True]['text':' seed ','line_number':249,'multiline':True]['text':'rnnDesc=','line_number':277,'multiline':True]['text':'recProjSize=','line_number':278,'multiline':True]['text':'outProjSize=','line_number':279,'multiline':True]['text':' Technically, as the default it's not necessary to explicitly','line_number':292,'multiline':False]['text':' set this.','line_number':293,'multiline':False]['text':' namespace','line_number':349,'multiline':False]