['text':' namespace native::mkldnn','line_number':19,'multiline':False]['text':' Number of threads set by the user','line_number':23,'multiline':False]['text':' namespace','line_number':27,'multiline':False]['text':' If we are using MKL an OpenMP make sure the number of threads match.','line_number':35,'multiline':False]['text':' Otherwise, MKL and our OpenMP-enabled functions will keep changing the','line_number':36,'multiline':False]['text':' size of the OpenMP thread pool, resulting in worse performance (and memory','line_number':37,'multiline':False]['text':' leaks in GCC 5.4)','line_number':38,'multiline':False]['text':' because PyTorch uses OpenMP outside of MKL invocations','line_number':55,'multiline':False]['text':' as well, we want this flag to be false, so that','line_number':56,'multiline':False]['text':' threads aren't destroyed and recreated across every','line_number':57,'multiline':False]['text':' MKL / non-MKL boundary of OpenMP usage','line_number':58,'multiline':False]['text':' See https://github.com/pytorch/pytorch/issues/13757','line_number':59,'multiline':False]['text':' because PyTorch uses caffe2::pthreadpool() in QNNPACK','line_number':63,'multiline':False]['text':' Explicitly calling omp_get_max_threads() as the size of the parallel','line_number':73,'multiline':False]['text':' region might be different in the new thread;','line_number':74,'multiline':False]['text':' Use init_num_threads() during thread initialization to ensure','line_number':75,'multiline':False]['text':' consistent size of parallel region in different threads','line_number':76,'multiline':False]['text':' execute inline in openmp case','line_number':105,'multiline':False]['text':' namespace at','line_number':117,'multiline':False]