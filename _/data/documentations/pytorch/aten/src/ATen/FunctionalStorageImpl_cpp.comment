['text':' Note [Functionalization: Alias Removal Part 2]','line_number':16,'multiline':False]['text':' See Note [Functionalization: Alias Removal] for more details.','line_number':17,'multiline':False]['text':' This function applies a single update from one of the views to the StorageImpl.','line_number':18,'multiline':False]['text':' We start out with <original_base> and <mutated_view>, and our goal is to end up with <mutated_base>.','line_number':19,'multiline':False]['text':' Consider this program:','line_number':20,'multiline':False]['text':'','line_number':21,'multiline':False]['text':' base = ...','line_number':22,'multiline':False]['text':' a = base.view1()','line_number':23,'multiline':False]['text':' b = a.view2()','line_number':24,'multiline':False]['text':' c = b.view3()','line_number':25,'multiline':False]['text':' c.add_(3)','line_number':26,'multiline':False]['text':'','line_number':27,'multiline':False]['text':' Then the functionalization pass will queue an update as follows:','line_number':28,'multiline':False]['text':'','line_number':29,'multiline':False]['text':' update.new_val = c  # the updated value of c','line_number':30,'multiline':False]['text':' update.view_metas = [view1_meta, view2_meta, view3_meta]','line_number':31,'multiline':False]['text':'','line_number':32,'multiline':False]['text':' Syncing any of a, b or c will eventually call apply_update() on the storage, and the following will run:','line_number':33,'multiline':False]['text':'','line_number':34,'multiline':False]['text':' tmp_values = [base, a, b]  # NB: c is not necessary','line_number':35,'multiline':False]['text':' t = update.new_val','line_number':36,'multiline':False]['text':' t = view3_inverse(b, t, 0)  # 0 is output index, these are all single output views so it's 0','line_number':37,'multiline':False]['text':' t = view2_inverse(a, t, 0)','line_number':38,'multiline':False]['text':' t = view1_inverse(base, t, 0)  # t now represents the updated storage.','line_number':39,'multiline':False]['text':' storage.base_ = t','line_number':40,'multiline':False]['text':' NB: We only actually need tmp_values for ops like select/slice/diagonal/squeeze/as_strided','line_number':50,'multiline':False]['text':' All of these ops require additional information to recover the sizes of the original tensor.','line_number':51,'multiline':False]['text':' If need to, we could probably apply this optimization and only bother computing tmp_values','line_number':52,'multiline':False]['text':' for those necessary view ops.','line_number':53,'multiline':False]['text':' Each view inverse is implemented in ViewInverses.cpp.','line_number':58,'multiline':False]['text':' The functionalization story when wrapping tensors that don't have storage','line_number':67,'multiline':False]['text':' is a bit wonky, but fortunately for some models (e.g., dlrm) we never','line_number':68,'multiline':False]['text':' actually perform mutations on these tensors, so you never really get','line_number':69,'multiline':False]['text':' called out on it.  For now, functionalization still creates "storages"','line_number':70,'multiline':False]['text':' for these tensors (which is wrong), but we don't give them any space.','line_number':71,'multiline':False]['text':' A more proper fix would be to have a SparseFunctionalTensorWrapper that','line_number':72,'multiline':False]['text':' models sparse correctly.','line_number':73,'multiline':False]['text':' Today, the two implementations of SymInt are in Python (proxy tensor),','line_number':78,'multiline':False]['text':' and lazy tensor (LTC/XLA).','line_number':79,'multiline':False]['text':' LTC hasn't implemented SymInt support yet though','line_number':80,'multiline':False]['text':' Once it does, we should remove this check.','line_number':81,'multiline':False]['text':' XLA storage objects also do not properly track nbytes.','line_number':87,'multiline':False]['text':'resizeable=','line_number':97,'multiline':True]['text':' N.B:none of the tensors used in this function should be FunctionalTensorWrappers at this point.','line_number':111,'multiline':False]['text':' The only reason we currently need the TLS exclude guard here is because of functorch's DynamicLayer stack.','line_number':112,'multiline':False]['text':' It adds the Functionalize key into TLS before redispatching to the functionalization kernels,','line_number':113,'multiline':False]['text':' which means that we need to explicitly exclude it here before doing any other work underneath the pass.','line_number':114,'multiline':False]['text':' namespace at::functionalization','line_number':124,'multiline':False]