['text':' This kernel assumes that all input tensors except `weight` and','line_number':62,'multiline':False]['text':' per_sample_weights are contiguous.','line_number':63,'multiline':False]['text':' the strategy here is that each bag x feature is handled by a single thread','line_number':72,'multiline':False]['text':' forces first offset to be 0 instead of asserting on it','line_number':84,'multiline':False]['text':' This kernel assumes that all input tensors except `weight` and','line_number':112,'multiline':False]['text':' per_sample_weights are contiguous.','line_number':113,'multiline':False]['text':' the strategy here is that each bag x feature is handled by a single thread','line_number':123,'multiline':False]['text':' forces first offset to be 0 instead of asserting on it','line_number':136,'multiline':False]['text':' all empty bags','line_number':185,'multiline':False]['text':' int64_t nbits = cuda::cub::get_num_bits(num_weights);','line_number':195,'multiline':False]['text':', 0, nbits','line_number':199,'multiline':True]['text':' Compute an increasing sequence per unique item in sortedIndices:','line_number':208,'multiline':False]['text':' sorted: 2 5 5 5 7 7 8 9 9','line_number':209,'multiline':False]['text':'  count: 1 1 2 3 1 2 1 1 2','line_number':210,'multiline':False]['text':' Take the maximum of each count per unique key in reverse:','line_number':220,'multiline':False]['text':' sorted: 2 5 5 5 7 7 8 9 9','line_number':221,'multiline':False]['text':'  count: 1 3 3 3 2 2 1 2 2','line_number':222,'multiline':False]['text':' If bag is empty, we have max_indices[idx] set to -1 in forward.','line_number':262,'multiline':False]['text':' See Note [Writing Nondeterministic Operations]','line_number':275,'multiline':False]['text':' Nondeterministic because of atomicAdd usage','line_number':276,'multiline':False]['text':' Assumes all input tensors are contiguous.','line_number':310,'multiline':False]['text':' See NOTE [ embedding_bag Native Functions ] in native_functions.yaml for details','line_number':311,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':317,'multiline':False]['text':' Assumes all input tensors are contiguous.','line_number':333,'multiline':False]['text':' See NOTE [ embedding_bag Native Functions ] in native_functions.yaml for details','line_number':334,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':351,'multiline':False]['text':' Check https://github.com/pytorch/pytorch/issues/29019','line_number':369,'multiline':False]['text':' We plan to add one more element in offsets, which is equal to the size of','line_number':370,'multiline':False]['text':' indices. Currently for cuda devices, we still use the legacy','line_number':371,'multiline':False]['text':' implementation even this flag is enabled.','line_number':372,'multiline':False]['text':' offset2bag = [0 0 0 0 0]','line_number':381,'multiline':False]['text':' No need to allocate if we aren't doing a backwards pass','line_number':392,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':437,'multiline':False]['text':' indices, offsets and offset2bag are assumed having correct dtypes and','line_number':441,'multiline':False]['text':' contiguous here due to the checks in _embedding_bag_backward in','line_number':442,'multiline':False]['text':' EmbeddingBag.cpp.','line_number':443,'multiline':False]['text':' Also see NOTE [ embedding_bag Native Functions ] in native_functions.yaml','line_number':444,'multiline':False]['text':' for more details.','line_number':445,'multiline':False]['text':' contiguous','line_number':477,'multiline':False]['text':' contiguous','line_number':478,'multiline':False]['text':' Each warp is responsible for the accumulation of one sample.','line_number':489,'multiline':False]['text':' This involves doing one dot product between grad[bag_idx] and weight[embedding_idx].','line_number':490,'multiline':False]['text':' NB: embedding table, not per_sample_weights','line_number':512,'multiline':False]['text':' Early return when there is no samples in the batch. This saves unnecesary kernel','line_number':541,'multiline':False]['text':' launch, but also prevents cudaGetLastError() to complain about invalid launch args','line_number':542,'multiline':False]['text':' namespace at::native','line_number':567,'multiline':False]