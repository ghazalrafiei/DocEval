['text':' Wrapper function for CUTLASS sparse GEMM implementation, used','line_number':32,'multiline':False]['text':' solely to simplify dispatching from','line_number':33,'multiline':False]['text':' _sparse_semi_structured_linear() function below.','line_number':34,'multiline':False]['text':' Fix CUTLASS sparse GEMM template arguments that are not','line_number':53,'multiline':False]['text':' provided as template argument of this function, and create an','line_number':54,'multiline':False]['text':' alias for particular instantiation of this template.','line_number':55,'multiline':False]['text':' Result of the operation will be provided in row-major format.','line_number':56,'multiline':False]['text':' Tensor cores are to be used for maximum performance.','line_number':57,'multiline':False]['text':' Only CC 8.x devices are suported at the moment.','line_number':58,'multiline':False]['text':' This choice provides good performance across wide range of operand sizes.','line_number':59,'multiline':False]['text':' This choice provides good performance across wide range of operand sizes.','line_number':60,'multiline':False]['text':' Datatype and layout of metadata matrix are inferred from sparse','line_number':78,'multiline':False]['text':' GEMM template.','line_number':79,'multiline':False]['text':' Operand sizes.','line_number':93,'multiline':False]['text':' Check for current CUTLASS limitations w.r.t. input sizes.','line_number':99,'multiline':False]['text':' Determine PyTorch datatype for the metadata matrix.','line_number':111,'multiline':False]['text':' Determine PyTorch datatype for the output matrix.','line_number':130,'multiline':False]['text':' Create output matrix.','line_number':151,'multiline':False]['text':' Prepare arguments for CUTLASS sparse GEMM kernel.','line_number':161,'multiline':False]['text':' Create a tuple of CUTLASS sparse GEMM kernel arguments.','line_number':189,'multiline':False]['text':' Create CUTLASS sparse GEMM kernel object.','line_number':202,'multiline':False]['text':' Verify that sparse GEMM operation with given arguments can be','line_number':205,'multiline':False]['text':' performed by CUTLASS.','line_number':206,'multiline':False]['text':' Allocate workspace for CUTLASS sparse GEMM kernel.','line_number':210,'multiline':False]['text':' Initialize CUTLASS sparse GEMM object.','line_number':215,'multiline':False]['text':' Perform sparse GEMM operation.','line_number':220,'multiline':False]['text':' Dispatch according to the input tensors layouts combination.','line_number':229,'multiline':False]['text':' Determine layouts (row-major or column-major) of input tensors.','line_number':247,'multiline':False]['text':' Perform dispatching.','line_number':255,'multiline':False]['text':' Dispatch according to the activation functions enabled.','line_number':352,'multiline':False]['text':' Perform dispatching.','line_number':372,'multiline':False]['text':' Perform linear transformation, but using corresponding CUTLASS','line_number':464,'multiline':False]['text':' sparse GEMM kernel, to given arguments:','line_number':465,'multiline':False]['text':'     output = input * weight.T + bias','line_number':466,'multiline':False]['text':' The "input" tensor is a dense tensor, while the "weight" tensor is','line_number':467,'multiline':False]['text':' a matrix with 2:4 sparsity pattern.  The "bias" tensor is optional;','line_number':468,'multiline':False]['text':' if provided, it should be a vector, with the number of elements','line_number':469,'multiline':False]['text':' equal to the number of rows of "weight" matrix.  It is assumed','line_number':470,'multiline':False]['text':' that.  It is assummed that "input", after squashing eventual batch','line_number':471,'multiline':False]['text':' dimensions with the next-to-last dimension of this tensor, and','line_number':472,'multiline':False]['text':' "weight" tensors are supplied either in row-major or column-major','line_number':473,'multiline':False]['text':' layouts (different layouts between these two tensors are OK, but','line_number':474,'multiline':False]['text':' not all combinations of formats are supported for some datatypes of','line_number':475,'multiline':False]['text':' these matrices).  The "meta" argument contains metadata matrix. The','line_number':476,'multiline':False]['text':' function returns the output tensor.','line_number':477,'multiline':False]['text':'','line_number':478,'multiline':False]['text':' There exists numerous limitations of CUTLASS sparse GEMM kernel,','line_number':479,'multiline':False]['text':' with regards to sizes and alignments of input tensors, their','line_number':480,'multiline':False]['text':' layouts and datatypes, and so on; this is the reason for large','line_number':481,'multiline':False]['text':' number of checks throughout the code.','line_number':482,'multiline':False]['text':' No need to check that all tensors are on CUDA device, as this','line_number':488,'multiline':False]['text':' is provided by dispatch.','line_number':489,'multiline':False]['text':' Introduce alias names for arguments, according to the CUTLASS','line_number':491,'multiline':False]['text':' naming conventions.  Also, squash the batch dimensions of the','line_number':492,'multiline':False]['text':' input tensor with its next-to-last dimensions.','line_number':493,'multiline':False]['text':' For now, only CC 8.x devices are supported.','line_number':503,'multiline':False]['text':' Validate datatypes of input tensors.','line_number':510,'multiline':False]['text':' Validate layouts of input tensors.','line_number':520,'multiline':False]['text':' Validate sizes of input tensors.','line_number':554,'multiline':False]['text':' Call wrapper function for CUTLASS sparse GEMM, dispatching on','line_number':566,'multiline':False]['text':' the input datatype, and then on input tensors layouts.','line_number':567,'multiline':False]['text':' According to the input tensors datatypes and layouts,','line_number':568,'multiline':False]['text':' correspnding template arguments are supplied for instantiating','line_number':569,'multiline':False]['text':' the wrapper function.  The tile sizes template arguments are','line_number':570,'multiline':False]['text':' selected according to the CUTLASS profiler results, for number','line_number':571,'multiline':False]['text':' of runs.','line_number':572,'multiline':False]['text':' Re-introduce batch dimensions into the output, and return.','line_number':702,'multiline':False]['text':' namespace native','line_number':712,'multiline':False]['text':' namespace at','line_number':713,'multiline':False]['text':' Following is just for testing purposes.','line_number':715,'multiline':False]['text':' Copied from tools/util/include/host_reorder.h, from CUTLASS source','line_number':720,'multiline':False]['text':' tree.  This is for simplicity - namely, this file is not under','line_number':721,'multiline':False]['text':' include/cutlass in this tree, as other CUTLASS include files','line_number':722,'multiline':False]['text':' needed, so it would require changing PyTorch CMake configuration;','line_number':723,'multiline':False]['text':' furthermore, including this file produces build errors in PyTorch','line_number':724,'multiline':False]['text':' at the moment.','line_number':725,'multiline':False]['text':' First reorder the rows.','line_number':732,'multiline':False]['text':' Next swizzle the 2x2 blocks from Z to N.','line_number':739,'multiline':False]['text':' Check dimensions of the dense matrix.','line_number':757,'multiline':False]['text':' Determine PyTorch datatype for the metadata matrix.','line_number':762,'multiline':False]['text':' 0100','line_number':814,'multiline':False]['text':' 1000','line_number':816,'multiline':False]['text':' 1001','line_number':818,'multiline':False]['text':' 1100','line_number':820,'multiline':False]['text':' 1101','line_number':822,'multiline':False]['text':' 1110','line_number':824,'multiline':False]['text':' namespace native','line_number':880,'multiline':False]['text':' namespace at','line_number':881,'multiline':False]