['text':'//////////////////////////////////////////////////////////////////////////////','line_number':9,'multiline':False]['text':' We need to distinguish here, since we want volta support. It is too much effort','line_number':11,'multiline':False]['text':' to write shared memory iterators that are probably needed for volta to function','line_number':12,'multiline':False]['text':' properly. As a result, we allow converters both after the LDG (for volta) and after','line_number':13,'multiline':False]['text':' the LDS for Turing+.','line_number':14,'multiline':False]['text':'/ Iterator for B matrix in global memory','line_number':16,'multiline':False]['text':'/ Warp level Mma','line_number':18,'multiline':False]['text':'/ Math operation perform by warp level operator','line_number':20,'multiline':False]['text':' Dequantize after LDG, so set transforms accordingly','line_number':25,'multiline':False]['text':'/ Iterator for B matrix in global memory','line_number':27,'multiline':False]['text':'/ Mma Policy','line_number':29,'multiline':False]['text':' Dequantize after LDS, so set transforms accordingly','line_number':42,'multiline':False]['text':'/ Iterator for B matrix in global memory','line_number':45,'multiline':False]['text':'/ Mma Policy','line_number':47,'multiline':False]['text':'//////////////////////////////////////////////////////////////////////////////','line_number':59,'multiline':False]['text':'/ Element type for A matrix operand','line_number':62,'multiline':False]['text':'/ Layout type for A matrix operand','line_number':64,'multiline':False]['text':'/ Access granularity of A matrix in units of elements','line_number':66,'multiline':False]['text':'/ Element type for B matrix operand','line_number':68,'multiline':False]['text':'/ Layout type for B matrix operand','line_number':70,'multiline':False]['text':'/ Access granularity of B matrix in units of elements','line_number':72,'multiline':False]['text':'/ Element type for the input scale','line_number':74,'multiline':False]['text':'/ Layout for the scale operand','line_number':76,'multiline':False]['text':'/ Access granularity of Scales in unit of elements','line_number':78,'multiline':False]['text':'/ Element type for internal accumulation','line_number':80,'multiline':False]['text':'/ Layout type for C and D matrix operands','line_number':82,'multiline':False]['text':'/ Operator class tag','line_number':84,'multiline':False]['text':'/ Tag indicating architecture to tune for','line_number':86,'multiline':False]['text':'/ Threadblock-level tile size (concept: GemmShape)','line_number':88,'multiline':False]['text':'/ Warp-level tile size (concept: GemmShape)','line_number':90,'multiline':False]['text':'/ Instruction-level tile size (concept: GemmShape)','line_number':92,'multiline':False]['text':'/ Number of stages used in the pipelined mainloop','line_number':94,'multiline':False]['text':'/ Operation performed by GEMM','line_number':96,'multiline':False]['text':'/ Use zfill or predicate for out-of-bound cp.async','line_number':98,'multiline':False]['text':'/','line_number':100,'multiline':False]['text':' namespace threadblock','line_number':104,'multiline':False]['text':' namespace gemm','line_number':105,'multiline':False]['text':' namespace cutlass','line_number':106,'multiline':False]