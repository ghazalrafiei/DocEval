['text':' For int8, uint8 input, we should not change the data type.','line_number':44,'multiline':False]['text':' NOTE: int32_t dims from ideep::tensor but sizes needs int64_t','line_number':48,'multiline':False]['text':' Make sure that NC11 strides follow formula of contiguous tensor.','line_number':72,'multiline':False]['text':' NOTE: forbid direct convert from non-contiguous (or channels last) to `ideep::tensor`.','line_number':89,'multiline':False]['text':' For int8, uint8 input, we should not change the data type.','line_number':93,'multiline':False]['text':' Mkldnn tensor has special non-public format for conv2d weights','line_number':133,'multiline':False]['text':' (dense_to_mkldnn only converts dense tensor to mkldnn tensor with','line_number':134,'multiline':False]['text':' public format). Ideep conv kernel will do implicit reorder if the','line_number':135,'multiline':False]['text':' weight is not already in this optimized format. By the time I'm','line_number':136,'multiline':False]['text':' writing this note, we are seeing ~20% perf cost of doing the','line_number':137,'multiline':False]['text':' on-the-fly reorder.','line_number':138,'multiline':False]['text':' if has input size, we always use channels last.','line_number':156,'multiline':False]['text':' Legacy mkldnn conv2d jitted module may contain a 5-d weight with an extra','line_number':164,'multiline':False]['text':' dimension when groups > 1, having dimension [g, o/g, i, h, w] instead of','line_number':165,'multiline':False]['text':' [o, i, h, w]. Ideally we should reorder the weight back in serialization.','line_number':166,'multiline':False]['text':' For backward compatibility, we squash the first two dims (g * o/g) back to','line_number':167,'multiline':False]['text':' its original form.','line_number':168,'multiline':False]['text':' weight dtype ','line_number':242,'multiline':True]['text':' src dtype ','line_number':243,'multiline':True]['text':' if has input size, we always use channels last.','line_number':309,'multiline':False]['text':'is_deconv_weights','line_number':339,'multiline':True]['text':' no value fed, provide one here','line_number':441,'multiline':False]['text':' has_biases','line_number':462,'multiline':False]['text':' num_layers','line_number':463,'multiline':False]['text':' bidirectional','line_number':464,'multiline':False]['text':' AT_MKLDNN_ENABLED()','line_number':527,'multiline':False]['text':' AT_MKL_ENABLED && AT_MKLDNN_ENABLED','line_number':573,'multiline':False]