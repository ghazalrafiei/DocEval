['text':' AT_MKLDNN_ENABLED()','line_number':15,'multiline':False]['text':' ConvTranpose padding adjustment','line_number':42,'multiline':False]['text':'','line_number':43,'multiline':False]['text':' PyTorch uses padding/output_padding:','line_number':44,'multiline':False]['text':'   osize = (isize - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1','line_number':45,'multiline':False]['text':'','line_number':46,'multiline':False]['text':' MKLDNN uses padding_l/padding_r:','line_number':47,'multiline':False]['text':'   osize = (isize - 1) * stride - padding_l - padding_r + dilation * (kernel_size - 1) + 1','line_number':48,'multiline':False]['text':'','line_number':49,'multiline':False]['text':' So: padding_l = padding, padding_r = padding - output_padding','line_number':50,'multiline':False]['text':'','line_number':51,'multiline':False]['text':' Make sure input has default contiguous strides if it's contiguous tensors for better performance.','line_number':60,'multiline':False]['text':' For example, for tensor of size = [1, 1280], stride = [0, 1], we'll convert it to size = [1, 1280], stride = [1280, 1]','line_number':61,'multiline':False]['text':' before calling oneDNN for better performance.','line_number':62,'multiline':False]['text':' AT_MKLDNN_ENABLED()','line_number':85,'multiline':False]['text':' Use ideep to check bf16 on X64 as cpuinfo has no avx_ne_convert check.','line_number':101,'multiline':False]