['text':' AT_MKL_ENABLED','line_number':140,'multiline':False]['text':' NB: Ignores the negative bit on tensors','line_number':219,'multiline':False]['text':' conj is a no-op for non-complex types','line_number':223,'multiline':False]['text':' Boolean type does not work with ~ (bitwise NOT) in C++. bitwise_not wraps this operation for both Boolean and','line_number':237,'multiline':False]['text':' integral types.','line_number':238,'multiline':False]['text':' NOTE: this implementation differs from the CUDA implementation which only does single dispatch','line_number':268,'multiline':False]['text':' (to avoid expensive compilation) because CPU kernels don't handle dynamic_casting','line_number':269,'multiline':False]['text':' (see needs_dynamic_casting).','line_number':270,'multiline':False]['text':' NB: Ignores the negative bit on tensors','line_number':288,'multiline':False]['text':' Comparison operators returns bitmask.','line_number':311,'multiline':False]['text':' NOTE: signbit does not always support integral arguments.','line_number':322,'multiline':False]['text':' The iter.dtype() here is the dtype of mantissa output.','line_number':561,'multiline':False]['text':' It's a floating point type and must be the same as the input's dtype.','line_number':562,'multiline':False]['text':' bessel_j0_kernel(TensorIteratorBase& iterator)','line_number':649,'multiline':False]['text':' bessel_j1_kernel(TensorIteratorBase& iterator)','line_number':659,'multiline':False]['text':' bessel_y0_kernel(TensorIteratorBase& iterator)','line_number':669,'multiline':False]['text':' bessel_y1_kernel(TensorIteratorBase& iterator)','line_number':679,'multiline':False]['text':' modified_bessel_i0_kernel(TensorIteratorBase& iterator)','line_number':689,'multiline':False]['text':' modified_bessel_i1_kernel(TensorIteratorBase& iterator)','line_number':699,'multiline':False]['text':' modified_bessel_k0_kernel(TensorIteratorBase& iterator)','line_number':709,'multiline':False]['text':' modified_bessel_k1_kernel(TensorIteratorBase& iterator)','line_number':719,'multiline':False]['text':' TODO: Disable cont. branch to test more risky code','line_number':721,'multiline':False]['text':' If either tensor is contiguous use it, otherwise copy into ','line_number':737,'multiline':True]['text':' a contiguous buffer so compute can still be vectorized ','line_number':738,'multiline':True]['text':' CPU_CAPABILITY namespace','line_number':811,'multiline':False]['text':' The following kernels are slower with AVX512','line_number':813,'multiline':False]['text':' The following kernels are compute-intensive & are compiled with both AVX512','line_number':841,'multiline':False]['text':' & AVX2','line_number':842,'multiline':False]['text':' Might enable AVX512 dispatch after enabling explicit vectorization for them','line_number':853,'multiline':False]['text':' namespace at::native','line_number':887,'multiline':False]