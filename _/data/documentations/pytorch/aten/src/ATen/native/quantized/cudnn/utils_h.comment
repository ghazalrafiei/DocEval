['text':'
This file contains some of the auxiliary functions used by both Conv.cpp & Linear.cpp (introduced in a later PR)
','line_number':2,'multiline':True]['text':' for the definition of AT_CUDNN_ENABLED','line_number':7,'multiline':False]['text':' output channels needs to be stored when we have to pad this dimension','line_number':110,'multiline':False]['text':' cudnn v8.4.0 expects conv2d's int8 weight tensor's input and output channels to be a multiple of 4. if it is not','line_number':173,'multiline':False]['text':' we need to explicitly pad it to a multiple of 4 ourselves as cudnn does not currently support padding, hence the naming','line_number':174,'multiline':False]['text':' convention "maybe"_padded_weight.','line_number':175,'multiline':False]['text':' TODO: when and if cudnn enables padding in their operators, we can remove padding on our end and rename this to orig_weight_','line_number':176,'multiline':False]['text':' TODO: we can remove this function when cuDNN enables pass by value support for','line_number':204,'multiline':False]['text':' pointwise multiplication operations. the only reason why we need this right now is','line_number':205,'multiline':False]['text':' we use broadcasting scalar multiplication in conv, linear, and add ops, and cuDNN requires','line_number':206,'multiline':False]['text':' the scalar to be a scalar tensor with the same number of dimensions (num_dim) as the tensor we're multiplying to','line_number':207,'multiline':False]['text':' alignment are in bytes','line_number':216,'multiline':False]['text':' For the two getTensorDescriptor functions, there is a is_virtual parameter. This parameter is used to set the cudnn','line_number':227,'multiline':False]['text':' tensor as virtual or not. Setting the tensor as virtual is expected to have some performance benefits as the cudnn','line_number':228,'multiline':False]['text':' backend cudnn will no longer directly save to the tensor, allowing us to omit this tensor from the variant pack.','line_number':229,'multiline':False]['text':' See third_party/cudnn_frontend/samples/fusion_sample.cpp for other examples','line_number':230,'multiline':False]['text':' TODO: there is a table from input dtype to operator dtype, we can derive','line_number':274,'multiline':False]['text':' the operator dtype based on input dtype','line_number':275,'multiline':False]['text':' TODO: there is a table from input dtype to operator dtype, we can derive','line_number':283,'multiline':False]['text':' the operator dtype based on input dtype','line_number':284,'multiline':False]['text':' TODO: there is a table from input dtype to operator dtype, we can derive','line_number':292,'multiline':False]['text':' the operator dtype based on input dtype','line_number':293,'multiline':False]['text':' std::cout << "Heuristic has " << heuristics.getEngineConfigCount() << " configurations " << std::endl;','line_number':327,'multiline':False]['text':' Try engine configs returned by the heuristics and pick up the first one that works.','line_number':330,'multiline':False]['text':' std::cout << opGraph.describe() << " has " << total_engines << " engines." << std::endl;','line_number':344,'multiline':False]['text':' std::cout << engine.describe() << std::endl;','line_number':346,'multiline':False]['text':' std::cout << engine_config.describe() << std::endl;','line_number':349,'multiline':False]['text':' anonymous','line_number':354,'multiline':False]['text':' cudnn_utils','line_number':355,'multiline':False]['text':' HAS_CUDNN_V8','line_number':357,'multiline':False]['text':' AT_CUDNN_ENABLED','line_number':358,'multiline':False]['text':' USE_CUDA','line_number':359,'multiline':False]