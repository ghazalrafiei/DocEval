['text':' TODO: make all operations that resize given outputs use this function','line_number':15,'multiline':False]['text':'   for consistency and maintainability.','line_number':16,'multiline':False]['text':'   Some operations like `cat` might not be able to make the use of','line_number':17,'multiline':False]['text':'   resize_output directly. For more details to understand how it works in `cat`,','line_number':18,'multiline':False]['text':'   see https://github.com/pytorch/pytorch/pull/62560#discussion_r687363362','line_number':19,'multiline':False]['text':' Resizes outputs','line_number':20,'multiline':False]['text':' Functions accepting output tensors, like with the "out" kwarg, should','line_number':21,'multiline':False]['text':'   call this function to handle resizing their output tensor.','line_number':22,'multiline':False]['text':' Issues a warning if the output tensor has one or more elements and','line_number':23,'multiline':False]['text':'   needs resizing','line_number':24,'multiline':False]['text':' NOTE: In the future the warning will become an error','line_number':25,'multiline':False]['text':' Returns a bool saying whether or not the resize actually happened or not','line_number':26,'multiline':False]['text':' WARNING: Do NOT call this directly. If you are resizing an output and want','line_number':28,'multiline':False]['text':' to support dynamic shapes call at::resize__symint and resize_output_check_symint.','line_number':29,'multiline':False]['text':' For more details, see: https://github.com/pytorch/pytorch/pull/111530/files#r1365845272','line_number':30,'multiline':False]['text':' Utility for resize_output','line_number':33,'multiline':False]['text':'  Returns a bool saying resize should happen or not and','line_number':34,'multiline':False]['text':'  raises a warning if resizing for one or more elements','line_number':35,'multiline':False]['text':' It does not make sense to try to resize a storage','line_number':43,'multiline':False]['text':' to hold 0 elements, and this can break','line_number':44,'multiline':False]['text':' if storage_offset is positive but','line_number':45,'multiline':False]['text':' new_size is 0, so just bail in that case','line_number':46,'multiline':False]['text':' (same comment is in cuda/Resize.h)','line_number':47,'multiline':False]['text':' NB: (a tensor with arbitrary 0 dims)'s storage can have any numel.','line_number':91,'multiline':False]['text':' FIXME: stride should be optional','line_number':115,'multiline':False]['text':' storage: note this can't be replaced with result.set_(storage) as the semantics of that','line_number':125,'multiline':False]['text':' function is to set the tensor size to be equal to the size of the storage.','line_number':126,'multiline':False]['text':' Caffe2 might have tensors whose storages are null, but we','line_number':128,'multiline':False]['text':' don't allow it in PyTorch.','line_number':129,'multiline':False]['text':' We used to allow this, but this breaks device caching.','line_number':133,'multiline':False]['text':' Let's put an actual error message for this one.','line_number':134,'multiline':False]['text':' storageOffset','line_number':142,'multiline':False]['text':'*
 * Set self's sizes, strides, and storage_offset.
 * (size, stride, storage_offset) must be in bounds for self's storage.
 ','line_number':146,'multiline':True]['text':' storage offset ','line_number':167,'multiline':True]['text':' namespace at::native','line_number':172,'multiline':False]