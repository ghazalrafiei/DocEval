['text':' std::is_same<T, at::BFloat16> || std::is_same<T, at::Half>','line_number':119,'multiline':False]['text':' std::is_same<T, at::BFloat16> || std::is_same<T, at::Half>','line_number':184,'multiline':False]['text':' std::is_same<T, at::BFloat16> || std::is_same<T, at::Half>','line_number':247,'multiline':False]['text':' NB: About algorithm choosen:','line_number':314,'multiline':False]['text':'','line_number':315,'multiline':False]['text':' On channels last, GroupNorm has a input shape of {N, H, W, GD},','line_number':316,'multiline':False]['text':' Mean and rstd are collected per each n and g, which involves reduction','line_number':317,'multiline':False]['text':' on non-adjacent dimensions. We can parallel in the following 2 impls:','line_number':318,'multiline':False]['text':'','line_number':319,'multiline':False]['text':' impl-1: parallel on N * G. Only need one omp session but memory access','line_number':320,'multiline':False]['text':'   per thread is non-contiguous.','line_number':321,'multiline':False]['text':'','line_number':322,'multiline':False]['text':' impl-2: parallel on N * HxW. Memory access per thread is contiguous,','line_number':323,'multiline':False]['text':'   but requires help of extra temp buffer of size {T, N, 2C}.','line_number':324,'multiline':False]['text':'','line_number':325,'multiline':False]['text':' Generally impl-2 has better performance when HxW is large enough, so that','line_number':326,'multiline':False]['text':'   data per thread {NHWC / T} is much larger then temp buffer per thread {2NC}','line_number':327,'multiline':False]['text':'','line_number':328,'multiline':False]['text':' impl-1: parallel on N * G.','line_number':331,'multiline':False]['text':'','line_number':332,'multiline':False]['text':' for each plain of HxW, scale and bias is calculated only once','line_number':333,'multiline':False]['text':' step-1: for each n and g, collect sum of x and x2','line_number':341,'multiline':False]['text':'','line_number':342,'multiline':False]['text':' Note that using vec::map_reduce_all here is simpler to write','line_number':343,'multiline':False]['text':' but it is slower since horizontal reduce from vec to scalar is slow.','line_number':344,'multiline':False]['text':' So it is better to reduce with a vec across all HxW plain,','line_number':345,'multiline':False]['text':' and do a horizontal add just once for each {n, g}.','line_number':346,'multiline':False]['text':'','line_number':347,'multiline':False]['text':' step-2: calculate scale and bias','line_number':360,'multiline':False]['text':' step-3: apply scale and bias','line_number':369,'multiline':False]['text':' impl-2: parallel on N * HxW.','line_number':380,'multiline':False]['text':'','line_number':381,'multiline':False]['text':' temp buffer holding x and x2','line_number':382,'multiline':False]['text':' step-1: accumulate on dimension of C','line_number':390,'multiline':False]['text':'','line_number':391,'multiline':False]['text':' In order to improve multi-core performance when N=1,','line_number':392,'multiline':False]['text':' we parallel on the all the outer dimensions of N and HxW,','line_number':393,'multiline':False]['text':' leaving the most inner dimension C for vectorization.','line_number':394,'multiline':False]['text':'','line_number':395,'multiline':False]['text':' Note that parallel on {N, HxW, G} is not feasible for some common configs,','line_number':396,'multiline':False]['text':' e.g. say input shape is {1, 32, h, w} and G = 8,','line_number':397,'multiline':False]['text':'   this will give D = 4 which is unable to take full SIMD length.','line_number':398,'multiline':False]['text':'','line_number':399,'multiline':False]['text':' To avoid thread conflict, we make use of a temp buffer of {T, N, 2C},','line_number':400,'multiline':False]['text':'   firstly, reduce from {N, HxW, C} to {T, N, 2C}','line_number':401,'multiline':False]['text':'','line_number':402,'multiline':False]['text':' step-2: compute mean and rstd','line_number':418,'multiline':False]['text':' step-3: compute scale and bias','line_number':437,'multiline':False]['text':'','line_number':438,'multiline':False]['text':' mean/rstd have shape of {N, G}, gamma/beta have shape of {G, D}.','line_number':439,'multiline':False]['text':' And scale/bias have shape of {N, C} so that we can directly vectorize on','line_number':440,'multiline':False]['text':' dimension of C in the final step.','line_number':441,'multiline':False]['text':'','line_number':442,'multiline':False]['text':' We could fuse step 3 and 4 into a single session but this way is better:','line_number':443,'multiline':False]['text':'   a. D might be too small for vectorization;','line_number':444,'multiline':False]['text':'   b. Avoid duplicate caculation of scale/bias, each HxW plain share the same scale/bias','line_number':445,'multiline':False]['text':'','line_number':446,'multiline':False]['text':' step-4: apply scale and bias','line_number':464,'multiline':False]['text':'','line_number':465,'multiline':False]['text':' Parallel on on the all the outer dimensions of N and HxW','line_number':466,'multiline':False]['text':' and vectorize on C.','line_number':467,'multiline':False]['text':'','line_number':468,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':573,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':575,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':675,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':677,'multiline':False]['text':' Similar to channels last forward, channels last backward has also 2 impls.','line_number':1396,'multiline':False]['text':' impl-1: parallel on N * G. Only need one omp session for input gradients','line_number':1397,'multiline':False]['text':'   but memory access per thread is non-contiguous.','line_number':1398,'multiline':False]['text':'','line_number':1399,'multiline':False]['text':' impl-2: parallel on N * HxW. Memory access per thread is contiguous,','line_number':1400,'multiline':False]['text':'   but requires help of extra temp buffer of size {T, N, 2C}.','line_number':1401,'multiline':False]['text':' Generally impl-2 has better performance when HxW is large enough, so that','line_number':1403,'multiline':False]['text':'   data per thread {NHWC / T} is much larger then temp buffer per thread {2NC}','line_number':1404,'multiline':False]['text':' impl-1: parallel on N * G.','line_number':1407,'multiline':False]['text':' Step 1. Compute internal gradients.','line_number':1412,'multiline':False]['text':' Step 2. Compute dX.','line_number':1428,'multiline':False]['text':' impl-2: parallel on N * HxW.','line_number':1440,'multiline':False]['text':' Step 1. Each thread compute their own internal gradients to the buffer.','line_number':1450,'multiline':False]['text':' Step 2. Collect internal gradients from each thread and','line_number':1467,'multiline':False]['text':' get the final internal gradients to ds, db, and tmp_buffer.','line_number':1468,'multiline':False]['text':' Step 3. Compute dx.','line_number':1491,'multiline':False]['text':' Finally compute dgamma and dbeta.','line_number':1520,'multiline':False]['text':' In training, using Amp to enable lower precision data type,','line_number':1543,'multiline':False]['text':' i.e., BFloat16 or Half, is recommended.','line_number':1544,'multiline':False]['text':' It will keep module parameters in opmath dtype i.e. float','line_number':1545,'multiline':False]['text':' while input/output will be in lower precision data type.','line_number':1546,'multiline':False]['text':' Using parameters in BFloat16 or Half may cause high precision loss.','line_number':1547,'multiline':False]['text':' namespace','line_number':1585,'multiline':False]['text':' namespace at::native','line_number':1590,'multiline':False]