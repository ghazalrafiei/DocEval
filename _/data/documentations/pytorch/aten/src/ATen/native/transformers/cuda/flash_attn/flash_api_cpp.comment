['text':'*****************************************************************************
 * Copyright (c) 2022, Tri Dao.
 * Copyright (c) 2011-2021, NVIDIA CORPORATION.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *     * Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *     * Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *     * Neither the name of the NVIDIA CORPORATION nor the
 *       names of its contributors may be used to endorse or promote products
 *       derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE FOR ANY
 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 *****************************************************************************','line_number':1,'multiline':True]['text':' sizes','line_number':73,'multiline':False]['text':' device pointers','line_number':83,'multiline':False]['text':' Reset the parameters should be equivalent','line_number':98,'multiline':False]['text':' memset(&params, 0, sizeof(params));','line_number':100,'multiline':False]['text':' Set the pointers and strides.','line_number':104,'multiline':False]['text':' All stride are in elements, not bytes.','line_number':108,'multiline':False]['text':' P = softmax(QK^T)','line_number':130,'multiline':False]['text':' Softmax sum','line_number':133,'multiline':False]['text':' Set the dimensions.','line_number':136,'multiline':False]['text':' Set the different scale values.','line_number':148,'multiline':False]['text':' Set this to probability of keeping an element to simplify things.','line_number':152,'multiline':False]['text':' Convert p from float to int so we don't have to convert the random uint to float to compare.','line_number':154,'multiline':False]['text':' [Minor] We want to round down since when we do the comparison we use <= instead of <','line_number':155,'multiline':False]['text':' params.p_dropout_in_uint = uint32_t(std::floor(params.p_dropout * 4294967295.0));','line_number':156,'multiline':False]['text':' params.p_dropout_in_uint16_t = uint16_t(std::floor(params.p_dropout * 65535.0));','line_number':157,'multiline':False]['text':' Causal is the special case where window_size_right == 0 and window_size_left < 0.','line_number':163,'multiline':False]['text':' Local is the more general case where window_size_right >= 0 or window_size_left >= 0.','line_number':164,'multiline':False]['text':' sizes','line_number':176,'multiline':False]['text':' device pointers','line_number':186,'multiline':False]['text':' Set the pointers and strides.','line_number':220,'multiline':False]['text':' Softmax sum','line_number':245,'multiline':False]['text':' If we don't set it num_splits == 0','line_number':252,'multiline':False]['text':' Find the number of splits that maximizes the occupancy. For example, if we have','line_number':261,'multiline':False]['text':' batch * n_heads = 48 and we have 108 SMs, having 2 splits (efficiency = 0.89) is','line_number':262,'multiline':False]['text':' better than having 3 splits (efficiency = 0.67). However, we also don't want too many','line_number':263,'multiline':False]['text':' splits as that would incur more HBM reads/writes.','line_number':264,'multiline':False]['text':' So we find the best efficiency, then find the smallest number of splits that gets 85%','line_number':265,'multiline':False]['text':' of the best efficiency.','line_number':266,'multiline':False]['text':' If we have enough to almost fill the SMs, then just use 1 split','line_number':268,'multiline':False]['text':' Some splits are not eligible. For example, if we have 64 blocks and choose 11 splits,','line_number':275,'multiline':False]['text':' we'll have 6 * 10 + 4 blocks. If we choose 12 splits, we'll have 6 * 11 + (-2) blocks','line_number':276,'multiline':False]['text':' (i.e. it's 11 splits anyway).','line_number':277,'multiline':False]['text':' So we check if the number of blocks per split is the same as the previous num_splits.','line_number':278,'multiline':False]['text':' printf("num_splits = %d, eff = %f\n", num_splits, eff);','line_number':288,'multiline':False]['text':' printf("num_splits chosen = %d\n", num_splits);','line_number':296,'multiline':False]['text':' return {out, q_padded, k_padded, v_padded, out_padded, softmax_lse, p};','line_number':303,'multiline':False]['text':' batch_size x seqlen_q x num_heads x head_size','line_number':305,'multiline':False]['text':' batch_size x seqlen_k x num_heads_k x head_size','line_number':306,'multiline':False]['text':' batch_size x seqlen_k x num_heads_k x head_size','line_number':307,'multiline':False]['text':' batch_size x seqlen_q x num_heads x head_size','line_number':308,'multiline':False]['text':' bool is_sm75 = dprops->major == 7 && dprops->minor == 5;','line_number':318,'multiline':False]['text':' We will support Turing in the near future','line_number':322,'multiline':False]['text':' TORCH_CHECK(is_sm90 || is_sm8x || is_sm75, "FlashAttention only supports Turing GPUs or newer.");','line_number':323,'multiline':False]['text':' causal=true is the same as causal=false in this case','line_number':353,'multiline':False]['text':' Faster to transpose q from (b, 1, (nheads_kv ngroups), d) to (b, ngroups, nheads_kv, d) in this case','line_number':356,'multiline':False]['text':' H/t Daniel Haziza','line_number':357,'multiline':False]['text':' Otherwise the kernel will be launched from cuda:0 device','line_number':394,'multiline':False]['text':' Cast to char to avoid compiler warning about narrowing','line_number':395,'multiline':False]['text':' Only return softmax if there's dropout to reduce compilation time','line_number':402,'multiline':False]['text':'cu_seqlens_q_d=','line_number':416,'multiline':True]['text':'cu_seqlens_k_d=','line_number':417,'multiline':True]['text':'seqused_k=','line_number':418,'multiline':True]['text':' This needs to match with run_mha_fwd_splitkv_dispatch','line_number':426,'multiline':False]['text':' Technically kBlockM = 64 only for the splitKV kernels, not the standard kernel.','line_number':429,'multiline':False]['text':' In any case we don't expect seqlen_q to be larger than 64 for inference.','line_number':430,'multiline':False]['text':' SplitKV is not implemented for dropout','line_number':433,'multiline':False]['text':' We want to checkpoint and save the RNG state for backward if dropout','line_number':444,'multiline':False]['text':' We get the default generator and return the seed and offset which will','line_number':445,'multiline':False]['text':' be used in the backward function','line_number':446,'multiline':False]['text':' number of times random will be generated per thread, to offset philox counter in thc random','line_number':450,'multiline':False]['text':' state','line_number':451,'multiline':False]['text':' We use a custom RNG that increases the offset by batch_size * nheads * 32.','line_number':452,'multiline':False]['text':' See Note [Acquire lock when using random generators]','line_number':454,'multiline':False]['text':' If seqlen_k == 0, then we have an empty tensor. We need to set the output to 0.','line_number':483,'multiline':False]['text':' total_q x num_heads x head_size, total_q := \sum_{i=0}^{b} s_i','line_number':497,'multiline':False]['text':' total_k x num_heads_k x head_size, total_k := \sum_{i=0}^{b} s_i','line_number':498,'multiline':False]['text':' total_k x num_heads_k x head_size, total_k := \sum_{i=0}^{b} s_i','line_number':499,'multiline':False]['text':' total_q x num_heads x head_size, total_k := \sum_{i=0}^{b} s_i','line_number':500,'multiline':False]['text':' b+1','line_number':501,'multiline':False]['text':' b+1','line_number':502,'multiline':False]['text':' b. If given, only this many elements of each batch element's keys are used.','line_number':503,'multiline':False]['text':' bool is_sm75 = dprops->major == 7 && dprops->minor == 5;','line_number':517,'multiline':False]['text':' We will support Turing in the near future','line_number':521,'multiline':False]['text':' TORCH_CHECK(is_sm90 || is_sm8x || is_sm75, "FlashAttention only supports Turing GPUs or newer.");','line_number':522,'multiline':False]['text':' Otherwise the kernel will be launched from cuda:0 device','line_number':594,'multiline':False]['text':' Cast to char to avoid compiler warning about narrowing','line_number':595,'multiline':False]['text':' Only return softmax if there's dropout to reduce compilation time','line_number':602,'multiline':False]['text':' We want to checkpoint and save the RNG state for backward if dropout','line_number':632,'multiline':False]['text':' We get the default generator and return the seed and offset which will','line_number':633,'multiline':False]['text':' be used in the backward function','line_number':634,'multiline':False]['text':' number of times random will be generated per thread, to offset philox counter in thc random','line_number':638,'multiline':False]['text':' state','line_number':639,'multiline':False]['text':' We use a custom RNG that increases the offset by batch_size * nheads * 32.','line_number':640,'multiline':False]['text':' See Note [Acquire lock when using random generators]','line_number':642,'multiline':False]['text':' batch_size x seqlen_q x num_heads, x head_size_og','line_number':696,'multiline':False]['text':' batch_size x seqlen_q x num_heads x head_size','line_number':697,'multiline':False]['text':' batch_size x seqlen_k x num_heads_k x head_size','line_number':698,'multiline':False]['text':' batch_size x seqlen_k x num_heads_k x head_size','line_number':699,'multiline':False]['text':' batch_size x seqlen_q x num_heads x head_size','line_number':700,'multiline':False]['text':' b x h x seqlen_q','line_number':701,'multiline':False]['text':' batch_size x seqlen_q x num_heads x head_size','line_number':702,'multiline':False]['text':' batch_size x seqlen_k x num_heads_k x head_size','line_number':703,'multiline':False]['text':' batch_size x seqlen_k x num_heads_k x head_size','line_number':704,'multiline':False]['text':' probability to drop','line_number':705,'multiline':False]['text':' bool is_sm75 = dprops->major == 7 && dprops->minor == 5;','line_number':715,'multiline':False]['text':' We will support Turing in the near future','line_number':720,'multiline':False]['text':' TORCH_CHECK(is_sm90 || is_sm8x || is_sm75, "FlashAttention only supports Turing GPUs or newer.");','line_number':721,'multiline':False]['text':' const at::Tensor& dout_padded = dout;','line_number':806,'multiline':False]['text':' bool loop = seqlen_k > blocksize_c;','line_number':808,'multiline':False]['text':' TODO: change later, for now set to true for simplicity','line_number':809,'multiline':False]['text':' Otherwise the kernel will be launched from cuda:0 device','line_number':812,'multiline':False]['text':' Cast to char to avoid compiler warning about narrowing','line_number':813,'multiline':False]['text':' dk_accum = at::empty({batch_size, num_heads_k, seqlen_k_rounded, head_size_rounded}, opts.dtype(at::kFloat));','line_number':822,'multiline':False]['text':' dv_accum = at::empty({batch_size, num_heads_k, seqlen_k_rounded, head_size_rounded}, opts.dtype(at::kFloat));','line_number':823,'multiline':False]['text':' MQA / GQA','line_number':827,'multiline':False]['text':' loop ? dk_accum.data_ptr() : nullptr,','line_number':848,'multiline':False]['text':' loop ? dv_accum.data_ptr() : nullptr,','line_number':849,'multiline':False]['text':' launch(params, stream, /*configure=*/true);','line_number':860,'multiline':False]['text':' dropout + capture','line_number':868,'multiline':False]['text':'configure=','line_number':876,'multiline':True]['text':' If seqlen_q == 0, then we have an empty tensor. We need to set the output to 0.','line_number':878,'multiline':False]['text':' For MQA/GQA we need to sum dK and dV across the groups','line_number':884,'multiline':False]['text':' total_q x num_heads, x head_size','line_number':893,'multiline':False]['text':' total_q x num_heads x head_size, total_q := \sum_{i=0}^{b} s_i','line_number':894,'multiline':False]['text':' total_k x num_heads_k x head_size, total_k := \sum_{i=0}^{b} s_i','line_number':895,'multiline':False]['text':' total_k x num_heads_k x head_size, total_k := \sum_{i=0}^{b} s_i','line_number':896,'multiline':False]['text':' total_q x num_heads x head_size','line_number':897,'multiline':False]['text':' b x h x s   softmax logsumexp','line_number':898,'multiline':False]['text':' total_q x num_heads x head_size, total_q := \sum_{i=0}^{b} s_i','line_number':899,'multiline':False]['text':' total_k x num_heads_k x head_size, total_k := \sum_{i=0}^{b} s_i','line_number':900,'multiline':False]['text':' total_k x num_heads_k x head_size, total_k := \sum_{i=0}^{b} s_i','line_number':901,'multiline':False]['text':' b+1','line_number':902,'multiline':False]['text':' b+1','line_number':903,'multiline':False]['text':' max sequence length to choose the kernel','line_number':905,'multiline':False]['text':' probability to drop','line_number':906,'multiline':False]['text':' bool is_sm75 = dprops->major == 7 && dprops->minor == 5;','line_number':917,'multiline':False]['text':' We will support Turing in the near future','line_number':922,'multiline':False]['text':' TORCH_CHECK(is_sm90 || is_sm8x || is_sm75, "FlashAttention only supports Turing GPUs or newer.");','line_number':923,'multiline':False]['text':' const at::Tensor& dout_padded = dout;','line_number':1014,'multiline':False]['text':' bool loop = max_seqlen_k > blocksize_c;','line_number':1016,'multiline':False]['text':' TODO: change later, for now set to true for simplicity','line_number':1017,'multiline':False]['text':' Otherwise the kernel will be launched from cuda:0 device','line_number':1020,'multiline':False]['text':' Cast to char to avoid compiler warning about narrowing','line_number':1021,'multiline':False]['text':' We don't want to allocate dq_accum of size (batch, seqlen_q_rounded, num_heads, head_size_rounded)','line_number':1028,'multiline':False]['text':' because that would be too large if there is a very long sequence and the rest of the sequences are short.','line_number':1029,'multiline':False]['text':' Instead, we allocate dq_accum of size (total_q + 128 * batch, num_heads, head_size_rounded).','line_number':1030,'multiline':False]['text':' Note that 128 is the max block size on the seqlen_q dimension.','line_number':1031,'multiline':False]['text':' For dQ, the i-th sequence is stored in indices from cu_seqlens[i] + 128 * i to','line_number':1032,'multiline':False]['text':' cu_seqlens[i + 1] * 128 * i - 1. This ensures that the i-th sequence and (i + 1)-th sequence will','line_number':1033,'multiline':False]['text':' be at least 128 apart. It's ok for us to do atomicAdds up to 128 rows beyond what we're normally','line_number':1034,'multiline':False]['text':' allowed to do. So we won't have to do any bound checking, and performance should stay the same.','line_number':1035,'multiline':False]['text':' MQA / GQA','line_number':1040,'multiline':False]['text':' launch(params, stream, /*configure=*/true);','line_number':1078,'multiline':False]['text':' dropout + capture','line_number':1086,'multiline':False]['text':'configure=','line_number':1093,'multiline':True]['text':' For MQA/GQA we need to sum dK and dV across the groups','line_number':1095,'multiline':False]['text':' batch_size x seqlen_q x num_heads x head_size','line_number':1105,'multiline':False]['text':' batch_size_c x seqlen_k x num_heads_k x head_size','line_number':1106,'multiline':False]['text':' batch_size_c x seqlen_k x num_heads_k x head_size','line_number':1107,'multiline':False]['text':' batch_size x seqlen_knew x num_heads_k x head_size','line_number':1108,'multiline':False]['text':' batch_size x seqlen_knew x num_heads_k x head_size','line_number':1109,'multiline':False]['text':' batch_size','line_number':1110,'multiline':False]['text':' seqlen_ro x (rotary_dim / 2)','line_number':1111,'multiline':False]['text':' seqlen_ro x (rotary_dim / 2)','line_number':1112,'multiline':False]['text':' indices to index into the KV cache','line_number':1113,'multiline':False]['text':' batch_size x seqlen_q x num_heads x head_size','line_number':1114,'multiline':False]['text':' if true, rotary combines indices 0 & 1, else indices 0 & rotary_dim / 2','line_number':1119,'multiline':False]['text':' bool is_sm75 = dprops->major == 7 && dprops->minor == 5;','line_number':1124,'multiline':False]['text':' We will support Turing in the near future','line_number':1128,'multiline':False]['text':' TORCH_CHECK(is_sm90 || is_sm8x || is_sm75, "FlashAttention only supports Turing GPUs or newer.");','line_number':1129,'multiline':False]['text':' causal=true is the same as causal=false in this case','line_number':1159,'multiline':False]['text':' Faster to transpose q from (b, 1, (nheads_kv ngroups), d) to (b, ngroups, nheads_kv, d) in this case','line_number':1162,'multiline':False]['text':' H/t Daniel Haziza','line_number':1163,'multiline':False]['text':' q_padded = at::nn::functional::pad(q, at::nn::functional::PadFuncOptions({0, 8 - head_size_og % 8}));','line_number':1181,'multiline':False]['text':' kcache_padded = at::nn::functional::pad(kcache, at::nn::functional::PadFuncOptions({0, 8 - head_size_og % 8}));','line_number':1182,'multiline':False]['text':' vcache_padded = at::nn::functional::pad(vcache, at::nn::functional::PadFuncOptions({0, 8 - head_size_og % 8}));','line_number':1183,'multiline':False]['text':' Otherwise the kernel will be launched from cuda:0 device','line_number':1208,'multiline':False]['text':' Cast to char to avoid compiler warning about narrowing','line_number':1209,'multiline':False]['text':'cu_seqlens_q_d=','line_number':1224,'multiline':True]['text':'cu_seqlens_k_d=','line_number':1225,'multiline':True]['text':'seqused_k=','line_number':1226,'multiline':True]['text':'p_ptr=','line_number':1227,'multiline':True]['text':'p_dropout=','line_number':1229,'multiline':True]['text':' k_padded = at::nn::functional::pad(k, at::nn::functional::PadFuncOptions({0, 8 - head_size_og % 8}));','line_number':1252,'multiline':False]['text':' v_padded = at::nn::functional::pad(v, at::nn::functional::PadFuncOptions({0, 8 - head_size_og % 8}));','line_number':1253,'multiline':False]['text':' All stride are in elements, not bytes.','line_number':1261,'multiline':False]['text':' This needs to match with run_mha_fwd_splitkv_dispatch','line_number':1313,'multiline':False]['text':' Technically kBlockM = 64 only for the splitKV kernels, not the standard kernel.','line_number':1316,'multiline':False]['text':' In any case we don't expect seqlen_q to be larger than 64 for inference.','line_number':1317,'multiline':False]['text':' Only split kernel supports appending to KV cache, or indexing to the cache with cache_batch_idx','line_number':1332,'multiline':False]['text':'force_split_kernel=','line_number':1333,'multiline':True]['text':' out = out.index({"...", at::indexing::Slice(at::indexing::None, head_size_og)});','line_number':1336,'multiline':False]['text':' It's expensive to copy the KV cache here for the case where head size not divisible by 8,','line_number':1340,'multiline':False]['text':' but we don't expect to get this case in practice. This is just so that the code works for that case.','line_number':1341,'multiline':False]['text':' kcache.copy_(kcache_padded.index({"...", at::indexing::Slice(at::indexing::None, head_size_og)}));','line_number':1344,'multiline':False]['text':' vcache.copy_(vcache_padded.index({"...", at::indexing::Slice(at::indexing::None, head_size_og)}));','line_number':1345,'multiline':False]['text':' namespace pytorch_fmha','line_number':1355,'multiline':False]