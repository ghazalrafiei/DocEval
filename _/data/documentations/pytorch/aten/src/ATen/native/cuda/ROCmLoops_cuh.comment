['text':' This file provides two functions to help write GPU elementwise kernels:','line_number':3,'multiline':False]['text':'','line_number':4,'multiline':False]['text':'   gpu_kernel(TensorIterator iter, <lambda>)','line_number':5,'multiline':False]['text':'   gpu_kernel_with_scalars(TensorIterator iter, <lambda>)','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':' The gpu_kernel_with_scalars generates specializations that support a','line_number':8,'multiline':False]['text':' single scalar CPU argument, such as from `cuda_tensor + 5`. The CPU scalar','line_number':9,'multiline':False]['text':' is lifted to a kernel parameter instead of copying to device memory.','line_number':10,'multiline':False]['text':' This should be  used in conjunction with TensorIterator::allow_cpu_scalars_,','line_number':11,'multiline':False]['text':' which is the default for TensorIterator::binary_op. Otherwise, all inputs','line_number':12,'multiline':False]['text':' and the output must be on the GPU.','line_number':13,'multiline':False]['text':'','line_number':14,'multiline':False]['text':' For example, to write a reciprocal kernel for GPU float Tensors:','line_number':15,'multiline':False]['text':'','line_number':16,'multiline':False]['text':'   gpu_kernel(iter, []GPU_LAMBDA(float a) {','line_number':17,'multiline':False]['text':'    return 1.0f / a;','line_number':18,'multiline':False]['text':'   });','line_number':19,'multiline':False]['text':'','line_number':20,'multiline':False]['text':' To write a multiplication kernel for GPU float Tensors where one argument','line_number':21,'multiline':False]['text':' may be a CPU scalar:','line_number':22,'multiline':False]['text':'','line_number':23,'multiline':False]['text':'   gpu_kernel_with_scalars(iter, []GPU_LAMBDA(float a, float b) {','line_number':24,'multiline':False]['text':'     return a * b;','line_number':25,'multiline':False]['text':'   });','line_number':26,'multiline':False]['text':'','line_number':27,'multiline':False]['text':' See BinaryOpsKernel.cu for the complete implementation','line_number':28,'multiline':False]['text':'','line_number':29,'multiline':False]['text':' See [NOTE: Complex Operator Unification]','line_number':58,'multiline':False]['text':' std::complex and thrust::complex don't work with some !needs_dynamic_casting optimizations.','line_number':59,'multiline':False]['text':' They always currently map to !needs_dynamic_casting even though we sometimes rely on the ability','line_number':60,'multiline':False]['text':' to reinterpret_cast between these representations.','line_number':61,'multiline':False]['text':' In order to separate these concerns, we have a check for non-c10 complex separately.','line_number':62,'multiline':False]['text':' NOTE: @zasdfgbnm is currently working on rewriting the gpu loops.','line_number':97,'multiline':False]['text':' Some of the old codes has been moved to namespace legacy, and','line_number':98,'multiline':False]['text':' new codes will be put into namespace modern. These two namespaces','line_number':99,'multiline':False]['text':' will coexists for a while until the rewrite is done. Once the rewrite','line_number':100,'multiline':False]['text':' is done, we will remove the legacy and modern namespace and everything','line_number':101,'multiline':False]['text':' will be in at::native directly.','line_number':102,'multiline':False]['text':' namespace legacy','line_number':161,'multiline':False]['text':' See the note for namespace legacy above.','line_number':163,'multiline':False]['text':' We need a way to compute the argument type of a function. But','line_number':181,'multiline':False]['text':' for nullary function, it does not really have an argument type','line_number':182,'multiline':False]['text':' in this case, we still need to return a valid type, but we don't','line_number':183,'multiline':False]['text':' really care what type this is.','line_number':184,'multiline':False]['text':' namespace arg_type','line_number':201,'multiline':False]['text':' namespace detail','line_number':222,'multiline':False]['text':' Assumption:','line_number':227,'multiline':False]['text':' 1. all arguments of `f` have the same type, which could be different from the return type of `f`','line_number':228,'multiline':False]['text':' 2. all tensors are contiguous, that is: stride == sizeof(type) for all tensors','line_number':229,'multiline':False]['text':' We need to create array to hold all the arguments, for nullary `f`, this means array of size 0.','line_number':236,'multiline':False]['text':' Unfortunately the compiler don't allow us to create array of 0 size, so for this case, we create','line_number':237,'multiline':False]['text':' an array of size 1 and just don't use it.','line_number':238,'multiline':False]['text':' compute base pointers','line_number':244,'multiline':False]['text':' fetch data','line_number':252,'multiline':False]['text':' compute','line_number':265,'multiline':False]['text':' store data','line_number':273,'multiline':False]['text':' TODO (@zasdfgbnm): this function assume trivial 1d and no dynamic casting','line_number':282,'multiline':False]['text':' namespace modern','line_number':298,'multiline':False]['text':' TODO: can non_c10_complex go through the other path?  Need to verify.','line_number':329,'multiline':False]['text':' TODO: can non_c10_complex go through the other path?  Need to verify.','line_number':346,'multiline':False]['text':' namespace at::native','line_number':364,'multiline':False]