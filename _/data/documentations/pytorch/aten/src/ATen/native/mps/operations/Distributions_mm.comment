['text':'  Copyright Â© 2022 Apple Inc.','line_number':1,'multiline':False]['text':' Only relevant for multinomial','line_number':35,'multiline':False]['text':' used for Normal distributions only','line_number':39,'multiline':False]['text':' for Uniform distributions with scalar from (val1) and to (val2) intervals','line_number':46,'multiline':False]['text':' for Normal distributions with scalar mean (val1) and std (val2) values','line_number':47,'multiline':False]['text':' FP16, FP32 and Int32 are the only data types supported for distributions on MPS backend.','line_number':71,'multiline':False]['text':' only for random_mps, we pass interval range of type int64_t','line_number':73,'multiline':False]['text':' we don't use the output state tensor from the MPSGraph API as it requires reading back from GPU to CPU.','line_number':95,'multiline':False]['text':' Instead, we keep the Philox state in the MPSGenerator and use the PyTorch's philox_engine to maintain','line_number':96,'multiline':False]['text':' the counters, and feed them to the graph manually','line_number':97,'multiline':False]['text':' results will be cast if self's scalar type isn't directly supported by MPS backend.','line_number':103,'multiline':False]['text':' feed the updated state values to the graph','line_number':107,'multiline':False]['text':' See Note [Acquire lock when using random generators]','line_number':112,'multiline':False]['text':' update the Philox state values on each run','line_number':114,'multiline':False]['text':' Bernoulli generates binary output so we use bool type','line_number':218,'multiline':False]['text':' namespace mps','line_number':230,'multiline':False]['text':' when there's no tensor-type mean, we cannot pass scalar mean value due to the order of','line_number':275,'multiline':False]['text':' multiply/add ops in random computation. So we create a mean tensor instead.','line_number':276,'multiline':False]['text':' when there's no tensor-type mean, we cannot pass scalar mean value due to the order of','line_number':292,'multiline':False]['text':' multiply/add ops in random computation. So we create a mean tensor instead.','line_number':293,'multiline':False]['text':' random_.from','line_number':318,'multiline':False]['text':' [from, to)','line_number':324,'multiline':False]['text':' [from, std::numeric_limits<int64_t>::max()]','line_number':342,'multiline':False]['text':'includeBool=','line_number':357,'multiline':True]['text':' [std::numeric_limits<int64_t>::lowest(), std::numeric_limits<int64_t>::max()]','line_number':370,'multiline':False]['text':' range = 2^64','line_number':371,'multiline':False]['text':' TODO - should we error out in case max is beyond MPS limit (INT32_MAX)?','line_number':373,'multiline':False]['text':' Exponential distribution','line_number':389,'multiline':False]['text':' Restructure data for 2d','line_number':471,'multiline':False]['text':' This is probability weights','line_number':485,'multiline':False]['text':' update the Philox state values on each run of the same graph','line_number':559,'multiline':False]['text':' See Note [Acquire lock when using random generators]','line_number':564,'multiline':False]['text':' update the Philox state values on each run','line_number':566,'multiline':False]['text':' The largest consecutive integer representable in float32 (2^24) ','line_number':587,'multiline':True]['text':' Since the index tensor is float, numCategories cannot exceed max','line_number':606,'multiline':False]['text':' float integer precision','line_number':607,'multiline':False]['text':' Fast-path for no replacement (or if only one sample draw).','line_number':620,'multiline':False]['text':' Reference:','line_number':621,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/11931#issuecomment-625882503','line_number':622,'multiline':False]['text':' Sanity checks on `self`.','line_number':624,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-init-variables)','line_number':627,'multiline':False]['text':' The algorithm is from gumbel softmax.','line_number':636,'multiline':False]['text':' s = argmax( logp - log(-log(eps)) ) where eps ~ U(0, 1)','line_number':637,'multiline':False]['text':' Here we can apply exp to the formula which will not affect result of','line_number':638,'multiline':False]['text':' argmax or topk. Then we have','line_number':639,'multiline':False]['text':' s = argmax( p / (-log(eps)) ) where eps ~ U(0, 1).','line_number':640,'multiline':False]['text':' We can also simplify the formula above by','line_number':641,'multiline':False]['text':' s = argmax( p / q ) where q ~ Exp(1)','line_number':642,'multiline':False]['text':' In theory the probability to generate 0 from exponential distribution is','line_number':644,'multiline':False]['text':' 0. However, on CUDA side there is a protection to avoid 0s, but on CPU','line_number':645,'multiline':False]['text':' side, there is a very low probability to generate 0 from','line_number':646,'multiline':False]['text':' exponential<double>. The probability is about 2^(-DBL_MANT_DIG). We just','line_number':647,'multiline':False]['text':' ignore it here, but there may be some risk to get invalid output on CPU.','line_number':648,'multiline':False]['text':'dim=','line_number':651,'multiline':True]['text':'keepdim=','line_number':651,'multiline':True]['text':' namespace at::native','line_number':670,'multiline':False]