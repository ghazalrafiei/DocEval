['text':' Check if tensor list has either a boolean tensor or a integer tensor','line_number':22,'multiline':False]['text':' check if tensor list has bool tensors','line_number':29,'multiline':False]['text':' Check foreach API restrictions','line_number':36,'multiline':False]['text':' - Tensor lists must be non-empty.','line_number':37,'multiline':False]['text':' - All TensorLists and ScalarLists must have the same number of elements.','line_number':38,'multiline':False]['text':' - Corresponding tensors must have the same size.','line_number':39,'multiline':False]['text':' Helper function called in check_fast_path_restrictions to check whether all','line_number':101,'multiline':False]['text':' corresponding tensors (aligning in index across the tensorLists) share the','line_number':102,'multiline':False]['text':' same device and dtype.','line_number':103,'multiline':False]['text':' Helper function called in check_fast_path_restrictions to check if','line_number':126,'multiline':False]['text':' corresponding tensors in tensor lists have the same sizes and strides.','line_number':127,'multiline':False]['text':' Helper function called in check_fast_path_restrictions to check whether','line_number':142,'multiline':False]['text':' all tensors type promote properly with the scalars in scalarList. This','line_number':143,'multiline':False]['text':' function assumes that _check_tensors_share_device_and_dtype has already been','line_number':144,'multiline':False]['text':' called so that all corresponding tensors in tensorLists have the same dtype.','line_number':145,'multiline':False]['text':' Then, it is sufficient to check the type promotion with just one tensorList.','line_number':146,'multiline':False]['text':' For division, integer inputs will result in float.','line_number':152,'multiline':False]['text':'includeBool','line_number':155,'multiline':True]['text':' note(mkozuki): This check might be responsible for','line_number':163,'multiline':False]['text':' `_foreach_add(bool_tensors, bool_tensors)` being pushed to slow path.','line_number':164,'multiline':False]['text':' To go via 'fast' path, several conditions must be satisfied','line_number':174,'multiline':False]['text':' - All tensors in all lists must have the same dtype.','line_number':175,'multiline':False]['text':' - All tensors must be on the same device','line_number':176,'multiline':False]['text':' - All tensors must have strided layout','line_number':177,'multiline':False]['text':' - All tensors must be non-overlapping and dense','line_number':178,'multiline':False]['text':' - Resulting tensor must have the same dtype as the input one','line_number':179,'multiline':False]['text':' Please, make sure to call check_foreach_api_restrictions before calling this','line_number':181,'multiline':False]['text':' method. There is a set of preconditions that have to be satisfied.','line_number':182,'multiline':False]['text':' note(crcrpar): Allow empty tensorlists following','line_number':274,'multiline':False]['text':' ref:','line_number':275,'multiline':False]['text':' https://github.com/pytorch/pytorch/blob/85885301fd3c6adb8b9dc3cf7afadf6945566684/torch/utils/_foreach_utils.py#L21-L24','line_number':276,'multiline':False]['text':' note(crcrpar): Currently the scope of this function is','line_number':300,'multiline':False]['text':' optimizers so there could be `state_steps` and other scalars','line_number':301,'multiline':False]['text':' whose elements are float tensors no matter what the parameter's','line_number':302,'multiline':False]['text':' dtype is.','line_number':303,'multiline':False]['text':' Note: `step` or `state_step` is float32 by default.','line_number':309,'multiline':False]['text':' note(crcrpar): There are some test cases (e.g.','line_number':313,'multiline':False]['text':' TestOptim::test_adam) where state_steps are on CPU and the','line_number':314,'multiline':False]['text':' others are on CUDA. Currently a state_step Tensor has the','line_number':315,'multiline':False]['text':' dtype of float.','line_number':316,'multiline':False]['text':' NB: num_tensors is the max possible length for any of','line_number':334,'multiline':False]['text':' the inner lists of tensor references. Reserving the max','line_number':335,'multiline':False]['text':' trades memory for perf. This should not have significant','line_number':336,'multiline':False]['text':' impact.','line_number':337,'multiline':False]['text':' namespace','line_number':368,'multiline':False]['text':' namespace at::native','line_number':369,'multiline':False]