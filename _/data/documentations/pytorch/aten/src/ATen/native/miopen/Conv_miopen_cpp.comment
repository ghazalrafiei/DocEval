['text':' TODO: Remove the condition on AT_ROCM_ENABLED entirely,','line_number':23,'multiline':False]['text':' don't build this file as part of CPU build.','line_number':24,'multiline':False]['text':' See Note [ATen preprocessor philosophy]','line_number':31,'multiline':False]['text':' optional ','line_number':34,'multiline':True]['text':' optional ','line_number':67,'multiline':True]['text':' optional ','line_number':95,'multiline':True]['text':' AT_ROCM_ENABLED','line_number':138,'multiline':False]['text':' This POD struct is used to let us easily compute hashes of the','line_number':170,'multiline':False]['text':' parameters','line_number':171,'multiline':False]['text':'This is needed to distinguish between miopen handles of multiple gpus.','line_number':184,'multiline':False]['text':' NB: transposed purposely omitted: transposed just swaps','line_number':185,'multiline':False]['text':' forward and backward, so you can reuse the benchmark entry,','line_number':186,'multiline':False]['text':' ConvolutionParams must be a POD because we read out its memory','line_number':188,'multiline':False]['text':' contenst as char* when hashing','line_number':189,'multiline':False]['text':' ASSERT(weight.dim() == input.dim())','line_number':202,'multiline':False]['text':' ASSERT(padding.size() == stride.size())','line_number':208,'multiline':False]['text':' ASSERT(padding.size() == dilation.size())','line_number':209,'multiline':False]['text':' Convenience struct for passing around descriptors and data','line_number':222,'multiline':False]['text':' pointers','line_number':223,'multiline':False]['text':' ---------------------------------------------------------------------','line_number':236,'multiline':False]['text':'','line_number':237,'multiline':False]['text':' Benchmarking','line_number':238,'multiline':False]['text':'','line_number':239,'multiline':False]['text':' ---------------------------------------------------------------------','line_number':240,'multiline':False]['text':' Hashing machinery for ConvolutionParams','line_number':242,'multiline':False]['text':' just return the fastest','line_number':378,'multiline':False]['text':' find default alg','line_number':412,'multiline':False]['text':' default algo was not found, select first algo without workspace requirement','line_number':418,'multiline':False]['text':' now what? fall through and hope for the best','line_number':424,'multiline':False]['text':' just return the fastest','line_number':451,'multiline':False]['text':' find default alg','line_number':485,'multiline':False]['text':' default algo was not found, select first algo without workspace requirement','line_number':491,'multiline':False]['text':' now what? fall through and hope for the best','line_number':497,'multiline':False]['text':' just return the fastest','line_number':524,'multiline':False]['text':' find default alg','line_number':558,'multiline':False]['text':' default algo was not found, select first algo without workspace requirement','line_number':564,'multiline':False]['text':' now what? fall through and hope for the best','line_number':570,'multiline':False]['text':' re-check cache since another thread may have benchmarked the algorithm','line_number':592,'multiline':False]['text':' clear OOM error','line_number':619,'multiline':False]['text':' switch to default algorithm and record it in the cache to prevent','line_number':621,'multiline':False]['text':' further OOM errors','line_number':622,'multiline':False]['text':' clear OOM error','line_number':640,'multiline':False]['text':' switch to default algorithm','line_number':642,'multiline':False]['text':' ---------------------------------------------------------------------','line_number':649,'multiline':False]['text':'','line_number':650,'multiline':False]['text':' Bias addition','line_number':651,'multiline':False]['text':'','line_number':652,'multiline':False]['text':' ---------------------------------------------------------------------','line_number':653,'multiline':False]['text':' In-place!','line_number':655,'multiline':False]['text':' Make sure that NC11 strides follow formula','line_number':669,'multiline':False]['text':' TODO: Workaround since MIOpen does not support NHWC bias','line_number':672,'multiline':False]['text':' See #64426','line_number':673,'multiline':False]['text':' MIOpen does not support NHWC bias; Activate once support is added.
  bdesc.set( bias_contig );
  odesc.set(*output);

  auto handle = getMiopenHandle();
  auto dataType = getMiopenDataType(*bias);
  Constant one(dataType, 1);
  Constant zero(dataType, 0);

  MIOPEN_CHECK(miopenConvolutionForwardBias(handle, &one, bdesc.desc(), bias->data_ptr(),
                                     &zero, odesc.desc(), output->data_ptr()));
  ','line_number':676,'multiline':True]['text':' see NOTE [ Convolution design ] in src/Aten/native/cudnn/Conv.cpp','line_number':690,'multiline':False]['text':' ---------------------------------------------------------------------','line_number':693,'multiline':False]['text':'','line_number':694,'multiline':False]['text':' Convolution forward / Transposed convolution backward','line_number':695,'multiline':False]['text':'','line_number':696,'multiline':False]['text':' ---------------------------------------------------------------------','line_number':697,'multiline':False]['text':' The raw API directly invokes MIOpen.','line_number':699,'multiline':False]['text':'','line_number':700,'multiline':False]['text':' There are a few reasons this should never be directly exposed','line_number':701,'multiline':False]['text':' via ATen:','line_number':702,'multiline':False]['text':'','line_number':703,'multiline':False]['text':'    - It takes output as a parameter (this should be computed!)','line_number':704,'multiline':False]['text':'    - It doesn't do input checking','line_number':705,'multiline':False]['text':'    - It doesn't resize output (it is assumed to be correctly sized)','line_number':706,'multiline':False]['text':'','line_number':707,'multiline':False]['text':'at::MemoryFormat::ChannelsLast3d','line_number':762,'multiline':True]['text':' Avoid ambiguity of "output" when this is being used as backwards','line_number':774,'multiline':False]['text':' See #4500','line_number':778,'multiline':False]['text':' Make sure that NC11 strides follow formula','line_number':780,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':799,'multiline':False]['text':'Depthwise Convolutions','line_number':815,'multiline':False]['text':'at::MemoryFormat::ChannelsLast3d','line_number':870,'multiline':True]['text':' See #4500','line_number':881,'multiline':False]['text':' Make sure that NC11 strides follow formula','line_number':883,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':900,'multiline':False]['text':' ---------------------------------------------------------------------','line_number':916,'multiline':False]['text':'','line_number':917,'multiline':False]['text':' Convolution backward (bias)','line_number':918,'multiline':False]['text':'','line_number':919,'multiline':False]['text':' ---------------------------------------------------------------------','line_number':920,'multiline':False]['text':' TODO: Workaround since MIOpen does not support NHWC bias','line_number':927,'multiline':False]['text':' See #64426','line_number':928,'multiline':False]['text':' always return a tensor of shape [_]','line_number':938,'multiline':False]['text':' MIOpen does not support NHWC bias. Activate once support is added.
  auto grad_bias_t = at::empty( { grad_output->size(output_channels_dim) }, grad_output->options());

  TensorArg grad_bias{ grad_bias_t, "result", 0 };

  TensorDescriptor bdesc{grad_bias->expand({1, grad_bias->size(0)}),
                         static_cast<size_t>(grad_output->dim())};
  TensorDescriptor odesc{*grad_output};

  auto handle = getMiopenHandle();
  auto dataType = getMiopenDataType(*grad_bias);
  Constant one(dataType, 1);
  Constant zero(dataType, 0);

  MIOPEN_CHECK(miopenConvolutionBackwardBias(handle, &one, odesc.desc(), grad_output->data_ptr(),
                                                   &zero, bdesc.desc(), grad_bias->data_ptr()));
  return *grad_bias;
','line_number':945,'multiline':True]['text':' ---------------------------------------------------------------------','line_number':965,'multiline':False]['text':'','line_number':966,'multiline':False]['text':' Convolution backward (weight)','line_number':967,'multiline':False]['text':'','line_number':968,'multiline':False]['text':' ---------------------------------------------------------------------','line_number':969,'multiline':False]['text':'Depthwise backward weights.','line_number':1014,'multiline':False]['text':'at::MemoryFormat::ChannelsLast3d','line_number':1070,'multiline':True]['text':' Make sure that NC11 strides follow formula','line_number':1074,'multiline':False]['text':' For uniformity with everything else, although it seems grad_weight','line_number':1084,'multiline':False]['text':' would be unambiguous too.','line_number':1085,'multiline':False]['text':'at::MemoryFormat::ChannelsLast3d','line_number':1123,'multiline':True]['text':' Make sure that NC11 strides follow formula','line_number':1127,'multiline':False]['text':' For uniformity with everything else, although it seems grad_weight','line_number':1137,'multiline':False]['text':' would be unambiguous too.','line_number':1138,'multiline':False]['text':' ---------------------------------------------------------------------','line_number':1212,'multiline':False]['text':'','line_number':1213,'multiline':False]['text':' Convolution backward / Transposed convolution forward','line_number':1214,'multiline':False]['text':'','line_number':1215,'multiline':False]['text':' ---------------------------------------------------------------------','line_number':1216,'multiline':False]['text':' see NOTE [ Backward vs transpose convolutions ] in src/Aten/native/cudnn/Conv.cpp','line_number':1263,'multiline':False]['text':'at::MemoryFormat::ChannelsLast3d','line_number':1276,'multiline':True]['text':' Avoid "grad_input" when this is being used as transposed convolution','line_number':1282,'multiline':False]['text':' See #4500','line_number':1286,'multiline':False]['text':' Make sure that NC11 strides follow formula','line_number':1288,'multiline':False]['text':'Depthwise convolutions backward data.','line_number':1326,'multiline':False]['text':'at::MemoryFormat::ChannelsLast3d','line_number':1383,'multiline':True]['text':' See #4500','line_number':1392,'multiline':False]['text':' Make sure that NC11 strides follow formula','line_number':1394,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':1467,'multiline':False]['text':' MIOpen fused convolution bias activation forward','line_number':1483,'multiline':False]['text':' Create the fusion plan','line_number':1510,'multiline':False]['text':' compile fusion plan','line_number':1520,'multiline':False]['text':' Set the Args','line_number':1523,'multiline':False]['text':' Cleanup','line_number':1537,'multiline':False]['text':' MIOpen does not support fusion of add, the alpha2 * z step of the below cuDNN function:','line_number':1559,'multiline':False]['text':' y = act ( alpha1 * conv(x) + alpha2 * z + bias )','line_number':1560,'multiline':False]['text':' deterministic','line_number':1578,'multiline':False]['text':' MIOpen currently only supports MemoryFormat::Contiguous and fp32 and 2d','line_number':1618,'multiline':False]['text':' FuseFrozenConvAddRelu performs some tensor shape checking','line_number':1623,'multiline':False]['text':' benchmark','line_number':1650,'multiline':False]['text':' deterministic','line_number':1651,'multiline':False]['text':' fallback','line_number':1657,'multiline':False]['text':' deterministic','line_number':1670,'multiline':False]['text':' namespace','line_number':1700,'multiline':False]