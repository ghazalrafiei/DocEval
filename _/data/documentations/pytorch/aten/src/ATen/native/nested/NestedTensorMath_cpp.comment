['text':' 0-dim Tensors have torch.Size of .size() 0, but carry 1 memory.','line_number':24,'multiline':False]['text':' Empty 1-dim Tensors (torch.tensor([])) have torch.Size of .size() 1,','line_number':25,'multiline':False]['text':' but carry 0 memory.','line_number':26,'multiline':False]['text':' TODO: accept strides as input when we support them instead of','line_number':31,'multiline':False]['text':' assuming contiguous.','line_number':32,'multiline':False]['text':' namespace','line_number':59,'multiline':False]['text':' N * L','line_number':70,'multiline':False]['text':' Make sure padding is only added at the end of mask','line_number':73,'multiline':False]['text':' N, ([size1, size2, ... sizeN])','line_number':76,'multiline':False]['text':' N, ([d1=D, d2=D, ... dN=D])','line_number':84,'multiline':False]['text':' N * 2, ([[size1, D], [size2, D], ..., [sizeN, D]])','line_number':87,'multiline':False]['text':' N * L','line_number':101,'multiline':False]['text':' Make sure padding is only added at the end of mask','line_number':104,'multiline':False]['text':' N, ([size1, size2, ... sizeN])','line_number':107,'multiline':False]['text':' dtype ','line_number':167,'multiline':True]['text':' layout ','line_number':168,'multiline':True]['text':' device ','line_number':169,'multiline':True]['text':' pin_memory ','line_number':170,'multiline':True]['text':' Check and do transform 0213','line_number':207,'multiline':False]['text':' There may be extra padding on padded beyond the max size in the nested tensor.','line_number':218,'multiline':False]['text':' Make the mask size match.','line_number':219,'multiline':False]['text':' TODO: support noncontiguous case','line_number':248,'multiline':False]['text':' error out for now','line_number':249,'multiline':False]['text':' TODO: skipped optimization for case of all 1x1 tensors','line_number':253,'multiline':False]['text':' TODO: doesn't handle empty/scalar entries because we don't need','line_number':267,'multiline':False]['text':' it for transformers; see to_padded_tensor in','line_number':268,'multiline':False]['text':' pytorch/nestedtensor's masking.cpp.','line_number':269,'multiline':False]['text':' Pad output tensor to output_size if provided','line_number':311,'multiline':False]['text':' Very rudimentary sum_dim for prototyping with torch_scatter.segment_reduce.','line_number':354,'multiline':False]['text':' Only allow reductions across the last dim','line_number':360,'multiline':False]['text':' Always keep reduced dim for now','line_number':373,'multiline':False]['text':' This is to avoid the case where the nested tensors are 1D and keepdim=False','line_number':374,'multiline':False]['text':' making the nested tensors -> elements (e.g. sum(nt([1, 2 ,3], [4, 5]), -1) -> nt(6, 9))','line_number':375,'multiline':False]['text':' acc_dtype is not supported for now','line_number':377,'multiline':False]['text':' create output size tensor for keepdim=True','line_number':391,'multiline':False]['text':' This logic assumes for now that','line_number':400,'multiline':False]['text':' (1) all the nested tensors are contiguous','line_number':401,'multiline':False]['text':' (2) the nested tensors are stored contiguously in the buffer','line_number':402,'multiline':False]['text':' regular tensor dropout reuses input size and stride','line_number':496,'multiline':False]['text':' i.e. if input is not contiguous, then output is also discontiguous','line_number':497,'multiline':False]['text':' create a contiguous output','line_number':516,'multiline':False]['text':' TODO We would ideally use a empty_like here, but that is not supported','line_number':517,'multiline':False]['text':' for nested tensors yet. Since we are only using the buffer for the options','line_number':518,'multiline':False]['text':' and size it is okay to use unsafe_storage_as_tensor here.','line_number':519,'multiline':False]['text':' call tensor softmax','line_number':524,'multiline':False]['text':' TODO: for cpu, maybe use `parallel_for` if benchmarks show necessity','line_number':525,'multiline':False]['text':'       to do that, have to merge `aten/src/ATen/native/cpu/SoftMaxKernel.cpp/softmax_kernel`','line_number':526,'multiline':False]['text':'       1. it has `parallel_for` and we cannot multi-thread in multi-thread','line_number':527,'multiline':False]['text':'       2. cannot dispatch in multi-thread (in this case at::_softmax_out)','line_number':528,'multiline':False]['text':' check input dimensions','line_number':543,'multiline':False]['text':' -- to exclude the implicit batch dimension','line_number':551,'multiline':False]['text':' transpose = switch `dim0` and `dim1` columns of `sizemat` and `stridemat`','line_number':555,'multiline':False]['text':' create transposed `sizemat` and `stridemat`','line_number':563,'multiline':False]['text':' if tensor.size(dim) != 1 torch.squeeze will return the result, we do the same here','line_number':587,'multiline':False]['text':' detach to avoid triggering throw_error_if_base_and_tensor_are_same','line_number':598,'multiline':False]['text':' if ndim == 2 and we pass the above if statement we should have a','line_number':601,'multiline':False]['text':' nested tensor of singleton tensors','line_number':602,'multiline':False]['text':' utilities supporting `view_nested` and `reshape_nested`','line_number':652,'multiline':False]['text':' Args:','line_number':654,'multiline':False]['text':'     sizes: the sizes of original nested tensor','line_number':655,'multiline':False]['text':'     strides: the strides of original nested tensor','line_number':656,'multiline':False]['text':'     proposed_shape: user proposed new shape','line_number':657,'multiline':False]['text':'     op: the options for new size and stride matrices','line_number':658,'multiline':False]['text':' Returns:','line_number':659,'multiline':False]['text':'     whether viewable','line_number':660,'multiline':False]['text':'     size matrix after reshape','line_number':661,'multiline':False]['text':'     stride matrix after reshape (not fully populated if not viewable)','line_number':662,'multiline':False]['text':' compute reshaped size','line_number':679,'multiline':False]['text':' only allow one pre-existing dimension to have proposed shape == -1','line_number':681,'multiline':False]['text':' some negative sizes remain to be infered','line_number':683,'multiline':False]['text':' replace negative sizes for old dimensions with old sizes','line_number':686,'multiline':False]['text':' infer negative size for new dimension','line_number':698,'multiline':False]['text':' See Note [Special size rule for nested tensor]','line_number':717,'multiline':False]['text':' all negative sizes can be replaced','line_number':724,'multiline':False]['text':' compute reshaped stride','line_number':745,'multiline':False]['text':' reshape as view is possible','line_number':747,'multiline':False]['text':' fill reshaped size and stride into sizemat and stridemat','line_number':750,'multiline':False]['text':' reshape as view is impossible','line_number':758,'multiline':False]['text':' fill reshaped size into sizemat','line_number':761,'multiline':False]['text':' namespace','line_number':770,'multiline':False]['text':' Note [Special size rule for nested tensor]','line_number':772,'multiline':False]['text':' Instead of infering size, -1 means "inherit the old size", so:','line_number':773,'multiline':False]['text':' * negative size is legal for a ragged dimension','line_number':774,'multiline':False]['text':' * however, we only allow one -1','line_number':775,'multiline':False]['text':' In principle we could still infer a dimension,','line_number':776,'multiline':False]['text':' we are designing a better semantics to include both inheritance and inference','line_number':777,'multiline':False]['text':' basic information before reshaping','line_number':783,'multiline':False]['text':' basic information after reshaping','line_number':788,'multiline':False]['text':' reshaping underlying tensor dimensions does not change offset','line_number':795,'multiline':False]['text':' determine reshaped size and stride','line_number':796,'multiline':False]['text':'*
   * Create a buffer tensor that is a view of self
   *
   * This serves as the boundary between nested and non nested tensor
   * view conversions
   *
   * @return Returns a new non nested tensor that
   * aliases the same storage as self
   ','line_number':809,'multiline':True]['text':'*
 * Create a nested tensor that is a view of a buffer
 *
 * This serves as the boundary between non nested tensor and nested
 * view conversions
 *
 * @return Returns a nested tensor that
 * aliases the same storage as buffer
 ','line_number':824,'multiline':True]['text':' See Note [Special size rule for nested tensor]','line_number':864,'multiline':False]['text':' basic information before reshaping','line_number':870,'multiline':False]['text':' basic information after reshaping','line_number':875,'multiline':False]['text':' reshaping underlying tensor dimensions does not change offset','line_number':882,'multiline':False]['text':' determine reshaped size and stride','line_number':883,'multiline':False]['text':' TODO: this is to reproduce other_ptr->opt_sizes_','line_number':899,'multiline':False]['text':'       if an accessor is provided in the future, can replace this','line_number':900,'multiline':False]['text':' reshape with other.opt_sizes_','line_number':911,'multiline':False]['text':' returns true if the sizes are compatible to be concatenated along the specified dim','line_number':921,'multiline':False]['text':' sizes should match outside of the dim of concatenation','line_number':922,'multiline':False]['text':' subtract 1 to account for batch dim','line_number':934,'multiline':False]['text':' cat a list of NTs that are representable as jagged','line_number':948,'multiline':False]['text':' only support inputs in the form (B, *, D_0, D_1, ...)','line_number':970,'multiline':False]['text':' i.e. require at most a single ragged dim next to the batch dim','line_number':971,'multiline':False]['text':' view each of the NTs as jagged for the cat() call','line_number':984,'multiline':False]['text':' wrap result into nested tensor','line_number':987,'multiline':False]['text':' handle simple case of dim=0: concat NT components','line_number':1004,'multiline':False]['text':' NB: support for other dims is restricted to nested tensors representable as jagged','line_number':1022,'multiline':False]['text':' namespace native','line_number':1031,'multiline':False]['text':' namespace at','line_number':1032,'multiline':False]