['text':' --------------------------------------------------------------------','line_number':81,'multiline':False]['text':' zero_(SparseTensor)','line_number':82,'multiline':False]['text':' --------------------------------------------------------------------','line_number':83,'multiline':False]['text':' hummu hummu','line_number':85,'multiline':False]['text':' NB: Don't need zeros, zeros_like, already implemented in TensorFactories','line_number':92,'multiline':False]['text':' --------------------------------------------------------------------','line_number':94,'multiline':False]['text':' mul(SparseTensor, Scalar)','line_number':95,'multiline':False]['text':' --------------------------------------------------------------------','line_number':96,'multiline':False]['text':' Resolve a possibly sparse COO value to a strided tensor.','line_number':103,'multiline':False]['text':' With broadcasting in action, value_ may be a 1-D tensor as long','line_number':114,'multiline':False]['text':' as its shape is (1,).','line_number':115,'multiline':False]['text':' Sigh... needed because mul_out takes Tensor&','line_number':125,'multiline':False]['text':' --------------------------------------------------------------------','line_number':137,'multiline':False]['text':' neg(SparseTensor)','line_number':138,'multiline':False]['text':' --------------------------------------------------------------------','line_number':139,'multiline':False]['text':' copy_sparse_ does not perform the copy if it is the same tensor','line_number':145,'multiline':False]['text':' --------------------------------------------------------------------','line_number':161,'multiline':False]['text':' pow(SparseTensor, Scalar)','line_number':162,'multiline':False]['text':' --------------------------------------------------------------------','line_number':163,'multiline':False]['text':' TODO: add in-place variant','line_number':165,'multiline':False]['text':' This coalesce is why we can't easily provide an inplace variant','line_number':172,'multiline':False]['text':' Sigh... needed because pow_out takes Tensor&','line_number':179,'multiline':False]['text':' --------------------------------------------------------------------','line_number':191,'multiline':False]['text':' div(SparseTensor, Scalar)','line_number':192,'multiline':False]['text':' --------------------------------------------------------------------','line_number':193,'multiline':False]['text':' Note [Sparse Floor Division]','line_number':209,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':210,'multiline':False]['text':' Uncoalesced sparse tensors cannot be floor divided correctly. Integer','line_number':211,'multiline':False]['text':' division is considered a special-case of floor division for purposes of','line_number':212,'multiline':False]['text':' this note.','line_number':213,'multiline':False]['text':' For example, an integer tensor with values=[3, 3] divided by 2 would produce','line_number':214,'multiline':False]['text':' values=[1, 1], which sum to 2 instead of 3 (=6/2).','line_number':215,'multiline':False]['text':' A float tensor with values=[3., 3.] floor divided by 2 would also produce','line_number':216,'multiline':False]['text':' values=[1., 1.] (after truncation), which sum to 2.f instead of 3.f.','line_number':217,'multiline':False]['text':' To perform floor division the sparse tensor must be coalesced first.','line_number':218,'multiline':False]['text':' See note "Sparse Floor Division"','line_number':229,'multiline':False]['text':' Sigh... needed because div_out takes Tensor&','line_number':245,'multiline':False]['text':'rounding_mode=','line_number':254,'multiline':True]['text':'includeBool=','line_number':259,'multiline':True]['text':'includeBool=','line_number':276,'multiline':True]['text':' --------------------------------------------------------------------','line_number':291,'multiline':False]['text':' floor_divide(SparseTensor, Scalar)','line_number':292,'multiline':False]['text':' --------------------------------------------------------------------','line_number':293,'multiline':False]['text':' Case 1: result and dividend are the same tensor','line_number':306,'multiline':False]['text':' Performs floor division in-place','line_number':307,'multiline':False]['text':' See note "Sparse Floor Division"','line_number':310,'multiline':False]['text':' Case 2: result and dividend are different tensors','line_number':319,'multiline':False]['text':' Ensures dividend_tmp is coalesced (see note above)','line_number':322,'multiline':False]['text':' Resizes and indexes result like dividend_tmp','line_number':327,'multiline':False]['text':' Computes result','line_number':332,'multiline':False]['text':' --------------------------------------------------------------------','line_number':354,'multiline':False]['text':' norm(SparseTensor, Scalar)','line_number':355,'multiline':False]['text':' --------------------------------------------------------------------','line_number':356,'multiline':False]['text':' Only supports floating point, FYI','line_number':358,'multiline':False]['text':' Only full reductions are supported, so check if that is the case','line_number':367,'multiline':False]['text':' Need to check for duplicates, and fail if any are found','line_number':374,'multiline':False]['text':' --------------------------------------------------------------------','line_number':393,'multiline':False]['text':' mv(SparseTensor, Tensor)','line_number':394,'multiline':False]['text':' --------------------------------------------------------------------','line_number':395,'multiline':False]['text':' --------------------------------------------------------------------','line_number':412,'multiline':False]['text':' add(SparseTensor, SparseTensor, Scalar)  [broadcasts]','line_number':413,'multiline':False]['text':' --------------------------------------------------------------------','line_number':414,'multiline':False]['text':' TODO: Why?! Can't we just flip the order here...','line_number':417,'multiline':False]['text':' redispatch!','line_number':423,'multiline':False]['text':' redispatch!','line_number':427,'multiline':False]['text':' There's actually nothing sparse specific about these implementations','line_number':430,'multiline':False]['text':' redispatch!','line_number':444,'multiline':False]['text':' saving those because they can be overwritten when doing in-place operations','line_number':449,'multiline':False]['text':' NB: relies on nnz tests above','line_number':466,'multiline':False]['text':' We add all elements from t_values to r_values only if t_values is not an empty tensor','line_number':500,'multiline':False]['text':' We add all elements from s_values to r_values only if s_values is not an empty tensor','line_number':511,'multiline':False]['text':' TODO: I think it may be possible to track inside the loop and','line_number':529,'multiline':False]['text':' detect when we are uncoalesced (e.g., by observing that an','line_number':530,'multiline':False]['text':' index goes backwards) which may be more precise than using the','line_number':531,'multiline':False]['text':' coalesced flag here.  But this is easy.','line_number':532,'multiline':False]['text':' If `t` or `src` contains non-contiguous `values`, `at::native::cpublas::axpy` doesn't work','line_number':540,'multiline':False]['text':' and we concat the indices and values tensors instead.','line_number':541,'multiline':False]['text':' Prevent unbounded growth of nnz','line_number':553,'multiline':False]['text':' TODO: Improved heuristic on when to coalesce or remove need to coalesce','line_number':554,'multiline':False]['text':' TODO: This test seems a bit goofy','line_number':569,'multiline':False]['text':' the dispatch argument','line_number':571,'multiline':False]['text':' --------------------------------------------------------------------','line_number':599,'multiline':False]['text':' add(Tensor, SparseTensor, Scalar)','line_number':600,'multiline':False]['text':'    formerly known as spcadd','line_number':601,'multiline':False]['text':' --------------------------------------------------------------------','line_number':602,'multiline':False]['text':' Get the dense dimension element numbers of hybrid sparse tensor','line_number':629,'multiline':False]['text':' Get the dense dimension element numbers of hybrid sparse tensor','line_number':661,'multiline':False]['text':'make chunk balance among threads as 211','line_number':688,'multiline':False]['text':' dispatch argument','line_number':723,'multiline':False]['text':'TODO: we can optimize it for non-hybrid by not using buffers','line_number':760,'multiline':False]['text':' Handle sparse is not coalesced','line_number':775,'multiline':False]['text':' Slow path for non-contiguous values and output','line_number':782,'multiline':False]['text':' TODO: coalesce() performance may can be further improved','line_number':783,'multiline':False]['text':' --------------------------------------------------------------------','line_number':807,'multiline':False]['text':' mul(SparseTensor, SparseTensor)  [broadcasts]','line_number':808,'multiline':False]['text':' --------------------------------------------------------------------','line_number':809,'multiline':False]['text':' Arbitrary (dense, sparse) and (sparse, dense) multiplication is not','line_number':813,'multiline':False]['text':' currently supported, but (0dim-dense, sparse) and (sparse, 0dim-dense) is.','line_number':814,'multiline':False]['text':' Make sure we use the sparse exemplar for result.','line_number':815,'multiline':False]['text':' redispatch!','line_number':819,'multiline':False]['text':' redispatch!','line_number':824,'multiline':False]['text':' A generic function to implement pointwise-like operations','line_number':834,'multiline':False]['text':' with index intersection between dense and sparse COO tensors.','line_number':835,'multiline':False]['text':' NOTE: op is always called as op(dense_values, sparse_values),','line_number':836,'multiline':False]['text':' so it is up to the user to supply right implementations for non-commutative','line_number':837,'multiline':False]['text':' operations.','line_number':838,'multiline':False]['text':' compute broadcasted shape.','line_number':847,'multiline':False]['text':' Short-circuit if either s_ or d is empty.','line_number':850,'multiline':False]['text':'size=','line_number':860,'multiline':True]['text':' Always coalesce when sparse broadcasts over dense,','line_number':869,'multiline':False]['text':' because new sparse dimensions are created and','line_number':870,'multiline':False]['text':' repeated indices have to be eliminated because of that.','line_number':871,'multiline':False]['text':' to(res.scalar_type) is only performed when both d and s are 0-dim.','line_number':882,'multiline':False]['text':' This insures right type promotions with the following rules:','line_number':883,'multiline':False]['text':' op(0-dim, 0-dim).dtype == <common dtype>','line_number':884,'multiline':False]['text':' op(0-dim, ge-1-dim).dtype == <ge-1-dim>.dtype,','line_number':885,'multiline':False]['text':' where ge-1-dim is a tensor with dim >= 1.','line_number':886,'multiline':False]['text':' We do not cast if op is performed in-place.','line_number':887,'multiline':False]['text':' The cast is required if s is 0-dim non-coalesced tensor and d is 0-dim.','line_number':888,'multiline':False]['text':' This is because s.values is at least 1D, so','line_number':889,'multiline':False]['text':' op(s.values, d).dtype == s.values.dtype, but we want','line_number':890,'multiline':False]['text':' op(s.values, d).dtype == <common dtype>.','line_number':891,'multiline':False]['text':' Easiest case: only dense dimensions intersect.','line_number':901,'multiline':False]['text':' This means only value tensors interact.','line_number':902,'multiline':False]['text':' Now we have intersection between sparse and dense dims.','line_number':907,'multiline':False]['text':' Index d with s_indices to find values which','line_number':912,'multiline':False]['text':' interact with s_values.','line_number':913,'multiline':False]['text':' we need to expand d in the dimensions it is being indexed into','line_number':932,'multiline':False]['text':' to avoid out of bound indices','line_number':933,'multiline':False]['text':' When dims match or sparse is "larger", the result nnz is the same,','line_number':939,'multiline':False]['text':' so only values get modified.','line_number':940,'multiline':False]['text':' Otherwise nnz gets larger, and both indices and values need an update.','line_number':945,'multiline':False]['text':' fill in indices corresponding to the "batch" dimensions of d.','line_number':970,'multiline':False]['text':' fill in indices corresponding to the "batch" dimension dim.','line_number':976,'multiline':False]['text':' Equivalent to indices[dim].copy_(repeat_interleave(dim_index, n_repeat_interleave).repeat(n_repeat))','line_number':977,'multiline':False]['text':' NOTE: indices is contiguous, so view is safe','line_number':981,'multiline':False]['text':' fill in indices corresponding to s_indices.','line_number':985,'multiline':False]['text':' Equivalent to indices_sparse.copy(s_indices.repeat({1, n_repeat})','line_number':986,'multiline':False]['text':' By design of index expansion and that s is coalesced,','line_number':999,'multiline':False]['text':' the result is also coalesced.','line_number':1000,'multiline':False]['text':' if squeeze does not kill the dim, it means that','line_number':1017,'multiline':False]['text':' vals is empty with shape [0]. In such a case we','line_number':1018,'multiline':False]['text':' return a 0-dim empty tensor to avoid broadcasting','line_number':1019,'multiline':False]['text':' issues in intersection_binary_op_sparse_dense_out','line_number':1020,'multiline':False]['text':' when the sparse argument is actually 0-dim.','line_number':1021,'multiline':False]['text':' The code dispatches to mul(dense, sparse), and the goal','line_number':1028,'multiline':False]['text':' is to delay calling into coalesce when converting one of','line_number':1029,'multiline':False]['text':' the sparse arguments to dense if possible.','line_number':1030,'multiline':False]['text':' This is possible when there is a 0-dim coalesced argument.','line_number':1031,'multiline':False]['text':' if is_wrapped_scalar(zero_dim)','line_number':1033,'multiline':False]['text':' Here zero_dim is not a wrapped scalar, so we test other.','line_number':1038,'multiline':False]['text':' Neither of inputs is a wrapped scalar, but zero_dim','line_number':1043,'multiline':False]['text':' is at least 0-dim, so we coalesce it to convert to','line_number':1044,'multiline':False]['text':' a scalar.','line_number':1045,'multiline':False]['text':' dispatch argument','line_number':1058,'multiline':False]['text':' case mul(sparse, dense)','line_number':1061,'multiline':False]['text':' case mul(dense, sparse)','line_number':1065,'multiline':False]['text':' case mul(sparse, sparse) with a 0-dim input.','line_number':1070,'multiline':False]['text':' mul(sparse, sparse) with inputs which broadcast only in dense dims','line_number':1080,'multiline':False]['text':' Short circuit when there is zero nnz','line_number':1089,'multiline':False]['text':' Not strictly necessary, but there are tests checking whether','line_number':1090,'multiline':False]['text':' resize in mul fails if run on tensors coming from .data/.detach.','line_number':1091,'multiline':False]['text':' _mul_sparse_sparse_out is faster for large inputs','line_number':1097,'multiline':False]['text':' and when either of the inputs is uncoalesced.','line_number':1098,'multiline':False]['text':' Otherwise _mul_sparse_sparse_out might be slower','line_number':1104,'multiline':False]['text':' than the brute-force solution below.','line_number':1105,'multiline':False]['text':' saving those because they can be overwritten when doing in-place operations','line_number':1110,'multiline':False]['text':' multiply by zero is zero, and can be dropped','line_number':1112,'multiline':False]['text':' NB: relies on nnz test above','line_number':1128,'multiline':False]['text':' Check if we can find matching indices, and if so, write an','line_number':1133,'multiline':False]['text':' entry to the result indices vector.  Returns true if matching','line_number':1134,'multiline':False]['text':' indices were found.','line_number':1135,'multiline':False]['text':' --------------------------------------------------------------------','line_number':1187,'multiline':False]['text':' addmm(D1, S, D2, beta, alpha) -> D  [broadcasts]','line_number':1188,'multiline':False]['text':'','line_number':1189,'multiline':False]['text':' D = beta * D1 + alpha * mm(S, D2)','line_number':1190,'multiline':False]['text':' --------------------------------------------------------------------','line_number':1191,'multiline':False]['text':' r_ = alpha * sparse * dense','line_number':1196,'multiline':False]['text':' AXPY call is no-op over an empty vector','line_number':1225,'multiline':False]['text':' TODO: This error message seems awfully opaque','line_number':1250,'multiline':False]['text':' ixj * jxk = ixk','line_number':1287,'multiline':False]['text':' NB: Purposely no broadcasting version of addmm inplace','line_number':1364,'multiline':False]['text':' _sparse_addmm forward is functionally equivalent to addmm; it's','line_number':1373,'multiline':False]['text':' just the backward that is different.  This technically does an','line_number':1374,'multiline':False]['text':' unnecessary redispatch, I was too lazy to make it not do that','line_number':1375,'multiline':False]['text':' NB: Despite its suggestive name, this actually only exists so that','line_number':1394,'multiline':False]['text':' we can redispatch to addmm_out; this is NOT an implementation of','line_number':1395,'multiline':False]['text':' the sparse masking version of mm','line_number':1396,'multiline':False]['text':' redispatch!','line_number':1401,'multiline':False]['text':' result: out, arg_out','line_number':1405,'multiline':False]['text':' --------------------------------------------------------------------','line_number':1410,'multiline':False]['text':' hspmm(SparseTensor mat1, Tensor mat2)','line_number':1411,'multiline':False]['text':' --------------------------------------------------------------------','line_number':1412,'multiline':False]['text':' TODO: Make this a real argument','line_number':1415,'multiline':False]['text':' dispatch argument','line_number':1418,'multiline':False]['text':' Initialize the sparse matrix that will be used with spaddmm to send rows','line_number':1449,'multiline':False]['text':' from the dense matrix to rows of the output's value tensor','line_number':1450,'multiline':False]['text':' Compute output indices','line_number':1455,'multiline':False]['text':' Compute output values tensor with sparse * dense multiplication','line_number':1476,'multiline':False]['text':' --------------------------------------------------------------------','line_number':1489,'multiline':False]['text':' sspaddmm(S1, S2, D, beta, alpha) -> S','line_number':1490,'multiline':False]['text':'','line_number':1491,'multiline':False]['text':' S = beta * S1 + alpha * mm(S2, D)','line_number':1492,'multiline':False]['text':' --------------------------------------------------------------------','line_number':1493,'multiline':False]['text':' dispatch argument','line_number':1502,'multiline':False]['text':' ixj * jxk = ixk','line_number':1516,'multiline':False]['text':' NB: This has to occur before the checks, because r may alias t.','line_number':1521,'multiline':False]['text':' See test_saddmm','line_number':1522,'multiline':False]['text':' We have to make indices contiguous as we use indices.data_ptr in _to_csr which assumes row-contiguous storage','line_number':1533,'multiline':False]['text':' sparse = sparse * dense','line_number':1558,'multiline':False]['text':' Fill up the indices with the right values','line_number':1591,'multiline':False]['text':' to avoid a clone','line_number':1603,'multiline':False]['text':' sparse, sparse, sparse, dense, real, real -> sparse','line_number':1610,'multiline':False]['text':' sparse, dense -> sparse','line_number':1616,'multiline':False]['text':' sparse, sparse, dense, real, real -> sparse','line_number':1623,'multiline':False]['text':' --------------------------------------------------------------------','line_number':1631,'multiline':False]['text':' sparse.sum()','line_number':1632,'multiline':False]['text':'','line_number':1633,'multiline':False]['text':' This implementation calls coalesce() to do the sum reduction on','line_number':1634,'multiline':False]['text':' sparse dims. Ideally in the future there should be unified reduction function','line_number':1635,'multiline':False]['text':' for ops like sum, max, and min.','line_number':1636,'multiline':False]['text':' --------------------------------------------------------------------','line_number':1637,'multiline':False]['text':' don't have to do a conversion to the correct dtype first','line_number':1643,'multiline':False]['text':' just need to setup the accumulator correctly','line_number':1644,'multiline':False]['text':' new values','line_number':1677,'multiline':False]['text':' return a dense tensor if sum over all sparse dims','line_number':1687,'multiline':False]['text':' !sum_all_sparse_dim','line_number':1691,'multiline':False]['text':' new indices','line_number':1692,'multiline':False]['text':' new size','line_number':1706,'multiline':False]['text':' exclude nnz dim','line_number':1708,'multiline':False]['text':' use coalesce() to do sum reduction','line_number':1714,'multiline':False]['text':' TODO: can we use input.is_coalesced()?','line_number':1715,'multiline':False]['text':' --------------------------------------------------------------------','line_number':1722,'multiline':False]['text':' NOTE [ sparse.sum() backward ]','line_number':1723,'multiline':False]['text':'','line_number':1724,'multiline':False]['text':' When sum over sparse_dim, backward scatters gradients from grad tensor to input tensor.','line_number':1725,'multiline':False]['text':' Grad and input need to align indices over sparse_dim that are not summed (given','line_number':1726,'multiline':False]['text':' input.spares_dim >= grad.sparse_dim). Implementation here compares each pair of','line_number':1727,'multiline':False]['text':' indices between grad and input. When a matching indices pair (input_i, grad_i) is found,','line_number':1728,'multiline':False]['text':' copy grad.values[grad_i] -> input_grad.values[input_i]. E.g.,','line_number':1729,'multiline':False]['text':'','line_number':1730,'multiline':False]['text':'  input.sparse_dim = [5, 5]','line_number':1731,'multiline':False]['text':'  input.indices = [[0, 0, 1, 2, 2, 3, 4, 4],','line_number':1732,'multiline':False]['text':'                   [1, 4, 4, 0, 1, 3, 2, 4]]','line_number':1733,'multiline':False]['text':'  input.values =   [0, 1, 2, 3, 4, 5, 6, 7]','line_number':1734,'multiline':False]['text':'  ...','line_number':1735,'multiline':False]['text':'  sparse.sum(input, [0])','line_number':1736,'multiline':False]['text':'  backward(...)','line_number':1737,'multiline':False]['text':'  ...','line_number':1738,'multiline':False]['text':'  grad.indices = [[0, 1, 2, 3]]','line_number':1739,'multiline':False]['text':'  grad.values =   [1, 2, 0, 4]','line_number':1740,'multiline':False]['text':'','line_number':1741,'multiline':False]['text':' # after indices matching','line_number':1742,'multiline':False]['text':'         input         grad','line_number':1743,'multiline':False]['text':'        [[0, 1],   ->  [1]','line_number':1744,'multiline':False]['text':'         [0, 4],   ->  [ ]','line_number':1745,'multiline':False]['text':'         [1, 4],   ->  [ ]','line_number':1746,'multiline':False]['text':'         [2, 0],   ->  [0]','line_number':1747,'multiline':False]['text':'         [2, 1],   ->  [1]','line_number':1748,'multiline':False]['text':'         [3, 3],   ->  [3]','line_number':1749,'multiline':False]['text':'         [4, 2],   ->  [2]','line_number':1750,'multiline':False]['text':'         [4, 4]])  ->  [ ]','line_number':1751,'multiline':False]['text':'','line_number':1752,'multiline':False]['text':' input_grad.indices = [[0, 0, 1, 2, 2, 3, 4, 4],','line_number':1753,'multiline':False]['text':'                       [1, 4, 4, 0, 1, 3, 2, 4]]','line_number':1754,'multiline':False]['text':' input_grad.values =   [2, 0, 0, 1, 2, 4, 0, 0]','line_number':1755,'multiline':False]['text':'','line_number':1756,'multiline':False]['text':' Note that we allow input to be uncoalesced in the forward,','line_number':1757,'multiline':False]['text':' we have to coalesce input at the backward, because grad-of-input','line_number':1758,'multiline':False]['text':' take the same indices as input, if input is not coalesced, then','line_number':1759,'multiline':False]['text':' coalescing grad-of-input may add up grad values for a duplicate indices,','line_number':1760,'multiline':False]['text':' and hence generates a wrong grad-of-input.','line_number':1761,'multiline':False]['text':'','line_number':1762,'multiline':False]['text':' Other edge cases:','line_number':1763,'multiline':False]['text':' - assign zero values to input gradients if cannot find matched indices at grad','line_number':1764,'multiline':False]['text':' - grad.values might have zeros','line_number':1765,'multiline':False]['text':' --------------------------------------------------------------------','line_number':1766,'multiline':False]['text':' Short circuit if grad is either zero or empty.','line_number':1771,'multiline':False]['text':' -1 since grad has no nnz dim','line_number':1814,'multiline':False]['text':' convert to grad dtype','line_number':1819,'multiline':False]['text':' see NOTE [ sparse.sum() backward ]','line_number':1839,'multiline':False]['text':' get flatten indices for grad and input','line_number':1842,'multiline':False]['text':' flatten indices on all sparse_dim of grad, output indices is coalesced and sorted','line_number':1846,'multiline':False]['text':'squash_dims=','line_number':1855,'multiline':True]['text':' binary search to find matching indices','line_number':1866,'multiline':False]['text':' grad_input_values[i].copy_(grad_values_expand[m])','line_number':1876,'multiline':False]['text':'non_blocking=','line_number':1879,'multiline':True]['text':' Search a sorted strided array for the rightmost instance of a value.','line_number':1911,'multiline':False]['text':' Array must be sorted from lowest to highest.','line_number':1912,'multiline':False]['text':' Returns the index of the found element.','line_number':1913,'multiline':False]['text':' Returns by reference `found`, true if search value was found, false otherwise','line_number':1914,'multiline':False]['text':' This value should be overwritten in the loop so we use','line_number':1924,'multiline':False]['text':' a destructive initial value to ensure disaster if that','line_number':1925,'multiline':False]['text':' turns out not to be the case.','line_number':1926,'multiline':False]['text':' First need to coalesce to get all of the first dimension indices','line_number':1972,'multiline':False]['text':' in order since we'll be sending each matrix into the MM operation','line_number':1973,'multiline':False]['text':' Iterate through each set of 2D matrices within the 3D','line_number':1996,'multiline':False]['text':' tensor inputs, performing a matrix multiply with each one.','line_number':1997,'multiline':False]['text':' If there are sparse matrices at the beginning or end that','line_number':2005,'multiline':False]['text':' have all zero elements, we need to zero out the result matrix.','line_number':2006,'multiline':False]['text':' Search for the range of sparse tensor elements that','line_number':2012,'multiline':False]['text':' correspond to the current matrix number. We already know','line_number':2013,'multiline':False]['text':' where the current matrix begins, so we just need to find','line_number':2014,'multiline':False]['text':' the end. The search excludes everything to the left of','line_number':2015,'multiline':False]['text':' the starting point, for best performance','line_number':2016,'multiline':False]['text':' Create tensors to view just the current set of matrices','line_number':2029,'multiline':False]['text':' If no elements for this sparse matrix are found, then','line_number':2047,'multiline':False]['text':' it's a zero matrix and we need to zero out the result','line_number':2048,'multiline':False]['text':' namespace at::native','line_number':2071,'multiline':False]