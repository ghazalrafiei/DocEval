['text':' namespace native','line_number':136,'multiline':False]['text':' 'opt_dtype' has the priority for both cases.','line_number':144,'multiline':False]['text':' Otherwise, get the result type, if defined.','line_number':146,'multiline':False]['text':' Last case is to get the self type.','line_number':149,'multiline':False]['text':' If the self type is an integer, we promote it to kLong.','line_number':150,'multiline':False]['text':' Refer [all, any : uint8 compatibility]','line_number':160,'multiline':False]['text':' Refer [all, any : uint8 compatibility]','line_number':170,'multiline':False]['text':' Note [all, any : uint8 compatibility]:','line_number':179,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':180,'multiline':False]['text':' For NumPy comptability, `all` and `any` return','line_number':181,'multiline':False]['text':' Tensor of dtype `bool`. However for compatibility reason,','line_number':182,'multiline':False]['text':' for `uint8`, they return Tensor of same dtype `uint8`.','line_number':183,'multiline':False]['text':' Reference: https://github.com/pytorch/pytorch/pull/47878#issuecomment-747108561','line_number':184,'multiline':False]['text':'allow_empty_dims=','line_number':194,'multiline':True]['text':' Checking whether 'dim' is valid.','line_number':253,'multiline':False]['text':'includeBool=','line_number':262,'multiline':True]['text':' namespace meta','line_number':405,'multiline':False]['text':' namespace native','line_number':433,'multiline':False]['text':'
    We show here how to derive an O(n) gradient formula for
    abitrary inputs. It follows via a basic application of the
    chain rule together with a number of observations for different
    cases. We assume that x is an n-dimensional vector and y = cumprod(x).
    In the actual implementation we will need to play a bit with masks
    to be able to implement the formulas deduced here for tensors.

    We will first deduce the formula for the case when
    x[i] != 0 for 1 <= i <= n.

    For F : R^n -> R the cost function (we will look at the complex case later),
    we have

    dF / dx_k = sum_j (dF / dy_j) * (dy_j / dx_k)   (1)

    The term dF / dy_j is just grad_output[j] (assuming again
    everything is one-dimensional).

    The term (dy_j / dx_k) is easilly seen to be

    if j >= k
      dy_j / dx_k = prod_{1 <= i <= j, i != k} x_i
    else:
      dy_j / dx_k = 0

    Note that the indicator (j>=k) can be taken out
    by replacing the sum in (1) with a sum from
    k <= j <= n.

    Thus,
    dF / dx_k = sum_{k <= j <= n} grad_output[j] * (dy_j / dx_k)

    with
    dy_j / dx_k = prod_{1 <= i <= j, i != k} x_i     (2)

    Note that this last term is just the cumulative product
    with k omitted. Thus, if x_k (the input) is nonzero, we can
    just express this as

    dy_j / dx_k = (prod_{1 <= i <= j} x_i) / x_k
                = y_j / x_k

    So therefore,

    dF / dx_k = sum_{k <= j <= n} grad_output[j] * y_j / x_k

    This formula just makes sense when input[i] != 0 for every i.

    Assume now that there exists at least a zero in the input.
    Denote by z1 the first element 1 <= z1 <= n with input[z1] = 0
    and z2 the second element z1 < z2 <= n with input[z2] = 0,
    (or z2 = n if there is just one zero in input)

    We have three cases.

    k > z1:
    Looking at (2), we see that dy_j / dx_k = 0, for j >= k, as these terms
    all include a x_{z1} which is zero. As such, dF / dx_k = 0 in this case

    k < z1:
    Reasoning as in the previous case, we see that for these elements we have that

    dF / dx_k = sum_{k <= j < z1} grad_output[j] * (dy_j / dx_k)

    as the terms of the sum for j in z1 <= j <= n are all zero

    k = z1:
    Similar to the case k < z1, we have that

    dF / dx_z1 = sum_{z1 <= j < z2} grad_output[j] * (dy_j / dx_z1)

    This case has a subtlety though. To compute (dy_j / dx_z1), we cannot use the formula

    dy_j / dx_z1 = y_j / x_z1

    as, y_j = x_z1 = 0 for j >= z1. We need to compute it with the formula for its derivative,
    that is:

    dy_j / dx_z1 = prod(x[:z1]) * (grad_output[z1] + sum(grad_output[z1+1:z2] * cumprod(x[z1+1:z2])))

    When the imputs are complex, this is map is holomorphic. As such, to compute
    its backwards is just the conjugate of the usual backwards. This simplifies to
    conjugating the input. We may also reuse the output as, since the map is holomorphic,
    cumprod(input.conj()) = cumprod(input).conj()
  ','line_number':520,'multiline':True]['text':' To enable complex support.','line_number':616,'multiline':False]['text':' From this line on `input_conj` and output_conj`','line_number':617,'multiline':False]['text':' are interchangeable with `input` and `output`.','line_number':618,'multiline':False]['text':' For Composite Compliance, we always choose the slower but composite compliant path.','line_number':622,'multiline':False]['text':' If we are not computing a second order gradient, we can use an','line_number':633,'multiline':False]['text':' O(n) implementation. The derivative of this implementation is _not_','line_number':634,'multiline':False]['text':' the second derivative of cumprod. As such, we fallback to a less efficient','line_number':635,'multiline':False]['text':' O(n^2) implementation when at::GradMode::is_enabled().','line_number':636,'multiline':False]['text':' n.b. This could probably be implemented much faster with a kernel','line_number':638,'multiline':False]['text':' From here on we need to use some mask gymnastics to','line_number':640,'multiline':False]['text':' account for the tensorial dimensions','line_number':641,'multiline':False]['text':' We do a cumsum of the zeros along the dimension.','line_number':642,'multiline':False]['text':' For a vector is_zero = [False, True, False, True, False]','line_number':643,'multiline':False]['text':' we would have cumsum = [0, 1, 1, 2, 2]','line_number':644,'multiline':False]['text':' As such we have (in python code for simplicity)','line_number':645,'multiline':False]['text':' The mask for the range [0, z1):','line_number':646,'multiline':False]['text':' cumsum == 0','line_number':647,'multiline':False]['text':' The indices of the first zero z1 and zeros when','line_number':648,'multiline':False]['text':' there is no first zero:','line_number':649,'multiline':False]['text':' indices = (cumsum == 1).max(dim, keepdim=True).indices','line_number':650,'multiline':False]['text':' The mask for the first zero:','line_number':651,'multiline':False]['text':' zeros_like(indices).scatter_(dim, indices, 1.) & cumsum == 1','line_number':652,'multiline':False]['text':' Note that the logic_and with cumsum == 1 accounts','line_number':653,'multiline':False]['text':' for the case when there is no first zero','line_number':654,'multiline':False]['text':' case k < z1','line_number':658,'multiline':False]['text':' select everything before the first zero [0, z1)','line_number':659,'multiline':False]['text':' equiv to grad_input[mask] = deriv[grad]','line_number':661,'multiline':False]['text':' select everything from the first zero to the second zero [z1, z2)','line_number':664,'multiline':False]['text':' case k = z1','line_number':667,'multiline':False]['text':' We start by select the first zero [z1]','line_number':668,'multiline':False]['text':' We locate the indices of the first zero using the max function','line_number':669,'multiline':False]['text':' We then go from the indices to a mask index_fill_','line_number':670,'multiline':False]['text':' When there is no zero in the slice, max will return the index 0.','line_number':671,'multiline':False]['text':' To account for this, we need to do an intersection with mask,','line_number':672,'multiline':False]['text':' which is true in the range [z1, z2)','line_number':673,'multiline':False]['text':'keepdim','line_number':674,'multiline':True]['text':'src','line_number':676,'multiline':True]['text':' select everything between the first zero and the second zero (z1, z2)','line_number':679,'multiline':False]['text':' here we compute','line_number':681,'multiline':False]['text':' dy_j / dx_z1 = sum(cumprod(input[z1+1:z2] * grad[z1+1:z2])) * prod(output[z1-1])','line_number':682,'multiline':False]['text':' relu_() necessary as gather does not support negative indices','line_number':683,'multiline':False]['text':' finally, we do grad_input[z1] = dy_j / dx_z1','line_number':684,'multiline':False]['text':'keepdim','line_number':688,'multiline':True]['text':' GradMode::enabled()','line_number':693,'multiline':False]['text':'
    If the input is nonzero, we need to calculate the dy_j / dx_k
    by using the formula (2), called in the code omitted_products.

    The way the code calculates it is simply by noting that

    prod_{1 <= i <= j, i != k} x_i
        = (prod_{1 <= i <= k} x_i) * (prod_{k + 1 <= i <= j} x_i)

    the first term is calculated as prods_until_k, which since
    doesn't depend in j is easy to vectorize.

    The second term (indexed by j) is the cumulative product of
    x_{k+1}, x_{k+2}, ..., x_n, and it's named in the code
    prods_from_k_pkus_1, and it's calculated as a cumprod.

    In order to vectorize this properly, we need to add to
    omitted_products the dimensions where k > j, and therefore
    dy_j / dx_k = 0, which is done right after the assert.
    ','line_number':694,'multiline':True]['text':' For Composite Compliance, we will use','line_number':716,'multiline':False]['text':' at::stack on the grad slices, hence the vector.','line_number':717,'multiline':False]['text':' At this point omitted_products is the same size','line_number':743,'multiline':False]['text':' as input, except on the dimension dim where it's','line_number':744,'multiline':False]['text':' dim_size - k','line_number':745,'multiline':False]['text':' Implement std::is_nan<IntegralType> for MSVC.','line_number':760,'multiline':False]['text':' for composite compliance, use out-of-place variant of','line_number':872,'multiline':False]['text':' `scatter_add` if `indices` or `grad` is a Tensor Subclass.','line_number':873,'multiline':False]['text':' Helper for diff that handles prepending and appending when at least one is present','line_number':881,'multiline':False]['text':' Helper for diff that checks whether the shape of the tensor to prepend or append','line_number':893,'multiline':False]['text':' is compatible with that of input','line_number':894,'multiline':False]['text':' Helper for diff that checks whether its parameters are valid','line_number':914,'multiline':False]['text':' Helper for gradient function to make sure input data satisfies prerequisites','line_number':1009,'multiline':False]['text':' NOTE: If spacing was given as a scalar, the callers of this function','line_number':1012,'multiline':False]['text':' create a spacing vector of the expected size, and this check passes','line_number':1013,'multiline':False]['text':' The following function get called to check whether dim argument satisfies prerequisites.','line_number':1025,'multiline':False]['text':' The output of the function is not used for the computation of gradient.','line_number':1026,'multiline':False]['text':' if gradient dim is provided as an integer, then we need to compute gradient only on this direction.','line_number':1100,'multiline':False]['text':' Moreover, if it's not provided at all, then we are interested in gradient for all directions.','line_number':1101,'multiline':False]['text':' Finally, if dim is provided as vector of ints, then it is not expected to be called by this function.','line_number':1102,'multiline':False]['text':' When spacing is given as scalar, while dim is given as IntArrayRef, scalar value need to','line_number':1147,'multiline':False]['text':' be taken as unit size at every given dimension element of - dim.','line_number':1148,'multiline':False]['text':' When unit_size not provided, it is always assumed to be equal to 1.','line_number':1159,'multiline':False]['text':' When dim has integer value it implies we are looking for gradient in the specific direction, however when','line_number':1160,'multiline':False]['text':' it is not provided, it means we are interested to find gradient in all directions.','line_number':1161,'multiline':False]['text':' ALL REDUCE #################################################################','line_number':1180,'multiline':False]['text':' For integral types, use existing sum as','line_number':1216,'multiline':False]['text':' integral types don't have `Nan`.','line_number':1217,'multiline':False]['text':' all integer types get promoted to kLong','line_number':1243,'multiline':False]['text':' NOTE: this could be implemented via diag and sum, but this has perf problems,','line_number':1250,'multiline':False]['text':' see https://github.com/pytorch/pytorch/pull/47305,','line_number':1251,'multiline':False]['text':' Returns the ScalarType of the self tensor if the tensor is non integral type','line_number':1254,'multiline':False]['text':' In the case, self is an integer type tensor, at::kLong is return since promote_integers','line_number':1255,'multiline':False]['text':' is set to true','line_number':1256,'multiline':False]['text':' TODO: the TensorIterator reduction implementation of mean','line_number':1329,'multiline':False]['text':' (mean_kernel_impl()) is unvectorized and leads to very poor performance','line_number':1330,'multiline':False]['text':' for production workloads. Once that's fixed, the following code can be used','line_number':1331,'multiline':False]['text':' in lieu of the sum + divide implementation below.','line_number':1332,'multiline':False]['text':' For accuracy reasons, BF16/FP16 mean should be computed via the','line_number':1344,'multiline':False]['text':' following approach:','line_number':1345,'multiline':False]['text':'  cast_fp32 -> sum -> div -> cast_bf16_or_fp16','line_number':1346,'multiline':False]['text':'','line_number':1347,'multiline':False]['text':' Such an approach is necessary because if we were to choose the same','line_number':1348,'multiline':False]['text':' approach for BF16/FP16 as FP32 here, then it would have resulted in','line_number':1349,'multiline':False]['text':' the following code-flow -','line_number':1350,'multiline':False]['text':' cast_fp32 -> sum -> cast_bf16 -> cast_fp32 -> div -> cast_bf16,','line_number':1351,'multiline':False]['text':' which, in turn, does not produce as accurate results.','line_number':1352,'multiline':False]['text':' If dtype is FP16 or BF16, self (input tensor) will initially be cast to','line_number':1356,'multiline':False]['text':' FP32 in sum_out. This results in having to read that FP32 tensor again,','line_number':1357,'multiline':False]['text':' but maybe in the future, we could revise the implementation to not','line_number':1358,'multiline':False]['text':' materialize that intermediate FP32 tensor. That approach would probably','line_number':1359,'multiline':False]['text':' require some modifications in binary_kernel_reduce_vec(),','line_number':1360,'multiline':False]['text':' TensorIteratorBase::for_each(), and','line_number':1361,'multiline':False]['text':' TensorIteratorBase::serial_for_each(), apart from sum kernel for CPU.','line_number':1362,'multiline':False]['text':' After sum & div, cast result_mut back to BF16 or FP16, if required.','line_number':1364,'multiline':False]['text':' device is not CPU','line_number':1367,'multiline':False]['text':' TODO(@heitorschueroff) implement custom kernels for nanmean','line_number':1391,'multiline':False]['text':' can't take max of empty tensor','line_number':1422,'multiline':False]['text':'includeBool=','line_number':1442,'multiline':True]['text':' for integral inputs, promote input to default floating type.','line_number':1443,'multiline':False]['text':'includeBool=','line_number':1456,'multiline':True]['text':' even for integral inputs, result is floating dtype','line_number':1457,'multiline':False]['text':' special_logsumexp, alias for logsumexp','line_number':1475,'multiline':False]['text':' Left this implementation without deprecating it as it is called in a number of places','line_number':1490,'multiline':False]['text':' in the codebase. We should swap those by linalg_vector_norm','line_number':1491,'multiline':False]['text':' As CUDA supports dynamic type casting, we use this overload of','line_number':1546,'multiline':False]['text':' `make_reduction`, which doesn't cast input to the result type i.e. kBool.,','line_number':1547,'multiline':False]['text':' otherwise we use the overload below which casts the input to kBool (which is','line_number':1548,'multiline':False]['text':' an extra operation).','line_number':1549,'multiline':False]['text':' Default implementation in terms of all-reduce or single dim reduce','line_number':1603,'multiline':False]['text':' Convert to a 1 or 0 mask','line_number':1621,'multiline':False]['text':'keepdim=','line_number':1632,'multiline':True]['text':'keepdim=','line_number':1634,'multiline':True]['text':' ((x - mean)**2).sum()','line_number':1764,'multiline':False]['text':' Convert to infinity if out of range for a float.','line_number':1774,'multiline':False]['text':' Doing it now prevents checked_convert failing later','line_number':1775,'multiline':False]['text':' namespace','line_number':1788,'multiline':False]['text':' For complex, calculate variance of real and imaginary components','line_number':1803,'multiline':False]['text':' separately then add to get overall variance.','line_number':1804,'multiline':False]['text':'take_sqrt=','line_number':1815,'multiline':True]['text':'take_sqrt=','line_number':1826,'multiline':True]['text':' Computation for floating point','line_number':1835,'multiline':False]['text':' Trivial reduction','line_number':1845,'multiline':False]['text':' NOTE: CPU performance significantly regressed when attempting to port to','line_number':1851,'multiline':False]['text':' ATen,','line_number':1852,'multiline':False]['text':'   so all-reduce has a custom implementation.','line_number':1853,'multiline':False]['text':'   See https://github.com/pytorch/pytorch/pull/43858.','line_number':1854,'multiline':False]['text':' For complex, calculate for real and imaginary components separately then combine as:','line_number':1879,'multiline':False]['text':' variance = var_real + var_imag','line_number':1880,'multiline':False]['text':' mean = mean_real + j * mean_imag','line_number':1881,'multiline':False]['text':'take_sqrt=','line_number':1894,'multiline':True]['text':'take_sqrt=','line_number':1907,'multiline':True]['text':' Computation for floating point','line_number':1917,'multiline':False]['text':' Trivial reduction','line_number':1925,'multiline':False]['text':'dim=','line_number':1937,'multiline':True]['text':'correction=','line_number':1938,'multiline':True]['text':'dim=','line_number':1945,'multiline':True]['text':'correction=','line_number':1946,'multiline':True]['text':'dim=','line_number':1952,'multiline':True]['text':'correction=','line_number':1953,'multiline':True]['text':'dim=','line_number':1958,'multiline':True]['text':'correction=','line_number':1959,'multiline':True]['text':'dim=','line_number':1993,'multiline':True]['text':'correction=','line_number':1994,'multiline':True]['text':'dim=','line_number':1999,'multiline':True]['text':'correction=','line_number':2000,'multiline':True]['text':'dim=','line_number':2006,'multiline':True]['text':'correction=','line_number':2007,'multiline':True]['text':'dim=','line_number':2013,'multiline':True]['text':'correction=','line_number':2013,'multiline':True]['text':'correction=','line_number':2018,'multiline':True]['text':'correction=','line_number':2023,'multiline':True]['text':' Since the flags like neg/conj should be already handled outside the','line_number':2193,'multiline':False]['text':' TensorIterator, it should be safe to have the following fast path by','line_number':2194,'multiline':False]['text':' ensuring the storage and strides exactly the same.','line_number':2195,'multiline':False]['text':' Extra checks to ensure the safety in case cpu_equal is directly called in C++.','line_number':2201,'multiline':False]['text':'includeBool=','line_number':2205,'multiline':True]['text':' max(dim), min(dim), topk(dim), mode(dim), are examples of reduction','line_number':2261,'multiline':False]['text':' functions that select values. value_selecting_reduction_backward is the','line_number':2262,'multiline':False]['text':' backward function for those operators; it propagates the grad to the','line_number':2263,'multiline':False]['text':' specific value locations referred to at `indices`.','line_number':2264,'multiline':False]['text':' TODO: The signature of sum.dim_IntList and _sparse_csr_sum.dim_dtype is a little','line_number':2322,'multiline':False]['text':' bit different in the second parameters `dim`, which causes the conversion of `dim`','line_number':2323,'multiline':False]['text':' to call into `_sparse_csr_sum`. Align the signatures would be a better choice.','line_number':2324,'multiline':False]['text':' namespace native','line_number':2335,'multiline':False]['text':' namespace at','line_number':2336,'multiline':False]