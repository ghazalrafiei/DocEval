['text':' See Note [BatchLinearAlgebraLib split implementation files]','line_number':1,'multiline':False]['text':' Some cuBLAS and cuSOLVER batched routines require input to be a device array of pointers to device individual matrices','line_number':42,'multiline':False]['text':' 'input' must be a contiguous tensor','line_number':43,'multiline':False]['text':' cublas/cusolver interface requires 'int'','line_number':49,'multiline':False]['text':' if batch_size==0, then start=0 and end=0','line_number':52,'multiline':False]['text':' if input_mat_stride==0, then step=sizeof(scalar_t)','line_number':53,'multiline':False]['text':'start=','line_number':55,'multiline':True]['text':'end=','line_number':56,'multiline':True]['text':'step=','line_number':57,'multiline':True]['text':' needed to run ldl_solve tests in parallel','line_number':144,'multiline':False]['text':' see https://github.com/pytorch/pytorch/issues/82894 for examples of failures','line_number':145,'multiline':False]['text':' allocate workspace storage','line_number':167,'multiline':False]['text':' info from sytrs only reports if the i-th parameter is wrong','line_number':200,'multiline':False]['text':' so we don't need to check it all the time','line_number':201,'multiline':False]['text':' anonymous namespace','line_number':206,'multiline':False]['text':' call cusolver gesvd function to calculate svd','line_number':248,'multiline':False]['text':' nb. We can do this .view() because V is a batch of F-contig matrices','line_number':280,'multiline':False]['text':' V is F-contig. Since this function computes Vh, we need an auxiliary F-conj-transposed matrix to hold Vh','line_number':283,'multiline':False]['text':' We'll copy A inside svd_cusolver_gesvd','line_number':321,'multiline':False]['text':' We need to pass a copy of A, as it will be overwritten','line_number':327,'multiline':False]['text':' gesvd just knows how to handle m >= n, so in the other case we need to transpose A','line_number':328,'multiline':False]['text':' Shallow copy','line_number':330,'multiline':False]['text':' Similar to the case in svd_magma(), experiments have shown Vh tensor is','line_number':332,'multiline':False]['text':' not guaranteed to be column major on ROCM, we have to create a copy to','line_number':333,'multiline':False]['text':' deal with this','line_number':334,'multiline':False]['text':' call cusolver gesvdj function to calculate svd','line_number':357,'multiline':False]['text':' Need to pass allocated memory to the function, otherwise it fails','line_number':366,'multiline':False]['text':' gesvdj_params controls the numerical accuracy of cusolver gesvdj iterations on GPU','line_number':389,'multiline':False]['text':' Todo: expose the following two parameters to users','line_number':393,'multiline':False]['text':' // The following code can be used to check or report the gesvdj residual.','line_number':420,'multiline':False]['text':' // Note: this will introduce a device-host sync and may negatively affect the performance','line_number':421,'multiline':False]['text':' double residual = 0;','line_number':422,'multiline':False]['text':' TORCH_CUSOLVER_CHECK(cusolverDnXgesvdjGetResidual(handle, gesvdj_params, &residual));','line_number':423,'multiline':False]['text':' printf("gesvdj residual = %.6e\n", residual);','line_number':424,'multiline':False]['text':' wrapper around apply_svd_cusolver_gesvdj that handles dtype dispatch','line_number':430,'multiline':False]['text':' note that gesvdj returns V, which is what we want','line_number':431,'multiline':False]['text':' Need to pass a copy of A, since A will be rewritten inside the function call','line_number':432,'multiline':False]['text':' call cusolver gesvdj batched function to calculate svd','line_number':439,'multiline':False]['text':' Need to pass allocated memory to the function, otherwise it fails','line_number':452,'multiline':False]['text':' gesvdj_params controls the numerical accuracy of cusolver gesvdj iterations on GPU','line_number':465,'multiline':False]['text':' Todo: expose the following two parameters to users','line_number':469,'multiline':False]['text':' The kernel assumes full_matrices == true','line_number':488,'multiline':False]['text':' If full_matrices == false and m != n, we create auxiliary tensors of the right size and copy the results back','line_number':489,'multiline':False]['text':' Size of U with full_matrices == True','line_number':495,'multiline':False]['text':' U, V should be a batch of Fortran contiguous arrays','line_number':497,'multiline':False]['text':' Size of V with full_matrices == True','line_number':500,'multiline':False]['text':' Here U_ and V_ are batches of F-contig square matrices','line_number':505,'multiline':False]['text':' Copy the result back if we created any new matrix','line_number':511,'multiline':False]['text':' number of singular values','line_number':540,'multiline':False]['text':' The strides for "empty matrices" are needed to satisfy cusolver.','line_number':541,'multiline':False]['text':' Need to pass allocated memory to the function, otherwise it fails','line_number':544,'multiline':False]['text':' The residual Frobenius norm is always returned in double.','line_number':564,'multiline':False]['text':' cuSOLVER remark: if the user is confident on the accuracy of singular values and singular vectors,','line_number':565,'multiline':False]['text':'   for example, certain conditions hold (required singular value is far from zero),','line_number':566,'multiline':False]['text':'   then the performance can be improved by passing a null pointer to h_RnrmF, i.e. no computation of residual norm.','line_number':567,'multiline':False]['text':' Comment: calculation of Frobenius norm is expensive and doesn't affect accuracy of the result','line_number':568,'multiline':False]['text':' cuSOLVER h_RnrmF is not calculated: reinterpret_cast<double*>(residual_frobenius_norm.get()),','line_number':574,'multiline':False]['text':' We'll copy A inside svd_cusolver_gesvdaStridedBatched','line_number':579,'multiline':False]['text':' We need to pass a copy of A, as it will be overwritten','line_number':583,'multiline':False]['text':' gesvdaStridedBatched just knows how to handle m >= n, so in the other case we need to transpose A','line_number':584,'multiline':False]['text':' Check convergence of gesvdj/gesvdjBatched/gesvdaStridedBatched results.','line_number':596,'multiline':False]['text':' If not converged, return a vector that contains indices of the non-converging batches.','line_number':597,'multiline':False]['text':' If the returned vector is empty, all the matrices are converged.','line_number':598,'multiline':False]['text':' This function will cause a device-host sync.','line_number':599,'multiline':False]['text':' From cusolver doc, if info < 0, the i-th function call parameter is wrong,','line_number':609,'multiline':False]['text':' which means pytorch implementation of cusolver is wrong.','line_number':610,'multiline':False]['text':' In our use case, gesvdj, gesvdjBatched, and gesvdaStridedBatched have the same notations for `info`.','line_number':613,'multiline':False]['text':' However, it is not the same for gesvd, though we don't use this function to check gesvd convergence either.','line_number':616,'multiline':False]['text':' If it's implemented some day in the future, this needs to be handled carefully.','line_number':617,'multiline':False]['text':' Depending on the number of non-converging batches,','line_number':623,'multiline':False]['text':' format the non-converging batches string as either (no leading or trailing whitespaces)','line_number':624,'multiline':False]['text':' batches 2, 3, 5  // or','line_number':625,'multiline':False]['text':' batches 2, 3, 5, 7, 11 and other 65535 batches','line_number':626,'multiline':False]['text':' This function returns V, not V^H.','line_number':647,'multiline':False]['text':' Here U and V are F-contig whenever they are defined (i.e. whenever compute_uv=true)','line_number':656,'multiline':False]['text':' The default heuristic is to use gesvdj driver','line_number':663,'multiline':False]['text':' See the benchmarks in','line_number':673,'multiline':False]['text':' https://github.com/pytorch/pytorch/pull/88502#issuecomment-1303860789','line_number':674,'multiline':False]['text':' The m <= 32 && n <= 32 restrictions come from the limitations of the cusolver backend. See the cusolver docs','line_number':675,'multiline':False]['text':' gesvdj driver may be numerically unstable for large sized matrix','line_number':679,'multiline':False]['text':' cuSOLVER: gesvdaStridedBatched is preferred for "tall skinny" (m > n) matrices','line_number':683,'multiline':False]['text':' We do a transpose here to make it also work for (m < n) matrices.','line_number':684,'multiline':False]['text':' Need convergence check','line_number':690,'multiline':False]['text':' A device-host sync will be performed.','line_number':692,'multiline':False]['text':' Todo: implement the svd_ex variant to not check result convergence, thus removing the device-host sync','line_number':693,'multiline':False]['text':' We'll do the fallback if user doesn't specify a driver and the default heuristic doesn't converge well.','line_number':705,'multiline':False]['text':' However, if user manually chooses a driver, should we just do a warning or a hard crash?','line_number':706,'multiline':False]['text':' `info` will be checked later at `TORCH_IMPL_FUNC(_linalg_svd_out)` function.','line_number':713,'multiline':False]['text':' Implementation of Cholesky decomposition using looped cusolverDn<T>potrf or cusolverDnXpotrf (64-bit)','line_number':717,'multiline':False]['text':' allocate workspace storage','line_number':738,'multiline':False]['text':' USE_CUSOLVER_64_BIT','line_number':759,'multiline':False]['text':' allocate workspace storage','line_number':766,'multiline':False]['text':' USE_CUSOLVER_64_BIT','line_number':781,'multiline':False]['text':' Implementation of Cholesky decomposition using batched cusolverDn<T>potrfBatched','line_number':784,'multiline':False]['text':' Warning: cusolverDn<T>potrfBatched doesn't work quite well when matrix size or batch size is zero.','line_number':785,'multiline':False]['text':' If you write your own C++ extension and use this function, make sure you do a zero numel check for the input.','line_number':786,'multiline':False]['text':' cusolver batched kernels require input be "device array of device pointers"','line_number':796,'multiline':False]['text':' USE_CUSOLVER_64_BIT','line_number':856,'multiline':False]['text':' USE_CUSOLVER_64_BIT','line_number':872,'multiline':False]['text':' This code path is only dispatched to if MAGMA is not linked in the pytorch build.','line_number':876,'multiline':False]['text':' cusolverDn<t>potrsBatched only supports nrhs == 1','line_number':877,'multiline':False]['text':' cusolverDn<t>potrsBatched only supports nrhs == 1','line_number':915,'multiline':False]['text':' info from potrs and potrsBatched only report if the i-th parameter is wrong, not about the matrix singularity, etc.','line_number':926,'multiline':False]['text':' So we don't need to check it all the time.','line_number':927,'multiline':False]['text':'offset=','line_number':938,'multiline':True]['text':'dim1=','line_number':938,'multiline':True]['text':'dim2=','line_number':938,'multiline':True]['text':' Debug only: info of cusolver potrs only check if the i-th parameter is wrong','line_number':943,'multiline':False]['text':' Function argument `infos` is a CPU tensor, the following copy will cause a device-host sync.','line_number':944,'multiline':False]['text':' infos.copy_(infos_gpu);','line_number':945,'multiline':False]['text':'
  The geqrf function computes the QR decomposition of a m x n matrix A.

  Args:
  * `A` - [in] Tensor with matrices for QR decomposition,
          [out] Tensor containing R in the upper triangle of A
          and elementary reflectors below the main diagonal of A
  * `tau` - Tensor containing the magnitudes of the elementary reflectors
  * `m` - The number of rows of `input` to consider
  * `n` - The number of columns of `input` to consider (actual sizes of `input` could be larger)

  For further details, please see the cuSOLVER documentation for GEQRF.
','line_number':954,'multiline':True]['text':' get the optimal work size and allocate workspace tensor','line_number':983,'multiline':False]['text':' workspaceInBytesOnDevice','line_number':985,'multiline':False]['text':' workspaceInBytesOnHost','line_number':986,'multiline':False]['text':' use default algorithm (currently it's the only option)','line_number':987,'multiline':False]['text':' USE_CUSOLVER_64_BIT','line_number':1005,'multiline':False]['text':' allocate workspace storage on device and host','line_number':1013,'multiline':False]['text':' allocate workspace storage on device','line_number':1032,'multiline':False]['text':' USE_CUSOLVER_64_BIT','line_number':1045,'multiline':False]['text':' info from geqrf only reports if the i-th parameter is wrong, not about the matrix singularity','line_number':1048,'multiline':False]['text':' so we don't need to check it all the time','line_number':1049,'multiline':False]['text':' This is a type dispatching helper function for 'apply_geqrf'','line_number':1053,'multiline':False]['text':'
  The ormqr function multiplies Q with another matrix from a sequence of
  elementary reflectors, such as is produced by the geqrf function.

  Args:
  * `input`     - Tensor with elementary reflectors below the diagonal,
                  encoding the matrix Q.
  * `tau`       - Tensor containing the magnitudes of the elementary
                  reflectors.
  * `other`     - [in] Tensor containing the matrix to be multiplied.
                  [out] result of the matrix multiplication with Q.
  * `left`      - bool, determining whether `other` is left- or right-multiplied with Q.
  * `transpose` - bool, determining whether to transpose (or conjugate transpose) Q before multiplying.

  For further details, please see the cuSOLVER documentation for ORMQR and UNMQR.
','line_number':1060,'multiline':True]['text':' get the optimal work size and allocate workspace tensor','line_number':1095,'multiline':False]['text':' allocate workspace storage','line_number':1109,'multiline':False]['text':' info from ormqr only reports if the i-th parameter is wrong','line_number':1125,'multiline':False]['text':' so we don't need to check it all the time','line_number':1126,'multiline':False]['text':' This is a type dispatching helper function for 'apply_ormqr'','line_number':1131,'multiline':False]['text':'
  The orgqr function allows reconstruction of an orthogonal (or unitary) matrix Q,
  from a sequence of elementary reflectors, such as produced by the geqrf function.

  Args:
  * `self` - Tensor with the directions of the elementary reflectors below the diagonal,
              it will be overwritten with the result
  * `tau` - Tensor containing the magnitudes of the elementary reflectors

  For further details, please see the cuSOLVER documentation for ORGQR and UNGQR.
','line_number':1138,'multiline':True]['text':' LAPACK's requirement','line_number':1161,'multiline':False]['text':' cuSOLVER doesn't compute anything for this case, which is wrong','line_number':1165,'multiline':False]['text':' the result should be a matrix with 1 on the diagonal','line_number':1166,'multiline':False]['text':'offset=','line_number':1169,'multiline':True]['text':'dim1=','line_number':1169,'multiline':True]['text':'dim2=','line_number':1169,'multiline':True]['text':' get the optimal work size and allocate workspace tensor','line_number':1173,'multiline':False]['text':' allocate workspace storage','line_number':1186,'multiline':False]['text':' info from orgqr only reports if the i-th parameter is wrong','line_number':1200,'multiline':False]['text':' so we don't need to check it all the time','line_number':1201,'multiline':False]['text':' This is a type dispatching helper function for 'apply_orgqr'','line_number':1206,'multiline':False]['text':' get the optimal work size and allocate workspace tensor','line_number':1232,'multiline':False]['text':' workspaceInBytesOnDevice','line_number':1234,'multiline':False]['text':' workspaceInBytesOnHost','line_number':1235,'multiline':False]['text':' use default algorithm (currently it's the only option)','line_number':1236,'multiline':False]['text':' USE_CUSOLVER_64_BIT','line_number':1254,'multiline':False]['text':' allocate workspace storage on device and host','line_number':1263,'multiline':False]['text':' allocate workspace storage on device','line_number':1283,'multiline':False]['text':' USE_CUSOLVER_64_BIT','line_number':1297,'multiline':False]['text':' syevj_params controls the numerical accuracy of syevj','line_number':1319,'multiline':False]['text':' by default the tolerance is set to machine accuracy','line_number':1320,'multiline':False]['text':' the maximum number of iteration of Jacobi method by default is 100','line_number':1321,'multiline':False]['text':' cuSOLVER documentations says: "15 sweeps are good enough to converge to machine accuracy"','line_number':1322,'multiline':False]['text':' LAPACK has SVD routine based on similar Jacobi algorithm (gesvj) and there a maximum of 30 iterations is set','line_number':1323,'multiline':False]['text':' Let's use the default values for now','line_number':1324,'multiline':False]['text':' get the optimal work size and allocate workspace tensor','line_number':1328,'multiline':False]['text':' allocate workspace storage on device','line_number':1339,'multiline':False]['text':' syevj_params controls the numerical accuracy of syevj','line_number':1373,'multiline':False]['text':' by default the tolerance is set to machine accuracy','line_number':1374,'multiline':False]['text':' the maximum number of iteration of Jacobi method by default is 100','line_number':1375,'multiline':False]['text':' cuSOLVER documentations says: "15 sweeps are good enough to converge to machine accuracy"','line_number':1376,'multiline':False]['text':' LAPACK has SVD routine based on similar Jacobi algorithm (gesvj) and there a maximum of 30 iterations is set','line_number':1377,'multiline':False]['text':' Let's use the default values for now','line_number':1378,'multiline':False]['text':' get the optimal work size and allocate workspace tensor','line_number':1385,'multiline':False]['text':' allocate workspace storage on device','line_number':1399,'multiline':False]['text':' Use syevjBatched for batched matrix opertion when matrix size <= 32','line_number':1438,'multiline':False]['text':' See https://github.com/pytorch/pytorch/pull/53040#issuecomment-788264724','line_number':1439,'multiline':False]['text':' syevj is better than syevd for float32 dtype and matrix sizes 32x32 - 512x512','line_number':1442,'multiline':False]['text':' See https://github.com/pytorch/pytorch/pull/53040#issuecomment-788264724','line_number':1443,'multiline':False]['text':' The 'apply_' word is used for templated by dtype functions that call an API routine','line_number':1450,'multiline':False]['text':' underneath. Since the cusolver API has a slightly different structure we do not prepend','line_number':1451,'multiline':False]['text':' apply_ to this function.','line_number':1452,'multiline':False]['text':' Necessary because cuSOLVER uses nan for outputs that correspond to 0 in MAGMA for non-pivoted LU.','line_number':1484,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/53879#issuecomment-830633572','line_number':1485,'multiline':False]['text':' nan_to_num does not work for complex inputs','line_number':1487,'multiline':False]['text':' https://github.com/pytorch/pytorch/issues/59247','line_number':1488,'multiline':False]['text':' lu and pivots tensors can be broadcast to b','line_number':1514,'multiline':False]['text':' here we construct a helper indexing tensor to linearly index into lu and pivots','line_number':1515,'multiline':False]['text':' USE_LINALG_SOLVER','line_number':1541,'multiline':False]['text':' namespace at::native','line_number':1543,'multiline':False]