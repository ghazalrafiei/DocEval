['text':' number of input & output planes and kernel size is indirectly defined by','line_number':96,'multiline':False]['text':' the weight tensor','line_number':97,'multiline':False]['text':' Force batch','line_number':262,'multiline':False]['text':' Batch size + input planes','line_number':280,'multiline':False]['text':' Resize output','line_number':283,'multiline':False]['text':' Create temporary columns','line_number':287,'multiline':False]['text':' Define a buffer of ones, for bias accumulation','line_number':291,'multiline':False]['text':' Helpers','line_number':298,'multiline':False]['text':' For each elt in batch, do:','line_number':302,'multiline':False]['text':' Matrix mulitply per output:','line_number':304,'multiline':False]['text':' M,N,K are dims of matrix A and B','line_number':308,'multiline':False]['text':' (see http://docs.nvidia.com/cuda/cublas/#cublas-lt-t-gt-gemm)','line_number':309,'multiline':False]['text':' Do GEMM (note: this is a bit confusing because gemm assumes','line_number':315,'multiline':False]['text':' column-major matrices)','line_number':316,'multiline':False]['text':' Unpack columns back into input:','line_number':332,'multiline':False]['text':' Do Bias after:','line_number':357,'multiline':False]['text':' M,N,K are dims of matrix A and B','line_number':358,'multiline':False]['text':' (see http://docs.nvidia.com/cuda/cublas/#cublas-lt-t-gt-gemm)','line_number':359,'multiline':False]['text':' Do GEMM (note: this is a bit confusing because gemm assumes','line_number':364,'multiline':False]['text':' column-major matrices)','line_number':365,'multiline':False]['text':' Resize output','line_number':384,'multiline':False]['text':' Force batch','line_number':488,'multiline':False]['text':' Batch size + input planes','line_number':510,'multiline':False]['text':' Resize output','line_number':513,'multiline':False]['text':' Create temporary columns','line_number':517,'multiline':False]['text':' Helpers','line_number':528,'multiline':False]['text':' For each elt in batch, do:','line_number':532,'multiline':False]['text':' Matrix mulitply per sample:','line_number':534,'multiline':False]['text':' Extract columns:','line_number':539,'multiline':False]['text':' M,N,K are dims of matrix A and B','line_number':565,'multiline':False]['text':' (see http://docs.nvidia.com/cuda/cublas/#cublas-lt-t-gt-gemm)','line_number':566,'multiline':False]['text':' Do GEMM (note: this is a bit confusing because gemm assumes','line_number':572,'multiline':False]['text':' column-major matrices)','line_number':573,'multiline':False]['text':' Resize output','line_number':592,'multiline':False]['text':' Force batch','line_number':712,'multiline':False]['text':' Batch size + input planes','line_number':735,'multiline':False]['text':' Create temporary columns','line_number':738,'multiline':False]['text':' Helpers','line_number':751,'multiline':False]['text':' For each elt in batch, do:','line_number':757,'multiline':False]['text':' Matrix mulitply per output:','line_number':759,'multiline':False]['text':' Do Weight:','line_number':762,'multiline':False]['text':' Matrix mulitply per output:','line_number':764,'multiline':False]['text':' Extract columns:','line_number':768,'multiline':False]['text':' M,N,K are dims of matrix A and B','line_number':794,'multiline':False]['text':' (see http://docs.nvidia.com/cuda/cublas/#cublas-lt-t-gt-gemm)','line_number':795,'multiline':False]['text':' n_input_plane','line_number':797,'multiline':False]['text':' Do GEMM (note: this is a bit confusing because gemm assumes','line_number':800,'multiline':False]['text':' column-major matrices)','line_number':801,'multiline':False]['text':' Resize','line_number':824,'multiline':False]['text':' namespace','line_number':834,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':844,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':870,'multiline':False]['text':' namespace at::native','line_number':1016,'multiline':False]