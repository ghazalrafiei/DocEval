['text':'resizable=','line_number':26,'multiline':True]['text':' If the allocators are the same and the memory is contiguous in the requested','line_number':42,'multiline':False]['text':' format, then there is no need to reallocate the tensor.','line_number':43,'multiline':False]['text':' If there is a need to reallocate the tensor on the other hand, either because','line_number':49,'multiline':False]['text':' the allocators are not the same, or the allocators are the same but the input','line_number':50,'multiline':False]['text':' is not contiguous in the requested format, then reallocate and directly copy','line_number':51,'multiline':False]['text':' into destination.  There is no need to allocate a temporary contiguous memory','line_number':52,'multiline':False]['text':' only to use it as the source of the copy operation onto our final destination.','line_number':53,'multiline':False]['text':' namespace mobile','line_number':64,'multiline':False]['text':' namespace native','line_number':65,'multiline':False]['text':' namespace at','line_number':66,'multiline':False]