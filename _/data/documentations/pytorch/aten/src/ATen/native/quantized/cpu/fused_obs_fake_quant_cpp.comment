['text':' Moving Average Min/Max observer for input tensor','line_number':46,'multiline':False]['text':' preserve sparsity','line_number':85,'multiline':False]['text':' force power of two','line_number':86,'multiline':False]['text':' preserve sparsity','line_number':97,'multiline':False]['text':' force power of two','line_number':98,'multiline':False]['text':' compute quantization parameters using min-max values','line_number':109,'multiline':False]['text':' bool preserve_sparsity','line_number':115,'multiline':False]['text':' force power of two','line_number':116,'multiline':False]['text':' compute quantization parameters using min-max values','line_number':123,'multiline':False]['text':' bool preserve_sparsity','line_number':129,'multiline':False]['text':' force power of two','line_number':130,'multiline':False]['text':' namespace','line_number':142,'multiline':False]['text':' Calculate min/max','line_number':162,'multiline':False]['text':' Calculate the size of the dimension we need to quantize over,','line_number':164,'multiline':False]['text':' For per-channel quant we default to axis 0, since it is only for','line_number':165,'multiline':False]['text':' weight quantization currently.','line_number':166,'multiline':False]['text':' Calculate qparams and fake_quantize','line_number':206,'multiline':False]['text':' namespace native','line_number':258,'multiline':False]['text':' namespace at','line_number':259,'multiline':False]