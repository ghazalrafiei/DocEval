['text':'  Copyright Â© 2022 Apple Inc.','line_number':1,'multiline':False]['text':' namespace to localize the CachedGraph struct for Binary Cross Entropy','line_number':109,'multiline':False]['text':' gradOutput only used on backward pass','line_number':115,'multiline':False]['text':' lossTensor used for forward, and gradInputTensor for backward pass','line_number':117,'multiline':False]['text':' Forward BCE: L = -w (y ln(x) + (1-y) ln(1-x))','line_number':127,'multiline':False]['text':' -100 is the hard limit value defined in BCELoss Spec. to clamp the log','line_number':129,'multiline':False]['text':' 1 - x','line_number':131,'multiline':False]['text':' log(x)','line_number':135,'multiline':False]['text':' max(log(x), -100)','line_number':137,'multiline':False]['text':' log(1 - x)','line_number':139,'multiline':False]['text':' max(log(1 - x), -100)','line_number':141,'multiline':False]['text':' (y - 1) resulted from -(1 - y)','line_number':143,'multiline':False]['text':' (y - 1) * max(log(1 - x), -100)','line_number':147,'multiline':False]['text':' y * max(log(x), -100)','line_number':151,'multiline':False]['text':' ((y - 1) * max(log(1 - x), -100)) - (y * max(log(x), -100))','line_number':155,'multiline':False]['text':' Backward BCE: d(L)/d(x) = -w (y - x) / (x - x^2)','line_number':165,'multiline':False]['text':' epsilon used to clamp the grad input denominator','line_number':167,'multiline':False]['text':' 1 - x','line_number':169,'multiline':False]['text':' x * (1 - x)','line_number':173,'multiline':False]['text':' max(x * (1 - x), epsilon)','line_number':177,'multiline':False]['text':' (x - y)','line_number':181,'multiline':False]['text':' (x - y) / max(x * (1 - x), epsilon)','line_number':185,'multiline':False]['text':' gradOutput * (((x - y) / max(x * (1 - x), epsilon)))','line_number':189,'multiline':False]['text':' Binary Cross Enropy (Forward/Backward BCELoss)','line_number':196,'multiline':False]['text':' NOTE: "loss" tensor would be "grad_input" if it's a backward pass','line_number':197,'multiline':False]['text':' TODO: add sanity check for the elements of input tensor to be within [0..1]','line_number':205,'multiline':False]['text':' if grad_output is defined, then it's a backward pass','line_number':229,'multiline':False]['text':' namespace BCELoss','line_number':285,'multiline':False]['text':' NLLLoss','line_number':287,'multiline':False]['text':' Replace ignored_index with length depth + 1 so that oneHotAPI ignores it','line_number':346,'multiline':False]['text':' Empty output','line_number':437,'multiline':False]['text':' TODO: Make the key','line_number':466,'multiline':False]['text':' The transposes are needed to get the class dimension (dim 1) to the inner most dim for gather op.','line_number':482,'multiline':False]['text':' The transpose become nop in the 2D case.','line_number':483,'multiline':False]['text':' Zero out loss','line_number':507,'multiline':False]['text':' Compute new batch size','line_number':525,'multiline':False]['text':' Create dictionary of inputs and outputs','line_number':566,'multiline':False]['text':' smooth_l1_loss_mps:','line_number':610,'multiline':False]['text':' ln = 0.5 * ( xn - yn ) ^ 2 / beta,       if |xn - yn| < beta','line_number':611,'multiline':False]['text':'    = | xn - yn | - 0.5 * beta,           otherwise','line_number':612,'multiline':False]['text':' Setup tensors','line_number':617,'multiline':False]['text':' 0.5 * beta','line_number':620,'multiline':False]['text':' Calculating first part of the equation:','line_number':622,'multiline':False]['text':' ln = 0.5(xn - yn)^2/beta, if |xn - yn| < beta','line_number':623,'multiline':False]['text':' xn - yn','line_number':625,'multiline':False]['text':' | xn - yn |','line_number':630,'multiline':False]['text':' | xn - yn | < beta','line_number':633,'multiline':False]['text':' ( xn - yn ) ^ 2','line_number':638,'multiline':False]['text':' 0.5 * ( xn - yn ) ^ 2','line_number':641,'multiline':False]['text':' 0.5 * ( xn - yn ) ^ 2 / beta','line_number':646,'multiline':False]['text':' Calculating second part of the equation:','line_number':651,'multiline':False]['text':' | xn - yn | - 0.5 * beta, if | xn - yn | >= beta','line_number':652,'multiline':False]['text':' | xn - yn | - 0.5 * beta','line_number':654,'multiline':False]['text':' Determine the shape of the output','line_number':698,'multiline':False]['text':' If the reduction is 'mean' or 'sum', the output shape is a scalar,','line_number':699,'multiline':False]['text':' otherwise, the output shape is the same shape as input','line_number':700,'multiline':False]['text':' Output: scalar, if reduction is 'mean' or 'sum'','line_number':702,'multiline':False]['text':' Output is a single value in case reduction is set to mean or sum','line_number':712,'multiline':False]['text':' Output: If reduction is 'none', then (N, *); same shape as the input','line_number':718,'multiline':False]['text':' resize_tensor(&output);','line_number':722,'multiline':False]['text':' xn - yn','line_number':758,'multiline':False]['text':' | xn - yn |','line_number':762,'multiline':False]['text':' | xn - yn | < beta','line_number':764,'multiline':False]['text':' ( xn - yn ) / beta','line_number':768,'multiline':False]['text':' ( x - y ) / | x - y |','line_number':772,'multiline':False]['text':' namespace mps','line_number':811,'multiline':False]['text':' APIs exposed to at::native scope','line_number':813,'multiline':False]['text':' HuberLoss','line_number':815,'multiline':False]['text':' Create dictionary of inputs and outputs','line_number':882,'multiline':False]['text':' constant does not support MPSDataTypeBool','line_number':936,'multiline':False]['text':' first condition: (input - target) <= -delta','line_number':956,'multiline':False]['text':' formula: -norm * grad_output * delta','line_number':957,'multiline':False]['text':' second condition: (input - target) >= delta','line_number':959,'multiline':False]['text':' formula: norm * grad_output * delta','line_number':960,'multiline':False]['text':' third condition: (input - target) within -delta to delta','line_number':963,'multiline':False]['text':' formula: norm * (input - target) * grad_output','line_number':964,'multiline':False]['text':' MSELoss','line_number':1010,'multiline':False]['text':' BCELoss','line_number':1064,'multiline':False]['text':' SmoothL1Loss','line_number':1099,'multiline':False]['text':' NLLLoss','line_number':1116,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':1196,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':1209,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':1252,'multiline':False]['text':' See [Note: hacky wrapper removal for optional tensor]','line_number':1268,'multiline':False]['text':' namespace at::native','line_number':1277,'multiline':False]