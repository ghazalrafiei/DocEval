['text':'  Copyright Â© 2022 Apple Inc.','line_number':1,'multiline':False]['text':' Create convolution descriptor','line_number':38,'multiline':False]['text':' TODO: Program the padding style','line_number':53,'multiline':False]['text':' PyTorch always uses OIHW memory layout for weights','line_number':64,'multiline':False]['text':' Derive from MPSCachedGraph','line_number':111,'multiline':False]['text':' Reshape the bias to be broadcastable with output of conv2d','line_number':221,'multiline':False]['text':' Avoid "grad_input" when this is being used as transposed convolution','line_number':272,'multiline':False]['text':' Derive from MPSCachedGraph','line_number':276,'multiline':False]['text':' Add backward with input','line_number':284,'multiline':False]['text':' Depthwise conv is input feature channels = groups. So I in OIHW has to be 1.','line_number':314,'multiline':False]['text':' For uniformity with everything else, although it seems grad_weight','line_number':407,'multiline':False]['text':' would be unambiguous too.','line_number':408,'multiline':False]['text':' Derive from MPSCachedGraph','line_number':421,'multiline':False]['text':' namespace at::native','line_number':629,'multiline':False]