['text':' Returns true if resize is necessary','line_number':20,'multiline':False]['text':' Tests for resizing of tensors with one or more elements','line_number':23,'multiline':False]['text':' avoid a redispatch for cpu and cuda.','line_number':59,'multiline':False]['text':' TODO: when resize_cuda_ is re-written to be unified with resize_,','line_number':60,'multiline':False]['text':' we can provide the same benefit for cuda.','line_number':61,'multiline':False]['text':'','line_number':62,'multiline':False]['text':' TODO(#61485): functorch wrapped tensors should not go through the','line_number':63,'multiline':False]['text':' fast path. This is a hack, longer term solutions are in the issue','line_number':64,'multiline':False]['text':' Call the sparse implementation in SparseTensor.cpp directly.','line_number':106,'multiline':False]['text':' A dynamic dispatch here is NOT necessary, so I didn't put','line_number':107,'multiline':False]['text':' this function in native_functions.yaml','line_number':108,'multiline':False]['text':' TODO(VitalyFedyunin): Move it to HTML docs.','line_number':111,'multiline':False]['text':'','line_number':112,'multiline':False]['text':' Strides of the output tensor of `resize_as_` operator is defined by input','line_number':113,'multiline':False]['text':' tensor strides and the value of memory_format argument.','line_number':114,'multiline':False]['text':'','line_number':115,'multiline':False]['text':' If memory_format is omitted and input tensor have the same shape as output','line_number':116,'multiline':False]['text':' tensor, strides of the output will remain unchanged. Strides going to be','line_number':117,'multiline':False]['text':' set to contiguous if shapes are different.','line_number':118,'multiline':False]['text':'','line_number':119,'multiline':False]['text':' If memory_format is equals to MemoryFormat::Contiguous (torch.contiguous_format)','line_number':120,'multiline':False]['text':' output tensor will have contiguous strides.','line_number':121,'multiline':False]['text':'','line_number':122,'multiline':False]['text':' If memory_format is equal to MemoryFormat::ChannelsLast (torch.channels_last)','line_number':123,'multiline':False]['text':' and input tensor is 4D, output tensor will have channels last memory layout.','line_number':124,'multiline':False]['text':'','line_number':125,'multiline':False]['text':' If memory_format is equal to MemoryFormat::Preserve (torch.preserve_format)','line_number':126,'multiline':False]['text':' output tensor will be defined by strides of the input tensor, following','line_number':127,'multiline':False]['text':' memory format preservation rule:','line_number':128,'multiline':False]['text':'','line_number':129,'multiline':False]['text':'  - If input tensor strides are in channels last format, output tensor will','line_number':130,'multiline':False]['text':'    have channels last memory layout.','line_number':131,'multiline':False]['text':'','line_number':132,'multiline':False]['text':'  - Otherwise, output tensor will have contiguous memory layout.','line_number':133,'multiline':False]['text':'','line_number':134,'multiline':False]['text':' It does not make sense to try to resize a storage','line_number':165,'multiline':False]['text':' to hold 0 elements, and this can break','line_number':166,'multiline':False]['text':' if storage_offset is positive but','line_number':167,'multiline':False]['text':' new_size is 0, so just bail in that case','line_number':168,'multiline':False]['text':' (same comment is in Resize.h)','line_number':169,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-argument-comment)','line_number':248,'multiline':False]['text':'strides=','line_number':249,'multiline':True]['text':' See Note [Enabling Deterministic Operations]','line_number':259,'multiline':False]['text':' namespace native','line_number':284,'multiline':False]['text':' namespace at','line_number':285,'multiline':False]