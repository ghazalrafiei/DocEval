['text':' launch bounds used for kernels utilizing TensorIterator','line_number':31,'multiline':False]['text':' number of randoms given by distributions like curand_uniform4, curand_uniform2_double','line_number':34,'multiline':False]['text':' used in calculating philox offset.','line_number':35,'multiline':False]['text':' utility function that calculates proper philox_offset','line_number':38,'multiline':False]['text':' for distributions utilizing TensorIterator. For distributions using','line_number':39,'multiline':False]['text':' TensorIterator, we are using a grid-stride loop with each','line_number':40,'multiline':False]['text':' thread yielding one element per thread. For the edge of the grid-stride','line_number':41,'multiline':False]['text':' loop, if the tensor size is large, the unroll loop will kick in and the float4','line_number':42,'multiline':False]['text':' from curand4 will start getting utilized (for common tensor sizes, we end up','line_number':43,'multiline':False]['text':' using rand.x from each thread). Hence, the philox_offset is','line_number':44,'multiline':False]['text':' (number of elements per thread * number of engine calls), which makes','line_number':45,'multiline':False]['text':' sure that philox offset increment is not less than the number of randoms used','line_number':46,'multiline':False]['text':' in each thread.','line_number':47,'multiline':False]['text':'number of times random will be generated per thread, to offset philox counter in thc random state','line_number':58,'multiline':False]['text':' grid stride loop kernel for distributions','line_number':64,'multiline':False]['text':'*
 * distribution_nullary_kernel is analogous to gpu_kernel in
 * ATen/native/cuda/Loops.cuh. Like gpu_kernel, it uses
 * TensorIterator to launch a kernel. However, the differences are
 *   - it launches a grid-stride loop based kernel. The kernel is not
 *     generic like elementwise_kernel in Loops.cuh and is specialized
 *     for the distribution kernels here.
 *   - For big size tensors, we can launch multiple kernels recursively
 *     (i.e. if (!iter.can_use_32bit_indexing())) and hence, the philox
 *     offset calculation is done in this function.
 *
 * FIXME: Can we specialize elementwise_kernel and launch_kernel in Loops.cuh
 * to have grid-stride loop kernel and then use that to launch our distribution
 * kernels? Note that we need a grid-stride loop kernel because, we found by testing
 * that it achieves peak effective bandwidth.
 ','line_number':94,'multiline':True]['text':' See Note [Acquire lock when using random generators]','line_number':132,'multiline':False]['text':' Binary kernel','line_number':177,'multiline':False]['text':' load data into registers','line_number':205,'multiline':False]['text':' compute and store','line_number':220,'multiline':False]['text':' namespace','line_number':275,'multiline':False]['text':' namespace at::native','line_number':276,'multiline':False]['text':' ==================================================== Random ========================================================','line_number':284,'multiline':False]['text':' define lambda to mod with range and add base','line_number':295,'multiline':False]['text':' This is the special kernel to handle single specific case:','line_number':323,'multiline':False]['text':' from(inclusive) = std::numeric_limits<int64_t>::lowest()','line_number':324,'multiline':False]['text':' to(exclusive) = None (= std::numeric_limits<int64_t>::max() + 1)','line_number':325,'multiline':False]['text':' ====================================================================================================================','line_number':399,'multiline':False]['text':' ==================================================== Normal ========================================================','line_number':431,'multiline':False]['text':' define lambda to multiply std and add mean','line_number':440,'multiline':False]['text':' ==================================================== Uniform ========================================================','line_number':455,'multiline':False]['text':' define lambda to reverse bounds, multiply 'range' and add 'from_'','line_number':464,'multiline':False]['text':' Compute output value before reversing the bounds','line_number':466,'multiline':False]['text':' BEFORE TOUCHING THIS CODE READ: https://github.com/pytorch/pytorch/issues/96947','line_number':467,'multiline':False]['text':' reverse the bounds of curand4 from (0, 1] to [0, 1)','line_number':469,'multiline':False]['text':' Note that this method is from legacy THCTensorRandom and is likely to give','line_number':470,'multiline':False]['text':' you more 0-s, since, the probability of gettings 1-s is higher than 0-s and','line_number':471,'multiline':False]['text':' by reversing the bounds, we are flipping the probabilities of 1-s and 0-s.','line_number':472,'multiline':False]['text':' BEFORE TOUCHING THIS CODE READ: https://github.com/pytorch/pytorch/issues/16706','line_number':473,'multiline':False]['text':' ================================================== LogNormal =======================================================','line_number':488,'multiline':False]['text':' define lambda for log_normal transformation','line_number':496,'multiline':False]['text':' =================================================== Geometric ======================================================','line_number':511,'multiline':False]['text':' define lambda for geometric transformation','line_number':517,'multiline':False]['text':' ================================================== Exponential =====================================================','line_number':532,'multiline':False]['text':' define lambda for exponential transformation','line_number':540,'multiline':False]['text':' ==================================================== Cauchy ========================================================','line_number':555,'multiline':False]['text':' define lambda for cauchy transformation','line_number':563,'multiline':False]['text':' ==================================================== Bernoulli =====================================================','line_number':578,'multiline':False]['text':' See Note [Register spilling in curand call for CUDA < 10]','line_number':594,'multiline':False]['text':' fallthrough','line_number':600,'multiline':False]['text':' fallthrough','line_number':605,'multiline':False]['text':' fallthrough','line_number':610,'multiline':False]['text':' The template argument `4` below indicates that we want to operate on four','line_number':618,'multiline':False]['text':' element at each time. See NOTE [ CUDA_tensor_applyN helpers ] for details.','line_number':619,'multiline':False]['text':'max_threads_per_block=','line_number':621,'multiline':True]['text':'min_blocks_per_sm==','line_number':622,'multiline':True]['text':' See Note [Acquire lock when using random generators]','line_number':629,'multiline':False]['text':' cast probabilities tensor to double for double `self` tensor, and to `float` for everything else','line_number':634,'multiline':False]['text':' define lambda for bernoulli transformation','line_number':653,'multiline':False]