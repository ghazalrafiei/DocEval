['text':' Algorithmic limitation: BlockReduce does two WarpReduce calls, each','line_number':13,'multiline':False]['text':' of which reduces C10_WARP_SIZE elements. So, at most','line_number':14,'multiline':False]['text':' C10_WARP_SIZE**2 elements can be reduced at a time.','line_number':15,'multiline':False]['text':' NOTE: This is >= the max block size on current hardware anyway (1024).','line_number':16,'multiline':False]['text':' Sums `val` accross all threads in a warp.','line_number':19,'multiline':False]['text':'','line_number':20,'multiline':False]['text':' Assumptions:','line_number':21,'multiline':False]['text':'   - The size of each block should be a multiple of `C10_WARP_SIZE`','line_number':22,'multiline':False]['text':' Sums `val` across all threads in a block.','line_number':50,'multiline':False]['text':'','line_number':51,'multiline':False]['text':' Warning: the return value is only valid for thread 0.','line_number':52,'multiline':False]['text':' Assumptions:','line_number':53,'multiline':False]['text':'   - The size of each block should be a multiple of `C10_WARP_SIZE`','line_number':54,'multiline':False]['text':'   - `shared` should be a pointer to shared memory with size of, at least,','line_number':55,'multiline':False]['text':'     `sizeof(T) * number_of_warps`','line_number':56,'multiline':False]['text':' prevent races when BlockReduces are called in a row.','line_number':63,'multiline':False]['text':' prevent races when BlockReduces are called in a row.','line_number':91,'multiline':False]['text':' namespace cuda_utils','line_number':103,'multiline':False]['text':' namespace native','line_number':104,'multiline':False]['text':' namespace at','line_number':105,'multiline':False]