['text':' for the definition of AT_CUDNN_ENABLED','line_number':2,'multiline':False]['text':' TODO: need to check out to implement groups for conv operator in Conv.cpp','line_number':35,'multiline':False]['text':' 1D is packed as 2d, hence we don't need other checks','line_number':39,'multiline':False]['text':' TODO: we create a broadcasted_bias tensor later so I think we don't need to make this contiguous here.','line_number':76,'multiline':False]['text':' we will revisit this when nvidia adds proper support for broadcasting','line_number':77,'multiline':False]['text':' bias_contig = bias->contiguous();','line_number':78,'multiline':False]['text':' cudnn v8.4.0 expects conv2d's int8 weight tensor's input and output channels to be a multiple of 4. if it is not','line_number':81,'multiline':False]['text':' we need to explicitly pad it to a multiple of 4 ourselves as cudnn does not currently support padding.','line_number':82,'multiline':False]['text':' TODO: when and if cudnn enables padding in their operators, we can remove padding on our end;','line_number':83,'multiline':False]['text':' currently, limit padding support to groups=1 (ungrouped conv)','line_number':84,'multiline':False]['text':' TODO: implement this for groups > 1','line_number':85,'multiline':False]['text':' the second argument is an initializer list of padded values. there are 2 values for each dimension.','line_number':90,'multiline':False]['text':' refer to https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html for more details','line_number':91,'multiline':False]['text':' TODO: this assumes 2D I think. make it more general?','line_number':99,'multiline':False]['text':'transpose=','line_number':145,'multiline':True]['text':'transpose=','line_number':175,'multiline':True]['text':' we currently use conv2d kernel for conv1d by making the input and weight tensors','line_number':189,'multiline':False]['text':' 4D rather than 3D. we add a dummy width dimension of size 1','line_number':190,'multiline':False]['text':' out channels, in channels / groups, L -> out channels, in channels / groups, 1, L','line_number':191,'multiline':False]['text':' namespace','line_number':210,'multiline':False]['text':' namespace native','line_number':211,'multiline':False]['text':' namespace at','line_number':212,'multiline':False]['text':' HAS_CUDNN_V8','line_number':214,'multiline':False]['text':' AT_CUDNN_ENABLED','line_number':215,'multiline':False]['text':' USE_CUDA','line_number':216,'multiline':False]