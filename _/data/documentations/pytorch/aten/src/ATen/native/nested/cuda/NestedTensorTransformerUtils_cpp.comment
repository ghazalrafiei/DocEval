['text':'*
 * This builds up the cumulative sequence length for a batch of sequences.
 * This is not very dry, but in the backward pass we already have cumulative_seq_len
 * on device. And all we need on CPU to launch the kernel is NNz. We could refactor the
 * the below function but it adds more complexity than I think is needed.
 ','line_number':12,'multiline':True]['text':' Calculate the cumulative sum of the sequence lengths','line_number':26,'multiline':False]['text':'*
   * This function is used to calculate two pieces of metadata that are needed
   * for use with flash-attention and efficient_attention kernels. They are the
   * cumulative sequence_length over a batch of sequences and the maximum
   * sequence length.
   *
   * @return A tuple of cumulative sequence lengths and the maximum sequence
   * length, and the last element in the cumulative_sequence_lengths
   ','line_number':33,'multiline':True]['text':' Calculate the cumulative sum of the sequence lengths','line_number':61,'multiline':False]['text':' Find the max element while we traverse','line_number':66,'multiline':False]['text':' Send to GPU, this is pretty light weight calc for normal batch size','line_number':69,'multiline':False]['text':' but maybe this needs to be on gpu','line_number':70,'multiline':False]['text':'*
   * This function checks if a nested tensor is valid for
   * use with the flash-attention and efficient_attention kernels without
   * needing to call contiguous on the nested tensor input.
   * It checks that the storage offsets' adjacent_differences are a constant
   * mutiple of the previous tensor in the nested tensor and that the strides
   * are monitonically decreasing. This check is done after calling transpose on
   * the nested tensor. Resulting in a Nt of shape [bsz, {seq_len}, num_heads, dim]
   *
   * @return A boolean indicating of contiguous needs to be called for input
   ','line_number':76,'multiline':True]['text':' This is safe since head_dim is assured to be consistent','line_number':95,'multiline':False]['text':' Check initially that the first tensor's strides','line_number':105,'multiline':False]['text':' are in strictly descending order','line_number':106,'multiline':False]['text':' NOTE: If num_heads is equal to 1 then we skip stride[0]','line_number':107,'multiline':False]['text':' Why you may ask? This is because we if n_heads == 1 then','line_number':108,'multiline':False]['text':' then as long as the last stride == 1 it does not matter','line_number':109,'multiline':False]['text':' what the strides are for the other dimensions.','line_number':110,'multiline':False]['text':'','line_number':111,'multiline':False]['text':' This would mean that the last stride is greater than the seq_len','line_number':114,'multiline':False]['text':' stride','line_number':115,'multiline':False]['text':' Check that each tensor i in the nested tensor has the same strides','line_number':124,'multiline':False]['text':' Check the offsets are a constant multiple from the previous numels','line_number':135,'multiline':False]['text':' TODO: When 0 seq_len nested tensors are allowed we need to guard','line_number':145,'multiline':False]['text':' against this','line_number':146,'multiline':False]['text':' Congrats you made it!','line_number':156,'multiline':False]['text':'*
   * Process an individual NestedTensor to reshape and view as a DenseTensor
   * Generally the approach for q, k, v is to
   * (1) get the storage of the contiguous nested tensor
   * (2) view as shape {output_batch_size, {*}_t.size(1), output_num_heads,
   * head_dim_{*}}, and stride {0, nnz_{*}_stride, head_{*}_stride,
   * head_dim_stride} where head_{*}_stride is 0 if
   * {*}_num_heads_needs_broadcast (3) collapse the first two dims by reshaping
   * to {Nnz_{*}, output_num_heads, head_dim_{*}} if {*}_t.size(1) (i.e. the
   * seq_len is 1), the reshape should be a view and should not incur a copy
   *  dense tensor without getting the storage
   ','line_number':160,'multiline':True]['text':'*
   * This function is a helper that takes nested query, key, and value
   * that require broadcasting on the batch or num_head dimensions
   * and will preprocess it in order to run with either
   * the flash-attention or efficient-attention kernels.
   * @return A tuple containing all the necessary data for running the fused
   * kernels
   ','line_number':204,'multiline':True]['text':' Query (Batch x Num_heads x {Q_seq_len}  x Dim_per_head)','line_number':214,'multiline':False]['text':' Key   (Batch x Num_heads x {KV_seq_len} x Dim_per_head)','line_number':215,'multiline':False]['text':' Value (Batch x Num_heads x {KV_seq_len} x Dim_per_head)','line_number':216,'multiline':False]['text':' Checks in sdp_utils ensure that if {*}_batch_size/{*}_num_heads !=','line_number':238,'multiline':False]['text':' output_batch_size/num_heads then they are 1','line_number':239,'multiline':False]['text':' If {*}_batch_size_needs_broadcast, then','line_number':244,'multiline':False]['text':' (1) max_seqlen_batch_{*} is given by {*}_t.size(1)','line_number':245,'multiline':False]['text':'     this is because needs_broadcast indicates that the batch_size is 1','line_number':246,'multiline':False]['text':'     and hence there is only 1 value for seq_len','line_number':247,'multiline':False]['text':' (2) The cum_seq_lens are given by [0, {*}_t.size(1), 2 * {*}_t.size(1),','line_number':248,'multiline':False]['text':' ..., outut_batch_size * {*}_t.size(1)] (3) Nnz_{*} is given by','line_number':249,'multiline':False]['text':' output_batch_size * {*}_t.size(1);','line_number':250,'multiline':False]['text':' If we are broadcasting then Nnz_q will be the output_batch_size since','line_number':310,'multiline':False]['text':' seq_len is 1','line_number':311,'multiline':False]['text':' If the physical layout of the NestedTensor's storage','line_number':326,'multiline':False]['text':' is not: batch, {seq_len}, num_heads, head_dim then we need','line_number':327,'multiline':False]['text':' to call contiguous','line_number':328,'multiline':False]['text':' namespace','line_number':384,'multiline':False]['text':' Query (Batch x Num_heads x {Q_seq_len}  x Dim_per_head)','line_number':391,'multiline':False]['text':' Key   (Batch x Num_heads x {KV_seq_len} x Dim_per_head)','line_number':392,'multiline':False]['text':' Value (Batch x Num_heads x {KV_seq_len} x Dim_per_head)','line_number':393,'multiline':False]['text':' [TODO] K and V have to have the same Nnz, should probably torch_check','line_number':418,'multiline':False]['text':' assume in order to not iterate over v','line_number':419,'multiline':False]['text':' If the physical layout of the NestedTensor's storage','line_number':442,'multiline':False]['text':' is not: batch, {seq_len}, num_heads, head_dim then we need','line_number':443,'multiline':False]['text':' to call contiguous','line_number':444,'multiline':False]['text':' If the physical layout of the NestedTensor's storage','line_number':525,'multiline':False]['text':' is not: batch, {seq_len}, num_heads, head_dim then we need','line_number':526,'multiline':False]['text':' to call contiguous','line_number':527,'multiline':False]['text':' namespace preprocessing','line_number':565,'multiline':False]['text':' namespace native','line_number':566,'multiline':False]['text':' namespace at','line_number':567,'multiline':False]