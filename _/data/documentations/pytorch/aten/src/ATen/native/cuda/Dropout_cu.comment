['text':' philox generates 128 bits of randomness at a time. Kernel uses this explicitly by putting suitably transformed result into float4','line_number':32,'multiline':False]['text':' for all members of float4 to be consumed UNROLL has to be 4. Don't change!','line_number':33,'multiline':False]['text':' Note: VEC <= 4 (and in most real-world cases will be 4), so same logic applies.','line_number':34,'multiline':False]['text':' make sure we don't break assumption that we can't have > 4 elements / thread','line_number':53,'multiline':False]['text':' Helps align the total number of times curand_uniform4 is called by each thread for the same totalElements','line_number':67,'multiline':False]['text':' in the vec=2 and vec=4 cases.','line_number':68,'multiline':False]['text':' Note: Vectorized loads means we'll stride each thread by an additional VEC factor, as we'll load VEC elements at a time','line_number':74,'multiline':False]['text':' local storage','line_number':78,'multiline':False]['text':' We'll use this to actually cause vectorized loads later','line_number':80,'multiline':False]['text':'curand_uniform_double was pure evil anyway, not doing what it promises, and there's nothing for halfs, so generate float for everything','line_number':83,'multiline':False]['text':' Note: need a new set of random values per 4 elements -- we'll handle VEC elements in this thread, so need ceil(VEC / 4)','line_number':84,'multiline':False]['text':' sets of rand.','line_number':85,'multiline':False]['text':' sets up the last two values we generated last iteration to be used this iteration.','line_number':89,'multiline':False]['text':' Note: We explicitly check for is_contiguous() before launching the vectorized kernel','line_number':102,'multiline':False]['text':' and replace IndexToOffset call with linearIndex to allow vectorization of NHWC (or other)','line_number':103,'multiline':False]['text':' ordering.','line_number':104,'multiline':False]['text':' Single vectorized load','line_number':105,'multiline':False]['text':' Perform the actual computation','line_number':111,'multiline':False]['text':' Vectorized writes for both mask & result','line_number':117,'multiline':False]['text':'curand_uniform_double was pure evil anyway, not doing what it promises, and there's nothing for halfs, so generate float for everything','line_number':155,'multiline':False]['text':' Convert `linearIndex` into an offset of `a`','line_number':165,'multiline':False]['text':' Convert `linearIndex` into an offset of `b`','line_number':174,'multiline':False]['text':' get the vector size','line_number':204,'multiline':False]['text':' check that we'd have no remainders - prefer a smaller vector size with no remainders over a larger vector and remainder.','line_number':211,'multiline':False]['text':' ret and mask are collapsed to 1d','line_number':246,'multiline':False]['text':' contiguous tensor','line_number':247,'multiline':False]['text':'anonymous namespace','line_number':333,'multiline':False]['text':' empty tensors should not get here, but just in case, avoid FPE','line_number':340,'multiline':False]['text':' non-training shot-cut','line_number':341,'multiline':False]['text':'number of times random will be generated per thread, to offset philox counter in thc random state','line_number':350,'multiline':False]['text':' See Note [Acquire lock when using random generators]','line_number':354,'multiline':False]['text':' short-cut for train == false','line_number':370,'multiline':False]['text':' short-cut','line_number':374,'multiline':False]['text':' native_dropout_cuda is in derivatives.yaml, so we don't need to add data','line_number':376,'multiline':False]['text':' dependency from output to input for autograd','line_number':377,'multiline':False]['text':' TODO: _fused_dropout_cuda is to be removed, see PR #63937','line_number':388,'multiline':False]['text':' TODO: masked_scale_cuda is to be removed, see PR #63937','line_number':410,'multiline':False]['text':' namespace at::native','line_number':416,'multiline':False]