['text':' Copyright 2004-present Facebook. All Rights Reserved.','line_number':1,'multiline':False]['text':' This kernel is used by two TensorList types:','line_number':23,'multiline':False]['text':' 1. stack_serial_kernel uses at::ArrayRef<Tensor>','line_number':24,'multiline':False]['text':' 2. Static runtime calls this kernel directly (csrc/jit/runtime/static/ops.cpp) with','line_number':25,'multiline':False]['text':'    ProcessedNodeInputWrapper.','line_number':26,'multiline':False]['text':' When making changes, make sure that they are compatible with both types!','line_number':27,'multiline':False]['text':' Checks to see whether native stack can be invoked under these conditions:','line_number':63,'multiline':False]['text':' - result and input tensors are contiguous','line_number':64,'multiline':False]['text':' - only one thread is used','line_number':65,'multiline':False]['text':' - no type promotion has to occur','line_number':66,'multiline':False]['text':' - tensors dtype is Double or Float','line_number':67,'multiline':False]['text':' stack dimension should be in range [0,firstTensor.dim())','line_number':72,'multiline':False]['text':' dim == firstTensor.dim() is a valid input, but it is handled by default code path','line_number':73,'multiline':False]['text':' that uses unsqueeze','line_number':74,'multiline':False]['text':' Native stack doesn't apply any tensor is skipped.','line_number':76,'multiline':False]['text':' there should be no type promotion','line_number':78,'multiline':False]['text':' fast path only works for Double and Float','line_number':88,'multiline':False]['text':' check remainder of inputs','line_number':93,'multiline':False]['text':' every tensor must be contiguous','line_number':101,'multiline':False]['text':' tensor sizes and strides must be the same','line_number':102,'multiline':False]['text':' there should be no type promotion','line_number':103,'multiline':False]['text':' fast native stack should only be used when it is not worth using multiple threads','line_number':111,'multiline':False]['text':' or there is only one thread. Note that we aren't checking result.numel() here because','line_number':112,'multiline':False]['text':' it may not have been resized and we want to defer that cost till later.','line_number':113,'multiline':False]['text':' Inputs cannot alias the output tensor','line_number':124,'multiline':False]['text':' namespace at::native::detail','line_number':144,'multiline':False]