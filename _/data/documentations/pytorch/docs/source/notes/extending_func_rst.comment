['text':' Note that forward does not take ctx','line_number':80,'multiline':False]['text':' Any intermediates to be saved in backward must be returned as','line_number':88,'multiline':False]['text':' outputs.','line_number':89,'multiline':False]['text':' The desired output','line_number':91,'multiline':False]['text':' intermediate to save for backward','line_number':93,'multiline':False]['text':' intermediate to save for backward','line_number':95,'multiline':False]['text':' setup_context is responsible for calling methods and/or assigning to','line_number':99,'multiline':False]['text':' the ctx object. Please do not do additional compute (e.g. add','line_number':100,'multiline':False]['text':' Tensors together) in setup_context.','line_number':101,'multiline':False]['text':' Note that output is whatever you returned from forward.','line_number':105,'multiline':False]['text':' If you returned multiple values, then output is a Tuple of multiple values.','line_number':106,'multiline':False]['text':' If you returned a single Tensor, then output is a Tensor.','line_number':107,'multiline':False]['text':' If you returned a Tuple with a single Tensor, then output is a','line_number':108,'multiline':False]['text':' Tuple with a single Tensor.','line_number':109,'multiline':False]['text':' Tensors must be saved via ctx.save_for_backward. Please do not','line_number':112,'multiline':False]['text':' assign them directly onto the ctx object.','line_number':113,'multiline':False]['text':' Non-tensors may be saved by assigning them as attributes on the ctx object.','line_number':115,'multiline':False]['text':' For the autograd.Function to be arbitrarily composable with function','line_number':120,'multiline':False]['text':' transforms, all staticmethod other than forward and setup_context','line_number':121,'multiline':False]['text':' must be implemented in a "transformable" way; that is, they must','line_number':122,'multiline':False]['text':' only consist of PyTorch operations or autograd.Function.','line_number':123,'multiline':False]['text':'','line_number':124,'multiline':False]['text':' For example, this allows us to do double backwards and/or compute','line_number':125,'multiline':False]['text':' second order gradients.','line_number':126,'multiline':False]['text':'','line_number':127,'multiline':False]['text':' We've written the backward pass of NumpySort in terms of another','line_number':128,'multiline':False]['text':' autograd.Function, NumpyTake.','line_number':129,'multiline':False]['text':' In regular PyTorch, if we had just run y = x ** 3, then the backward','line_number':193,'multiline':False]['text':' pass computes dx = 3 * x ** 2. In this autograd.Function, we've done','line_number':194,'multiline':False]['text':' that computation here in the forward pass instead.','line_number':195,'multiline':False]['text':' In order for the autograd.Function to work with higher-order','line_number':208,'multiline':False]['text':' gradients, we must add the gradient contribution of `dx`.','line_number':209,'multiline':False]['text':' Set generate_vmap_rule to True to ask PyTorch to automatically generate','line_number':284,'multiline':False]['text':' a vmap rule.','line_number':285,'multiline':False]['text':' The signature of the vmap staticmethod is:','line_number':392,'multiline':False]['text':' vmap(info, in_dims: Tuple[Optional[int]], *args)','line_number':393,'multiline':False]['text':' where *args is the same as the arguments to `forward`.','line_number':394,'multiline':False]['text':' For every input (x and dim), in_dims stores an Optional[int]','line_number':397,'multiline':False]['text':' that is:','line_number':398,'multiline':False]['text':' - None if the input is not being vmapped over or if the input','line_number':399,'multiline':False]['text':'   is not a Tensor','line_number':400,'multiline':False]['text':' - an integer if the input is being vmapped over that represents','line_number':401,'multiline':False]['text':'   the index of the dimension being vmapped over.','line_number':402,'multiline':False]['text':' A "vmap rule" is the logic of how to perform the operation given','line_number':405,'multiline':False]['text':' inputs with one additional dimension. In NumpySort, x has an','line_number':406,'multiline':False]['text':' additional dimension (x_bdim). The vmap rule is simply','line_number':407,'multiline':False]['text':' to call NumpySort again but pass it a different `dim`.','line_number':408,'multiline':False]['text':' Handle negative dims correctly','line_number':410,'multiline':False]['text':' The vmap rule must return a tuple of two things','line_number':414,'multiline':False]['text':' 1. the output. Should be the same amount of things','line_number':415,'multiline':False]['text':'    as returned by the forward().','line_number':416,'multiline':False]['text':' 2. one Optional[int] for each output specifying if each output','line_number':417,'multiline':False]['text':' is being vmapped over, and if so, the index of the','line_number':418,'multiline':False]['text':' dimension being vmapped over.','line_number':419,'multiline':False]['text':'','line_number':420,'multiline':False]['text':' NumpySort.forward returns a Tuple of 3 Tensors. Since we moved the','line_number':421,'multiline':False]['text':' dimension being vmapped over to the front of `x`, that appears at','line_number':422,'multiline':False]['text':' dimension 0 of all outputs.','line_number':423,'multiline':False]['text':' The return is (output, out_dims) -- output is a tuple of 3 Tensors','line_number':424,'multiline':False]['text':' and out_dims is a Tuple of 3 Optional[int]','line_number':425,'multiline':False]['text':' The strategy is: expand {x, ind, ind_inv} to all have the dimension','line_number':452,'multiline':False]['text':' being vmapped over.','line_number':453,'multiline':False]['text':' Then, call back into NumpyTake(expanded_x, expanded_ind, expanded_ind_inv, new_dim).','line_number':454,'multiline':False]['text':' Handle negative dims by wrapping them to be positive','line_number':456,'multiline':False]['text':' If the Tensor doesn't have the dimension being vmapped over,','line_number':465,'multiline':False]['text':' expand it out. Otherwise, move it to the front of the Tensor','line_number':466,'multiline':False]['text':' The return is a tuple (output, out_dims). Since output is a Tensor,','line_number':471,'multiline':False]['text':' then out_dims is an Optional[int] (instead of being a Tuple).','line_number':472,'multiline':False]