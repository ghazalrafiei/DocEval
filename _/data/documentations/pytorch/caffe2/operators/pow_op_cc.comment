['text':' definition of NumericTypes and SameTypeAsInput is in below header file','line_number':4,'multiline':False]['text':'#include "caffe2/operators/elementwise_op.h"','line_number':5,'multiline':False]['text':'
    //below code only allows elementary ops, such as +, -, * and /,
    //and does not allow operations, such as pow, exp and log
    EIGEN_POW(
       (ConstEigenArrayMap<T>(a, n, pre).colwise()),
       (ConstEigenVectorArrayMap<T>(b, n)));
     ','line_number':55,'multiline':True]['text':'
      //below code only allows elementary ops, such as +, -, * and /,
      //and does not allow for operations, such as pow, exp and log
      EIEGN_POW(
        (ConstEigenArrayMap<T>(a + i * n * post, post, n).rowwise()),
        (Eigen::Map<const Eigen::Array<T, 1, Eigen::Dynamic>>(b, n)));
      ','line_number':78,'multiline':True]['text':'NumericTypes','line_number':92,'multiline':True]['text':'github.com/pytorch/pytorch/blob/main/caffe2/operators/pow_op.h','line_number':107,'multiline':False]['text':'github.com/pytorch/pytorch/blob/main/caffe2/operators/pow_op.cc','line_number':108,'multiline':False]['text':' second input is a scalar','line_number':164,'multiline':False]['text':' function f(w,a) = w^a','line_number':165,'multiline':False]['text':' gradient operator with respect to first input tensor','line_number':166,'multiline':False]['text':' df/dw = a * w^(a-1) (all operations are component-wise)','line_number':167,'multiline':False]['text':'
      // Alternative gradient computation
      return vector<OperatorDef>{CreateOperatorDef(
                                     "Div",
                                     "",
                                     std::vector<string>{O(0), I(0)},
                                     std::vector<string>{GI(0)}),
                                 CreateOperatorDef(
                                     "Mul",
                                     "",
                                     std::vector<string>{GI(0), GO(0)},
                                     std::vector<string>{GI(0)}),
                                 CreateOperatorDef(
                                     "Scale",
                                     "",
                                     std::vector<string>{GI(0)},
                                     std::vector<string>{GI(0)},
                                     std::vector<Argument>{scale_arg})};
      ','line_number':199,'multiline':True]['text':' second input is a tensor','line_number':218,'multiline':False]['text':' function f(w,a) = w^a','line_number':255,'multiline':False]['text':' gradient operator with respect to first input tensor','line_number':256,'multiline':False]['text':' df/dw = a * w^(a-1) (all operations are component-wise)','line_number':257,'multiline':False]['text':'
      // Alternative gradient computation (no broadcast support)
      grad_ops.push_back(CreateOperatorDef(
                           "Div",
                           "",
                           std::vector<string>{O(0), I(0)},
                           std::vector<string>{GI(0)}));
      grad_ops.push_back(CreateOperatorDef(
                           "Mul",
                           "",
                           std::vector<string>{GI(0), GO(0)},
                           std::vector<string>{GI(0)}));
      grad_ops.push_back(CreateOperatorDef(
                           "Mul",
                           "",
                           std::vector<string>{GI(0), I(1)},
                           std::vector<string>{GI(0)}));
      ','line_number':303,'multiline':True]['text':' gradient operator for with respect to second input tensor','line_number':321,'multiline':False]['text':' df/da =  w^a * ln w (all operations are component-wise)','line_number':322,'multiline':False]['text':'
      // reset GI(1) to zero
      Argument zero_arg;
      zero_arg.set_name("value");
      zero_arg.set_f(0);
      grad_ops.push_back(CreateOperatorDef(
          "ConstantFill",
          "",
          std::vector<string>{I(1)},
          std::vector<string>{GI(1)},
          std::vector<Argument>{zero_arg}));
      ','line_number':323,'multiline':True]['text':' Argument `shape` is no longer needed in backprop.','line_number':369,'multiline':False]['text':' namespace caffe2','line_number':377,'multiline':False]