['text':'*
 * Special execution for CUDA. It tries to run ops with as little overhead as
 * possible, but to identify opportunities to run ops with "frontier execution"
 * parallelism, i.e by starting kernel from next timestep in parallel with
 * the current timestep. This is done by assigning streams.
 ','line_number':32,'multiline':True]['text':' Loop over timesteps','line_number':51,'multiline':False]['text':' Special handling for link ops -- we just run them directly','line_number':62,'multiline':False]['text':' they do not execute any kernels.','line_number':63,'multiline':False]['text':' If have recurrent parents, add for event waits so that those','line_number':83,'multiline':False]['text':' parents complete their work.','line_number':84,'multiline':False]['text':' Run the op in the given stream','line_number':99,'multiline':False]['text':' Create and record event for this op, if it has at least one','line_number':102,'multiline':False]['text':' recurrent dependency.','line_number':103,'multiline':False]['text':' Create event for recurrent connections','line_number':108,'multiline':False]['text':' for over ops','line_number':119,'multiline':False]['text':' Next timestep will run on different stream','line_number':121,'multiline':False]['text':' for over timesteps','line_number':125,'multiline':False]['text':'*
   * Wait for all the started streams to complete.
   ','line_number':127,'multiline':True]