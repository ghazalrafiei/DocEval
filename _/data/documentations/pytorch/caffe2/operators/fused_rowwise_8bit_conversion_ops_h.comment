['text':' Type for Scale and Bias','line_number':25,'multiline':False]['text':' The "fused" representation stores the scale and bias with the row-wise','line_number':41,'multiline':False]['text':' quantized data in one tensor. Since we quantize with 8 bits (1 byte) and','line_number':42,'multiline':False]['text':' represent the scale and bias with 32-bit floats, we'll use the last 8','line_number':43,'multiline':False]['text':' bytes of each row for scale (4 bytes) and bias (4 bytes).','line_number':44,'multiline':False]['text':' | ... int8 data ... | scale       | bias       |','line_number':45,'multiline':False]['text':' | number_of_columns |  sizeof(Tsb)| sizeof(Tsb)|','line_number':46,'multiline':False]['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':83,'multiline':False]['text':' The last 2*sizeof(Tsb) bytes per row are the scale and the bias.','line_number':126,'multiline':False]['text':' The rest of input_columns is the number of values in the original row.','line_number':127,'multiline':False]['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':162,'multiline':False]['text':' namespace caffe2','line_number':189,'multiline':False]['text':' CAFFE2_OPERATORS_FUSED_ROWWISE_8BIT_CONVERSION_OPS_H_','line_number':191,'multiline':False]