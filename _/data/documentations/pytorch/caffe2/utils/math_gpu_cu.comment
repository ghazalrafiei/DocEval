['text':' Implements the math functions for GPU.','line_number':1,'multiline':False]['text':' TODO: Move this to fixed_divisor.h','line_number':23,'multiline':False]['text':' USE_ROCM','line_number':34,'multiline':False]['text':' USE_ROCM','line_number':39,'multiline':False]['text':' until we use hipblas v2','line_number':44,'multiline':False]['text':' hipify correctly maps things like CUDA_R_16F to HIP_R_16F,','line_number':45,'multiline':False]['text':' however hipblas v1 is still using its custom type','line_number':46,'multiline':False]['text':' USE_ROCM','line_number':49,'multiline':False]['text':' USE_ROCM','line_number':51,'multiline':False]['text':' THRUST_VERSION >= 100800','line_number':57,'multiline':False]['text':' namespace','line_number':318,'multiline':False]['text':' Caffe2 gemm provides a simpler interface to the gemm functions, with the','line_number':548,'multiline':False]['text':' limitation that the data has to be contiguous in memory.','line_number':549,'multiline':False]['text':' Note that cublas follows fortran order, so the order is different from','line_number':564,'multiline':False]['text':' the cblas convention.','line_number':565,'multiline':False]['text':' Note that cublas follows fortran order, so the order is different from','line_number':605,'multiline':False]['text':' the cblas convention.','line_number':606,'multiline':False]['text':' hipblas doesn't support hipblasSgemmEx type API.','line_number':617,'multiline':False]['text':' It has more general hipblasGemmEx API which is more close to cublasGemmEx.','line_number':618,'multiline':False]['text':' hipblasGemmEx does D = alpha*op( A )*op( B ) + beta*C,','line_number':619,'multiline':False]['text':' whereas cublasSgemmEx does C = alpha*op( A )*op( B ) + beta*C','line_number':620,'multiline':False]['text':' compute type','line_number':639,'multiline':False]['text':' USE_ROCM','line_number':660,'multiline':False]['text':' convert alpha, beta from float -> __half','line_number':662,'multiline':False]['text':' call cublasHgemm','line_number':665,'multiline':False]['text':' fail','line_number':684,'multiline':False]['text':' loop over matrices in the batch','line_number':727,'multiline':False]['text':' Note that cublas follows fortran order, so the order is different from','line_number':744,'multiline':False]['text':' the cblas convention.','line_number':745,'multiline':False]['text':' Note that cublas follows fortran order, so the order is different from','line_number':795,'multiline':False]['text':' the cblas convention.','line_number':796,'multiline':False]['text':' Note that cublas follows fortran order, so the order is different from','line_number':842,'multiline':False]['text':' the cblas convention.','line_number':843,'multiline':False]['text':' Convert alpha, beta from float -> __half','line_number':879,'multiline':False]['text':' Note that cublas follows fortran order, so the order is different from','line_number':936,'multiline':False]['text':' the cblas convention.','line_number':937,'multiline':False]['text':' Convert alpha, beta from float -> __half','line_number':973,'multiline':False]['text':' sort out what we need to call cublasSgemmEx / cublasHgemm','line_number':1048,'multiline':False]['text':' hipblas doesn't support hipblasSgemmEx type API.','line_number':1058,'multiline':False]['text':' It has more general hipblasGemmEx API which is more close to cublasGemmEx.','line_number':1059,'multiline':False]['text':' hipblasGemmEx does D = alpha*op( A )*op( B ) + beta*C,','line_number':1060,'multiline':False]['text':' whereas cublasSgemmEx does C = alpha*op( A )*op( B ) + beta*C','line_number':1061,'multiline':False]['text':' compute type','line_number':1080,'multiline':False]['text':' USE_ROCM','line_number':1101,'multiline':False]['text':' fail','line_number':1123,'multiline':False]['text':' No change, but required. Defer to default CUDA engine','line_number':1130,'multiline':False]['text':' Note that cublas follows fortran order, so the order is different from','line_number':1163,'multiline':False]['text':' the cblas convention.','line_number':1164,'multiline':False]['text':' enable TensorCore for this call on this handle','line_number':1172,'multiline':False]['text':' Now disable TensorCore math for subsequent calls to this handle','line_number':1201,'multiline':False]['text':' Note that cublas follows fortran order, so the order is different from','line_number':1396,'multiline':False]['text':' the cblas convention.','line_number':1397,'multiline':False]['text':' Batched Add variants','line_number':1421,'multiline':False]['text':' namespace','line_number':1440,'multiline':False]['text':' namespace','line_number':1481,'multiline':False]['text':' If n is odd, we add a random Gaussian value at the end manually','line_number':1558,'multiline':False]['text':' and generate n-1 random values using curandGenerateNormal.','line_number':1559,'multiline':False]['text':' curandGenerateNormal requires n to be even.','line_number':1560,'multiline':False]['text':' execute with 32-bit math','line_number':1599,'multiline':False]['text':' A previous version of caffe2 used Thrust but it turns out that thrust','line_number':1616,'multiline':False]['text':' reduction has an implicit scratch space allocation and deallocation, which','line_number':1617,'multiline':False]['text':' may interfere with NCCL and create a deadlock. Hence we are using a custom','line_number':1618,'multiline':False]['text':' reduction here.','line_number':1619,'multiline':False]['text':' A multilevel reduction.','line_number':1628,'multiline':False]['text':' N -> 128','line_number':1629,'multiline':False]['text':' 128 -> 32','line_number':1641,'multiline':False]['text':' 32 -> 1','line_number':1647,'multiline':False]['text':' According to the benchmarks script','line_number':1657,'multiline':False]['text':' caffe2/caffe2/experiments/python/device_reduce_sum_bench.py,','line_number':1658,'multiline':False]['text':' device reduce is slower for N <= 10000.','line_number':1659,'multiline':False]['text':' allocate one more T at the end of scratch for dest','line_number':1682,'multiline':False]['text':' namespace','line_number':1696,'multiline':False]['text':' namespace','line_number':1737,'multiline':False]['text':'  namespace','line_number':1772,'multiline':False]['text':' namespace','line_number':1834,'multiline':False]['text':' compute the start and end of the output','line_number':2002,'multiline':False]['text':' compute the start and end of the output','line_number':2056,'multiline':False]['text':' namespace','line_number':2237,'multiline':False]['text':' groups ','line_number':2257,'multiline':True]['text':' groups ','line_number':2353,'multiline':True]['text':' In NCHW, the number of groups doesn't affect Col2Im.','line_number':2354,'multiline':False]['text':' groups ','line_number':2446,'multiline':True]['text':' In NCHW, the number of groups doesn't affect Im2Col.','line_number':2447,'multiline':False]['text':' groups ','line_number':2497,'multiline':True]['text':' In NCHW, the number of groups doesn't affect Col2Im.','line_number':2498,'multiline':False]['text':' namespace','line_number':2669,'multiline':False]['text':' namespace','line_number':2708,'multiline':False]['text':' namespace','line_number':2788,'multiline':False]['text':' namespace','line_number':2838,'multiline':False]['text':' namespace math','line_number':2858,'multiline':False]['text':' namespace caffe2','line_number':2859,'multiline':False]