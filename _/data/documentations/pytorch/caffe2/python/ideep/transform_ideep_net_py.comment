['text':' Can't fuse if more than one user','line_number':69,'multiline':False]['text':' else, can fuse','line_number':72,'multiline':False]['text':' Fix fused_conv to ensure we have a bias passed.','line_number':78,'multiline':False]['text':' First, BN computation can be phrased as follows:','line_number':96,'multiline':False]['text':' (X - running_mean) * (1.0 / sqrt(running_var + eps)) *','line_number':97,'multiline':False]['text':' bn_scale + bias','line_number':98,'multiline':False]['text':' Thus, we can rewrite bn_scale as:','line_number':99,'multiline':False]['text':' X * bn_scale * 1.0 / (sqrt(running_var + eps)) + (bias -','line_number':100,'multiline':False]['text':' running_mean * (1.0 / sqrt(running_var + eps)) * bn_scale)','line_number':101,'multiline':False]['text':' Thus, can just have the affine transform','line_number':102,'multiline':False]['text':' X * A + B','line_number':103,'multiline':False]['text':' where','line_number':104,'multiline':False]['text':' A = bn_scale * 1.0 / (sqrt(running_var + eps))','line_number':105,'multiline':False]['text':' B =  (bias - running_mean * (1.0 / sqrt(running_var + eps))','line_number':106,'multiline':False]['text':' * bn_scale)','line_number':107,'multiline':False]['text':' This identify should hold if we have correctly fused','line_number':115,'multiline':False]['text':' np.testing.assert_array_equal(','line_number':116,'multiline':False]['text':'     params[conv.output[0]] * A + B,','line_number':117,'multiline':False]['text':'     params[bn.output[0]])','line_number':118,'multiline':False]['text':' Now, we have that the computation made is the following:','line_number':120,'multiline':False]['text':' ((X `conv` W) + b) * A + B','line_number':121,'multiline':False]['text':' Then, we can simply fuse this as follows:','line_number':122,'multiline':False]['text':' (X `conv` (W * A)) + b * A + B','line_number':123,'multiline':False]['text':' which is simply','line_number':124,'multiline':False]['text':' (X `conv` Q) + C','line_number':125,'multiline':False]['text':' where','line_number':126,'multiline':False]['text':' Q = W * A','line_number':128,'multiline':False]['text':' C = b * A + B','line_number':129,'multiline':False]['text':' For ConvTranspose, from the view of convolutions as a','line_number':131,'multiline':False]['text':' Toepeliz multiplication, we have W_ = W^T, so the weights','line_number':132,'multiline':False]['text':' are laid out as (R, S, K, K) (vs (S, R, K, K) for a Conv),','line_number':133,'multiline':False]['text':' so the weights broadcast slightly differently. Remember, our','line_number':134,'multiline':False]['text':' BN scale 'B' is of size (S,)','line_number':135,'multiline':False]['text':' Run until we hit a fixed point','line_number':161,'multiline':False]['text':' Run until we hit a fixed point','line_number':223,'multiline':False]['text':' pass array of uint8 as a string to save storage','line_number':247,'multiline':False]['text':' storing uint8_t has a large overhead for now','line_number':248,'multiline':False]