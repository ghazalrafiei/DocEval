['text':' Note we explicitly cast variables to np.float32 in a couple of places to avoid','line_number':6,'multiline':False]['text':' the default casting in Python often resuling in double precision and to make','line_number':7,'multiline':False]['text':' sure we're doing the same numerics as C++ code.','line_number':8,'multiline':False]['text':' [(left, right, loss)] # local optima solution','line_number':15,'multiline':False]['text':' move left','line_number':20,'multiline':False]['text':' move right','line_number':24,'multiline':False]['text':' found a local optima','line_number':30,'multiline':False]['text':' affine transform to put Xq in [0,2**bit_rate - 1]','line_number':46,'multiline':False]['text':' Xq = (2 ** bit_rate - 1) * (Xq - xmin) / data_range','line_number':47,'multiline':False]['text':' Manually compute loss instead of using np.linalg.norm to use the same','line_number':60,'multiline':False]['text':' accumulation order used by C++ code','line_number':61,'multiline':False]