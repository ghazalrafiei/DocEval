['text':' TODO(jiayq): make them hypothesis tests for better coverage.','line_number':19,'multiline':False]['text':' Set broadcast and no axis, i.e. broadcasting last dimensions.','line_number':35,'multiline':False]['text':' broadcasting intermediate dimensions','line_number':41,'multiline':False]['text':' broadcasting the first dimension','line_number':47,'multiline':False]['text':' broadcasting with single elem dimensions at both ends','line_number':53,'multiline':False]['text':'operator','line_number':106,'multiline':False]['text':'two gradients Y*X^(Y-1) and X^Y * ln(X)','line_number':110,'multiline':False]['text':'1. Set broadcast and no axis, i.e. broadcasting last dimensions.','line_number':116,'multiline':False]['text':'two gradients Y*X^(Y-1) and X^Y * ln(X)','line_number':120,'multiline':False]['text':'latter gradient is summed over 1 and 0 dims to account for broadcast','line_number':121,'multiline':False]['text':'2. broadcasting intermediate dimensions','line_number':134,'multiline':False]['text':'pow op with the latter array increased by one dim','line_number':138,'multiline':False]['text':'two gradients Y*X^(Y-1) and X^Y * ln(X)','line_number':142,'multiline':False]['text':'latter gradient is summed over 3 and 0 dims to account for broadcast','line_number':143,'multiline':False]['text':'3. broadcasting the first dimension','line_number':157,'multiline':False]['text':'pow op with the latter array increased by one dim','line_number':161,'multiline':False]['text':'two gradients Y*X^(Y-1) and X^Y * ln(X)','line_number':165,'multiline':False]['text':'latter gradient is summed over 3, 2 and 1 dims to account for broadcast','line_number':166,'multiline':False]['text':'4. broadcasting with single elem dimensions at both ends','line_number':182,'multiline':False]['text':'pow op with the latter array increased by one dim','line_number':186,'multiline':False]['text':'two gradients Y*X^(Y-1) and X^Y * ln(X)','line_number':190,'multiline':False]['text':'latter gradient is summed over 0 and 1 dims to account for broadcast','line_number':191,'multiline':False]['text':' broadcasting constant','line_number':208,'multiline':False]['text':' broadcasting scalar','line_number':222,'multiline':False]['text':' NCHW as default','line_number':238,'multiline':False]['text':' NHWC','line_number':252,'multiline':False]['text':' Set broadcast and no axis, i.e. broadcasting last dimensions.','line_number':277,'multiline':False]['text':' Set broadcast and no axis, i.e. broadcasting last dimensions.','line_number':291,'multiline':False]['text':' broadcasting intermediate dimensions','line_number':305,'multiline':False]['text':' broadcasting intermediate dimensions','line_number':319,'multiline':False]['text':' broadcasting with single elem dimensions at both ends','line_number':331,'multiline':False]['text':' fp64 is not supported with the CUDA op','line_number':345,'multiline':False]['text':' Set broadcast and no axis, i.e. broadcasting last dimensions.','line_number':354,'multiline':False]['text':' Set broadcast and no axis, i.e. broadcasting last dimensions.','line_number':372,'multiline':False]['text':' broadcasting intermediate dimensions','line_number':390,'multiline':False]['text':' broadcasting with single elem dimensions at both ends','line_number':408,'multiline':False]