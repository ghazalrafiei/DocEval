['text':' Retrieve buffer size','line_number':20,'multiline':False]['text':' Allocate temporary storage','line_number':29,'multiline':False]['text':' Run inclusive prefix sum','line_number':34,'multiline':False]['text':' Retrieve buffer size','line_number':54,'multiline':False]['text':' Allocate temporary storage','line_number':69,'multiline':False]['text':' prefix of lengths','line_number':112,'multiline':False]['text':' (offsets for the','line_number':113,'multiline':False]['text':' segments)','line_number':114,'multiline':False]['text':' number of rows (hash size) of embedding table','line_number':115,'multiline':False]['text':' embedding dimension size','line_number':116,'multiline':False]['text':' num_lengths blocks, each block process one segment','line_number':125,'multiline':False]['text':' the group-th segment','line_number':126,'multiline':False]['text':' start offset of the segment','line_number':129,'multiline':False]['text':' end offset of the segment','line_number':130,'multiline':False]['text':' index for grad','line_number':135,'multiline':False]['text':' line: the idx in the indices','line_number':137,'multiline':False]['text':' threadIdx.x: index in the embedding dimension','line_number':138,'multiline':False]['text':' the index-th row in the embedding table','line_number':140,'multiline':False]['text':' index for param','line_number':142,'multiline':False]['text':' i: index in the embedding dimension','line_number':153,'multiline':False]['text':' index for grad','line_number':154,'multiline':False]['text':' line: the idx in the indices','line_number':156,'multiline':False]['text':' the index row in the embedding table','line_number':158,'multiline':False]['text':' index for param','line_number':159,'multiline':False]['text':' number of rows (hash size) of embedding table','line_number':179,'multiline':False]['text':' embedding dimension size','line_number':180,'multiline':False]['text':' num_lengths blocks, each block process one segment','line_number':191,'multiline':False]['text':' the group-th segment','line_number':192,'multiline':False]['text':' start offset of the segment','line_number':195,'multiline':False]['text':' end offset of the segment','line_number':196,'multiline':False]['text':' TODO: Tuning NumThreads for w_grad','line_number':200,'multiline':False]['text':' TODO(jianyuhuang): parallelize this outer loop','line_number':204,'multiline':False]['text':' line: the idx in the indices','line_number':207,'multiline':False]['text':' the index-th row in the embedding table','line_number':209,'multiline':False]['text':' SparseAdagradFusedWithSparseLengthsWeightedSumGradientOp also fuses','line_number':211,'multiline':False]['text':' LengthsRangeFill + Gather operator. In the normal SLWS operator weight','line_number':212,'multiline':False]['text':' is accessed via weights[line] but in most cases the weights are','line_number':213,'multiline':False]['text':' generated by LengthsRangeFill and Gather operator.','line_number':214,'multiline':False]['text':' For example, if lengths is [2, 3, 1] LengthsRangeFill will generate [0,','line_number':215,'multiline':False]['text':' 1; 0, 1, 2; 0] and they are used as indices of Gather.','line_number':216,'multiline':False]['text':' So if we fuse all of these, weights[line] just becomes','line_number':217,'multiline':False]['text':' weights[line - start].','line_number':218,'multiline':False]['text':' i: index in the embedding dimension','line_number':222,'multiline':False]['text':' index for in_grad','line_number':223,'multiline':False]['text':' index for param','line_number':224,'multiline':False]['text':' TODO: trying to reduce the variable number (common subexpression','line_number':226,'multiline':False]['text':' elimination).','line_number':227,'multiline':False]['text':' TODO: split it into two kernels to make it more similar to exact','line_number':234,'multiline':False]['text':' fusion kernel (not Approx on CPUs).','line_number':235,'multiline':False]['text':' Construct a reverse map of offset_of_idx -> segment_id.','line_number':252,'multiline':False]['text':' prefix of lengths','line_number':258,'multiline':False]['text':' segment id','line_number':259,'multiline':False]['text':' num_lengths blocks, each block process one segment','line_number':261,'multiline':False]['text':' the group-th segment','line_number':262,'multiline':False]['text':' start offset of the segment','line_number':265,'multiline':False]['text':' end offset of the segment','line_number':266,'multiline':False]['text':' line: the idx in the indices','line_number':269,'multiline':False]['text':' embedding dimension size','line_number':284,'multiline':False]['text':' number of indices','line_number':285,'multiline':False]['text':' sorted linear indices','line_number':290,'multiline':False]['text':' sorted segment id','line_number':291,'multiline':False]['text':' num_indices blocks, each block process one index','line_number':302,'multiline':False]['text':' the index of sorted_linear_ind','line_number':306,'multiline':False]['text':' the index of sorted_linear_ind','line_number':308,'multiline':False]['text':' don't have warp divergence when embedding dim is multiple of 32','line_number':311,'multiline':False]['text':' the index row in the embedding table','line_number':315,'multiline':False]['text':' check if this thread block is responsible for this whole linear index','line_number':318,'multiline':False]['text':' don't have warp divergence when embedding dim is multiple of 32','line_number':324,'multiline':False]['text':' find the num of duplicated indices.','line_number':329,'multiline':False]['text':' we need to avoid index collision for the threads in the same block.','line_number':352,'multiline':False]['text':' Different threadIdx.y works on different `index`.','line_number':353,'multiline':False]['text':' i: index in the embedding dimension','line_number':357,'multiline':False]['text':' We have a strong assumption that blockDim.x = 32, which is equal to the warp size.','line_number':371,'multiline':False]['text':' update param','line_number':376,'multiline':False]['text':' index for param','line_number':379,'multiline':False]['text':' find the num of duplicated indices.','line_number':384,'multiline':False]['text':' TODO: Tuning NumThreads for sum_squares','line_number':391,'multiline':False]['text':' i: index in the embedding dimension','line_number':401,'multiline':False]['text':' update param','line_number':422,'multiline':False]['text':' index for param','line_number':425,'multiline':False]['text':' prefix of lengths','line_number':438,'multiline':False]['text':' (offsets for the','line_number':439,'multiline':False]['text':' segments)','line_number':440,'multiline':False]['text':' number of rows (hash size) of embedding table','line_number':441,'multiline':False]['text':' embedding dimension size','line_number':442,'multiline':False]['text':' num_lengths blocks, each block process one segment','line_number':453,'multiline':False]['text':' the group-th segment','line_number':454,'multiline':False]['text':' start offset of the segment','line_number':457,'multiline':False]['text':' end offset of the segment','line_number':458,'multiline':False]['text':' TODO: Tuning NumThreads for w_grad','line_number':462,'multiline':False]['text':' for avg_square_weight. Can we reuse temp_storage','line_number':467,'multiline':False]['text':' TODO(jianyuhuang): parallelize this outer loop','line_number':470,'multiline':False]['text':' i: index in the embedding dimension','line_number':473,'multiline':False]['text':' update param','line_number':494,'multiline':False]['text':' index for in_grad','line_number':498,'multiline':False]['text':' index for param','line_number':499,'multiline':False]['text':' TODO: trying to reduce the variable number (common subexpression','line_number':500,'multiline':False]['text':' elimination).','line_number':501,'multiline':False]['text':' TODO: split it into two kernels to make it more similar to exact','line_number':507,'multiline':False]['text':' fusion kernel (not Approx on CPUs).','line_number':508,'multiline':False]['text':' namespace','line_number':520,'multiline':False]['text':' Enforce shapes','line_number':543,'multiline':False]['text':' Enforce:','line_number':573,'multiline':False]['text':' input(embedding/momentum) == outputs(embedding/momentum)','line_number':574,'multiline':False]['text':' return early to avoid invalid empty kernel','line_number':590,'multiline':False]['text':' compute output size using length','line_number':602,'multiline':False]['text':' calling cuda kernel with ExactBlock = true','line_number':637,'multiline':False]['text':' calling cuda kernel with ExactBlock = false','line_number':655,'multiline':False]['text':' member field to manage memory','line_number':677,'multiline':False]['text':' Enforce shapes','line_number':710,'multiline':False]['text':' Allocate output to an empty tensor','line_number':725,'multiline':False]['text':' Enforce:','line_number':744,'multiline':False]['text':' input(embedding/momentum) == outputs(embedding/momentum)','line_number':745,'multiline':False]['text':' return early to avoid invalid empty kernel','line_number':765,'multiline':False]['text':' compute output size using length','line_number':777,'multiline':False]['text':' member field to manage memory','line_number':875,'multiline':False]['text':' Enforce shapes','line_number':910,'multiline':False]['text':' Enforce:','line_number':939,'multiline':False]['text':' number of rows: input(embedding/momentum) ==','line_number':940,'multiline':False]['text':' outputs(embedding/momentum)','line_number':941,'multiline':False]['text':' return early to avoid invalid empty kernel','line_number':957,'multiline':False]['text':' compute output size using length','line_number':969,'multiline':False]['text':' 0: nearest rounding','line_number':1002,'multiline':False]['text':' 1: stochastic rounding','line_number':1003,'multiline':False]['text':' Fast path when the embedding dimension is a multiple of 32, using','line_number':1009,'multiline':False]['text':' WarpReduce.','line_number':1010,'multiline':False]['text':' member field to manage memory','line_number':1109,'multiline':False]['text':' Enforce shapes','line_number':1150,'multiline':False]['text':' Enforce:','line_number':1179,'multiline':False]['text':' number of rows: input(embedding/momentum) == outputs(embedding/momentum)','line_number':1180,'multiline':False]['text':' return early to avoid invalid empty kernel','line_number':1199,'multiline':False]['text':' compute output size using length','line_number':1211,'multiline':False]['text':' 0: nearest rounding','line_number':1264,'multiline':False]['text':' 1: stochastic rounding','line_number':1265,'multiline':False]['text':' Fast path when the embedding dimension is a multiple of 32, using','line_number':1272,'multiline':False]['text':' WarpReduce.','line_number':1273,'multiline':False]['text':' Maximum shared memory allocated per thread block is 48 KB on Maxwell/Pascal','line_number':1283,'multiline':False]['text':' Maximum shared memory allocated per thread block is 48 KB on Maxwell/Pascal','line_number':1338,'multiline':False]['text':' member field to manage memory','line_number':1396,'multiline':False]['text':' Enforce shapes','line_number':1436,'multiline':False]['text':' Enforce:','line_number':1468,'multiline':False]['text':' number of rows: input(embedding/momentum) ==','line_number':1469,'multiline':False]['text':' outputs(embedding/momentum)','line_number':1470,'multiline':False]['text':' return early to avoid invalid empty kernel','line_number':1490,'multiline':False]['text':' compute output size using length','line_number':1502,'multiline':False]['text':' member field to manage memory','line_number':1601,'multiline':False]['text':' For GPU, the implementation of the exact and approx (RowWise)SparseAdagrad','line_number':1612,'multiline':False]['text':' fusion are both approximate implementations.','line_number':1613,'multiline':False]['text':' When we don't have the duplicated indices, the outputs are the same as the','line_number':1614,'multiline':False]['text':' CPU implementation.','line_number':1615,'multiline':False]['text':' namespace caffe2','line_number':1698,'multiline':False]