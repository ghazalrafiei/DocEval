['text':' PyTorch containers are a special zip archive with the following layout','line_number':24,'multiline':False]['text':' archive_name.zip contains:','line_number':25,'multiline':False]['text':'    archive_name/','line_number':26,'multiline':False]['text':'        version # a file with a single decimal number written in ascii,','line_number':27,'multiline':False]['text':'                # used to establish the version of the archive format','line_number':28,'multiline':False]['text':'        model.json # overall model description, this is a json output of','line_number':29,'multiline':False]['text':'                   # ModelDef from torch.proto','line_number':30,'multiline':False]['text':'        # the following names are by convention only, model.json will','line_number':31,'multiline':False]['text':'        # refer to these files by full names','line_number':32,'multiline':False]['text':'        tensors/','line_number':33,'multiline':False]['text':'          0 # flat storage for tensor data, meta-data about shapes, etc. is','line_number':34,'multiline':False]['text':'            # in model.json','line_number':35,'multiline':False]['text':'          1','line_number':36,'multiline':False]['text':'          ...','line_number':37,'multiline':False]['text':'        # code entries will only exist for modules that have methods attached','line_number':38,'multiline':False]['text':'        code/','line_number':39,'multiline':False]['text':'          archive_name.py # serialized torch script code (python syntax, using','line_number':40,'multiline':False]['text':'          PythonPrint) archive_name_my_submodule.py # submodules have separate','line_number':41,'multiline':False]['text':'          files','line_number':42,'multiline':False]['text':'','line_number':43,'multiline':False]['text':' The PyTorchStreamWriter also ensures additional useful properties for these','line_number':44,'multiline':False]['text':' files','line_number':45,'multiline':False]['text':' 1. All files are stored uncompressed.','line_number':46,'multiline':False]['text':' 2. All files in the archive are aligned to 64 byte boundaries such that','line_number':47,'multiline':False]['text':'    it is possible to mmap the entire file and get an aligned pointer to','line_number':48,'multiline':False]['text':'    tensor data.','line_number':49,'multiline':False]['text':' 3. We universally write in ZIP64 format for consistency.','line_number':50,'multiline':False]['text':' The PyTorchStreamReader also provides additional properties:','line_number':52,'multiline':False]['text':' 1. It can read zip files that are created with common','line_number':53,'multiline':False]['text':'    zip tools. This means that even though our writer doesn't compress files,','line_number':54,'multiline':False]['text':'    the reader can still read files that were compressed.','line_number':55,'multiline':False]['text':' 2. It provides a getRecordOffset function which returns the offset into the','line_number':56,'multiline':False]['text':'    raw file where file data lives. If the file was written with','line_number':57,'multiline':False]['text':'    PyTorchStreamWriter it is guaranteed to be 64 byte aligned.','line_number':58,'multiline':False]['text':' PyTorchReader/Writer handle checking the version number on the archive format','line_number':60,'multiline':False]['text':' and ensure that all files are written to a archive_name directory so they','line_number':61,'multiline':False]['text':' unzip cleanly.','line_number':62,'multiline':False]['text':' When developing this format we want to pay particular attention to the','line_number':64,'multiline':False]['text':' following use cases:','line_number':65,'multiline':False]['text':'','line_number':66,'multiline':False]['text':' -- Reading --','line_number':67,'multiline':False]['text':' 1) Reading with full random access','line_number':68,'multiline':False]['text':'   a) Reading with file api's such as fread()','line_number':69,'multiline':False]['text':'   b) mmaping the file and jumping around the mapped region','line_number':70,'multiline':False]['text':' 2) Reading with 1-pass sequential access','line_number':71,'multiline':False]['text':'      -> A reader will need to build up a data structure of parsed structures','line_number':72,'multiline':False]['text':'         as it reads','line_number':73,'multiline':False]['text':'','line_number':74,'multiline':False]['text':' -- Writing --','line_number':75,'multiline':False]['text':' 1) Writing with full random access','line_number':76,'multiline':False]['text':' 2) Writing with 1-pass sequential access','line_number':77,'multiline':False]['text':'      -> We must take care not to require updating values that have already','line_number':78,'multiline':False]['text':'         been written. We place the variable-length index at the end and do','line_number':79,'multiline':False]['text':'         not put any indicies into the header to fulfill this constraint.','line_number':80,'multiline':False]['text':' The model.json, which contains all the metadata information,','line_number':82,'multiline':False]['text':' should be written as the last file. One reason is that the size of tensor','line_number':83,'multiline':False]['text':' data is usually stable. As long as the shape and type of the tensor do not','line_number':84,'multiline':False]['text':' change, the size of the data won't change. On the other sied, the size of the','line_number':85,'multiline':False]['text':' serialized model is likely to change, so we store it as the last record, and','line_number':86,'multiline':False]['text':' we don't need to move previous records when updating the model data.','line_number':87,'multiline':False]['text':' The zip format is sufficiently flexible to handle the above use-case.','line_number':89,'multiline':False]['text':' it puts its central directory at the end of the archive and we write','line_number':90,'multiline':False]['text':' model.json as the last file when writing after we have accumulated all','line_number':91,'multiline':False]['text':' other information.','line_number':92,'multiline':False]['text':' Read at most `chunkSize` into `buf`. Return the number of actual bytes read.','line_number':105,'multiline':False]['text':' return dataptr, size','line_number':128,'multiline':False]['text':' multi-thread getRecord','line_number':130,'multiline':False]['text':' inplace memory writing','line_number':132,'multiline':False]['text':' inplace memory writing, multi-threads.','line_number':134,'multiline':False]['text':' When additionalReaders is empty, the default behavior is call getRecord(name, dst, n) with default reader','line_number':135,'multiline':False]['text':' This approach can be used for reading large tensors.','line_number':136,'multiline':False]['text':' Concurrent reading records with multiple readers.','line_number':147,'multiline':False]['text':' additionalReaders are additional clients to access the underlying record at different offsets','line_number':148,'multiline':False]['text':' and write to different trunks of buffers.','line_number':149,'multiline':False]['text':' If the overall size of the tensor is 10, and size of additionalReader is 2.','line_number':150,'multiline':False]['text':' The default thread will read [0,4), the additional reader will read [4,8).','line_number':151,'multiline':False]['text':' The default reader will read [8,10).','line_number':152,'multiline':False]['text':' The default reader will write to buffer[0,4), the additional reader will write to buffer[4,8),','line_number':153,'multiline':False]['text':' the additional reader will write to buffer[8,10).','line_number':154,'multiline':False]['text':' When additionalReaders is empty, the default behavior is call getRecord(name) with default reader','line_number':155,'multiline':False]['text':' This approach can be used for reading large tensors.','line_number':156,'multiline':False]['text':' This number will be updated when the model has operators','line_number':251,'multiline':False]['text':' that have valid upgraders.','line_number':252,'multiline':False]['text':' Writer-specific constants','line_number':264,'multiline':False]['text':' Returns a record to be appended to the local user extra data entry in order','line_number':267,'multiline':False]['text':' to make data beginning aligned at kFieldAlignment bytes boundary.','line_number':268,'multiline':False]['text':' namespace detail','line_number':274,'multiline':False]['text':' namespace serialize','line_number':276,'multiline':False]['text':' namespace caffe2','line_number':277,'multiline':False]