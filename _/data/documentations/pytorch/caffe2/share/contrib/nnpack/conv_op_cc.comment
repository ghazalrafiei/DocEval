['text':'//////////////////////////////////////////////////////////////////////////////','line_number':27,'multiline':False]['text':' Definitions','line_number':28,'multiline':False]['text':'//////////////////////////////////////////////////////////////////////////////','line_number':29,'multiline':False]['text':' Modified after precomputing the kernels. State transitions are:','line_number':64,'multiline':False]['text':' - precompute -> (first call to Run()) -> reuse (on successful precompute)','line_number':65,'multiline':False]['text':'                                       -> compute (on failing precompute)','line_number':66,'multiline':False]['text':' - compute','line_number':67,'multiline':False]['text':' Per-group transformed filters','line_number':70,'multiline':False]['text':' Zero-filled bias for convolutions without bias','line_number':72,'multiline':False]['text':' This may be needed because NNPACK interface always expects conv with bias','line_number':73,'multiline':False]['text':'//////////////////////////////////////////////////////////////////////////////','line_number':77,'multiline':False]['text':' Implementations','line_number':78,'multiline':False]['text':'//////////////////////////////////////////////////////////////////////////////','line_number':79,'multiline':False]['text':' No preference is stated. Heuristics for the best mobile device','line_number':83,'multiline':False]['text':' algorithm are different than NNPACK's version, as Winograd','line_number':84,'multiline':False]['text':' tends to be a lot faster. Use Winograd if the convolution','line_number':85,'multiline':False]['text':' is 3x3d1s1.','line_number':86,'multiline':False]['text':' use Winograd','line_number':89,'multiline':False]['text':' Otherwise, there is a preference.','line_number':96,'multiline':False]['text':' Default to computing each time.','line_number':129,'multiline':False]['text':' Global variable with a unique ID of the pre-transformed kernel blob ','line_number':146,'multiline':True]['text':' Convolution with bias ','line_number':166,'multiline':True]['text':' NNPACK interface requires bias. Use a dummy zero-filled vector. ','line_number':172,'multiline':True]['text':' NOLINTNEXTLINE(clang-diagnostic-sign-compare)','line_number':173,'multiline':False]['text':' filter is MCHW','line_number':183,'multiline':False]['text':' pad is tblr','line_number':187,'multiline':False]['text':' input ','line_number':219,'multiline':True]['text':' filters ','line_number':220,'multiline':True]['text':' bias ','line_number':221,'multiline':True]['text':' output ','line_number':222,'multiline':True]['text':' workspace buffer = transformed filter ','line_number':223,'multiline':True]['text':' activation parameter ','line_number':226,'multiline':True]['text':' profile ','line_number':228,'multiline':True]['text':' For these convolution parameters filter transforms can be
         * pre-computed ','line_number':230,'multiline':True]['text':' Division with rounding up, in case size is not multiple of
         * sizeof(float) ','line_number':233,'multiline':True]['text':' input ','line_number':256,'multiline':True]['text':' bias ','line_number':258,'multiline':True]['text':' output ','line_number':259,'multiline':True]['text':' activation parameter ','line_number':264,'multiline':True]['text':' profile ','line_number':266,'multiline':True]['text':'
         * Now, we've precomputed all our filter transformations.
         * Switch to reuse strategy to avoid doing transformation again on next
         * iteration.
         ','line_number':272,'multiline':True]['text':' Enforce when we leave this block that we have transitioned out of the','line_number':288,'multiline':False]['text':' precompute state.','line_number':289,'multiline':False]['text':' NOLINTNEXTLINE(cppcoreguidelines-pro-type-member-init)','line_number':300,'multiline':False]['text':' Allocate some memory to ensure buffer pointer is not NULL. This
           * simplifies further logic. ','line_number':304,'multiline':True]['text':' activation parameter ','line_number':328,'multiline':True]['text':' Query required workspace size, increase buffer, and try again ','line_number':332,'multiline':True]['text':' input ','line_number':342,'multiline':True]['text':' bias ','line_number':344,'multiline':True]['text':' output ','line_number':345,'multiline':True]['text':' workspace buffer ','line_number':346,'multiline':True]['text':' activation parameter ','line_number':349,'multiline':True]['text':' profile ','line_number':351,'multiline':True]['text':' Division with rounding up, in case size is not multiple of
             * sizeof(float) ','line_number':353,'multiline':True]['text':' Try convolution_inference again. If this time it fails, it is
             * fatal. ','line_number':359,'multiline':True]['text':' activation parameter ','line_number':382,'multiline':True]['text':' NOLINTNEXTLINE(cppcoreguidelines-avoid-c-arrays,cppcoreguidelines-avoid-magic-numbers,modernize-avoid-c-arrays)','line_number':393,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-integer-division)','line_number':397,'multiline':False]['text':' NOLINTNEXTLINE(clang-analyzer-core.UndefinedBinaryOperatorResult)','line_number':401,'multiline':False]['text':' namespace caffe2','line_number':434,'multiline':False]