['text':' Note that input of trt tensor is in CHW format, while our tensor is NCHW','line_number':14,'multiline':False]['text':' \return -1 if there is dimension mismatch between C2 tensor and trt tensor.','line_number':15,'multiline':False]['text':' Otherwise, return the product of CHW dimensions','line_number':16,'multiline':False]['text':' namespace','line_number':45,'multiline':False]['text':' Upon construction, we build the inference engine by deserializing from','line_number':47,'multiline':False]['text':' protobuf string. And since we know the input/output blobs, we can do the','line_number':48,'multiline':False]['text':' binding here too.','line_number':49,'multiline':False]['text':' TODO(support trt plugin factory)','line_number':64,'multiline':False]['text':' Pull the weights from workspace and assembly it back to the onnx model,','line_number':75,'multiline':False]['text':' notice that since we may have rewritten the net, we need to map the','line_number':76,'multiline':False]['text':' weight names','line_number':77,'multiline':False]['text':' Build the trt engine','line_number':95,'multiline':False]['text':' match and bind the input/output','line_number':107,'multiline':False]['text':' For output, we try to get its output size hint','line_number':115,'multiline':False]['text':' We conform to the output shape hints. NB: We might need an explicit','line_number':148,'multiline':False]['text':' reshape op for this','line_number':149,'multiline':False]['text':' Decide input batch size','line_number':156,'multiline':False]['text':' We need to do the binding at RunOnDevice time because we only know the','line_number':176,'multiline':False]['text':' exact shapes of the tensors now. In addition, since TensorRT engine has','line_number':177,'multiline':False]['text':' max_batch_size, we need to call that multiple times if input batch size','line_number':178,'multiline':False]['text':' exceeeds this limit.','line_number':179,'multiline':False]['text':' input, check input dimensions','line_number':194,'multiline':False]['text':' output, we need to allocate the output tensor at first batch run','line_number':201,'multiline':False]['text':' namespace caffe2','line_number':254,'multiline':False]