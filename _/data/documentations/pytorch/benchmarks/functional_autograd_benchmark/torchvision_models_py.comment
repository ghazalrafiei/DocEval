['text':' Taken from https://github.com/pytorch/vision','line_number':1,'multiline':False]['text':' So that we don't need torchvision to be installed','line_number':2,'multiline':False]['text':' Both self.conv1 and self.downsample layers downsample the input when stride != 1','line_number':59,'multiline':False]['text':' Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)','line_number':88,'multiline':False]['text':' while original implementation places the stride at the first 1x1 convolution(self.conv1)','line_number':89,'multiline':False]['text':' according to "Deep residual learning for image recognition"https://arxiv.org/abs/1512.03385.','line_number':90,'multiline':False]['text':' This variant is also known as ResNet V1.5 and improves accuracy according to','line_number':91,'multiline':False]['text':' https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.','line_number':92,'multiline':False]['text':' Both self.conv2 and self.downsample layers downsample the input when stride != 1','line_number':111,'multiline':False]['text':' each element in the tuple indicates if we should replace','line_number':165,'multiline':False]['text':' the 2x2 stride with a dilated convolution instead','line_number':166,'multiline':False]['text':' Zero-initialize the last BN in each residual branch,','line_number':201,'multiline':False]['text':' so that the residual branch starts with zeros, and each residual block behaves like an identity.','line_number':202,'multiline':False]['text':' This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677','line_number':203,'multiline':False]['text':' See note [TorchScript super()]','line_number':253,'multiline':False]['text':' if pretrained:','line_number':276,'multiline':False]['text':'     state_dict = load_state_dict_from_url(model_urls[arch],','line_number':277,'multiline':False]['text':'                                           progress=progress)','line_number':278,'multiline':False]['text':'     model.load_state_dict(state_dict)','line_number':279,'multiline':False]['text':' contract: features is a dict of tensors','line_number':374,'multiline':False]['text':' backbone = resnet.__dict__[backbone_name](','line_number':423,'multiline':False]['text':'     pretrained=pretrained_backbone,','line_number':424,'multiline':False]['text':'     replace_stride_with_dilation=[False, True, True])','line_number':425,'multiline':False]['text':' Hardcoded resnet 50','line_number':426,'multiline':False]['text':' 'deeplabv3': (DeepLabHead, DeepLabV3), # Not used','line_number':443,'multiline':False]['text':' if pretrained:','line_number':460,'multiline':False]['text':'     arch = arch_type + '_' + backbone + '_coco'','line_number':461,'multiline':False]['text':'     model_url = model_urls[arch]','line_number':462,'multiline':False]['text':'     if model_url is None:','line_number':463,'multiline':False]['text':'         raise NotImplementedError('pretrained {} is not supported as of now'.format(arch))','line_number':464,'multiline':False]['text':'     else:','line_number':465,'multiline':False]['text':'         state_dict = load_state_dict_from_url(model_url, progress=progress)','line_number':466,'multiline':False]['text':'         model.load_state_dict(state_dict)','line_number':467,'multiline':False]['text':' Taken from @fmassa example slides and https://github.com/facebookresearch/detr','line_number':485,'multiline':False]['text':' create ResNet-50 backbone','line_number':509,'multiline':False]['text':' create conversion layer','line_number':513,'multiline':False]['text':' create a default PyTorch transformer','line_number':516,'multiline':False]['text':' prediction heads, one extra class for predicting non-empty slots','line_number':521,'multiline':False]['text':' note that in baseline DETR linear_bbox layer is 3-layer MLP','line_number':522,'multiline':False]['text':' output positional encodings (object queries)','line_number':526,'multiline':False]['text':' spatial positional encodings','line_number':529,'multiline':False]['text':' note that in baseline DETR we use sine positional encodings','line_number':530,'multiline':False]['text':' propagate inputs through ResNet-50 up to avg-pool layer','line_number':535,'multiline':False]['text':' convert from 2048 to 256 feature planes for the transformer','line_number':546,'multiline':False]['text':' construct positional encodings','line_number':549,'multiline':False]['text':' propagate through the transformer','line_number':563,'multiline':False]['text':' TODO (alband) Why this is not automatically broadcasted? (had to add the repeat)','line_number':564,'multiline':False]['text':' finally project transformer outputs to class labels and bounding boxes','line_number':570,'multiline':False]['text':' degenerate boxes gives inf / nan results','line_number':584,'multiline':False]['text':' so do an early check','line_number':585,'multiline':False]['text':' [N,M,2]','line_number':593,'multiline':False]['text':' modified from torchvision to also return the union','line_number':618,'multiline':False]['text':' [N,M,2]','line_number':623,'multiline':False]['text':' [N,M,2]','line_number':624,'multiline':False]['text':' [N,M,2]','line_number':626,'multiline':False]['text':' [N,M]','line_number':627,'multiline':False]['text':' TODO this should probably be a separate loss, not hacked in this one here','line_number':714,'multiline':False]['text':' Count the number of predictions that are NOT "no-object" (which is the last class)','line_number':728,'multiline':False]['text':' TODO use valid to mask invalid areas due to padding in loss','line_number':770,'multiline':False]['text':' upsample predictions to the target size','line_number':777,'multiline':False]['text':' permute predictions following indices','line_number':795,'multiline':False]['text':' permute targets following indices','line_number':803,'multiline':False]['text':' Retrieve the matching between the outputs of the last layer and the targets','line_number':829,'multiline':False]['text':' Compute the average number of target boxes across all nodes, for normalization purposes','line_number':832,'multiline':False]['text':' Compute all the requested losses','line_number':841,'multiline':False]['text':' In case of auxiliary losses, we repeat this process with the output of each intermediate layer.','line_number':846,'multiline':False]['text':' Intermediate masks losses are too costly to compute, we ignore them.','line_number':852,'multiline':False]['text':' Logging is enabled only for the last layer','line_number':856,'multiline':False]['text':' We flatten to compute the cost matrices in a batch','line_number':911,'multiline':False]['text':' [batch_size * num_queries, num_classes]','line_number':914,'multiline':False]['text':' [batch_size * num_queries, 4]','line_number':915,'multiline':False]['text':' Also concat the target labels and boxes','line_number':917,'multiline':False]['text':' Compute the classification cost. Contrary to the loss, we don't use the NLL,','line_number':921,'multiline':False]['text':' but approximate it in 1 - proba[target class].','line_number':922,'multiline':False]['text':' The 1 is a constant that doesn't change the matching, it can be ommitted.','line_number':923,'multiline':False]['text':' Compute the L1 cost between boxes','line_number':926,'multiline':False]['text':' Compute the giou cost betwen boxes','line_number':929,'multiline':False]['text':' Final cost matrix','line_number':934,'multiline':False]