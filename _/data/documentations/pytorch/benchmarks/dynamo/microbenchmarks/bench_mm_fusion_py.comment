['text':' flake8: noqa','line_number':1,'multiline':False]['text':' torch._inductor.config.debug = True','line_number':9,'multiline':False]['text':' The flag below controls whether to allow TF32 on matmul.','line_number':14,'multiline':False]['text':' mm','line_number':19,'multiline':False]['text':' mm+bias','line_number':25,'multiline':False]['text':' relu(mm)','line_number':31,'multiline':False]['text':' relu(mm+bias)','line_number':37,'multiline':False]['text':' allocate inputs','line_number':50,'multiline':False]['text':' reset to force code gen new python code','line_number':77,'multiline':False]['text':' alexnet','line_number':91,'multiline':False]['text':' BERT','line_number':95,'multiline':False]['text':' hf_GPT2','line_number':99,'multiline':False]