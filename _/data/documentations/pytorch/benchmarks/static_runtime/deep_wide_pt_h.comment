['text':' Placeholder for ReplaceNaN','line_number':22,'multiline':False]['text':' Implementation using native functions and pre-allocated tensors.','line_number':36,'multiline':False]['text':' It could be used as a "speed of light" for static runtime.','line_number':37,'multiline':False]['text':' Placeholder for ReplaceNaN','line_number':56,'multiline':False]['text':' auto dp = at::native::flatten(dp_unflatten, 1);','line_number':61,'multiline':False]['text':' fc1 = torch::nn::functional::linear(input, fc_w_, fc_b_);','line_number':65,'multiline':False]['text':' Potential optimization: add and mul could be fused together (e.g. with','line_number':85,'multiline':False]['text':' Eigen).','line_number':86,'multiline':False]['text':' Potential optimization: original tensor could be pre-transposed.','line_number':93,'multiline':False]['text':' prealloc_tensors[3] = at::native::transpose(user_emb, 1, 2);','line_number':94,'multiline':False]['text':' Potential optimization: call MKLDNN directly.','line_number':105,'multiline':False]['text':' in unlikely case that the input tensor changed we need to','line_number':109,'multiline':False]['text':' reinitialize the view','line_number':110,'multiline':False]['text':' Potential optimization: we can replace cat with carefully constructed','line_number':115,'multiline':False]['text':' tensor views on the output that are passed to the _out ops above.','line_number':116,'multiline':False]