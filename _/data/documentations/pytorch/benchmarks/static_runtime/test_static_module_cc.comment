['text':' here we do not freeze graph','line_number':36,'multiline':False]['text':' namespace','line_number':80,'multiline':False]['text':' Test that StaticModule::value_group groups values of the graph into','line_number':82,'multiline':False]['text':' 1) Inputs/Constants and their aliases 2) Outputs and their aliases.','line_number':83,'multiline':False]['text':' Cannot use out variants for list/tuple construction here because','line_number':123,'multiline':False]['text':' inputs are not produced by nodes with out variants.','line_number':124,'multiline':False]['text':' Cannot use out variants for list/tuple construction here because','line_number':144,'multiline':False]['text':' types are not Tensors','line_number':145,'multiline':False]['text':' This container should be optimizable since aten::add has an','line_number':166,'multiline':False]['text':' out variant the container contains Tensors.','line_number':167,'multiline':False]['text':' Test operator() with rvalue inputs','line_number':188,'multiline':False]['text':' aten::reshape -> static_runtime::reshape_copy','line_number':222,'multiline':False]['text':' No Replacement','line_number':259,'multiline':False]['text':' dict of tuple of list','line_number':363,'multiline':False]['text':' tuple of lists','line_number':374,'multiline':False]['text':' list of tuple of dict','line_number':385,'multiline':False]['text':' lit of dict','line_number':397,'multiline':False]['text':' test memory reuse','line_number':431,'multiline':False]['text':' run jit graph executor','line_number':438,'multiline':False]['text':' run static runtime','line_number':442,'multiline':False]['text':'rtol=','line_number':448,'multiline':True]['text':'atol=','line_number':448,'multiline':True]['text':' run jit graph executor','line_number':457,'multiline':False]['text':' run static runtime','line_number':461,'multiline':False]['text':'rtol=','line_number':467,'multiline':True]['text':'atol=','line_number':467,'multiline':True]['text':' run jit graph executor','line_number':482,'multiline':False]['text':' run static runtime','line_number':486,'multiline':False]['text':'rtol=','line_number':493,'multiline':True]['text':'atol=','line_number':493,'multiline':True]['text':' run jit graph executor','line_number':512,'multiline':False]['text':' run static runtime','line_number':515,'multiline':False]['text':'rtol=','line_number':521,'multiline':True]['text':'atol=','line_number':521,'multiline':True]['text':' check for output aliasing','line_number':523,'multiline':False]['text':' check for input aliasing (deep & wide does not have ops','line_number':530,'multiline':False]['text':' that create aliases of input tensors)','line_number':531,'multiline':False]['text':' run jit graph executor','line_number':551,'multiline':False]['text':' run static runtime','line_number':560,'multiline':False]['text':'rtol=','line_number':566,'multiline':True]['text':'atol=','line_number':566,'multiline':True]['text':' check for output aliasing','line_number':568,'multiline':False]['text':' when manage_output_tensors is enabled, enable_out_variant','line_number':609,'multiline':False]['text':' must be enabled too','line_number':610,'multiline':False]['text':' when optimize_memory is enabled, enable_out_variant must be','line_number':614,'multiline':False]['text':' enabled too','line_number':615,'multiline':False]['text':' run jit graph executor','line_number':632,'multiline':False]['text':' run static runtime','line_number':636,'multiline':False]['text':'rtol=','line_number':644,'multiline':True]['text':'atol=','line_number':644,'multiline':True]['text':'enable_out_variant=','line_number':687,'multiline':True]['text':'optimize_memory=','line_number':688,'multiline':True]['text':'manage_output_tensors=','line_number':689,'multiline':True]['text':' Profile run.','line_number':694,'multiline':False]['text':' Do not manage input value.','line_number':699,'multiline':False]['text':' Do not manage direct output value.','line_number':701,'multiline':False]['text':' Tensor to be managed, but not yet from the profile run.','line_number':704,'multiline':False]['text':' Second run that manages output tensors.','line_number':710,'multiline':False]['text':' Do not manage input value.','line_number':715,'multiline':False]['text':' Do not manage direct output value.','line_number':717,'multiline':False]['text':' Tensor to be managed, but not yet from the profile run.','line_number':720,'multiline':False]['text':'enable_out_variant=','line_number':734,'multiline':True]['text':'optimize_memory=','line_number':735,'multiline':True]['text':'manage_output_tensors=','line_number':736,'multiline':True]['text':' Reenter the runtime with the input with the same shape/different shapes.','line_number':739,'multiline':False]['text':'enable_out_variant=','line_number':758,'multiline':True]['text':'optimize_memory=','line_number':759,'multiline':True]['text':'manage_output_tensors=','line_number':760,'multiline':True]['text':' Profile run.','line_number':768,'multiline':False]['text':' Run again to allocate output Tensors without deallocating them.','line_number':771,'multiline':False]['text':' Memory leak checking fails.','line_number':773,'multiline':False]['text':' Calling the runtime without deallocation fails too.','line_number':775,'multiline':False]['text':' After deallocation, everything works fine.','line_number':777,'multiline':False]['text':'enable_out_variant=','line_number':795,'multiline':True]['text':'optimize_memory=','line_number':796,'multiline':True]['text':'manage_output_tensors=','line_number':797,'multiline':True]['text':' Profile run.','line_number':802,'multiline':False]['text':' Second run that manages output tensors.','line_number':811,'multiline':False]['text':' Reset the runtime and start profiling again.','line_number':821,'multiline':False]['text':' New profile run.','line_number':826,'multiline':False]['text':' No-op since manage_output_tensor is disabled now.','line_number':834,'multiline':False]['text':' Ensure that `original_output_tensor` is no longer managed: even after','line_number':838,'multiline':False]['text':' calling `runtime.deallocateOutputTensors();` `original_output_tensor` still','line_number':839,'multiline':False]['text':' contains a valid value.','line_number':840,'multiline':False]['text':' Ensure that the second optimized run does not manage the output tensor','line_number':844,'multiline':False]['text':' either.','line_number':845,'multiline':False]['text':' No-op since manage_output_tensor is disabled now.','line_number':853,'multiline':False]['text':' Ensure that `original_output_tensor` is no longer managed: even after','line_number':857,'multiline':False]['text':' calling `runtime.deallocateOutputTensors();` `original_output_tensor` still','line_number':858,'multiline':False]['text':' contains a valid value.','line_number':859,'multiline':False]['text':' run jit graph executor','line_number':874,'multiline':False]['text':'rtol=','line_number':890,'multiline':True]['text':'atol=','line_number':890,'multiline':True]['text':' Not using out= variant.','line_number':913,'multiline':False]['text':'enable_out_variant=','line_number':920,'multiline':True]['text':'check_memory_overlap=','line_number':921,'multiline':True]['text':' force_check','line_number':925,'multiline':True]['text':' force_check','line_number':928,'multiline':True]['text':' Using out= variant.','line_number':933,'multiline':False]['text':'enable_out_variant=','line_number':940,'multiline':True]['text':'check_memory_overlap=','line_number':941,'multiline':True]['text':'enable_out_variant=','line_number':968,'multiline':True]['text':'check_memory_overlap ','line_number':969,'multiline':True]['text':' force_check','line_number':976,'multiline':True]['text':'enable_out_variant=','line_number':983,'multiline':True]['text':'check_memory_overlap ','line_number':984,'multiline':True]['text':' force_check','line_number':993,'multiline':True]['text':' namespace test','line_number':1011,'multiline':False]['text':' test::bad_add has the schema with incorrect alias annotation.','line_number':1013,'multiline':False]['text':' test::good_add has the correct alias annotation.','line_number':1014,'multiline':False]['text':' big enough to trigger resize of the internal buffer','line_number':1037,'multiline':False]['text':' This test doesn't pass yet. This is the corner case mentioned in Step 2 of','line_number':1040,'multiline':False]['text':' [Check and correct bad schema alias info at runtime]','line_number':1041,'multiline':False]['text':' testStaticRuntime(src, {x1, 10}, {x2, 0});','line_number':1042,'multiline':False]['text':' This test repeats the last test, but with the correct schema alias','line_number':1046,'multiline':False]['text':' annotations','line_number':1047,'multiline':False]['text':' comment out the prim::TupleConstruct repro the failure of','line_number':1049,'multiline':False]['text':' DCHECK(!isManagedOutputTensor(*outputs_[0]));','line_number':1050,'multiline':False]['text':' big enough to trigger resize of the internal buffer','line_number':1063,'multiline':False]['text':'enable_out_variant=','line_number':1083,'multiline':True]['text':'check_memory_overlap=','line_number':1084,'multiline':True]['text':'enable_out_variant=','line_number':1091,'multiline':True]['text':'check_memory_overlap=','line_number':1092,'multiline':True]['text':' We don't care about the order, so convert to set. But make sure','line_number':1172,'multiline':False]['text':' there are no duplicates.','line_number':1173,'multiline':False]['text':' For checking the correctness of assignStorageToManageTensors, the following','line_number':1264,'multiline':False]['text':' conditions must hold','line_number':1265,'multiline':False]['text':' 1. All managed tensors are assigned to some storage group, and a tensor','line_number':1266,'multiline':False]['text':'    may not be assigned to more than 1 storage group.','line_number':1267,'multiline':False]['text':' 2. Managed tensors with overlapping lifetimes should not be in the same','line_number':1268,'multiline':False]['text':'    storage group.','line_number':1269,'multiline':False]['text':' 3. The number of reused tensors is >= min_reused_tensors.','line_number':1270,'multiline':False]['text':' Some extra bookkeeping; construct the set of managed Tensor* and','line_number':1276,'multiline':False]['text':' invert the tensor_value_to_tensor map. StorageGroup stores','line_number':1277,'multiline':False]['text':' Tensor*, so this will make everything a little easier.','line_number':1278,'multiline':False]['text':' Condition (1)','line_number':1289,'multiline':False]['text':' Condition (2)','line_number':1300,'multiline':False]['text':' Condition (3)','line_number':1314,'multiline':False]['text':' A convenience function for testing assignStorageToManagedTensors. It','line_number':1318,'multiline':False]['text':' takes in an IR graph as well as a map from managed tensor name to tensor','line_number':1319,'multiline':False]['text':' value. It constructs all of the necessary data structures, invokes','line_number':1320,'multiline':False]['text':' assignStorageToManageTensors, and verifies correctness with','line_number':1321,'multiline':False]['text':' checkStorageGroups.','line_number':1322,'multiline':False]['text':' namespace','line_number':1353,'multiline':False]['text':' namespace','line_number':1405,'multiline':False]['text':' namespace','line_number':1430,'multiline':False]['text':' turn the ListConstruct(%constant) into proper constant lists','line_number':1556,'multiline':False]['text':' turn the ListConstruct(%constant) into proper constant lists','line_number':1579,'multiline':False]['text':' turn the ListConstruct(%constant) into proper constant lists','line_number':1597,'multiline':False]['text':'args2=','line_number':1627,'multiline':True]['text':'use_allclose=','line_number':1627,'multiline':True]['text':' FuseClampNaNToNum pass is disabled externally to avoid MSVC errors in CI','line_number':1708,'multiline':False]['text':' Correctness of the op is exercised in StaticRuntime.clamp_nan_to_num','line_number':1723,'multiline':False]