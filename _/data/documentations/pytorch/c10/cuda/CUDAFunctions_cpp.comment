['text':' returns -1 on failure','line_number':9,'multiline':False]['text':' Clear out the error state, so we don't spuriously trigger someone else.','line_number':22,'multiline':False]['text':' (This shouldn't really matter, since we won't be running very much CUDA','line_number':23,'multiline':False]['text':' code in this regime.)','line_number':24,'multiline':False]['text':' Zero devices is ok here','line_number':28,'multiline':False]['text':' No CUDA driver means no devices','line_number':35,'multiline':False]['text':' In ASAN mode, we know that a cudaErrorMemoryAllocation error will','line_number':72,'multiline':False]['text':' pop up if compiled with NVCC (clang-cuda is fine)','line_number':73,'multiline':False]['text':' C10_ASAN_ENABLED','line_number':81,'multiline':False]['text':' namespace','line_number':94,'multiline':False]['text':' initialize number of devices only once','line_number':97,'multiline':False]['text':'fail_if_no_driver=','line_number':100,'multiline':True]['text':' We don't want to fail, but still log the warning','line_number':106,'multiline':False]['text':' msg() returns the message without the stack trace','line_number':107,'multiline':False]['text':' Call the implementation every time to throw the exception','line_number':116,'multiline':False]['text':'fail_if_no_driver=','line_number':117,'multiline':True]['text':' Zero gpus doesn't produce a warning in `device_count` but we fail here','line_number':118,'multiline':False]['text':' this function has to be called from callers performing cuda synchronizing','line_number':141,'multiline':False]['text':' operations, to raise proper error or warning','line_number':142,'multiline':False]['text':' check current device first','line_number':152,'multiline':False]['text':' Private api to be called from CUDAHooks.cpp','line_number':175,'multiline':False]['text':' namespace _internal','line_number':179,'multiline':False]['text':' Wrappers for raw CUDA device management functions','line_number':185,'multiline':False]['text':' This is a codepath for CUDA 12 that comes with a critical change in behavior','line_number':190,'multiline':False]['text':' of `cudaSetDevice`. Unlike to previous CUDA versions that allocate context','line_number':191,'multiline':False]['text':' lazily CUDA 12.x eagerly allocates primary context the moment `cudaSetDevice`','line_number':192,'multiline':False]['text':' is called. This can lead to dramatic consequences and pollute the device','line_number':193,'multiline':False]['text':' memory in distributed runs. To avoid unnecessary context creation a new','line_number':194,'multiline':False]['text':' function called `MaybeSetDevice` was introduced. This function is to be','line_number':195,'multiline':False]['text':' called in device guard destructor and at the exit of torch.cuda.device','line_number':196,'multiline':False]['text':' context manager. The behavior of `MaybeSetDevice` is quite simple, it calls','line_number':197,'multiline':False]['text':' to `cudaSetDevice` if context already exist or if context was not allocated','line_number':198,'multiline':False]['text':' on targeted device it simply saves the device index. This way we can keep','line_number':199,'multiline':False]['text':' PyTorch backward compatible for applications like this:','line_number':200,'multiline':False]['text':'','line_number':201,'multiline':False]['text':' ```','line_number':202,'multiline':False]['text':' import torch','line_number':203,'multiline':False]['text':' x = torch.empty(1, device=“cuda:1”) # no CUDA context on cuda:0 after this','line_number':204,'multiline':False]['text':' call y = torch.empty(1, device=“cuda”) # CUDA context is created on cuda:0','line_number':205,'multiline':False]['text':' ```','line_number':206,'multiline':False]['text':' This function always initializes the CUDA context','line_number':237,'multiline':False]['text':' on to_device','line_number':238,'multiline':False]['text':' This function does not initialize the CUDA context','line_number':252,'multiline':False]['text':' on to_device if it does not already exist','line_number':253,'multiline':False]['text':' no-op on CUDA version < 12.x','line_number':307,'multiline':False]['text':' namespace c10::cuda','line_number':311,'multiline':False]