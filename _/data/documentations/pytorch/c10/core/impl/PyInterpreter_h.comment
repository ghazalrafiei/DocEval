['text':' Forward declarations','line_number':14,'multiline':False]['text':' namespace c10','line_number':20,'multiline':False]['text':' namespace torch','line_number':26,'multiline':False]['text':' Actual implementation','line_number':28,'multiline':False]['text':' Note [Python interpreter tag]','line_number':35,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':36,'multiline':False]['text':' Traditionally, PyTorch is layered such that our Python library','line_number':37,'multiline':False]['text':' (libtorch_python) references our pure C++ library (libtorch) as the','line_number':38,'multiline':False]['text':' natural order of things.  However, sometimes this natural order is','line_number':39,'multiline':False]['text':' subverted: C++ objects refer to Python objects (for example, we','line_number':40,'multiline':False]['text':' store a PyObject* pointer on TensorImpl so that converting from a','line_number':41,'multiline':False]['text':' C++ Tensor to a Python Tensor is just a memory dereference).','line_number':42,'multiline':False]['text':'','line_number':43,'multiline':False]['text':' These unusual orderings must be treated with care.  To start, you need to','line_number':44,'multiline':False]['text':' virtualize the destructor so that the PyObject can be decref'ed on','line_number':45,'multiline':False]['text':' destruction (because the C++ object itself doesn't know anything about','line_number':46,'multiline':False]['text':' Python--remember, layering!).  This process itself is fraught, since','line_number':47,'multiline':False]['text':' acquiring the GIL could lead to deadlocks if someone is blocking on you','line_number':48,'multiline':False]['text':' while holding the GIL.  Furthermore, if the C++ objects outlive the','line_number':49,'multiline':False]['text':' interpreter (which can happen if you stash them in a static global','line_number':50,'multiline':False]['text':' variable defined in libtorch), you may attempt to decref the object when','line_number':51,'multiline':False]['text':' the Python interpreter has already been shutdown.','line_number':52,'multiline':False]['text':'','line_number':53,'multiline':False]['text':' BUT WAIT, IT GETS WORSE.  With torchdeploy, there may be multiple Python','line_number':54,'multiline':False]['text':' interpreters in a single process. If a C++ object is accessible from','line_number':55,'multiline':False]['text':' multiple interpreters, we must take care not to accidentally pass a','line_number':56,'multiline':False]['text':' PyObject from one interpreter with another interpreter.','line_number':57,'multiline':False]['text':'','line_number':58,'multiline':False]['text':' To prevent these mixups, we introduce a PyInterpreter "tag" (object with','line_number':59,'multiline':False]['text':' a vtable), which specifies a specific Python interpreter.','line_number':60,'multiline':False]['text':'','line_number':61,'multiline':False]['text':'  - Any given object can be associated with AT MOST one Python interpreter.','line_number':62,'multiline':False]['text':'    We represent the interpreter tag as a memory address to an instance of','line_number':63,'multiline':False]['text':'    a virtual class that is allocated once per interpreter (this is so that','line_number':64,'multiline':False]['text':'    we can request the interpreter to perform operations for us, if','line_number':65,'multiline':False]['text':'    necessary).','line_number':66,'multiline':False]['text':'','line_number':67,'multiline':False]['text':'  - It can be recorded with a PyObject (PyInterpreterObject) so that','line_number':68,'multiline':False]['text':'    we know what interpreter the object is associated with, and we can','line_number':69,'multiline':False]['text':'    raise an error if you try to use the PyObject from the wrong','line_number':70,'multiline':False]['text':'    interpreter context.','line_number':71,'multiline':False]['text':'','line_number':72,'multiline':False]['text':'  - It contains a vtable that can be used to perform various Python','line_number':73,'multiline':False]['text':'    operations from ordinary C++ code that ordinarily wouldn't be accessible','line_number':74,'multiline':False]['text':'    from libtorch.','line_number':75,'multiline':False]['text':'','line_number':76,'multiline':False]['text':' A simple use case is when a C++ object must be associated with a PyObject.','line_number':77,'multiline':False]['text':' However, for TensorImpl, we lazily allocate a PyObject the first time the','line_number':78,'multiline':False]['text':' object passes into Python.  The invariants for this situation are more','line_number':79,'multiline':False]['text':' subtle:','line_number':80,'multiline':False]['text':'','line_number':81,'multiline':False]['text':'  - A given TensorImpl's interpreter tag can only go from uninitialized to','line_number':82,'multiline':False]['text':'    tagged; once tagged, this is a quiescent state (once tagged to an','line_number':83,'multiline':False]['text':'    interpreter, ALWAYS tagged to that interpreter)','line_number':84,'multiline':False]['text':'','line_number':85,'multiline':False]['text':'  - A thread may mutate the PyObject field of a TensorImpl if and only if it','line_number':86,'multiline':False]['text':'    holds the GIL for the interpreter tagged on the TensorImpl.  (If the','line_number':87,'multiline':False]['text':'    TensorImpl is not tagged, it must first atomically claim its tag before it','line_number':88,'multiline':False]['text':'    can validly write)','line_number':89,'multiline':False]['text':'','line_number':90,'multiline':False]['text':' WARNING: This class has to be written very carefully, because it may be','line_number':91,'multiline':False]['text':' possible for a Tensor to have a reference an interpreter corresponding to','line_number':92,'multiline':False]['text':' a shared library that has ALREADY BEEN UNLOADED.  This makes blindly calling','line_number':93,'multiline':False]['text':' virtual methods very dangerous, because the vtable may be garbage at that','line_number':94,'multiline':False]['text':' point (on a good day, you might get "pure virtual method called").','line_number':95,'multiline':False]['text':'','line_number':96,'multiline':False]['text':' The idea to solve this problem is we always leak PyInterpreters (so they','line_number':97,'multiline':False]['text':' always stay live even after dlclose), and make sure we can disarm their','line_number':98,'multiline':False]['text':' virtual methods by indirecting through a separate PyInterpreterVTable','line_number':99,'multiline':False]['text':' object.  This can be replaced with a no-op vtable from libc10.so, which','line_number':100,'multiline':False]['text':' is guaranteed to stick around until the bitter end.','line_number':101,'multiline':False]['text':'','line_number':102,'multiline':False]['text':' NB: The downside with representing PyInterpreter tags as full objects is that','line_number':103,'multiline':False]['text':' it takes an extra word on TensorImpl.  If tags were instead just integer','line_number':104,'multiline':False]['text':' indices, on 64-bit architectures we could pack the tag and PyObject together','line_number':105,'multiline':False]['text':' into a single atomic word.  On 32-bit architectures we could simply say that','line_number':106,'multiline':False]['text':' only one Python interpreter is supported (erroring if a nontrivial','line_number':107,'multiline':False]['text':' interpreter tag is attempted to be set).','line_number':108,'multiline':False]['text':'','line_number':109,'multiline':False]['text':' The difficulty with this scheme is we need to maintain an out-of-line table','line_number':110,'multiline':False]['text':' to get at the PyInterpreters so that we can do virtual method calls on them,','line_number':111,'multiline':False]['text':' and registration/deregistration to this table must be done in a thread safe','line_number':112,'multiline':False]['text':' manner.  This can be easily done if the number of possible PyInterpreters is','line_number':113,'multiline':False]['text':' small enough (e.g., 8-bit integer) by simply preallocating an array of','line_number':114,'multiline':False]['text':' sufficient size to hold all possible interpreters.  Surely 128 threads is','line_number':115,'multiline':False]['text':' more than enough for anyone!','line_number':116,'multiline':False]['text':'','line_number':117,'multiline':False]['text':' I didn't decide to do this technique at the moment, because the extra word','line_number':118,'multiline':False]['text':' added by the PyInterpreter tag takes us to 24 words, which means that we','line_number':119,'multiline':False]['text':' still fit inside three eight word cache lines.  If you need to penny pinch','line_number':120,'multiline':False]['text':' another word consider doing this!','line_number':121,'multiline':False]['text':' Report the name of this interpreter','line_number':126,'multiline':False]['text':' Run Py_DECREF on a PyObject.  We DO NOT assume the GIL is held on call','line_number':129,'multiline':False]['text':' See NOTE [PyInterpreter::decref takes a `has_pyobj_slot` arg]','line_number':130,'multiline':False]['text':' Perform a detach by deferring to the __torch_dispatch__ implementation of','line_number':133,'multiline':False]['text':' detach, which will also arrange for the PyObject to get copied in this','line_number':134,'multiline':False]['text':' situation','line_number':135,'multiline':False]['text':' Invoke the Python boxed fallback dispatch to go back into Python','line_number':139,'multiline':False]['text':' This is only invoked in the multipy/torchdeploy situation from','line_number':146,'multiline':False]['text':' pythonOpRegistrationTrampoline; this lets us get to the Python','line_number':147,'multiline':False]['text':' interpreter to actually find the appropriate Python op registration','line_number':148,'multiline':False]['text':' entry to call.','line_number':149,'multiline':False]['text':' Invoke the Python dispatcher to handle this call','line_number':160,'multiline':False]['text':' Disarm this PyInterpreter, making all of its methods noops.','line_number':210,'multiline':False]['text':' The vtable pointer is not an atomic at the moment, which means','line_number':211,'multiline':False]['text':' a disarm() invocation that is concurrent with active destructors','line_number':212,'multiline':False]['text':' is not thread safe and will trigger TSAN.  My hope is that this','line_number':213,'multiline':False]['text':' situations doesn't ever actually happen; tensor destruction should','line_number':214,'multiline':False]['text':' quiesce when a dlclose happens, and any long lived tensors whose','line_number':215,'multiline':False]['text':' destructors would be disarmed here only begin the destruction process','line_number':216,'multiline':False]['text':' on process shutdown (long after the dlclose has occurred).','line_number':217,'multiline':False]['text':' PyInterpreterStatus describes what the state of its interpreter tag','line_number':221,'multiline':False]['text':' is, relative to the thread currently holding the GIL.','line_number':222,'multiline':False]['text':' We just allocated the Tensor, it hasn't escaped to other threads,','line_number':224,'multiline':False]['text':' we know that it definitely hasn't been tagged to be associated','line_number':225,'multiline':False]['text':' with an interpreter.','line_number':226,'multiline':False]['text':' We queried the interpreter field and it looked uninitialized.  But','line_number':228,'multiline':False]['text':' another thread may have raced with us to tag it with some other','line_number':229,'multiline':False]['text':' interpreter id.  So we will have to do a CEX to make sure we can','line_number':230,'multiline':False]['text':' actually nab it.','line_number':231,'multiline':False]['text':' We queried the interpreter field and it was tagged to belong to us.','line_number':233,'multiline':False]['text':' This means we have sole write access (as we hold the GIL for this','line_number':234,'multiline':False]['text':' interpreter)','line_number':235,'multiline':False]['text':' Someone else tagged this.  We can't use this TensorImpl from Python.','line_number':237,'multiline':False]['text':' namespace impl','line_number':241,'multiline':False]['text':' namespace c10','line_number':242,'multiline':False]