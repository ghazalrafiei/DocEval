['text':' Memory format is not the property of a Tensor. It is the way to tell an','line_number':9,'multiline':False]['text':' operator how the result should be organized in memory and nothing more. That','line_number':10,'multiline':False]['text':' means memory format should never be used as return value for any tensor state','line_number':11,'multiline':False]['text':' interrogation functions (internally and externally).','line_number':12,'multiline':False]['text':'','line_number':13,'multiline':False]['text':' Possible options are:','line_number':14,'multiline':False]['text':'  Preserve:','line_number':15,'multiline':False]['text':'    If any of the input tensors is in channels_last format, operator output','line_number':16,'multiline':False]['text':'    should be in channels_last format','line_number':17,'multiline':False]['text':'','line_number':18,'multiline':False]['text':'  Contiguous:','line_number':19,'multiline':False]['text':'    Regardless of input tensors format, the output should be contiguous','line_number':20,'multiline':False]['text':'    Tensor.','line_number':21,'multiline':False]['text':'','line_number':22,'multiline':False]['text':'  ChannelsLast:','line_number':23,'multiline':False]['text':'    Regardless of input tensors format, the output should be in channels_last','line_number':24,'multiline':False]['text':'    format.','line_number':25,'multiline':False]['text':' If you are seeing this, it means that this call site was not checked if','line_number':36,'multiline':False]['text':' the memory format could be preserved, and it was switched to old default','line_number':37,'multiline':False]['text':' behaviour of contiguous','line_number':38,'multiline':False]['text':' Note: Hardcoded the channel last stride indices here to get better','line_number':62,'multiline':False]['text':' performance','line_number':63,'multiline':False]['text':' NOTE:','line_number':116,'multiline':False]['text':' Below are Helper functions for is_channels_last_strides_xd.','line_number':117,'multiline':False]['text':' 1. Please do not combine these helper functions, each helper function handles','line_number':118,'multiline':False]['text':' exactly one case of sizes + memory_format, by doing this, the strides indices','line_number':119,'multiline':False]['text':' will be a constant array and we can access it using constant index number,','line_number':120,'multiline':False]['text':' the compiler will fully unroll the loop on strides indices to gain a better','line_number':121,'multiline':False]['text':' performance.','line_number':122,'multiline':False]['text':' 2. No error check in helper function, caller ensures the correctness of the','line_number':123,'multiline':False]['text':' input','line_number':124,'multiline':False]['text':' 3. All helper functions have similar comments, only 1st helper function is','line_number':125,'multiline':False]['text':' commented here.','line_number':126,'multiline':False]['text':' special case for trivial C dimension. default to NCHW','line_number':132,'multiline':False]['text':' loop strides indices','line_number':136,'multiline':False]['text':' Fallback to NCHW as default layout for ambiguous cases','line_number':144,'multiline':False]['text':' This is the flaw of implicit memory_format from strides.','line_number':145,'multiline':False]['text':' N111 tensor with identical strides for size 1 dimension;','line_number':146,'multiline':False]['text':' Two cases could lead us here:','line_number':147,'multiline':False]['text':' a. N111 contiguous Tensor ([N,1,1,1]@[1,1,1,1])','line_number':148,'multiline':False]['text':' b. N11W contiguous Tensor sliced on the W-dimension.','line_number':149,'multiline':False]['text':' ([N,1,1,1]@[W,W,W,W])','line_number':150,'multiline':False]['text':' This is necessary to:','line_number':154,'multiline':False]['text':' 1. distinguish the memory_format of N1H1;','line_number':155,'multiline':False]['text':'     [H, 1, 1, 1] channels_last stride','line_number':156,'multiline':False]['text':'     [H, H, 1, 1] contiguous stride','line_number':157,'multiline':False]['text':' 2. permutation of 1C1W:','line_number':158,'multiline':False]['text':'     [1, C, 1, H]@[HC, H, H, 1] transpose(1, 3)','line_number':159,'multiline':False]['text':'     [1, H, 1, C]@[HC, 1, H, H] shouldn't be identified as channels_last','line_number':160,'multiline':False]['text':' Note [Ambiguous is_channels_last_strides_xd]','line_number':195,'multiline':False]['text':' ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~','line_number':196,'multiline':False]['text':' The flaw of carrying memory_format implicitly through strides is very hard','line_number':197,'multiline':False]['text':' to WAR properly. issue #24090','line_number':198,'multiline':False]['text':' Without the history of permutation, we can't infer the memory_format of a','line_number':199,'multiline':False]['text':' tensor from the snapshot of its size & stride','line_number':200,'multiline':False]['text':' e.g.','line_number':201,'multiline':False]['text':'','line_number':202,'multiline':False]['text':' 1. We can NOT specify the memory_format of N111 tensor through strides in a','line_number':203,'multiline':False]['text':'  meaningful way;','line_number':204,'multiline':False]['text':'','line_number':205,'multiline':False]['text':' 2. Two path that ended up with identical size/stride','line_number':206,'multiline':False]['text':'  N11W contiguous tensor sliced at w-dimension becomes [N,1,1,1]@[W,W,W,W]','line_number':207,'multiline':False]['text':'  NC11 channels_last tensor sliced at c-dimension becomes [N,1,1,1]@[C,C,C,C]','line_number':208,'multiline':False]['text':'    So if we see a tensor [N,1,1,1]@[X,X,X,X], there's no way for us to infer','line_number':209,'multiline':False]['text':'    the memory_format of the original tensor.','line_number':210,'multiline':False]['text':'','line_number':211,'multiline':False]['text':' Due to the limitations, our temporary WAR `is_channels_last_strides` does the','line_number':212,'multiline':False]['text':' best effort to infer whether the original memory_format of a tensor is','line_number':213,'multiline':False]['text':' at::MemoryFormat::ChannelsLast. The two objectives of this function (ordered','line_number':214,'multiline':False]['text':' by their importance):','line_number':215,'multiline':False]['text':'   1. Ensure that normal shape manipulation does not accidentally change the','line_number':216,'multiline':False]['text':'      MemoryFormat of an existing tensor.','line_number':217,'multiline':False]['text':'   2. Allows user to mark MemoryFormat::ChannelsLast to tensors;','line_number':218,'multiline':False]['text':'','line_number':219,'multiline':False]['text':' The function does so via checking strides of the tensor, including strides of','line_number':220,'multiline':False]['text':' size-1 dimensions. Although conventionally PyTorch implies no restriction on','line_number':221,'multiline':False]['text':' trivial stride (stride for size-1 dimension).','line_number':222,'multiline':False]['text':'','line_number':223,'multiline':False]['text':' Note that this approach is a compromise. We did not solve the problem','line_number':224,'multiline':False]['text':' completely. Many cases we will not be able to infer the correct memory','line_number':225,'multiline':False]['text':' format.','line_number':226,'multiline':False]['text':' The implementation of `is_channels_last_strides` is to serve the objectives:','line_number':227,'multiline':False]['text':' MemoryFormat::ChannelsLast has to be explicitly opted-in (no accidental','line_number':228,'multiline':False]['text':' conversion); Best effort to maintain the ChannelsLast flag.','line_number':229,'multiline':False]['text':'','line_number':230,'multiline':False]['text':' Due to the fact that this is not a bulletproof solution, through testing','line_number':231,'multiline':False]['text':' (aten/src/ATen/test/memory_format_test.cpp)','line_number':232,'multiline':False]['text':'   a. we ensure that the common tasks are supported;','line_number':233,'multiline':False]['text':'   a. we identify corner cases where the implementation compromises on.','line_number':234,'multiline':False]['text':'','line_number':235,'multiline':False]['text':' By the time accumulated permutation is enabled to replace implicit','line_number':236,'multiline':False]['text':' memory_format through strides, we should be updating our tests and fix the','line_number':237,'multiline':False]['text':' issues in our tests.','line_number':238,'multiline':False]['text':'','line_number':239,'multiline':False]['text':' We use Channels Last 2d as an example above.','line_number':240,'multiline':False]['text':' This is a general problem for all the is_channels_last_strides_xd','line_number':241,'multiline':False]['text':' implementation. Please check the helper functions','line_number':242,'multiline':False]['text':' (is_channels_last_strides_*d_s*) for more details.','line_number':243,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':252,'multiline':False]['text':' TODO dim == 3 case will be enabled once it is fully tested','line_number':254,'multiline':False]['text':' NOLINTNEXTLINE(bugprone-branch-clone)','line_number':268,'multiline':False]['text':' TODO dim == 4 case will be enabled once it is fully tested','line_number':270,'multiline':False]['text':' namespace c10','line_number':289,'multiline':False]