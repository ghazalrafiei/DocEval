['text':'*****************************************************************************
  Copyright (c) 2007-2011, Intel Corp.
  All rights reserved.

  Redistribution and use in source and binary forms, with or without
  modification, are permitted provided that the following conditions are met:

    * Redistributions of source code must retain the above copyright notice,
      this list of conditions and the following disclaimer.
    * Redistributions in binary form must reproduce the above copyright
      notice, this list of conditions and the following disclaimer in the
      documentation and/or other materials provided with the distribution.
    * Neither the name of Intel Corporation nor the names of its contributors
      may be used to endorse or promote products derived from this software
      without specific prior written permission.

  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  THE POSSIBILITY OF SUCH DAMAGE.
*****************************************************************************','line_number':1,'multiline':True]['text':' This definition of F_MUL_CHOPPED is used for dynamic
	rounding modes and when no directed rounding is available.
	In the later case results will not be correctly rounded.  ','line_number':78,'multiline':True]['text':'
** NUM_FRAC_BITS specifies the number of mantissa bits used for
** indexing the table (the table index also includes the low-order
** exponent bit).  NUM_FRAC_BITS also affects the table size:
**
**	sizeof(D_SQRT_TABLE_NAME) = (1 << (NUM_FRAC_BITS + 1))
**				    * (2*sizeof(float)+sizeof(double))
','line_number':87,'multiline':True]['text':'
**	LOC_OF_EXPON is the bit offset within u.B_SIGNED_HI_32 of the
**	low-order exponent bit of u.f, where u is a B_UNION.  (We assume
**	the highest bits of B_SIGNED_HI_32 hold the sign bit and exponent).
**
**	From LOC_OF_EXPON, EXP_BITS_OF_ONE_HALF and HI_EXP_BIT_MASK are derived.
','line_number':102,'multiline':True]['text':'
**	SAVE_EXP saves the exponent in a temporary so it can be used in
**	the INPUT_IS_ABNORMAL macro
','line_number':118,'multiline':True]['text':' INPUT_IS_ABNORMAL doesn't need it ','line_number':138,'multiline':True]['text':' We can do 64-bit stores ','line_number':146,'multiline':True]['text':' This is an optimization of the 'else' clause below ','line_number':147,'multiline':True]['text':' Store it in 32-bits pieces ','line_number':158,'multiline':True]['text':' This condition is complicated.  ','line_number':174,'multiline':True]['text':'
** The definitions of SQRT_COEF_STRUCT and D_SQRT_TABLE_NAME also
** appear in the generated .c file for the table.
','line_number':197,'multiline':True]['text':'
**  SCALE_AND_DO_INDEXED_POLY_APPROX
**
**	Inputs:
**		x		any number
**				= f * 2^(2*i+j)
**			where	1/2 <= f < 1, integer i and j,
**				and j = 0 or 1
**			ignoring f <= 0
**
**	Outputs:
**		half_scale	= 2^(i-1)	(SQRT, F_SQRT)
**
**		flah_scale	= 2^(1-i)	(RSQRT)
**				(the name is clear, albeit cute)
**
**		scaled_x	= f * 2^j
**			so	1/2 <= scaled_x < 2
**
**		y		~= 1/sqrt(scaled_x)
**
**			so	sqrt(x) ~= y * scaled_x * 2 * half_scale
**			and	1/sqrt(x) ~= y / (2 * half_scale)
**
**	Temporaries:
**		u, a, b, c, index
','line_number':209,'multiline':True]['text':' end of SCALE_AND_DO_INDEXED_POLY_APPROX ','line_number':267,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':271,'multiline':True]['text':'                      Tuckerman's Rounding                                  ','line_number':272,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':273,'multiline':True]['text':'
** Tuckerman's rounding is used to compute the correctly rounded sqrt(x).
** It's 'good to the last bit', or more precisely 'to within 1/2 lsb(sqrt(x))'.
** This is a short proof of Tuckerman's rounding.
**
** Let z be a machine-precision approximation to sqrt(x); then z+lsb(z) is the
** smallest representable number larger than z (NB: z-lsb(z) is the largest
** representable number less than z, _except_ when z is a power of 2).
** Within this proof, let [] represent _truncation_ to machine precision,
** and {} represent _rounding_ to machine precision.
**
** Note that for _any_ y (not necessarily representable in machine precision),
**
**      z + 1/2 lsb(z) <= y  <==>  z < {y}.
**
** For sqrt(x), we never have equality:
**      z + 1/2 lsb(z) <= sqrt(x)  ==>  z + 1/2 lsb(z) < sqrt(x),
** because if they were equal, we'd have:
**      (z + 1/2 lsb(z))^2 = x
** which is impossible, because to represent the left hand side requires more
** than twice the machine precision, while the right hand side is representable.
**
** Now the following statements are equivalent in turn:
**
**              z < {sqrt(x)}
**              z + 1/2 lsb(z) <= sqrt(x)
**              z + 1/2 lsb(z) < sqrt(x)
**              (z +  1/2 lsb(z))^2 < x
**              z (z + 1/2 lsb(z)) < x          (the reverse is proved below)
**              [ z (z + 1/2 lsb(z)) ] < x.
**
** To complete the reverse of the third inference above, suppose it were false.
** Then: z (z + 1/2 lsb(z)) < x <= (z +  1/2 lsb(z))^2.  The left hand side is
** some multiple of 1/2 lsb(z)^2.  The right hand side is only larger by
** d = 1/4 lsb(z)^2, so [rhs] = [rhs-d] = [lhs].  But the inequality implies
** [lhs] < x <= [rhs], and we have a contradiction.
**
** In conclusion,
**              z < {sqrt(x)}  <==>  [ z (z + 1/2 lsb(z)) ] < x.
','line_number':275,'multiline':True]['text':'
** Here we cover another question:  How closely must y approximate sqrt(x) to
** ensure {y} = {sqrt(x)}, where x is a representable number?  We state without
** proof that the closest sqrt(x) approaches a value halfway between consecutive
** representable numbers occurs either when x is just larger than a power of 4,
** or just less than a power of 4.  We have:
**
**	sqrt(4^k*(1+lsb( 1 ))) = 2^k*(1 + lsb( 1 )/2 - lsb( 1 )^2/8 + ...), and
**	sqrt(4^k*(1-lsb(1/2))  = 2^k*(1 - lsb(1/2)/2 - lsb(1/2)^2/8 - ...).
**
** So if |y - sqrt(x)| < lsb(sqrt(x))^2/8 - O(lsb^3), {y} = {sqrt(x)}.
** For our purposes, this means that 50-bit accuracy (barely) suffices to
** produce a correctly-rounded 24-bit result, since (2^(1-24))^2/8 = 2^(1-50).
** After our Newton's iteration, we have nearly 53-bit accuracy.  All is well.
','line_number':316,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':332,'multiline':True]['text':'			Computing 'x+' and 'x-'				      ','line_number':333,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':334,'multiline':True]['text':'
** For Tuckerman's rounding, we need to compute the (machine-)representable
** numbers just after and before a representable x: 'x+' = x + lsb(x) and
** 'x-' = x - lsb(x-lsb(x)).  Letting '{}' denote rounding to machine precision,
** we compute these by:
**
**	'x+' = {x + {c x}}			(1)
**	'x-' = {x - {c x}}			(2)
**
** for some appropriate constant c, where neither x+{c x} nor x-{c x} are midway
** between two consecutive representable numbers.
**
** The weakest preconditions that satisfy the above are:
**
**	1/2 lsb(x) < {c x} < 3/2 lsb(x)		(1a), when x != 2^n(1-lsb(1/2))
**	1/2 lsb(x) < {c x} <  2  lsb(x)		(1b), when x = 2^n(1-lsb(1/2))
**	1/2 lsb(x) < {c x} < 3/2 lsb(x)		(2a), when x != 2^n
**	1/4 lsb(x) < {c x} < 3/4 lsb(x)		(2b), when x = 2^n
**
** For (1a), (1b), and (2a), we can take:
**
**	1/2 lsb(x)/x < c < 3/2 lsb(x)/x, which we can 'shrink' to simplify:
** 	1/2 lsb(1)/1 < c < 3/2 lsb(1)/2
**	1/2 lsb(1) < c < 3/4 lsb(1)
**
** For (2b), we require:
**
**	1/4 lsb(1) < c < 3/4 lsb(1)
**
** Thus, in any case, we can use any c in the range:
**
**	1/2 lsb(1) < c < 3/4 lsb(1)
**
** We choose the midpoint:
**
**	c = 5/8 lsb(1) = 5/8 2^(1-p) = 5/4 2^(-p)
**
** FWIW: It's possibly to compute 'x-' by:	'x-' = {x * (1-lsb(1/2))},
** but 'x+' isn't necessarily computed by:	'x+' = {x * (1+lsb(1))}. 
','line_number':336,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':393,'multiline':True]['text':'			Newton's Iteration     				      ','line_number':394,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':395,'multiline':True]['text':'
    Newton's iteration for 1 / (nth root of x) is:

	y' = y + [ (1 - x * y^n) * y / n ]

    So, the iteration for 1 / sqrt(x) is:

	y' = y + [ (1 - x * y^2) * y * 0.5 ]

    If we want to do one iteration, multiply the result by x,
    and multiply the result by a scale factor we get:

	y' = scale   * x     * ( y + [ (1 - x * y^2) * y * 0.5 ] )
	y' = scale   * x * y * ( 1 + [ (1 - x * y^2) * 0.5 ] )
	y' = scale/2 * x * y * ( 2 + [ (1 - x * y^2) ] )        gives about 5/4 lsb error
	y' = scale/2 * x * y * ( 3 - x * y^2 )			gives about 8/4 lsb error

    So iterate to get better 1/sqrt(x) and multiply by x to get sqrt(x). 
','line_number':397,'multiline':True]['text':'
**  For quad precision, we need additional Newton's iterations.
**  For lower precisions, the iteration (if needed) is embedded
**  in the ITERATE_AND_MAYBE_CHECK_LAST_BIT macro.
','line_number':417,'multiline':True]['text':'
**  NEWTONS_ITERATION
**
**	Inputs:
**		scaled_x	any number
**			ignoring scaled_x <= 0
**
**		y		~= 1/sqrt(scaled_x)
**
**	Outputs:
**		y		~= 1/sqrt(scaled_x)
**			y becomes a better approximation
**
**	Temporaries:
**		a, b, c
','line_number':424,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':457,'multiline':True]['text':'			ITERATE_AND_MAYBE_CHECK_LAST_BIT		      ','line_number':458,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':459,'multiline':True]['text':' To make all arms 'elif's ','line_number':461,'multiline':True]['text':' Don't do a Newton's iteration ','line_number':464,'multiline':True]['text':' Don't do a Newton's iteration ','line_number':475,'multiline':True]['text':' This case is unlikely enough that we will worry about it
	when we need to (if ever).  There is code in older versions of
	sqrt that does a tuckermans rounding on single prec values.  ','line_number':485,'multiline':True]['text':' Make sure the last bit is correctly rounded by computing
	a double-precision result, and then rounding it to single.  ','line_number':493,'multiline':True]['text':' Do more accurate iteration (about 1 lsb error) ','line_number':507,'multiline':True]['text':' Do sloppy iteration (about 2 lsb error).
	y = (y * flah_scale) * (three - (y*scaled_x) * y) ','line_number':517,'multiline':True]['text':' Do sloppy iteration (about 2 lsb error).
	y = ((y*scaled_x) * half_scale) * (three - (y*scaled_x) * y) ','line_number':531,'multiline':True]['text':' Do more accurate iteration and check last bit.
	[ NB: we compute ulp = 2*ULP_FACTOR*c, because y ~= 2*c.] ','line_number':545,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':589,'multiline':True]['text':'                      The Function Itself!                                  ','line_number':590,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':591,'multiline':True]['text':' x is either 0 or negative   ','line_number':646,'multiline':True]['text':' must be positive denorm ','line_number':707,'multiline':True]['text':' Scale down again (up for RSQRT) ','line_number':725,'multiline':True]['text':' sqrt ','line_number':735,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':739,'multiline':True]['text':'                      MPHOC code to generate the table                      ','line_number':740,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':741,'multiline':True]['text':'
	** Print header information.
	','line_number':752,'multiline':True]['text':'
	** The definitions of SQRT_COEF_STRUCT and D_SQRT_TABLE_NAME also
	** appear in the code.
	','line_number':760,'multiline':True]['text':'
** Generate and print the polynomial coefficients.
','line_number':772,'multiline':True]['text':'
**  For each half fo the table, ...
','line_number':779,'multiline':True]['text':'
	** Determine a minimum-error quadratic approximation to
	** sqrt(xkk/x) in the range xa <= x <= xb.  (This doesn't
	** minimize the error after a Newton's iteration; that'd
	** require a weighting function of x^(1/4), a needless
	** complication for this single-precision approximation).
	','line_number':796,'multiline':True]['text':'
	** Now round the x^2 and x coefficients to single precision,
	** by subtracting Chebyshev polynomials.  The additional error
	** is negligible (less than 3%; e.g., if the polynomial was good to
	** 27 bits, it's degraded to only 27-log2(1.03) = 26.96 bits).
	**
	** The algebra is simplified by expressing the range xa..xb in terms of
	** the range's midpoint and radius.
	','line_number':809,'multiline':True]['text':'
	** The Chebyshev polynomials we subtract are multiples of:
	**
	**	w	  <->	(x-xm)/xr
	**	1-2*w^2	  <->	1-2*((x-xm)/xr)^2
	**
	** The x terms are collected, scaled (by t), and subtracted from the
	** polynomial coefficients.
	**
	** First we subtract (a multiple of) the 2nd degree Chebyshev polynomial
	** to produce a new polynomial with the desired (representable in single
	** precision) 2nd degree polynomial coefficient.  This minimizes the
	** maximum absolute error between the 'Remes' polynomial and the new
	** polynomial (since the difference is a Chebyshev polynomial, which
	** has the 'equal ripple' property).
	** 
	** Then we subtract (a multiple of) the 1st degree Chebyshev polynomial
	** to produce a new polynomial with the desired (representable in single
	** precision) 1st degree coefficient.  This minimizes the maximum
	** absolute error between the previous polynomial and the newer one
	** (under the constraints of having the same 2nd degree coefficient,
	** and the desired 1st degree coefficient).  The 0th degree coefficient
	** is rounded to double precision (somebody's got to!), and this has
	** no significant effect on the single precision result.
	**
	** Is the resulting polynomial optimal?  Nope; nobody claims it is.
	** Is it 'best' in some sense?  Yes -- the theory is clear and the code
	** is short (disregarding this phillipic).  Is it close enough?  Yep.
	** Why?  That's a good question....
	**
	** To see why this works, consider the polynomial for 1/sqrt(x) for
	** 1 <= x < 1+2^-7,
	**
	**	0.37... x^2 + -1.24... x + 1.87...
	**
	** Simply rounding the x coefficient to 24 bits may corrupt the result
	** of the polynomial by as much as (1+2^-7) * 0.5*s_lsb(1.24), where
	** s_lsb(z) = 2^floor(log2(|z|) + 1 - 24) is the value of z's least
	** significant bit when z is expressed in single precision.  This is
	** as much as 2^-24, which is 2*s_lsb(1/sqrt(x)) -- two single-precision
	** lsb of the result!  Rounding the x^2 coefficient has similar effects,
	** affecting the result by 1/2 single-precision lsb.  We can do better.
	**
	** If rounding increases the x coefficient by t, |t| <= 0.5*lsb(1.24),
	** the corruption can be partly compensated by adjusting the constant
	** coefficient, decreasing it by (for example) t*(1 + 1+2^-7)/2.
	** The corruption is then:
	**
	**	t*( x - (1+1+2^-7)/2 )
	**
	** Since 1 <= x < 1+2^-7, and |t| <= 0.5*lsb(1.24), we have:
	**
	**	| t*( x - (1+1+2^-7)/2 ) | <= 0.5*lsb(1.24) * 2^-8 = 2^(-24 -8)
	**
	** which is only 0.0078125*s_lsb(1/sqrt(x)) -- a factor of 256 smaller
	** than the corruption from simply rounding the x coefficient. 
	**
	** To minimize the (absolute value of the) maximum corruption, we add
	** a multiple of a Chebyshev polynomial, for the particular range of x,
	** because Chebyshev polynomials are 'minimax' (or 'equal ripple')
	** polynomials.
	** For the range -1 <= w <= 1, the Chebyshev polynomials are:
	**
	**	1,  w,  2*w^2-1,  4*w^3-3*w,  ....
	** 
	** To convert these to polynomials in x for the range a <= x <= b,
	** substitute (x-m)/r, with m = (b+a)/2, r = (b-a)/2, and z = m/r.
	** The Chebyshev polynomials become:
	**
	**	1, x/r - z, 2*(x/r)^2 - 4*z*(x/r) + 2*z^2-1,
	**	4*(x/r)^3 - 12*z*(x/r)^2 + (12*z^2-3)*(x/r) - 4*z^3+3*z, ....
	**
	** For 1 <= x < 1+2^-7, these are:
	**
	**	1, 2^8*x - (2^8+1), 2^17*x^2 - (2^18+2^10)*x + (2^17+2^10+1),
	**	2^26*x^3 - 3*(2^26+2^18)*x^2 + 3*(2^26+2^19+3*2^8)*x
	**			- (2^26+3*2^18+2^11+2^8+1), ....
	**
	** Each of these are 'equal ripple', oscillating between +/-1.  We see
	** our previous adjustment, ( x - (1+1+2^-7)/2 ), appear here with a
	** factor of 2^8.  Scaling it by t*2^-8 gives our previous result; this
	** scaling also reduces the 'ripple' to +/-t*2^-8.
	**
	** When we use the 2nd degree Chebyshev polynomial to round the 2nd
	** degree coefficient to single precision, we must scale the polynomial
	** by a factor of t*2^-17, where here |t| <= 0.5*lsb(0.37).  This means
	** that the effect of this corruption, the size of the 'ripple', is less
	** than 0.5*lsb(0.37)*2^-17 = 2^-43, or 2^-18*s_lsb(1/sqrt(x)).  This is
	** far better than the the 1/2 lsb we got when we simply rounded the x^2
	** coefficient.
	** 
	** Can this technique be applied to other polynomial coefficients?
	** It is an invention of my own conception developed outside the term
	** of my contract, and for which I've received no compensation.
	','line_number':821,'multiline':True]['text':'
	** Print the trailer.
	','line_number':930,'multiline':True]['text':' MAKE_INCLUDE ','line_number':945,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':948,'multiline':True]['text':'                              Testing                                       ','line_number':949,'multiline':True]['text':'----------------------------------------------------------------------------','line_number':950,'multiline':True]['text':' MAKE_MTC ','line_number':1112,'multiline':True]