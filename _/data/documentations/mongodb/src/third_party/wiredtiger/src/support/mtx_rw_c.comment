['text':'-
 * Public Domain 2014-present MongoDB, Inc.
 * Public Domain 2008-2014 WiredTiger, Inc.
 *
 * This is free and unencumbered software released into the public domain.
 *
 * Anyone is free to copy, modify, publish, use, compile, sell, or
 * distribute this software, either in source code form or as a compiled
 * binary, for any purpose, commercial or non-commercial, and by any
 * means.
 *
 * In jurisdictions that recognize copyright laws, the author or authors
 * of this software dedicate any and all copyright interest in the
 * software to the public domain. We make this dedication for the benefit
 * of the public at large and to the detriment of our heirs and
 * successors. We intend this dedication to be an overt act of
 * relinquishment in perpetuity of all present and future rights to this
 * software under copyright law.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR
 * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
 * OTHER DEALINGS IN THE SOFTWARE.
 ','line_number':1,'multiline':True]['text':'
 * Inspired by "Spinlocks and Read-Write Locks" by Dr. Steven Fuerst:
 *	http://locklessinc.com/articles/locks/
 *
 * Dr. Fuerst further credits:
 *	There exists a form of the ticket lock that is designed for read-write
 * locks. An example written in assembly was posted to the Linux kernel mailing
 * list in 2002 by David Howells from RedHat. This was a highly optimized
 * version of a read-write ticket lock developed at IBM in the early 90's by
 * Joseph Seigh. Note that a similar (but not identical) algorithm was published
 * by John Mellor-Crummey and Michael Scott in their landmark paper "Scalable
 * Reader-Writer Synchronization for Shared-Memory Multiprocessors".
 *
 * The following is an explanation of our interpretation and implementation.
 * First, the underlying lock structure.
 *
 * volatile union {
 *	uint64_t v;				// Full 64-bit value
 *	struct {
 *		uint8_t current;		// Current ticket
 *		uint8_t next;			// Next available ticket
 *		uint8_t reader;			// Read queue ticket
 *		uint8_t readers_queued;		// Count of queued readers
 *		uint32_t readers_active;	// Count of active readers
 *	} s;
 * } u;
 *
 * First, imagine a store's 'take a number' ticket algorithm. A customer takes
 * a unique ticket number and customers are served in ticket order. In the data
 * structure, 'next' is the ticket that will be allocated next, and 'current'
 * is the ticket being served.
 *
 * Next, consider exclusive (write) locks.  To lock, 'take a number' and wait
 * until that number is being served; more specifically, atomically increment
 * 'next', and then wait until 'current' equals that allocated ticket.
 *
 * Shared (read) locks are similar, except that readers can share a ticket
 * (both with each other and with a single writer).  Readers with a given
 * ticket execute before the writer with that ticket.  In other words, writers
 * wait for both their ticket to become current and for all readers to exit
 * the lock.
 *
 * If there are no active writers (indicated by 'current' == 'next'), readers
 * can immediately enter the lock by atomically incrementing 'readers_active'.
 * When there are writers active, readers form a new queue by first setting
 * 'reader' to 'next' (i.e. readers are scheduled after any queued writers,
 * avoiding starvation), then atomically incrementing 'readers_queued'.
 *
 * We limit how many readers can queue: we don't allow more readers to queue
 * than there are active writers (calculated as `next - current`): otherwise,
 * in write-heavy workloads, readers can keep queuing up in front of writers
 * and throughput is unstable.  The remaining read requests wait without any
 * ordering.
 *
 * The 'next' field is a 1-byte value so the available ticket number wraps
 * after 256 requests. If a thread's write lock request would cause the 'next'
 * field to catch up with 'current', instead it waits to avoid the same ticket
 * being allocated to multiple threads.
 ','line_number':29,'multiline':True]['text':'
 * __wt_rwlock_init --
 *     Initialize a read/write lock.
 ','line_number':91,'multiline':True]['text':'
 * __wt_rwlock_destroy --
 *     Destroy a read/write lock.
 ','line_number':107,'multiline':True]['text':'
 * __wt_try_readlock --
 *     Try to get a shared lock, fail immediately if unavailable.
 ','line_number':120,'multiline':True]['text':' This read lock can only be granted if there are no active writers. ','line_number':138,'multiline':True]['text':'
     * The replacement lock value is a result of adding an active reader. Check for overflow: if the
     * maximum number of readers are already active, no new readers can enter the lock.
     ','line_number':142,'multiline':True]['text':' We rely on this atomic operation to provide a barrier. ','line_number':150,'multiline':True]['text':'
 * __read_blocked --
 *     Check whether the current read lock request should keep waiting.
 ','line_number':154,'multiline':True]['text':'
 * __wt_readlock --
 *     Get a shared lock.
 ','line_number':164,'multiline':True]['text':'
         * Fast path: if there is no active writer, join the current group.
         ','line_number':183,'multiline':True]['text':'
             * Check for overflow: if the maximum number of readers are already active, no new
             * readers can enter the lock.
             ','line_number':188,'multiline':True]['text':'
         * There is an active writer: join the next group.
         *
         * Limit how many readers can queue: don't allow more readers
         * to queue than there are active writers (calculated as
         * `next - current`): otherwise, in write-heavy workloads,
         * readers can keep queuing up in front of writers and
         * throughput is unstable.
         *
         * If the maximum allowed number of readers are already queued or there is a
         * potential overflow, wait until we can get a valid ticket.
         ','line_number':199,'multiline':True]['text':'
         * If we are the first reader to queue, set the next read group. Note: don't re-read from
         * the lock or we could race with a writer unlocking.
         ','line_number':218,'multiline':True]['text':' Wait for our group to start. ','line_number':231,'multiline':True]['text':'
         * Not all read-write locks increment session statistics. Check whether the offset is
         * initialized to determine whether they are enabled.
         ','line_number':257,'multiline':True]['text':'
     * Applications depend on a barrier here so that operations holding the lock see consistent
     * data. The atomic operation above isn't sufficient here because we don't own the lock until
     * our ticket comes up and whatever data we are protecting may have changed in the meantime.
     ','line_number':265,'multiline':True]['text':' Sanity check that we (still) have the lock. ','line_number':272,'multiline':True]['text':'
 * __wt_readunlock --
 *     Release a shared lock.
 ','line_number':276,'multiline':True]['text':'
         * Decrement the active reader count (other readers are doing the same, make sure we don't
         * race).
         ','line_number':289,'multiline':True]['text':'
 * __wt_try_writelock --
 *     Try to get an exclusive lock, fail immediately if unavailable.
 ','line_number':301,'multiline':True]['text':'
     * This write lock can only be granted if no readers or writers blocked on the lock, that is, if
     * this thread's ticket would be the next ticket granted. Check if this can possibly succeed
     * (and confirm the lock is in the correct state to grant this write lock).
     ','line_number':317,'multiline':True]['text':'
     * We've checked above that there is no writer active (since
     * `current == next`), so there should be no readers queued.
     ','line_number':326,'multiline':True]['text':'
     * The replacement lock value is a result of allocating a new ticket.
     *
     * We rely on this atomic operation to provide a barrier.
     ','line_number':332,'multiline':True]['text':'
 * __write_blocked --
 *     Check whether the current write lock request should keep waiting.
 ','line_number':342,'multiline':True]['text':'
 * __wt_writelock --
 *     Wait to get an exclusive lock.
 ','line_number':355,'multiline':True]['text':' Allocate a ticket. ','line_number':373,'multiline':True]['text':'
         * Check for overflow: if the next ticket is allowed to catch up with the current batch, two
         * writers could be granted the lock simultaneously.
         ','line_number':377,'multiline':True]['text':'
     * Wait for our group to start and any readers to drain.
     *
     * We take care here to do an atomic read of the full 64-bit lock value. Otherwise, reads are
     * not guaranteed to be ordered and we could see no readers active from a different batch and
     * decide that we have the lock.
     ','line_number':389,'multiline':True]['text':'
         * Not all read-write locks increment session statistics. Check whether the offset is
         * initialized to determine whether they are enabled.
         ','line_number':422,'multiline':True]['text':'
     * Applications depend on a barrier here so that operations holding the lock see consistent
     * data. The atomic operation above isn't sufficient here because we don't own the lock until
     * our ticket comes up and whatever data we are protecting may have changed in the meantime.
     ','line_number':430,'multiline':True]['text':' Sanity check that we (still) have the lock. ','line_number':437,'multiline':True]['text':'
 * __wt_writeunlock --
 *     Release an exclusive lock.
 ','line_number':441,'multiline':True]['text':'
         * We're holding the lock exclusive, there shouldn't be any active readers.
         ','line_number':453,'multiline':True]['text':'
         * Allow the next batch to start.
         *
         * If there are readers in the next group, swap queued readers to active: this could race
         * with new readlock requests, so we have to spin.
         ','line_number':458,'multiline':True]['text':'
 * __wt_rwlock_islocked --
 *     Return if a read/write lock is currently locked for reading or writing.
 ','line_number':479,'multiline':True]