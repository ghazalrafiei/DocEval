['text':'-
 * Copyright (c) 2014-present MongoDB, Inc.
 * Copyright (c) 2008-2014 WiredTiger, Inc.
 *	All rights reserved.
 *
 * See the file LICENSE for redistribution information.
 ','line_number':1,'multiline':True]['text':'
 * __rec_col_fix_bulk_insert_split_check --
 *     Check if a bulk-loaded fixed-length column store page needs to split.
 ','line_number':11,'multiline':True]['text':'
             * If everything didn't fit, update the counters and split.
             *
             * Boundary: split or write the page.
             *
             * No need to have a minimum split size boundary, all pages are filled 100% except the
             * last, allowing it to grow in the future.
             ','line_number':28,'multiline':True]['text':'
 * __wt_bulk_insert_fix --
 *     Fixed-length column-store bulk insert.
 ','line_number':48,'multiline':True]['text':'
     * Initialize the time aggregate that's going into the parent page. It's necessary to update an
     * aggregate at least once if it's been initialized for merging, or it will fail validation.
     * Also, it should reflect the fact that we've just loaded a batch of stable values.
     ','line_number':70,'multiline':True]['text':'
 * __wt_bulk_insert_fix_bitmap --
 *     Fixed-length column-store bulk insert.
 ','line_number':80,'multiline':True]['text':' Initialize the time aggregate that's going into the parent page. See note above. ','line_number':112,'multiline':True]['text':'
 * __wt_bulk_insert_var --
 *     Variable-length column-store bulk insert.
 ','line_number':118,'multiline':True]['text':'
         * Store the bulk cursor's last buffer, not the current value, we're tracking duplicates,
         * which means we want the previous value seen, not the current value.
         ','line_number':141,'multiline':True]['text':' Boundary: split or write the page. ','line_number':148,'multiline':True]['text':' Copy the value onto the page. ','line_number':152,'multiline':True]['text':' Initialize the time aggregate that's going into the parent page. See note above. ','line_number':157,'multiline':True]['text':' Update the starting record number in case we split. ','line_number':160,'multiline':True]['text':'
 * __rec_col_merge --
 *     Merge in a split page.
 ','line_number':166,'multiline':True]['text':' For each entry in the split array... ','line_number':183,'multiline':True]['text':' Update the starting record number in case we split. ','line_number':185,'multiline':True]['text':' Build the value cell. ','line_number':188,'multiline':True]['text':' Boundary: split or write the page. ','line_number':192,'multiline':True]['text':' Copy the value onto the page. ','line_number':196,'multiline':True]['text':'
 * __wt_rec_col_int --
 *     Reconcile a column-store internal page.
 ','line_number':203,'multiline':True]['text':' For each entry in the in-memory page... ','line_number':233,'multiline':True]['text':' Update the starting record number in case we split. ','line_number':235,'multiline':True]['text':'
         * Modified child. The page may be emptied or internally created during a split.
         * Deleted/split pages are merged into the parent and discarded.
         ','line_number':238,'multiline':True]['text':' Ignored child. ','line_number':249,'multiline':True]['text':'
             * Modified child. Empty pages are merged into the parent and discarded.
             ','line_number':254,'multiline':True]['text':' Original child. ','line_number':273,'multiline':True]['text':' Deleted child where we write a proxy cell. ','line_number':276,'multiline':True]['text':'
         * Build the value cell. The child page address is in one of 3 places: if the page was
         * replaced, the page's modify structure references it and we assigned it just above in the
         * switch statement. Otherwise, the WT_REF->addr reference points to either an on-page cell
         * or an off-page WT_ADDR structure: if it's an on-page cell we copy it from the page, else
         * build a new cell.
         ','line_number':281,'multiline':True]['text':'
                 * Need to build a proxy (page-deleted) cell or rebuild the cell with updated time
                 * info.
                 ','line_number':296,'multiline':True]['text':' Copy the entire existing cell, including any page-delete information. ','line_number':303,'multiline':True]['text':' Boundary: split or write the page. ','line_number':315,'multiline':True]['text':' Copy the value (which is in val, val == r->v) onto the page. ','line_number':319,'multiline':True]['text':' Write the remnant page. ','line_number':327,'multiline':True]['text':'
 * __wt_col_fix_estimate_auxiliary_space --
 *     Estimate how much on-disk auxiliary space a fixed-length column store page will need.
 ','line_number':335,'multiline':True]['text':'
     * Iterate both the update and append lists to count the number of possible time windows. This
     * isn't free, but it's likely a win if it can avoid having to reallocate the write buffer in
     * the middle of reconciliation.
     *
     ','line_number':347,'multiline':True]['text':' Add in the existing time windows. ','line_number':358,'multiline':True]['text':'
     * Each time window record is two cells and might take up as much as 63 bytes:
     *     - 1: key cell descriptor byte
     *     - 5: key (32-bit recno offset)
     *     - 1: value cell descriptor byte
     *     - 1: value cell time window descriptor byte
     *     - 36: up to 4 64-bit timestamps
     *     - 18: up to 2 64-bit transaction ids
     *     - 1: zero byte for value length
     *     - 0: value
     *
     * For now, allocate enough space to hold a maximal cell pair for each possible time window.
     * This is perhaps too pessimistic. Also include the reservation for header space, since the
     * downstream code counts that in the auxiliary space.
     ','line_number':362,'multiline':True]['text':'
 * __rec_col_fix_get_bitmap_size --
 *     Figure the bitmap size of a new page from the reconciliation info.
 ','line_number':380,'multiline':True]['text':' Figure the size of the primary part of the page by subtracting off the header. ','line_number':389,'multiline':True]['text':' Subtract off the main page header. ','line_number':392,'multiline':True]['text':'
 * __wt_rec_col_fix_addtw --
 *     Create a fixed-length column store time window cell and add it to the new page image.
 ','line_number':396,'multiline':True]['text':' Pack the key. ','line_number':415,'multiline':True]['text':' Pack the value, which is empty, but with a time window. ','line_number':423,'multiline':True]['text':' Figure how much space we need, and reallocate the page if about to run out. ','line_number':426,'multiline':True]['text':'
         * Reallocate the page. Increase the size by 1/3 of the auxiliary space. This is arbitrary,
         * but chosen on purpose (instead of just doubling the size of the page image, which is the
         * usual thing to do) because we already made a generous estimate of the required auxiliary
         * space, and if we don't fit it's probably because a few extra updates happened, not
         * because a huge amount more time window data suddenly appeared. Use a fraction of the
         * current space to avoid adverse asymptotic behavior if a lot of stuff _did_ appear, but
         * not a huge one to avoid wasting memory.
         ','line_number':429,'multiline':True]['text':' Just in case. ','line_number':439,'multiline':True]['text':' Copy both cells onto the page. This counts as one entry. ','line_number':445,'multiline':True]['text':' If we're on key 3 we should have just written at most the 4th time window. ','line_number':451,'multiline':True]['text':'
 * __wt_rec_col_fix --
 *     Reconcile a fixed-width, column-store leaf page.
 ','line_number':457,'multiline':True]['text':'
     * Blank the unpack record in case we need to use it before unpacking anything into it. The
     * visibility code currently only uses the value and the time window, and asserts about the
     * type, but that could change so be careful.
     ','line_number':478,'multiline':True]['text':' Track the start of the current page we're working on. Changes when we split. ','line_number':486,'multiline':True]['text':' Also check where the disk image starts, which might be different in salvage. ','line_number':488,'multiline':True]['text':'
     * The configured max leaf page size is the size of the bitmap data on the page, not including
     * the time window data. The actual page size is (often) larger. Estimate how much more space we
     * need. This isn't a guarantee (more inserts can happen while we're working) but it should
     * avoid needing to reallocate the page buffer in the common case.
     *
     * Do this before fiddling around with the salvage logic so the latter can make sure the page
     * size doesn't try to grow past 2^32.
     ','line_number':491,'multiline':True]['text':'
     * The salvage code may have found overlapping ranges in the key namespace, in which case we're
     * given (a) either a count of missing entries to write at the beginning of the page or a count
     * of existing entries to skip over at the start of the page, and (b) a count of the number of
     * entries to take from the page.
     *
     * In theory we shouldn't ever get pages with overlapping key ranges, even during salvage.
     * Because all the pages are the same size, they should always begin at the same recnos,
     * regardless of what might have happened at runtime.
     *
     * In practice this is not so clear; there are at least three ways that odd-sized pages can
     * appear (and it's possible that more might be added in the future) and once that happens, it
     * can happen differently on different runs and lead to overlapping key ranges detected during
     * salvage. (Because pages are never merged once written, in order to get overlapping ranges of
     * keys in VLCS one must also be seeing the results of different splits on different runs, so
     * such scenarios are within the scope of what salvage needs to handle.)
     *
     * First, odd-sized pages can be generated by in-memory (append) splits. These do not honor the
     * configured page size and are based on in-memory size estimates, which in FLCS are quite
     * different from on-disk sizes. The resulting sizes can be completely arbitrary. Note that even
     * if things are changed to keep this from happening in the future, it has been this way for a
     * long time so it's reasonable to assume that in general any deployed database with an FLCS
     * column can already have odd-sized pages in it.
     *
     * Second, it isn't clear that we prevent the user from changing the configured leaf_page_max
     * after there are already pages in the database, nor is it clear that we should; if this were
     * to happen we'll then have pages of multiple sizes. This is less likely to generate
     * overlapping ranges, but it isn't impossible, especially in conjunction with the next case.
     *
     * Third, because at salvage time we account for missing key ranges by writing larger pages and
     * splitting them again later, as described below, if there are odd-sized pages before salvage,
     * running salvage can shift around where the page boundaries are. Thus on a subsequent salvage
     * run, overlaps that wouldn't otherwise be possible can manifest.
     *
     * For these reasons, and because we don't want to have to refit the code later if more reasons
     * appear, and because it doesn't cost much, we do check for overlapping ranges during salvage
     * (this doesn't even require additional code because the column-store internal pages are the
     * same for VLCS and FLCS) and handle it here.
     ','line_number':502,'multiline':True]['text':' We should not already be done. ','line_number':542,'multiline':True]['text':' We shouldn't both have missing records to insert and records to skip. ','line_number':545,'multiline':True]['text':' If there's a page, we shouldn't have been asked for more than was already on the page. ','line_number':548,'multiline':True]['text':' Allow us to be called without a disk page, to generate a fresh page of missing items. ','line_number':551,'multiline':True]['text':'
         * The upstream code changed the page start "for" us; assert things are as expected. That
         * is: it should have been adjusted either down by the missing count or up by the skip
         * count. Skip if there's no disk image since in that case there's no original start. Under
         * normal circumstances salvage will always have a disk image, since that's the point, but
         * this code is deliberately written so salvage can ask it to generate fresh pages of zeros
         * to help populate missing ranges of the key space, and if code for that ever appears it
         * won't have a disk image to pass.
         ','line_number':555,'multiline':True]['text':'
         * Compute how much space we need for the resulting bitmap data.
         *
         * This may be vastly greater than the intended maximum page size. If a page gets corrupted
         * and is thus lost, its entire key range will be missing, and on the next page we'll be
         * asked to fill in those keys. In fact, if a series of pages goes missing, all the dropped
         * keys will appear in salvage->missing on the next keys. So salvage->missing may be not
         * only greater than the maximum page size but a multiple of it. Since we cannot split
         * during salvage, and unlike VLCS we have no compact representation for a large range of
         * deleted keys, if this happens the only possible approach is to create a monster page,
         * write it out, and live with it, since it also currently isn't possible to re-split it
         * later once it's been created.
         *
         * FUTURE: I've intentionally written the code here to allow the upstream code to
         * manufacture empty new pages and reconcile each of them with salvage->missing equal to the
         * intended items per page, instead of asking us to produce monster pages, since doing so
         * was cheap. Whether doing this in the upstream code is feasible or not I dunno, but it's
         * perhaps worth looking into.
         *
         * FUTURE: Alternatively, when we get fast-delete support for column store it is reasonable
         * to teach the upstream code to produce fast-delete entries for whole missing pages rather
         * than have us materialize all the zeros.
         *
         * In principle if we have a small number of entries to take, we could generate a small page
         * rather than allocating the full size. At least for the moment this won't work because we
         * assume elsewhere that any small page might be appended to.
         ','line_number':568,'multiline':True]['text':' Salvage is the backup plan: don't let this fail. ','line_number':598,'multiline':True]['text':' Under ordinary circumstances the bitmap size is the configured maximum page size. ','line_number':610,'multiline':True]['text':' If not in salvage, there should be no shenanigans with the page start. ','line_number':613,'multiline':True]['text':'
         * In theory the page could have been generated by a prior salvage run and be oversized. If
         * so, preserve the size. In principle such pages should be split, but the logic below does
         * not support that and I don't want to complicate it just to support this (very marginal)
         * case.
         ','line_number':616,'multiline':True]['text':' Remember where we are. ','line_number':628,'multiline':True]['text':' If salvage wants us to insert entries, do that. ','line_number':632,'multiline':True]['text':'
         * Now copy the entries from the page data. We could proceed one at a time until we reach
         * byte-alignment and then memcpy, but don't do that, on the grounds that it would be easy
         * to get the code wrong and hard to test it.
         ','line_number':639,'multiline':True]['text':' Copy the original, disk-image bytes into place. ','line_number':650,'multiline':True]['text':' Remember how far we can go before the end of page. ','line_number':656,'multiline':True]['text':'
     * Iterate over the data items on the page. We need to go through both the insert list and the
     * timestamp index together, to make sure that if we have an update for an item that also has a
     * time window in the existing on-disk page we write out at most one time window and it's the
     * one from the update. (Also, we want the keys to come out in order.)
     *
     * Note that if we're in salvage, we might be changing the page's start recno. This makes the
     * offset computations complicated: offsets from the old page are relative to the old page start
     * (origstartrecno, which came from the disk image) and offsets from the new page are relative
     * to the new page start, which is curstartrecno. (And also ref->recno, but we don't use the
     * latter in case anyone wants to rewrite this code to split in the middle of the existing
     * bitmap.)
     *
     * So for time windows, when reading compute the absolute recno by adding the old page start,
     * and recompute it against the new page start when writing. (Note that at this point we can't
     * have split yet, so these are the same if we aren't in salvage, but if we changed things so
     * that we could, this would still be the correct computation.)
     *
     * Apply the bitmap data changes from the update too, of course.
     *
     * Note: origstartrecno is not valid if there is no prior disk image, but in that case there
     * will also be no time windows, and also nothing in the update (rather than insert) list.
     ','line_number':659,'multiline':True]['text':' Salvage wanted us to skip some records. Skip their time windows too. ','line_number':687,'multiline':True]['text':' Update for skipped item. Shouldn't happen, but just in case it does, skip it. ','line_number':697,'multiline':True]['text':' Copy in all the preexisting time windows for keys before this one. ','line_number':700,'multiline':True]['text':' Get the previous time window so as to copy it. ','line_number':702,'multiline':True]['text':' Clear the on-disk cell time window if it is obsolete. ','line_number':706,'multiline':True]['text':'
             * The checks in unpack and clear_obsolete do not handle obsolete stop times; we need to
             * do that explicitly because we need to act on it. So there are three cases: (a) the
             * value has a globally visible stop time, in which case we should delete the value and
             * drop the time window; (b) the time window may have changed but remains nonempty, in
             * which case we leave the value and write the time window to the new page; or (c) the
             * time window has become empty, in which case we leave the value and drop the time
             * window, which amounts to doing nothing at all.
             ','line_number':709,'multiline':True]['text':'
         * Fake up an unpack record to pass to update selection; it needs to have the current
         * on-disk value and its timestamp, if any, and it also needs to be tagged as a value cell.
         * This is how that value gets into the history store if that's needed.
         ','line_number':730,'multiline':True]['text':' Get the on-disk time window by unpacking the value cell. ','line_number':736,'multiline':True]['text':' Fake up a value cell with a default time window. ','line_number':740,'multiline':True]['text':'
         * Stick in the current on-disk value. We can't use __bit_getv_recno here because it
         * implicitly uses pageref->ref_recno to figure the offset; that's wrong if salvage has
         * changed the page origin.
         ','line_number':745,'multiline':True]['text':'
             * It apparently used to be possible to get back no update but a nonempty time window to
             * apply to the current on-disk value. As of Oct. 2021 this is no longer the case;
             * instead we get back an update with a copy of the current on-disk value. In case of
             * future changes, assert that there's nothing to do.
             ','line_number':758,'multiline':True]['text':' If there's an update to apply, apply the value. ','line_number':768,'multiline':True]['text':' Do not write a time window; if we get just a tombstone, it is globally visible. ','line_number':772,'multiline':True]['text':' MODIFY is not allowed in FLCS. ','line_number':774,'multiline':True]['text':' Write the time window. ','line_number':778,'multiline':True]['text':'
         * When a tombstone without a timestamp is written to disk, remove any historical versions
         * that are greater in the history store for this key.
         ','line_number':785,'multiline':True]['text':' Write the data. ','line_number':793,'multiline':True]['text':' If there was an entry in the time windows index for this key, skip over it. ','line_number':796,'multiline':True]['text':' We should never see an update off the end of the tree. Those should be inserts. ','line_number':800,'multiline':True]['text':' Copy all the remaining time windows, if any. ','line_number':804,'multiline':True]['text':' Get the old page's time window so as to copy it. ','line_number':806,'multiline':True]['text':' This time window is for an item salvage wants us to skip. ','line_number':812,'multiline':True]['text':' Clear the on-disk cell time window if it is obsolete. ','line_number':815,'multiline':True]['text':' These cases are the same as the corresponding ones above. ','line_number':818,'multiline':True]['text':'
     * Figure out how much more space is left. This is how many more entries will fit in the bitmap
     * data. We have to accommodate the auxiliary data for those entries, even if it becomes large.
     * We can't split based on the auxiliary image size, at least not without a major rewrite.
     ','line_number':828,'multiline':True]['text':' Walk any append list. ','line_number':836,'multiline':True]['text':'
             * If the page split, instantiate any missing records in
             * the page's name space. (Imagine record 98 is
             * transactionally visible, 99 wasn't created or is not
             * yet visible, 100 is visible. Then the page splits and
             * record 100 moves to another page. When we reconcile
             * the original page, we write record 98, then we don't
             * see record 99 for whatever reason. If we've moved
             * record 100, we don't know to write a deleted record
             * 99 on the page.)
             *
             * The record number recorded during the split is the
             * first key on the split page, that is, one larger than
             * the last key on this page, we have to decrement it.
             *
             * Assert that we haven't already overrun the split; that is,
             * r->recno (the next key to write) should not be greater.
             ','line_number':839,'multiline':True]['text':'
             * The following loop assumes records to write, and the previous key might have been
             * visible. If so, we had r->recno == recno before the decrement.
             ','line_number':863,'multiline':True]['text':' Make sure not to apply an uninitialized time window, or one from another key. ','line_number':870,'multiline':True]['text':' Initialize the selected update. ','line_number':873,'multiline':True]['text':' We shouldn't ever get appends during salvage. ','line_number':876,'multiline':True]['text':'
             * Currently __wt_col_modify assumes that all restored updates are updates rather than
             * appends. Therefore, if we see an invisible update, we need to write a value under it
             * (instead of just skipping by) -- otherwise, when it's restored after reconciliation
             * is done, __wt_col_modify mishandles it. Fixing __wt_col_modify to handle restored
             * appends appears to be straightforward (and would reduce the tendency of the end of
             * the tree to move around nontransactionally) but is not on the critical path, so I'm
             * not going to do it for now. But in principle we can check here for a null update and
             * continue to the next insert entry.
             ','line_number':882,'multiline':True]['text':'
             * The application may have inserted records which left gaps in the name space. Note:
             * nrecs is the number of bitmap entries left on the page.
             ','line_number':894,'multiline':True]['text':' There's still space; write the inserted value. ','line_number':902,'multiline':True]['text':'
                     * If there's no update because we had no insert list and we're filling in at
                     * the end of an in-memory split, write a globally visible zero with no time
                     * window. Similarly, if there are only aborted or invisible updates for this
                     * key (the insert list exists but the visibility code gave us no update to
                     * write), don't write a time window. And, if we get just a tombstone back from
                     * visibility, that means a globally visible deleted value. There might be a
                     * nonempty window in upd_select.tw, but we're supposed to ignore it.
                     ','line_number':905,'multiline':True]['text':' MODIFY is not allowed in FLCS, so the update must be an ordinary value. ','line_number':916,'multiline':True]['text':'
                 * When a tombstone without a timestamp is written to disk, remove any historical
                 * versions that are greater in the history store for this key.
                 ','line_number':924,'multiline':True]['text':'
             * If everything didn't fit, update the counters and split.
             *
             * Boundary: split or write the page.
             *
             * No need to have a minimum split size boundary, all pages are filled 100% except the
             * last, allowing it to grow in the future.
             ','line_number':939,'multiline':True]['text':' If there are entries we didn't write timestamps for, aggregate a stable timestamp. ','line_number':949,'multiline':True]['text':' Make sure the trailing bits in the bitmap get cleared. ','line_number':955,'multiline':True]['text':' Now split. ','line_number':959,'multiline':True]['text':' (Re)calculate the number of entries per page. ','line_number':962,'multiline':True]['text':'
         * Execute this loop once without an insert item to catch any missing records due to a
         * split, then quit.
         ','line_number':968,'multiline':True]['text':' Update the counters. ','line_number':976,'multiline':True]['text':'
     * If there are entries we didn't write timestamps for, aggregate in a stable timestamp. Do this
     * when there are no entries too, just in case that happens. Otherwise the aggregate, which was
     * initialized for merging, will fail validation if nothing's been merged into it.
     ','line_number':979,'multiline':True]['text':' Make sure the trailing bits in the bitmap get cleared. ','line_number':989,'multiline':True]['text':' Write the remnant page. ','line_number':992,'multiline':True]['text':'
 * __wt_rec_col_fix_write_auxheader --
 *     Write the auxiliary header into the page image.
 ','line_number':999,'multiline':True]['text':'
     * Encoding the offset should fit -- either it is less than what encodes to 1 byte or greater
     * than or equal to the maximum header size. This works out to asserting that the latter is less
     * than the maximum 1-byte-encoded integer. That in turn is a static condition.
     *
     * This in turn guarantees that the pack calls cannot fail.
     ','line_number':1011,'multiline':True]['text':' only used in DIAGNOSTIC ','line_number':1021,'multiline':True]['text':'
     * Compute some positions.
     *
     * If the page is full, or oversized, the page contents are as follows:
     *    - the page header
     *    - the bitmap data
     *    - the auxiliary header
     *    - the auxiliary data
     *
     * If the page is not full, the page contents are as follows:
     *    - the page header
     *    - the bitmap data
     *    - the auxiliary header
     *    - some waste space
     *    - the auxiliary data
     *
     * During normal operation we don't know if the page will be full or not; if it isn't already
     * full this depends on the append list, but we can only iterate the append list once (for
     * atomicity) and we need to start writing auxiliary data before we get to that point.
     *
     * Therefore, we always begin the page assuming the primary data will be a full page, and write
     * the auxiliary data in the proper position for that. If the page ends up not full, there is a
     * gap. We always write the auxiliary header immediately after the bitmap data, so we can find
     * it easily when we read the page back in; the gap thus appears between the auxiliary header
     * and the auxiliary data.
     *
     * (FUTURE: if the auxiliary data is small we could memmove it; this isn't free, but might be
     * cheaper than writing out the waste space and then reading it back in. Note that in an ideal
     * world only the last page in the tree is short, so the waste is limited, but currently there
     * are also other ways for odd-sized pages to appear.)
     *
     * Salvage needs to be able to write out oversized pages, and then once that happens currently
     * they can't be split again later. For these pages we know what the bitmap size will be
     * (because there are no appends during salvage, and if we see appends to an oversize page at
     * some later point we aren't going to grow the page and they'll go on the next one) so we can
     * always put the auxiliary data in the right place up front.
     *
     * However, this means that we should not assume the bitmap size is given by the btree maximum
     * leaf page size but get it from the reconciliation info.
     *
     * Note: it is important to use *this* chunk's auxiliary start offset (passed in) and not read
     * the auxiliary start offset from the WT_RECONCILE, as we may be writing the previous chunk and
     * the latter describes the current chunk.
     ','line_number':1025,'multiline':True]['text':' Figure how much primary data we have. ','line_number':1070,'multiline':True]['text':' The auxiliary header goes after the bitmap, which goes after the page header. ','line_number':1073,'multiline':True]['text':' This should also have left sufficient room for the header. ','line_number':1076,'multiline':True]['text':'
     * If there is no auxiliary data, we will have already shortened the image size to discard the
     * auxiliary section and the auxiliary section should be past the end. In this case, skip the
     * header. This writes a page compatible with earlier versions. On odd-sized pages, e.g. the
     * last page in the tree, this also avoids the space wastage described above.
     ','line_number':1079,'multiline':True]['text':' The offset we're going to write is the distance from the header start to the data. ','line_number':1090,'multiline':True]['text':' Zero the empty space, if any. ','line_number':1101,'multiline':True]['text':'
 * __rec_col_var_helper --
 *     Create a column-store variable length record cell and write it onto a page.
 ','line_number':1107,'multiline':True]['text':'
     * Occasionally, salvage needs to discard records from the beginning or end of the page, and
     * because the items may be part of a RLE cell, do the adjustments here. It's not a mistake we
     * don't bother telling our caller we've handled all the records from the page we care about,
     * and can quit processing the page: salvage is a rare operation and I don't want to complicate
     * our caller's loop.
     ','line_number':1124,'multiline':True]['text':' Boundary: split or write the page. ','line_number':1169,'multiline':True]['text':' Copy the value onto the page. ','line_number':1173,'multiline':True]['text':' Update the starting record number in case we split. ','line_number':1179,'multiline':True]['text':'
 * __wt_rec_col_var --
 *     Reconcile a variable-width column-store leaf page.
 ','line_number':1185,'multiline':True]['text':' Value ','line_number':1195,'multiline':True]['text':' If deleted ','line_number':1197,'multiline':True]['text':' Set the "last" values to cause failure if they're not set. ','line_number':1230,'multiline':True]['text':'
     * The salvage code may be calling us to reconcile a page where there were missing records in
     * the column-store name space. If taking the first record from on the page, it might be a
     * deleted record, so we have to give the RLE code a chance to figure that out. Else, if not
     * taking the first record from the page, write a single element representing the missing
     * records onto a new page. (Don't pass the salvage cookie to our helper function in this case,
     * we're handling one of the salvage cookie fields on our own, and we don't need the helper
     * function's assistance.)
     ','line_number':1240,'multiline':True]['text':'
             * Correct the number of records we're going to "take", pretending the missing records
             * were on the page.
             ','line_number':1255,'multiline':True]['text':'
     * We track two data items through this loop: the previous (last) item and the current item: if
     * the last item is the same as the current item, we increment the RLE count for the last item;
     * if the last item is different from the current item, we write the last item onto the page,
     * and replace it with the current item. The r->recno counter tracks records written to the
     * page, and is incremented by the helper function immediately after writing records to the
     * page. The record number of our source record, that is, the current item, is maintained in
     * src_recno.
     ','line_number':1265,'multiline':True]['text':' For each entry in the in-memory page... ','line_number':1276,'multiline':True]['text':'
         * If the original value is "deleted", there's no value to compare, we're done.
         ','line_number':1284,'multiline':True]['text':' If the original value is stale, delete it when no updates are found. ','line_number':1291,'multiline':True]['text':'
         * Overflow items are tricky: we don't know until we're finished processing the set of
         * values if we need the overflow value or not. If we don't use the overflow item at all, we
         * have to discard it from the backing file, otherwise we'll leak blocks on the checkpoint.
         * That's safe because if the backing overflow value is still needed by any running
         * transaction, we'll cache a copy in the update list.
         *
         * Regardless, we avoid copying in overflow records: if there's a WT_INSERT entry that
         * modifies a reference counted overflow record, we may have to write copies of the overflow
         * record, and in that case we'll do the comparisons, but we don't read overflow items just
         * to see if they match records on either side.
         ','line_number':1294,'multiline':True]['text':'
         * If data is Huffman encoded, we have to decode it in order to compare it with the last
         * item we saw, which may have been an update string. This guarantees we find every single
         * pair of objects we can RLE encode, including applications updating an existing record
         * where the new value happens (?) to match a Huffman- encoded value in a previous or next
         * record.
         ','line_number':1311,'multiline':True]['text':'
         * Generate on-page entries: loop repeat records, looking for WT_INSERT entries matching the
         * record number. The WT_INSERT lists are in sorted order, so only need check the next one.
         ','line_number':1321,'multiline':True]['text':' No data copy ','line_number':1333,'multiline':True]['text':' Single record ','line_number':1334,'multiline':True]['text':' The on-disk value is stale and there was no update. Treat it as deleted. ','line_number':1338,'multiline':True]['text':' Maybe data copy ','line_number':1342,'multiline':True]['text':'
                 * The repeat count is the number of records up to the next WT_INSERT record, or up
                 * to the end of the entry if we have no more WT_INSERT records.
                 ','line_number':1344,'multiline':True]['text':'
                 * The key on the old disk image is unchanged. Clear the time window information if
                 * it's a deleted record, else take the time window from the cell.
                 ','line_number':1353,'multiline':True]['text':' Clear the on-disk cell time window if it is obsolete. ','line_number':1364,'multiline':True]['text':'
                 * If we are handling overflow items, use the overflow item itself exactly once,
                 * after which we have to copy it into a buffer and from then on use a complete copy
                 * because we are re-creating a new overflow record each time.
                 ','line_number':1367,'multiline':True]['text':'
                     * An as-yet-unused overflow item.
                     *
                     * We're going to copy the on-page cell, write out any record we're tracking.
                     ','line_number':1374,'multiline':True]['text':'
                     * Salvage may have caused us to skip the overflow item, only update overflow
                     * items we use.
                     ','line_number':1392,'multiline':True]['text':' Track if page has overflow items. ','line_number':1397,'multiline':True]['text':'
                     * Original is an overflow item; we used it for a key and now we need another
                     * copy; read it into memory.
                     ','line_number':1402,'multiline':True]['text':' FALLTHROUGH ','line_number':1409,'multiline':True]['text':'
                     * Original is an overflow item and we were forced to copy it into memory, or
                     * the original wasn't an overflow item; use the data copied into orig.
                     ','line_number':1411,'multiline':True]['text':'
                 * When a tombstone without a timestamp is written to disk, remove any historical
                 * versions that are greater in the history store for this key.
                 ','line_number':1444,'multiline':True]['text':'
             * If we have a record against which to compare and the records compare equal, increment
             * the RLE and continue. If the records don't compare equal, output the last record and
             * swap the last and current buffers: do NOT update the starting record number, we've
             * been doing that all along.
             ','line_number':1454,'multiline':True]['text':' The time window for deleted keys must be empty. ','line_number':1466,'multiline':True]['text':'
             * Swap the current/last state.
             *
             * Reset RLE counter and turn on comparisons.
             ','line_number':1479,'multiline':True]['text':'
                 * We can't simply assign the data values into the last buffer because they may have
                 * come from a copy built from an encoded/overflow cell and creating the next record
                 * is going to overwrite that memory. Check, because encoded/overflow cells aren't
                 * that common and we'd like to avoid the copy. If data was taken from the current
                 * unpack structure (which points into the page), or was taken from an update
                 * structure, we can just use the pointers, they're not moving.
                 ','line_number':1485,'multiline':True]['text':'
         * The first time we find an overflow record we never used, discard the underlying blocks,
         * they're no longer useful.
         ','line_number':1505,'multiline':True]['text':' Walk any append list. ','line_number':1513,'multiline':True]['text':'
             * Stop when we reach the end of the append list. There might be a gap between that and
             * the beginning of the next page. (Imagine record 98 is written, then record 100 is
             * written, then the page splits and record 100 moves to another page. There is no entry
             * for record 99 and we don't write one out.) In VLCS we (now) tolerate such gaps as
             * they are, though likely smaller, equivalent to gaps created by fast-truncate.
             ','line_number':1516,'multiline':True]['text':' No data copy ','line_number':1531,'multiline':True]['text':'
             * The application may have inserted records which left gaps in the name space, and
             * these gaps can be huge. If we're in a set of deleted records, skip the boring part.
             ','line_number':1534,'multiline':True]['text':' The time window for deleted keys must be empty. ','line_number':1541,'multiline':True]['text':'
                     * The record adjustment is decremented by one so we can naturally fall into the
                     * RLE accounting below, where we increment rle by one, then continue in the
                     * outer loop, where we increment src_recno by one.
                     ','line_number':1543,'multiline':True]['text':' Set time window for the first deleted key in a deleted range. ','line_number':1552,'multiline':True]['text':' The updates on the key are all uncommitted so we write a deleted key to disk. ','line_number':1555,'multiline':True]['text':' Set time window for the key. ','line_number':1559,'multiline':True]['text':'
                     * Impossible slot, there's no backing on-page item.
                     ','line_number':1564,'multiline':True]['text':'
                 * When a tombstone without a timestamp is written to disk, remove any historical
                 * versions that are greater in the history store for this key.
                 ','line_number':1587,'multiline':True]['text':'
             * Handle RLE accounting and comparisons -- see comment above, this code fragment does
             * the same thing.
             ','line_number':1596,'multiline':True]['text':' The time window for deleted keys must be empty. ','line_number':1606,'multiline':True]['text':'
             * Swap the current/last state. We can't simply assign the data values into the last
             * buffer because they may be a temporary copy built from a chain of modified updates
             * and creating the next record will overwrite that memory. Check, we'd like to avoid
             * the copy. If data was taken from an update structure, we can just use the pointers,
             * they're not moving.
             ','line_number':1619,'multiline':True]['text':' Ready for the next loop, reset the RLE counter. ','line_number':1634,'multiline':True]['text':'
             * Move to the next record. It's not a simple increment because if it's the maximum
             * record, incrementing it wraps to 0 and this turns into an infinite loop.
             ','line_number':1639,'multiline':True]['text':'
         * Execute this loop once without an insert item to catch any missing records due to a
         * split, then quit.
         ','line_number':1649,'multiline':True]['text':' If we were tracking a record, write it. ','line_number':1657,'multiline':True]['text':'
     * If we have not generated any real values but only deleted-value cells, bail out and call the
     * page empty instead. (Note that this should always be exactly one deleted-value cell, because
     * of the RLE handling, so we can't have split.) This will create a namespace gap like those
     * produced by truncate.
     *
     * Skip this step if:
     *     - We're in salvage, to avoid any odd interactions with the way salvage reconstructs the
     *       namespace.
     *     - There were invisible updates, because then the page isn't really empty. Also, at least
     *       for now if we try to restore updates to an empty page col_modify will trip on its
     *       shoelaces.
     *     - We wrote no cells at all. This can happen if a page with no cells and no append list
     *       entries at all (not just one with no or only aborted updates) gets marked dirty somehow
     *       and reconciled; this is apparently possible in some circumstances.
     ','line_number':1665,'multiline':True]['text':' Don't bother adjusting r->space_avail or r->first_free. ','line_number':1685,'multiline':True]['text':' Write the remnant page. ','line_number':1688,'multiline':True]