['text':'-
 * Copyright (c) 2014-present MongoDB, Inc.
 * Copyright (c) 2008-2014 WiredTiger, Inc.
 *	All rights reserved.
 *
 * See the file LICENSE for redistribution information.
 ','line_number':1,'multiline':True]['text':'
 * Structure to hold state for metadata entry worker procedure. It is only used during restore after
 * partial backup.
 ','line_number':11,'multiline':True]['text':' queue of target URI entries ','line_number':16,'multiline':True]['text':' max key length ','line_number':17,'multiline':True]['text':' next slot ','line_number':19,'multiline':True]['text':' allocated for partial backup keys array ','line_number':20,'multiline':True]['text':' partial backup keys array ','line_number':21,'multiline':True]['text':'
 * __metadata_config --
 *     Return the default configuration information for the metadata file.
 ','line_number':24,'multiline':True]['text':' Create a turtle file with default values. ','line_number':37,'multiline':True]['text':'
 * __metadata_init --
 *     Create the metadata file.
 ','line_number':50,'multiline':True]['text':'
     * We're single-threaded, but acquire the schema lock regardless: the lower level code checks
     * that it is appropriately synchronized.
     ','line_number':59,'multiline':True]['text':'
 * __metadata_backup_target_uri_search --
 *     Search in the backup uri hash table if the given uri exists.
 ','line_number':68,'multiline':True]['text':'
 * __wt_read_metadata_file --
 *     Open a text-based metadata file and iterate over the key value pairs calling the worker
 *     function for each of them.
 ','line_number':95,'multiline':True]['text':' Look for the given filename. If it exists, load it. ','line_number':110,'multiline':True]['text':' Read line pairs and add them to the import list. ','line_number':116,'multiline':True]['text':'
 * __metadata_entry_worker --
 *     Worker function for metadata file reader procedure. The function populates the partial backup
 *     names array and updates the metadata of the database with the new entries read from the file.
 ','line_number':138,'multiline':True]['text':'
     * When performing partial backup restore, generate a list of tables that are not part of the
     * target uri list so that we can drop all entries later. To do this, parse through all the
     * table metadata entries and check if the metadata entry exists in the target uri hash table.
     * If the metadata entry doesn't exist in the hash table, append the table name to the partial
     * backup remove list.
     ','line_number':155,'multiline':True]['text':' Assert that there should be no WiredTiger tables with a table format. ','line_number':164,'multiline':True]['text':'
         * The target uri will be the deciding factor if a specific metadata table entry needs to be
         * dropped. If the metadata table entry does not exist in the target uri hash table, append
         * the metadata key to the backup remove list.
         ','line_number':166,'multiline':True]['text':'
     * In the case of partial backup restore, add the entry to the metadata even if the table entry
     * doesn't exist so that we can correctly drop all related entries via the schema code later.
     ','line_number':187,'multiline':True]['text':'
 * __metadata_load_hot_backup --
 *     Load the contents of any hot backup file.
 ','line_number':196,'multiline':True]['text':' Open the metadata backup file and iterate over the key value pairs. ','line_number':220,'multiline':True]['text':'
         * Parse through the partial backup list and attempt to clean up all metadata references
         * relating to the file. To do so, perform a schema drop operation on the table to cleanly
         * remove all linked references. At the same time generate a list of btree ids to be used in
         * recovery to truncate all the history store records.
         ','line_number':231,'multiline':True]['text':'
     * Free the partial backup names list. The backup id list is used in recovery to truncate the
     * history store entries that do not exist as part of the database anymore.
     ','line_number':257,'multiline':True]['text':'
 * __metadata_load_bulk --
 *     Create any bulk-loaded file stubs.
 ','line_number':270,'multiline':True]['text':'
     * If a file was being bulk-loaded during the hot backup, it will appear in the metadata file,
     * but the file won't exist. Create on demand.
     ','line_number':284,'multiline':True]['text':' If the file exists, it's all good. ','line_number':294,'multiline':True]['text':'
         * If the file doesn't exist, assume it's a bulk-loaded file; retrieve the allocation size
         * and re-create the file.
         ','line_number':299,'multiline':True]['text':'
     * We want to explicitly close, not just release the metadata cursor here. We know we are in
     * initialization and this open cursor holds a lock on the metadata and we may need to verify
     * the metadata.
     ','line_number':312,'multiline':True]['text':'
 * __wt_turtle_validate_version --
 *     Retrieve version numbers from the turtle file and validate them against our WiredTiger
 *     version.
 ','line_number':321,'multiline':True]['text':'
 * __wt_turtle_exists --
 *     Return if the turtle file exists on startup.
 ','line_number':357,'multiline':True]['text':'
     * The last thing we do in database initialization is rename a turtle
     * file into place, and there's never a database home after that point
     * without a turtle file. On startup we check if the turtle file exists
     * to decide if we're creating the database or re-opening an existing
     * database.
     *	Unfortunately, we re-write the turtle file at checkpoint end,
     * first creating the "set" file and then renaming it into place.
     * Renames on Windows aren't guaranteed to be atomic, a power failure
     * could leave us with only the set file. The turtle file is the file
     * we regularly rename when WiredTiger is running, so if we're going to
     * get caught, the turtle file is where it will happen. If we have a set
     * file and no turtle file, rename the set file into place. We don't
     * know what went wrong for sure, so this can theoretically make it
     * worse, but there aren't alternatives other than human intervention.
     ','line_number':364,'multiline':True]['text':'
 * __metadata_add_backup_target_uri --
 *     Add the target uri to the backup uri hash table.
 ','line_number':395,'multiline':True]['text':' Insert target uri entry into hashtable. ','line_number':416,'multiline':True]['text':'
 * __metadata_load_target_uri_list --
 *     Load the list of target uris and construct a hashtable from it.
 ','line_number':428,'multiline':True]['text':'
         * Check that the configuration string only has table schema formats in the target list and
         * construct the target hash table.
         ','line_number':447,'multiline':True]['text':'
 * __wt_turtle_init --
 *     Check the turtle file and create if necessary.
 ','line_number':465,'multiline':True]['text':' Initialize target uri hashtable. ','line_number':483,'multiline':True]['text':'
     * Discard any turtle setup file left-over from previous runs. This doesn't matter for
     * correctness, it's just cleaning up random files.
     ','line_number':488,'multiline':True]['text':' If we're a readonly database, we can skip discarding the leftover file. ','line_number':494,'multiline':True]['text':'
     * If we found a corrupted turtle file, then delete it and create a new. We could die after
     * creating the turtle file and before creating the metadata file, or worse, the metadata file
     * might be in some random state. Make sure that doesn't happen: if we don't find the turtle
     * file, first create the metadata file, load any hot backup, and then create the turtle file.
     * No matter what happens, if metadata file creation doesn't fully complete, we won't have a
     * turtle file and we will repeat the process until we succeed.
     *
     * Incremental backups can occur only if recovery is run and it becomes live. So, if there is a
     * turtle file and an incremental backup file, that is an error. Otherwise, if there's already a
     * turtle file, we're done.
     ','line_number':500,'multiline':True]['text':'
         * Failure to read means a bad turtle file. Remove it and create a new turtle file.
         ','line_number':518,'multiline':True]['text':'
             * Set a flag to specify that we should validate whether we can start up on the turtle
             * file version seen. Return an error if we can't. Only check if we either didn't run
             * salvage or if salvage didn't fail to read it.
             ','line_number':531,'multiline':True]['text':'
         * We need to detect the difference between a source database that may have crashed with an
         * incremental backup file and a destination database that incorrectly ran recovery.
         ','line_number':538,'multiline':True]['text':'
         * If we have a backup file and metadata and turtle files, we want to recreate the metadata
         * from the backup.
         ','line_number':544,'multiline':True]['text':'
         * Verifying the metadata is incompatible with restarting from a backup because the verify
         * call will rewrite the metadata's checkpoint and could lead to skipping recovery. Test
         * here before creating the metadata file and reading in the backup file.
         ','line_number':563,'multiline':True]['text':' If partial backup target is non-empty, construct the target backup uri list. ','line_number':571,'multiline':True]['text':' Create the metadata file. ','line_number':574,'multiline':True]['text':' Load any hot-backup information. ','line_number':577,'multiline':True]['text':' Create any bulk-loaded file stubs. ','line_number':580,'multiline':True]['text':' Create the turtle file. ','line_number':585,'multiline':True]['text':' Remove target uri entry from the hashtable. ','line_number':596,'multiline':True]['text':'
     * We used to remove the backup file here. But we cannot do that until the metadata is fully
     * synced to disk after recovery.
     ','line_number':603,'multiline':True]['text':'
 * __wt_turtle_read --
 *     Read the turtle file.
 ','line_number':610,'multiline':True]['text':' Require single-threading. ','line_number':624,'multiline':True]['text':'
     * Open the turtle file; there's one case where we won't find the turtle file, yet still
     * succeed. We create the metadata file before creating the turtle file, and that means
     * returning the default configuration string for the metadata file.
     ','line_number':628,'multiline':True]['text':' Search for the key. ','line_number':641,'multiline':True]['text':' Key matched: read the subsequent line for the value. ','line_number':648,'multiline':True]['text':' Copy the value for the caller. ','line_number':653,'multiline':True]['text':'
     * A file error or a missing key/value pair in the turtle file means something has gone horribly
     * wrong, except for the compatibility setting which is optional. Failure to read the turtle
     * file when salvaging means it can't be used for salvage.
     ','line_number':663,'multiline':True]['text':'
 * __wt_turtle_update --
 *     Update the turtle file.
 ','line_number':674,'multiline':True]['text':' Require single-threading. ','line_number':690,'multiline':True]['text':'
     * Create the turtle setup file: we currently re-write it from scratch every time.
     ','line_number':694,'multiline':True]['text':'
     * If a compatibility setting has been explicitly set, save it out to the turtle file.
     ','line_number':700,'multiline':True]['text':' FIXME-WT-12021 Replace this with a proper failpoint once the framework is available. ','line_number':715,'multiline':True]['text':' Flush the stream and rename the file into place. ','line_number':719,'multiline':True]['text':' Close any file handle left open, remove any temporary file. ','line_number':722,'multiline':True]['text':'
     * An error updating the turtle file means something has gone horribly wrong -- we're done.
     ','line_number':727,'multiline':True]