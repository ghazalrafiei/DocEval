['text':'*
 *    Copyright (C) 2018-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]['text':' namespace mongo::write_ops_exec','line_number':184,'multiline':False]['text':' namespace mongo','line_number':189,'multiline':False]['text':'*
 * Atomic wrapper for long long type for Metrics.
 ','line_number':193,'multiline':True]['text':'* Set _value to the max of the current or newMax. ','line_number':198,'multiline':True]['text':'  Note: compareAndSwap will load into val most recent value. ','line_number':200,'multiline':True]['text':'* store val into value. ','line_number':205,'multiline':True]['text':'* Return the current value. ','line_number':210,'multiline':True]['text':'* TODO: SERVER-73806 Avoid implicit conversion to long long ','line_number':215,'multiline':True]['text':' Convention in this file: generic helpers go in the anonymous namespace. Helpers that are for a','line_number':224,'multiline':False]['text':' single type of operation are static functions defined above their caller.','line_number':225,'multiline':False]['text':' The withLock fail points are for testing interruptability of these operations, so they will not','line_number':240,'multiline':False]['text':' themselves check for interrupt.','line_number':241,'multiline':False]['text':'*
 * Metrics group for the `updateMany` and `deleteMany` operations. For each
 * operation, the `duration` and `numDocs` will contribute to aggregated total
 * and max metrics.
 ','line_number':250,'multiline':True]['text':'*
     * To avoid rapid accumulation of roundoff error in the duration total, it
     * is maintained precisely, and we arrange for the corresponding
     * Millisecond metric to hold an exported low-res image of it.
     ','line_number':268,'multiline':True]['text':' Mark the op as complete, log it and profile if the op should be sampled for profiling.','line_number':311,'multiline':False]['text':' We need to ignore all errors here. We don't want a successful op to fail because of a','line_number':315,'multiline':False]['text':' failure to record stats. We also don't want to replace the error reported for an op that','line_number':316,'multiline':False]['text':' is failing.','line_number':317,'multiline':False]['text':' someone else may have beat us to it.','line_number':329,'multiline':False]['text':' TODO (SERVER-77915): Remove once 8.0 becomes last LTS.','line_number':331,'multiline':False]['text':' TODO (SERVER-82066): Update handling for direct connections.','line_number':332,'multiline':False]['text':' TODO (SERVER-81937): Update handling for transactions.','line_number':333,'multiline':False]['text':' Intentionally not using writeConflictRetry. That is handled by the caller so it can react to','line_number':363,'multiline':False]['text':' oversized batches.','line_number':364,'multiline':False]['text':' Acquire optimes and fill them in for each item in the batch.','line_number':367,'multiline':False]['text':' This must only be done for doc-locking storage engines, which are allowed to insert oplog','line_number':368,'multiline':False]['text':' documents out-of-timestamp-order.  For other storage engines, the oplog entries must be','line_number':369,'multiline':False]['text':' physically written in timestamp order, so we defer optime assignment until the oplog is about','line_number':370,'multiline':False]['text':' to be written. Multidocument transactions should not generate opTimes because they are','line_number':371,'multiline':False]['text':' generated at the time of commit.','line_number':372,'multiline':False]['text':' Populate 'slots' with new optimes for each insert.','line_number':378,'multiline':False]['text':' This also notifies the storage engine of each new timestamp.','line_number':379,'multiline':False]['text':' Check if the failpoint specifies no collection or matches the existing one.','line_number':397,'multiline':False]['text':'*
 * Returns a OperationNotSupportedInTransaction error Status if we are in a transaction and
 * operating on a capped collection.
 *
 * The behavior of an operation against a capped collection may differ across replica set members,
 * where it can succeed on one member and fail on another, crashing the failing member. Prepared
 * transactions are not allowed to fail, so capped collections will not be allowed on shards.
 * Even in the unsharded case, capped collections are still problematic with transactions because
 * they only allow one operation at a time because they enforce insertion order with a MODE_X
 * collection lock, which we cannot hold in transactions.
 ','line_number':411,'multiline':True]['text':' Returns the flags that determine the type of document validation we want to','line_number':452,'multiline':False]['text':' perform. First item in the tuple determines whether to bypass document validation altogether,','line_number':453,'multiline':False]['text':' second item determines if _safeContent_ array can be modified in an encrypted collection.','line_number':454,'multiline':False]['text':' namespace','line_number':462,'multiline':False]['text':' These have always failed the whole batch.','line_number':476,'multiline':False]['text':' Sample the diff before rethrowing the error since mongos will handle this update by','line_number':481,'multiline':False]['text':' by performing a delete on the shard owning the pre-image doc and an insert on the','line_number':482,'multiline':False]['text':' shard owning the post-image doc. As a result, this update will not show up in the','line_number':483,'multiline':False]['text':' OpObserver as an update.','line_number':484,'multiline':False]['text':' Fail this write so mongos can retry','line_number':496,'multiline':False]['text':' hasWriteConcernError ','line_number':502,'multiline':True]['text':' isCommitOrAbort ','line_number':502,'multiline':True]['text':' Tell the client to try the whole txn again, by returning ok: 0 with errorLabels.','line_number':503,'multiline':False]['text':' If we are in a transaction, we must fail the whole batch.','line_number':506,'multiline':False]['text':' For routing errors, it is guaranteed that all subsequent operations will fail','line_number':521,'multiline':False]['text':' with the same cause, so don't try doing any more operations. The command reply serializer','line_number':522,'multiline':False]['text':' will handle repeating this error for unordered writes.','line_number':523,'multiline':False]['text':' (On the other hand, ShardCannotRefreshDueToLocksHeld is caused by a temporary inability','line_number':524,'multiline':False]['text':' to access a stable version of the cache during the execution of the batch; the error is','line_number':525,'multiline':False]['text':' returned back to the router to leverage its capability of selectively retrying','line_number':526,'multiline':False]['text':' operations).','line_number':527,'multiline':False]['text':' Multiple not-idempotent updates are not safe to retry at the cloud level. We treat these','line_number':533,'multiline':False]['text':' the same as an interruption due to a repl state change and fail the whole batch.','line_number':534,'multiline':False]['text':' If the migration is active, we throw a different code that will be caught higher up','line_number':540,'multiline':False]['text':' and replaced with a non-retryable code after the migration finishes to avoid wasted','line_number':541,'multiline':False]['text':' retries.','line_number':542,'multiline':False]['text':' If an op fails due to a TenantMigrationError then subsequent ops will also fail due to a','line_number':551,'multiline':False]['text':' migration blocking, committing, or aborting.','line_number':552,'multiline':False]['text':'*
 * Returns true if caller should try to insert more documents. Does nothing else if batch is empty.
 ','line_number':576,'multiline':True]['text':' unlock.','line_number':624,'multiline':False]['text':' It is not safe to ignore errors from collection creation while inside a','line_number':645,'multiline':False]['text':' multi-document transaction.','line_number':646,'multiline':False]['text':' multiUpdate ','line_number':648,'multiline':True]['text':' sampleId ','line_number':648,'multiline':True]['text':' Otherwise, proceed as though the batch insert block failed, since the batch insert block','line_number':652,'multiline':False]['text':' assumes `acquireCollection` is successful.','line_number':653,'multiline':False]['text':' First try doing it all together. If all goes well, this is all we need to do.','line_number':660,'multiline':False]['text':' See Collection::_insertDocuments for why we do all capped inserts one-at-a-time.','line_number':661,'multiline':False]['text':' Ignore this failure and behave as if we never tried to do the combined batch','line_number':682,'multiline':False]['text':' insert. The loop below will handle reporting any non-transient errors.','line_number':683,'multiline':False]['text':' Try to insert the batch one-at-a-time. This path is executed for singular batches,','line_number':688,'multiline':False]['text':' multi-statement transactions, capped collections, and if we failed all-at-once inserting.','line_number':689,'multiline':False]['text':' Transactions are not allowed to operate on capped collections.','line_number':699,'multiline':False]['text':' Release the lock following any error if we are not in multi-statement','line_number':713,'multiline':False]['text':' transaction. Among other things, this ensures that we don't sleep in the WCE','line_number':714,'multiline':False]['text':' retry loop with the lock held.','line_number':715,'multiline':False]['text':' If we are in multi-statement transaction and under a WUOW, we will','line_number':716,'multiline':False]['text':' not actually release the lock.','line_number':717,'multiline':False]['text':' multiUpdate ','line_number':724,'multiline':True]['text':' sampleId ','line_number':724,'multiline':True]['text':' Failed in ordered batch, or in a transaction, or from some unrecoverable error.','line_number':727,'multiline':False]['text':' TODO SERVER-76583: Remove this check.','line_number':784,'multiline':False]['text':' TODO SERVER-50983: Create abstraction for creating collection when using','line_number':822,'multiline':False]['text':' AutoGetCollection Create the collection if it does not exist when performing an upsert','line_number':823,'multiline':False]['text':' because the update stage does not create its own collection','line_number':824,'multiline':False]['text':' TODO (SERVER-77915): Remove once 8.0 becomes last LTS.','line_number':828,'multiline':False]['text':' TODO (SERVER-82066): Update handling for direct connections.','line_number':829,'multiline':False]['text':' TODO (SERVER-81937): Update handling for transactions.','line_number':830,'multiline':False]['text':'forgoOpCounterIncrements','line_number':866,'multiline':True]['text':' verbosity
        ','line_number':871,'multiline':True]['text':' Nothing after advancing the plan executor should throw a WriteConflictException,','line_number':883,'multiline':False]['text':' so the following bookkeeping with execution stats won't end up being done','line_number':884,'multiline':False]['text':' multiple times.','line_number':885,'multiline':False]['text':' If it's an upsert, increment 'inserts' metric, otherwise increment 'updates'.','line_number':899,'multiline':False]['text':' TODO SERVER-76583: Remove this check.','line_number':937,'multiline':False]['text':' Transactions are not allowed to operate on capped collections.','line_number':961,'multiline':False]['text':' verbosity
        ','line_number':983,'multiline':True]['text':' Nothing after advancing the plan executor should throw a WriteConflictException,','line_number':993,'multiline':False]['text':' so the following bookkeeping with execution stats won't end up being done','line_number':994,'multiline':False]['text':' multiple times.','line_number':995,'multiline':False]['text':' Fill out OpDebug with the number of deleted docs.','line_number':1004,'multiline':False]['text':' Interruption errors encountered during batch execution fail the entire batch, so throw on','line_number':1041,'multiline':False]['text':' such errors here for consistency.','line_number':1042,'multiline':False]['text':' Tenant migration errors, similarly to migration errors consume too much space in the','line_number':1047,'multiline':False]['text':' ordered:false responses and get truncated. Since the call to','line_number':1048,'multiline':False]['text':' 'handleTenantMigrationConflict' above replaces the original status, we need to manually','line_number':1049,'multiline':False]['text':' truncate the new reason if the original 'status' was also truncated.','line_number':1050,'multiline':False]['text':' Stash the current transaction so that writes to the profile collection are not','line_number':1085,'multiline':False]['text':' done as part of the transaction.','line_number':1086,'multiline':False]['text':' Insert performs its own retries, so we should only be within a WriteUnitOfWork when run in a','line_number':1096,'multiline':False]['text':' transaction.','line_number':1097,'multiline':False]['text':' Timeseries inserts already did as part of performTimeseriesWrites.','line_number':1104,'multiline':False]['text':' This is the only part of finishCurOp we need to do for inserts because they','line_number':1106,'multiline':False]['text':' reuse the top-level curOp. The rest is handled by the top-level entrypoint.','line_number':1107,'multiline':False]['text':' Timeseries inserts already did as part of performTimeseriesWrites.','line_number':1120,'multiline':False]['text':' If we are performing inserts from tenant migrations, skip checking if the user is allowed to','line_number':1129,'multiline':False]['text':' write to the namespace.','line_number':1130,'multiline':False]['text':' Handled after we insert anything in the batch to be sure we report errors in the','line_number':1169,'multiline':False]['text':' correct order. In an ordered insert, if one of the docs ahead of us fails, we should','line_number':1170,'multiline':False]['text':' behave as-if we never got to this document.','line_number':1171,'multiline':False]['text':' Similarly, if the insert was already executed as part of a retryable write, flush the','line_number':1173,'multiline':False]['text':' current batch to preserve the error results order.','line_number':1174,'multiline':False]['text':' A time-series insert can combine multiple writes into a single operation, and thus','line_number':1181,'multiline':False]['text':' can have multiple statement ids associated with it if it is retryable.','line_number':1182,'multiline':False]['text':' Add more to batch before inserting.','line_number':1191,'multiline':False]['text':' We won't need the current batch any more.','line_number':1202,'multiline':False]['text':' If the batch had an error and decides to not continue, do not process a current doc that','line_number':1205,'multiline':False]['text':' was unsuccessfully "fixed" or an already executed retryable write.','line_number':1206,'multiline':False]['text':' Revisit any conditions that may have caused the batch to be flushed. In those cases,','line_number':1211,'multiline':False]['text':' append the appropriate result to the output.','line_number':1212,'multiline':False]['text':' multiUpdate ','line_number':1225,'multiline':True]['text':' sampleId ','line_number':1226,'multiline':True]['text':' If this is an upsert, which is an insert, we must have a collection.','line_number':1284,'multiline':False]['text':' An update on a non-existent collection is okay and handled later.','line_number':1285,'multiline':False]['text':' Inexistent collection.','line_number':1287,'multiline':False]['text':' Disable auto yielding in the plan executor in order to prevent retrying on','line_number':1303,'multiline':False]['text':' WriteConflictExceptions internally. A WriteConflictException can be thrown in order to','line_number':1304,'multiline':False]['text':' abort a WriteBatch in an attempt to retry the operation, so we need it to escape the plan','line_number':1305,'multiline':False]['text':' executor layer.','line_number':1306,'multiline':False]['text':' Transactions are not allowed to operate on capped collections.','line_number':1311,'multiline':False]['text':' verbosity ','line_number':1335,'multiline':True]['text':'*
 * Performs a single update, retrying failure due to DuplicateKeyError when eligible.
 ','line_number':1379,'multiline':True]['text':' If the first stmtId is uninitialized, we assume all are.','line_number':1409,'multiline':False]['text':' If it's an upsert, increment 'inserts' metric, otherwise increment 'updates'.','line_number':1440,'multiline':False]['text':' expCtx ','line_number':1446,'multiline':True]['text':' Propagates the write results from executing the statement to the current','line_number':1487,'multiline':False]['text':' command's results.','line_number':1488,'multiline':False]['text':' Rethrows the error from the command or the internal transaction api to handle them','line_number':1505,'multiline':False]['text':' accordingly.','line_number':1506,'multiline':False]['text':' Update performs its own retries, so we should not be in a WriteUnitOfWork unless run in a','line_number':1539,'multiline':False]['text':' transaction.','line_number':1540,'multiline':False]['text':' If the update command specified runtime constants, we adopt them. Otherwise, we set them to','line_number':1564,'multiline':False]['text':' the current local and cluster time. These constants are applied to each update in the batch.','line_number':1565,'multiline':False]['text':' Increment operator counters only during the first single update operation in a batch of','line_number':1569,'multiline':False]['text':' updates.','line_number':1570,'multiline':False]['text':' For non-sharded user time-series updates, handles the metrics of the command at','line_number':1586,'multiline':False]['text':' the caller since each statement will run as a command through the internal','line_number':1587,'multiline':False]['text':' transaction API.','line_number':1588,'multiline':False]['text':' Returns the '_id' of the user measurement for time-series upserts.','line_number':1592,'multiline':False]['text':' TODO: don't create nested CurOp for legacy writes.','line_number':1604,'multiline':False]['text':' Add Command pointer to the nested CurOp.','line_number':1605,'multiline':False]['text':' A time-series insert can combine multiple writes into a single operation, and thus','line_number':1630,'multiline':False]['text':' can have multiple statement ids associated with it if it is retryable.','line_number':1631,'multiline':False]['text':' Do not handle errors for time-series bucket compressions. They need to be transparent','line_number':1661,'multiline':False]['text':' to users to not interfere with any decisions around operation retry. It is OK to','line_number':1662,'multiline':False]['text':' leave bucket uncompressed in these edge cases. We just record the status to the','line_number':1663,'multiline':False]['text':' result vector so we can keep track of statistics for failed bucket compressions.','line_number':1664,'multiline':False]['text':' verbosity ','line_number':1762,'multiline':True]['text':' Delete performs its own retries, so we should not be in a WriteUnitOfWork unless we are in a','line_number':1803,'multiline':False]['text':' transaction.','line_number':1804,'multiline':False]['text':' If the delete command specified runtime constants, we adopt them. Otherwise, we set them to','line_number':1828,'multiline':False]['text':' the current local and cluster time. These constants are applied to each delete in the batch.','line_number':1829,'multiline':False]['text':' TODO: don't create nested CurOp for legacy writes.','line_number':1853,'multiline':False]['text':' Add Command pointer to the nested CurOp.','line_number':1854,'multiline':False]['text':' multiUpdate ','line_number':1906,'multiline':True]['text':' namespace mongo::write_ops_exec','line_number':1920,'multiline':False]['text':' Since we are manually updating the "lastWriteOpTime" before committing, we'll also need to','line_number':1961,'multiline':False]['text':' manually reset if the storage transaction is aborted.','line_number':1962,'multiline':False]['text':' Manually sets the timestamp so that the "prevOpTime" field in the oplog entry is','line_number':1988,'multiline':False]['text':' correctly chained to the previous operations.','line_number':1989,'multiline':False]['text':' Assume all indexes are affected.','line_number':2013,'multiline':False]['text':'indexesAffected','line_number':2045,'multiline':True]['text':' Manually sets the timestamp so that the "prevOpTime" field in the oplog entry is','line_number':2050,'multiline':False]['text':' correctly chained to the previous operations.','line_number':2051,'multiline':False]['text':'*
 * Returns whether a given MatchExpression contains is a MatchType::EQ or a MatchType::AND node with
 * only MatchType::EQ children.
 ','line_number':2080,'multiline':True]['text':' namespace','line_number':2101,'multiline':False]['text':' In order to be retryable, the update must be an upsert with multi:false.','line_number':2106,'multiline':False]['text':' In order to be retryable, the update query must contain no expressions other than AND and EQ.','line_number':2114,'multiline':False]['text':' In order to be retryable, the update equality field paths must be identical to the unique','line_number':2119,'multiline':False]['text':' index key field paths. Also, the values that triggered the DuplicateKey error must match the','line_number':2120,'multiline':False]['text':' values used in the upsert query predicate.','line_number':2121,'multiline':False]['text':' Comparison which obeys field ordering but ignores field name.','line_number':2146,'multiline':False]['text':'*
 * Returns true if the time-series write is retryable.
 ','line_number':2168,'multiline':True]['text':' The schema validation configured in the bucket collection is intended for direct','line_number':2238,'multiline':False]['text':' operations by end users and is not applicable here.','line_number':2239,'multiline':False]['text':' Timeseries compression operation is not a user operation and should not use a','line_number':2242,'multiline':False]['text':' statement id from any user op. Set to Uninitialized to bypass.','line_number':2243,'multiline':False]['text':'*
 * Returns the status and whether the request can continue.
 ','line_number':2250,'multiline':True]['text':'*
 * Returns the status and whether the request can continue.
 ','line_number':2271,'multiline':True]['text':'*
 * Attempts to perform bucket compression on time-series bucket. It will surpress any error caused
 * by the write and silently leave the bucket uncompressed when any type of error is encountered.
 ','line_number':2287,'multiline':True]['text':' When enabled, we skip constructing ClosedBuckets which results in skipping compression.','line_number':2294,'multiline':False]['text':' Buckets with just a single measurement is not worth compressing.','line_number':2298,'multiline':False]['text':' Skip compression if the bucket is already compressed.','line_number':2313,'multiline':False]['text':' Reset every time we run to ensure we never use a stale value','line_number':2318,'multiline':False]['text':' If compressed object size is larger than uncompressed, skip compression update.','line_number':2325,'multiline':False]['text':'*
 * Returns whether the request can continue.
 ','line_number':2366,'multiline':True]['text':' Automatically attempts to retry on DuplicateKey error.','line_number':2400,'multiline':False]['text':' If this write closed a bucket, compress the bucket','line_number':2455,'multiline':False]['text':' For sharded time-series collections, we need to use the granularity from the config','line_number':2549,'multiline':False]['text':' server (through shard filtering information) as the source of truth for the current','line_number':2550,'multiline':False]['text':' granularity value, due to the possible inconsistency in the process of granularity','line_number':2551,'multiline':False]['text':' updates.','line_number':2552,'multiline':False]['text':' numInserted ','line_number':2590,'multiline':True]['text':' Holding this shared pointer to the collection guarantees that the collator is not','line_number':2601,'multiline':False]['text':' invalidated.','line_number':2602,'multiline':False]['text':' This could occur when the shard version attached to the request is for the time','line_number':2613,'multiline':False]['text':' series namespace (unsharded), which is compared to the shard version of the','line_number':2614,'multiline':False]['text':' bucket namespace. Consequently, every single entry fails but the whole operation','line_number':2615,'multiline':False]['text':' succeeds.','line_number':2616,'multiline':False]['text':' If this insert closed buckets, rewrite to be a compressed column. If we cannot','line_number':2678,'multiline':False]['text':' perform write operations at this point the bucket will be left uncompressed.','line_number':2679,'multiline':False]['text':' If there are any unprocessed batches, we mark them as error with the last known','line_number':2720,'multiline':False]['text':' error.','line_number':2721,'multiline':False]['text':' If we cannot continue the request, we should convert all the 'docsToRetry' into an','line_number':2757,'multiline':False]['text':' error.','line_number':2758,'multiline':False]['text':'*
 * Writes to the underlying system.buckets collection. Returns the indices, of the batch
 * which were attempted in an update operation, but found no bucket to update. These indices
 * can be passed as the 'indices' parameter in a subsequent call to this function, in order
 * to to be retried.
 * In rare cases due to collision from OID generation, we will also retry inserting those bucket
 * documents for a limited number of times.
 ','line_number':2788,'multiline':True]['text':'*
 * Returns the number of documents that were inserted.
 ','line_number':2889,'multiline':True]['text':' namespace','line_number':2914,'multiline':False]['text':' This is the only part of finishCurOp we need to do for inserts because they reuse','line_number':2921,'multiline':False]['text':' the top-level curOp. The rest is handled by the top-level entrypoint.','line_number':2922,'multiline':False]['text':' If an expected collection UUID is provided, always fail because the user-facing time-series','line_number':2950,'multiline':False]['text':' namespace does not have a UUID.','line_number':2951,'multiline':False]['text':' Explains of write commands are read-only, but we take write locks so that timing','line_number':3015,'multiline':False]['text':' info is more accurate.','line_number':3016,'multiline':False]['text':' forgoOpCounterIncrements ','line_number':3033,'multiline':True]['text':' Explains of write commands are read-only, but we take write locks so that timing','line_number':3057,'multiline':False]['text':' info is more accurate.','line_number':3058,'multiline':False]['text':' Explain the plan tree.','line_number':3076,'multiline':False]['text':' namespace mongo::write_ops_exec','line_number':3090,'multiline':False]