['text':'*
 *    Copyright (C) 2023-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]['text':' IWYU pragma: no_include "ext/alloc_traits.h"','line_number':38,'multiline':False]['text':' The ranks computed by this function is 0-based.','line_number':115,'multiline':False]['text':' std::lower_bound returns an iterator pointing to the first element in the range [first, last)','line_number':117,'multiline':False]['text':' that does _not_ satisfy element < value.','line_number':118,'multiline':False]['text':' t-digest doesn't guarantee accuracy error bounds (there exists inputs for which the error can','line_number':125,'multiline':False]['text':' be arbitrary large), however, for already sorted inputs the error does have the upper bound','line_number':126,'multiline':False]['text':' and for most "normal" inputs it's not that far off. Note: the error is defined in terms of','line_number':127,'multiline':False]['text':' _rank_.','line_number':128,'multiline':False]['text':' If there are duplicates in the data, the true rank is a range of values so we need to','line_number':136,'multiline':False]['text':' find its lower and upper bounds.','line_number':137,'multiline':False]['text':'==================================================================================================
  Tests with fixed datasets.
==================================================================================================','line_number':172,'multiline':True]['text':'*
 * For the GetPercentile_* tests the scaling function and delta don't matter as the tests create
 * fully formed digests.
 ','line_number':175,'multiline':True]['text':' negInfCount','line_number':186,'multiline':False]['text':' posInfCount','line_number':187,'multiline':False]['text':' min','line_number':188,'multiline':False]['text':' max','line_number':189,'multiline':False]['text':' k1_limit ','line_number':191,'multiline':True]['text':' delta ','line_number':192,'multiline':True]['text':' Our t-digest computes accurate minimum.','line_number':198,'multiline':False]['text':' negInfCount','line_number':200,'multiline':False]['text':' posInfCount','line_number':201,'multiline':False]['text':' min','line_number':202,'multiline':False]['text':' max','line_number':203,'multiline':False]['text':' k1_limit ','line_number':205,'multiline':True]['text':' delta ','line_number':206,'multiline':True]['text':' Our t-digest computes accurate maximum.','line_number':210,'multiline':False]['text':' negInfCount','line_number':212,'multiline':False]['text':' posInfCount','line_number':213,'multiline':False]['text':' min','line_number':214,'multiline':False]['text':' max','line_number':215,'multiline':False]['text':' k1_limit ','line_number':217,'multiline':True]['text':' delta ','line_number':218,'multiline':True]['text':' On a single t-digest computes continuous percentiles.','line_number':222,'multiline':False]['text':' {1, 2, ..., 100}','line_number':225,'multiline':False]['text':' negInfCount','line_number':227,'multiline':False]['text':' posInfCount','line_number':228,'multiline':False]['text':' min','line_number':229,'multiline':False]['text':' max','line_number':230,'multiline':False]['text':' the single centroid','line_number':231,'multiline':False]['text':' k1_limit ','line_number':232,'multiline':True]['text':' delta ','line_number':233,'multiline':True]['text':' On tiny inputs like these t-digest will create single-point centroids and compute accurate','line_number':243,'multiline':False]['text':' results. The result should match the DiscretePercentile.','line_number':244,'multiline':False]['text':'delta','line_number':248,'multiline':True]['text':'delta','line_number':259,'multiline':True]['text':'delta','line_number':270,'multiline':True]['text':' Single-point centroids should yield accurate discrete percentiles, even if the rest of the data','line_number':278,'multiline':False]['text':' distribution isn't "even".','line_number':279,'multiline':False]['text':' negInfCount','line_number':281,'multiline':False]['text':' posInfCount','line_number':282,'multiline':False]['text':' min','line_number':283,'multiline':False]['text':' max','line_number':284,'multiline':False]['text':' {weight, mean}','line_number':286,'multiline':False]['text':' 100 datapoints total','line_number':295,'multiline':False]['text':' k1_limit ','line_number':296,'multiline':True]['text':' delta ','line_number':297,'multiline':True]['text':'*
 * Tests with the special double inputs. The scaling function doesn't matter for these tests but
 * using a smaller delta to exercise compacting of centroids.
 ','line_number':303,'multiline':True]['text':' doesn't really matter in this test as no centroids are created','line_number':308,'multiline':False]['text':' Setup the data as 70 negative infinities, and 30 positive infinities.','line_number':311,'multiline':False]['text':' 70 out of 100 values are negative infinities','line_number':334,'multiline':False]['text':' 30 out of 100 values are positive infinities','line_number':340,'multiline':False]['text':' Setup the data as 1000 evenly distributed "normal values", 200 positive infinities, and','line_number':351,'multiline':False]['text':' 300 negative infinities.','line_number':352,'multiline':False]['text':' {1, 2, ..., 1000}','line_number':357,'multiline':False]['text':' sorted by construction','line_number':361,'multiline':False]['text':' 300 out of 1500 values are negative infinities','line_number':377,'multiline':False]['text':' percentiles ','line_number':387,'multiline':True]['text':' accuracyError ','line_number':387,'multiline':True]['text':' 200 out of 1500 values are positive infinities','line_number':389,'multiline':False]['text':' {1, 2, ..., 1000}','line_number':400,'multiline':False]['text':' Add NaN value into the dataset.','line_number':405,'multiline':False]['text':' Create a dataset consisting of four groups of values (large/small refer to the abs value):','line_number':426,'multiline':False]['text':' 1. large negative numbers','line_number':428,'multiline':False]['text':' from ','line_number':431,'multiline':True]['text':' to ','line_number':431,'multiline':True]['text':' 2. small negative numbers','line_number':433,'multiline':False]['text':' from ','line_number':436,'multiline':True]['text':' to ','line_number':436,'multiline':True]['text':' 3. small positive numbers','line_number':438,'multiline':False]['text':' from ','line_number':441,'multiline':True]['text':' to ','line_number':441,'multiline':True]['text':' 4. large positive numbers','line_number':443,'multiline':False]['text':' from ','line_number':446,'multiline':True]['text':' to ','line_number':446,'multiline':True]['text':' percentiles ','line_number':469,'multiline':True]['text':' accuracyError ','line_number':470,'multiline':True]['text':'*
 * The following set of tests checks the workings of merging data into a digest. They use a simpler
 * k0 = delta*q/2 scaling function as it's easier to reason about the resulting centroids.
 *
 * For k0 = delta*q/2 size of a centroid cannot excede 2*n/delta and for a fully compacted digest
 * the number of centroids cannot exceed 2*delta (and has to be at least delta/2).
 ','line_number':474,'multiline':True]['text':' one extra item to dodge the floating point precision issues','line_number':495,'multiline':False]['text':' {1, 2, ..., 21}','line_number':496,'multiline':False]['text':' negInfCount','line_number':512,'multiline':False]['text':' posInfCount','line_number':513,'multiline':False]['text':' min','line_number':514,'multiline':False]['text':' max','line_number':515,'multiline':False]['text':' centroids','line_number':516,'multiline':False]['text':' Add to the digest data that is larger than any of the already accumulated points.','line_number':522,'multiline':False]['text':' {22, 23, ..., 31}','line_number':524,'multiline':False]['text':' Because the data in the second batch is sorted higher than the existing data, none of the','line_number':533,'multiline':False]['text':' previously created centroids except the very last one can be merged (because the max weight','line_number':534,'multiline':False]['text':' is 6 but the fully compacted centroids after the first batch all have size of 4).','line_number':535,'multiline':False]['text':' negInfCount','line_number':543,'multiline':False]['text':' posInfCount','line_number':544,'multiline':False]['text':' min','line_number':545,'multiline':False]['text':' max','line_number':546,'multiline':False]['text':' centroids','line_number':547,'multiline':False]['text':' Add to the digest data that is smaller than any of the already accumulated points.','line_number':553,'multiline':False]['text':' {-9, -8, ..., 0}','line_number':555,'multiline':False]['text':' Because the data in the second batch is sorted lower than the existing data, none of the','line_number':564,'multiline':False]['text':' previously created centroids can be merged (because the max weight is 6 but the fully','line_number':565,'multiline':False]['text':' compacted centroids after the first batch all have size of 4).','line_number':566,'multiline':False]['text':' negInfCount','line_number':574,'multiline':False]['text':' posInfCount','line_number':575,'multiline':False]['text':' min','line_number':576,'multiline':False]['text':' max','line_number':577,'multiline':False]['text':' centroids','line_number':578,'multiline':False]['text':' Use inputs that land between the current centroids of the digest. Note: more than 3','line_number':585,'multiline':False]['text':' additional inputs would allow the centroids of bigger sizes.','line_number':586,'multiline':False]['text':' Incorporating more data would increase the bound on centroid size to 6 and cause compaction.','line_number':605,'multiline':False]['text':'*
 * The following tests checks merging of two digests. They use a simpler k0 = delta*q/2 scaling
 * function as it's easier to reason about the resulting centroids. Notice, that the results of
 * merging two digests aren't necessarily the same as when merging data into a digest.
 *
 * For k0 = delta*q/2 size of a centroid cannot exceed 2*n/delta and for a fully compacted digest
 * the number of centroids cannot exceed 2*delta (and has to be at least delta/2).
 ','line_number':612,'multiline':True]['text':' negInfCount','line_number':623,'multiline':False]['text':' posInfCount','line_number':624,'multiline':False]['text':' min','line_number':625,'multiline':False]['text':' max','line_number':626,'multiline':False]['text':' centroids','line_number':627,'multiline':False]['text':' negInfCount','line_number':634,'multiline':False]['text':' posInfCount','line_number':635,'multiline':False]['text':' min','line_number':636,'multiline':False]['text':' max','line_number':637,'multiline':False]['text':' centroids','line_number':638,'multiline':False]['text':' negInfCount','line_number':654,'multiline':False]['text':' posInfCount','line_number':655,'multiline':False]['text':' min','line_number':656,'multiline':False]['text':' max','line_number':657,'multiline':False]['text':' centroids','line_number':658,'multiline':False]['text':' negInfCount','line_number':664,'multiline':False]['text':' posInfCount','line_number':665,'multiline':False]['text':' min','line_number':666,'multiline':False]['text':' max','line_number':667,'multiline':False]['text':' centroids','line_number':668,'multiline':False]['text':'*
 * The following test doesn't add coverage but is meant to illustrate the difference between scaling
 * functions.
 ','line_number':681,'multiline':True]['text':' {1, 2, ..., 101}','line_number':689,'multiline':False]['text':' k0 attempts to split data into centroids of equal weights.','line_number':703,'multiline':False]['text':' k1 is biased to create smaller centroids at the extremes of the data.','line_number':717,'multiline':False]['text':' k2 is also biased with the same asymptotic characteristics at 0 and 1 as k1 and is cheaper','line_number':731,'multiline':False]['text':' to compute (but it has higher upper bound on the number of number of centroids).','line_number':732,'multiline':False]['text':'*
 * Until there are enough inputs, t-digest has to keep a centroid per input point, which means they
 * are strictly sorted and the computed percentiles are precise. However, the threshold on the
 * number of the inputs depends on the scaling function and delta.
 ','line_number':739,'multiline':True]['text':' {1.0, ..., 100.0}','line_number':747,'multiline':False]['text':' Spot-check a few percentiles.','line_number':753,'multiline':False]['text':' Check that asking for the same percentiles at once gives the same answers.','line_number':761,'multiline':False]['text':' delta ','line_number':771,'multiline':True]['text':' delta ','line_number':775,'multiline':True]['text':' delta ','line_number':779,'multiline':True]['text':'==================================================================================================
  Tests with various data distributions.
==================================================================================================','line_number':783,'multiline':True]['text':' Generates n * dupes values using provided distribution. The dupes can be either kept together or','line_number':787,'multiline':False]['text':' spread across the whole generated dataset. NB: when data is fed to t-digest the algorithm fills','line_number':788,'multiline':False]['text':' and then sorts a buffer so spreading the duplicates within distances comparable to the','line_number':789,'multiline':False]['text':' buffer-size doesn't serve any purpose.','line_number':790,'multiline':False]['text':' duplicate 'inputs' the requested number of times.','line_number':813,'multiline':False]['text':' Generates 'n' values in [0, 100] range with uniform distribution.','line_number':826,'multiline':False]['text':' min ','line_number':828,'multiline':True]['text':' max ','line_number':828,'multiline':True]['text':' Generates 'n' values from normal distribution with mean = 0.0 and sigma = 0.5.','line_number':832,'multiline':False]['text':' mean ','line_number':834,'multiline':True]['text':' sigma ','line_number':834,'multiline':True]['text':' Generates 'n' values from exponential distribution with lambda = 1.0: p(x)=lambda*e^(-lambda*x).','line_number':838,'multiline':False]['text':' lambda ','line_number':840,'multiline':True]['text':' Generates 'n' values from weibull distribution with a : 1.0, b: 0.5 to produce a heavy tail.','line_number':844,'multiline':False]['text':' a ','line_number':846,'multiline':True]['text':' b ','line_number':846,'multiline':True]['text':'
 * The following tests generate datasets with 10,000 values. T-digest does not guarantee error
 * bounds, but on well-behaved datasets it should be within 0.5% for the middle percentiles and even
 * better for the extreme ones.
 *
 * These tests also indirectly validate the merging and compacting with a more complex scaling
 * function.
 ','line_number':850,'multiline':True]['text':' nUnique ','line_number':866,'multiline':True]['text':' dupes ','line_number':866,'multiline':True]['text':' keepDupesTogether','line_number':866,'multiline':True]['text':'seed','line_number':866,'multiline':True]['text':' accuracy ','line_number':890,'multiline':True]['text':' accuracy ','line_number':899,'multiline':True]['text':' accuracy ','line_number':909,'multiline':True]['text':' accuracy ','line_number':918,'multiline':True]['text':' accuracy ','line_number':928,'multiline':True]['text':' accuracy ','line_number':937,'multiline':True]['text':' accuracy ','line_number':947,'multiline':True]['text':' accuracy ','line_number':956,'multiline':True]['text':'*
 * Tests distributions with duplicated data. Notice that we tend to get lower accuracy in presence
 * of many duplicates.
 ','line_number':960,'multiline':True]['text':'seed','line_number':972,'multiline':True]['text':' nUnique','line_number':993,'multiline':True]['text':' dupes ','line_number':994,'multiline':True]['text':' keepDupesTogether','line_number':995,'multiline':True]['text':' accuracy ','line_number':997,'multiline':True]['text':' nUnique','line_number':1000,'multiline':True]['text':' dupes ','line_number':1001,'multiline':True]['text':' keepDupesTogether','line_number':1002,'multiline':True]['text':' accuracy ','line_number':1004,'multiline':True]['text':' nUnique','line_number':1008,'multiline':True]['text':' dupes ','line_number':1009,'multiline':True]['text':' keepDupesTogether','line_number':1010,'multiline':True]['text':' accuracy ','line_number':1012,'multiline':True]['text':' nUnique','line_number':1015,'multiline':True]['text':' dupes ','line_number':1016,'multiline':True]['text':' keepDupesTogether','line_number':1017,'multiline':True]['text':' accuracy ','line_number':1019,'multiline':True]['text':' nUnique','line_number':1027,'multiline':True]['text':' dupes ','line_number':1028,'multiline':True]['text':' keepDupesTogether','line_number':1029,'multiline':True]['text':' accuracy ','line_number':1031,'multiline':True]['text':' nUnique','line_number':1034,'multiline':True]['text':' dupes ','line_number':1035,'multiline':True]['text':' keepDupesTogether','line_number':1036,'multiline':True]['text':' accuracy ','line_number':1038,'multiline':True]['text':' nUnique','line_number':1042,'multiline':True]['text':' dupes ','line_number':1043,'multiline':True]['text':' keepDupesTogether','line_number':1044,'multiline':True]['text':' accuracy ','line_number':1046,'multiline':True]['text':' nUnique','line_number':1049,'multiline':True]['text':' dupes ','line_number':1050,'multiline':True]['text':' keepDupesTogether','line_number':1051,'multiline':True]['text':' accuracy ','line_number':1053,'multiline':True]['text':' The t-digest of all duplicates will still contain multiple centroids but because all of them','line_number':1068,'multiline':False]['text':' have the same mean that is equal to min and max, the interpolation should always return that','line_number':1069,'multiline':False]['text':' mean as a result and, thus, would produce accurate percentile.','line_number':1070,'multiline':False]['text':' percentiles ','line_number':1074,'multiline':True]['text':' accuracy ','line_number':1075,'multiline':True]['text':' percentiles ','line_number':1101,'multiline':True]['text':' accuracy ','line_number':1102,'multiline':True]['text':' percentiles ','line_number':1106,'multiline':True]['text':' accuracy ','line_number':1107,'multiline':True]['text':' 10000','line_number':1113,'multiline':False]['text':' 10000','line_number':1114,'multiline':False]['text':' 10000','line_number':1115,'multiline':False]['text':' 10000','line_number':1116,'multiline':False]['text':' 10000','line_number':1117,'multiline':False]['text':' 30000','line_number':1118,'multiline':False]['text':' 10000','line_number':1119,'multiline':False]['text':' 10000','line_number':1120,'multiline':False]['text':' 10000','line_number':1121,'multiline':False]['text':'seed','line_number':1128,'multiline':True]['text':' For k2 the upper bound on the number of centroids is 2*delta','line_number':1140,'multiline':False]['text':'*
 * The tests below were used to assess accuracy of t-digest on datasets of large size (>=1e7) over
 * multiple iterations. They never fail but we'd like to keep the code alive to be able to repeat
 * the experiments in the future if we decide to tune t-digest further. However, for running as part
 * of unit tests the number of iterations and the dataset size have been set to lower values.
 ','line_number':1156,'multiline':True]['text':'errors','line_number':1177,'multiline':True]['text':'# centroids','line_number':1177,'multiline':True]['text':' dupes ','line_number':1188,'multiline':True]['text':' keepDupesTogether ','line_number':1188,'multiline':True]['text':' For one of the iterations let's assess the amount of overlap between the centroids.','line_number':1205,'multiline':False]['text':' Two centroids overlap if the max of the left one is greater than the min of the right','line_number':1206,'multiline':False]['text':' one. From the empirical review it seems unlikely for a centroid to overlap with more','line_number':1207,'multiline':False]['text':' than 20 others, so we'll limit the loop to that.','line_number':1208,'multiline':False]['text':' TEST(TDigestTest, AccuracyStats_uniform) {','line_number':1237,'multiline':False]['text':'     runAccuracyTest(generateUniform);','line_number':1238,'multiline':False]['text':' }','line_number':1239,'multiline':False]['text':' TEST(TDigestTest, AccuracyStats_normal) {','line_number':1240,'multiline':False]['text':'     runAccuracyTest(generateNormal);','line_number':1241,'multiline':False]['text':' }','line_number':1242,'multiline':False]['text':' TEST(TDigestTest, AccuracyStats_exp) {','line_number':1243,'multiline':False]['text':'     runAccuracyTest(generateExponential);','line_number':1244,'multiline':False]['text':' }','line_number':1245,'multiline':False]['text':' TEST(TDigestTest, AccuracyStats_weibull) {','line_number':1246,'multiline':False]['text':'     runAccuracyTest(generateWeibull);','line_number':1247,'multiline':False]['text':' }','line_number':1248,'multiline':False]['text':' namespace','line_number':1249,'multiline':False]['text':' namespace mongo','line_number':1250,'multiline':False]