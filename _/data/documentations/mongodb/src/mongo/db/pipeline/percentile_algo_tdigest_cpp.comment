['text':'*
 *    Copyright (C) 2023-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]['text':' TODO SERVER-75565: 'boost::sort::spreadsort::spreadsort' shows an observable perf improvement','line_number':125,'multiline':False]['text':' over std::sort on large datasets. If switching to boost's spreadsort would need to re-tune','line_number':126,'multiline':False]['text':' the default delta setting and the size of the buffer.','line_number':127,'multiline':False]['text':' We compute accurate min and max values. This check must be done _before_ dealing with','line_number':142,'multiline':False]['text':' infinites.','line_number':143,'multiline':False]['text':' Even though strict ordering of centroids isn't guaranteed, the algorithm assumes it when','line_number':158,'multiline':False]['text':' computing percentiles (this is the reason t-digest cannot guarantee the accuracy bounds). So,','line_number':159,'multiline':False]['text':' under this assumption, let's find the centroid an input with rank 'rank' would have','line_number':160,'multiline':False]['text':' contributed to.','line_number':161,'multiline':False]['text':' index of the target centroid','line_number':162,'multiline':False]['text':' cumulative weight of all centroids up to, and including, i_th one','line_number':163,'multiline':False]['text':' We are not optimizing traversing the set of centroids for higher percentiles or when','line_number':165,'multiline':False]['text':' multiple percentiles have been requested because our benchmarks don't show this to be a','line_number':166,'multiline':False]['text':' problem in the accumulator context, and for expressions, where it might matter, we are not','line_number':167,'multiline':False]['text':' using t-digest.','line_number':168,'multiline':False]['text':' If the i_th centroid has weight exactly 1, it hasn't lost any information and we can give it','line_number':176,'multiline':False]['text':' out as the answer (if the centroids are strictly ordered, this answer would be accurate).','line_number':177,'multiline':False]['text':' We also assume that the inputs are uniformly distributed within each centroid so we can do','line_number':182,'multiline':False]['text':' linear interpolation between the means of the centroids to compute the percentile. Basically,','line_number':183,'multiline':False]['text':' given centroids {w: 10, m: 2.4} and {w: 16, m: 3.7} we assume that there are 10/2 + 16/2 = 13','line_number':184,'multiline':False]['text':' evenly distributed points in [2.4, 3.7). NB: we do _not_ interpolate with infinities.','line_number':185,'multiline':False]['text':' (r - rank) is in (0.0, wCur] by construction of 'r'','line_number':194,'multiline':False]['text':' The target point sits between the previous and i_th centroids' means.','line_number':196,'multiline':False]['text':' [wLeft, wLeft + wRight]','line_number':201,'multiline':False]['text':' The target point sits between the i_th and the next centroids' means (or _max).','line_number':203,'multiline':False]['text':' [0.0, wLeft]','line_number':208,'multiline':False]['text':' [0.0, 1.0]','line_number':210,'multiline':False]['text':' Both (right - left) and innerP are non-negative, so the computation below is guaranteed to be','line_number':212,'multiline':False]['text':' to the right of 'left' but the precision error might make it greater than 'right'...','line_number':213,'multiline':False]['text':' Invariant: after the merge, the weights of all centroids should add up to the new _n.','line_number':244,'multiline':False]['text':' to ensure floating point math below','line_number':249,'multiline':False]['text':' Conceptually, the algorithm treats 'sorted' as a t-digest with single-point centroids, merges','line_number':251,'multiline':False]['text':' the two sorted lists of centroids into one sorted list and then compacts it according to','line_number':252,'multiline':False]['text':' the scaling function (that is, merges the adjacent centroids if the size of the resulting','line_number':253,'multiline':False]['text':' centroid is allowed by the scaling function). We do this in a single pass, compacting the','line_number':254,'multiline':False]['text':' centroids as we are merging the sorted centroids with the sorted data.','line_number':255,'multiline':False]['text':' cumulative weights of the centroids up to (but not including) the current one','line_number':257,'multiline':False]['text':' Have run out of the sorted data => merge the remaining tail of centoids (some of them might','line_number':283,'multiline':False]['text':' need to be compacted).','line_number':284,'multiline':False]['text':' Have run out of the centroids => merge in the remainging tail of the sorted data.','line_number':297,'multiline':False]['text':' Invariant: after the merge, the weights of all centroids should add up to the new _n.','line_number':340,'multiline':False]['text':' to ensure floating point division below when it involves '_n'','line_number':345,'multiline':False]['text':' Conceptually, the algorithm merges the two sorted lists of centroids into one sorted list','line_number':347,'multiline':False]['text':' and then compacts it according to the scaling function (that is, merges the adjacent','line_number':348,'multiline':False]['text':' centroids if the size of the resulting centroid is allowed by the scaling function). We do','line_number':349,'multiline':False]['text':' this in a single pass, compacting the centroids as we are merging the sorted lists.','line_number':350,'multiline':False]['text':' cumulative weights of centroids up to (not including) the current one','line_number':352,'multiline':False]['text':' Process the remaining tail.','line_number':370,'multiline':False]['text':' namespace mongo','line_number':407,'multiline':False]