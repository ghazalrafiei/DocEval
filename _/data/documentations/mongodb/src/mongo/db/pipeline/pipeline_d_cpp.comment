['text':'*
 *    Copyright (C) 2018-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]['text':'*
 * Helper for findSbeCompatibleStagesForPushdown() that checks whether 'stage' is a $project or
 * $addFields that can be pushed down to SBE as a 'DocumentSourceInternalProjection' stage. If so,
 * this returns a pointer to a constructed object of the latter type, else it returns nullptr.
 ','line_number':169,'multiline':True]['text':'*
 * Helper for findSbeCompatibleStagesForPushdown() that creates a
 * 'DocumentSourceInternalReplaceRoot' from 'stage' if 'stage' is a '$replaceRoot' that can be
 * pushed down to SBE or returns nullptr otherwise.
 ','line_number':208,'multiline':True]['text':' A bit field with a bool flag for each aggregation pipeline stage that can be translated to SBE.','line_number':230,'multiline':False]['text':' The flags can be used to indicate which translations are enabled and/or supported in a particular','line_number':231,'multiline':False]['text':' context.','line_number':232,'multiline':False]['text':' The $project and $addField stages are considered the same for the purposes of SBE','line_number':237,'multiline':False]['text':' translation.','line_number':238,'multiline':False]['text':' Determine if 'stage' is eligible for SBE, and if it is add it to the 'stagesForPushdown' list and','line_number':250,'multiline':False]['text':' return true. Return false if 'stage' is ineligible, either because it is disallowed by','line_number':251,'multiline':False]['text':' 'allowedStages' or because it requires functionality that cannot be translated to SBE.','line_number':252,'multiline':False]['text':' We do not push to SBE an addFields that has been created as part of a setWindowFields','line_number':290,'multiline':False]['text':' stage because it causes a performance regression. TODO (SERVER-75103) : Once','line_number':291,'multiline':False]['text':' setWindowFields has been pushed to SBE, this should be removed.','line_number':292,'multiline':False]['text':'*
 * Prunes $addFields from 'stagesForPushdown' if it is the last stage, subject to additional
 * conditions. (Must be called repeatedly until it returns false.) When splitting a pipeline between
 * SBE and Classic DocumentSource stages, there is often a performance penalty for executing an
 * $addFields in SBE only to immediately translate its output to MutableDocument form for the
 * Classic DocumentSource execution phase. Instead, we keep the $addFields as a DocumentSource.
 *
 * 'containsEntirePipeline' indicates that 'stagesForPushdown' contains the entire aggregation
 * pipeline for the query, meaning that execution will use SBE exclusively, skipping the
 * MutableDocument translation step and follow-on Classic DocumentSource processing.
 *
 * Returns true iff it pruned a stage.
 ','line_number':354,'multiline':True]['text':' If we are able to push down the entire pipeline, we prefer to do that, rather than pruning','line_number':369,'multiline':False]['text':' this $addFields stage and requiring split SBE/Classic execution.','line_number':370,'multiline':False]['text':'*
 * Prunes $unwind from 'stagesForPushdown' if it is the last stage. (Must be called repeatedly until
 * it returns false.) This pruning is done because $unwind performance is bottlenecked by processing
 * of EExpressions for sbe::ProjectStages in the SBE VM, which is slower than Classic's native C++
 * projection implementation. Pushing $unwind down only has a performance benefit when doing so
 * allows additional non-$unwind stages to be pushed down after it.
 *
 * Returns true iff it pruned a stage.
 ','line_number':385,'multiline':True]['text':'*
 * After copying as many pipeline stages as possible into the 'stagesForPushdown' pipeline, this
 * second pass takes off any stages that may not benefit from execution in SBE.
 ','line_number':403,'multiline':True]['text':' have any stages been pruned?','line_number':410,'multiline':False]['text':' were any stages pruned in the current loop iteration?','line_number':411,'multiline':False]['text':' When 'minRequiredCompatibility' is permissive enough (because featureFlagSbeFull is','line_number':415,'multiline':False]['text':' enabled), do not remove trailing $addFields stages.','line_number':416,'multiline':False]['text':' Otherwise, remove trailing $addFields stages that we don't expect to improve','line_number':418,'multiline':False]['text':' performance when they execute in SBE.','line_number':419,'multiline':False]['text':' $unwind should not be the last stage pushed down as it is more expensive in SBE.','line_number':426,'multiline':False]['text':' Limit the number of aggregation pipeline stages that can be "pushed down" to the SBE stage','line_number':434,'multiline':False]['text':' builders. Compiling too many pipeline stages during stage building would overflow the call stack.','line_number':435,'multiline':False]['text':' The limit is higher for optimized builds, because optimization reduces the size of stack frames.','line_number':436,'multiline':False]['text':'*
 * Finds a prefix of stages from the given pipeline to prepare for pushdown into the inner query
 * layer so that it can be executed using SBE. Populates 'stagesForPushdown' with the result and
 * returns true iff _all_ stages were included in pushdown.
 *
 * Unless pushdown is completely disabled by
 * {'internalQueryFrameworkControl': 'forceClassicEngine'}, a stage can be extracted from the
 * pipeline if and only if all the stages before it are extracted and it meets the criteria for its
 * stage type. When 'internalQueryFrameworkControl' is set to 'trySbeRestricted', only '$group',
 * '$lookup', '$_internalUnpackBucket', and search can be extracted. Criteria by stage type:
 *
 * $group via 'DocumentSourceGroup':
 *   - The 'internalQuerySlotBasedExecutionDisableGroupPushdown' knob is false and
 *   - the $group is not a merging operation that aggregates partial groups
 *     (DocumentSourceGroupBase::doingMerge()).
 *
 * $lookup via 'DocumentSourceLookUp':
 *   - The 'internalQuerySlotBasedExecutionDisableLookupPushdown' query knob is false,
 *   - the $lookup uses only the 'localField'/'foreignField' syntax (no pipelines), and
 *   - the foreign collection is neither sharded nor a view.
 *
 * $project via 'DocumentSourceInternalProjection':
 *   - No additional criteria.
 *
 * $addFields via 'DocumentSourceInternalProjection':
 *   - The stage that _follows_ the $addFields is also pushed down _or_
 *   - the 'featureFlagSbeFull' flag is enabled.
 *
 * $replaceRoot/$replaceWith via 'DocumentSourceSingleDocumentTransformation':
 *   - No additional criteria.
 *
 * $sort via 'DocumentSourceSort':
 *   - The sort operation does not produce sort key "meta" fields need by a later merging operation
 *     (i.e., 'needsMerge' is false).
 *
 * $match via 'DocumentSourceMatch':
 *   - No additional criteria.
 *
 * $limit via 'DocumentSourceLimit':
 *   - No additional criteria.
 *
 * $skip via 'DocumentSourceSkip':
 *   - No additional criteria.
 *
 * 'DocumentSourceUnpackBucket':
 *   - The 'featureFlagSbeFull' flag is enabled.
 *
 * 'DocumentSourceSearch':
 *   - The 'featureFlagSearchInSbe' flag is enabled.
 *
 * $_internalUnpackBucket via 'DocumentSourceInternalUnpackBucket':
 *   - The 'featureFlagTimeSeriesInSbe' flag is enabled and
 *   - the 'internalQuerySlotBasedExecutionDisableTimeSeriesPushdown', is _not_ enabled,
 ','line_number':443,'multiline':True]['text':' No pushdown if we're using the classic engine.','line_number':503,'multiline':False]['text':' SERVER-78998: Refactor these checks so that they do not load their values multiple times','line_number':515,'multiline':False]['text':' during the same query.','line_number':516,'multiline':False]['text':' (Ignore FCV check): featureFlagSbeFull does not change the semantics of queries, so it can','line_number':517,'multiline':False]['text':' safely be enabled on some nodes and disabled on other nodes during upgrade/downgrade.','line_number':518,'multiline':False]['text':' 'trySbeRestricted' allows only $group, $lookup, $_internalUnpackBucket, and search stages to','line_number':526,'multiline':False]['text':' be pushed down. However, this can be overridden when 'sbeFullEnabled' is true.','line_number':527,'multiline':False]['text':' If lookup pushdown isn't enabled or the main collection is sharded or any of the','line_number':535,'multiline':False]['text':' secondary namespaces are sharded or are a view, then no $lookup stage will be eligible','line_number':536,'multiline':False]['text':' for pushdown.','line_number':537,'multiline':False]['text':'','line_number':538,'multiline':False]['text':' When acquiring locks for multiple collections, it is the case that we can only determine','line_number':539,'multiline':False]['text':' whether any secondary collection is a view or is sharded, not which ones are a view or','line_number':540,'multiline':False]['text':' are sharded and which ones aren't. As such, if any secondary collection is a view or is','line_number':541,'multiline':False]['text':' sharded, no $lookup will be eligible for pushdown.','line_number':542,'multiline':False]['text':' TODO (SERVER-80226): SBE execution of 'unwind' stages requires 'featureFlagSbeFull' to be','line_number':551,'multiline':False]['text':' enabled.','line_number':552,'multiline':False]['text':' Note: even if its sort pattern is SBE compatible, we cannot push down a $sort stage when','line_number':555,'multiline':False]['text':' the pipeline is the shard part of a sorted-merge query on a sharded collection. It is','line_number':556,'multiline':False]['text':' possible that the merge operation will need a $sortKey field from the sort, and SBE plans','line_number':557,'multiline':False]['text':' do not yet support metadata fields.','line_number':558,'multiline':False]['text':' TODO (SERVER-77229): SBE execution of $search requires 'featureFlagSearchInSbe' to be','line_number':565,'multiline':False]['text':' enabled.','line_number':566,'multiline':False]['text':' (Ignore FCV check): As with 'featureFlagSbeFull' (above), the effects of','line_number':567,'multiline':False]['text':' 'featureFlagSearchInSbe' are local to this node, making it safe to ignore the FCV.','line_number':568,'multiline':False]['text':' TODO (SERVER-80243): Remove 'featureFlagTimeSeriesInSbe' check.','line_number':573,'multiline':False]['text':' Push down at most kMaxPipelineStages stages for execution in SBE.','line_number':582,'multiline':False]['text':' Stop pushing stages down once we hit an incompatible stage.','line_number':592,'multiline':False]['text':' Remove stage patterns where pushing down may degrade performance.','line_number':598,'multiline':False]['text':' findSbeCompatibleStagesForPushdown','line_number':602,'multiline':False]['text':'*
 * Removes the first 'stagesToRemove' stages from the pipeline. This function is meant to be paired
 * with a call to findSbeCompatibleStagesForPushdown() - the caller must first get the stages to
 * push down, then remove them.
 ','line_number':604,'multiline':True]['text':' The collation on the ExpressionContext has been resolved to either the user-specified','line_number':649,'multiline':False]['text':' collation or the collection default. This BSON should never be empty even if the resolved','line_number':650,'multiline':False]['text':' collator is simple.','line_number':651,'multiline':False]['text':' Reset the 'sbeCompatible' flag before canonicalizing the 'findCommand' to potentially','line_number':668,'multiline':False]['text':' allow SBE to execute the portion of the query that's pushed down, even if the portion of','line_number':669,'multiline':False]['text':' the query that is not pushed down contains expressions not supported by SBE.','line_number':670,'multiline':False]['text':' Return an error instead of uasserting, since there are cases where the combination of','line_number':686,'multiline':False]['text':' sort and projection will result in a bad query, but when we try with a different','line_number':687,'multiline':False]['text':' combination it will be ok. e.g. a sort by {$meta: 'textScore'}, without any projection','line_number':688,'multiline':False]['text':' will fail, but will succeed when the corresponding '$meta' projection is passed in','line_number':689,'multiline':False]['text':' another attempt.','line_number':690,'multiline':False]['text':' Mark the metadata that's requested by the pipeline on the CQ.','line_number':694,'multiline':False]['text':' Attempt to get a plan executor that uses a DISTINCT_SCAN to scan exactly one document for','line_number':697,'multiline':False]['text':' each group. It's the caller's responsibility to deal with an error to create such a plan.','line_number':698,'multiline':False]['text':' If the GroupFromFirst transformation was generated for the $last case, we will need to','line_number':703,'multiline':False]['text':' flip the direction of any generated DISTINCT_SCAN to preserve the semantics of the query.','line_number':704,'multiline':False]['text':' We have to request a "strict" distinct plan because:','line_number':708,'multiline':False]['text':' 1) $group with distinct semantics doesn't de-duplicate the results.','line_number':709,'multiline':False]['text':' 2) Non-strict parameter would allow use of multikey indexes for DISTINCT_SCAN, which','line_number':710,'multiline':False]['text':'    means that for {a: [1, 2]} two distinct values would be returned, but for group keys','line_number':711,'multiline':False]['text':'    arrays shouldn't be traversed.','line_number':712,'multiline':False]['text':' Queries that can use SBE may push down compatible pipeline stages. 'getExecutorFind' will','line_number':720,'multiline':False]['text':' call this lambda in two phases: 1) determine compatible stages and attach them to the','line_number':721,'multiline':False]['text':' canonical query, and 2) finalize the push down and trim the pushed-down stages from the','line_number':722,'multiline':False]['text':' original pipeline.','line_number':723,'multiline':False]['text':' For performance, we pass a null callback instead of 'extractAndAttachPipelineStages' when','line_number':736,'multiline':False]['text':' 'pipeline' is empty. The 'extractAndAttachPipelineStages' is a no-op when there are no','line_number':737,'multiline':False]['text':' pipeline stages, so we can save some work by skipping it. The 'getExecutorFind()' function is','line_number':738,'multiline':False]['text':' responsible for checking that the callback is non-null before calling it.','line_number':739,'multiline':False]['text':' permitYield ','line_number':746,'multiline':True]['text':'*
 * Examines the indexes in 'collection' and returns the field name of a geo-indexed field suitable
 * for use in $geoNear. 2d indexes are given priority over 2dsphere indexes.
 *
 * The 'collection' is required to exist. Throws if no usable 2d or 2dsphere index could be found.
 ','line_number':750,'multiline':True]['text':' If there are no 2d indexes, look for a 2dsphere index.','line_number':776,'multiline':False]['text':'*
 * This attempts to either extract a $sample stage at the front of the pipeline or a
 * $_internalUnpackBucket stage at the front of the pipeline immediately followed by a $sample
 * stage. In the former case a 'nullptr' is returned for the second element of the pair <$sample,
 * $_internalUnpackBucket>, and if the latter case is encountered both elements of the pair will be
 * a populated. If the pipeline doesn't contain a $_internalUnpackBucket at the front of the
 * pipeline immediately followed by a $sample stage, then the first element in the pair will be a
 * 'nullptr'.
 ','line_number':797,'multiline':True]['text':' The time field maps to control.min.[time], control.max.[time], or','line_number':840,'multiline':False]['text':' _id, and $_internalUnpackBucket assumes that all of those fields are','line_number':841,'multiline':False]['text':' preserved. (We never push down a stage that would overwrite them.)','line_number':842,'multiline':False]['text':' Each field [meta].a.b.c maps to 'meta.a.b.c'.','line_number':844,'multiline':False]['text':' Skip the last field, which is time: only check the meta fields','line_number':852,'multiline':False]['text':' This stage operates on events: check the event-level field names.','line_number':864,'multiline':False]['text':' This stage operates on buckets: check the bucket-level field names.','line_number':867,'multiline':False]['text':' There can be exactly one unpack stage in a pipeline but multiple sort stages. We'll find the','line_number':872,'multiline':False]['text':' _first_ sort.','line_number':873,'multiline':False]['text':' namespace','line_number':903,'multiline':False]['text':' Verify that we are already under a collection lock or in a lock-free read. We avoid taking','line_number':914,'multiline':False]['text':' locks ourselves in this function because double-locking forces any PlanExecutor we create to','line_number':915,'multiline':False]['text':' adopt an INTERRUPT_ONLY policy.','line_number':916,'multiline':False]['text':' Suppose that a time-series bucket collection is observed to contain 200 buckets, and the','line_number':936,'multiline':False]['text':' 'gTimeseriesBucketMaxCount' parameter is set to 1000. If all buckets are full, then the','line_number':937,'multiline':False]['text':' maximum possible measurment count would be 200 * 1000 = 200,000. While the','line_number':938,'multiline':False]['text':' 'SampleFromTimeseriesBucket' plan is more efficient when the sample size is small','line_number':939,'multiline':False]['text':' relative to the total number of measurements in the time-series collection, for larger','line_number':940,'multiline':False]['text':' sample sizes the top-k sort based sample is faster. Experiments have approximated that','line_number':941,'multiline':False]['text':' the tipping point is roughly when the requested sample size is greater than 1% of the','line_number':942,'multiline':False]['text':' maximum possible number of measurements in the collection (i.e. numBuckets *','line_number':943,'multiline':False]['text':' maxMeasurementsPerBucket).','line_number':944,'multiline':False]['text':' Attempt to get a random cursor from the RecordStore.','line_number':951,'multiline':False]['text':' The storage engine has no random cursor support.','line_number':954,'multiline':False]['text':' Build a MultiIteratorStage and pass it the random-sampling RecordCursor.','line_number':958,'multiline':False]['text':' Because 'numRecords' includes orphan documents, our initial decision to optimize the $sample','line_number':977,'multiline':False]['text':' cursor may have been mistaken. For sharded collections, build a TRIAL plan that will switch','line_number':978,'multiline':False]['text':' to a collection scan if the ratio of orphaned to owned documents encountered over the first','line_number':979,'multiline':False]['text':' 100 works() is such that we would have chosen not to optimize.','line_number':980,'multiline':False]['text':' We can't take ARHASH optimization path for a direct $sample on the system.buckets','line_number':983,'multiline':False]['text':' collection because data is in compressed form. If we did have a direct $sample on the','line_number':984,'multiline':False]['text':' system.buckets collection, then the 'bucketUnpacker' would not be set up properly. We','line_number':985,'multiline':False]['text':' also should bail out early if a $sample is made against a time series collection that is','line_number':986,'multiline':False]['text':' empty. If we don't the 'minAdvancedToWorkRatio' can be nan/-nan depending on the','line_number':987,'multiline':False]['text':' architecture.','line_number':988,'multiline':False]['text':' Use a 'TrialStage' to run a trial between 'SampleFromTimeseriesBucket' and','line_number':993,'multiline':False]['text':' 'UnpackTimeseriesBucket' with $sample left in the pipeline in-place. If the buckets are','line_number':994,'multiline':False]['text':' not sufficiently full, or the 'SampleFromTimeseriesBucket' plan draws too many','line_number':995,'multiline':False]['text':' duplicates, then we will fall back to the 'TrialStage' backup plan. This backup plan uses','line_number':996,'multiline':False]['text':' the top-k sort sampling approach.','line_number':997,'multiline':False]['text':'','line_number':998,'multiline':False]['text':' Suppose the 'gTimeseriesBucketMaxCount' is 1000, but each bucket only contains 500','line_number':999,'multiline':False]['text':' documents on average. The observed trial advanced/work ratio approximates the average','line_number':1000,'multiline':False]['text':' bucket fullness, noted here as "abf". In this example, abf = 500 / 1000 = 0.5.','line_number':1001,'multiline':False]['text':' Experiments have shown that the optimized 'SampleFromTimeseriesBucket' algorithm performs','line_number':1002,'multiline':False]['text':' better than backup plan when','line_number':1003,'multiline':False]['text':'','line_number':1004,'multiline':False]['text':'     sampleSize < 0.02 * abf * numRecords * gTimeseriesBucketMaxCount','line_number':1005,'multiline':False]['text':'','line_number':1006,'multiline':False]['text':'  This inequality can be rewritten as','line_number':1007,'multiline':False]['text':'','line_number':1008,'multiline':False]['text':'     abf > sampleSize / (0.02 * numRecords * gTimeseriesBucketMaxCount)','line_number':1009,'multiline':False]['text':'','line_number':1010,'multiline':False]['text':' Therefore, if the advanced/work ratio exceeds this threshold, we will use the','line_number':1011,'multiline':False]['text':' 'SampleFromTimeseriesBucket' plan. Note that as the sample size requested by the user','line_number':1012,'multiline':False]['text':' becomes larger with respect to the number of buckets, we require a higher advanced/work','line_number':1013,'multiline':False]['text':' ratio in order to justify using 'SampleFromTimeseriesBucket'.','line_number':1014,'multiline':False]['text':'','line_number':1015,'multiline':False]['text':' Additionally, we require the 'TrialStage' to approximate the abf as at least 0.25. When','line_number':1016,'multiline':False]['text':' buckets are mostly empty, the 'SampleFromTimeseriesBucket' will be inefficient due to a','line_number':1017,'multiline':False]['text':' lot of sampling "misses".','line_number':1018,'multiline':False]['text':' In the sharded case, we need to use a ShardFilterer within the ARHASH plan to','line_number':1027,'multiline':False]['text':' eliminate orphans from the working set, since the stage owns the cursor.','line_number':1028,'multiline':False]['text':' By using a quantity slightly higher than 'kMaxPresampleSize', we ensure that the','line_number':1039,'multiline':False]['text':' 'SampleFromTimeseriesBucket' stage won't fail due to too many consecutive sampling','line_number':1040,'multiline':False]['text':' attempts during the 'TrialStage's trial period.','line_number':1041,'multiline':False]['text':' In the sharded case, we need to add a shard-filterer stage to the backup plan to','line_number':1050,'multiline':False]['text':' eliminate orphans. The trial plan is thus SHARDING_FILTER-COLLSCAN.','line_number':1051,'multiline':False]['text':' In a sharded collection we need to preserve the $sample source in order to provide the','line_number':1060,'multiline':False]['text':' AsyncResultsMerger with $sortKeys it can use to merge samples from multiple shards.','line_number':1061,'multiline':False]['text':' However, this means we need to perform a sort on the results of ARHASH. This work is not','line_number':1062,'multiline':False]['text':' counted by the TrialStage, so we impose an arbitrary upper limit on the sample size','line_number':1063,'multiline':False]['text':' before defaulting to a Top-K sort, in order to bound the cost of sorting the sample','line_number':1064,'multiline':False]['text':' returned by ARHASH.','line_number':1065,'multiline':False]['text':' We need to use a TrialStage approach to handle a problem where ARHASH sampling can','line_number':1070,'multiline':False]['text':' fail due to small measurement counts. We can push sampling and bucket unpacking down','line_number':1071,'multiline':False]['text':' to the PlanStage layer and erase $_internalUnpackBucket and $sample.','line_number':1072,'multiline':False]['text':' The ratio of owned to orphaned documents must be at least equal to the ratio between the','line_number':1083,'multiline':False]['text':' requested sampleSize and the maximum permitted sampleSize for the original constraints to','line_number':1084,'multiline':False]['text':' be satisfied. For instance, if there are 200 documents and the sampleSize is 5, then at','line_number':1085,'multiline':False]['text':' least (5 / (200*0.05)) = (5/10) = 50% of those documents must be owned. If less than 5%','line_number':1086,'multiline':False]['text':' of the documents in the collection are owned, we default to the backup plan.','line_number':1087,'multiline':False]['text':' Since the incoming operation is sharded, use the CSS to infer the filtering metadata for','line_number':1090,'multiline':False]['text':' the collection. We get the shard ownership filter after checking to see if the collection','line_number':1091,'multiline':False]['text':' is sharded to avoid an invariant from being fired in this call.','line_number':1092,'multiline':False]['text':' The trial plan is SHARDING_FILTER-MULTI_ITERATOR.','line_number':1094,'multiline':False]['text':' The backup plan is SHARDING_FILTER-COLLSCAN.','line_number':1097,'multiline':False]['text':' Place a TRIAL stage at the root of the plan tree, and pass it the trial and backup plans.','line_number':1102,'multiline':False]['text':' For sharded collections, the root of the plan tree is a TrialStage that may have chosen','line_number':1122,'multiline':False]['text':' either a random-sampling cursor trial plan or a COLLSCAN backup plan. We can only optimize','line_number':1123,'multiline':False]['text':' the $sample aggregation stage if the trial plan was chosen.','line_number':1124,'multiline':False]['text':' Replace $sample stage with $sampleFromRandomCursor stage.','line_number':1128,'multiline':False]['text':' For timeseries collections, we should remove the $_internalUnpackBucket stage which is at','line_number':1135,'multiline':False]['text':' the front of the pipeline, regardless of which plan the TrialStage has chosen. The','line_number':1136,'multiline':False]['text':' unpacking will be done by the 'UnpackTimeseriesBucket' PlanStage if the backup plan','line_number':1137,'multiline':False]['text':' (Top-K sort plan) was chosen, and by the 'SampleFromTimeseriesBucket' PlanStage if the','line_number':1138,'multiline':False]['text':' ARHASH plan was chosen.','line_number':1139,'multiline':False]['text':' We can push down the $sample source into the PlanStage layer if the chosen strategy uses','line_number':1142,'multiline':False]['text':' ARHASH sampling on unsharded collections. For sharded collections, we cannot erase','line_number':1143,'multiline':False]['text':' $sample because we need to preserve the sort metadata (the $sortKey field) for the merge','line_number':1144,'multiline':False]['text':' cursor on mongos.','line_number':1145,'multiline':False]['text':' The order in which we evaluate these arguments is significant. We'd like to be','line_number':1175,'multiline':False]['text':' sure that the DocumentSourceCursor is created _last_, because if we run into a','line_number':1176,'multiline':False]['text':' case where a DocumentSourceCursor has been created (yet hasn't been put into a','line_number':1177,'multiline':False]['text':' Pipeline) and an exception is thrown, an invariant will trigger in the','line_number':1178,'multiline':False]['text':' DocumentSourceCursor. This is a design flaw in DocumentSourceCursor.','line_number':1179,'multiline':False]['text':' We will be modifying the source vector as we go.','line_number':1204,'multiline':False]['text':' We skip the 'requiresInputDocSource' check in the case of pushing $search down into SBE,','line_number':1207,'multiline':False]['text':' as $search has 'requiresInputDocSource' as false.','line_number':1208,'multiline':False]['text':' Try to inspect if the DocumentSourceSample or a DocumentSourceInternalUnpackBucket stage','line_number':1217,'multiline':False]['text':' can be optimized for sampling backed by a storage engine supplied random cursor.','line_number':1218,'multiline':False]['text':' Optimize an initial $sample stage if possible.','line_number':1222,'multiline':False]['text':' If the first stage is $geoNear, prepare a special DocumentSourceGeoNearCursor stage;','line_number':1232,'multiline':False]['text':' otherwise, create a generic DocumentSourceCursor.','line_number':1233,'multiline':False]['text':' If the pipeline doesn't need a $cursor stage, there will be no callback function and','line_number':1252,'multiline':False]['text':' PlanExecutor provided in the 'attachExecutorCallback' object, so we don't need to do','line_number':1253,'multiline':False]['text':' anything.','line_number':1254,'multiline':False]['text':'*
 * Look for $sort, $group at the beginning of the pipeline, potentially returning either or both.
 * Returns nullptr for any of the stages that are not found. Note that we are not looking for the
 * opposite pattern ($group, $sort). In that case, this function will return only the $group stage.
 *
 * This function will not return the $group in the case that there is an initial $sort with
 * intermediate stages that separate it from the $group (e.g.: $sort, $limit, $group). That includes
 * the case of a $sort with a non-null value for getLimitSrc(), indicating that there was previously
 * a $limit stage that was optimized away.
 ','line_number':1274,'multiline':True]['text':' This $sort stage was previously followed by a $limit stage.','line_number':1296,'multiline':False]['text':' If the disablePipelineOptimization failpoint is enabled, then do not attempt the skip','line_number':1310,'multiline':False]['text':' pushdown optimization.','line_number':1311,'multiline':False]['text':' Removing stages may have produced the opportunity for additional optimizations.','line_number':1319,'multiline':False]['text':' If the disablePipelineOptimization failpoint is enabled, then do not attempt the limit and','line_number':1326,'multiline':False]['text':' skip pushdown optimization.','line_number':1327,'multiline':False]['text':' It is important to call 'extractLimitForPushdown' before 'extractSkipForPushdown'. Otherwise','line_number':1333,'multiline':False]['text':' there could be a situation when $limit stages in pipeline would prevent','line_number':1334,'multiline':False]['text':' 'extractSkipForPushdown' from extracting all $skip stages.','line_number':1335,'multiline':False]['text':' Removing stages may have produced the opportunity for additional optimizations.','line_number':1340,'multiline':False]['text':'*
 * Given a dependency set and a pipeline, builds a projection BSON object to push down into the
 * PlanStage layer. The rules to push down the projection are as follows:
 *    1. If there is an inclusion projection at the front of the pipeline, it will be pushed down
 *       as is.
 *    2. If there is no inclusion projection at the front of the pipeline, but there is a finite
 *       dependency set, a projection representing this dependency set will be pushed down.
 *    3. If there is an exclusion projection at the front of the pipeline, it will be pushed down.
 *    4. Otherwise, an empty projection is returned and no projection push down will happen.
 *
 * If 'allowExpressions' is true, the returned projection may include expressions (which can only
 * happen in case 1). If 'allowExpressions' is false and the projection we find has expressions,
 * then we fall through to case 2 and attempt to push down a pure-inclusion projection based on its
 * dependencies.
 *
 * If 'timeseriesBoundedSortOptimization' is true, an exclusion projection won't be pushed down,
 * because it breaks PlanExecutorImpl analysis required to enable this optimization.
 ','line_number':1346,'multiline':True]['text':' Short-circuit if the pipeline is empty: there is no projection and nothing to push down.','line_number':1370,'multiline':False]['text':' If there is an inclusion projection at the front of the pipeline, we have case 1.','line_number':1385,'multiline':False]['text':' If there is a finite dependency set, return a projection representing this dependency set.','line_number':1395,'multiline':False]['text':' This is case 2.','line_number':1396,'multiline':False]['text':' If there is an exclusion projection at the front of the pipeline, we have case 3.','line_number':1404,'multiline':False]['text':' TODO SERVER-70655: Remove this check and argument when it is no longer needed.','line_number':1407,'multiline':False]['text':' Case 4: no projection to push down','line_number':1416,'multiline':False]['text':' namespace','line_number':1419,'multiline':False]['text':' Check the sort we're asking for is on time, and that the buckets are actually','line_number':1435,'multiline':False]['text':' ordered on time.','line_number':1436,'multiline':False]['text':' Check that the directions agree.','line_number':1439,'multiline':False]['text':' Scanning only part of an index means we don't see all the index keys for a','line_number':1450,'multiline':False]['text':' document, which means the representative (first key we encounter, for a','line_number':1451,'multiline':False]['text':' given document) will be different. For simplicity, just check whether the','line_number':1452,'multiline':False]['text':' index is multikey. Mabye we could do better by looking at whether each field','line_number':1453,'multiline':False]['text':' separately is multikey, or by allowing a full index scan.','line_number':1454,'multiline':False]['text':' The index component must not be special.','line_number':1466,'multiline':False]['text':' Is the index (as it is stored) ascending or descending on this field?','line_number':1469,'multiline':False]['text':' Does the index scan produce this field in ascending or descending order?','line_number':1471,'multiline':False]['text':' For example: a backwards scan of a descending index produces ascending data.','line_number':1472,'multiline':False]['text':' Return none if the keyPattern cannot support the sort.','line_number':1477,'multiline':False]['text':' Compare the requested 'sort' against the index 'keyPattern' one field at a time.','line_number':1479,'multiline':False]['text':' - If the leading fields are compatible, keep comparing.','line_number':1480,'multiline':False]['text':' - If the leading field of the index has a point predicate, ignore it.','line_number':1481,'multiline':False]['text':' - If we reach the end of the sort first, success!','line_number':1482,'multiline':False]['text':' - if we find a field of the sort that the index can't satisfy, fail.','line_number':1483,'multiline':False]['text':' We never found a 'time' field in the sort.','line_number':1489,'multiline':False]['text':' There are still components of the sort, that the index key didn't satisfy.','line_number':1493,'multiline':False]['text':' We don't handle special $meta sort.','line_number':1497,'multiline':False]['text':' Does the leading sort field match the index?','line_number':1501,'multiline':False]['text':' No conflict. Continue comparing the index vs the sort.','line_number':1509,'multiline':False]['text':' Does this index field have a point predicate?','line_number':1515,'multiline':False]['text':' We require the 'time' field to be the last component of the sort.','line_number':1529,'multiline':False]['text':' (It's fine if the index has additional fields; we just ignore those.)','line_number':1530,'multiline':False]['text':' Now any of the following index fields can satisfy a sort on time:','line_number':1534,'multiline':False]['text':' - control.min.time','line_number':1535,'multiline':False]['text':' - control.max.time','line_number':1536,'multiline':False]['text':' - _id  (like control.min.time but may break ties)','line_number':1537,'multiline':False]['text':' as long as the direction matches.','line_number':1538,'multiline':False]['text':' However, it's not possible for users to index the bucket _id (unless they','line_number':1539,'multiline':False]['text':' bypass the view), so don't bother optimizing that case.','line_number':1540,'multiline':False]['text':' If we've inserted a date before 1-1-1970, we round the min up towards 1970,','line_number':1545,'multiline':False]['text':' rather then down, which has the effect of increasing the control.min.t.','line_number':1546,'multiline':False]['text':' This means the minimum time in the bucket is likely to be lower than','line_number':1547,'multiline':False]['text':' indicated and thus, actual dates may be out of order relative to what's','line_number':1548,'multiline':False]['text':' indicated by the bucket bounds.','line_number':1549,'multiline':False]['text':' Success! Every field of the sort can be satisfied by a field of the index.','line_number':1557,'multiline':False]['text':' Now the caller wants to know:','line_number':1559,'multiline':False]['text':' 1. Does the field in the index agree with the scan direction?','line_number':1560,'multiline':False]['text':'    An index on 'control.min.time' or '_id' is better for ascending.','line_number':1561,'multiline':False]['text':'    An index on 'control.max.time' is better for descending.','line_number':1562,'multiline':False]['text':' 2. Which field was first? min or max (treating _id the same as min).','line_number':1563,'multiline':False]['text':' This index field can't satisfy this sort field.','line_number':1569,'multiline':False]['text':' namespace mongo','line_number':1576,'multiline':False]['text':' Check that the index isn't special.','line_number':1587,'multiline':False]['text':' Verify the direction and fieldNames match.','line_number':1592,'multiline':False]['text':' Terminate early if it wasn't max or min or if the directions don't match.','line_number':1597,'multiline':False]['text':' If they don't have the same path length they cannot agree.','line_number':1611,'multiline':False]['text':' Check these paths are on the meta field.','line_number':1615,'multiline':False]['text':' If meta was the only path component then return true.','line_number':1623,'multiline':False]['text':' Note: We already checked that the path lengths are equal.','line_number':1624,'multiline':False]['text':' Otherwise return if the remaining path components are equal.','line_number':1628,'multiline':False]['text':' Reverse the sort pattern so we can look for indexes that match.','line_number':1636,'multiline':False]['text':' The field wasn't meta or time, so no direction preference should be made.','line_number':1655,'multiline':False]['text':' The $search is pushed down into SBE executor.','line_number':1699,'multiline':False]['text':' Create a yield policy for metadata cursor.','line_number':1701,'multiline':False]['text':' Make a last effort to optimize pipeline stages before potentially detaching them to be','line_number':1718,'multiline':False]['text':' pushed down into the query executor.','line_number':1719,'multiline':False]['text':' Look for an initial match. This works whether we got an initial query or not. If not, it','line_number':1725,'multiline':False]['text':' results in a "{}" query, which will be what we want in that case.','line_number':1726,'multiline':False]['text':' If a $match query is pulled into the cursor, the $match is redundant, and can be','line_number':1731,'multiline':False]['text':' removed from the pipeline.','line_number':1732,'multiline':False]['text':' A $geoNear stage, the only other stage that can produce an initial query, is also','line_number':1735,'multiline':False]['text':' a valid initial stage. However, we should be in prepareGeoNearCursorSource() instead.','line_number':1736,'multiline':False]['text':' If there is a $limit or $skip stage (or multiple of them) that could be pushed down into the','line_number':1747,'multiline':False]['text':' PlanStage layer, obtain the value of the limit and skip and remove the $limit and $skip','line_number':1748,'multiline':False]['text':' stages from the pipeline.','line_number':1749,'multiline':False]['text':'','line_number':1750,'multiline':False]['text':' This analysis is done here rather than in 'optimizePipeline()' because swapping $limit before','line_number':1751,'multiline':False]['text':' stages such as $project is not always useful, and can sometimes defeat other optimizations.','line_number':1752,'multiline':False]['text':' In particular, in a sharded scenario a pipeline such as [$project, $limit] is preferable to','line_number':1753,'multiline':False]['text':' [$limit, $project]. The former permits the execution of the projection operation to be','line_number':1754,'multiline':False]['text':' parallelized across all targeted shards, whereas the latter would bring all of the data to a','line_number':1755,'multiline':False]['text':' merging shard first, and then apply the projection serially. See SERVER-24981 for a more','line_number':1756,'multiline':False]['text':' detailed discussion.','line_number':1757,'multiline':False]['text':'','line_number':1758,'multiline':False]['text':' This only handles the case in which the the $limit or $skip can logically be swapped to the','line_number':1759,'multiline':False]['text':' front of the pipeline. We can also push down a $limit which comes after a $sort into the','line_number':1760,'multiline':False]['text':' PlanStage layer, but that is handled elsewhere.','line_number':1761,'multiline':False]['text':' If this is a query on a time-series collection we might need to keep it fully classic to','line_number':1768,'multiline':False]['text':' ensure no perf regressions until we implement the corresponding scenarios fully in SBE.','line_number':1769,'multiline':False]['text':' Do not double-optimize the sort.','line_number':1771,'multiline':False]['text':' But in classic it may be eligible for a post-planning sort optimization. We check eligibility','line_number':1778,'multiline':False]['text':' and perform the rewrite here.','line_number':1779,'multiline':False]['text':' Whether to use bounded sort or not is determined _after_ the executor is created, based','line_number':1785,'multiline':False]['text':' on whether the chosen collection access stage would support it. Because bounded sort and','line_number':1786,'multiline':False]['text':' streaming group aren't implemented in SBE yet we have to block the whole pipeline from','line_number':1787,'multiline':False]['text':' lowering to SBE so that it has the chance of doing the optimization. To allow as many','line_number':1788,'multiline':False]['text':' sort + group pipelines over time-series to lower to SBE we'll only block those that sort','line_number':1789,'multiline':False]['text':' on time as these are the only ones that _might_ end up using bounded sort.','line_number':1790,'multiline':False]['text':' Note: This check (sort on time after unpacking) also disables the streaming group','line_number':1791,'multiline':False]['text':' optimization, that might happen w/o bounded sort.','line_number':1792,'multiline':False]['text':' Create the PlanExecutor.','line_number':1802,'multiline':False]['text':' If this is a query on a time-series collection then it may be eligible for a post-planning','line_number':1819,'multiline':False]['text':' sort optimization. We check eligibility and perform the rewrite here.','line_number':1820,'multiline':False]['text':' Get source stage','line_number':1824,'multiline':False]['text':' Scan the pipeline to check if it's compatible with the  optimization.','line_number':1868,'multiline':False]['text':' do nothing','line_number':1880,'multiline':False]['text':' Check that the time field is preserved.','line_number':1893,'multiline':False]['text':' If the sort is compound, check that the entire meta field is preserved.','line_number':1897,'multiline':False]['text':' - Is there a meta field?','line_number':1899,'multiline':False]['text':' - Will it be unpacked?','line_number':1900,'multiline':False]['text':' - Will it be overwritten by 'computedMetaProjFields'?','line_number':1901,'multiline':False]['text':' This is safe because we have seen a sort so we must have at least one stage','line_number':1922,'multiline':False]['text':' to the left of the current iterator position.','line_number':1923,'multiline':False]['text':' Since the sortPattern and the direction of the index don't agree we must','line_number':1943,'multiline':False]['text':' use the offset to get an estimate on the bounds of the bucket.','line_number':1944,'multiline':False]['text':'*
                         * We wish to create the following predicate to avoid returning incorrect
                         * results in the unlikely event bucketMaxSpanSeconds changes under us.
                         *
                         * {$expr:
                         *   {$lte: [
                         *     {$subtract: [$control.max.timeField, $control.min.timeField]},
                         *     {$const: bucketMaxSpanSeconds, in milliseconds}
                         * ]}}
                         ','line_number':1958,'multiline':True]['text':' This produces {$lte: ... }','line_number':1971,'multiline':False]['text':' This produces [...]','line_number':1975,'multiline':False]['text':' This produces {$subtract: ... }','line_number':1977,'multiline':False]['text':' This produces [...]','line_number':1980,'multiline':False]['text':' This produces "$control.max.timeField"','line_number':1982,'multiline':False]['text':' This produces "$control.min.timeField"','line_number':1985,'multiline':False]['text':' This produces {$const: maxBucketSpanSeconds}','line_number':1990,'multiline':False]['text':' Ensure we're erasing the sort source.','line_number':2001,'multiline':False]['text':' If this is a change stream pipeline or a resharding resume token has been requested, make','line_number':2017,'multiline':False]['text':' sure that we tell DSCursor to track the oplog time.','line_number':2018,'multiline':False]['text':' $geoNear can only run over the main collection.','line_number':2046,'multiline':False]['text':' If the user specified a "key" field, use that field to satisfy the "near" query. Otherwise,','line_number':2058,'multiline':False]['text':' look for a geo-indexed field in 'collection' that can.','line_number':2059,'multiline':False]['text':' Create a PlanExecutor whose query is the "near" predicate on 'nearFieldName' combined with','line_number':2065,'multiline':False]['text':' the optional "query" argument in the $geoNear stage.','line_number':2066,'multiline':False]['text':' sortStage ','line_number':2075,'multiline':True]['text':' rewrittenGroupStage ','line_number':2076,'multiline':True]['text':' timeseriesBoundedSortOptimization ','line_number':2083,'multiline':True]['text':' Remove the initial $geoNear; it will be replaced by $geoNearCursor.','line_number':2100,'multiline':False]['text':' The $_requestReshardingResumeToken parameter is only valid for an oplog scan.','line_number':2130,'multiline':False]['text':' If there is a sort stage eligible for pushdown, serialize its SortPattern to a BSONObj. The','line_number':2136,'multiline':False]['text':' BSONObj format is currently necessary to request that the sort is computed by the query layer','line_number':2137,'multiline':False]['text':' inside the inner PlanExecutor. We also remove the $sort stage from the Pipeline, since it','line_number':2138,'multiline':False]['text':' will be handled instead by PlanStage execution.','line_number':2139,'multiline':False]['text':' Now that we've pushed down the sort, see if there is a $limit and $skip to push down','line_number':2148,'multiline':False]['text':' also. We should not already have a limit or skip here, otherwise it would be incorrect','line_number':2149,'multiline':False]['text':' for the caller to pass us a sort stage to push down, since the order matters.','line_number':2150,'multiline':False]['text':' Since all $limit stages were already pushdowned to the sort stage, we are only looking','line_number':2154,'multiline':False]['text':' for $skip stages.','line_number':2155,'multiline':False]['text':' Since the limit from $sort is going before the extracted $skip stages, we construct','line_number':2158,'multiline':False]['text':' 'LimitThenSkip' object and then convert it 'SkipThenLimit'.','line_number':2159,'multiline':False]['text':' Perform dependency analysis. In order to minimize the dependency set, we only analyze the','line_number':2163,'multiline':False]['text':' stages that remain in the pipeline after pushdown. In particular, any dependencies for a','line_number':2164,'multiline':False]['text':' $match or $sort pushed down into the query layer will not be reflected here.','line_number':2165,'multiline':False]['text':' Build a BSONObj representing a projection eligible for pushdown. If there is an inclusion','line_number':2171,'multiline':False]['text':' projection at the front of the pipeline, it will be removed and handled by the PlanStage','line_number':2172,'multiline':False]['text':' layer. If a projection cannot be pushed down, an empty BSONObj will be returned.','line_number':2173,'multiline':False]['text':' In most cases .find() behaves as if it evaluates in a predictable order:','line_number':2175,'multiline':False]['text':'     predicate, sort, skip, limit, projection.','line_number':2176,'multiline':False]['text':' But there is at least one case where it runs the projection before the sort/skip/limit:','line_number':2177,'multiline':False]['text':' when the predicate has a rooted $or.  (In that case we plan each branch of the $or','line_number':2178,'multiline':False]['text':' separately, using Subplan, and include the projection on each branch.)','line_number':2179,'multiline':False]['text':' To work around this behavior, don't allow pushing down expressions if we are also going','line_number':2181,'multiline':False]['text':' to push down a sort, skip or limit. We don't want the expressions to be evaluated on any','line_number':2182,'multiline':False]['text':' documents that the sort/skip/limit would have filtered out. (The sort stage can be a','line_number':2183,'multiline':False]['text':' top-k sort, which both sorts and limits.)','line_number':2184,'multiline':False]['text':' See if the query system can handle the $group and $sort stage using a DISTINCT_SCAN','line_number':2193,'multiline':False]['text':' (SERVER-9507).','line_number':2194,'multiline':False]['text':' isCountLike ','line_number':2211,'multiline':True]['text':' Any $limit stage before the $group stage should make the pipeline ineligible for this','line_number':2214,'multiline':False]['text':' optimization.','line_number':2215,'multiline':False]['text':' We remove the $sort and $group stages that begin the pipeline, because the executor','line_number':2218,'multiline':False]['text':' will handle the sort, and the groupTransform (added below) will handle the $group','line_number':2219,'multiline':False]['text':' stage.','line_number':2220,'multiline':False]['text':' independentOfAnyCollection ','line_number':2229,'multiline':True]['text':' If this pipeline is a change stream, then the cursor must use the simple collation, so we','line_number':2240,'multiline':False]['text':' temporarily switch the collator on the ExpressionContext to nullptr. We do this here because','line_number':2241,'multiline':False]['text':' by this point, all the necessary pipeline analyses and optimizations have already been','line_number':2242,'multiline':False]['text':' performed. Note that 'collatorStash' restores the original collator when it leaves scope.','line_number':2243,'multiline':False]['text':' groupForDistinctScan ','line_number':2254,'multiline':True]['text':' isCountLike ','line_number':2258,'multiline':True]['text':' While constructing the executor, some stages might have been lowered from the 'pipeline' into','line_number':2260,'multiline':False]['text':' the executor, so we need to recheck whether the executor's layer can still produce an empty','line_number':2261,'multiline':False]['text':' document.','line_number':2262,'multiline':False]['text':' (Ignore FCV check): FCV checking is unnecessary because SBE execution is local to a given','line_number':2294,'multiline':False]['text':' node.','line_number':2295,'multiline':False]['text':' namespace mongo','line_number':2303,'multiline':False]