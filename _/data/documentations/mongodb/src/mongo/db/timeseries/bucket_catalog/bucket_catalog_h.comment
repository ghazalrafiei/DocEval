['text':'*
 *    Copyright (C) 2020-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]['text':'*
 * Whether to allow inserts to be batched together with those from other clients.
 ','line_number':85,'multiline':True]['text':'*
 * Return type indicating that a call to 'insert' or 'tryInsert' successfully staged the input
 * measurement for insertion. See 'insert' and 'tryInsert' for more information.
 ','line_number':93,'multiline':True]['text':'*
 * Return type indicating that a call to 'tryInsert' must retry after waiting for a conflicting
 * operation to resolve. Caller should wait using 'waitToInsert'.
 *
 * In particular, if 'tryInsert' would have generated a 'ReopeningContext', but there is already an
 * outstanding 'ReopeningRequest' or a prepared 'WriteBatch' for a bucket in the series (same
 * metaField value), that represents a conflict.
 ','line_number':110,'multiline':True]['text':'*
 * Variant representing the possible outcomes of 'tryInsert' or 'insert'. See 'tryInsert' and
 * 'insert' for more details.
 ','line_number':120,'multiline':True]['text':'*
 * Struct to hold a portion of the buckets managed by the catalog.
 *
 * Each of the bucket lists, as well as the buckets themselves, are protected by 'mutex'.
 ','line_number':126,'multiline':True]['text':' All access to a stripe should happen while 'mutex' is locked.','line_number':132,'multiline':False]['text':' All buckets currently open in the catalog, including buckets which are full or pending','line_number':136,'multiline':False]['text':' closure but not yet committed, indexed by BucketId. Owning pointers.','line_number':137,'multiline':False]['text':' All buckets currently open in the catalog, including buckets which are full or pending','line_number':140,'multiline':False]['text':' closure but not yet committed, indexed by BucketKey. Non-owning pointers.','line_number':141,'multiline':False]['text':' Open buckets that do not have any outstanding writes.','line_number':144,'multiline':False]['text':' Buckets that are not currently in the catalog, but which are eligible to receive more','line_number':148,'multiline':False]['text':' measurements. The top-level map is keyed by the hash of the BucketKey, while the stored','line_number':149,'multiline':False]['text':' map is keyed by the bucket's minimum timestamp.','line_number':150,'multiline':False]['text':'','line_number':151,'multiline':False]['text':' We invert the key comparison in the inner map so that we can use lower_bound to efficiently','line_number':152,'multiline':False]['text':' find an archived bucket that is a candidate for an incoming measurement.','line_number':153,'multiline':False]['text':' All series currently with outstanding reopening operations. Used to coordinate disk access','line_number':159,'multiline':False]['text':' between reopenings and regular writes to prevent stale reads and corrupted updates.','line_number':160,'multiline':False]['text':'*
 * This class holds all the data used to coordinate and combine time series inserts amongst threads.
 ','line_number':167,'multiline':True]['text':' Stores state information about all buckets managed by the catalog, across stripes.','line_number':185,'multiline':False]['text':' The actual buckets in the catalog are distributed across a number of 'Stripe's. Each can be','line_number':188,'multiline':False]['text':' independently locked and operated on in parallel. The size of the stripe vector should not be','line_number':189,'multiline':False]['text':' changed after initialization.','line_number':190,'multiline':False]['text':' Per-namespace execution stats. This map is protected by 'mutex'. Once you complete your','line_number':194,'multiline':False]['text':' lookup, you can keep the shared_ptr to an individual namespace's stats object and release the','line_number':195,'multiline':False]['text':' lock. The object itself is thread-safe (using atomics).','line_number':196,'multiline':False]['text':' Global execution stats used to report aggregated metrics in server status.','line_number':200,'multiline':False]['text':' Approximate memory usage of the bucket catalog across all stripes.','line_number':203,'multiline':False]['text':' Memory usage threshold in bytes after which idle buckets will be expired.','line_number':206,'multiline':False]['text':' Cardinality of opened and archived buckets managed across all stripes.','line_number':209,'multiline':False]['text':'*
 * Returns the metadata for the given bucket in the following format:
 *     {<metadata field name>: <value>}
 * All measurements in the given bucket share same metadata value.
 *
 * Returns an empty document if the given bucket cannot be found or if this time-series collection
 * was not created with a metadata field name.
 ','line_number':213,'multiline':True]['text':'*
 * Tries to insert 'doc' into a suitable bucket. If an open bucket is full (or has incompatible
 * schema), but is otherwise suitable, we will close it and open a new bucket. If we find no bucket
 * with matching data and a time range that can accommodate 'doc', we will not open a new bucket,
 * but rather let the caller know to either
 *  - search for an archived or closed bucket that can accommodate 'doc' by returning a
 *    'ReopeningContext', or
 *  - retry the insert after waiting on the returned 'InsertWaiter'.
 *
 * If a suitable bucket is found or opened, returns a 'SuccessfulInsertion' containing the
 * 'WriteBatch' into which 'doc' was inserted and a list of any buckets that were closed to make
 * space to insert 'doc'. Any caller who receives the same batch may commit or abort the batch after
 * claiming commit rights. See 'WriteBatch' for more details.
 *
 * If a 'ReopeningContext' is returned, it contains either a bucket ID, corresponding to an archived
 * bucket which should be fetched, an aggregation pipeline that can be used to search for a
 * previously-closed bucket that can accommodate 'doc', or (in hopefully rare cases) a
 * std::monostate which requires no intermediate action, The caller should then proceed to call
 * 'insert' to insert 'doc', passing any fetched bucket back as a member of the 'ReopeningContext'.
 ','line_number':223,'multiline':True]['text':'*
 * Returns the WriteBatch into which the document was inserted and a list of any buckets that were
 * closed in order to make space to insert the document. Any caller who receives the same batch may
 * commit or abort the batch after claiming commit rights. See WriteBatch for more details.
 *
 * If 'reopeningContext' is passed with a bucket, we will reopen that bucket and attempt to add
 * 'doc' to that bucket. Otherwise we will attempt to find a suitable open bucket, or open a new
 * bucket if none exists.
 ','line_number':251,'multiline':True]['text':'*
 * If a 'tryInsert' call returns a 'InsertWaiter' object, the caller should use this function to
 * wait before repeating their attempt.
 ','line_number':269,'multiline':True]['text':'*
 * Prepares a batch for commit, transitioning it to an inactive state. Caller must already have
 * commit rights on batch. Returns OK if the batch was successfully prepared, or a status indicating
 * why the batch was previously aborted by another operation. If another batch is already prepared
 * on the same bucket, or there is an outstanding 'ReopeningRequest' for the same series (metaField
 * value), this operation will block waiting for it to complete.
 ','line_number':275,'multiline':True]['text':'*
 * Records the result of a batch commit. Caller must already have commit rights on batch, and batch
 * must have been previously prepared.
 *
 * Returns bucket information of a bucket if one was closed.
 *
 * Debug builds will attempt to verify the resulting bucket contents on disk if passed an 'opCtx'.
 ','line_number':284,'multiline':True]['text':'*
 * Aborts the given write batch and any other outstanding (unprepared) batches on the same bucket,
 * using the provided status.
 ','line_number':297,'multiline':True]['text':'*
 * Notifies the catalog of a direct write (that is, a write not initiated by the BucketCatalog) that
 * will be performed on the bucket document with the specified ID. If there is already an
 * internally-prepared operation on that bucket, this method will throw a 'WriteConflictException'.
 * This should be followed by a call to 'directWriteFinish' after the write has been committed,
 * rolled back, or otherwise finished.
 ','line_number':303,'multiline':True]['text':'*
 * Notifies the catalog that a pending direct write to the bucket document with the specified ID has
 * finished or been abandoned, and normal operations on the bucket can resume. After this point any
 * in-memory representation of the on-disk bucket data from before the direct write should have been
 * cleared from the catalog, and it may be safely reopened from the on-disk state.
 ','line_number':312,'multiline':True]['text':'*
 * Clears any bucket whose namespace satisfies the predicate by removing the bucket from the catalog
 * asynchronously through the BucketStateRegistry.
 ','line_number':320,'multiline':True]['text':'*
 * Clears the buckets for the given namespace by removing the bucket from the catalog asynchronously
 * through the BucketStateRegistry.
 ','line_number':326,'multiline':True]['text':'*
 * Clears the buckets for the given database by removing the bucket from the catalog asynchronously
 * through the BucketStateRegistry.
 ','line_number':332,'multiline':True]['text':'*
 * Resets the counter used for bucket OID generation. Should be called after a bucket _id collision.
 ','line_number':338,'multiline':True]['text':'*
 * Appends the execution stats for the given namespace to the builder.
 ','line_number':343,'multiline':True]['text':'*
 * Reports a number of measurements inserted that were committed by a different thread than the one
 * that initially staged them. These measurements are considered to have benefitted from "group
 * commit".
 ','line_number':350,'multiline':True]['text':' namespace mongo::timeseries::bucket_catalog','line_number':360,'multiline':False]