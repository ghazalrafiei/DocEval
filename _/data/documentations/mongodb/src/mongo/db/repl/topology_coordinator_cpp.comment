['text':'*
 *    Copyright (C) 2018-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]['text':' If this fail point is enabled, TopologyCoordinator::shouldChangeSyncSource() will ignore','line_number':90,'multiline':False]['text':' the option TopologyCoordinator::Options::maxSyncSourceLagSecs. The sync source will not be','line_number':91,'multiline':False]['text':' re-evaluated if it lags behind another node by more than 'maxSyncSourceLagSecs' seconds.','line_number':92,'multiline':False]['text':' Tracks the number of times we decide to change sync sources in order to sync from a significantly','line_number':97,'multiline':False]['text':' closer node.','line_number':98,'multiline':False]['text':'*
 * Returns true if the only up heartbeats are auth errors.
 ','line_number':139,'multiline':True]['text':' namespace','line_number':164,'multiline':False]['text':' Transition to 'FAILED' state if this was our last retry.','line_number':189,'multiline':False]['text':' Return false if we have fewer than maxNumSyncSourceChangesPerHour entries.','line_number':198,'multiline':False]['text':' Remove additional entries in case maxNumSyncSourceChangesPerHour was changed.','line_number':203,'multiline':False]['text':' Return whether all entries in the queue happened within the last hour by checking the oldest','line_number':208,'multiline':False]['text':' entry.','line_number':209,'multiline':False]['text':' Remove additional entries if the queue already has maxNumSyncSourceChangerPerHour entries.','line_number':215,'multiline':False]['text':' Need an entry for self in the memberHearbeatData.','line_number':239,'multiline':False]['text':' If we chose another node rather than clearing the sync source, update the recent sync source','line_number':272,'multiline':False]['text':' changes.','line_number':273,'multiline':False]['text':' If we are not a member of the current replica set configuration, no sync source is valid.','line_number':282,'multiline':False]['text':' Check to see if we should choose a sync source because 'unsupportedSyncSource' was','line_number':289,'multiline':False]['text':' set.','line_number':290,'multiline':False]['text':' fromReplSetSyncFrom ','line_number':293,'multiline':True]['text':' Check to see if we should choose a sync source because the 'replSetSyncFrom' command was set.','line_number':297,'multiline':False]['text':' If we have a forced sync source via 'replSetSyncFrom', set the _replSetSyncFromSet flag','line_number':300,'multiline':False]['text':' to true.','line_number':301,'multiline':False]['text':' fromReplSetSyncFrom ','line_number':302,'multiline':True]['text':' Check to make sure we can choose a sync source, and choose one if the','line_number':306,'multiline':False]['text':' 'forceSyncSourceCandidate' failpoint is set.','line_number':307,'multiline':False]['text':' If we are only allowed to sync from the primary, use it as the sync source if possible.','line_number':314,'multiline':False]['text':' If we prefer the primary, try it first.','line_number':325,'multiline':False]['text':' We should have handled PrimaryOnly before calling this.','line_number':338,'multiline':False]['text':' find the member with the lowest ping time that is ahead of me','line_number':341,'multiline':False]['text':' Make two attempts, with less restrictive rules the second time.','line_number':345,'multiline':False]['text':'','line_number':346,'multiline':False]['text':' During the first attempt, we ignore those nodes that have a larger secondary','line_number':347,'multiline':False]['text':' delay, hidden nodes or non-voting, and nodes that are excessively behind.','line_number':348,'multiline':False]['text':'','line_number':349,'multiline':False]['text':' For the second attempt include those nodes, in case those are the only ones we can reach.','line_number':350,'multiline':False]['text':'','line_number':351,'multiline':False]['text':' This loop attempts to set 'closestIndex', to select a viable candidate.','line_number':352,'multiline':False]['text':' firstAttempt ','line_number':365,'multiline':True]['text':' shouldCheckStaleness ','line_number':366,'multiline':True]['text':' Node is not a viable sync source candidate.','line_number':367,'multiline':False]['text':' Set 'closestIndex' if this node is the first viable candidate we have encountered.','line_number':371,'multiline':False]['text':' Do not update 'closestIndex' if the candidate is not the closest node we've seen.','line_number':384,'multiline':False]['text':' no need for second attempt','line_number':400,'multiline':False]['text':' Did not find any members to sync from','line_number':404,'multiline':False]['text':' Only log when we had a valid sync source before','line_number':405,'multiline':False]['text':' Find primary's oplog time. We will reject sync candidates that are more than','line_number':425,'multiline':False]['text':' _options.maxSyncSourceLagSecs seconds behind this optime.','line_number':426,'multiline':False]['text':' Check if primaryOpTime is still close to 0 because we haven't received','line_number':430,'multiline':False]['text':' our first heartbeat from a new primary yet.','line_number':431,'multiline':False]['text':' Don't consider ourselves.','line_number':448,'multiline':False]['text':' Candidate must be up to be considered.','line_number':457,'multiline':False]['text':' Candidate must be PRIMARY or SECONDARY state to be considered.','line_number':464,'multiline':False]['text':' Disallow the primary for first or all attempts depending on the readPreference.','line_number':472,'multiline':False]['text':' On the first attempt, we skip candidates that do not match these criteria.','line_number':484,'multiline':False]['text':' Candidate must be a voter if we are a voter.','line_number':486,'multiline':False]['text':' Candidates must not be hidden.','line_number':493,'multiline':False]['text':' Candidates cannot be excessively behind, if we are checking for staleness.','line_number':500,'multiline':False]['text':' Candidate must not have a configured delay larger than ours.','line_number':513,'multiline':False]['text':' Candidate must build indexes if we build indexes, to be considered.','line_number':524,'multiline':False]['text':' Only select a candidate that is ahead of me, if we are checking for staleness.','line_number':533,'multiline':False]['text':' Candidate cannot be denylisted.','line_number':543,'multiline':False]['text':' This candidate has passed all tests.','line_number':550,'multiline':False]['text':' If we have a target we've requested to sync from, use it.','line_number':561,'multiline':False]['text':' wait for 2N pings (not counting ourselves) before choosing a sync target','line_number':645,'multiline':False]['text':' not returning bad Status, just warning','line_number':825,'multiline':False]['text':' produce a reply to a heartbeat, and return whether the remote node's config has changed.','line_number':837,'multiline':False]['text':' Verify that replica set names match','line_number':843,'multiline':False]['text':' We include null times for lastApplied and lastDurable if we are in STARTUP_2, as we do not','line_number':881,'multiline':False]['text':' want to report replication progress and be part of write majorities while in initial sync.','line_number':882,'multiline':False]['text':' Deliver new config if caller's config is older than ours','line_number':913,'multiline':False]['text':' Resolve the caller's id in our Member list','line_number':918,'multiline':False]['text':' note that we got a heartbeat from this node','line_number':929,'multiline':False]['text':' Update liveness for sending node.','line_number':931,'multiline':False]['text':' This is either the first request ever for "target", or the heartbeat timeout has','line_number':953,'multiline':False]['text':' passed, so we're starting a "new" heartbeat.','line_number':954,'multiline':False]['text':' Send primary member id if one exists.','line_number':966,'multiline':False]['text':' Config version -2 is for uninitialized config.','line_number':977,'multiline':False]['text':' Replication of auth changes can cause temporary auth failures.','line_number':1004,'multiline':False]['text':' If a node is not PRIMARY and has no sync source, we increase the heartbeat rate in order','line_number':1011,'multiline':False]['text':' to help it find a sync source more quickly, which helps ensure the PRIMARY will continue to','line_number':1012,'multiline':False]['text':' see the majority of the cluster.','line_number':1013,'multiline':False]['text':'','line_number':1014,'multiline':False]['text':' Arbiters also decrease their heartbeat interval to at most half the election timeout period.','line_number':1015,'multiline':False]['text':' Determine the next heartbeat start time. If a heartbeat has not succeeded or failed, and we','line_number':1027,'multiline':False]['text':' have not used up the timeout period, we should retry.','line_number':1028,'multiline':False]['text':' There are still retries left, let's use one.','line_number':1030,'multiline':False]['text':' -2 is for uninitialized config.','line_number':1049,'multiline':False]['text':' Only continue processing heartbeat in primary state. In other states it is not','line_number':1058,'multiline':False]['text':' safe to continue processing heartbeat and should start reconfig right away.','line_number':1059,'multiline':False]['text':' e.g. if this node was removed from replSet, _selfIndex is -1, and a following','line_number':1060,'multiline':False]['text':' check on _selfIndex will keep retrying heartbeat to fetch new config, preventing','line_number':1061,'multiline':False]['text':' the new config to be installed.','line_number':1062,'multiline':False]['text':' Continue processing heartbeat responses even if we decide to install a new config.','line_number':1067,'multiline':False]['text':' Could be we got the newer version before we got the response, or the','line_number':1069,'multiline':False]['text':' target erroneously sent us one, even though it isn't newer.','line_number':1070,'multiline':False]['text':' Check if the heartbeat target is in our config.  If it isn't, there's nothing left to do,','line_number':1089,'multiline':False]['text':' so return early.','line_number':1090,'multiline':False]['text':' This server is not in the config, either because it was removed or a DNS error finding self.','line_number':1094,'multiline':False]['text':' If the heartbeat has failed i.e. used up all retries, then we mark the target node as','line_number':1125,'multiline':False]['text':' down.','line_number':1126,'multiline':False]['text':' If we've decided to install a newer config, we don't need to consider takeovers.','line_number':1153,'multiline':False]['text':' Replication progress that is for some reason ahead of us should not allow us to','line_number':1170,'multiline':False]['text':' satisfy a write concern if we aren't caught up ourselves.','line_number':1171,'multiline':False]['text':' Invariants that we only wait for an OpTime in the term that this node is currently writing','line_number':1177,'multiline':False]['text':' to. In other words, we do not support waiting for an OpTime written by a previous primary','line_number':1178,'multiline':False]['text':' because comparing members' lastApplied/lastDurable alone is not sufficient to tell if the','line_number':1179,'multiline':False]['text':' OpTime has been replicated.','line_number':1180,'multiline':False]['text':' We do not count arbiters towards the write concern.','line_number':1186,'multiline':False]['text':' In addition to checking if a member has a greater/equal timestamp field we also need to','line_number':1194,'multiline':False]['text':' make sure that the memberOpTime is in the same term as the OpTime we wait for. If a','line_number':1195,'multiline':False]['text':' member's OpTime has a higher term, it indicates that this node will be stepping down. And','line_number':1196,'multiline':False]['text':' thus we do not know if the target OpTime in our previous term has been replicated to the','line_number':1197,'multiline':False]['text':' member because the memberOpTime in a higher term could correspond to an operation in a','line_number':1198,'multiline':False]['text':' divergent branch of history regardless of its timestamp.','line_number':1199,'multiline':False]['text':' Invariants that we only wait for an OpTime in the term that this node is currently writing','line_number':1221,'multiline':False]['text':' to. In other words, we do not support waiting for an OpTime written by a previous primary','line_number':1222,'multiline':False]['text':' because comparing members' lastApplied/lastDurable alone is not sufficient to tell if the','line_number':1223,'multiline':False]['text':' OpTime has been replicated.','line_number':1224,'multiline':False]['text':' In addition to checking if a member has a greater/equal timestamp field we also need to','line_number':1231,'multiline':False]['text':' make sure that the memberOpTime is in the same term as the OpTime we wait for. If a','line_number':1232,'multiline':False]['text':' member's OpTime has a higher term, it indicates that this node will be stepping down. And','line_number':1233,'multiline':False]['text':' thus we do not know if the target OpTime in our previous term has been replicated to the','line_number':1234,'multiline':False]['text':' member because the memberOpTime in a higher term could correspond to an operation in a','line_number':1235,'multiline':False]['text':' divergent branch of history regardless of its timestamp.','line_number':1236,'multiline':False]['text':' This node has satisfied the predicate, now we need to check if it is a part','line_number':1254,'multiline':False]['text':' of the tagPattern.','line_number':1255,'multiline':False]['text':' Already stale.','line_number':1328,'multiline':False]['text':' In pv1, oplog entries are ordered by non-decreasing term and strictly increasing','line_number':1390,'multiline':False]['text':' timestamp. So, in pv1, its not possible for us to get opTime with higher term and','line_number':1391,'multiline':False]['text':' timestamp lesser than or equal to our current lastAppliedOptime.','line_number':1392,'multiline':False]['text':' Ignore updates when we're in state REMOVED.','line_number':1421,'multiline':False]['text':' Can only use setLastOptimeForMember in replSet mode.','line_number':1425,'multiline':False]['text':' Do not let remote nodes tell us what our optime is.','line_number':1435,'multiline':False]['text':' If we are applying a splitConfig for a shard split, we may still be receiving updates for','line_number':1449,'multiline':False]['text':' nodes that have been removed from the donor set.','line_number':1450,'multiline':False]['text':' Do not advance optime','line_number':1457,'multiline':False]['text':' While we can accept replSetUpdatePosition commands across config versions, we still do not','line_number':1461,'multiline':False]['text':' allow receiving them from a node that is not in our config.','line_number':1462,'multiline':False]['text':' Arbiters are always expected to report null durable optimes (and wall times).','line_number':1478,'multiline':False]['text':' If that is not the case here, make sure to correct these times before ingesting them.','line_number':1479,'multiline':False]['text':' If we were previously a secondary, we must make sure that we commit a new op as primary','line_number':1519,'multiline':False]['text':' before we can commit any other oplog entries, which necessitates the need for using the','line_number':1520,'multiline':False]['text':' '_firstOpTimeOfMyTerm' value here.','line_number':1521,'multiline':False]['text':' Updates the local notion of which remote node, if any is primary.','line_number':1533,'multiline':False]['text':' If we are the primary, there must be no other primary, otherwise its higher term would','line_number':1536,'multiline':False]['text':' have already made us step down.','line_number':1537,'multiline':False]['text':' Scan the member list's heartbeat data for who is primary, and update _currentPrimaryIndex.','line_number':1542,'multiline':False]['text':' Clear last heartbeat message on ourselves.','line_number':1559,'multiline':False]['text':' Takeover when the replset is stable.','line_number':1564,'multiline':False]['text':'','line_number':1565,'multiline':False]['text':' Take over the primary only if the remote primary is in the latest term I know.','line_number':1566,'multiline':False]['text':' This is done only when we get a heartbeat response from the primary.','line_number':1567,'multiline':False]['text':' Otherwise, there must be an outstanding election, which may succeed or not, but','line_number':1568,'multiline':False]['text':' the remote primary will become aware of that election eventually and step down.','line_number':1569,'multiline':False]['text':' A priority 0 node cannot win an election. Even if the priority changed via reconfig to make','line_number':1580,'multiline':False]['text':' the node eligible by the time a takeover scheduled here would happen, we would end up','line_number':1581,'multiline':False]['text':' canceling that takeover due to the reconfig.','line_number':1582,'multiline':False]['text':' Don't schedule catchup takeover if catchup takeover or primary catchup is disabled.','line_number':1587,'multiline':False]['text':' If we have a stale view of the new primary's opTime and believe its opTime to be','line_number':1595,'multiline':False]['text':' less than our own, we may end up scheduling an unecessary takeover. Primaries','line_number':1596,'multiline':False]['text':' increment the term as soon as they start a real election, but they do not write','line_number':1597,'multiline':False]['text':' anything in that new term until they have finished their full state transition.','line_number':1598,'multiline':False]['text':' Thus, if we have applied anything in the new term, it means that the primary is','line_number':1599,'multiline':False]['text':' already past the catchup phase and we should not be attempting a catchup takeover.','line_number':1600,'multiline':False]['text':' Calculate rank of current node. A rank of 0 indicates that it has the highest priority.','line_number':1631,'multiline':False]['text':' Schedule a priority takeover early only if we know that the current node has the highest','line_number':1634,'multiline':False]['text':' priority in the replica set, has a higher priority than the primary, and is the most','line_number':1635,'multiline':False]['text':' up to date node.','line_number':1636,'multiline':False]['text':' Otherwise, prefer to schedule a catchup takeover over a priority takeover','line_number':1637,'multiline':False]['text':' Rules are:','line_number':1691,'multiline':False]['text':' - If the terms don't match, we don't call for priority takeover.','line_number':1692,'multiline':False]['text':' - If our optime and the latest optime happen in different seconds, our optime must be within','line_number':1693,'multiline':False]['text':' at least priorityTakeoverFreshnessWindowSeconds seconds of the latest optime.','line_number':1694,'multiline':False]['text':' - If our optime and the latest optime happen in the same second, our optime must be within','line_number':1695,'multiline':False]['text':' at least 1000 oplog entries of the latest optime (i.e. the increment portion of the timestamp','line_number':1696,'multiline':False]['text':' must be within 1000).  This is to handle the case where a primary had its clock set far into','line_number':1697,'multiline':False]['text':' the future, took some writes, then had its clock set back.  In that case the timestamp','line_number':1698,'multiline':False]['text':' component of all future oplog entries generated will be the same, until real world time','line_number':1699,'multiline':False]['text':' passes the timestamp component of the last oplog entry.','line_number':1700,'multiline':False]['text':' Rules are:','line_number':1722,'multiline':False]['text':' - We must have the freshest optime of all the up nodes.','line_number':1723,'multiline':False]['text':' - We must specifically have a fresher optime than the primary (can't be equal).','line_number':1724,'multiline':False]['text':' - The term of our last applied op must be less than the current term. This ensures that no','line_number':1725,'multiline':False]['text':' writes have happened since the most recent election and that the primary is still in','line_number':1726,'multiline':False]['text':' catchup mode.','line_number':1727,'multiline':False]['text':' There is no point to a catchup takeover if we aren't the freshest node because','line_number':1729,'multiline':False]['text':' another node would immediately perform another catchup takeover when we become primary.','line_number':1730,'multiline':False]['text':' If we aren't ahead of the primary, there is no point to having a catchup takeover.','line_number':1740,'multiline':False]['text':' If the term of our last applied op is less than the current term, the primary didn't write','line_number':1747,'multiline':False]['text':' anything and it is still in catchup mode.','line_number':1748,'multiline':False]['text':' Can only be processing one required stepdown at a time.','line_number':1763,'multiline':False]['text':' Heartbeat and reconfig (via cmd or heartbeat) initiated stepdowns take precedence over','line_number':1766,'multiline':False]['text':' stepdown command initiated stepdowns, so it's safe to transition from kAttemptingStepDown','line_number':1767,'multiline':False]['text':' to kSteppingDown.','line_number':1768,'multiline':False]['text':' Construct a ReplSetStatusArgs using default parameters. Missing parameters will not be','line_number':1886,'multiline':False]['text':' included in the status string.','line_number':1887,'multiline':False]['text':' output for each member','line_number':1902,'multiline':False]['text':' We're REMOVED or have an invalid config','line_number':1917,'multiline':False]['text':' add self','line_number':1943,'multiline':False]['text':' add non-self member','line_number':1985,'multiline':False]['text':' if we can't connect the state info is from the past','line_number':1995,'multiline':False]['text':' and could be confusing to show','line_number':1996,'multiline':False]['text':' sort members bson','line_number':2051,'multiline':False]['text':' Add sync source info','line_number':2063,'multiline':False]['text':' New optimes, to hold them all.','line_number':2088,'multiline':False]['text':' Only include this field if the storage engine supports RTT.','line_number':2106,'multiline':False]['text':' Do not send updates if we have been removed from the config.','line_number':2130,'multiline':False]['text':' Create an array containing objects each live member connected to us and for ourself.','line_number':2136,'multiline':False]['text':' Don't include info on members we haven't heard from yet.','line_number':2140,'multiline':False]['text':' Don't include members we think are down.','line_number':2143,'multiline':False]['text':' Add metadata to command','line_number':2162,'multiline':False]['text':' Depending on whether or not the client sent a hello/isMaster request, we set the','line_number':2225,'multiline':False]['text':' "isWritablePrimary"/"ismaster" field to false if we are not primary. If we're stepping down,','line_number':2226,'multiline':False]['text':' we're waiting for the Replication State Transition Lock before we can change to secondary,','line_number':2227,'multiline':False]['text':' but we should report "isWritablePrimary"/"ismaster" false to indicate that we can't accept','line_number':2228,'multiline':False]['text':' new writes.','line_number':2229,'multiline':False]['text':' Filter out internal tags','line_number':2259,'multiline':False]['text':' This member existed in the old config with the same member ID and','line_number':2328,'multiline':False]['text':' HostAndPort, so copy its heartbeat data over.','line_number':2329,'multiline':False]['text':' It's necessary to have self member data even if self isn't in the configuration.','line_number':2341,'multiline':False]['text':' We don't need data for the other nodes (which no longer know about us, or soon won't)','line_number':2342,'multiline':False]['text':' We're not in the config, we can't sync any more.','line_number':2344,'multiline':False]['text':' We shouldn't get a sync source until we've received pings for our new config.','line_number':2346,'multiline':False]['text':' This function installs a new config object and recreates MemberData objects','line_number':2361,'multiline':False]['text':' that reflect the new config.','line_number':2362,'multiline':False]['text':' Reset term on startup.','line_number':2367,'multiline':False]['text':' If selfIndex is -1, we are removed from the current config and clear our _memberData.','line_number':2380,'multiline':False]['text':' Do not repopulate it.','line_number':2381,'multiline':False]['text':' Don't stepdown if you don't have to.','line_number':2393,'multiline':False]['text':' By this point we know we are in Role::kFollower','line_number':2401,'multiline':False]['text':' force secondaries to re-detect who the primary is','line_number':2402,'multiline':False]['text':' ignore messages over 2 minutes old','line_number':2405,'multiline':False]['text':' If there is no config or we're not in the config, the first-and-only entry should be for','line_number':2433,'multiline':False]['text':' self.','line_number':2434,'multiline':False]['text':' Cannot be electable unless secondary or already primary','line_number':2484,'multiline':False]['text':' Invariants for valid state transitions.','line_number':2598,'multiline':False]['text':' TODO(SERVER-30852): remove this case','line_number':2604,'multiline':False]['text':' TODO(SERVER-30852): remove this case','line_number':2610,'multiline':False]['text':' Prevent last committed optime from updating until we finish draining.','line_number':2691,'multiline':False]['text':' Stepdown attempt failed.','line_number':2723,'multiline':False]['text':' Check waitUntil after at least one stepdown attempt, so that stepdown could succeed even','line_number':2725,'multiline':False]['text':' if secondaryCatchUpPeriodSecs == 0.','line_number':2726,'multiline':False]['text':' Stepdown attempt failed, but in a way that can be retried','line_number':2735,'multiline':False]['text':' Stepdown attempt success!','line_number':2739,'multiline':False]['text':' No need to wait for secondaries to catch up if this node has not yet written in the current','line_number':2769,'multiline':False]['text':' term.','line_number':2770,'multiline':False]['text':' Check if a majority of nodes have reached the last applied optime.','line_number':2778,'multiline':False]['text':' Now check that we also have at least one caught up node that is electable.','line_number':2783,'multiline':False]['text':' ignore your self','line_number':2785,'multiline':False]['text':' Skip your own member index.','line_number':2807,'multiline':False]['text':' Skip this node if it is not eligible to become primary. This includes nodes with','line_number':2812,'multiline':False]['text':' priority 0.','line_number':2813,'multiline':False]['text':' Only update best if priority is strictly greater. This guarantees that','line_number':2818,'multiline':False]['text':' we will pick the member with the lowest index in case of a tie. Note that','line_number':2819,'multiline':False]['text':' member priority is always a non-negative number.','line_number':2820,'multiline':False]['text':' This is the most suitable node.','line_number':2828,'multiline':False]['text':' Single node replset must be electable.','line_number':2848,'multiline':False]['text':' two other nodes think they are primary (asynchronously polled)','line_number':2866,'multiline':False]['text':' -- wait for things to settle down.','line_number':2867,'multiline':False]['text':' If we're not primary or we're stepping down due to learning of a new term then we must not','line_number':2889,'multiline':False]['text':' advance the commit point.  If we are stepping down due to a user request, however, then it','line_number':2890,'multiline':False]['text':' is safe to advance the commit point, and in fact we must since the stepdown request may be','line_number':2891,'multiline':False]['text':' waiting for the commit point to advance enough to be able to safely complete the step down.','line_number':2892,'multiline':False]['text':' Whether we use the applied or durable OpTime for the commit point is decided here.','line_number':2897,'multiline':False]['text':' need the majority to have this OpTime','line_number':2922,'multiline':False]['text':' Force update in the replSetInitiate case.','line_number':2935,'multiline':False]['text':' The config hasn't been installed or we are not in the config. This could happen','line_number':2944,'multiline':False]['text':' on heartbeats before installing a config.','line_number':2945,'multiline':False]['text':' This check is performed to ensure primaries do not commit an OpTime from a previous term.','line_number':2949,'multiline':False]['text':' Arbiters don't have data so they always advance their commit point via heartbeats.','line_number':2959,'multiline':False]['text':' Hasn't changed, so ignore it.','line_number':2977,'multiline':False]['text':' Allow completing the transition to primary even when in the middle of a stepdown attempt,','line_number':3018,'multiline':False]['text':' in case the stepdown attempt fails.','line_number':3019,'multiline':False]['text':' Don't run election if we just stood up or learned about a new term.','line_number':3057,'multiline':False]['text':' Don't update the term just yet if we are going to step down, as we don't want to report','line_number':3060,'multiline':False]['text':' that we are primary in the new term.','line_number':3061,'multiline':False]['text':' Methodology:','line_number':3080,'multiline':False]['text':' If there exists a viable sync source member other than currentSource, whose oplog has','line_number':3081,'multiline':False]['text':' reached an optime greater than _options.maxSyncSourceLagSecs later than currentSource's,','line_number':3082,'multiline':False]['text':' return true.','line_number':3083,'multiline':False]['text':' If the currentSource has the same replication progress as we do and has no source for further','line_number':3084,'multiline':False]['text':' progress, return true.','line_number':3085,'multiline':False]['text':' Change sync source if they are not ahead of us, and don't have a sync source,','line_number':3107,'multiline':False]['text':' unless they are primary.','line_number':3108,'multiline':False]['text':' We change sync source on error if','line_number':3133,'multiline':False]['text':' 1) A forced sync source change has been requested.','line_number':3134,'multiline':False]['text':' 2) Chaining is disabled and a new primary has been detected.','line_number':3135,'multiline':False]['text':' 3) A more eligible node exists. Note this covers the case where our current sync source is','line_number':3136,'multiline':False]['text':'    down.','line_number':3137,'multiline':False]['text':' If the user requested a sync source change, return kYes.','line_number':3170,'multiline':False]['text':' While we can allow data replication across config versions, we still do not allow syncing','line_number':3178,'multiline':False]['text':' from a node that is not in our config.','line_number':3179,'multiline':False]['text':' Change sync source if chaining is disabled (without overrides), we are not syncing from the','line_number':3194,'multiline':False]['text':' primary, and we know who the new primary is. We do not consider chaining disabled if we are','line_number':3195,'multiline':False]['text':' the primary, since we are in catchup mode.','line_number':3196,'multiline':False]['text':' Change sync source if our sync source is also syncing from us when we are in primary','line_number':3237,'multiline':False]['text':' catchup mode, forming a sync source selection cycle, and the sync source is not ahead','line_number':3238,'multiline':False]['text':' of us. This is to prevent a deadlock situation. See SERVER-58988 for details.','line_number':3239,'multiline':False]['text':' firstAttempt ','line_number':3278,'multiline':True]['text':' shouldCheckStaleness ','line_number':3279,'multiline':True]['text':' Change sync source if our current sync source is not a preferred sync source node choice due','line_number':3304,'multiline':False]['text':' to non-staleness issues, such as being a non-voter when we are a voter, or being hidden, or','line_number':3305,'multiline':False]['text':' any of the other conditions checked in _isEligibleSyncSource with firstAttempt=true, and','line_number':3306,'multiline':False]['text':' another eligible node exists which does meet these criteria. Note that while we bypass','line_number':3307,'multiline':False]['text':' staleness checks for our current node, we should not do this for a potential new node,','line_number':3308,'multiline':False]['text':' because we could end up with a situation where shouldChangeSyncSource returns true, causing','line_number':3309,'multiline':False]['text':' the sync source to be cleared, but then being reset to our previous sync source repeatedly','line_number':3310,'multiline':False]['text':' because the new source is not actually valid. Note that _isEligibleSyncSource only checks for','line_number':3311,'multiline':False]['text':' ReadPreference::Secondary*, so any choice besides those for the read preference is fine.','line_number':3312,'multiline':False]['text':' firstAttempt ','line_number':3317,'multiline':True]['text':' shouldCheckStaleness ','line_number':3318,'multiline':True]['text':' firstAttempt ','line_number':3325,'multiline':True]['text':' shouldCheckStaleness ','line_number':3326,'multiline':True]['text':' If we find an eligible sync source that is significantly closer than our current sync source,','line_number':3350,'multiline':False]['text':' return true.','line_number':3351,'multiline':False]['text':' Do not re-evaluate our sync source if it was set via the replSetSyncFrom command, the','line_number':3353,'multiline':False]['text':' forceSyncSourceCandidate failpoint, or the 'unsupportedSyncSource' server parameter.','line_number':3354,'multiline':False]['text':' If we are in initial sync, do not re-evaluate our sync source.','line_number':3361,'multiline':False]['text':' If we are configured with secondaryDelaySecs, do not re-evaluate our sync source.','line_number':3367,'multiline':False]['text':' If we have already changed sync sources more than 'maxNumSyncSourceChangesPerHour' in the','line_number':3372,'multiline':False]['text':' past hour, do not re-evaluate our sync source.','line_number':3373,'multiline':False]['text':' If the threshold is set to zero, do not consider changing sync sources due to ping time.','line_number':3388,'multiline':False]['text':' If we have not yet received 5N pings (not counting ourselves), do not re-evaluate our sync','line_number':3393,'multiline':False]['text':' source.','line_number':3394,'multiline':False]['text':' Ping data for our current sync source could not be found.','line_number':3401,'multiline':False]['text':' Use ping times to look for another viable sync source that is significantly closer.','line_number':3408,'multiline':False]['text':' Either we are the candidate node or ping data for the candidateNode could not be','line_number':3412,'multiline':False]['text':' found. Continue to the next node.','line_number':3413,'multiline':False]['text':' Only choose a new sync source if ping times indicate that the candidate is significantly','line_number':3417,'multiline':False]['text':' closer than our current sync source and it is an eligible sync source.','line_number':3418,'multiline':False]['text':' firstAttempt ','line_number':3429,'multiline':True]['text':' shouldCheckStaleness ','line_number':3430,'multiline':True]['text':' isPrimary ','line_number':3454,'multiline':True]['text':' Do not grant vote if we are arbiter and can see a healthy primary of greater or equal','line_number':3520,'multiline':False]['text':' priority, to prevent primary flapping when there are two nodes that can't talk to each','line_number':3521,'multiline':False]['text':' other but we that can talk to both as arbiter. We only do this if the voter's config','line_number':3522,'multiline':False]['text':' is same as ours, otherwise the primary information might be stale and we might not be','line_number':3523,'multiline':False]['text':' arbiter in the candidate's newer config. We might also hit an invariant described in','line_number':3524,'multiline':False]['text':' SERVER-46387 without the check for same config.','line_number':3525,'multiline':False]['text':' All checks passed, become a candidate and start election proceedings.','line_number':3579,'multiline':False]['text':' Ignore self','line_number':3609,'multiline':False]['text':' Ignore down members','line_number':3613,'multiline':False]['text':' Ignore removed nodes (not in config, so not valid).','line_number':3617,'multiline':False]['text':' The smallest OpTime in PV1.','line_number':3633,'multiline':False]['text':' If any heartbeat is not fresh enough, return none.','line_number':3641,'multiline':False]['text':' Ignore down members','line_number':3645,'multiline':False]['text':' Even if all the nodes in the set had a given write it still would not satisfy this','line_number':3697,'multiline':False]['text':' commit quorum.','line_number':3698,'multiline':False]['text':' Only count data-bearing nodes.','line_number':3714,'multiline':False]['text':' Only count nodes that build indexes.','line_number':3719,'multiline':False]['text':' buildIndexes:false should not be included in a commitQuorum because they never actually build','line_number':3731,'multiline':False]['text':' indexes and vote to commit. Provide a helpful error message to prevent users from starting','line_number':3732,'multiline':False]['text':' index builds that will never commit.','line_number':3733,'multiline':False]['text':' namespace repl','line_number':3744,'multiline':False]['text':' namespace mongo','line_number':3745,'multiline':False]