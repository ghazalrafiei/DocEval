['text':'*
 *    Copyright (C) 2019-present MongoDB, Inc.
 *
 *    This program is free software: you can redistribute it and/or modify
 *    it under the terms of the Server Side Public License, version 1,
 *    as published by MongoDB, Inc.
 *
 *    This program is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    Server Side Public License for more details.
 *
 *    You should have received a copy of the Server Side Public License
 *    along with this program. If not, see
 *    <http://www.mongodb.com/licensing/server-side-public-license>.
 *
 *    As a special exception, the copyright holders give permission to link the
 *    code of portions of this program with the OpenSSL library under certain
 *    conditions as described in each individual source file and distribute
 *    linked combinations including the program with the OpenSSL library. You
 *    must comply with the Server Side Public License in all respects for
 *    all of the code used other than as permitted herein. If you modify file(s)
 *    with this exception, you may extend this exception to your version of the
 *    file(s), but you are not obligated to do so. If you do not wish to do so,
 *    delete this exception statement from your version. If you delete this
 *    exception statement from all source files in the program, then also delete
 *    it in the license file.
 ','line_number':1,'multiline':True]['text':' Process group by columns.','line_number':192,'multiline':False]['text':' Construct accessors for obtaining the key values from either the hash table '_ht' or the','line_number':198,'multiline':False]['text':' '_recordStore'.','line_number':199,'multiline':False]['text':' A 'SwitchAccessor' is used to point the '_outKeyAccessors' to the key coming from the','line_number':204,'multiline':False]['text':' '_ht' or the '_recordStore' when draining the HashAgg stage in getNext(). If no spilling','line_number':205,'multiline':False]['text':' occurred, the keys will be obtained from the hash table. If spilling kicked in, then all','line_number':206,'multiline':False]['text':' of the data is written out to the record store, so the 'SwitchAccessor' is reconfigured','line_number':207,'multiline':False]['text':' to obtain all of the keys from the spill table.','line_number':208,'multiline':False]['text':' Process seek keys (if any). The keys must come from outside of the subtree (by definition) so','line_number':218,'multiline':False]['text':' we go directly to the compilation context.','line_number':219,'multiline':False]['text':' Just like with the output accessors for the keys, we construct output accessors for the','line_number':228,'multiline':False]['text':' aggregate values that read from either the hash table '_ht' or the '_recordStore'.','line_number':229,'multiline':False]['text':' A 'SwitchAccessor' is used to toggle the '_outAggAccessors' between the '_ht' and the','line_number':234,'multiline':False]['text':' '_recordStore'. Just like the key values, the aggregate values are always obtained from','line_number':235,'multiline':False]['text':' the hash table if no spilling occurred and are always obtained from the record store if','line_number':236,'multiline':False]['text':' spilling occurred.','line_number':237,'multiline':False]['text':' If disk use is allowed, then we need to compile the merging expressions as well.','line_number':257,'multiline':False]['text':' The slots into which we read spilled partial aggregates, accessible via','line_number':286,'multiline':False]['text':' '_spilledAggsAccessors', should only be visible to this stage. They are used internally','line_number':287,'multiline':False]['text':' when merging spilled partial aggregates and should never be read by ancestor stages.','line_number':288,'multiline':False]['text':' Therefore, they are only made visible when this stage is in the process of compiling','line_number':289,'multiline':False]['text':' itself.','line_number':290,'multiline':False]['text':' Serialize the key that will be used as the record id (rid) when storing the record in the','line_number':324,'multiline':False]['text':' record store. Use a keystring for the spilled entry's rid such that partial aggregates are','line_number':325,'multiline':False]['text':' guaranteed to have identical keystrings when their keys are equal with respect to the','line_number':326,'multiline':False]['text':' collation.','line_number':327,'multiline':False]['text':' Add a unique integer to the end of the key, since record ids must be unique. We want equal','line_number':329,'multiline':False]['text':' keys to be adjacent in the 'RecordStore' so that we can merge the partial aggregates with a','line_number':330,'multiline':False]['text':' single pass.','line_number':331,'multiline':False]['text':' The keystring cannot always be deserialized back to the original keys when a collation is','line_number':336,'multiline':False]['text':' in use, so we also store the unmodified key in the data part of the spilled record.','line_number':337,'multiline':False]['text':'update','line_number':338,'multiline':True]['text':'update','line_number':341,'multiline':True]['text':' Since we flush the entire hash table to disk, we also clear any state related to estimating','line_number':353,'multiline':False]['text':' memory consumption.','line_number':354,'multiline':False]['text':' We're not actually doing any sorting here or using the 'Sorter' class, but for the purposes','line_number':366,'multiline':False]['text':' of $operationMetrics we incorporate the number of spilled records into the "keysSorted"','line_number':367,'multiline':False]['text':' metric. Similarly, "sorterSpills" despite the name counts the number of individual spill','line_number':368,'multiline':False]['text':' events.','line_number':369,'multiline':False]['text':' Checks memory usage. Ideally, we'd want to know the exact size of already accumulated data, but','line_number':378,'multiline':False]['text':' we cannot, so we estimate it based on the last updated/inserted row, if we have one, or the first','line_number':379,'multiline':False]['text':' row in the '_ht' table. If the estimated memory usage exceeds the allowed, this method initiates','line_number':380,'multiline':False]['text':' spilling.','line_number':381,'multiline':False]['text':' If the group-by key is empty we will only ever aggregate into a single row so no sense in','line_number':385,'multiline':False]['text':' spilling.','line_number':386,'multiline':False]['text':' We haven't reached the next checkpoint at which we estimate memory usage and decide if we','line_number':393,'multiline':False]['text':' should spill.','line_number':394,'multiline':False]['text':' Calculate the next memory checkpoint. We estimate it based on the prior growth of the','line_number':405,'multiline':False]['text':' '_ht' and the remaining available memory. If 'estimatedGainPerChildAdvance' suggests that','line_number':406,'multiline':False]['text':' the hash table is growing, then the checkpoint is estimated as some configurable','line_number':407,'multiline':False]['text':' percentage of the number of additional input rows that we would have to process to','line_number':408,'multiline':False]['text':' consume the remaining memory. On the other hand, a value of 'estimtedGainPerChildAdvance'','line_number':409,'multiline':False]['text':' close to zero indicates a stable hash stable size, in which case we can delay the next','line_number':410,'multiline':False]['text':' check progressively.','line_number':411,'multiline':False]['text':' Reset state since this stage may have been previously opened.','line_number':454,'multiline':False]['text':' Copy keys in order to do the lookup.','line_number':474,'multiline':False]['text':' The key is not present in the hash table yet, so we insert it and initialize the','line_number':484,'multiline':False]['text':' corresponding accumulator. Note that as a future optimization, we could avoid','line_number':485,'multiline':False]['text':' doing a lookup both in the 'find()' call and in 'emplace()'.','line_number':486,'multiline':False]['text':' Run accumulator initializer if needed.','line_number':494,'multiline':False]['text':' Accumulate state in '_ht'.','line_number':503,'multiline':False]['text':' If configured to spill more than usual, we spill after seeing the same key twice.','line_number':510,'multiline':False]['text':' Estimates how much memory is being used. If we estimate that the hash table','line_number':513,'multiline':False]['text':' exceeds the allotted memory budget, its contents are spilled to the','line_number':514,'multiline':False]['text':' '_recordStore' and '_ht' is cleared.','line_number':515,'multiline':False]['text':' During trial runs, we want to limit the amount of work done by opening a blocking','line_number':520,'multiline':False]['text':' stage, like this one. The blocking stage tracks the number of documents it has','line_number':521,'multiline':False]['text':' read from its child, and if the TrialRunTracker ends the trial, a special','line_number':522,'multiline':False]['text':' exception returns control back to the planner.','line_number':523,'multiline':False]['text':' If we spilled at any point while consuming the input, then do one final spill to write','line_number':535,'multiline':False]['text':' any leftover contents of '_ht' to the record store. That way, when recovering the input','line_number':536,'multiline':False]['text':' from the record store and merging partial aggregates we don't have to worry about the','line_number':537,'multiline':False]['text':' possibility of some of the data being in the hash table and some being in the record','line_number':538,'multiline':False]['text':' store.','line_number':539,'multiline':False]['text':' Establish a cursor, positioned at the beginning of the record store.','line_number':547,'multiline':False]['text':' Callers will be obtaining the results from the spill table, so set the','line_number':550,'multiline':False]['text':' 'SwitchAccessors' so that they refer to the rows recovered from the record store','line_number':551,'multiline':False]['text':' under the hood.','line_number':552,'multiline':False]['text':' Copy keys in order to do the lookup.','line_number':563,'multiline':False]['text':' Read the values and type bits out of the value part of the record.','line_number':576,'multiline':False]['text':'collator','line_number':579,'multiline':True]['text':'numPrefixValuesToRead','line_number':585,'multiline':True]['text':' When a collator has been defined, both the key and the value are stored in the data part of','line_number':593,'multiline':False]['text':' the record. First read the key and then read the value.','line_number':594,'multiline':False]['text':' Use the appropriate method to deserialize the record based on whether a collator is used.','line_number':607,'multiline':False]['text':' We are just starting the process of merging the spilled file segments.','line_number':622,'multiline':False]['text':' We peeked at the next key last time around.','line_number':628,'multiline':False]['text':' Clear the stashed row.','line_number':632,'multiline':False]['text':' Find additional partial aggregates for the same key and merge them in order to compute the','line_number':636,'multiline':False]['text':' final output.','line_number':637,'multiline':False]['text':' The newly recovered spilled row belongs to a new key, so we're done merging partial','line_number':641,'multiline':False]['text':' aggregates for the old key. Save the new row for later and return advanced.','line_number':642,'multiline':False]['text':' Merge in the new partial aggregate values.','line_number':647,'multiline':False]['text':' If we've spilled, then we need to produce the output by merging the spilled segments from the','line_number':661,'multiline':False]['text':' spill file.','line_number':662,'multiline':False]['text':' We didn't spill. Obtain the next output row from the hash table.','line_number':667,'multiline':False]['text':' First invocation of getNext() after open().','line_number':669,'multiline':False]['text':' Subsequent invocation with seek keys. Return only 1 single row (if any).','line_number':676,'multiline':False]['text':' The hash table has been drained (and we never spilled to disk) so we're done.','line_number':683,'multiline':False]['text':' Spilling stats.','line_number':722,'multiline':False]['text':' The HashAggStage only tracks the "numResults" metric when it is the most deeply nested','line_number':856,'multiline':False]['text':' blocking stage.','line_number':857,'multiline':False]['text':' Return true to indicate that the tracker is attached to a blocking stage: either this stage','line_number':862,'multiline':False]['text':' or one of its descendent stages.','line_number':863,'multiline':False]['text':' namespace sbe','line_number':867,'multiline':False]['text':' namespace mongo','line_number':868,'multiline':False]