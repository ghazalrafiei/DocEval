['text':'*
 * Confirms that the decision to run the optimized $sample stage takes the ratio of orphans to legit
 * documents into account. In particular, a shard which possesses *only* orphan documents does not
 * induce the infinite-loop behaviour detailed in SERVER-36871.
 * @tags: [
 *   requires_replication,
 * ]
 ','line_number':1,'multiline':True]['text':' Deliberately inserts orphans outside of migration.','line_number':11,'multiline':False]['text':' Set up a 2-shard cluster.','line_number':14,'multiline':False]['text':' Obtain a connection to the mongoS and one direct connection to each shard.','line_number':17,'multiline':False]['text':' Helper function that runs a $sample aggregation, confirms that the results are correct, and','line_number':41,'multiline':False]['text':' verifies that the expected optimized or unoptimized $sample stage ran on each shard.','line_number':42,'multiline':False]['text':' Run the aggregation via mongoS with the given 'comment' parameter.','line_number':44,'multiline':False]['text':' Obtain the explain output for the aggregation.','line_number':48,'multiline':False]['text':' Verify that the expected $sample stage, optimized or unoptimized, ran on each shard.','line_number':52,'multiline':False]['text':' Shard the collection on {_id: 1}, split at {_id: 0} and move the empty upper chunk to shard1.','line_number':61,'multiline':False]['text':' Write some documents to the lower chunk on shard0.','line_number':64,'multiline':False]['text':' Set a failpoint to hang after cloning documents to shard1 but before committing.','line_number':69,'multiline':False]['text':' Spawn a parallel shell to move the lower chunk from shard0 to shard1.','line_number':73,'multiline':False]['text':' Wait until we see that all documents have been cloned to shard1.','line_number':84,'multiline':False]['text':' Confirm that shard0 still owns the chunk, according to the config DB metadata.','line_number':89,'multiline':False]['text':' Run a $sample aggregation without committing the chunk migration. We expect to see that the','line_number':92,'multiline':False]['text':' optimized $sample stage was used on shard0, which own the documents. Despite the fact that','line_number':93,'multiline':False]['text':' there are 200 documents on shard1 and we should naively have used the random-cursor','line_number':94,'multiline':False]['text':' optimization, confirm that we instead detected that the documents were orphans and used the','line_number':95,'multiline':False]['text':' non-optimized $sample stage.','line_number':96,'multiline':False]['text':' Confirm that shard0 still owns the chunk.','line_number':103,'multiline':False]['text':' Release the failpoints and wait for the parallel moveChunk shell to complete.','line_number':106,'multiline':False]['text':' Confirm that shard1 now owns the chunk.','line_number':111,'multiline':False]['text':' Move the lower chunk back to shard0.','line_number':114,'multiline':False]['text':' Write 1 legitimate document and 100 orphans directly to shard1, which owns the upper chunk.','line_number':118,'multiline':False]['text':' Confirm that there are 101 documents on shard1 and mongoS can see the 1 non-orphan.','line_number':124,'multiline':False]['text':' Re-run the $sample aggregation. On shard1 we should again use the non-optimized stage, since','line_number':128,'multiline':False]['text':' despite the fact that there are 101 documents present, only 1 is owned by the shard.','line_number':129,'multiline':False]['text':' Write 199 additional documents to the upper chunk which still resides on shard1.','line_number':136,'multiline':False]['text':' Re-run the $sample aggregation and confirm that the optimized stage now runs on both shards.','line_number':142,'multiline':False]