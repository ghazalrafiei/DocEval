['text':'*
 * Tests inserting sample data into the time-series buckets collection. This test is for the
 * exercising the optimized $sample implementation for $_internalUnpackBucket.
 ','line_number':1,'multiline':True]['text':' The trial stage should always appear in the output, regardless of which plan won.','line_number':27,'multiline':False]['text':' Verify that execution stats are reported correctly for the UNPACK_BUCKET stage in','line_number':35,'multiline':False]['text':' explain.','line_number':36,'multiline':False]['text':' In the top-k plan, all of the buckets need to be unpacked.','line_number':40,'multiline':False]['text':' When the trial plan succeeds, any data produced during the trial period will be queued','line_number':43,'multiline':False]['text':' and returned via the QUEUED_DATA stage. If the trial plan being assessed reached EOF,','line_number':44,'multiline':False]['text':' then we expect only a QUEUED_DATA stage to appear in explain because all of the necessary','line_number':45,'multiline':False]['text':' data has already been produced. If the plan is not EOF, then we expect OR','line_number':46,'multiline':False]['text':' (QUEUED_DATA, <trial plan>). Either way, the presence of the QUEUED_DATA stage indicates','line_number':47,'multiline':False]['text':' that the trial plan was selected over the backup plan.','line_number':48,'multiline':False]['text':'*
 * Creates the collection 'coll' as a time-series collection, and inserts data such that there are
 * the given number of measurementsPerBucket (assuming there are 'nBuckets'). Returns the total
 * number of measurement documents inserted into the collection.
 ','line_number':55,'multiline':True]['text':' Check the time-series view to make sure we have the correct number of docs and that there are','line_number':87,'multiline':False]['text':' no duplicates after sampling.','line_number':88,'multiline':False]['text':' Check that we have executed the correct branch of the TrialStage.','line_number':97,'multiline':False]['text':' Run an agg pipeline with optimization disabled.','line_number':102,'multiline':False]['text':' Check that $sample hasn't been absorbed by $_internalUnpackBucket when the','line_number':106,'multiline':False]['text':' sample size is sufficiently large. The server will never try to use random cursor-based','line_number':107,'multiline':False]['text':' sampling for timeseries collections when the requested sample exceeds 1% of the maximum','line_number':108,'multiline':False]['text':' measurement count. Since the maximum number of measurements per bucket is 100, this means','line_number':109,'multiline':False]['text':' that we expect to use a top-k plan (without using 'TrialStage') when the sample size exceeds','line_number':110,'multiline':False]['text':' 'nBuckets'.','line_number':111,'multiline':False]['text':' Check that a sampleSize greater than the number of measurements doesn't cause an infinte','line_number':124,'multiline':False]['text':' loop.','line_number':125,'multiline':False]['text':' Check that $lookup against a time-series collection doesn't cache inner pipeline results if','line_number':129,'multiline':False]['text':' it contains a $sample stage.','line_number':130,'multiline':False]['text':' Each subquery should be an independent sample by checking that we didn't sample the same','line_number':136,'multiline':False]['text':' document repeatedly. It's sufficient for now to make sure that the seen set contains at least','line_number':137,'multiline':False]['text':' two distinct samples.','line_number':138,'multiline':False]['text':' Test the case where the buckets are only 1% full. Due to the mostly empty buckets, we expect to','line_number':147,'multiline':False]['text':' fall back to the non-optimized top-k algorithm for sampling from a time-series collection.','line_number':148,'multiline':False]['text':' Test the case where the buckets are 95% full. Here we expect the optimized','line_number':151,'multiline':False]['text':' SAMPLE_FROM_TIMESERIES_BUCKET plan to be used.','line_number':152,'multiline':False]['text':' Restart the mongod in order to raise the maximum bucket size to 1000.','line_number':155,'multiline':False]['text':' Create a timeseries collection that has 40 buckets, each with 900 documents.','line_number':161,'multiline':False]['text':' Run a sample query where the sample size is large enough to merit multiple batches.','line_number':166,'multiline':False]['text':' Explain the $sample. Given that the buckets are mostly full, we expect the trial to succeed. We','line_number':169,'multiline':False]['text':' should see a TRIAL stage, and it should have selected the SAMPLE_FROM_TIMESERIES_BUCKET plan. The','line_number':170,'multiline':False]['text':' initial batch of data collected during the trial period will be returned via a QUEUED_DATA_STAGE.','line_number':171,'multiline':False]['text':' Verify that the SAMPLE_FROM_TIMESERIES_BUCKET stage exists in the plan and has reasonable','line_number':180,'multiline':False]['text':' runtime stats.','line_number':181,'multiline':False]['text':' Since we are returning a sample size of 150, we expect to test at least that many dups.','line_number':188,'multiline':False]['text':' The SAMPLE_FROM_TIMESERIES_BUCKET stage reads from a MULTI_ITERATOR stage, which in turn reads','line_number':192,'multiline':False]['text':' from a storage-provided random cursor.','line_number':193,'multiline':False]