['text':'*
 * This test ensures readers on a secondary are unable to read from unique indexes that temporarily
 * violate their uniqueness constraint. When oplog entries are applied in parallel batch writes,
 * operations can be applied out-of-order, and reading at an inconsistent state is possible.
 *
 * For example, take two documents, { _id: 1, x: 1} and  { _id: 2, x: 2} with a unique index on 'x'.
 * On the primary, two updates take place in this order:
 *   { _id: 2, x: 3 }
 *   { _id: 1, x: 2 }
 * There is no uniqueness violation here because x: 3 happens before x: 2. If the updates had
 * occured in the opposite order, a DuplicateKey error would be returned to the user.
 *
 * When these operations are applied on a secondary, they split up across one of 16 writer threads,
 * hashed on the _id of the document. This guarantees that updates to the same document will occur
 * in-order on the same thread.
 *
 * Take two parallel threads applying the same updates as before:
 *      Thread 1            Thread 2
 *   { _id: 1, x: 2 }
 *                       { _id: 2, x: 3 }
 *
 * If a secondary reader were to access the index entry for x=2 after Thread 1 made its update but
 * before Thread 2 made its update, they would find two entries for x=2, which is a violation of the
 * uniqueness constraint. When applying operations in parallel like this, we temporarily ignore
 * uniqueness violations on indexes, and require readers on secondaries to wait for the parallel
 * batch insert to complete, at which point the state of the indexes will be consistent.
 ','line_number':1,'multiline':True]['text':' Setup collection.','line_number':38,'multiline':False]['text':' Create a unique index on the collection in the foreground.','line_number':42,'multiline':False]['text':' We want to do updates with at least as many different documents as there are parallel batch','line_number':49,'multiline':False]['text':' writer threads (16). Each iteration increments and decrements a uniquely indexed value, 'x'.','line_number':50,'multiline':False]['text':' The goal is that a reader on a secondary might find a case where the unique index constraint','line_number':51,'multiline':False]['text':' is ignored, and an index on x maps to two different records.','line_number':52,'multiline':False]['text':' Do a bunch of reads using the 'x' index on the secondary.','line_number':57,'multiline':False]['text':' No errors should be encountered on the secondary.','line_number':58,'multiline':False]['text':' Sleep a bit to make these reader threads less CPU intensive.','line_number':67,'multiline':False]['text':' Write the initial documents. Ensure they have been replicated.','line_number':75,'multiline':False]['text':' Cycle the value of x in the document {_id: i, x: i} between i and i+1 each iteration.','line_number':82,'multiline':False]['text':' Reset each document.','line_number':85,'multiline':False]['text':' Generate updates that increment x on each document backwards by _id to avoid conficts','line_number':93,'multiline':False]['text':' when applied in-order. When these updates get applied to the secondary, they may get','line_number':94,'multiline':False]['text':' applied out of order by different threads and temporarily violate unique index','line_number':95,'multiline':False]['text':' constraints.','line_number':96,'multiline':False]['text':' Start at the end and increment x by 1.','line_number':98,'multiline':False]