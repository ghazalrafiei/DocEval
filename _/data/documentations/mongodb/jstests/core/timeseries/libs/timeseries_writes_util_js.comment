['text':'*
 * Helpers for testing timeseries arbitrary writes.
 ','line_number':1,'multiline':True]['text':' The split point is between the 'A' and 'B' meta values which is _id: 4. [1, 3] goes to the','line_number':16,'multiline':False]['text':' primary shard and [4, 7] goes to the other shard.','line_number':17,'multiline':False]['text':' This split point is the same as the 'splitMetaPointBetweenTwoShards'.','line_number':22,'multiline':False]['text':' Defines sample data set for testing.','line_number':31,'multiline':False]['text':'*
 * Composes and returns a bucket-level filter for timeseries arbitrary writes.
 *
 * The bucket-level filter is composed of the closed bucket filter and the given filter(s) which
 * are ANDed together. The closed bucket filter is always the first element of the AND array.
 ','line_number':87,'multiline':True]['text':' [MinKey, splitPoint) and [splitPoint, MaxKey) are the two chunks after the split.','line_number':151,'multiline':False]['text':'*
 * Returns the name of the caller of the function that called this function using the stack trace.
 *
 * This is useful for generating unique collection names. If the return function name is not unique
 * and the caller needs to generate a unique collection name, the caller can append a unique suffix.
 ','line_number':203,'multiline':True]['text':' Validate the collection's exact contents if we were given the expected results. We may skip','line_number':217,'multiline':False]['text':' this step in some cases, if the delete doesn't pinpoint a specific document.','line_number':218,'multiline':False]['text':' stats can't really show the results close to real execution. We can just verify','line_number':834,'multiline':False]['text':' plan part.','line_number':835,'multiline':False]['text':' Note: To figure out the expected result documents, we need to know the _id of the','line_number':858,'multiline':False]['text':' deleted document.','line_number':859,'multiline':False]['text':' Note: To figure out the expected result documents, we need to know the _id of the','line_number':865,'multiline':False]['text':' deleted document. And so we don't allow 'fields' to be specified because it might','line_number':866,'multiline':False]['text':' exclude _id field.','line_number':867,'multiline':False]['text':' TODO SERVER-76583: Remove this test.','line_number':881,'multiline':False]['text':'*
 * Verifies that a findAndModify update on a sharded timeseries collection returns the expected
 * result(s) 'res'.
 *
 * - initialDocList: The initial documents in the collection.
 * - cmd.filter: The 'query' spec for the findAndModify command.
 * - cmd.update: The 'update' spec for the findAndModify command.
 * - cmd.returnNew: The 'new' option for the findAndModify command.
 * - cmd.upsert: The 'upsert' option for the findAndModify command.
 * - cmd.fields: The projection for the findAndModify command.
 * - cmd.sort: The sort option for the findAndModify command.
 * - cmd.collation: The collation option for the findAndModify command.
 * - res.errorCode: If errorCode is set, we expect the command to fail with that code and other
 *                  fields of 'res' are ignored.
 * - res.resultDocList: The expected documents in the collection after the update.
 * - res.returnDoc: The expected document returned by the findAndModify command.
 * - res.writeType: "twoPhaseProtocol" or "targeted". On sharded time-series collection, we route
 *                  queries to shards if the queries contain the shardkey. "twoPhaseProtocol" means
 *                  that we cannot target a specific data-bearing shard from the query and should
 *                  the scatter-gather-like two-phase protocol. On the other hand, "targeted" means
 *                  we can from the query.
 * - res.dataBearingShard: "primary", "other", "none", or "any". For "none" and "any", only
 *                         the "twoPhaseProtocol" is allowed.
 * - res.rootStage: The expected root stage of the explain plan.
 * - res.bucketFilter: The expected bucket filter of the TS_MODIFY stage.
 * - res.residualFilter: The expected residual filter of the TS_MODIFY stage.
 * - res.nBucketsUnpacked: The expected number of buckets unpacked by the TS_MODIFY stage.
 * - res.nMatched: The expected number of documents matched by the TS_MODIFY stage.
 * - res.nModified: The expected number of documents modified by the TS_MODIFY stage.
 * - res.nUpserted: The expected number of documents upserted by the TS_MODIFY stage.
 ','line_number':887,'multiline':True]['text':' Explain can't be run inside a transaction.','line_number':956,'multiline':False]['text':' Due to the limitation of two-phase write protocol, the TS_MODIFY stage's execution','line_number':958,'multiline':False]['text':' stats can't really show the results close to real execution. We can just verify','line_number':959,'multiline':False]['text':' plan part.','line_number':960,'multiline':False]['text':'*
 * Sets up a sharded cluster. 'nMongos' is the number of mongos in the cluster.
 ','line_number':1035,'multiline':True]['text':'*
 * Tears down the sharded cluster created by setUpShardedCluster().
 ','line_number':1062,'multiline':True]