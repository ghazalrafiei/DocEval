['text':'*
 * Runs the dbHash command across all members of a replica set and compares the output.
 *
 * Unlike run_check_repl_dbhash.js, this version of the hook doesn't require that all operations
 * have finished replicating, nor does it require that the test has finished running. The dbHash
 * command reads at a particular clusterTime in order for an identical snapshot to be used by all
 * members of the replica set.
 *
 * The find and getMore commands used to generate the collection diff read at the same clusterTime
 * as the dbHash command. While this ensures the diagnostics for a dbhash mismatch aren't subjected
 * to changes from any operations in flight, it is possible for the collection or an index on the
 * collection to be dropped due to no locks being held.
 *
 * If a transient error occurs, then the dbhash check is retried until it succeeds, or until it
 * fails with a non-transient error. The most common case of a transient error is attempting to read
 * from a collection after a catalog operation has been performed on the collection or database.
 ','line_number':1,'multiline':True]['text':' We turn off printing the JavaScript stacktrace in doassert() to avoid generating an','line_number':26,'multiline':False]['text':' overwhelming amount of log messages when handling transient errors.','line_number':27,'multiline':False]['text':' Disable implicit sessions so FSM workloads that kill random sessions won't interrupt the','line_number':31,'multiline':False]['text':' operations in this test that aren't resilient to interruptions.','line_number':32,'multiline':False]['text':' Calls 'func' with the print() function overridden to be a no-op.','line_number':41,'multiline':False]['text':' We construct the ReplSetTest instance with the print() function overridden to be a no-op','line_number':53,'multiline':False]['text':' in order to suppress the log messages about the replica set configuration. The','line_number':54,'multiline':False]['text':' run_check_repl_dbhash_background.js hook is executed frequently by resmoke.py and would','line_number':55,'multiline':False]['text':' otherwise lead to generating an overwhelming amount of log messages.','line_number':56,'multiline':False]['text':' We enable the "WTPreserveSnapshotHistoryIndefinitely" failpoint to ensure that the same','line_number':79,'multiline':False]['text':' snapshot will be available to read at on the primary and secondaries.','line_number':80,'multiline':False]['text':' Use the session's client directly so FSM workloads that kill random sessions won't','line_number':82,'multiline':False]['text':' interrupt these operations.','line_number':83,'multiline':False]['text':' Use the session's client directly so FSM workloads that kill random sessions won't','line_number':106,'multiline':False]['text':' interrupt these operations.','line_number':107,'multiline':False]['text':' Transactions cannot be run on the following databases so we don't attempt to read at a','line_number':121,'multiline':False]['text':' clusterTime on them either. (The "local" database is also not replicated.)','line_number':122,'multiline':False]['text':' The waitForSecondaries() function waits for all secondaries to have applied up to','line_number':129,'multiline':False]['text':' 'clusterTime' locally. This ensures that a later $_internalReadAtClusterTime read doesn't','line_number':130,'multiline':False]['text':' fail as a result of the secondary's clusterTime being behind 'clusterTime'.','line_number':131,'multiline':False]['text':' We advance the clusterTime on the secondary's session to ensure that','line_number':138,'multiline':False]['text':' 'clusterTime' doesn't exceed the node's notion of the latest clusterTime.','line_number':139,'multiline':False]['text':' We need to make sure the secondary has applied up to 'clusterTime' and advanced','line_number':142,'multiline':False]['text':' its majority commit point.','line_number':143,'multiline':False]['text':' If majority reads are supported, we can issue an afterClusterTime read on','line_number':146,'multiline':False]['text':' a nonexistent collection and wait on it. This has the advantage of being','line_number':147,'multiline':False]['text':' easier to debug in case of a timeout.','line_number':148,'multiline':False]['text':' If majority reads are not supported, then our only option is to poll for the','line_number':162,'multiline':False]['text':' appliedOpTime on the secondary to catch up.','line_number':163,'multiline':False]['text':' The 'atClusterTime' waits for the appliedOpTime to advance to','line_number':169,'multiline':False]['text':' 'clusterTime'.','line_number':170,'multiline':False]['text':' The checkCollectionHashesForDB() function identifies a collection by its UUID and ignores','line_number':189,'multiline':False]['text':' the case where a collection isn't present on a node to work around how the collection','line_number':190,'multiline':False]['text':' catalog isn't multi-versioned. Unlike with ReplSetTest#checkReplicatedDataHashes(), it is','line_number':191,'multiline':False]['text':' possible for a collection catalog operation (e.g. a drop or rename) to have been applied','line_number':192,'multiline':False]['text':' on the primary but not yet applied on the secondary.','line_number':193,'multiline':False]['text':' Outside of checkCollectionHashesForDB(), operations in this function are not resilient to','line_number':261,'multiline':False]['text':' their session being killed by a concurrent FSM workload, so the driver sessions started above','line_number':262,'multiline':False]['text':' have not been used and will have contain null logical time values. The process for selecting','line_number':263,'multiline':False]['text':' a read timestamp below assumes each session has valid logical times, so run a dummy command','line_number':264,'multiline':False]['text':' through each session to populate its logical times.','line_number':265,'multiline':False]['text':' The isTransientError() function is responsible for setting hasTransientError to true.','line_number':275,'multiline':False]['text':' It is possible for the ReplSetTest#getHashesUsingSessions() function to be','line_number':277,'multiline':False]['text':' interrupted due to active sessions being killed by a test running concurrently.','line_number':278,'multiline':False]['text':' We treat this as a transient error and simply retry running the dbHash check.','line_number':279,'multiline':False]['text':'','line_number':280,'multiline':False]['text':' Note that unlike auto_retry_transaction.js, we do not treat CursorKilled or','line_number':281,'multiline':False]['text':' CursorNotFound error responses as transient errors because the','line_number':282,'multiline':False]['text':' run_check_repl_dbhash_background.js hook would only establish a cursor via','line_number':283,'multiline':False]['text':' DataConsistencyChecker#getCollectionDiffUsingSessions() upon detecting a dbHash','line_number':284,'multiline':False]['text':' mismatch. It is still useful to know that a bug exists even if we cannot','line_number':285,'multiline':False]['text':' get more diagnostics for it.','line_number':286,'multiline':False]['text':' Perform a no-op write to the primary if the clusterTime between each call remain','line_number':291,'multiline':False]['text':' the same and if we encounter the SnapshotUnavailable error as the secondaries','line_number':292,'multiline':False]['text':' minimum timestamp can be greater than the primaries minimum timestamp.','line_number':293,'multiline':False]['text':' InvalidOptions can be returned when $_internalReadAtClusterTime is greater than','line_number':301,'multiline':False]['text':' the all-committed timestamp. As the dbHash command is running in the background','line_number':302,'multiline':False]['text':' at varying times, it's possible that we may run dbHash while a prepared','line_number':303,'multiline':False]['text':' transactions has yet to commit or abort.','line_number':304,'multiline':False]['text':' In debug builds, read-only operations can receive write conflicts when the storage','line_number':309,'multiline':False]['text':' engine cache is full. Since dbHash holds open a read snapshot for an extended period','line_number':310,'multiline':False]['text':' of time and pulls all collection data into cache, the storage engine may abort the','line_number':311,'multiline':False]['text':' operation if it needs to free up space. Try again after space has been freed.','line_number':312,'multiline':False]['text':' SERVER-38928: Due to races around advancing last applied, there's technically no','line_number':321,'multiline':False]['text':' guarantee that a primary will report a later operation time than its','line_number':322,'multiline':False]['text':' secondaries. Perform the snapshot read at the latest reported operation time.','line_number':323,'multiline':False]['text':' Use the session's client directly so FSM workloads that kill random','line_number':353,'multiline':False]['text':' sessions won't interrupt appendOplogNote.','line_number':354,'multiline':False]['text':' If the no-op write fails due to the global lock not being able to be','line_number':357,'multiline':False]['text':' acquired within 1 millisecond, retry the operation again at a later','line_number':358,'multiline':False]['text':' time.','line_number':359,'multiline':False]['text':' Wait for each thread to finish. Throw an error if any thread fails.','line_number':488,'multiline':False]['text':' eslint-disable-next-line','line_number':501,'multiline':False]