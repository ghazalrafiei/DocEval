['text':'**************************
 * load/store
 **************************','line_number':10,'multiline':True]['text':' unaligned load','line_number':42,'multiline':False]['text':' aligned load','line_number':45,'multiline':False]['text':' stream load','line_number':48,'multiline':False]['text':' load lower part','line_number':53,'multiline':False]['text':' unaligned store','line_number':56,'multiline':False]['text':' aligned store','line_number':59,'multiline':False]['text':' stream store','line_number':62,'multiline':False]['text':' store lower part','line_number':65,'multiline':False]['text':' store higher part','line_number':68,'multiline':False]['text':'**************************
 * Non-contiguous Load
 **************************','line_number':71,'multiline':True]['text':'// 32','line_number':74,'multiline':False]['text':'// 64','line_number':86,'multiline':False]['text':'// 64-bit load over 32-bit stride','line_number':100,'multiline':False]['text':'// 128-bit load over 64-bit stride','line_number':114,'multiline':False]['text':'**************************
 * Non-contiguous Store
 **************************','line_number':125,'multiline':True]['text':'// 32','line_number':128,'multiline':False]['text':'// 64','line_number':146,'multiline':False]['text':'// 64-bit store over 32-bit stride','line_number':161,'multiline':False]['text':'// 128-bit store over 64-bit stride','line_number':176,'multiline':False]['text':'********************************
 * Partial Load
 ********************************','line_number':187,'multiline':True]['text':'// 32','line_number':190,'multiline':False]['text':' fill zero to rest lanes','line_number':206,'multiline':False]['text':'// 64','line_number':220,'multiline':False]['text':' fill zero to rest lanes','line_number':236,'multiline':False]['text':'// 64-bit nlane','line_number':251,'multiline':False]['text':' fill zero to rest lanes','line_number':271,'multiline':False]['text':'/ 128-bit nlane','line_number':275,'multiline':False]['text':' fill zero to rest lanes','line_number':288,'multiline':False]['text':'********************************
 * Non-contiguous partial load
 ********************************','line_number':303,'multiline':True]['text':'// 32','line_number':306,'multiline':False]['text':' fill zero to rest lanes','line_number':324,'multiline':False]['text':'// 64','line_number':328,'multiline':False]['text':' fill zero to rest lanes','line_number':345,'multiline':False]['text':'// 64-bit load over 32-bit stride','line_number':350,'multiline':False]['text':' fill zero to rest lanes','line_number':370,'multiline':False]['text':'// 128-bit load over 64-bit stride','line_number':374,'multiline':False]['text':' fill zero to rest lanes','line_number':396,'multiline':False]['text':'********************************
 * Partial store
 ********************************','line_number':400,'multiline':True]['text':'// 32','line_number':403,'multiline':False]['text':'// 64','line_number':412,'multiline':False]['text':'// 64-bit nlane','line_number':422,'multiline':False]['text':'// 128-bit nlane','line_number':426,'multiline':False]['text':'
    * Although this version is compatible with all other compilers,
    * there is no performance benefit in retaining the other branch.
    * However, it serves as evidence of a newly emerging bug in MSVC
    * that started to appear since v19.30.
    * For some reason, the MSVC optimizer chooses to ignore the lower store (128-bit mov)
    * and replace with full mov counting on ymmword pointer.
    *
    * For more details, please refer to the discussion on https://github.com/numpy/numpy/issues/23896.
    ','line_number':431,'multiline':True]['text':'********************************
 * Non-contiguous partial store
 ********************************','line_number':454,'multiline':True]['text':'// 32','line_number':457,'multiline':False]['text':'// 64','line_number':511,'multiline':False]['text':'// 64-bit store over 32-bit stride','line_number':537,'multiline':False]['text':'// 128-bit store over 64-bit stride','line_number':562,'multiline':False]['text':'****************************************************************************
 * Implement partial load/store for u32/f32/u64/f64... via reinterpret cast
 ****************************************************************************','line_number':571,'multiline':True]['text':' 128-bit/64-bit stride (load/store pair)','line_number':636,'multiline':False]['text':'***********************************************************
 *  de-interlave load / interleave contiguous store
 ***********************************************************','line_number':707,'multiline':True]['text':' two channels','line_number':710,'multiline':False]['text':'********************************
 * Lookup tables
 ********************************','line_number':740,'multiline':True]['text':' uses vector as indexes into a table','line_number':743,'multiline':False]['text':' that contains 32 elements of float32.','line_number':744,'multiline':False]['text':' uses vector as indexes into a table','line_number':752,'multiline':False]['text':' that contains 16 elements of float64.','line_number':753,'multiline':False]['text':' _NPY_SIMD_AVX2_MEMORY_H','line_number':761,'multiline':False]