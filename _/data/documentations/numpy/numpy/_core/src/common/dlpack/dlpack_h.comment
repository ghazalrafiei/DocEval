['text':' Taken from:','line_number':1,'multiline':False]['text':' https://github.com/dmlc/dlpack/blob/ca4d00ad3e2e0f410eeab3264d21b8a39397f362/include/dlpack/dlpack.h','line_number':2,'multiline':False]['text':'!
 *  Copyright (c) 2017 by Contributors
 * \file dlpack.h
 * \brief The common header of DLPack.
 ','line_number':3,'multiline':True]['text':'*
 * \brief Compatibility with C++
 ','line_number':11,'multiline':True]['text':'! \brief The current major version of dlpack ','line_number':20,'multiline':True]['text':'! \brief The current minor version of dlpack ','line_number':23,'multiline':True]['text':'! \brief DLPACK_DLL prefix for windows ','line_number':26,'multiline':True]['text':'!
 * \brief The DLPack version.
 *
 * A change in major version indicates that we have changed the
 * data layout of the ABI - DLManagedTensorVersioned.
 *
 * A change in minor version indicates that we have added new
 * code, such as a new device type, but the ABI is kept the same.
 *
 * If an obtained DLPack tensor has a major version that disagrees
 * with the version number specified in this header file
 * (i.e. major != DLPACK_MAJOR_VERSION), the consumer must call the deleter
 * (and it is safe to do so). It is not safe to access any other fields
 * as the memory layout will have changed.
 *
 * In the case of a minor version mismatch, the tensor can be safely used as
 * long as the consumer knows how to interpret all fields. Minor version
 * updates indicate the addition of enumeration values.
 ','line_number':44,'multiline':True]['text':'! \brief DLPack major version. ','line_number':64,'multiline':True]['text':'! \brief DLPack minor version. ','line_number':66,'multiline':True]['text':'!
 * \brief The device type in DLDevice.
 ','line_number':70,'multiline':True]['text':'! \brief CPU device ','line_number':78,'multiline':True]['text':'! \brief CUDA GPU device ','line_number':80,'multiline':True]['text':'!
   * \brief Pinned CUDA CPU memory by cudaMallocHost
   ','line_number':82,'multiline':True]['text':'! \brief OpenCL devices. ','line_number':86,'multiline':True]['text':'! \brief Vulkan buffer for next generation graphics. ','line_number':88,'multiline':True]['text':'! \brief Metal for Apple GPU. ','line_number':90,'multiline':True]['text':'! \brief Verilog simulator buffer ','line_number':92,'multiline':True]['text':'! \brief ROCm GPUs for AMD GPUs ','line_number':94,'multiline':True]['text':'!
   * \brief Pinned ROCm CPU memory allocated by hipMallocHost
   ','line_number':96,'multiline':True]['text':'!
   * \brief Reserved extension device type,
   * used for quickly test extension device
   * The semantics can differ depending on the implementation.
   ','line_number':100,'multiline':True]['text':'!
   * \brief CUDA managed/unified memory allocated by cudaMallocManaged
   ','line_number':106,'multiline':True]['text':'!
   * \brief Unified shared memory allocated on a oneAPI non-partititioned
   * device. Call to oneAPI runtime is required to determine the device
   * type, the USM allocation type and the sycl context it is bound to.
   *
   ','line_number':110,'multiline':True]['text':'! \brief GPU support for next generation WebGPU standard. ','line_number':117,'multiline':True]['text':'! \brief Qualcomm Hexagon DSP ','line_number':119,'multiline':True]['text':'!
 * \brief A Device for Tensor and operator.
 ','line_number':123,'multiline':True]['text':'! \brief The device type used in the device. ','line_number':127,'multiline':True]['text':'!
   * \brief The device index.
   * For vanilla CPU memory, pinned memory, or managed memory, this is set to 0.
   ','line_number':129,'multiline':True]['text':'!
 * \brief The type code options DLDataType.
 ','line_number':136,'multiline':True]['text':'! \brief signed integer ','line_number':140,'multiline':True]['text':'! \brief unsigned integer ','line_number':142,'multiline':True]['text':'! \brief IEEE floating point ','line_number':144,'multiline':True]['text':'!
   * \brief Opaque handle type, reserved for testing purposes.
   * Frameworks need to agree on the handle data type for the exchange to be well-defined.
   ','line_number':146,'multiline':True]['text':'! \brief bfloat16 ','line_number':151,'multiline':True]['text':'!
   * \brief complex number
   * (C/C++/Python layout: compact struct per complex number)
   ','line_number':153,'multiline':True]['text':'! \brief boolean ','line_number':158,'multiline':True]['text':'!
 * \brief The data type the tensor can hold. The data type is assumed to follow the
 * native endian-ness. An explicit error message should be raised when attempting to
 * export an array with non-native endianness
 *
 *  Examples
 *   - float: type_code = 2, bits = 32, lanes = 1
 *   - float4(vectorized 4 float): type_code = 2, bits = 32, lanes = 4
 *   - int8: type_code = 0, bits = 8, lanes = 1
 *   - std::complex<float>: type_code = 5, bits = 64, lanes = 1
 *   - bool: type_code = 6, bits = 8, lanes = 1 (as per common array library convention, the underlying storage size of bool is 8 bits)
 ','line_number':162,'multiline':True]['text':'!
   * \brief Type code of base types.
   * We keep it uint8_t instead of DLDataTypeCode for minimal memory
   * footprint, but the value should be one of DLDataTypeCode enum values.
   * ','line_number':175,'multiline':True]['text':'!
   * \brief Number of bits, common choices are 8, 16, 32.
   ','line_number':181,'multiline':True]['text':'! \brief Number of lanes in the type, used for vector types. ','line_number':185,'multiline':True]['text':'!
 * \brief Plain C Tensor object, does not manage memory.
 ','line_number':189,'multiline':True]['text':'!
   * \brief The data pointer points to the allocated data. This will be CUDA
   * device pointer or cl_mem handle in OpenCL. It may be opaque on some device
   * types. This pointer is always aligned to 256 bytes as in CUDA. The
   * `byte_offset` field should be used to point to the beginning of the data.
   *
   * Note that as of Nov 2021, multiply libraries (CuPy, PyTorch, TensorFlow,
   * TVM, perhaps others) do not adhere to this 256 byte alignment requirement
   * on CPU/CUDA/ROCm, and always use `byte_offset=0`.  This must be fixed
   * (after which this note will be updated); at the moment it is recommended
   * to not rely on the data pointer being correctly aligned.
   *
   * For given DLTensor, the size of memory required to store the contents of
   * data is calculated as follows:
   *
   * \code{.c}
   * static inline size_t GetDataSize(const DLTensor* t) {
   *   size_t size = 1;
   *   for (tvm_index_t i = 0; i < t->ndim; ++i) {
   *     size *= t->shape[i];
   *   }
   *   size *= (t->dtype.bits * t->dtype.lanes + 7) / 8;
   *   return size;
   * }
   * \endcode
   ','line_number':193,'multiline':True]['text':'! \brief The device of the tensor ','line_number':220,'multiline':True]['text':'! \brief Number of dimensions ','line_number':222,'multiline':True]['text':'! \brief The data type of the pointer','line_number':224,'multiline':True]['text':'! \brief The shape of the tensor ','line_number':226,'multiline':True]['text':'!
   * \brief strides of the tensor (in number of elements, not bytes)
   *  can be NULL, indicating tensor is compact and row-majored.
   ','line_number':228,'multiline':True]['text':'! \brief The offset in bytes to the beginning pointer to data ','line_number':233,'multiline':True]['text':'!
 * \brief C Tensor object, manage memory of DLTensor. This data structure is
 *  intended to facilitate the borrowing of DLTensor by another framework. It is
 *  not meant to transfer the tensor. When the borrowing framework doesn't need
 *  the tensor, it should call the deleter to notify the host that the resource
 *  is no longer needed.
 *
 * \note This data structure is used as Legacy DLManagedTensor
 *       in DLPack exchange and is deprecated after DLPack v0.8
 *       Use DLManagedTensorVersioned instead.
 *       This data structure may get renamed or deleted in future versions.
 *
 * \sa DLManagedTensorVersioned
 ','line_number':237,'multiline':True]['text':'! \brief DLTensor which is being memory managed ','line_number':252,'multiline':True]['text':'! \brief the context of the original host framework of DLManagedTensor in
   *   which DLManagedTensor is used in the framework. It can also be NULL.
   ','line_number':254,'multiline':True]['text':'!
   * \brief Destructor - this should be called
   * to destruct the manager_ctx  which backs the DLManagedTensor. It can be
   * NULL if there is no way for the caller to provide a reasonable destructor.
   * The destructors deletes the argument self as well.
   ','line_number':258,'multiline':True]['text':' bit masks used in in the DLManagedTensorVersioned','line_number':267,'multiline':False]['text':'! \brief bit mask to indicate that the tensor is read only. ','line_number':269,'multiline':True]['text':'!
 * \brief A versioned and managed C Tensor object, manage memory of DLTensor.
 *
 * This data structure is intended to facilitate the borrowing of DLTensor by
 * another framework. It is not meant to transfer the tensor. When the borrowing
 * framework doesn't need the tensor, it should call the deleter to notify the
 * host that the resource is no longer needed.
 *
 * \note This is the current standard DLPack exchange data structure.
 ','line_number':272,'multiline':True]['text':'!
   * \brief The API and ABI version of the current managed Tensor
   ','line_number':283,'multiline':True]['text':'!
   * \brief the context of the original host framework.
   *
   * Stores DLManagedTensorVersioned is used in the
   * framework. It can also be NULL.
   ','line_number':287,'multiline':True]['text':'!
   * \brief Destructor.
   *
   * This should be called to destruct manager_ctx which holds the DLManagedTensorVersioned.
   * It can be NULL if there is no way for the caller to provide a reasonable
   * destructor. The destructors deletes the argument self as well.
   ','line_number':294,'multiline':True]['text':'!
   * \brief Additional bitmask flags information about the tensor.
   *
   * By default the flags should be set to 0.
   *
   * \note Future ABI changes should keep everything until this field
   *       stable, to ensure that deleter can be correctly called.
   *
   * \sa DLPACK_FLAG_BITMASK_READ_ONLY
   ','line_number':302,'multiline':True]['text':'! \brief DLTensor which is being memory managed ','line_number':313,'multiline':True]['text':' DLPACK_EXTERN_C','line_number':318,'multiline':False]['text':' DLPACK_DLPACK_H_','line_number':320,'multiline':False]