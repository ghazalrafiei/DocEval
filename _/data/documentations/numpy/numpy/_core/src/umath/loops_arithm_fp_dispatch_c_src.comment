['text':'@targets
 ** $maxopt baseline
 ** sse2 (avx2 fma3)
 ** neon asimd
 ** vsx2 vsx3
 ** vx vxe
 *','line_number':1,'multiline':True]['text':' Provides the various *_LOOP macros','line_number':16,'multiline':False]['text':'*
 * TODO:
 *  - Improve the implementation of SIMD complex absolute,
 *    current one kinda slow and it can be optimized by
 *    at least avoiding the division and keep sqrt.
 *  - Vectorize reductions
 *  - Add support for ASIMD/VCMLA through universal intrinics.
 ','line_number':19,'multiline':True]['text':'###############################################################################','line_number':28,'multiline':False]['text':'## Real Single/Double precision','line_number':29,'multiline':False]['text':'###############################################################################','line_number':30,'multiline':False]['text':'*******************************************************************************
 ** Defining ufunc inner functions
 *******************************************************************************','line_number':31,'multiline':True]['text':'*begin repeat
 * Float types
 *  #type = npy_float, npy_double#
 *  #TYPE = FLOAT, DOUBLE#
 *  #sfx  = f32, f64#
 *  #c = f, #
 *  #C = F, #
 *  #VECTOR = NPY_SIMD_F32, NPY_SIMD_F64#
 ','line_number':34,'multiline':True]['text':'*begin repeat1
 * Arithmetic
 * # kind = add, subtract, multiply, divide#
 * # intrin = add, sub, mul, div#
 * # OP = +, -, *, /#
 * # PW = 1, 0, 0, 0#
 * # is_div = 0*3, 1#
 * # is_mul = 0*2, 1, 0#
 ','line_number':43,'multiline':True]['text':' reduce','line_number':58,'multiline':False]['text':'*
     * The SIMD branch is disabled on armhf(armv7) due to the absence of native SIMD
     * support for single-precision floating-point division. Only scalar division is
     * supported natively, and without hardware for performance and accuracy comparison,
     * it's challenging to evaluate the benefits of emulated SIMD intrinsic versus
     * native scalar division.
     *
     * The `npyv_div_f32` universal intrinsic emulates the division operation using an
     * approximate reciprocal combined with 3 Newton-Raphson iterations for enhanced
     * precision. However, this approach has limitations:
     *
     * - It can cause unexpected floating-point overflows in special cases, such as when
     *   the divisor is subnormal (refer: https://github.com/numpy/numpy/issues/25097).
     *
     * - The precision may vary between the emulated SIMD and scalar division due to
     *   non-uniform branches (non-contiguous) in the code, leading to precision
     *   inconsistencies.
     *
     * - Considering the necessity of multiple Newton-Raphson iterations, the performance
     *   gain may not sufficiently offset these drawbacks.
     ','line_number':78,'multiline':True]['text':' lots of specializations, to squeeze out max performance','line_number':108,'multiline':False]['text':'*end repeat1*','line_number':210,'multiline':True]['text':'*end repeat*','line_number':211,'multiline':True]['text':'###############################################################################','line_number':213,'multiline':False]['text':'## Complex Single/Double precision','line_number':214,'multiline':False]['text':'###############################################################################','line_number':215,'multiline':False]['text':'*******************************************************************************
 ** op intrinsics
 *******************************************************************************','line_number':217,'multiline':True]['text':' a_im * b_im, a_im * b_re','line_number':248,'multiline':False]['text':' a_im * b_im, a_im * b_re','line_number':289,'multiline':False]['text':'*******************************************************************************
 ** Defining ufunc inner functions
 *******************************************************************************','line_number':299,'multiline':True]['text':'*begin repeat
 * complex types
 * #TYPE = CFLOAT, CDOUBLE#
 * #ftype = npy_float, npy_double#
 * #VECTOR = NPY_SIMD_F32, NPY_SIMD_F64#
 * #sfx = f32, f64#
 * #c = f, #
 * #C = F, #
 ','line_number':302,'multiline':True]['text':'*begin repeat1
 * arithmetic
 * #kind = add, subtract, multiply#
 * #vectorf = npyv_add, npyv_sub, simd_cmul#
 * #OP = +, -, *#
 * #PW = 1, 0, 0#
 * #is_mul = 0*2, 1#
 ','line_number':311,'multiline':True]['text':' reduce','line_number':326,'multiline':False]['text':' Certain versions of Apple clang (commonly used in CI images) produce','line_number':339,'multiline':False]['text':' non-deterministic output in the mul path with AVX2 enabled on x86_64.','line_number':340,'multiline':False]['text':' Work around by scalarising.','line_number':341,'multiline':False]['text':' end affected Apple clang.','line_number':348,'multiline':False]['text':' lots**lots of specializations, to squeeze out max performance','line_number':373,'multiline':False]['text':' contig','line_number':374,'multiline':False]['text':' scalar 0','line_number':393,'multiline':False]['text':' contig','line_number':396,'multiline':False]['text':' non-contig','line_number':416,'multiline':False]['text':' scalar 1','line_number':440,'multiline':False]['text':' non-contig','line_number':462,'multiline':False]['text':' non-contig','line_number':487,'multiline':False]['text':'*end repeat1*','line_number':569,'multiline':True]['text':'*begin repeat1
 *  #kind = conjugate, square#
 *  #is_square = 0, 1#
 ','line_number':571,'multiline':True]['text':'*end repeat1*','line_number':661,'multiline':True]['text':'*end repeat*','line_number':662,'multiline':True]