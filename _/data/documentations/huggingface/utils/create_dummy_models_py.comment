['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2022 The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' make sure tokenizer plays nice with multiprocessing','line_number':54,'multiline':False]['text':' This list contains the model architectures for which a tiny version could not be created.','line_number':83,'multiline':False]['text':' Avoid to add new architectures here - unless we have verified carefully that it's (almost) impossible to create them.','line_number':84,'multiline':False]['text':' One such case is: no model tester class is implemented for a model type (like `MT5`) because its architecture is','line_number':85,'multiline':False]['text':' identical to another one (`MT5` is based on `T5`), but trained on different datasets or with different techniques.','line_number':86,'multiline':False]['text':' To make a uniform return type','line_number':156,'multiline':False]['text':' Check first if a model has `ProcessorMixin`. Otherwise, check if it has tokenizers, and/or an image processor or','line_number':169,'multiline':False]['text':' a feature extractor','line_number':170,'multiline':False]['text':' Remark: some configurations have no processor at all. For example, generic composite models like','line_number':182,'multiline':False]['text':' `EncoderDecoderModel` is used for any (compatible) text models. Also, `DecisionTransformer` doesn't','line_number':183,'multiline':False]['text':' require any processor.','line_number':184,'multiline':False]['text':' We might get `None` for some tokenizers - remove them here.','line_number':186,'multiline':False]['text':' A model architecture could appear in several mappings. For example, `BartForConditionalGeneration` is in','line_number':197,'multiline':False]['text':'   - MODEL_FOR_PRETRAINING_MAPPING_NAMES','line_number':198,'multiline':False]['text':'   - MODEL_WITH_LM_HEAD_MAPPING_NAMES','line_number':199,'multiline':False]['text':'   - MODEL_FOR_MASKED_LM_MAPPING_NAMES','line_number':200,'multiline':False]['text':'   - MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES','line_number':201,'multiline':False]['text':' We avoid the duplication.','line_number':202,'multiline':False]['text':' `Wav2Vec2CTCTokenizer` -> `Wav2Vec2Config`','line_number':235,'multiline':False]['text':' Find the new configuration class','line_number':239,'multiline':False]['text':' Currently, this solely uses the docstring in the source file of `config_class` to find a checkpoint.','line_number':256,'multiline':False]['text':' try to get the checkpoint from the config class for `processor_class`.','line_number':260,'multiline':False]['text':' This helps cases like `XCLIPConfig` and `VideoMAEFeatureExtractor` to find a checkpoint from `VideoMAEConfig`.','line_number':261,'multiline':False]['text':' Try to get a new processor class from checkpoint. This is helpful for a checkpoint without necessary file to load','line_number':271,'multiline':False]['text':' processor while `processor_class` is an Auto class. For example, `sew` has `Wav2Vec2Processor` in','line_number':272,'multiline':False]['text':' `PROCESSOR_MAPPING_NAMES`, its `tokenizer_class` is `AutoTokenizer`, and the checkpoint','line_number':273,'multiline':False]['text':' `https://huggingface.co/asapp/sew-tiny-100k` has no tokenizer file, but we can get','line_number':274,'multiline':False]['text':' `tokenizer_class: Wav2Vec2CTCTokenizer` from the config file. (The new processor class won't be able to load from','line_number':275,'multiline':False]['text':' `checkpoint`, but it helps this recursive method to find a way to build a processor).','line_number':276,'multiline':False]['text':' If `tokenizer_class` is not specified in `config`, let's use `config` to get the process class via auto','line_number':299,'multiline':False]['text':' mappings, but only allow the tokenizer mapping being used. This is to make `Wav2Vec2Conformer` build','line_number':300,'multiline':False]['text':' Used to avoid infinite recursion between a pair of fast/slow tokenizer types','line_number':305,'multiline':False]['text':' Let's use fast tokenizer if there is any','line_number':314,'multiline':False]['text':' Try to build each component (tokenizer & feature extractor) of a `ProcessorMixin`.','line_number':322,'multiline':False]['text':' This could be a tuple (for tokenizers). For example, `CLIPProcessor` has','line_number':327,'multiline':False]['text':'   - feature_extractor_class = "CLIPFeatureExtractor"','line_number':328,'multiline':False]['text':'   - tokenizer_class = ("CLIPTokenizer", "CLIPTokenizerFast")','line_number':329,'multiline':False]['text':' try to build a `ProcessorMixin`, so we can return a single value','line_number':340,'multiline':False]['text':' `checkpoint` might lack some file(s) to load a processor. For example, `facebook/hubert-base-ls960`','line_number':347,'multiline':False]['text':' has no tokenizer file to load `Wav2Vec2CTCTokenizer`. In this case, we try to build a processor','line_number':348,'multiline':False]['text':' with the configuration class (for example, `Wav2Vec2Config`) corresponding to `processor_class`.','line_number':349,'multiline':False]['text':' Try to create an image processor or a feature extractor without any checkpoint','line_number':354,'multiline':False]['text':' validation','line_number':365,'multiline':False]['text':' For model type like `data2vec-vision` and `donut-swin`, we can't get the config/model file name directly via','line_number':387,'multiline':False]['text':' `model_type` as it would be sth. like `configuration_data2vec_vision.py`.','line_number':388,'multiline':False]['text':' A simple way is to use `inspect.getsourcefile(config_class)`.','line_number':389,'multiline':False]['text':' The modeling file name without prefix (`modeling_`) and postfix (`.py`)','line_number':391,'multiline':False]['text':' Find the model tester class','line_number':401,'multiline':False]['text':' sort with the length of the class names first, then the alphabetical order','line_number':410,'multiline':False]['text':' This is to avoid `T5EncoderOnlyModelTest` is used instead of `T5ModelTest`, which has','line_number':411,'multiline':False]['text':' `is_encoder_decoder=False` and causes some pipeline tests failing (also failures in `Optimum` CI).','line_number':412,'multiline':False]['text':' TODO: More fine grained control of the desired tester class.','line_number':413,'multiline':False]['text':' CLIP-like models have `text_model_tester` and `vision_model_tester`, and we need to pass `vocab_size` to','line_number':423,'multiline':False]['text':' `text_model_tester` via `text_kwargs`. The same trick is also necessary for `Flava`.','line_number':424,'multiline':False]['text':' `parent` is an instance of `unittest.TestCase`, but we don't need it here.','line_number':431,'multiline':False]['text':' `PoolFormer` has no `get_config` defined. Furthermore, it's better to use `prepare_config_and_inputs` even if','line_number':437,'multiline':False]['text':' `get_config` is defined, since there might be some extra changes in `prepare_config_and_inputs`.','line_number':438,'multiline':False]['text':' make sure this is long enough (some model tester has `20` for this attr.) to pass `text-generation`','line_number':449,'multiline':False]['text':' pipeline tests.','line_number':450,'multiline':False]['text':' Make sure it at least runs','line_number':475,'multiline':False]['text':' Speech2TextModel specific.','line_number':498,'multiline':False]['text':' sanity check 1: fast and slow tokenizers should be compatible (vocab_size)','line_number':526,'multiline':False]['text':' sanity check 2: fast and slow tokenizers should be compatible (length)','line_number':541,'multiline':False]['text':' Currently, we only have these 2 possibilities','line_number':572,'multiline':False]['text':' check the built processors have the unique type','line_number':584,'multiline':False]['text':' If the (original) fast/slow tokenizers don't correspond, keep only the fast tokenizer.','line_number':601,'multiline':False]['text':' This doesn't necessarily imply the fast/slow tokenizers in a single Hub repo. has issues.','line_number':602,'multiline':False]['text':' It's more of an issue in `build_processor` which tries to get a checkpoint with as much effort as possible.','line_number':603,'multiline':False]['text':' For `YosoModel` (which uses `AlbertTokenizer(Fast)`), its real (Hub) checkpoint doesn't contain valid files to','line_number':604,'multiline':False]['text':' load the slower tokenizer (`AlbertTokenizer`), and it ends up finding the (canonical) checkpoint of `AlbertModel`,','line_number':605,'multiline':False]['text':' which has different vocabulary.','line_number':606,'multiline':False]['text':' TODO: Try to improve `build_processor`'s definition and/or usage to avoid the above situation in the first place.','line_number':607,'multiline':False]['text':' Wav2Vec2ForCTC , ByT5Tokenizer etc. all are already small enough and have no fast version that can','line_number':613,'multiline':False]['text':' be retrained','line_number':614,'multiline':False]['text':' If `fast_tokenizer` exists, `slow_tokenizer` should correspond to it.','line_number':625,'multiline':False]['text':' Make sure the fast tokenizer can be saved','line_number':627,'multiline':False]['text':' We don't save it to `output_folder` at this moment - only at the end of this function.','line_number':629,'multiline':False]['text':' Let's just keep the fast version','line_number':641,'multiline':False]['text':' If the (possibly converted) fast/slow tokenizers don't correspond, set them to `None`, and use the original','line_number':652,'multiline':False]['text':' tokenizers.','line_number':653,'multiline':False]['text':' If there is any conversion failed, we keep the original tokenizers.','line_number':656,'multiline':False]['text':' Let's use the original version at the end (`original_fast_tokenizer` and `original_slow_tokenizer`)','line_number':665,'multiline':False]['text':' Make sure the fast tokenizer can be saved','line_number':669,'multiline':False]['text':' We don't save it to `output_folder` at this moment - only at the end of this function.','line_number':671,'multiline':False]['text':' Make sure the slow tokenizer can be saved','line_number':683,'multiline':False]['text':' We don't save it to `output_folder` at this moment - only at the end of this function.','line_number':685,'multiline':False]['text':' update feature extractors using the tiny config','line_number':698,'multiline':False]['text':' copy the (same set of) processors (for a model type) to the model arch. specific folder','line_number':761,'multiline':False]['text':' Open a PR on the existing Hub repo.','line_number':821,'multiline':False]['text':' TODO: We need this information?','line_number':832,'multiline':False]['text':' Push to Hub repo directly','line_number':834,'multiline':False]['text':' this prints a progress bar with the upload','line_number':837,'multiline':False]['text':' These will be removed at the end if they are empty','line_number':869,'multiline':False]['text':' Not encoder-decoder, but encoder-encoder. We just keep the same name as above to make code easier','line_number':900,'multiline':False]['text':' build encoder','line_number':912,'multiline':False]['text':' build decoder','line_number':917,'multiline':False]['text':' build encoder-decoder','line_number':922,'multiline':False]['text':' Specify these explicitly for encoder-decoder like models, but not for `vision-text-dual-encoder` as it','line_number':927,'multiline':False]['text':' has no decoder.','line_number':928,'multiline':False]['text':' copy the processors','line_number':950,'multiline':False]['text':' fill `result`','line_number':958,'multiline':False]['text':' `Bark` configuration is too special. Let's just not handle this for now.','line_number':1005,'multiline':False]['text':' Check if there is any tokenizer (prefer fast version if any)','line_number':1011,'multiline':False]['text':' Get some properties of the (already converted) tokenizer (smaller vocab size, special token ids, etc.)','line_number':1023,'multiline':False]['text':' We use `len(tokenizer)` instead of `tokenizer.vocab_size` to avoid potential issues for tokenizers with non-empty','line_number':1024,'multiline':False]['text':' `added_tokens_encoder`. One example is the `DebertaV2Tokenizer` where the mask token is the extra token.','line_number':1025,'multiline':False]['text':' The original checkpoint has length `35998`, but it doesn't have ids `30400` and `30514` but instead `35998` and','line_number':1028,'multiline':False]['text':' `35999`.','line_number':1029,'multiline':False]['text':' Used to create a new model tester with `tokenizer.vocab_size` in order to get the (updated) special token ids.','line_number':1035,'multiline':False]['text':' `FSMTModelTester` accepts `src_vocab_size` and `tgt_vocab_size` but not `vocab_size`.','line_number':1037,'multiline':False]['text':' handle the possibility of `text_config` inside `_tiny_config` for clip-like models (`owlvit`, `groupvit`, etc.)','line_number':1045,'multiline':False]['text':' Collect values of some special token ids','line_number':1049,'multiline':False]['text':' Using the token id values from `tokenizer` instead of from `_tiny_config`.','line_number':1054,'multiline':False]['text':' `FSMTConfig` has `DecoderConfig` as `decoder` attribute.','line_number':1061,'multiline':False]['text':' These will be removed at the end if they are empty','line_number':1097,'multiline':False]['text':' Build processors','line_number':1101,'multiline':False]['text':' Convert the processors (reduce vocabulary size, smaller image size, etc.)','line_number':1137,'multiline':False]['text':' Just for us to see this easily in the report','line_number':1162,'multiline':False]['text':' Update attributes that `vocab_size` involves','line_number':1166,'multiline':False]['text':' So far, we only have to deal with `text_config`, as `config_overrides` contains text-related attributes only.','line_number':1170,'multiline':False]['text':' `FuyuConfig` saves data under both FuyuConfig and its `text_config`. This is not good, but let's just update','line_number':1171,'multiline':False]['text':' every involved fields to avoid potential failure.','line_number':1172,'multiline':False]['text':' If `text_config_dict` exists, we need to update its value here too in order to # make','line_number':1179,'multiline':False]['text':' `save_pretrained -> from_pretrained` work.','line_number':1180,'multiline':False]['text':' update `result["processor"]`','line_number':1187,'multiline':False]['text':' Make PT/TF weights compatible','line_number':1209,'multiline':False]['text':' Remove `TF`','line_number':1210,'multiline':False]['text':' Use the same weights from PyTorch.','line_number':1217,'multiline':False]['text':' Conversion may fail. Let's not create a model with different weights to avoid confusion (for now).','line_number':1222,'multiline':False]['text':' tiny model is not created for `arch_name`','line_number':1275,'multiline':False]['text':' composite models' checkpoints have more precise repo. names on the Hub.','line_number':1291,'multiline':False]['text':' The directory is not created, but processor(s) is/are included in `results`.','line_number':1298,'multiline':False]['text':' we might get duplication here. We will remove them below when creating `updated_data`.','line_number':1365,'multiline':False]['text':' deduplication and sort','line_number':1375,'multiline':False]['text':' A map from config classes to tuples of processors (tokenizer, feature extractor, processor) classes','line_number':1416,'multiline':False]['text':' This is the directory containing the reports','line_number':1448,'multiline':False]['text':' Build the tiny model summary file. The `tokenizer_classes` and `processor_classes` could be both empty lists.','line_number':1470,'multiline':False]['text':' When using the items in this file to update the file `tests/utils/tiny_model_summary.json`, the model','line_number':1471,'multiline':False]['text':' architectures with `tokenizer_classes` and `processor_classes` being both empty should **NOT** be added to','line_number':1472,'multiline':False]['text':' `tests/utils/tiny_model_summary.json`.','line_number':1473,'multiline':False]['text':' Build the warning/failure report (json format): same format as the complete `results` except this contains only','line_number':1481,'multiline':False]['text':' warnings or errors.','line_number':1482,'multiline':False]['text':' The simplified report: a .txt file with each line of format:','line_number':1488,'multiline':False]['text':' {model architecture name}: {OK or error message}','line_number':1489,'multiline':False]['text':' The simplified failure report: same above except this only contains line with errors','line_number':1493,'multiline':False]['text':' This has to be `spawn` to avoid hanging forever!','line_number':1501,'multiline':False]