['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2021 Facebook AI Research The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' See all DETR models at https://huggingface.co/models?filter=detr','line_number':60,'multiline':False]['text':' BELOW: utilities copied from','line_number':267,'multiline':False]['text':' https://github.com/facebookresearch/detr/blob/master/backbone.py','line_number':268,'multiline':False]['text':' move reshapes to the beginning','line_number':296,'multiline':False]['text':' to make it user-friendly','line_number':297,'multiline':False]['text':' replace batch norm by frozen batch norm','line_number':361,'multiline':False]['text':' send pixel_values through the model to get list of feature maps','line_number':380,'multiline':False]['text':' downsample pixel_mask to match shape of corresponding feature_map','line_number':385,'multiline':False]['text':' send pixel_values and pixel_mask through backbone to get list of (feature_map, pixel_mask) tuples','line_number':402,'multiline':False]['text':' position encoding','line_number':406,'multiline':False]['text':' TODO find a better way of exposing other arguments','line_number':475,'multiline':False]['text':' if key_value_states are provided this layer is used as a cross-attention layer','line_number':578,'multiline':False]['text':' for the decoder','line_number':579,'multiline':False]['text':' add position embeddings to the hidden states before projecting to queries and keys','line_number':583,'multiline':False]['text':' add key-value position embeddings to the key value states','line_number':588,'multiline':False]['text':' get query proj','line_number':593,'multiline':False]['text':' get key, value proj','line_number':595,'multiline':False]['text':' cross_attentions','line_number':597,'multiline':False]['text':' self_attention','line_number':601,'multiline':False]['text':' this operation is a bit awkward, but it's required to','line_number':632,'multiline':False]['text':' make sure that attn_weights keeps its gradient.','line_number':633,'multiline':False]['text':' In order to do so, attn_weights have to reshaped','line_number':634,'multiline':False]['text':' twice and have to be reused in the following','line_number':635,'multiline':False]['text':' Self Attention','line_number':823,'multiline':False]['text':' Cross-Attention Block','line_number':835,'multiline':False]['text':' Fully Connected','line_number':853,'multiline':False]['text':' Slightly different from the TF version which uses truncated_normal for initialization','line_number':907,'multiline':False]['text':' cf https://github.com/pytorch/pytorch/pull/5617','line_number':908,'multiline':False]['text':' in the original DETR, no layernorm is used at the end of the encoder, as "normalize_before" is set to False by default','line_number':995,'multiline':False]['text':' Initialize weights and apply final processing','line_number':997,'multiline':False]['text':' expand attention_mask','line_number':1060,'multiline':False]['text':' [batch_size, seq_len] -> [batch_size, 1, target_seq_len, source_seq_len]','line_number':1062,'multiline':False]['text':' add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)','line_number':1070,'multiline':False]['text':' skip the layer','line_number':1074,'multiline':False]['text':' we add object_queries as extra input to the encoder_layer','line_number':1080,'multiline':False]['text':' in DETR, the decoder uses layernorm after the last decoder layer output','line_number':1124,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1128,'multiline':False]['text':' [batch_size, seq_len] -> [batch_size, 1, target_seq_len, source_seq_len]','line_number':1209,'multiline':False]['text':' expand encoder attention mask','line_number':1214,'multiline':False]['text':' [batch_size, seq_len] -> [batch_size, 1, target_seq_len, source_seq_len]','line_number':1216,'multiline':False]['text':' optional intermediate hidden states','line_number':1221,'multiline':False]['text':' decoder layers','line_number':1224,'multiline':False]['text':' add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)','line_number':1230,'multiline':False]['text':' finally, apply layernorm','line_number':1270,'multiline':False]['text':' add hidden states from the last decoder layer','line_number':1273,'multiline':False]['text':' stack intermediate decoder activations','line_number':1277,'multiline':False]['text':' Create backbone + positional encoding','line_number':1307,'multiline':False]['text':' Create projection layer','line_number':1312,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1320,'multiline':False]['text':' First, sent pixel_values + pixel_mask through Backbone to obtain the features','line_number':1391,'multiline':False]['text':' pixel_values should be of shape (batch_size, num_channels, height, width)','line_number':1392,'multiline':False]['text':' pixel_mask should be of shape (batch_size, height, width)','line_number':1393,'multiline':False]['text':' get final feature map and downsampled mask','line_number':1396,'multiline':False]['text':' Second, apply 1x1 convolution to reduce the channel dimension to d_model (256 by default)','line_number':1402,'multiline':False]['text':' Third, flatten the feature map + position embeddings of shape NxCxHxW to NxCxHW, and permute it to NxHWxC','line_number':1405,'multiline':False]['text':' In other words, turn their shape into (batch_size, sequence_length, hidden_size)','line_number':1406,'multiline':False]['text':' Fourth, sent flattened_features + flattened_mask + position embeddings through encoder','line_number':1412,'multiline':False]['text':' flattened_features is a Tensor of shape (batch_size, heigth*width, hidden_size)','line_number':1413,'multiline':False]['text':' flattened_mask is a Tensor of shape (batch_size, heigth*width)','line_number':1414,'multiline':False]['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':1424,'multiline':False]['text':' Fifth, sent query embeddings + object_queries through the decoder (which is conditioned on the encoder output)','line_number':1432,'multiline':False]['text':' decoder outputs consists of (dec_features, dec_hidden, dec_attn)','line_number':1436,'multiline':False]['text':' DETR encoder-decoder model','line_number':1475,'multiline':False]['text':' Object detection heads','line_number':1478,'multiline':False]['text':' We add one for the "no object" class','line_number':1481,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1486,'multiline':False]['text':' taken from https://github.com/facebookresearch/detr/blob/master/models/detr.py','line_number':1489,'multiline':False]['text':' this is a workaround to make torchscript happy, as torchscript','line_number':1492,'multiline':False]['text':' doesn't support dictionary with non-homogeneous values, such','line_number':1493,'multiline':False]['text':' as a dict having both a Tensor and a list.','line_number':1494,'multiline':False]['text':' First, sent images through DETR base model to obtain encoder + decoder outputs','line_number':1558,'multiline':False]['text':' class logits + predicted bounding boxes','line_number':1573,'multiline':False]['text':' First: create the matcher','line_number':1579,'multiline':False]['text':' Second: create the criterion','line_number':1583,'multiline':False]['text':' Third: compute the losses, based on outputs and labels','line_number':1592,'multiline':False]['text':' Fourth: compute total loss, as a weighted sum of the various losses','line_number':1604,'multiline':False]['text':' object detection model','line_number':1649,'multiline':False]['text':' segmentation head','line_number':1652,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1664,'multiline':False]['text':' First, get list of feature maps and position embeddings','line_number':1735,'multiline':False]['text':' Second, apply 1x1 convolution to reduce the channel dimension to d_model (256 by default)','line_number':1738,'multiline':False]['text':' Third, flatten the feature map + position embeddings of shape NxCxHxW to NxCxHW, and permute it to NxHWxC','line_number':1743,'multiline':False]['text':' In other words, turn their shape into (batch_size, sequence_length, hidden_size)','line_number':1744,'multiline':False]['text':' Fourth, sent flattened_features + flattened_mask + position embeddings through encoder','line_number':1750,'multiline':False]['text':' flattened_features is a Tensor of shape (batch_size, heigth*width, hidden_size)','line_number':1751,'multiline':False]['text':' flattened_mask is a Tensor of shape (batch_size, heigth*width)','line_number':1752,'multiline':False]['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':1762,'multiline':False]['text':' Fifth, sent query embeddings + position embeddings through the decoder (which is conditioned on the encoder output)','line_number':1770,'multiline':False]['text':' decoder outputs consists of (dec_features, dec_hidden, dec_attn)','line_number':1776,'multiline':False]['text':' Sixth, compute logits, pred_boxes and pred_masks','line_number':1791,'multiline':False]['text':' FIXME h_boxes takes the last one computed, keep this in mind','line_number':1798,'multiline':False]['text':' important: we need to reverse the mask, since in the original implementation the mask works reversed','line_number':1799,'multiline':False]['text':' bbox_mask is of shape (batch_size, num_queries, number_of_attention_heads in bbox_attention, height/32, width/32)','line_number':1800,'multiline':False]['text':' First: create the matcher','line_number':1809,'multiline':False]['text':' Second: create the criterion','line_number':1813,'multiline':False]['text':' Third: compute the losses, based on outputs and labels','line_number':1822,'multiline':False]['text':' Fourth: compute total loss, as a weighted sum of the various losses','line_number':1835,'multiline':False]['text':' taken from https://github.com/facebookresearch/detr/blob/master/models/segmentation.py','line_number':1875,'multiline':False]['text':' here we concatenate x, the projected feature map, of shape (batch_size, d_model, heigth/32, width/32) with','line_number':1916,'multiline':False]['text':' the bbox_mask = the attention maps of shape (batch_size, n_queries, n_heads, height/32, width/32).','line_number':1917,'multiline':False]['text':' We expand the projected feature map to match the number of heads.','line_number':1918,'multiline':False]['text':' add modulating factor','line_number':2023,'multiline':False]['text':' taken from https://github.com/facebookresearch/detr/blob/master/models/detr.py','line_number':2034,'multiline':False]['text':' removed logging parameter, which was part of the original implementation','line_number':2070,'multiline':False]['text':' Count the number of predictions that are NOT "no-object" (which is the last class)','line_number':2102,'multiline':False]['text':' TODO use valid to mask invalid areas due to padding in loss','line_number':2146,'multiline':False]['text':' upsample predictions to the target size','line_number':2151,'multiline':False]['text':' permute predictions following indices','line_number':2166,'multiline':False]['text':' permute targets following indices','line_number':2172,'multiline':False]['text':' Retrieve the matching between the outputs of the last layer and the targets','line_number':2201,'multiline':False]['text':' Compute the average number of target boxes across all nodes, for normalization purposes','line_number':2204,'multiline':False]['text':' (Niels): comment out function below, distributed training to be added','line_number':2207,'multiline':False]['text':' if is_dist_avail_and_initialized():','line_number':2208,'multiline':False]['text':'     torch.distributed.all_reduce(num_boxes)','line_number':2209,'multiline':False]['text':' (Niels) in original implementation, num_boxes is divided by get_world_size()','line_number':2210,'multiline':False]['text':' Compute all the requested losses','line_number':2213,'multiline':False]['text':' In case of auxiliary losses, we repeat this process with the output of each intermediate layer.','line_number':2218,'multiline':False]['text':' Intermediate masks losses are too costly to compute, we ignore them.','line_number':2224,'multiline':False]['text':' taken from https://github.com/facebookresearch/detr/blob/master/models/detr.py','line_number':2233,'multiline':False]['text':' taken from https://github.com/facebookresearch/detr/blob/master/models/matcher.py','line_number':2255,'multiline':False]['text':' We flatten to compute the cost matrices in a batch','line_number':2306,'multiline':False]['text':' [batch_size * num_queries, num_classes]','line_number':2307,'multiline':False]['text':' [batch_size * num_queries, 4]','line_number':2308,'multiline':False]['text':' Also concat the target labels and boxes','line_number':2310,'multiline':False]['text':' Compute the classification cost. Contrary to the loss, we don't use the NLL,','line_number':2314,'multiline':False]['text':' but approximate it in 1 - proba[target class].','line_number':2315,'multiline':False]['text':' The 1 is a constant that doesn't change the matching, it can be ommitted.','line_number':2316,'multiline':False]['text':' Compute the L1 cost between boxes','line_number':2319,'multiline':False]['text':' Compute the giou cost between boxes','line_number':2322,'multiline':False]['text':' Final cost matrix','line_number':2325,'multiline':False]['text':' below: bounding box utilities taken from https://github.com/facebookresearch/detr/blob/master/util/box_ops.py','line_number':2334,'multiline':False]['text':' Protects from numerical overflows in multiplications by upcasting to the equivalent higher type','line_number':2338,'multiline':False]['text':' modified from torchvision to also return the union','line_number':2361,'multiline':False]['text':' [N,M,2]','line_number':2366,'multiline':False]['text':' [N,M,2]','line_number':2367,'multiline':False]['text':' [N,M,2]','line_number':2369,'multiline':False]['text':' [N,M]','line_number':2370,'multiline':False]['text':' degenerate boxes gives inf / nan results','line_number':2385,'multiline':False]['text':' so do an early check','line_number':2386,'multiline':False]['text':' [N,M,2]','line_number':2396,'multiline':False]['text':' below: taken from https://github.com/facebookresearch/detr/blob/master/util/misc.py#L306','line_number':2402,'multiline':False]['text':' type: (List[List[int]]) -> List[int]','line_number':2404,'multiline':False]