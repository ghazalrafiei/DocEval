['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2021 The I-BERT Authors (Sehoon Kim, Amir Gholami, Zhewei Yao,','line_number':2,'multiline':False]['text':' Michael Mahoney, Kurt Keutzer - UC Berkeley) and The HuggingFace Inc. team.','line_number':3,'multiline':False]['text':' Copyright (c) 20121, NVIDIA CORPORATION.  All rights reserved.','line_number':4,'multiline':False]['text':'','line_number':5,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':6,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':7,'multiline':False]['text':' You may obtain a copy of the License at','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':10,'multiline':False]['text':'','line_number':11,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':12,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':13,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':14,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':15,'multiline':False]['text':' limitations under the License.','line_number':16,'multiline':False]['text':' collect running stats if training','line_number':167,'multiline':False]['text':' Initialization','line_number':178,'multiline':False]['text':' exponential moving average (EMA)','line_number':183,'multiline':False]['text':' use momentum to prevent the quantized values change greatly every iteration','line_number':184,'multiline':False]['text':' this is for the input quantization','line_number':203,'multiline':False]['text':' assert that prev_act_scaling_factor is a scalar tensor','line_number':266,'multiline':False]['text':' dummy integer constant','line_number':323,'multiline':False]['text':' a(x+b)**2 + c','line_number':324,'multiline':False]['text':' avoid overflow','line_number':336,'multiline':False]['text':' -ln2','line_number':381,'multiline':False]['text':' dummy integer constant','line_number':382,'multiline':False]['text':' ax**2 + bx + c','line_number':383,'multiline':False]['text':' Avoid overflow','line_number':417,'multiline':False]['text':' adjusts `self.shift`','line_number':474,'multiline':False]['text':' compute sqrt of the feature dimension if it is the first run','line_number':489,'multiline':False]['text':' Normalization: computes mean and variance(std)','line_number':494,'multiline':False]['text':' overflow handling in training time','line_number':502,'multiline':False]['text':' if overflow is detected','line_number':504,'multiline':False]['text':' To be replaced with integer-sqrt kernel that produces the same output','line_number':512,'multiline':False]['text':' scaling and shifting','line_number':518,'multiline':False]['text':' lower_index += 1','line_number':555,'multiline':False]['text':' reshape scale and zeropoint for convolutional weights and activation','line_number':582,'multiline':False]['text':' reshape scale and zeropoint for linear weights','line_number':586,'multiline':False]['text':' quantized = float / scale + zero_point','line_number':593,'multiline':False]['text':' in this part, we do not need any gradient computation,','line_number':616,'multiline':False]['text':' in order to enforce this, we put torch.no_grad()','line_number':617,'multiline':False]['text':' reshape scale and zeropoint for linear weights','line_number':668,'multiline':False]['text':' trans the input to be a 1-d tensor','line_number':719,'multiline':False]['text':' noqa: E731','line_number':773,'multiline':False]['text':' noqa: E731','line_number':775,'multiline':False]['text':' needs addition of identity activation','line_number':799,'multiline':False]