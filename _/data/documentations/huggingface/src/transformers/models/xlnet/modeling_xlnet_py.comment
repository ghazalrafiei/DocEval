['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2018 Google AI, Google Brain and Carnegie Mellon University Authors and the HuggingFace Inc. team.','line_number':2,'multiline':False]['text':' Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.','line_number':3,'multiline':False]['text':'','line_number':4,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':5,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':6,'multiline':False]['text':' You may obtain a copy of the License at','line_number':7,'multiline':False]['text':'','line_number':8,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':9,'multiline':False]['text':'','line_number':10,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':11,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':12,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':13,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':14,'multiline':False]['text':' limitations under the License.','line_number':15,'multiline':False]['text':' See all XLNet models at https://huggingface.co/models?filter=xlnet','line_number':49,'multiline':False]['text':' We will load also the output bias','line_number':63,'multiline':False]['text':' We will load also the sequence summary','line_number':66,'multiline':False]['text':' Now load the rest of the transformer','line_number':77,'multiline':False]['text':' Embeddings and output','line_number':80,'multiline':False]['text':' Transformer blocks','line_number':88,'multiline':False]['text':' Relative positioning biases','line_number':109,'multiline':False]['text':' Load weights from TF model','line_number':147,'multiline':False]['text':' Build TF to PyTorch weights loading map','line_number':155,'multiline':False]['text':' adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v','line_number':164,'multiline':False]['text':' which are not required for using pretrained model','line_number':165,'multiline':False]['text':' Here we will split the TF weights','line_number':170,'multiline':False]['text':' x = x[:, 0:klen, :, :]','line_number':243,'multiline':False]['text':' Note: the tensor-slice form was faster in my testing than torch.index_select','line_number':255,'multiline':False]['text':'       However, tracing doesn't like the nature of the slice, and if klen changes','line_number':256,'multiline':False]['text':'       during the run then it'll fail, whereas index_select will be fine.','line_number':257,'multiline':False]['text':' x = x[:, :, :, :klen]','line_number':259,'multiline':False]['text':' content based attention score','line_number':276,'multiline':False]['text':' position based attention score','line_number':279,'multiline':False]['text':' segment based attention score','line_number':283,'multiline':False]['text':' merge attention scores and perform masking','line_number':290,'multiline':False]['text':' attn_score = attn_score * (1 - attn_mask) - 1e30 * attn_mask','line_number':293,'multiline':False]['text':' attention probability','line_number':299,'multiline':False]['text':' Mask heads if we want to','line_number':303,'multiline':False]['text':' attention output','line_number':307,'multiline':False]['text':' post-attention projection (back to `d_model`)','line_number':317,'multiline':False]['text':' Two-stream attention with relative positional encoding.','line_number':341,'multiline':False]['text':' content based attention score','line_number':342,'multiline':False]['text':' content-based key head','line_number':348,'multiline':False]['text':' content-based value head','line_number':351,'multiline':False]['text':' position-based key head','line_number':354,'multiline':False]['text':' h-stream','line_number':357,'multiline':False]['text':' content-stream query head','line_number':358,'multiline':False]['text':' core attention ops','line_number':361,'multiline':False]['text':' post processing','line_number':376,'multiline':False]['text':' g-stream','line_number':379,'multiline':False]['text':' query-stream query head','line_number':380,'multiline':False]['text':' core attention ops','line_number':383,'multiline':False]['text':' post processing','line_number':416,'multiline':False]['text':' Multi-head attention with relative positional encoding','line_number':423,'multiline':False]['text':' content heads','line_number':429,'multiline':False]['text':' positional heads','line_number':434,'multiline':False]['text':' type casting for fp16 support','line_number':435,'multiline':False]['text':' core attention ops','line_number':438,'multiline':False]['text':' post processing','line_number':453,'multiline':False]['text':' Add again attentions if there are there','line_number':528,'multiline':False]['text':' Slightly different from the TF version which uses truncated_normal for initialization','line_number':549,'multiline':False]['text':' cf https://github.com/pytorch/pytorch/pull/5617','line_number':550,'multiline':False]['text':' Initialize weights and apply final processing','line_number':949,'multiline':False]['text':' cache hidden states into memory.','line_number':990,'multiline':False]['text':' If `use_mems` is active but no `mem_len` is defined, the model behaves like GPT-2 at inference time','line_number':995,'multiline':False]['text':' and returns all of the past and current hidden states.','line_number':996,'multiline':False]['text':' If `use_mems` is active and `mem_len` is defined, the model returns the last `mem_len` hidden','line_number':999,'multiline':False]['text':' states. This is the preferred setting for training and long-form generation.','line_number':1000,'multiline':False]['text':' if `use_mems` is active and `mem_len` is defined, the model','line_number':1003,'multiline':False]['text':' create relative positional encoding.','line_number':1022,'multiline':False]['text':' beg, end = klen - 1, -qlen','line_number':1027,'multiline':False]['text':' beg, end = klen - 1, -1','line_number':1030,'multiline':False]['text':' delete after depreciation warning is removed','line_number':1080,'multiline':False]['text':' the original code for XLNet uses shapes [len, bsz] with the batch dimension at the end','line_number':1101,'multiline':False]['text':' but we want a unified interface in the library with the batch size on the first dimension','line_number':1102,'multiline':False]['text':' so we move here the first dimension (batch) to the end','line_number':1103,'multiline':False]['text':' Attention mask','line_number':1127,'multiline':False]['text':' causal attention mask','line_number':1128,'multiline':False]['text':' data mask: input mask & perm mask','line_number':1137,'multiline':False]['text':' all mems can be attended to','line_number':1152,'multiline':False]['text':' Word embeddings and prepare h & g hidden states','line_number':1172,'multiline':False]['text':' else:  # We removed the inp_q input which was same as target mapping','line_number':1180,'multiline':False]['text':'     inp_q_ext = inp_q[:, :, None]','line_number':1181,'multiline':False]['text':'     word_emb_q = inp_q_ext * self.mask_emb + (1 - inp_q_ext) * word_emb_k','line_number':1182,'multiline':False]['text':' Segment embedding','line_number':1187,'multiline':False]['text':' Convert `token_type_ids` to one-hot `seg_mat`','line_number':1189,'multiline':False]['text':' `1` indicates not in the same segment [qlen x klen x bsz]','line_number':1196,'multiline':False]['text':' Positional encoding','line_number':1202,'multiline':False]['text':' Prepare head mask if needed','line_number':1207,'multiline':False]['text':' 1.0 in head_mask indicate we keep the head','line_number':1208,'multiline':False]['text':' attention_probs has shape bsz x n_heads x N x N','line_number':1209,'multiline':False]['text':' input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)','line_number':1210,'multiline':False]['text':' and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]','line_number':1211,'multiline':False]['text':' switch to float if need + fp16 compatibility','line_number':1220,'multiline':False]['text':' cache new mems','line_number':1232,'multiline':False]['text':' Add last hidden state','line_number':1253,'multiline':False]['text':' Prepare outputs, we transpose back here to shape [bsz, len, hidden_dim] (cf. beginning of forward() method)','line_number':1259,'multiline':False]['text':' when target_mapping is provided, there are 2-tuple of attentions','line_number':1273,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1305,'multiline':False]['text':' Add dummy token at the end (no attention on this one)','line_number':1315,'multiline':False]['text':' At every pass, the attention values for the new token and the two last generated tokens','line_number':1320,'multiline':False]['text':' are computed, the rest is reloaded from the `past` cache. A purely auto-regressive model would have','line_number':1321,'multiline':False]['text':' offset = 1; offset = 2 seems to have slightly better computation.','line_number':1322,'multiline':False]['text':' Build permutation mask so that previous tokens don't see last token','line_number':1330,'multiline':False]['text':' We'll only predict the last token','line_number':1337,'multiline':False]['text':' if past is defined in model kwargs then use it for faster decoding','line_number':1350,'multiline':False]['text':' delete when `use_cache` is removed in XLNetModel','line_number':1374,'multiline':False]['text':' Flatten the tokens','line_number':1467,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1510,'multiline':False]['text':' delete when `use_cache` is removed in XLNetModel','line_number':1535,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1617,'multiline':False]['text':' delete when `use_cache` is removed in XLNetModel','line_number':1642,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1704,'multiline':False]['text':' delete when `use_cache` is removed in XLNetModel','line_number':1729,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1807,'multiline':False]['text':' delete when `use_cache` is removed in XLNetModel','line_number':1833,'multiline':False]['text':' If we are on multi-GPU, split add a dimension','line_number':1873,'multiline':False]['text':' sometimes the start/end positions are outside our model inputs, we ignore these terms','line_number':1878,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1920,'multiline':False]['text':' delete when `use_cache` is removed in XLNetModel','line_number':1945,'multiline':False]['text':' Keep mems, hidden states, attentions if there are in it','line_number':2006,'multiline':False]['text':' If we are on multi-GPU, let's remove the dimension added by batch splitting','line_number':2009,'multiline':False]['text':' during training, compute the end logits based on the ground truth of the start position','line_number':2014,'multiline':False]['text':' Predict answerability from the representation of CLS and START','line_number':2023,'multiline':False]['text':' note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss','line_number':2028,'multiline':False]['text':' during inference, compute the end logits based on beam search','line_number':2042,'multiline':False]['text':' shape (bsz, slen)','line_number':2044,'multiline':False]['text':' shape (bsz, start_n_top)','line_number':2048,'multiline':False]['text':' shape (bsz, start_n_top, hsz)','line_number':2049,'multiline':False]['text':' shape (bsz, start_n_top, hsz)','line_number':2050,'multiline':False]['text':' shape (bsz, slen, start_n_top, hsz)','line_number':2051,'multiline':False]['text':' shape (bsz, slen, start_n_top, hsz)','line_number':2055,'multiline':False]['text':' shape (bsz, slen, start_n_top)','line_number':2058,'multiline':False]['text':' shape (bsz, end_n_top, start_n_top)','line_number':2062,'multiline':False]['text':' get the representation of START as weighted sum of hidden states','line_number':2068,'multiline':False]['text':' Shape (batch size,): one single `cls_logits` for each sample','line_number':2071,'multiline':False]