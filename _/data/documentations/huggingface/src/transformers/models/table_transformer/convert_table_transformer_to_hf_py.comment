['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2022 The HuggingFace Inc. team.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' here we list all keys to be renamed (original name on the left, our name on the right)','line_number':37,'multiline':False]['text':' encoder layers: output projection, 2 feedforward neural networks and 2 layernorms','line_number':40,'multiline':False]['text':' decoder layers: 2 times output projection, 2 feedforward neural networks and 3 layernorms','line_number':57,'multiline':False]['text':' convolutional projection + query embeddings + layernorm of encoder + layernorm of decoder + class and bounding box heads','line_number':93,'multiline':False]['text':' first: transformer encoder','line_number':135,'multiline':False]['text':' read in weights + bias of input projection layer (in PyTorch's MultiHeadAttention, this is a single matrix + bias)','line_number':137,'multiline':False]['text':' next, add query, keys and values (in that order) to the state dict','line_number':140,'multiline':False]['text':' next: transformer decoder (which is a bit more complex because it also includes cross-attention)','line_number':147,'multiline':False]['text':' read in weights + bias of input projection layer of self-attention','line_number':149,'multiline':False]['text':' next, add query, keys and values (in that order) to the state dict','line_number':152,'multiline':False]['text':' read in weights + bias of input projection layer of cross-attention','line_number':159,'multiline':False]['text':' next, add query, keys and values (in that order) of cross-attention to the state dict','line_number':164,'multiline':False]['text':' load original state dict','line_number':197,'multiline':False]['text':' rename keys','line_number':199,'multiline':False]['text':' query, key and value matrices need special treatment','line_number':203,'multiline':False]['text':' important: we need to prepend a prefix to each of the base model keys as the head models use different attributes for them','line_number':205,'multiline':False]['text':' create HuggingFace model and load state dict','line_number':211,'multiline':False]['text':' verify our conversion','line_number':252,'multiline':False]['text':' Save model and image processor','line_number':280,'multiline':False]['text':' Push model to HF hub','line_number':287,'multiline':False]