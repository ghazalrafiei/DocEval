['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2023 The HuggingFace Inc. team.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' here we list all keys to be renamed (original name on the left, our name on the right)','line_number':38,'multiline':False]['text':' stem','line_number':41,'multiline':False]['text':' fmt: off','line_number':42,'multiline':False]['text':' stages','line_number':48,'multiline':False]['text':' all ResNet stages except the first one have a downsample as first layer','line_number':111,'multiline':False]['text':' "backbone.conv_encoder.model.encoder.stages.3.layers.0.shortcut.normalization.running_var"','line_number':139,'multiline':False]['text':' fmt: on','line_number':144,'multiline':False]['text':' encoder layers: output projection, 2 feedforward neural networks and 2 layernorms','line_number':147,'multiline':False]['text':' decoder layers: 2 times output projection, 2 feedforward neural networks and 3 layernorms','line_number':171,'multiline':False]['text':' convolutional projection + query embeddings + layernorm of decoder + class and bounding box heads','line_number':214,'multiline':False]['text':' first: transformer encoder','line_number':248,'multiline':False]['text':' read in weights + bias of input projection layer (in PyTorch's MultiHeadAttention, this is a single matrix + bias)','line_number':250,'multiline':False]['text':' next, add query, keys and values (in that order) to the state dict','line_number':253,'multiline':False]['text':' next: transformer decoder (which is a bit more complex because it also includes cross-attention)','line_number':260,'multiline':False]['text':' read in weights + bias of input projection layer of self-attention','line_number':262,'multiline':False]['text':' next, add query, keys and values (in that order) to the state dict','line_number':265,'multiline':False]['text':' read in weights + bias of input projection layer of cross-attention','line_number':272,'multiline':False]['text':' next, add query, keys and values (in that order) of cross-attention to the state dict','line_number':277,'multiline':False]['text':' create HuggingFace model and load state dict','line_number':310,'multiline':False]['text':' load original state dict','line_number':329,'multiline':False]['text':' rename keys','line_number':332,'multiline':False]['text':' query, key and value matrices need special treatment','line_number':335,'multiline':False]['text':' important: we need to prepend a prefix to each of the base model keys as the head models use different attributes for them','line_number':337,'multiline':False]['text':' verify our conversion','line_number':369,'multiline':False]['text':' Save model and image processor','line_number':397,'multiline':False]['text':' Push model to HF hub','line_number':404,'multiline':False]