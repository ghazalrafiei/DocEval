['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2020-present Google Brain and Carnegie Mellon University Authors and the HuggingFace Inc. team.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' B4-4-4H768','line_number':53,'multiline':False]['text':' B4-4-4H768, no decoder','line_number':54,'multiline':False]['text':' B6-3x2-3x2H768','line_number':55,'multiline':False]['text':' B6-3x2-3x2H768, no decoder','line_number':56,'multiline':False]['text':' B6-6-6H768','line_number':57,'multiline':False]['text':' B6-6-6H768, no decoder','line_number':58,'multiline':False]['text':' B8-8-8H1024','line_number':59,'multiline':False]['text':' B8-8-8H1024, no decoder','line_number':60,'multiline':False]['text':' B10-10-10H1024','line_number':61,'multiline':False]['text':' B10-10-10H1024, no decoder','line_number':62,'multiline':False]['text':' Load weights from TF model','line_number':83,'multiline':False]['text':' adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v','line_number':112,'multiline':False]['text':' which are not required for using pretrained model','line_number':113,'multiline':False]['text':' Track where we are at in terms of pooling from the original input, e.g., by how much the sequence length was','line_number':187,'multiline':False]['text':' divided.','line_number':188,'multiline':False]['text':' inputs_embeds has shape batch_size x seq_len x d_model','line_number':198,'multiline':False]['text':' attention_mask and token_type_ids have shape batch_size x seq_len','line_number':199,'multiline':False]['text':' Treat <cls> as in the same segment as both A & B','line_number':214,'multiline':False]['text':' Notations from the paper, appending A.2.2, final formula.','line_number':236,'multiline':False]['text':' We need to create and return the matrices phi, psi, pi and omega.','line_number':237,'multiline':False]['text':' This is different from the formula on the paper...','line_number':246,'multiline':False]['text':' Notations from the paper, appending A.2.1, final formula.','line_number':253,'multiline':False]['text':' We need to create and return all the possible vectors R for all blocks and shifts.','line_number':254,'multiline':False]['text':' Maximum relative positions for the first input','line_number':257,'multiline':False]['text':' For each block with block_index > 0, we need two types position embeddings:','line_number':269,'multiline':False]['text':'   - Attention(pooled-q, unpooled-kv)','line_number':270,'multiline':False]['text':'   - Attention(pooled-q, pooled-kv)','line_number':271,'multiline':False]['text':' For block_index = 0 we only need the second one and leave the first one as None.','line_number':272,'multiline':False]['text':' First type','line_number':274,'multiline':False]['text':' construct rel_pos_id','line_number':280,'multiline':False]['text':' Second type','line_number':287,'multiline':False]['text':' Under separate <cls>, we treat the <cls> as the first token in','line_number':304,'multiline':False]['text':' the previous block of the 1st real block. Since the 1st real','line_number':305,'multiline':False]['text':' block always has position 1, the position of the previous block','line_number':306,'multiline':False]['text':' will be at `1 - 2 ** block_index`.','line_number':307,'multiline':False]['text':' Do the stride pool recursively if axis is a list or a tuple of ints.','line_number':339,'multiline':False]['text':' Do the stride pool recursively if tensor is a list or tuple of tensors.','line_number':345,'multiline':False]['text':' Deal with negative axis','line_number':349,'multiline':False]['text':' Do the pool recursively if tensor is a list or tuple of tensors.','line_number':368,'multiline':False]['text':' Stride is applied on the second-to-last dimension.','line_number':381,'multiline':False]['text':' max_rel_len = 2 * context_len + shift -1 is the numbers of possible relative positions i-j','line_number':437,'multiline':False]['text':' What's next is the same as doing the following gather, which might be clearer code but less efficient.','line_number':439,'multiline':False]['text':' idxs = context_len + torch.arange(0, context_len).unsqueeze(0) - torch.arange(0, seq_len).unsqueeze(1)','line_number':440,'multiline':False]['text':' # matrix of context_len + i-j','line_number':441,'multiline':False]['text':' return positional_attn.gather(3, idxs.expand([batch_size, n_head, context_len, context_len]))','line_number':442,'multiline':False]['text':' q_head has shape batch_size x sea_len x n_head x d_head','line_number':477,'multiline':False]['text':' Notations from the paper, appending A.2.2, final formula (https://arxiv.org/abs/2006.03236)','line_number':479,'multiline':False]['text':' phi and pi have shape seq_len x d_model, psi and omega have shape context_len x d_model','line_number':480,'multiline':False]['text':' Shape n_head x d_head','line_number':482,'multiline':False]['text':' Shape d_model x n_head x d_head','line_number':484,'multiline':False]['text':' Shape batch_size x sea_len x n_head x d_model','line_number':487,'multiline':False]['text':' Shape batch_size x n_head x seq_len x context_len','line_number':492,'multiline':False]['text':' Notations from the paper, appending A.2.1, final formula (https://arxiv.org/abs/2006.03236)','line_number':498,'multiline':False]['text':' Grab the proper positional encoding, shape max_rel_len x d_model','line_number':499,'multiline':False]['text':' Shape n_head x d_head','line_number':501,'multiline':False]['text':' Shape d_model x n_head x d_head','line_number':503,'multiline':False]['text':' Shape max_rel_len x n_head x d_model','line_number':506,'multiline':False]['text':' Shape batch_size x n_head x seq_len x max_rel_len','line_number':508,'multiline':False]['text':' Shape batch_size x n_head x seq_len x context_len','line_number':510,'multiline':False]['text':' q_head has shape batch_size x seq_len x n_head x d_head','line_number':522,'multiline':False]['text':' Shape n_head x d_head','line_number':523,'multiline':False]['text':' Shape batch_size x n_head x seq_len x 2','line_number':526,'multiline':False]['text':' Shape batch_size x n_head x seq_len x context_len','line_number':528,'multiline':False]['text':' Shapes batch_size x n_head x seq_len','line_number':530,'multiline':False]['text':' Shape batch_size x n_head x seq_len x context_len','line_number':532,'multiline':False]['text':' query has shape batch_size x seq_len x d_model','line_number':549,'multiline':False]['text':' key and value have shapes batch_size x context_len x d_model','line_number':550,'multiline':False]['text':' Shape batch_size x seq_len x n_head x d_head','line_number':557,'multiline':False]['text':' Shapes batch_size x context_len x n_head x d_head','line_number':559,'multiline':False]['text':' Shape n_head x d_head','line_number':564,'multiline':False]['text':' Shapes batch_size x n_head x seq_len x context_len','line_number':566,'multiline':False]['text':' merge attention scores','line_number':571,'multiline':False]['text':' precision safe in case of mixed precision training','line_number':574,'multiline':False]['text':' perform masking','line_number':577,'multiline':False]['text':' attention probability','line_number':580,'multiline':False]['text':' attention output, shape batch_size x seq_len x n_head x d_head','line_number':584,'multiline':False]['text':' Shape shape batch_size x seq_len x d_model','line_number':587,'multiline':False]['text':' The pooling is not implemented on long tensors, so we convert this mask.','line_number':654,'multiline':False]['text':' Initialize weights and apply final processing','line_number':933,'multiline':False]['text':' TODO: deal with head_mask','line_number':983,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1011,'multiline':False]['text':' TODO: deal with head_mask','line_number':1059,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1117,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1203,'multiline':False]['text':' -100 index = padding token','line_number':1253,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1283,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1373,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1459,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1531,'multiline':False]['text':' If we are on multi-GPU, split add a dimension','line_number':1583,'multiline':False]['text':' sometimes the start/end positions are outside our model inputs, we ignore these terms','line_number':1588,'multiline':False]