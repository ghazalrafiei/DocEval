['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2022 SenseTime and The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' See all DETA models at https://huggingface.co/models?filter=deta','line_number':65,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrDecoderOutput with DeformableDetr->Deta','line_number':70,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModelOutput with DeformableDetr->Deta,Deformable DETR->DETA','line_number':108,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrObjectDetectionOutput with DeformableDetr->Deta','line_number':167,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrFrozenBatchNorm2d with Detr->Deta','line_number':258,'multiline':False]['text':' move reshapes to the beginning','line_number':286,'multiline':False]['text':' to make it user-friendly','line_number':287,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.replace_batch_norm with Detr->Deta','line_number':298,'multiline':False]['text':' TODO fix this','line_number':339,'multiline':False]['text':' first, send pixel_values through the backbone to get list of feature maps','line_number':352,'multiline':False]['text':' next, create position embeddings','line_number':355,'multiline':False]['text':' downsample pixel_mask to match shape of corresponding feature_map','line_number':359,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrSinePositionEmbedding with DeformableDetr->Deta','line_number':368,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrLearnedPositionEmbedding','line_number':407,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.build_position_encoding with Detr->Deta','line_number':431,'multiline':False]['text':' TODO find a better way of exposing other arguments','line_number':435,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.multi_scale_deformable_attention','line_number':445,'multiline':False]['text':' batch_size, height*width, num_heads, hidden_dim','line_number':455,'multiline':False]['text':' -> batch_size, height*width, num_heads*hidden_dim','line_number':456,'multiline':False]['text':' -> batch_size, num_heads*hidden_dim, height*width','line_number':457,'multiline':False]['text':' -> batch_size*num_heads, hidden_dim, height, width','line_number':458,'multiline':False]['text':' batch_size, num_queries, num_heads, num_points, 2','line_number':462,'multiline':False]['text':' -> batch_size, num_heads, num_queries, num_points, 2','line_number':463,'multiline':False]['text':' -> batch_size*num_heads, num_queries, num_points, 2','line_number':464,'multiline':False]['text':' batch_size*num_heads, hidden_dim, num_queries, num_points','line_number':466,'multiline':False]['text':' (batch_size, num_queries, num_heads, num_levels, num_points)','line_number':471,'multiline':False]['text':' -> (batch_size, num_heads, num_queries, num_levels, num_points)','line_number':472,'multiline':False]['text':' -> (batch_size, num_heads, 1, num_queries, num_levels*num_points)','line_number':473,'multiline':False]['text':' check if dim_per_head is power of 2','line_number':497,'multiline':False]['text':' add position embeddings to the hidden states before projecting to queries and keys','line_number':554,'multiline':False]['text':' we invert the attention_mask','line_number':567,'multiline':False]['text':' batch_size, num_queries, n_heads, n_levels, n_points, 2','line_number':579,'multiline':False]['text':' PyTorch implementation (for now)','line_number':593,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrMultiheadAttention with DeformableDetr->Deta,Deformable DETR->DETA','line_number':600,'multiline':False]['text':' add position embeddings to the hidden states before projecting to queries and keys','line_number':648,'multiline':False]['text':' get queries, keys and values','line_number':653,'multiline':False]['text':' expand attention_mask','line_number':673,'multiline':False]['text':' [batch_size, seq_len] -> [batch_size, 1, target_seq_len, source_seq_len]','line_number':675,'multiline':False]['text':' this operation is a bit awkward, but it's required to','line_number':690,'multiline':False]['text':' make sure that attn_weights keeps its gradient.','line_number':691,'multiline':False]['text':' In order to do so, attn_weights have to reshaped','line_number':692,'multiline':False]['text':' twice and have to be reused in the following','line_number':693,'multiline':False]['text':' Apply Multi-scale Deformable Attention Module on the multi-scale feature maps.','line_number':766,'multiline':False]['text':' self-attention','line_number':811,'multiline':False]['text':' cross-attention','line_number':822,'multiline':False]['text':' feedforward neural networks','line_number':830,'multiline':False]['text':' Self Attention','line_number':869,'multiline':False]['text':' Cross-Attention','line_number':882,'multiline':False]['text':' Fully Connected','line_number':901,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrClassificationHead','line_number':918,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrPreTrainedModel with DeformableDetrConvEncoder->DetaBackboneWithPositionalEncodings,DeformableDetr->Deta','line_number':937,'multiline':False]['text':' Slightly different from the TF version which uses truncated_normal for initialization','line_number':953,'multiline':False]['text':' cf https://github.com/pytorch/pytorch/pull/5617','line_number':954,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrEncoder with DeformableDetr->Deta','line_number':1023,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1041,'multiline':False]['text':' TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36','line_number':1066,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrDecoder with DeformableDetr->Deta,Deformable DETR->DETA','line_number':1154,'multiline':False]['text':' hack implementation for iterative bounding box refinement and two-stage Deformable DETR','line_number':1177,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1181,'multiline':False]['text':' decoder layers','line_number':1239,'multiline':False]['text':' hack implementation for iterative bounding box refinement','line_number':1281,'multiline':False]['text':' Keep batch_size as first dimension','line_number':1306,'multiline':False]['text':' add hidden states from the last decoder layer','line_number':1310,'multiline':False]['text':' Create backbone with positional encoding','line_number':1351,'multiline':False]['text':' Create input projection layers','line_number':1355,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModel.get_encoder','line_number':1409,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModel.get_decoder','line_number':1413,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModel.get_valid_ratio','line_number':1425,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrModel.get_proposal_pos_embed','line_number':1437,'multiline':False]['text':' batch_size, num_queries, 4','line_number':1447,'multiline':False]['text':' batch_size, num_queries, 4, 128','line_number':1449,'multiline':False]['text':' batch_size, num_queries, 4, 64, 2 -> batch_size, num_queries, 512','line_number':1451,'multiline':False]['text':' inverse sigmoid','line_number':1495,'multiline':False]['text':' assign each pixel as an object query','line_number':1499,'multiline':False]['text':' Extract multi-scale feature maps of same resolution `config.d_model` (cf Figure 4 in paper)','line_number':1557,'multiline':False]['text':' First, sent pixel_values + pixel_mask through Backbone to obtain the features','line_number':1558,'multiline':False]['text':' which is a list of tuples','line_number':1559,'multiline':False]['text':' Then, apply 1x1 convolution to reduce the channel dimension to d_model (256 by default)','line_number':1562,'multiline':False]['text':' Lowest resolution feature maps are obtained via 3x3 stride 2 convolutions on the final stage','line_number':1571,'multiline':False]['text':' Create queries','line_number':1585,'multiline':False]['text':' Prepare encoder inputs (by flattening)','line_number':1590,'multiline':False]['text':' Fourth, sent source_flatten + mask_flatten + lvl_pos_embed_flatten (backbone + proj layer output) through encoder','line_number':1609,'multiline':False]['text':' Also provide spatial_shapes, level_start_index and valid_ratios','line_number':1610,'multiline':False]['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':1623,'multiline':False]['text':' Fifth, prepare decoder inputs','line_number':1631,'multiline':False]['text':' hack implementation for two-stage DETA','line_number':1640,'multiline':False]['text':' apply a detection head to each pixel (A.4 in paper)','line_number':1641,'multiline':False]['text':' linear projection for bounding box binary classification (i.e. foreground and background)','line_number':1642,'multiline':False]['text':' 3-layer FFN to predict bounding boxes coordinates (bbox regression branch)','line_number':1644,'multiline':False]['text':' only keep top scoring `config.two_stage_num_proposals` proposals','line_number':1648,'multiline':False]['text':' pre-nms per-level topk','line_number':1659,'multiline':False]['text':' nms on topk indices','line_number':1667,'multiline':False]['text':' keep top Q/L indices for L levels','line_number':1680,'multiline':False]['text':' LS','line_number':1686,'multiline':False]['text':' S','line_number':1687,'multiline':False]['text':' pad to Q indices (might let ones filtered from pre-nms sneak by... unlikely because we pick high conf anyways)','line_number':1689,'multiline':False]['text':' When using clones, all layers > 0 will be clones, but layer 0 *is* required','line_number':1760,'multiline':False]['text':' We can't initialize the model on meta device as some weights are modified during the initialization','line_number':1762,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrForObjectDetection.__init__ with DeformableDetr->Deta','line_number':1765,'multiline':False]['text':' Deformable DETR encoder-decoder model','line_number':1769,'multiline':False]['text':' Detection heads on top','line_number':1772,'multiline':False]['text':' if two-stage, the last class_embed and bbox_embed is for region proposal generation','line_number':1784,'multiline':False]['text':' hack implementation for iterative bounding box refinement','line_number':1790,'multiline':False]['text':' hack implementation for two-stage','line_number':1798,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1803,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrForObjectDetection._set_aux_loss','line_number':1807,'multiline':False]['text':' this is a workaround to make torchscript happy, as torchscript','line_number':1809,'multiline':False]['text':' doesn't support dictionary with non-homogeneous values, such','line_number':1810,'multiline':False]['text':' as a dict having both a Tensor and a list.','line_number':1811,'multiline':False]['text':' First, sent images through DETR base model to obtain encoder + decoder outputs','line_number':1872,'multiline':False]['text':' class logits + predicted bounding boxes','line_number':1889,'multiline':False]['text':' Keep batch_size as first dimension','line_number':1911,'multiline':False]['text':' First: create the matcher','line_number':1920,'multiline':False]['text':' Second: create the criterion','line_number':1924,'multiline':False]['text':' Third: compute the losses, based on outputs and labels','line_number':1934,'multiline':False]['text':' Fourth: compute total loss, as a weighted sum of the various losses','line_number':1949,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.dice_loss','line_number':1991,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.sigmoid_focal_loss','line_number':2011,'multiline':False]['text':' add modulating factor','line_number':2032,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss.loss_labels','line_number':2083,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss.loss_cardinality','line_number':2118,'multiline':False]['text':' Count the number of predictions that are NOT "no-object" (which is the last class)','line_number':2128,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss.loss_boxes','line_number':2134,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss._get_source_permutation_idx','line_number':2159,'multiline':False]['text':' permute predictions following indices','line_number':2161,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss._get_target_permutation_idx','line_number':2166,'multiline':False]['text':' permute targets following indices','line_number':2168,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrLoss.get_loss','line_number':2173,'multiline':False]['text':' Retrieve the matching between the outputs of the last layer and the targets','line_number':2197,'multiline':False]['text':' Compute the average number of target boxes accross all nodes, for normalization purposes','line_number':2203,'multiline':False]['text':' (Niels): comment out function below, distributed training to be added','line_number':2206,'multiline':False]['text':' if is_dist_avail_and_initialized():','line_number':2207,'multiline':False]['text':'     torch.distributed.all_reduce(num_boxes)','line_number':2208,'multiline':False]['text':' (Niels) in original implementation, num_boxes is divided by get_world_size()','line_number':2209,'multiline':False]['text':' Compute all the requested losses','line_number':2212,'multiline':False]['text':' In case of auxiliary losses, we repeat this process with the output of each intermediate layer.','line_number':2217,'multiline':False]['text':' Logging is enabled only for the last layer','line_number':2239,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrMLPPredictionHead','line_number':2248,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.DeformableDetrHungarianMatcher with DeformableDetr->Deta','line_number':2270,'multiline':False]['text':' We flatten to compute the cost matrices in a batch','line_number':2321,'multiline':False]['text':' [batch_size * num_queries, num_classes]','line_number':2322,'multiline':False]['text':' [batch_size * num_queries, 4]','line_number':2323,'multiline':False]['text':' Also concat the target labels and boxes','line_number':2325,'multiline':False]['text':' Compute the classification cost.','line_number':2329,'multiline':False]['text':' Compute the L1 cost between boxes','line_number':2336,'multiline':False]['text':' Compute the giou cost between boxes','line_number':2339,'multiline':False]['text':' Final cost matrix','line_number':2342,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr._upcast','line_number':2351,'multiline':False]['text':' Protects from numerical overflows in multiplications by upcasting to the equivalent higher type','line_number':2353,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.box_area','line_number':2360,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.box_iou','line_number':2377,'multiline':False]['text':' [N,M,2]','line_number':2382,'multiline':False]['text':' [N,M,2]','line_number':2383,'multiline':False]['text':' [N,M,2]','line_number':2385,'multiline':False]['text':' [N,M]','line_number':2386,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.generalized_box_iou','line_number':2394,'multiline':False]['text':' degenerate boxes gives inf / nan results','line_number':2402,'multiline':False]['text':' so do an early check','line_number':2403,'multiline':False]['text':' [N,M,2]','line_number':2413,'multiline':False]['text':' from https://github.com/facebookresearch/detectron2/blob/cbbc1ce26473cb2a5cc8f58e8ada9ae14cb41052/detectron2/layers/wrappers.py#L100','line_number':2419,'multiline':False]['text':' from https://github.com/facebookresearch/detectron2/blob/9921a2caa585d4fa66c4b534b6fab6e74d89b582/detectron2/modeling/matcher.py#L9','line_number':2433,'multiline':False]['text':' Add -inf and +inf to first and last position in thresholds','line_number':2465,'multiline':False]['text':' Currently torchscript does not support all + generator','line_number':2471,'multiline':False]['text':' When no gt boxes exist, we define IOU = 0 and therefore set labels','line_number':2498,'multiline':False]['text':' to `self.labels[0]`, which usually defaults to background class 0','line_number':2499,'multiline':False]['text':' To choose to ignore instead, can make labels=[-1,0,-1,1] + set appropriate thresholds','line_number':2500,'multiline':False]['text':' match_quality_matrix is M (gt) x N (predicted)','line_number':2508,'multiline':False]['text':' Max over gt elements (dim 0) to find best gt candidate for each prediction','line_number':2509,'multiline':False]['text':' For each gt, find the prediction with which it has highest quality','line_number':2531,'multiline':False]['text':' Find the highest quality match available, even if it is low, including ties.','line_number':2533,'multiline':False]['text':' Note that the matches qualities must be positive due to the use of','line_number':2534,'multiline':False]['text':' `torch.nonzero`.','line_number':2535,'multiline':False]['text':' If an anchor was labeled positive only due to a low-quality match','line_number':2537,'multiline':False]['text':' with gt_A, but it has larger overlap with gt_B, it's matched index will still be gt_B.','line_number':2538,'multiline':False]['text':' This follows the implementation in Detectron, and is found to have no significant impact.','line_number':2539,'multiline':False]['text':' from https://github.com/facebookresearch/detectron2/blob/cbbc1ce26473cb2a5cc8f58e8ada9ae14cb41052/detectron2/modeling/sampling.py#L9','line_number':2543,'multiline':False]['text':' protect against not enough positive examples','line_number':2572,'multiline':False]['text':' protect against not enough negative examples','line_number':2575,'multiline':False]['text':' randomly select positive and negative examples','line_number':2578,'multiline':False]['text':' find topk matches for each gt','line_number':2590,'multiline':False]['text':' filter to as many matches that gt has','line_number':2595,'multiline':False]['text':' modified from https://github.com/facebookresearch/detectron2/blob/cbbc1ce26473cb2a5cc8f58e8ada9ae14cb41052/detectron2/modeling/roi_heads/roi_heads.py#L123','line_number':2601,'multiline':False]['text':' number > 91 to filter out later','line_number':2606,'multiline':False]['text':' Get the corresponding GT for each proposal','line_number':2630,'multiline':False]['text':' Label unmatched proposals (0 label from matcher) as background (label=num_classes)','line_number':2633,'multiline':False]['text':' Label ignore proposals (-1 label)','line_number':2635,'multiline':False]['text':' COCO categories are from 1 to 90. They set num_classes=91 and apply sigmoid.','line_number':2648,'multiline':False]['text':' proposal_id -> highest_iou_gt_id, proposal_id -> [1 if iou > 0.6, 0 ow]','line_number':2660,'multiline':False]['text':' list of sampled proposal_ids, sampled_id -> [0, num_classes)+[bg_label]','line_number':2664,'multiline':False]['text':' modified from https://github.com/facebookresearch/detectron2/blob/cbbc1ce26473cb2a5cc8f58e8ada9ae14cb41052/detectron2/modeling/proposal_generator/rpn.py#L181','line_number':2680,'multiline':False]['text':' Fill with the ignore label (-1), then set positive and negative labels','line_number':2702,'multiline':False]['text':' proposal_id -> highest_iou_gt_id, proposal_id -> [1 if iou > 0.7, 0 if iou < 0.3, -1 ow]','line_number':2727,'multiline':False]