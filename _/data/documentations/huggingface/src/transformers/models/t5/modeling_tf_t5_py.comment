['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2020 T5 Authors and The HuggingFace Inc. team.','line_number':2,'multiline':False]['text':' Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.','line_number':3,'multiline':False]['text':'','line_number':4,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':5,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':6,'multiline':False]['text':' You may obtain a copy of the License at','line_number':7,'multiline':False]['text':'','line_number':8,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':9,'multiline':False]['text':'','line_number':10,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':11,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':12,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':13,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':14,'multiline':False]['text':' limitations under the License.','line_number':15,'multiline':False]['text':' See all T5 models at https://huggingface.co/models?filter=t5','line_number':66,'multiline':False]['text':'###################################################','line_number':69,'multiline':False]['text':' TF 2.0 Models are constructed using Keras imperative API by sub-classing','line_number':70,'multiline':False]['text':' - tf.keras.layers.Layer for the layers and','line_number':71,'multiline':False]['text':' - TFPreTrainedModel for the models (it-self a sub-class of tf.keras.Model)','line_number':72,'multiline':False]['text':'###################################################','line_number':73,'multiline':False]['text':' Update init weights as in flax','line_number':107,'multiline':False]['text':' Update init weights as in flax','line_number':110,'multiline':False]['text':' Update init weights as in flax','line_number':145,'multiline':False]['text':' Update init weights as in flax','line_number':148,'multiline':False]['text':' Update init weights as in flax','line_number':151,'multiline':False]['text':' Mesh TensorFlow initialization to avoid scaling before softmax','line_number':226,'multiline':False]['text':' Update init weights as in flax','line_number':245,'multiline':False]['text':' Update init weights as in flax','line_number':248,'multiline':False]['text':' Update init weights as in flax','line_number':251,'multiline':False]['text':' Update init weights as in flax','line_number':254,'multiline':False]['text':' Add initializer','line_number':268,'multiline':False]['text':'        n = -relative_position','line_number':309,'multiline':False]['text':' now n is in the range [0, inf)','line_number':318,'multiline':False]['text':' shape (query_length, key_length)','line_number':335,'multiline':False]['text':' shape (query_length, key_length, num_heads)','line_number':344,'multiline':False]['text':' shape (1, num_heads, query_length, key_length)','line_number':347,'multiline':False]['text':' Input is (batch_size, query_length, dim)','line_number':366,'multiline':False]['text':' Mask is (batch_size, key_length) (non-causal) or (batch_size, key_length, key_length)','line_number':367,'multiline':False]['text':' past_key_value[0] is (batch_size, n_heads, q_len - 1, dim_per_head)','line_number':368,'multiline':False]['text':' self-attn','line_number':394,'multiline':False]['text':' (batch_size, n_heads, seq_length, dim_per_head)','line_number':395,'multiline':False]['text':' cross-attn','line_number':398,'multiline':False]['text':' (batch_size, n_heads, seq_length, dim_per_head)','line_number':399,'multiline':False]['text':' self-attn','line_number':404,'multiline':False]['text':' (batch_size, n_heads, key_length, dim_per_head)','line_number':405,'multiline':False]['text':' cross-attn','line_number':408,'multiline':False]['text':' get query','line_number':412,'multiline':False]['text':' (batch_size, n_heads, query_length, dim_per_head)','line_number':413,'multiline':False]['text':' get key/value','line_number':415,'multiline':False]['text':' to cope with keras serialization','line_number':423,'multiline':False]['text':' (batch_size, n_heads, query_length, key_length)','line_number':431,'multiline':False]['text':' if key and values are already calculated we want only the last query position bias','line_number':439,'multiline':False]['text':' we might have a padded past structure, in which case we want to fetch the position bias slice','line_number':444,'multiline':False]['text':' right after the most recently filled past index','line_number':445,'multiline':False]['text':' (batch_size, n_heads, query_length, key_length)','line_number':455,'multiline':False]['text':' (batch_size, n_heads, query_length, key_length)','line_number':458,'multiline':False]['text':' (batch_size, n_heads, query_length, key_length)','line_number':459,'multiline':False]['text':' Mask heads if we want to','line_number':461,'multiline':False]['text':' (batch_size, n_heads, query_length, dim_per_head)','line_number':473,'multiline':False]['text':' add attentions if we output them','line_number':519,'multiline':False]['text':' add attentions if we output them','line_number':572,'multiline':False]['text':' Keep self-attention outputs and relative position weights','line_number':651,'multiline':False]['text':' the actual query length is unknown for cross attention','line_number':654,'multiline':False]['text':' if using past key value states. Need to inject it here','line_number':655,'multiline':False]['text':' Combine self attn and cross attn key value states','line_number':674,'multiline':False]['text':' Keep cross-attention outputs and relative position weights','line_number':678,'multiline':False]['text':' Apply Feed Forward layer','line_number':681,'multiline':False]['text':' Add attentions if we output them','line_number':685,'multiline':False]['text':' hidden-states, present_key_value_states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)','line_number':687,'multiline':False]['text':'###################################################','line_number':699,'multiline':False]['text':' The full model without a specific pretrained or finetuning head is','line_number':700,'multiline':False]['text':' provided as a tf.keras.layers.Layer usually called "TFT5MainLayer"','line_number':701,'multiline':False]['text':'###################################################','line_number':702,'multiline':False]['text':' Not implemented yet in the library fr TF 2.0 models','line_number':731,'multiline':False]['text':' required mask seq length can be calculated via length of past','line_number':771,'multiline':False]['text':' initialize past_key_values with `None` if past does not exist','line_number':782,'multiline':False]['text':' We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]','line_number':786,'multiline':False]['text':' ourselves in which case we just need to make it broadcastable to all heads.','line_number':787,'multiline':False]['text':' Provided a padding mask of dimensions [batch_size, mask_seq_length]','line_number':793,'multiline':False]['text':' - if the model is a decoder, apply a causal mask in addition to the padding mask','line_number':794,'multiline':False]['text':' - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, mask_seq_length, mask_seq_length]','line_number':795,'multiline':False]['text':' Since attention_mask is 1.0 for positions we want to attend and 0.0 for','line_number':809,'multiline':False]['text':' masked positions, this operation will create a tensor which is 0.0 for','line_number':810,'multiline':False]['text':' positions we want to attend and  -1e9 for masked positions.','line_number':811,'multiline':False]['text':' Since we are adding it to the raw scores before the softmax, this is','line_number':812,'multiline':False]['text':' effectively the same as removing these entirely.','line_number':813,'multiline':False]['text':' T5 has a mask that can compare sequence ids, we can simulate this here with this transposition','line_number':815,'multiline':False]['text':' Cf. https://github.com/tensorflow/mesh/blob/8d2465e9bc93129b913b5ccc6a59aa97abd96ec6/mesh_tensorflow/transformer/transformer_layers.py#L270','line_number':816,'multiline':False]['text':' extended_attention_mask = tf.math.equal(extended_attention_mask,','line_number':817,'multiline':False]['text':'                                         tf.transpose(extended_attention_mask, perm=(-1, -2)))','line_number':818,'multiline':False]['text':' If a 2D ou 3D attention mask is provided for the cross-attention','line_number':823,'multiline':False]['text':' we need to make broadcastable to [batch_size, num_heads, mask_seq_length, mask_seq_length]','line_number':824,'multiline':False]['text':' we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]','line_number':825,'multiline':False]['text':' T5 has a mask that can compare sequence ids, we can simulate this here with this transposition','line_number':833,'multiline':False]['text':' Cf. https://github.com/tensorflow/mesh/blob/8d2465e9bc93129b913b5ccc6a59aa97abd96ec6/mesh_tensorflow/transformer/transformer_layers.py#L270','line_number':834,'multiline':False]['text':' encoder_extended_attention_mask = tf.math.equal(encoder_extended_attention_mask,','line_number':835,'multiline':False]['text':'                                         tf.transpose(encoder_extended_attention_mask, perm=(-1, -2)))','line_number':836,'multiline':False]['text':' layer_outputs is a tuple with:','line_number':869,'multiline':False]['text':' hidden-states, key-value-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)','line_number':870,'multiline':False]['text':' We share the position biases between the layers - the first layer store them','line_number':873,'multiline':False]['text':' layer_outputs = hidden-states, past_key_values, (self-attention weights),','line_number':874,'multiline':False]['text':' (self-attention position bias), (cross-attention position bias), (cross-attention weights),','line_number':875,'multiline':False]['text':' append next layer key value states','line_number':881,'multiline':False]['text':' Add last layer','line_number':893,'multiline':False]['text':' need to check if is decoder here as well for special cases when using keras compile','line_number':899,'multiline':False]['text':' last-layer hidden state, (past_key_values), (all hidden states), (all attentions), (all_cross_attentions)','line_number':908,'multiline':False]['text':'###################################################','line_number':938,'multiline':False]['text':' TFT5PreTrainedModel is a sub-class of tf.keras.Model','line_number':939,'multiline':False]['text':' which take care of loading and saving pretrained weights','line_number':940,'multiline':False]['text':' and various common utilities.','line_number':941,'multiline':False]['text':' Here you just need to specify a few (self-explanatory)','line_number':942,'multiline':False]['text':' pointers for your model.','line_number':943,'multiline':False]['text':'###################################################','line_number':944,'multiline':False]['text':' names with a '.' represents the authorized unexpected/missing layers when a TF model is loaded from a PT model','line_number':953,'multiline':False]['text':' Ensure compatible dtypes for concatenation','line_number':975,'multiline':False]['text':' replace possible -100 values in labels by `pad_token_id`','line_number':979,'multiline':False]['text':' "Verify that `labels` has only positive values and -100"','line_number':986,'multiline':False]['text':' Make sure the assertion op is called by wrapping the result in an identity no-op','line_number':991,'multiline':False]['text':' Additional attribute to specify the expected name scope of the layer (for loading/storing weights)','line_number':1191,'multiline':False]['text':' FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask','line_number':1254,'multiline':False]['text':' Encode if needed (training, first prediction pass)','line_number':1259,'multiline':False]['text':' Decode','line_number':1278,'multiline':False]['text':' The shared/tied weights expect to be in the model base namespace','line_number':1316,'multiline':False]['text':' Adding "/" to the end (not the start!) of a tf.name_scope puts it in the root namespace rather than','line_number':1317,'multiline':False]['text':' the current one.','line_number':1318,'multiline':False]['text':' Additional attribute to specify the expected name scope of the layer (for loading/storing weights)','line_number':1340,'multiline':False]['text':' Update init weights as in flax','line_number':1356,'multiline':False]['text':' in a dense layer the kernel has a shape (last_dim, units), for us (dim, num_tokens)','line_number':1363,'multiline':False]['text':' value has a shape (num_tokens, dim) then needs to be transposed','line_number':1364,'multiline':False]['text':' Update init weights as in flax','line_number':1374,'multiline':False]['text':' in a dense layer the kernel has a shape (last_dim, units), for us (dim, num_tokens)','line_number':1375,'multiline':False]['text':' value has a shape (num_tokens, dim) then needs to be transposed','line_number':1376,'multiline':False]['text':' FutureWarning: head_mask was separated into two input args - head_mask, decoder_head_mask','line_number':1438,'multiline':False]['text':' Encode if needed (training, first prediction pass)','line_number':1443,'multiline':False]['text':' get decoder inputs from shifting lm labels to the right','line_number':1459,'multiline':False]['text':' Decode','line_number':1462,'multiline':False]['text':' T5v1.1 does not tie output word embeddings and thus does not require downscaling','line_number':1480,'multiline':False]['text':' If the user passed a tuple for encoder_outputs, we wrap it in a TFBaseModelOutput when return_dict=True','line_number':1498,'multiline':False]['text':' cut decoder_input_ids if past is used','line_number':1560,'multiline':False]['text':' needs to be passed to make Keras.layer.__call__ happy','line_number':1565,'multiline':False]['text':' The shared/tied weights expect to be in the model base namespace','line_number':1583,'multiline':False]['text':' Adding "/" to the end (not the start!) of a tf.name_scope puts it in the root namespace rather than','line_number':1584,'multiline':False]['text':' the current one.','line_number':1585,'multiline':False]['text':' Additional attribute to specify the expected name scope of the layer (for loading/storing weights)','line_number':1612,'multiline':False]['text':' The shared/tied weights expect to be in the model base namespace','line_number':1681,'multiline':False]['text':' Adding "/" to the end (not the start!) of a tf.name_scope puts it in the root namespace rather than','line_number':1682,'multiline':False]['text':' the current one.','line_number':1683,'multiline':False]