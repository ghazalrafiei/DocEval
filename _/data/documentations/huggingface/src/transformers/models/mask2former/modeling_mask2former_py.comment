['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2022 Meta Platforms, Inc. and The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' See all mask2former models at https://huggingface.co/models?filter=mask2former','line_number':54,'multiline':False]['text':' Adapted from https://github.com/facebookresearch/detectron2/blob/main/projects/PointRend/point_rend/point_features.py','line_number':248,'multiline':False]['text':' use nn.function.grid_sample to get features for points in `point_coordinates` via bilinear interpolation','line_number':273,'multiline':False]['text':' Copied from transformers.models.maskformer.modeling_maskformer.dice_loss','line_number':281,'multiline':False]['text':' Copied from transformers.models.maskformer.modeling_maskformer.pair_wise_dice_loss','line_number':331,'multiline':False]['text':' using broadcasting to get a [num_queries, NUM_CLASSES] matrix','line_number':348,'multiline':False]['text':' Adapted from https://github.com/facebookresearch/Mask2Former/blob/main/mask2former/modeling/matcher.py','line_number':382,'multiline':False]['text':' iterate through batch size','line_number':447,'multiline':False]['text':' Compute the classification cost. Contrary to the loss, we don't use the NLL, but approximate it in 1 - proba[target class]. The 1 is a constant that doesn't change the matching, it can be ommitted.','line_number':453,'multiline':False]['text':' Sample ground truth and predicted masks','line_number':459,'multiline':False]['text':' compute the cross entropy loss between each mask pairs -> shape (num_queries, num_labels)','line_number':468,'multiline':False]['text':' Compute the dice loss betwen each mask pairs -> shape (num_queries, num_labels)','line_number':470,'multiline':False]['text':' final cost matrix','line_number':472,'multiline':False]['text':' eliminate infinite values in cost_matrix to avoid the error ``ValueError: cost matrix is infeasible``','line_number':474,'multiline':False]['text':' do the assigmented using the hungarian algorithm in scipy','line_number':477,'multiline':False]['text':' It could be stacked in one tensor','line_number':481,'multiline':False]['text':' Adapted from https://github.com/facebookresearch/Mask2Former/blob/main/mask2former/modeling/criterion.py','line_number':488,'multiline':False]['text':' Weight to apply to the null class','line_number':507,'multiline':False]['text':' pointwise mask loss parameters','line_number':513,'multiline':False]['text':' Adapted from nested_tensor_from_tensor_list() in original implementation','line_number':532,'multiline':False]['text':' get the maximum size in the batch','line_number':534,'multiline':False]['text':' compute final size','line_number':536,'multiline':False]['text':' pad the tensors to the size of the biggest one','line_number':543,'multiline':False]['text':' shape of (batch_size, num_queries)','line_number':570,'multiline':False]['text':' shape of (batch_size, num_queries)','line_number':573,'multiline':False]['text':' Permute target_classes (batch_size, num_queries, num_labels) -> (batch_size, num_labels, num_queries)','line_number':578,'multiline':False]['text':' shape (batch_size * num_queries, height, width)','line_number':612,'multiline':False]['text':' shape (batch_size, num_queries, height, width)','line_number':614,'multiline':False]['text':' pad all and stack the targets to the num_labels dimension','line_number':615,'multiline':False]['text':' No need to upsample predictions as we are using normalized coordinates','line_number':619,'multiline':False]['text':' Sample point coordinates','line_number':623,'multiline':False]['text':' Permute predictions following indices','line_number':647,'multiline':False]['text':' Permute labels following indices','line_number':653,'multiline':False]['text':' Get random point coordinates','line_number':708,'multiline':False]['text':' Get sampled prediction value for the point coordinates','line_number':710,'multiline':False]['text':' Calculate the uncertainties based on the sampled prediction values of the points','line_number':712,'multiline':False]['text':' retrieve the matching between the outputs of the last layer and the labels','line_number':765,'multiline':False]['text':' compute the average number of target masks for normalization purposes','line_number':767,'multiline':False]['text':' get all the losses','line_number':769,'multiline':False]['text':' in case of auxiliary losses, we repeat this process with the output of each intermediate layer.','line_number':774,'multiline':False]['text':' Copied from transformers.models.deformable_detr.modeling_deformable_detr.multi_scale_deformable_attention','line_number':794,'multiline':False]['text':' batch_size, height*width, num_heads, hidden_dim','line_number':804,'multiline':False]['text':' -> batch_size, height*width, num_heads*hidden_dim','line_number':805,'multiline':False]['text':' -> batch_size, num_heads*hidden_dim, height*width','line_number':806,'multiline':False]['text':' -> batch_size*num_heads, hidden_dim, height, width','line_number':807,'multiline':False]['text':' batch_size, num_queries, num_heads, num_points, 2','line_number':811,'multiline':False]['text':' -> batch_size, num_heads, num_queries, num_points, 2','line_number':812,'multiline':False]['text':' -> batch_size*num_heads, num_queries, num_points, 2','line_number':813,'multiline':False]['text':' batch_size*num_heads, hidden_dim, num_queries, num_points','line_number':815,'multiline':False]['text':' (batch_size, num_queries, num_heads, num_levels, num_points)','line_number':820,'multiline':False]['text':' -> (batch_size, num_heads, num_queries, num_levels, num_points)','line_number':821,'multiline':False]['text':' -> (batch_size, num_heads, 1, num_queries, num_levels*num_points)','line_number':822,'multiline':False]['text':' Copied from transformers.models.maskformer.modeling_maskformer.MaskFormerSinePositionEmbedding with MaskFormer->Mask2Former','line_number':834,'multiline':False]['text':' Modified from transformers.models.detr.modeling_deformable_detr.DeformableDetrMultiscaleDeformableAttention','line_number':874,'multiline':False]['text':' check if dim_per_head is power of 2','line_number':887,'multiline':False]['text':' add position embeddings to the hidden states before projecting to queries and keys','line_number':922,'multiline':False]['text':' we invert the attention_mask','line_number':935,'multiline':False]['text':' batch_size, num_queries, n_heads, n_levels, n_points, 2','line_number':947,'multiline':False]['text':' Apply Multi-scale Deformable Attention Module on the multi-scale feature maps.','line_number':1017,'multiline':False]['text':' Modified from from transformers.models.detr.modeling_deformable_detr.DeformableDetrEncoder with DeformableDetrEncoder->Mask2FormerPixelDecoderEncoderOnly','line_number':1057,'multiline':False]['text':' Modified from from transformers.models.detr.modeling_deformable_detr.DeformableDetrModel with DeformableDetrModel->Mask2FormerPixelDecoder','line_number':1186,'multiline':False]['text':' Create input projection layers','line_number':1205,'multiline':False]['text':' Extra FPN levels','line_number':1229,'multiline':False]['text':' Order convolutional layers from low to high resolution','line_number':1254,'multiline':False]['text':' Apply 1x1 convolution to reduce the channel dimension to d_model (256 by default)','line_number':1282,'multiline':False]['text':' Prepare encoder inputs (by flattening)','line_number':1293,'multiline':False]['text':' Send input_embeds_flat + masks_flat + level_pos_embed_flat (backbone + proj layer output) through encoder','line_number':1306,'multiline':False]['text':' Compute final features','line_number':1332,'multiline':False]['text':' Append extra FPN levels to outputs, ordered from low to high resolution','line_number':1338,'multiline':False]['text':' Following FPN implementation, we use nearest upsampling here','line_number':1344,'multiline':False]['text':' Modified from transformers.models.detr.modeling_detr.DetrAttention with Detr->Mask2Former','line_number':1394,'multiline':False]['text':' if key_value_states are provided this layer is used as a cross-attention layer','line_number':1450,'multiline':False]['text':' for the decoder','line_number':1451,'multiline':False]['text':' add position embeddings to the hidden states before projecting to queries and keys','line_number':1455,'multiline':False]['text':' add key-value position embeddings to the key value states','line_number':1460,'multiline':False]['text':' get query proj','line_number':1465,'multiline':False]['text':' get key, value proj','line_number':1467,'multiline':False]['text':' cross_attentions','line_number':1469,'multiline':False]['text':' self_attention','line_number':1473,'multiline':False]['text':' this operation is a bit awkward, but it's required to','line_number':1503,'multiline':False]['text':' make sure that attn_weights keeps its gradient.','line_number':1504,'multiline':False]['text':' In order to do so, attn_weights have to reshaped','line_number':1505,'multiline':False]['text':' twice and have to be reused in the following','line_number':1506,'multiline':False]['text':' Masked(Cross)-Attention Block','line_number':1582,'multiline':False]['text':' Self Attention Block','line_number':1600,'multiline':False]['text':' Fully Connected','line_number':1614,'multiline':False]['text':' Masked(Cross)-Attention Block','line_number':1641,'multiline':False]['text':' Self Attention Block','line_number':1660,'multiline':False]['text':' Fully Connected','line_number':1675,'multiline':False]['text':' level embedding (3 scales)','line_number':1765,'multiline':False]['text':' intermediate hidden states with layernorm applied - required for predicting class logits','line_number':1827,'multiline':False]['text':' decoder layers','line_number':1830,'multiline':False]['text':' intermediate mask predictions from transformer decoder layers','line_number':1834,'multiline':False]['text':' add intermediate hidden states with layer norm applied which will be used for predicting class logits','line_number':1890,'multiline':False]['text':' add hidden states from the last decoder layer','line_number':1898,'multiline':False]['text':' Copied from transformers.models.maskformer.modeling_maskformer.PredictionBlock with MaskFormer->Mask2Former','line_number':1916,'multiline':False]['text':' Maintain submodule indexing as if part of a Sequential block','line_number':1921,'multiline':False]['text':' Provide backwards compatibility from when the class inherited from nn.Sequential','line_number':1956,'multiline':False]['text':' In nn.Sequential subclasses, the name given to the layer is its index in the sequence.','line_number':1957,'multiline':False]['text':' In nn.Module subclasses they derived from the instance attribute they are assigned to e.g.','line_number':1958,'multiline':False]['text':' self.my_layer_name = Layer()','line_number':1959,'multiline':False]['text':' We can't give instance attributes integer names i.e. self.0 is not permitted and so need to register','line_number':1960,'multiline':False]['text':' explicitly','line_number':1961,'multiline':False]['text':' Equivalent to einsum('bqc, bchw -> bqhw') but jit friendly','line_number':1996,'multiline':False]['text':' Flatten (batch_size, num_channels, height, width) -> (height*width, batch_size, num_channels)','line_number':2056,'multiline':False]['text':' [num_queries, batch_size, num_channels]','line_number':2062,'multiline':False]['text':' weight each loss by `self.weight_dict[<LOSS_NAME>]` including auxiliary losses','line_number':2331,'multiline':False]