['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2023 The Meta AI Authors and The HuggingFace Team. All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' See all SAM models at https://huggingface.co/models?filter=sam','line_number':44,'multiline':False]['text':' Copied from transformers.models.convnext.modeling_convnext.ConvNextLayerNorm with ConvNext->Sam','line_number':163,'multiline':False]['text':' Input projections','line_number':228,'multiline':False]['text':' Separate into heads','line_number':234,'multiline':False]['text':' SamAttention','line_number':239,'multiline':False]['text':' batch_size * point_batch_size  x N_heads x N_tokens x N_tokens','line_number':241,'multiline':False]['text':' Get output','line_number':249,'multiline':False]['text':' Self attention block','line_number':300,'multiline':False]['text':' Cross attention block, tokens attending to image embedding','line_number':309,'multiline':False]['text':' MLP block','line_number':320,'multiline':False]['text':' Cross attention block, image embedding attending to tokens','line_number':325,'multiline':False]['text':' Prepare queries','line_number':383,'multiline':False]['text':' Apply transformer blocks and final layernorm','line_number':387,'multiline':False]['text':' Apply the final attenion layer from the points to the image','line_number':404,'multiline':False]['text':' should we create a new class for this?','line_number':453,'multiline':False]['text':' Concatenate output tokens','line_number':498,'multiline':False]['text':' Expand per-image data in batch direction to be per-point','line_number':508,'multiline':False]['text':' Run the transformer, image_positional_embedding are consumed','line_number':513,'multiline':False]['text':' Upscale mask embeddings and predict masks using the mask tokens','line_number':525,'multiline':False]['text':' Generate mask quality predictions','line_number':544,'multiline':False]['text':' Select the correct mask or masks for output','line_number':547,'multiline':False]['text':' assuming coords are in [0, 1]^2 square and have d_1 x ... x d_n x 2 shape','line_number':579,'multiline':False]['text':' outputs d_1 x ... x d_n x channel shape','line_number':584,'multiline':False]['text':' Shift to center of pixel','line_number':633,'multiline':False]['text':' torch.where and expanding the labels tensor is required by the ONNX export','line_number':644,'multiline':False]['text':' This is required for the ONNX export. The dtype, device need to be explicitely','line_number':647,'multiline':False]['text':' specificed as otherwise torch.onnx.export interprets as double','line_number':648,'multiline':False]['text':' Shift to center of pixel','line_number':671,'multiline':False]['text':' initialize relative positional embeddings','line_number':751,'multiline':False]['text':' Interpolate rel pos.','line_number':772,'multiline':False]['text':' Scale the coords with short length if shapes for q and k are different.','line_number':780,'multiline':False]['text':' qkv with shape (3, batch_size, nHead, height * width, channel)','line_number':834,'multiline':False]['text':' q, k, v with shape (batch_size * nHead, height * width, channel)','line_number':840,'multiline':False]['text':' Window partition','line_number':938,'multiline':False]['text':' Reverse window partition','line_number':947,'multiline':False]['text':' Initialize absolute positional embedding with pretrain image size.','line_number':992,'multiline':False]['text':' channel x height x width','line_number':1212,'multiline':False]['text':' repeat with batch size','line_number':1353,'multiline':False]