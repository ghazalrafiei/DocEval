['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2021 The Fairseq Authors and the HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' compute number of masked spans in batch','line_number':143,'multiline':False]['text':' make sure num masked indices <= sequence_length','line_number':147,'multiline':False]['text':' SpecAugment mask to fill','line_number':151,'multiline':False]['text':' get random indices to mask','line_number':154,'multiline':False]['text':' expand masked indices to masked spans','line_number':162,'multiline':False]['text':' scatter indices to mask','line_number':172,'multiline':False]['text':' make sure padded input ids cannot be masked','line_number':176,'multiline':False]['text':' get `num_negatives` random vector indices from the same utterance','line_number':193,'multiline':False]['text':' generate indices of the positive vectors themselves, repeat them `num_negatives` times','line_number':202,'multiline':False]['text':' avoid sampling the same positive vector, but keep the distribution uniform','line_number':205,'multiline':False]['text':' correct for batch size','line_number':208,'multiline':False]['text':' the dtype of the computation','line_number':442,'multiline':False]['text':' get query proj','line_number':480,'multiline':False]['text':' Convert the boolean attention mask to an attention bias.','line_number':493,'multiline':False]['text':' attention mask in the form of attention bias','line_number':495,'multiline':False]['text':' make sure padded tokens are not attended to','line_number':666,'multiline':False]['text':' update the last element in `hidden_states` after applying `layernorm` above','line_number':686,'multiline':False]['text':' storage for codebook variables (codewords)','line_number':720,'multiline':False]['text':' project to codevector dim','line_number':747,'multiline':False]['text':' sample code vector probs via gumbel in differentiateable way','line_number':752,'multiline':False]['text':' compute perplexity','line_number':757,'multiline':False]['text':' take argmax in non-differentiable way','line_number':763,'multiline':False]['text':' comptute hard codevector distribution (one hot)','line_number':764,'multiline':False]['text':' use probs to retrieve codevectors','line_number':771,'multiline':False]['text':' hidden_states require down-projection if feature dims don't match','line_number':784,'multiline':False]['text':' down-project hidden_states if required','line_number':798,'multiline':False]['text':' init input tensors','line_number':870,'multiline':False]['text':' Handle any PRNG if needed','line_number':913,'multiline':False]['text':' make sure that no loss is computed on padded inputs','line_number':970,'multiline':False]['text':' compute reduced attention_mask corresponding to feature vectors','line_number':972,'multiline':False]['text':' apply SpecAugment along time axis with given indices','line_number':978,'multiline':False]['text':' 1D convolutional layer output length formula taken','line_number':1019,'multiline':False]['text':' from https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html','line_number':1020,'multiline':False]['text':' Effectively attention_mask.sum(-1), but not inplace to be able to run','line_number':1035,'multiline':False]['text':' on inference mode.','line_number':1036,'multiline':False]['text':' these two operations makes sure that all values','line_number':1044,'multiline':False]['text':' before the output lengths indices are attended to','line_number':1045,'multiline':False]['text':' 1D convolutional layer output length formula taken','line_number':1155,'multiline':False]['text':' from https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html','line_number':1156,'multiline':False]['text':' project all transformed features (including masked) to final vq dim','line_number':1273,'multiline':False]['text':' quantize all (unmasked) extracted features and project to final vq dim','line_number':1276,'multiline':False]['text':' 1D convolutional layer output length formula taken','line_number':1304,'multiline':False]['text':' from https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html','line_number':1305,'multiline':False]['text':' overwrite since has `gumbel_temperature` input','line_number':1323,'multiline':False]['text':' Handle any PRNG if needed','line_number':1350,'multiline':False]