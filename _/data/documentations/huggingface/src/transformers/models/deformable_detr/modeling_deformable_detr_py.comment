['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2022 SenseTime and The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' Move this to not compile only when importing, this needs to happen later, like in __init__.','line_number':54,'multiline':False]['text':' See all Deformable DETR models at https://huggingface.co/models?filter=deformable-detr','line_number':130,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrFrozenBatchNorm2d with Detr->DeformableDetr','line_number':320,'multiline':False]['text':' move reshapes to the beginning','line_number':348,'multiline':False]['text':' to make it user-friendly','line_number':349,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.replace_batch_norm with Detr->DeformableDetr','line_number':360,'multiline':False]['text':' replace batch norm by frozen batch norm','line_number':414,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrConvEncoder.forward with Detr->DeformableDetr','line_number':432,'multiline':False]['text':' send pixel_values through the model to get list of feature maps','line_number':434,'multiline':False]['text':' downsample pixel_mask to match shape of corresponding feature_map','line_number':439,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrConvModel with Detr->DeformableDetr','line_number':445,'multiline':False]['text':' send pixel_values and pixel_mask through backbone to get list of (feature_map, pixel_mask) tuples','line_number':457,'multiline':False]['text':' position encoding','line_number':461,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrLearnedPositionEmbedding','line_number':505,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.build_position_encoding with Detr->DeformableDetr','line_number':529,'multiline':False]['text':' TODO find a better way of exposing other arguments','line_number':533,'multiline':False]['text':' batch_size, height*width, num_heads, hidden_dim','line_number':552,'multiline':False]['text':' -> batch_size, height*width, num_heads*hidden_dim','line_number':553,'multiline':False]['text':' -> batch_size, num_heads*hidden_dim, height*width','line_number':554,'multiline':False]['text':' -> batch_size*num_heads, hidden_dim, height, width','line_number':555,'multiline':False]['text':' batch_size, num_queries, num_heads, num_points, 2','line_number':559,'multiline':False]['text':' -> batch_size, num_heads, num_queries, num_points, 2','line_number':560,'multiline':False]['text':' -> batch_size*num_heads, num_queries, num_points, 2','line_number':561,'multiline':False]['text':' batch_size*num_heads, hidden_dim, num_queries, num_points','line_number':563,'multiline':False]['text':' (batch_size, num_queries, num_heads, num_levels, num_points)','line_number':568,'multiline':False]['text':' -> (batch_size, num_heads, num_queries, num_levels, num_points)','line_number':569,'multiline':False]['text':' -> (batch_size, num_heads, 1, num_queries, num_levels*num_points)','line_number':570,'multiline':False]['text':' check if dim_per_head is power of 2','line_number':594,'multiline':False]['text':' add position embeddings to the hidden states before projecting to queries and keys','line_number':653,'multiline':False]['text':' we invert the attention_mask','line_number':666,'multiline':False]['text':' batch_size, num_queries, n_heads, n_levels, n_points, 2','line_number':678,'multiline':False]['text':' PyTorch implementation','line_number':694,'multiline':False]['text':' custom kernel','line_number':698,'multiline':False]['text':' PyTorch implementation','line_number':708,'multiline':False]['text':' add position embeddings to the hidden states before projecting to queries and keys','line_number':762,'multiline':False]['text':' get queries, keys and values','line_number':767,'multiline':False]['text':' expand attention_mask','line_number':787,'multiline':False]['text':' [batch_size, seq_len] -> [batch_size, 1, target_seq_len, source_seq_len]','line_number':789,'multiline':False]['text':' this operation is a bit awkward, but it's required to','line_number':804,'multiline':False]['text':' make sure that attn_weights keeps its gradient.','line_number':805,'multiline':False]['text':' In order to do so, attn_weights have to reshaped','line_number':806,'multiline':False]['text':' twice and have to be reused in the following','line_number':807,'multiline':False]['text':' Apply Multi-scale Deformable Attention Module on the multi-scale feature maps.','line_number':877,'multiline':False]['text':' self-attention','line_number':922,'multiline':False]['text':' cross-attention','line_number':933,'multiline':False]['text':' feedforward neural networks','line_number':940,'multiline':False]['text':' Self Attention','line_number':979,'multiline':False]['text':' Cross-Attention','line_number':992,'multiline':False]['text':' Fully Connected','line_number':1011,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrClassificationHead','line_number':1028,'multiline':False]['text':' Slightly different from the TF version which uses truncated_normal for initialization','line_number':1062,'multiline':False]['text':' cf https://github.com/pytorch/pytorch/pull/5617','line_number':1063,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1150,'multiline':False]['text':' TODO: valid_ratios could be useless here. check https://github.com/fundamentalvision/Deformable-DETR/issues/36','line_number':1175,'multiline':False]['text':' hack implementation for iterative bounding box refinement and two-stage Deformable DETR','line_number':1285,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1289,'multiline':False]['text':' decoder layers','line_number':1347,'multiline':False]['text':' hack implementation for iterative bounding box refinement','line_number':1389,'multiline':False]['text':' Keep batch_size as first dimension','line_number':1414,'multiline':False]['text':' add hidden states from the last decoder layer','line_number':1418,'multiline':False]['text':' Create backbone + positional encoding','line_number':1456,'multiline':False]['text':' Create input projection layers','line_number':1461,'multiline':False]['text':' batch_size, num_queries, 4','line_number':1544,'multiline':False]['text':' batch_size, num_queries, 4, 128','line_number':1546,'multiline':False]['text':' batch_size, num_queries, 4, 64, 2 -> batch_size, num_queries, 512','line_number':1548,'multiline':False]['text':' inverse sigmoid','line_number':1590,'multiline':False]['text':' assign each pixel as an object query','line_number':1594,'multiline':False]['text':' Extract multi-scale feature maps of same resolution `config.d_model` (cf Figure 4 in paper)','line_number':1651,'multiline':False]['text':' First, sent pixel_values + pixel_mask through Backbone to obtain the features','line_number':1652,'multiline':False]['text':' which is a list of tuples','line_number':1653,'multiline':False]['text':' Then, apply 1x1 convolution to reduce the channel dimension to d_model (256 by default)','line_number':1656,'multiline':False]['text':' Lowest resolution feature maps are obtained via 3x3 stride 2 convolutions on the final stage','line_number':1665,'multiline':False]['text':' Create queries','line_number':1679,'multiline':False]['text':' Prepare encoder inputs (by flattening)','line_number':1684,'multiline':False]['text':' Fourth, sent source_flatten + mask_flatten + lvl_pos_embed_flatten (backbone + proj layer output) through encoder','line_number':1708,'multiline':False]['text':' Also provide spatial_shapes, level_start_index and valid_ratios','line_number':1709,'multiline':False]['text':' If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True','line_number':1722,'multiline':False]['text':' Fifth, prepare decoder inputs','line_number':1730,'multiline':False]['text':' hack implementation for two-stage Deformable DETR','line_number':1739,'multiline':False]['text':' apply a detection head to each pixel (A.4 in paper)','line_number':1740,'multiline':False]['text':' linear projection for bounding box binary classification (i.e. foreground and background)','line_number':1741,'multiline':False]['text':' 3-layer FFN to predict bounding boxes coordinates (bbox regression branch)','line_number':1743,'multiline':False]['text':' only keep top scoring `config.two_stage_num_proposals` proposals','line_number':1747,'multiline':False]['text':' When using clones, all layers > 0 will be clones, but layer 0 *is* required','line_number':1810,'multiline':False]['text':' We can't initialize the model on meta device as some weights are modified during the initialization','line_number':1812,'multiline':False]['text':' Deformable DETR encoder-decoder model','line_number':1818,'multiline':False]['text':' Detection heads on top','line_number':1821,'multiline':False]['text':' if two-stage, the last class_embed and bbox_embed is for region proposal generation','line_number':1833,'multiline':False]['text':' hack implementation for iterative bounding box refinement','line_number':1839,'multiline':False]['text':' hack implementation for two-stage','line_number':1847,'multiline':False]['text':' Initialize weights and apply final processing','line_number':1852,'multiline':False]['text':' taken from https://github.com/facebookresearch/detr/blob/master/models/detr.py','line_number':1855,'multiline':False]['text':' this is a workaround to make torchscript happy, as torchscript','line_number':1858,'multiline':False]['text':' doesn't support dictionary with non-homogeneous values, such','line_number':1859,'multiline':False]['text':' as a dict having both a Tensor and a list.','line_number':1860,'multiline':False]['text':' First, sent images through DETR base model to obtain encoder + decoder outputs','line_number':1920,'multiline':False]['text':' class logits + predicted bounding boxes','line_number':1937,'multiline':False]['text':' First: create the matcher','line_number':1967,'multiline':False]['text':' Second: create the criterion','line_number':1971,'multiline':False]['text':' Third: compute the losses, based on outputs and labels','line_number':1980,'multiline':False]['text':' Fourth: compute total loss, as a weighted sum of the various losses','line_number':1992,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.dice_loss','line_number':2034,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.sigmoid_focal_loss','line_number':2054,'multiline':False]['text':' add modulating factor','line_number':2075,'multiline':False]['text':' removed logging parameter, which was part of the original implementation','line_number':2110,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrLoss.loss_cardinality','line_number':2145,'multiline':False]['text':' Count the number of predictions that are NOT "no-object" (which is the last class)','line_number':2155,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrLoss.loss_boxes','line_number':2161,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrLoss._get_source_permutation_idx','line_number':2186,'multiline':False]['text':' permute predictions following indices','line_number':2188,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrLoss._get_target_permutation_idx','line_number':2193,'multiline':False]['text':' permute targets following indices','line_number':2195,'multiline':False]['text':' Retrieve the matching between the outputs of the last layer and the targets','line_number':2223,'multiline':False]['text':' Compute the average number of target boxes accross all nodes, for normalization purposes','line_number':2226,'multiline':False]['text':' (Niels): comment out function below, distributed training to be added','line_number':2229,'multiline':False]['text':' if is_dist_avail_and_initialized():','line_number':2230,'multiline':False]['text':'     torch.distributed.all_reduce(num_boxes)','line_number':2231,'multiline':False]['text':' (Niels) in original implementation, num_boxes is divided by get_world_size()','line_number':2232,'multiline':False]['text':' Compute all the requested losses','line_number':2235,'multiline':False]['text':' In case of auxiliary losses, we repeat this process with the output of each intermediate layer.','line_number':2240,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.DetrMLPPredictionHead','line_number':2263,'multiline':False]['text':' We flatten to compute the cost matrices in a batch','line_number':2335,'multiline':False]['text':' [batch_size * num_queries, num_classes]','line_number':2336,'multiline':False]['text':' [batch_size * num_queries, 4]','line_number':2337,'multiline':False]['text':' Also concat the target labels and boxes','line_number':2339,'multiline':False]['text':' Compute the classification cost.','line_number':2343,'multiline':False]['text':' Compute the L1 cost between boxes','line_number':2350,'multiline':False]['text':' Compute the giou cost between boxes','line_number':2353,'multiline':False]['text':' Final cost matrix','line_number':2356,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr._upcast','line_number':2365,'multiline':False]['text':' Protects from numerical overflows in multiplications by upcasting to the equivalent higher type','line_number':2367,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.box_area','line_number':2374,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.box_iou','line_number':2391,'multiline':False]['text':' [N,M,2]','line_number':2396,'multiline':False]['text':' [N,M,2]','line_number':2397,'multiline':False]['text':' [N,M,2]','line_number':2399,'multiline':False]['text':' [N,M]','line_number':2400,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.generalized_box_iou','line_number':2408,'multiline':False]['text':' degenerate boxes gives inf / nan results','line_number':2416,'multiline':False]['text':' so do an early check','line_number':2417,'multiline':False]['text':' [N,M,2]','line_number':2427,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr._max_by_axis','line_number':2433,'multiline':False]['text':' type: (List[List[int]]) -> List[int]','line_number':2435,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.NestedTensor','line_number':2443,'multiline':False]['text':' Copied from transformers.models.detr.modeling_detr.nested_tensor_from_tensor_list','line_number':2465,'multiline':False]