['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2020 The HuggingFace Inc. team.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' Fast tokenizers (provided by HuggingFace tokenizer's library) can be saved in a single file','line_number':50,'multiline':False]['text':' Slow tokenizers have an additional added tokens files','line_number':55,'multiline':False]['text':' We have a serialization from tokenizers which let us directly build the backend','line_number':110,'multiline':False]['text':' We need to convert a slow tokenizer to build the backend','line_number':113,'multiline':False]['text':' We need to create and convert a slow tokenizer to build the backend','line_number':116,'multiline':False]['text':' We call this after having initialized the backend tokenizer because we update it.','line_number':155,'multiline':False]['text':' The following logic will be replace with a single add_tokens once a fix is pushed to tokenizers','line_number':158,'multiline':False]['text':' allows converting a slow -> fast, non-legacy: if the `tokenizer.json` does not have all the added tokens','line_number':159,'multiline':False]['text':' uses the information stored in `added_tokens_decoder`.','line_number':160,'multiline':False]['text':' this is costly for fast tokenizers as we re-compute the regex again. But not all tokens are added tokens','line_number':161,'multiline':False]['text':' if some of the special tokens are strings, we check if we don't already have a token','line_number':168,'multiline':False]['text':' super hack: if a token.special is set, tokenizer ignores it for now so FIXME @ArthurZ','line_number':173,'multiline':False]['text':' Accumulate added tokens into batches of special/non-special tokens, because calling add_tokens() for','line_number':174,'multiline':False]['text':' individual tokens would repeatedly rebuild a trie, which can be slow.','line_number':175,'multiline':False]['text':' Set truncation and padding on the backend tokenizer','line_number':429,'multiline':False]['text':' _truncation might contain more keys that the target `transformers`','line_number':441,'multiline':False]['text':' supports. Use only the target keys to trigger `enable_truncation`.','line_number':442,'multiline':False]['text':' This should enable this code to works on various `tokenizers`','line_number':443,'multiline':False]['text':' targets.','line_number':444,'multiline':False]['text':' Set the truncation and padding strategy and restore the initial configuration','line_number':495,'multiline':False]['text':' Convert encoding to dict','line_number':510,'multiline':False]['text':' `Tokens` has type: Tuple[','line_number':511,'multiline':False]['text':'                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],','line_number':512,'multiline':False]['text':'                       List[EncodingFast]','line_number':513,'multiline':False]['text':'                    ]','line_number':514,'multiline':False]['text':' with nested dimensions corresponding to batch, overflows, sequence length','line_number':515,'multiline':False]['text':' Convert the output to have dict[list] from list[dict] and remove the additional overflows dimension','line_number':530,'multiline':False]['text':' From (variable) shape (batch, overflows, sequence length) to ~ (batch * overflows, sequence length)','line_number':531,'multiline':False]['text':' (we say ~ because the number of overflow varies with the example in the batch)','line_number':532,'multiline':False]['text':'','line_number':533,'multiline':False]['text':' To match each overflowing sample with the original sample in the batch','line_number':534,'multiline':False]['text':' we add an overflow_to_sample_mapping array (see below)','line_number':535,'multiline':False]['text':' If returning overflowing tokens, we need to return a mapping','line_number':542,'multiline':False]['text':' from the batch idx to the original sample','line_number':543,'multiline':False]['text':' Return tensor is None, then we can remove the leading batch axis','line_number':596,'multiline':False]['text':' Overflowing tokens are returned as a batch of output so we keep them in this case','line_number':597,'multiline':False]['text':' make sure to be foward compatible','line_number':668,'multiline':False]['text':' Remove added tokens for now (uses IDs of tokens)','line_number':722,'multiline':False]['text':' Remove post processor for now (uses IDs of tokens)','line_number':724,'multiline':False]['text':' Remove vocab','line_number':728,'multiline':False]['text':' Get the special tokens from the current tokenizer if none are specified.','line_number':757,'multiline':False]['text':' Trainer needs to know the end of word / continuing subword thingies in BPE','line_number':771,'multiline':False]['text':' Almost done, we just have to adjust the token IDs in the post processor','line_number':795,'multiline':False]['text':' Map pad/cls/mask token at the Transformers level','line_number':816,'multiline':False]['text':' Get the private one to avoid unnecessary warnings.','line_number':820,'multiline':False]['text':' Create an added token with the same parameters except the content','line_number':828,'multiline':False]