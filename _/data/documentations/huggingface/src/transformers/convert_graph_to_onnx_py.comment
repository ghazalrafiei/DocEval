['text':' Copyright 2020 The HuggingFace Team. All rights reserved.','line_number':1,'multiline':False]['text':'','line_number':2,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':3,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':4,'multiline':False]['text':' You may obtain a copy of the License at','line_number':5,'multiline':False]['text':'','line_number':6,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':7,'multiline':False]['text':'','line_number':8,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':9,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':10,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':11,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':12,'multiline':False]['text':' limitations under the License.','line_number':13,'multiline':False]['text':' This is the minimal required version to','line_number':28,'multiline':False]['text':' support some ONNX Runtime features','line_number':29,'multiline':False]['text':' Parse the version of the installed onnxruntime','line_number':115,'multiline':False]['text':' We require 1.4.0 minimum','line_number':118,'multiline':False]['text':' start at index 1 to skip "self" argument','line_number':150,'multiline':False]['text':' Let's assume batch is the first axis with only 1 element (~~ might not be always true ...)','line_number':183,'multiline':False]['text':' Generate input names & axes','line_number':205,'multiline':False]['text':' flatten potentially grouped outputs (past for gpt2, attentions)','line_number':209,'multiline':False]['text':' Generate output names & axes','line_number':217,'multiline':False]['text':' Create the aggregated axes representation','line_number':221,'multiline':False]['text':' If no tokenizer provided','line_number':241,'multiline':False]['text':' Check the wanted framework is available','line_number':245,'multiline':False]['text':' Allocate tokenizer and model','line_number':253,'multiline':False]['text':' PyTorch deprecated the `enable_onnx_checker` and `use_external_data_format` arguments in v1.11,','line_number':284,'multiline':False]['text':' so we check the torch version for backwards compatibility','line_number':285,'multiline':False]['text':' Build','line_number':336,'multiline':False]['text':' Forward','line_number':339,'multiline':False]['text':' Load the pipeline','line_number':386,'multiline':False]['text':' Export the graph','line_number':395,'multiline':False]['text':' Generate model name with suffix "optimized"','line_number':415,'multiline':False]['text':' Load the ONNX model','line_number':443,'multiline':False]['text':' Copy it','line_number':452,'multiline':False]['text':' Construct quantizer','line_number':456,'multiline':False]['text':' onnxruntime renamed input_qType to activation_qType in v1.13.1, so we','line_number':457,'multiline':False]['text':' check the onnxruntime version to ensure backward compatibility.','line_number':458,'multiline':False]['text':' See also: https://github.com/microsoft/onnxruntime/pull/12873','line_number':459,'multiline':False]['text':' Quantize and export','line_number':489,'multiline':False]['text':' Append "-quantized" at the end of the model's name','line_number':492,'multiline':False]['text':' Save model','line_number':495,'multiline':False]['text':' Make sure output is absolute path','line_number':519,'multiline':False]['text':' Convert','line_number':524,'multiline':False]['text':' Ensure requirements for quantization on onnxruntime is met','line_number':536,'multiline':False]['text':' onnxruntime optimizations doesn't provide the same level of performances on TensorFlow than PyTorch','line_number':539,'multiline':False]['text':' Quantization works best when using the optimized version of the model','line_number':550,'multiline':False]['text':' Do the quantization on the right graph','line_number':553,'multiline':False]['text':' And verify','line_number':556,'multiline':False]