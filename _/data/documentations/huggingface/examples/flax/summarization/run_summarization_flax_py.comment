['text':'!/usr/bin/env python','line_number':1,'multiline':False]['text':' coding=utf-8','line_number':2,'multiline':False]['text':' Copyright 2021 The HuggingFace Team All rights reserved.','line_number':3,'multiline':False]['text':'','line_number':4,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':5,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':6,'multiline':False]['text':' You may obtain a copy of the License at','line_number':7,'multiline':False]['text':'','line_number':8,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':9,'multiline':False]['text':'','line_number':10,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':11,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':12,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':13,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':14,'multiline':False]['text':' limitations under the License.','line_number':15,'multiline':False]['text':' You can also adapt this script on your own sequence to sequence task. Pointers for this are left as comments.','line_number':19,'multiline':False]['text':' Here to have a nice missing dependency error message early on','line_number':38,'multiline':False]['text':' Skip incomplete batch.','line_number':384,'multiline':False]['text':' See all possible arguments in src/transformers/training_args.py','line_number':425,'multiline':False]['text':' or by passing the --help flag to this script.','line_number':426,'multiline':False]['text':' We now keep distinct sets of args, for a cleaner separation of concerns.','line_number':427,'multiline':False]['text':' If we pass only one argument to the script and it's the path to a json file,','line_number':431,'multiline':False]['text':' let's parse it to get our arguments.','line_number':432,'multiline':False]['text':' Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The','line_number':446,'multiline':False]['text':' information sent is the one passed as arguments along with your Python/PyTorch versions.','line_number':447,'multiline':False]['text':' Make one log on every process with the configuration for debugging.','line_number':461,'multiline':False]['text':' Setup logging, we only want one process per machine to log things on the screen.','line_number':467,'multiline':False]['text':' Set the verbosity to info of the Transformers logger (on main process only):','line_number':476,'multiline':False]['text':' Handle the repository creation','line_number':479,'multiline':False]['text':' Retrieve of infer repo_name','line_number':481,'multiline':False]['text':' Create repo and retrieve repo_id','line_number':485,'multiline':False]['text':' Clone repo locally','line_number':487,'multiline':False]['text':' Get the datasets: you can either provide your own CSV/JSON training and evaluation files (see below)','line_number':490,'multiline':False]['text':' or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/','line_number':491,'multiline':False]['text':' (the dataset will be downloaded automatically from the datasets Hub).','line_number':492,'multiline':False]['text':'','line_number':493,'multiline':False]['text':' For CSV/JSON files this script will use the first column for the full texts and the second column for the','line_number':494,'multiline':False]['text':' summaries (unless you specify column names for this with the `text_column` and `summary_column` arguments).','line_number':495,'multiline':False]['text':'','line_number':496,'multiline':False]['text':' Downloading and loading a dataset from the hub.','line_number':498,'multiline':False]['text':' See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at','line_number':523,'multiline':False]['text':' https://huggingface.co/docs/datasets/loading_datasets.','line_number':524,'multiline':False]['text':' Load pretrained model and tokenizer','line_number':526,'multiline':False]['text':' Preprocessing the datasets.','line_number':593,'multiline':False]['text':' We need to tokenize inputs and targets.','line_number':594,'multiline':False]['text':' Get the column names for input/target.','line_number':611,'multiline':False]['text':' Temporarily set max_target_length for training.','line_number':630,'multiline':False]['text':' In Flax, for seq2seq models we need to pass `decoder_input_ids`','line_number':633,'multiline':False]['text':' as the Flax models don't accept `labels`, we need to prepare the decoder_input_ids here','line_number':634,'multiline':False]['text':' for that dynamically import the `shift_tokens_right` function from the model file','line_number':635,'multiline':False]['text':' Setting padding="max_length" as we need fixed length inputs for jitted functions','line_number':639,'multiline':False]['text':' Setup the tokenizer for targets','line_number':648,'multiline':False]['text':' We need decoder_attention_mask so we can ignore pad tokens from loss','line_number':663,'multiline':False]['text':' Metric','line_number':712,'multiline':False]['text':' rougeLSum expects newline after each sentence','line_number':719,'multiline':False]['text':' Some simple post-processing','line_number':729,'multiline':False]['text':' Enable tensorboard only on the master node','line_number':738,'multiline':False]['text':' Initialize our training','line_number':756,'multiline':False]['text':' Store some constant','line_number':760,'multiline':False]['text':' Create learning rate schedule','line_number':768,'multiline':False]['text':' We use Optax's "masking" functionality to not apply weight decay','line_number':777,'multiline':False]['text':' to bias and LayerNorm scale parameters. decay_mask_fn returns a','line_number':778,'multiline':False]['text':' mask boolean with the same structure as the parameters.','line_number':779,'multiline':False]['text':' The mask is True for parameters that should be decayed.','line_number':780,'multiline':False]['text':' find out all LayerNorm parameters','line_number':783,'multiline':False]['text':' create adam optimizer','line_number':794,'multiline':False]['text':' Setup train state','line_number':804,'multiline':False]['text':' label smoothed cross entropy','line_number':807,'multiline':False]['text':' ignore padded tokens from loss','line_number':824,'multiline':False]['text':' Define gradient update step fn','line_number':830,'multiline':False]['text':' true loss = total loss / total samples','line_number':844,'multiline':False]['text':' true grad = total grad / total samples','line_number':848,'multiline':False]['text':' Define eval fn','line_number':856,'multiline':False]['text':' true loss = total loss / total samples','line_number':864,'multiline':False]['text':' Define generation function','line_number':871,'multiline':False]['text':' Create parallel version of the train and eval step','line_number':883,'multiline':False]['text':' Replicate the train state on each device','line_number':890,'multiline':False]['text':' ======================== Training ================================','line_number':903,'multiline':False]['text':' Create sampling rng','line_number':906,'multiline':False]['text':' Generate an epoch by shuffling sampling indices from the train dataset','line_number':910,'multiline':False]['text':' train','line_number':913,'multiline':False]['text':' ======================== Evaluating ==============================','line_number':929,'multiline':False]['text':' Model forward','line_number':937,'multiline':False]['text':' generation','line_number':946,'multiline':False]['text':' normalize eval metrics','line_number':952,'multiline':False]['text':' compute ROUGE metrics','line_number':956,'multiline':False]['text':' Print metrics and update progress bar','line_number':963,'multiline':False]['text':' Save metrics','line_number':968,'multiline':False]['text':' save checkpoint after each epoch and push checkpoint to the hub','line_number':973,'multiline':False]['text':' ======================== Prediction loop ==============================','line_number':981,'multiline':False]['text':' Model forward','line_number':992,'multiline':False]['text':' generation','line_number':1001,'multiline':False]['text':' normalize prediction metrics','line_number':1007,'multiline':False]['text':' compute ROUGE metrics','line_number':1011,'multiline':False]['text':' Print metrics','line_number':1018,'multiline':False]['text':' save final metrics in json','line_number':1022,'multiline':False]