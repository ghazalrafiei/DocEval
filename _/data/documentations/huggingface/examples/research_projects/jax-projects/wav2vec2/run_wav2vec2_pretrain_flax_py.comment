['text':'!/usr/bin/env python3','line_number':1,'multiline':False]['text':' reformat list to dict and set to pytorch format','line_number':172,'multiline':False]['text':' these two operations makes sure that all values','line_number':189,'multiline':False]['text':' before the output lengths indices are attended to','line_number':190,'multiline':False]['text':' sample randomly masked indices','line_number':194,'multiline':False]['text':' sample indices to take for negative vectors','line_number':203,'multiline':False]['text':' take negative vectors from sampled indices','line_number':256,'multiline':False]['text':' make sure incorrectly sampled vectors don't contribute to loss','line_number':269,'multiline':False]['text':' See all possible arguments in src/transformers/training_args.py','line_number':284,'multiline':False]['text':' or by passing the --help flag to this script.','line_number':285,'multiline':False]['text':' We now keep distinct sets of args, for a cleaner separation of concerns.','line_number':286,'multiline':False]['text':' Downloading and loading a dataset from the hub.','line_number':293,'multiline':False]['text':' make sure only "validation" and "train" keys remain"','line_number':297,'multiline':False]['text':' make sure only "validation" and "train" keys remain"','line_number':312,'multiline':False]['text':' only normalized-inputs-training is supported','line_number':327,'multiline':False]['text':' check that all files have the correct sampling rate','line_number':333,'multiline':False]['text':' load audio files into numpy arrays','line_number':337,'multiline':False]['text':' filter audio files that are too long','line_number':342,'multiline':False]['text':' normalize and transform to `BatchFeatures`','line_number':350,'multiline':False]['text':' pretraining is only supported for "newer" stable layer norm architecture','line_number':359,'multiline':False]['text':' apply_spec_augment has to be True, mask_feature_prob has to be 0.0','line_number':360,'multiline':False]['text':' Activate gradient checkpointing if needed','line_number':374,'multiline':False]['text':' Enable tensorboard only on the master node','line_number':382,'multiline':False]['text':' Initialize our training','line_number':400,'multiline':False]['text':' Create learning rate schedule','line_number':411,'multiline':False]['text':' We use Optax's "masking" functionality to not apply weight decay','line_number':424,'multiline':False]['text':' to bias and LayerNorm scale parameters. decay_mask_fn returns a','line_number':425,'multiline':False]['text':' mask boolean with the same structure as the parameters.','line_number':426,'multiline':False]['text':' The mask is True for parameters that should be decayed.','line_number':427,'multiline':False]['text':' create adam optimizer','line_number':436,'multiline':False]['text':' Setup train state and define training hyper-parameters','line_number':446,'multiline':False]['text':' Define gradient update step fn','line_number':453,'multiline':False]['text':' Create parallel version of the train step','line_number':500,'multiline':False]['text':' Define eval fn','line_number':503,'multiline':False]['text':' summarize metrics','line_number':521,'multiline':False]['text':' Replicate the train state on each device','line_number':529,'multiline':False]['text':' ======================== Training ================================','line_number':536,'multiline':False]['text':' Create sampling rng','line_number':539,'multiline':False]['text':' Generate an epoch by shuffling sampling indices from the train dataset','line_number':542,'multiline':False]['text':' Avoid using jax.numpy here in case of TPU training','line_number':544,'multiline':False]['text':' Gather the indexes for creating the batch and do a training step','line_number':548,'multiline':False]['text':' Model forward','line_number':554,'multiline':False]['text':' Save metrics','line_number':563,'multiline':False]['text':' ======================== Evaluating ==============================','line_number':576,'multiline':False]['text':' Avoid using jax.numpy here in case of TPU training','line_number':578,'multiline':False]['text':' Model forward','line_number':587,'multiline':False]['text':' get eval metrics','line_number':592,'multiline':False]['text':' Update progress bar','line_number':596,'multiline':False]['text':' Save metrics','line_number':602,'multiline':False]['text':' save checkpoint after each epoch and push checkpoint to the hub','line_number':607,'multiline':False]