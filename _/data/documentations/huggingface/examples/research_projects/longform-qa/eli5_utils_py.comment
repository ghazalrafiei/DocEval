['text':' noqa: F401','line_number':3,'multiline':False]['text':' noqa: F401','line_number':7,'multiline':False]['text':' noqa: F401','line_number':8,'multiline':False]['text':' noqa: F401','line_number':13,'multiline':False]['text':' noqa: F401','line_number':14,'multiline':False]['text':'##############','line_number':25,'multiline':False]['text':' Sparse index','line_number':26,'multiline':False]['text':'##############','line_number':27,'multiline':False]['text':' create the ES index','line_number':51,'multiline':False]['text':'##############','line_number':90,'multiline':False]['text':' ELI5 retriever training','line_number':91,'multiline':False]['text':'##############','line_number':92,'multiline':False]['text':' reproduces BERT forward pass with checkpointing','line_number':130,'multiline':False]['text':' prepare implicit variables','line_number':134,'multiline':False]['text':' define function for checkpointing','line_number':143,'multiline':False]['text':' run embedding layer on everything at once','line_number':154,'multiline':False]['text':' run encoding and pooling on one mini-batch at a time','line_number':158,'multiline':False]['text':' run bert_model on a dummy batch to get output dimension','line_number':189,'multiline':False]['text':' has model weights, optimizer, and scheduler states','line_number':197,'multiline':False]['text':' make iterator','line_number':220,'multiline':False]['text':' accumulate loss since last print','line_number':227,'multiline':False]['text':' optimizer','line_number':235,'multiline':False]['text':' some printing within the epoch','line_number':240,'multiline':False]['text':' make iterator','line_number':262,'multiline':False]['text':' accumulate loss since last print','line_number':270,'multiline':False]['text':' optimizer','line_number':278,'multiline':False]['text':' some printing within the epoch','line_number':283,'multiline':False]['text':' make iterator','line_number':302,'multiline':False]['text':'##############','line_number':338,'multiline':False]['text':' ELI5 seq2seq model training','line_number':339,'multiline':False]['text':'##############','line_number':340,'multiline':False]['text':' make index of specific question-answer pairs from multi-answers','line_number':350,'multiline':False]['text':' has model weights, optimizer, and scheduler states','line_number':388,'multiline':False]['text':' make iterator','line_number':419,'multiline':False]['text':' accumulate loss since last print','line_number':429,'multiline':False]['text':' optimizer','line_number':437,'multiline':False]['text':' some printing within the epoch','line_number':442,'multiline':False]['text':' make iterator','line_number':461,'multiline':False]['text':' accumulate loss since last print','line_number':468,'multiline':False]['text':' generate answer from input "question: ... context: <p> ..."','line_number':523,'multiline':False]['text':'##############','line_number':565,'multiline':False]['text':' ELI5-trained retrieval model usage','line_number':566,'multiline':False]['text':'##############','line_number':567,'multiline':False]['text':' build a support document for the question out of Wikipedia snippets','line_number':629,'multiline':False]['text':' find nearest neighbors of an answer or declarative text in Wikipedia snippets','line_number':660,'multiline':False]