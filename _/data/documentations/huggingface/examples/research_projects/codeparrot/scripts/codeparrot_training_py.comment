['text':' we only want to setup logging once','line_number':110,'multiline':False]['text':' TFLOPs formula (from Equation 3 in Section 5.1 of https://arxiv.org/pdf/2104.04473.pdf).','line_number':161,'multiline':False]['text':' Settings','line_number':194,'multiline':False]['text':' Accelerator','line_number':198,'multiline':False]['text':' Clone model repository','line_number':207,'multiline':False]['text':' Logging','line_number':211,'multiline':False]['text':' Checkout new branch on repo','line_number':215,'multiline':False]['text':' Load model and tokenizer','line_number':219,'multiline':False]['text':' Load dataset and dataloader','line_number':225,'multiline':False]['text':' Prepare the optimizer and learning rate scheduler','line_number':228,'multiline':False]['text':' Prepare everything with our `accelerator`.','line_number':243,'multiline':False]['text':' load in the weights and states from a previous save','line_number':248,'multiline':False]['text':' Get the most recent checkpoint','line_number':255,'multiline':False]['text':' Sorts folders by date modified, most recent checkpoint is the last','line_number':258,'multiline':False]['text':' Extract the step of the checkpoint to continue from there','line_number':259,'multiline':False]['text':' Train model','line_number':263,'multiline':False]['text':' we need to skip steps until we reach the resumed step','line_number':270,'multiline':False]['text':' Prevent backward from doing gradient all_reduce in every step','line_number':277,'multiline':False]['text':' Evaluate and save the last checkpoint','line_number':318,'multiline':False]