['text':' without strip, the model generate commented codes ...','line_number':38,'multiline':False]['text':' last string should be ""','line_number':70,'multiline':False]['text':' dict of list of generated tokens','line_number':112,'multiline':False]['text':' each task is generated batch_size times','line_number':119,'multiline':False]['text':' Setup configuration','line_number':141,'multiline':False]['text':' enables code execution in code_eval metric','line_number':146,'multiline':False]['text':' make sure tokenizer plays nice with multiprocessing','line_number':148,'multiline':False]['text':' Use dataset load to feed to accelerate','line_number':154,'multiline':False]['text':' Load model and tokenizer','line_number':158,'multiline':False]['text':' Generation settings','line_number':163,'multiline':False]['text':' Load evaluation dataset and metric','line_number':173,'multiline':False]['text':' do not confuse args.batch_size, which is actually the num_return_sequences','line_number':181,'multiline':False]['text':' Run a quick test to see if code evaluation is enabled','line_number':184,'multiline':False]['text':' Evaluate completions with "code_eval" metric','line_number':214,'multiline':False]['text':' Save results to json file','line_number':220,'multiline':False]['text':' For some reason the folliwng seems to be necessary sometimes for code_eval to work nice with multiprocessing','line_number':225,'multiline':False]['text':' https://stackoverflow.com/questions/60804599/python-multiprocessing-keeps-spawning-the-whole-script','line_number':226,'multiline':False]