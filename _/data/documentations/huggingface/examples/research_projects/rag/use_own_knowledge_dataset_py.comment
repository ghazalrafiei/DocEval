['text':'#####################################','line_number':59,'multiline':False]['text':'#####################################','line_number':61,'multiline':False]['text':' The dataset needed for RAG must have three columns:','line_number':63,'multiline':False]['text':' - title (string): title of the document','line_number':64,'multiline':False]['text':' - text (string): text of a passage of the document','line_number':65,'multiline':False]['text':' - embeddings (array of dimension d): DPR representation of the passage','line_number':66,'multiline':False]['text':' Let's say you have documents in tab-separated csv files with columns "title" and "text"','line_number':68,'multiline':False]['text':' You can load a Dataset object this way','line_number':71,'multiline':False]['text':' More info about loading csv files in the documentation: https://huggingface.co/docs/datasets/loading_datasets?highlight=csv#csv-files','line_number':76,'multiline':False]['text':' Then split the documents into passages of 100 words','line_number':78,'multiline':False]['text':' And compute the embeddings','line_number':81,'multiline':False]['text':' optional, save as float32 instead of float64 to save space','line_number':86,'multiline':False]['text':' And finally save your dataset','line_number':94,'multiline':False]['text':' from datasets import load_from_disk','line_number':97,'multiline':False]['text':' dataset = load_from_disk(passages_path)  # to reload the dataset','line_number':98,'multiline':False]['text':'#####################################','line_number':100,'multiline':False]['text':'#####################################','line_number':102,'multiline':False]['text':' Let's use the Faiss implementation of HNSW for fast approximate nearest neighbor search','line_number':104,'multiline':False]['text':' And save the index','line_number':108,'multiline':False]['text':' dataset.load_faiss_index("embeddings", index_path)  # to reload the index','line_number':111,'multiline':False]['text':'#####################################','line_number':113,'multiline':False]['text':'#####################################','line_number':115,'multiline':False]['text':' Easy way to load the model','line_number':117,'multiline':False]['text':' For distributed fine-tuning you'll need to provide the paths instead, as the dataset and the index are loaded separately.','line_number':124,'multiline':False]['text':' retriever = RagRetriever.from_pretrained(rag_model_name, index_name="custom", passages_path=passages_path, index_path=index_path)','line_number':125,'multiline':False]['text':'#####################################','line_number':127,'multiline':False]['text':'#####################################','line_number':129,'multiline':False]