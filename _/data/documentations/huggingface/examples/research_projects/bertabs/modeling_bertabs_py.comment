['text':' MIT License','line_number':1,'multiline':False]['text':' Copyright (c) 2019 Yang Liu and the HuggingFace team','line_number':3,'multiline':False]['text':' Permission is hereby granted, free of charge, to any person obtaining a copy','line_number':5,'multiline':False]['text':' of this software and associated documentation files (the "Software"), to deal','line_number':6,'multiline':False]['text':' in the Software without restriction, including without limitation the rights','line_number':7,'multiline':False]['text':' to use, copy, modify, merge, publish, distribute, sublicense, and/or sell','line_number':8,'multiline':False]['text':' copies of the Software, and to permit persons to whom the Software is','line_number':9,'multiline':False]['text':' furnished to do so, subject to the following conditions:','line_number':10,'multiline':False]['text':' The above copyright notice and this permission notice shall be included in all','line_number':12,'multiline':False]['text':' copies or substantial portions of the Software.','line_number':13,'multiline':False]['text':' THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR','line_number':15,'multiline':False]['text':' IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,','line_number':16,'multiline':False]['text':' FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE','line_number':17,'multiline':False]['text':' AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER','line_number':18,'multiline':False]['text':' LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,','line_number':19,'multiline':False]['text':' OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE','line_number':20,'multiline':False]['text':' SOFTWARE.','line_number':21,'multiline':False]['text':' If pre-trained weights are passed for Bert, load these.','line_number':53,'multiline':False]['text':' Basic attributes.','line_number':161,'multiline':False]['text':' Build TransformerDecoder.','line_number':167,'multiline':False]['text':' forward(input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask)','line_number':174,'multiline':False]['text':' def forward(self, input_ids, state, attention_mask=None, memory_lengths=None,','line_number':175,'multiline':False]['text':' step=None, cache=None, encoder_attention_mask=None, encoder_hidden_states=None, memory_masks=None):','line_number':176,'multiline':False]['text':' Name conversion','line_number':192,'multiline':False]['text':' src_words = state.src','line_number':197,'multiline':False]['text':' Decoder padding mask','line_number':203,'multiline':False]['text':' Encoder padding mask','line_number':208,'multiline':False]['text':' Pass through the embeddings','line_number':215,'multiline':False]['text':' len x batch x embedding_dim','line_number':218,'multiline':False]['text':' Decoders in transformers return a tuple. Beam search will fail','line_number':249,'multiline':False]['text':' if we don't follow this convention.','line_number':250,'multiline':False]['text':' , state','line_number':251,'multiline':False]['text':' Register self.mask as a saved_state in TransformerDecoderLayer, so','line_number':311,'multiline':False]['text':' it gets TransformerDecoderLayer's cuda behavior automatically.','line_number':312,'multiline':False]['text':' return output','line_number':370,'multiline':False]['text':' 1) Project key, value, and query.','line_number':489,'multiline':False]['text':' 2) Calculate and scale scores.','line_number':536,'multiline':False]['text':' 3) Apply attention dropout and compute context vectors.','line_number':544,'multiline':False]['text':'','line_number':687,'multiline':False]['text':' TRANSLATOR','line_number':688,'multiline':False]['text':' The following code is used to generate summaries using the','line_number':689,'multiline':False]['text':' pre-trained weights and beam search.','line_number':690,'multiline':False]['text':'','line_number':691,'multiline':False]['text':' we should be able to refactor the global scorer a lot','line_number':695,'multiline':False]['text':' Where the beam search lives','line_number':825,'multiline':False]['text':' I have no idea why it is being called from the method above','line_number':826,'multiline':False]['text':' The batch object is funny','line_number':830,'multiline':False]['text':' Instead of just looking at the size of the arguments we encapsulate','line_number':831,'multiline':False]['text':' a size argument.','line_number':832,'multiline':False]['text':' Where is it defined?','line_number':833,'multiline':False]['text':' Tile states and memory beam_size times.','line_number':844,'multiline':False]['text':' Give full probability to the first beam on the first step.','line_number':851,'multiline':False]['text':' Structure that holds finished hypotheses.','line_number':854,'multiline':False]['text':' noqa: F812','line_number':855,'multiline':False]['text':' noqa: F812','line_number':858,'multiline':False]['text':' noqa: F812','line_number':859,'multiline':False]['text':' Decoder forward.','line_number':866,'multiline':False]['text':' Generator forward.','line_number':871,'multiline':False]['text':' Multiply probs by the beam probability.','line_number':878,'multiline':False]['text':' Flatten probs into a list of possibilities.','line_number':884,'multiline':False]['text':' Recover log probs.','line_number':907,'multiline':False]['text':' Resolve beam origin and true word ids.','line_number':910,'multiline':False]['text':' Map beam_index to batch_index in the flat representation.','line_number':914,'multiline':False]['text':' Append last prediction.','line_number':918,'multiline':False]['text':' End condition is top beam is finished.','line_number':924,'multiline':False]['text':' Save finished hypotheses.','line_number':926,'multiline':False]['text':' Store finished hypotheses for this batch.','line_number':934,'multiline':False]['text':' If the batch reached the end, save the n_best hypotheses.','line_number':937,'multiline':False]['text':' If all sentences are translated, no need to go further.','line_number':945,'multiline':False]['text':' Remove finished batches for the next step.','line_number':948,'multiline':False]['text':' Reorder states.','line_number':953,'multiline':False]['text':'','line_number':1003,'multiline':False]['text':' Optimizer for training. We keep this here in case we want to add','line_number':1004,'multiline':False]['text':' a finetuning script.','line_number':1005,'multiline':False]['text':'','line_number':1006,'multiline':False]