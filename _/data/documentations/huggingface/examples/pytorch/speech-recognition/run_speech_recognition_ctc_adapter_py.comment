['text':'!/usr/bin/env python','line_number':1,'multiline':False]['text':' coding=utf-8','line_number':2,'multiline':False]['text':' Copyright 2023 The HuggingFace Inc. team. All rights reserved.','line_number':3,'multiline':False]['text':'','line_number':4,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':5,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':6,'multiline':False]['text':' You may obtain a copy of the License at','line_number':7,'multiline':False]['text':'','line_number':8,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':9,'multiline':False]['text':'','line_number':10,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':11,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':12,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':13,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':14,'multiline':False]['text':' limitations under the License.','line_number':15,'multiline':False]['text':' Will error if the minimal version of Transformers is not installed. Remove at your own risks.','line_number':55,'multiline':False]['text':' split inputs and labels since they have to be of different lengths and need','line_number':310,'multiline':False]['text':' different padding methods','line_number':311,'multiline':False]['text':' replace padding with -100 to ignore loss correctly','line_number':329,'multiline':False]['text':' Given training and test labels create vocabulary','line_number':345,'multiline':False]['text':' take union of all unique characters in each dataset','line_number':359,'multiline':False]['text':' replace white space with delimiter token','line_number':366,'multiline':False]['text':' add unk and pad token','line_number':371,'multiline':False]['text':' See all possible arguments in src/transformers/training_args.py','line_number':382,'multiline':False]['text':' or by passing the --help flag to this script.','line_number':383,'multiline':False]['text':' We now keep distinct sets of args, for a cleaner separation of concerns.','line_number':384,'multiline':False]['text':' If we pass only one argument to the script and it's the path to a json file,','line_number':388,'multiline':False]['text':' let's parse it to get our arguments.','line_number':389,'multiline':False]['text':' Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The','line_number':403,'multiline':False]['text':' information sent is the one passed as arguments along with your Python/PyTorch versions.','line_number':404,'multiline':False]['text':' Detecting last checkpoint.','line_number':407,'multiline':False]['text':' Setup logging','line_number':422,'multiline':False]['text':' Log on each process the small summary:','line_number':430,'multiline':False]['text':' Set the verbosity to info of the Transformers logger (on main process only):','line_number':435,'multiline':False]['text':' Set seed before initializing model.','line_number':440,'multiline':False]['text':' 1. First, let's load the dataset','line_number':443,'multiline':False]['text':' 2. We remove some special characters from the datasets','line_number':482,'multiline':False]['text':' that make training complicated and do not help in transcribing the speech','line_number':483,'multiline':False]['text':' E.g. characters, such as `,` and `.` do not really have an acoustic characteristic','line_number':484,'multiline':False]['text':' that could be easily picked up by the model','line_number':485,'multiline':False]['text':' save special tokens for tokenizer','line_number':505,'multiline':False]['text':' 3. Next, let's load the config as we might need it to create','line_number':510,'multiline':False]['text':' the tokenizer','line_number':511,'multiline':False]['text':' load config','line_number':512,'multiline':False]['text':' 4. Next, if no tokenizer file is defined,','line_number':520,'multiline':False]['text':' we create the vocabulary of the model by extracting all unique characters from','line_number':521,'multiline':False]['text':' the training and evaluation datasets','line_number':522,'multiline':False]['text':' We need to make sure that only first rank saves vocabulary','line_number':523,'multiline':False]['text':' make sure all processes wait until vocab is created','line_number':524,'multiline':False]['text':' load vocabulary of other adapter languages so that new language can be appended','line_number':530,'multiline':False]['text':' save vocab in training output dir','line_number':550,'multiline':False]['text':' in shared file-systems it might be the case that','line_number':560,'multiline':False]['text':' two processes try to delete the vocab file at the some time','line_number':561,'multiline':False]['text':' if we doing adapter language training, save','line_number':574,'multiline':False]['text':' vocab with adpter language','line_number':575,'multiline':False]['text':' save vocab dict to be loaded into tokenizer','line_number':579,'multiline':False]['text':' if tokenizer has just been created','line_number':583,'multiline':False]['text':' it is defined by `tokenizer_class` if present in config else by `model_type`','line_number':584,'multiline':False]['text':' 5. Now we can instantiate the feature extractor, tokenizer and model','line_number':594,'multiline':False]['text':' Note for distributed training, the .from_pretrained methods guarantee that only','line_number':595,'multiline':False]['text':' one local process can concurrently download model & vocab.','line_number':596,'multiline':False]['text':' load feature_extractor and tokenizer','line_number':598,'multiline':False]['text':' adapt config','line_number':612,'multiline':False]['text':' create model','line_number':629,'multiline':False]['text':' if attn adapter is defined, freeze all non-adapter weights','line_number':639,'multiline':False]['text':' first we freeze the whole base model','line_number':642,'multiline':False]['text':' next we unfreeze all adapter layers','line_number':645,'multiline':False]['text':' 6. Now we preprocess the datasets including loading the audio, resampling and normalization','line_number':650,'multiline':False]['text':' Thankfully, `datasets` takes care of automatically loading and resampling the audio,','line_number':651,'multiline':False]['text':' so that we just need to set the correct target sampling rate and normalize the input','line_number':652,'multiline':False]['text':' via the `feature_extractor`','line_number':653,'multiline':False]['text':' make sure that dataset decodes audio with correct sampling rate','line_number':655,'multiline':False]['text':' derive max & min input length for sample rate & max duration','line_number':662,'multiline':False]['text':' Preprocessing the datasets.','line_number':668,'multiline':False]['text':' We need to read the audio files as arrays and tokenize the targets.','line_number':669,'multiline':False]['text':' load audio','line_number':671,'multiline':False]['text':' encode targets','line_number':678,'multiline':False]['text':' filter data that is shorter than min_input_length','line_number':693,'multiline':False]['text':' 7. Next, we can prepare the training.','line_number':700,'multiline':False]['text':' Let's use word error rate (WER) as our evaluation metric,','line_number':701,'multiline':False]['text':' instantiate a data collator and the trainer','line_number':702,'multiline':False]['text':' Define evaluation metrics during training, *i.e.* word error rate, character error rate','line_number':704,'multiline':False]['text':' for large datasets it is advised to run the preprocessing on a','line_number':707,'multiline':False]['text':' single machine first with ``args.preprocessing_only`` since there will mostly likely','line_number':708,'multiline':False]['text':' be a timeout when running the script in distributed mode.','line_number':709,'multiline':False]['text':' In a second step ``args.preprocessing_only`` can then be set to `False` to load the','line_number':710,'multiline':False]['text':' cached dataset','line_number':711,'multiline':False]['text':' we do not want to group tokens when computing the metrics','line_number':723,'multiline':False]['text':' Now save everything to be able to create a single processor later','line_number':730,'multiline':False]['text':' make sure all processes wait until data is saved','line_number':731,'multiline':False]['text':' only the main process saves them','line_number':733,'multiline':False]['text':' save feature extractor, tokenizer and config','line_number':735,'multiline':False]['text':' Instantiate custom data collator','line_number':752,'multiline':False]['text':' Initialize Trainer','line_number':755,'multiline':False]['text':' 8. Finally, we can start training','line_number':766,'multiline':False]['text':' Training','line_number':768,'multiline':False]['text':' use last checkpoint if exist','line_number':770,'multiline':False]['text':' Evaluation','line_number':793,'multiline':False]['text':' Write model card and (optionally) push to hub','line_number':806,'multiline':False]['text':' make sure that adapter weights are saved seperately','line_number':821,'multiline':False]