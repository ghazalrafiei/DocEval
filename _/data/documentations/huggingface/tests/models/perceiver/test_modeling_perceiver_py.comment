['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2021 The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' set subsampling for multimodal model (take first chunk)','line_number':129,'multiline':False]['text':' input mask is only relevant for text inputs','line_number':153,'multiline':False]['text':' Byte level vocab','line_number':212,'multiline':False]['text':' we don't test common_properties and arguments_init as these don't apply for Perceiver','line_number':337,'multiline':False]['text':' we overwrite this, as the embeddings of Perceiver are an instance of nn.Parameter','line_number':374,'multiline':False]['text':' and Perceiver doesn't support get_output_embeddings','line_number':375,'multiline':False]['text':' signature.parameters is an OrderedDict => so arg_names order is deterministic','line_number':406,'multiline':False]['text':' model outputs a dictionary with logits per modality, let's verify each modality','line_number':425,'multiline':False]['text':' check expected number of attentions depending on model class','line_number':459,'multiline':False]['text':' we expect to have 2 cross-attentions, namely one in the PerceiverEncoder, and one in PerceiverBasicDecoder','line_number':462,'multiline':False]['text':' we expect to have 2 cross-attentions, namely one in the PerceiverEncoder, and one in PerceiverBasicDecoder','line_number':465,'multiline':False]['text':' check that output_attentions also work using config','line_number':470,'multiline':False]['text':' Check attention is always last and order is fine','line_number':489,'multiline':False]['text':' check that output_hidden_states also work using config','line_number':535,'multiline':False]['text':' optical flow + multimodal models don't support training for now','line_number':589,'multiline':False]['text':' optical flow + multimodal models don't support training for now','line_number':604,'multiline':False]['text':' optical flow + multimodal models don't support training for now','line_number':610,'multiline':False]['text':' optical flow + multimodal models don't support training for now','line_number':616,'multiline':False]['text':' no need to test all models as different heads yield the same functionality','line_number':624,'multiline':False]['text':' Encoder-only model','line_number':639,'multiline':False]['text':' model outputs a dictionary with logits for each modality','line_number':670,'multiline':False]['text':' Make sure we don't have nans','line_number':700,'multiline':False]['text':' Make sure we don't have nans','line_number':717,'multiline':False]['text':' most Perceiver models don't have a typical head like is the case with BERT','line_number':729,'multiline':False]['text':' This tests that we do not trigger the warning form PyTorch "Using a target size that is different','line_number':778,'multiline':False]['text':' to the input size. This will likely lead to incorrect results due to broadcasting. Please ensure','line_number':779,'multiline':False]['text':' they have the same size." which is a symptom something in wrong for the regression problem.','line_number':780,'multiline':False]['text':' See https://github.com/huggingface/transformers/issues/11780','line_number':781,'multiline':False]['text':' We will verify our results on an image of cute cats','line_number':833,'multiline':False]['text':' Helper functions for optical flow integration test','line_number':839,'multiline':False]['text':' Do TF 'SAME' Padding','line_number':853,'multiline':False]['text':' Extract patches','line_number':861,'multiline':False]['text':' prepare inputs','line_number':877,'multiline':False]['text':' mask " missing.".','line_number':881,'multiline':False]['text':' forward pass','line_number':885,'multiline':False]['text':' verify logits','line_number':890,'multiline':False]['text':' prepare inputs','line_number':911,'multiline':False]['text':' forward pass','line_number':916,'multiline':False]['text':' verify logits','line_number':921,'multiline':False]['text':' prepare inputs','line_number':935,'multiline':False]['text':' forward pass','line_number':940,'multiline':False]['text':' verify logits','line_number':945,'multiline':False]['text':' prepare inputs','line_number':959,'multiline':False]['text':' forward pass','line_number':964,'multiline':False]['text':' verify logits','line_number':969,'multiline':False]['text':' prepare inputs','line_number':982,'multiline':False]['text':' stack images','line_number':987,'multiline':False]['text':' extract 3x3 patches','line_number':992,'multiline':False]['text':' forward pass','line_number':1001,'multiline':False]['text':' verify logits','line_number':1006,'multiline':False]