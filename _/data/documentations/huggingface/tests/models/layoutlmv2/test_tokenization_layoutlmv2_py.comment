['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2021 The HuggingFace Inc. team.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' Example taken from the issue https://github.com/huggingface/tokenizers/issues/340','line_number':241,'multiline':False]['text':' We usually have added tokens from the start in tests because our vocab fixtures are','line_number':315,'multiline':False]['text':' smaller than the original vocabs - let's not assert this','line_number':316,'multiline':False]['text':' self.assertEqual(vocab_size, all_size)','line_number':317,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':397,'multiline':False]['text':' Test 'longest' and 'no_padding' don't do anything','line_number':408,'multiline':False]['text':' Test right padding','line_number':441,'multiline':False]['text':' Test left padding','line_number':460,'multiline':False]['text':' test 1: single sequence','line_number':532,'multiline':False]['text':' Method is implemented (e.g. not GPT-2)','line_number':538,'multiline':False]['text':' test 2: two sequences','line_number':544,'multiline':False]['text':' Method is implemented (e.g. not GPT-2)','line_number':550,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':564,'multiline':False]['text':' Check that it correctly pads when a maximum length is specified along with the padding flag set to True','line_number':569,'multiline':False]['text':' FIXME: the next line should be padding(max_length) to avoid warning','line_number':573,'multiline':False]['text':' Check that nothing is done when a maximum length is not specified','line_number':581,'multiline':False]['text':' Encode - Simple input','line_number':600,'multiline':False]['text':' Encode - Pair input','line_number':613,'multiline':False]['text':' Encode_plus - Simple input','line_number':629,'multiline':False]['text':' Encode_plus - Pair input','line_number':648,'multiline':False]['text':' Batch_encode_plus - Simple input','line_number':673,'multiline':False]['text':' Batch_encode_plus - Pair input','line_number':722,'multiline':False]['text':' Using pad on single examples after tokenization','line_number':757,'multiline':False]['text':' Using pad on single examples after tokenization','line_number':769,'multiline':False]['text':' Using pad after tokenization','line_number':778,'multiline':False]['text':' Using pad after tokenization','line_number':794,'multiline':False]['text':' We want to assert there are no warnings, but the 'assertLogs' method does not support that.','line_number':843,'multiline':False]['text':' Therefore, we are adding a dummy warning, and then we will assert it is the only warning.','line_number':844,'multiline':False]['text':' Tests that all call wrap to encode_plus and batch_encode_plus','line_number':854,'multiline':False]['text':' Test not batched','line_number':858,'multiline':False]['text':' Test not batched pairs','line_number':864,'multiline':False]['text':' Test batched','line_number':870,'multiline':False]['text':' Tests that all encoded values have the correct size','line_number':877,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':896,'multiline':False]['text':' check 'longest' is unsensitive to a max length','line_number':914,'multiline':False]['text':' check 'no_padding' is unsensitive to a max length','line_number':927,'multiline':False]['text':' Test that padded sequences are equivalent between batch_encode_plus and encode_plus','line_number':945,'multiline':False]['text':' Right padding tests','line_number':947,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':955,'multiline':False]['text':' Left padding tests','line_number':971,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':980,'multiline':False]['text':' empty_tokens = tokenizer([""], [[]], padding=True, pad_to_multiple_of=8)','line_number':1005,'multiline':False]['text':' for key, value in empty_tokens.items():','line_number':1007,'multiline':False]['text':'     self.assertEqual(len(value) % 8, 0, f"BatchEncoding.{key} is not multiple of 8")','line_number':1008,'multiline':False]['text':' Should also work with truncation','line_number':1016,'multiline':False]['text':' truncation to something which is not a multiple of pad_to_multiple_of raises an error','line_number':1021,'multiline':False]['text':' as we don't have a slow version, we can't compare the outputs between slow and fast versions','line_number':1043,'multiline':False]['text':' Input tokens id','line_number':1051,'multiline':False]['text':' Generate output','line_number':1056,'multiline':False]['text':' Generate pair output','line_number':1061,'multiline':False]['text':' add_prefix_space=False,','line_number':1077,'multiline':False]['text':' Testing single inputs','line_number':1094,'multiline':False]['text':' safety check on max_len default value so we are sure the test works','line_number':1107,'multiline':False]['text':' Now let's start the test','line_number':1113,'multiline':False]['text':' Isolate this from the other tests because we save additional tokens/etc','line_number':1117,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':1141,'multiline':False]['text':' RIGHT PADDING - Check that it correctly pads when a maximum length is specified along with the padding flag set to True','line_number':1146,'multiline':False]['text':' LEFT PADDING - Check that it correctly pads when a maximum length is specified along with the padding flag set to True','line_number':1157,'multiline':False]['text':' RIGHT & LEFT PADDING - Check that nothing is done for 'longest' and 'no_padding'','line_number':1168,'multiline':False]['text':' test 1: single sequence','line_number':1200,'multiline':False]['text':' Assert that the token type IDs have the same length as the input IDs','line_number':1205,'multiline':False]['text':' Assert that the token type IDs have the same length as the attention mask','line_number':1208,'multiline':False]['text':' test 2: two sequences (question + words)','line_number':1214,'multiline':False]['text':' Assert that the token type IDs have the same length as the input IDs','line_number':1219,'multiline':False]['text':' Assert that the token type IDs have the same length as the attention mask','line_number':1222,'multiline':False]['text':' No pair','line_number':1236,'multiline':False]['text':' Assert there is the same number of tokens and offsets','line_number':1247,'multiline':False]['text':' Assert there is online added_tokens special_tokens','line_number':1250,'multiline':False]['text':' Pairs','line_number':1253,'multiline':False]['text':' Assert there is the same number of tokens and offsets','line_number':1268,'multiline':False]['text':' Assert there is online added_tokens special_tokens','line_number':1271,'multiline':False]['text':' Make sure the model contains at least the full vocabulary size in its embedding matrix','line_number':1298,'multiline':False]['text':' Build sequence','line_number':1306,'multiline':False]['text':' We add dummy image keys (as LayoutLMv2 actually also requires a feature extractor','line_number':1313,'multiline':False]['text':' to prepare the image input)','line_number':1314,'multiline':False]['text':' This should not fail','line_number':1318,'multiline':False]['text':' saves some time','line_number':1319,'multiline':False]['text':' as we don't have a slow version, we can't compare the outputs between slow and fast versions','line_number':1328,'multiline':False]['text':' as we don't have a slow version, we can't compare the outputs between slow and fast versions','line_number':1346,'multiline':False]['text':' Ensure basic input match','line_number':1356,'multiline':False]['text':' Ensure truncation match','line_number':1376,'multiline':False]['text':' Ensure truncation with stride match','line_number':1385,'multiline':False]['text':' as we don't have a slow version, we can't compare the outputs between slow and fast versions','line_number':1400,'multiline':False]['text':' tokenize()','line_number':1437,'multiline':False]['text':' encode()','line_number':1442,'multiline':False]['text':' encode_plus()','line_number':1447,'multiline':False]['text':' # batch_encode_plus','line_number':1456,'multiline':False]['text':' Ensure that the input IDs are less than the max length defined.','line_number':1474,'multiline':False]['text':' Ensure that the input IDs are still truncated when no max_length is specified','line_number':1481,'multiline':False]['text':' A Tensor cannot be build by sequences which are not the same size','line_number':1492,'multiline':False]['text':' We want to have sequence 0 and sequence 1 are tagged','line_number':1537,'multiline':False]['text':' respectively with 0 and 1 token_ids','line_number':1538,'multiline':False]['text':' (regardless of whether the model use token type ids)','line_number':1539,'multiline':False]['text':' We use this assumption in the QA pipeline among other place','line_number':1540,'multiline':False]['text':' This feature only exists for fast tokenizers','line_number':1589,'multiline':False]['text':' Test we can use the new tokenizer with something not seen during training','line_number':1596,'multiline':False]['text':' We check that the parameters of the tokenizer remained the same','line_number':1608,'multiline':False]['text':' Check we have the same number of added_tokens for both pair and non-pair inputs.','line_number':1609,'multiline':False]['text':' Check we have the correct max_length for both pair and non-pair inputs.','line_number':1613,'multiline':False]['text':' Assert the set of special tokens match as we didn't ask to change them','line_number':1617,'multiline':False]['text':' This feature only exists for fast tokenizers','line_number':1626,'multiline':False]['text':' Test with a special tokens map','line_number':1631,'multiline':False]['text':' Create a new mapping from the special tokens defined in the original tokenizer','line_number':1641,'multiline':False]['text':' Get the private one to avoid unnecessary warnings.','line_number':1646,'multiline':False]['text':' Train new tokenizer','line_number':1651,'multiline':False]['text':' Check the changes','line_number':1656,'multiline':False]['text':' Get the private one to avoid unnecessary warnings.','line_number':1658,'multiline':False]['text':' Check if the AddedToken / string format has been kept','line_number':1669,'multiline':False]['text':' The special token must appear identically in the list of the new tokenizer.','line_number':1672,'multiline':False]['text':' The special token must appear in the list of the new tokenizer as an object of type AddedToken with','line_number':1678,'multiline':False]['text':' the same parameters as the old AddedToken except the content that the user has requested to change.','line_number':1679,'multiline':False]['text':' The special token must appear identically in the list of the new tokenizer.','line_number':1702,'multiline':False]['text':' The special token must appear in the list of the new tokenizer as an object of type string.','line_number':1709,'multiline':False]['text':' Test we can use the new tokenizer with something not seen during training','line_number':1712,'multiline':False]['text':' only test prepare_for_model for the slow tokenizer','line_number':1727,'multiline':False]['text':' as we don't have a slow version, we can't compare the outputs between slow and fast versions','line_number':1740,'multiline':False]['text':' rename encoded batch to "inputs"','line_number':1755,'multiline':False]['text':' Renaming `input_ids` to `inputs`','line_number':1762,'multiline':False]['text':' Single example','line_number':1796,'multiline':False]['text':' Batch of examples','line_number':1814,'multiline':False]['text':' For these 2 examples, 3 training examples will be created','line_number':1815,'multiline':False]['text':' toks_str = [t[1] for t in toks]','line_number':1854,'multiline':False]['text':' Ensure consistency','line_number':1857,'multiline':False]['text':' @unittest.skip("LayoutLMv2 tokenizer requires boxes besides sequences.")','line_number':1873,'multiline':False]['text':' Build a sequence from our model's vocabulary','line_number':1878,'multiline':False]['text':' We are not using the special tokens - a bit too hard to test all the tokenizers with this','line_number':1907,'multiline':False]['text':' TODO try this again later','line_number':1908,'multiline':False]['text':' , add_prefix_space=False)','line_number':1911,'multiline':False]['text':' Test with max model input length','line_number':1913,'multiline':False]['text':' Simple','line_number':1930,'multiline':False]['text':' Simple','line_number':1958,'multiline':False]['text':' Simple with no truncation','line_number':1971,'multiline':False]['text':' Reset warnings','line_number':1972,'multiline':False]['text':' Check the order of Sequence of input ids, overflowing tokens and bbox sequence with truncation','line_number':2002,'multiline':False]['text':' Overflowing tokens are handled quite differently in slow and fast tokenizers','line_number':2054,'multiline':False]['text':' add_prefix_space=False,','line_number':2065,'multiline':False]['text':' No overflowing tokens when using 'longest' in python tokenizers','line_number':2083,'multiline':False]['text':' add_prefix_space=False,','line_number':2094,'multiline':False]['text':' Overflowing tokens are handled quite differently in slow and fast tokenizers','line_number':2105,'multiline':False]['text':' add_prefix_space=False,','line_number':2116,'multiline':False]['text':' No overflowing tokens when using 'longest' in python tokenizers','line_number':2132,'multiline':False]['text':' add_prefix_space=False,','line_number':2143,'multiline':False]['text':' add_prefix_space=False,','line_number':2163,'multiline':False]['text':' Overflowing tokens are handled quite differently in slow and fast tokenizers','line_number':2165,'multiline':False]['text':' add_prefix_space=False,','line_number':2203,'multiline':False]['text':' Overflowing tokens are handled quite differently in slow and fast tokenizers','line_number':2205,'multiline':False]['text':' @unittest.skip("LayoutLMv2 tokenizer requires boxes besides sequences.")','line_number':2235,'multiline':False]['text':' Test with max model input length','line_number':2249,'multiline':False]['text':' Simple','line_number':2262,'multiline':False]['text':' Simple with no truncation','line_number':2288,'multiline':False]['text':' Reset warnings','line_number':2289,'multiline':False]['text':' Check the order of Sequence of input ids, overflowing tokens and bbox sequence with truncation','line_number':2315,'multiline':False]['text':' add_prefix_space=False,','line_number':2325,'multiline':False]['text':' Overflowing tokens are handled quite differently in slow and fast tokenizers','line_number':2328,'multiline':False]['text':' test slow tokenizer','line_number':2375,'multiline':False]['text':' test fast tokenizer','line_number':2386,'multiline':False]['text':' There are 3 cases:','line_number':2402,'multiline':False]['text':' CASE 1: document image classification (training + inference), document image token classification (inference),','line_number':2403,'multiline':False]['text':' in which case only words and normalized bounding boxes are provided to the tokenizer','line_number':2404,'multiline':False]['text':' CASE 2: document image token classification (training),','line_number':2405,'multiline':False]['text':' in which case one also provides word labels to the tokenizer','line_number':2406,'multiline':False]['text':' CASE 3: document image visual question answering (inference),','line_number':2407,'multiline':False]['text':' in which case one also provides a question to the tokenizer','line_number':2408,'multiline':False]['text':' We need to test all 3 cases both on batched and non-batched inputs.','line_number':2410,'multiline':False]['text':' CASE 1: not batched','line_number':2412,'multiline':False]['text':' fmt: skip','line_number':2415,'multiline':False]['text':' CASE 1: batched','line_number':2422,'multiline':False]['text':' fmt: skip','line_number':2425,'multiline':False]['text':' CASE 2: not batched','line_number':2432,'multiline':False]['text':' fmt: skip','line_number':2436,'multiline':False]['text':' CASE 2: batched','line_number':2443,'multiline':False]['text':' fmt: skip','line_number':2447,'multiline':False]['text':' CASE 3: not batched','line_number':2454,'multiline':False]['text':' fmt: skip','line_number':2457,'multiline':False]['text':' CASE 3: batched','line_number':2464,'multiline':False]['text':' fmt: skip','line_number':2467,'multiline':False]