['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2022 HuggingFace Inc. team.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' Make sure `loss` exist','line_number':241,'multiline':False]['text':' make the decoder inputs a different shape from the encoder inputs to harden the test','line_number':260,'multiline':False]['text':' Generate until max length','line_number':306,'multiline':False]['text':' Bert does not have a bos token id, so use pad_token_id instead','line_number':312,'multiline':False]['text':' Allow `ModelOutput` (e.g. `CLIPOutput` has `text_model_output` and `vision_model_output`).','line_number':336,'multiline':False]['text':' convert to the case of `tuple`','line_number':348,'multiline':False]['text':' appending each key to the current (string) `names`','line_number':349,'multiline':False]['text':' Allow `list` (e.g. `TransfoXLModelOutput.mems` is a list of tensors.)','line_number':355,'multiline':False]['text':' case 1: each output has assigned name (e.g. a tuple form of a `ModelOutput`)','line_number':361,'multiline':False]['text':' case 2: each output has no assigned name (e.g. hidden states of each layer) -> add an index to `names`','line_number':368,'multiline':False]['text':' deal with NumPy's scalars to make replacing nan values by 0 work.','line_number':386,'multiline':False]['text':' other general float inputs','line_number':418,'multiline':False]['text':' send pytorch inputs to the correct device','line_number':429,'multiline':False]['text':' send pytorch model to the correct device','line_number':434,'multiline':False]['text':' Check predictions on first output (logits/hidden-states) are close enough given low-level computational differences','line_number':437,'multiline':False]['text':' tf models returned loss is usually a tensor rather than a scalar.','line_number':444,'multiline':False]['text':' (see `hf_compute_loss`: it uses `tf.keras.losses.Reduction.NONE`)','line_number':445,'multiline':False]['text':' Change it here to a scalar to match PyTorch models' loss','line_number':446,'multiline':False]['text':' PT -> TF','line_number':458,'multiline':False]['text':' Output all for aggressive testing','line_number':467,'multiline':False]['text':' All models tested in this file have attentions','line_number':469,'multiline':False]['text':' Output all for aggressive testing','line_number':482,'multiline':False]['text':' TODO: A generalizable way to determine this attribute','line_number':484,'multiline':False]['text':' Make sure model is built before saving','line_number':488,'multiline':False]['text':' Keep only common arguments','line_number':538,'multiline':False]['text':' Output all for aggressive testing','line_number':552,'multiline':False]['text':' All models tested in this file have attentions','line_number':555,'multiline':False]['text':' `encoder_hidden_states` is not used in model call/forward','line_number':560,'multiline':False]['text':' Make sure no sequence has all zeros as attention mask, otherwise some tests fail due to the inconsistency','line_number':563,'multiline':False]['text':' of the usage `1e-4`, `1e-9`, `1e-30`, `-inf`.','line_number':564,'multiline':False]['text':' Make sure no all 0s attention masks - to avoid failure at this moment.','line_number':568,'multiline':False]['text':' Put `1` at the beginning of sequences to make it still work when combining causal attention masks.','line_number':569,'multiline':False]['text':' TODO: remove this line once a fix regarding large negative values for attention mask is done.','line_number':570,'multiline':False]['text':' Original test: check without `labels` and  without `enc_to_dec_proj` projection','line_number':581,'multiline':False]['text':' check with `labels`','line_number':586,'multiline':False]['text':' check `enc_to_dec_proj` work as expected','line_number':590,'multiline':False]['text':' make sure that cross attention layers are added','line_number':656,'multiline':False]['text':' disable cache for now','line_number':658,'multiline':False]['text':' This is not used in the tests.','line_number':667,'multiline':False]['text':' We will verify our results on an image of cute cats','line_number':707,'multiline':False]['text':' create two random ViT/GPT2 models for vit-gpt2 & initialize weights (+cross_attention weights)','line_number':730,'multiline':False]['text':' create two random ViT/GPT2 models for vit-gpt2 & initialize weights (+cross_attention weights)','line_number':780,'multiline':False]['text':' PyTorch => TensorFlow','line_number':801,'multiline':False]['text':' Make sure `from_pretrained` following `save_pretrained` work and give the same result','line_number':814,'multiline':False]['text':' (See https://github.com/huggingface/transformers/pull/14016)','line_number':815,'multiline':False]['text':' Since most of HF's models don't have pretrained cross-attention layers, they are randomly','line_number':839,'multiline':False]['text':' initialized even if we create models using `from_pretrained` method.','line_number':840,'multiline':False]['text':' For the tests, the decoder need to be a model with pretrained cross-attention layers.','line_number':841,'multiline':False]['text':' So we create pretrained models (without `load_weight_prefix`), save them, and later,','line_number':842,'multiline':False]['text':' we load them using `from_pretrained`.','line_number':843,'multiline':False]['text':' (we don't need to do this for encoder, but let's make the code more similar between encoder/decoder)','line_number':844,'multiline':False]['text':' It's necessary to specify `add_cross_attention=True` here.','line_number':846,'multiline':False]['text':' check that the from pretrained methods work','line_number':861,'multiline':False]['text':' Create the model using `__init__` with loaded ``pretrained`` encoder / decoder','line_number':870,'multiline':False]['text':' We will verify our results on an image of cute cats','line_number':900,'multiline':False]['text':' verify the logits','line_number':908,'multiline':False]['text':' should produce','line_number':939,'multiline':False]['text':' ["a cat laying on top of a couch next to another cat"]','line_number':940,'multiline':False]