['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2021 The HuggingFace Inc. team. All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' this is most likely not correctly set yet','line_number':64,'multiline':False]['text':' test does not pass for models making use of `group_norm`','line_number':140,'multiline':False]['text':' check: https://github.com/pytorch/fairseq/issues/3227','line_number':141,'multiline':False]['text':' convert values that are over input_lengths to padding','line_number':151,'multiline':False]['text':' convert values that are over input_lengths to padding','line_number':176,'multiline':False]['text':' freeze feature encoder','line_number':191,'multiline':False]['text':' overwrite because input_values != input_ids','line_number':240,'multiline':False]['text':' signature.parameters is an OrderedDict => so arg_names order is deterministic','line_number':247,'multiline':False]['text':' overwrite because input_values != input_ids','line_number':253,'multiline':False]['text':' TODO: (Amy) - check whether skipping CTC model resolves this issue and possible resolutions for CTC','line_number':332,'multiline':False]['text':' TODO: (Amy) - check whether skipping CTC model resolves this issue and possible resolutions for CTC','line_number':337,'multiline':False]['text':' We override the base test here to skip loss calculation for Hubert models because the loss is massive with','line_number':342,'multiline':False]['text':' the default labels and frequently overflows to inf or exceeds numerical tolerances between TF/PT','line_number':343,'multiline':False]['text':' Output all for aggressive testing','line_number':351,'multiline':False]['text':' Make sure no sequence has all zeros as attention mask, otherwise some tests fail due to the inconsistency','line_number':355,'multiline':False]['text':' of the usage `1e-4`, `1e-9`, `1e-30`, `-inf`.','line_number':356,'multiline':False]['text':' TODO: Use a uniform value for all models, make sure all tests pass without this processing, and remove it.','line_number':357,'multiline':False]['text':' Skip the "TF" at the beginning','line_number':360,'multiline':False]['text':' Check we can load pt model in tf and vice-versa with model => model functions','line_number':368,'multiline':False]['text':' Original test: check without `labels`','line_number':376,'multiline':False]['text':' Check we can load pt model in tf and vice-versa with checkpoint => model functions','line_number':379,'multiline':False]['text':' Original test: check without `labels`','line_number':393,'multiline':False]['text':' overwrite because input_values != input_ids','line_number':414,'multiline':False]['text':' signature.parameters is an OrderedDict => so arg_names order is deterministic','line_number':421,'multiline':False]['text':' overwrite because input_values != input_ids','line_number':427,'multiline':False]['text':' TODO: (Amy) - check whether skipping CTC model resolves this issue and possible resolutions for CTC','line_number':513,'multiline':False]['text':' TODO: (Amy) - check whether skipping CTC model resolves this issue and possible resolutions for CTC','line_number':518,'multiline':False]['text':' We override the base test here to skip loss calculation for Hubert models because the loss is massive with','line_number':523,'multiline':False]['text':' the default labels and frequently overflows to inf or exceeds numerical tolerances between TF/PT','line_number':524,'multiline':False]['text':' Output all for aggressive testing','line_number':532,'multiline':False]['text':' Make sure no sequence has all zeros as attention mask, otherwise some tests fail due to the inconsistency','line_number':536,'multiline':False]['text':' of the usage `1e-4`, `1e-9`, `1e-30`, `-inf`.','line_number':537,'multiline':False]['text':' TODO: Use a uniform value for all models, make sure all tests pass without this processing, and remove it.','line_number':538,'multiline':False]['text':' Skip the "TF" at the beginning','line_number':541,'multiline':False]['text':' Check we can load pt model in tf and vice-versa with model => model functions','line_number':549,'multiline':False]['text':' Original test: check without `labels`','line_number':557,'multiline':False]['text':' Check we can load pt model in tf and vice-versa with checkpoint => model functions','line_number':560,'multiline':False]['text':' Original test: check without `labels`','line_number':574,'multiline':False]['text':' because of overlap mask don't have to add up exactly to `mask_prob * sequence_length`, but have to be smaller or equal','line_number':600,'multiline':False]['text':' automatic decoding with librispeech','line_number':613,'multiline':False]