['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2020 HuggingFace Inc. team.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' Test passing encoder_outputs as tuple.','line_number':145,'multiline':False]['text':' BartConfig has no hidden_dropout_prob.','line_number':178,'multiline':False]['text':' check that backprop works','line_number':344,'multiline':False]['text':' make the decoder inputs a different shape from the encoder inputs to harden the test','line_number':400,'multiline':False]['text':' Similar to `check_encoder_decoder_model_output_attentions`, but with `output_attentions` triggered from the','line_number':429,'multiline':False]['text':' config file. Contrarily to most models, changing the model's config won't work -- the defaults are loaded','line_number':430,'multiline':False]['text':' from the inner models' configurations.','line_number':431,'multiline':False]['text':' model config -> won't work','line_number':437,'multiline':False]['text':' inner model config -> will work','line_number':452,'multiline':False]['text':' Generate until max length','line_number':471,'multiline':False]['text':' Bert does not have a bos token id, so use pad_token_id instead','line_number':478,'multiline':False]['text':' load state dict copies weights but does not tie them','line_number':501,'multiline':False]['text':' check that models has less parameters','line_number':528,'multiline':False]['text':' check that outputs are equal','line_number':532,'multiline':False]['text':' check that outputs after saving and loading are equal','line_number':539,'multiline':False]['text':' check that models has less parameters','line_number':546,'multiline':False]['text':' check that outputs are equal','line_number':559,'multiline':False]['text':' make sure that cross attention layers are added','line_number':706,'multiline':False]['text':' Assert that the warning does not show up since a default decoder_attention_mask should have been created.','line_number':807,'multiline':False]['text':' Create a new attention mask that ignores padding, and test that the loss differs for this new attention mask','line_number':810,'multiline':False]['text':' and the default attention mask.','line_number':811,'multiline':False]['text':' make sure that cross attention layers are added','line_number':851,'multiline':False]['text':' make sure that cross attention layers are added','line_number':922,'multiline':False]['text':' make sure that cross attention layers are added','line_number':977,'multiline':False]['text':'  disable cache for now','line_number':979,'multiline':False]['text':' make sure that cross attention layers are added','line_number':1053,'multiline':False]['text':'  disable cache for now','line_number':1055,'multiline':False]['text':' make sure that cross attention layers are added','line_number':1109,'multiline':False]['text':'  disable cache for now','line_number':1111,'multiline':False]