['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2021 The HuggingFace Team. All rights reserved.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' Copied from tests.models.whisper.test_feature_extraction_whisper.floats_list','line_number':42,'multiline':False]['text':' TODO(PVP) - change to facebook','line_number':78,'multiline':False]['text':' TODO(PVP) - change to facebook','line_number':91,'multiline':False]['text':' Tests that all call wrap to encode_plus and batch_encode_plus','line_number':152,'multiline':False]['text':' create three inputs of length 800, 1000, and 1200','line_number':154,'multiline':False]['text':' Test not batched input','line_number':158,'multiline':False]['text':' Test batched','line_number':163,'multiline':False]['text':' Test 2-D numpy arrays are batched.','line_number':169,'multiline':False]['text':' padding should be 0.0','line_number':207,'multiline':False]['text':' padding should be 0.0','line_number':216,'multiline':False]['text':' padding should be 0.0','line_number':228,'multiline':False]['text':' Checks everything loads correctly in the same way','line_number':247,'multiline':False]['text':' Check special tokens are set accordingly on Rust and Python','line_number':250,'multiline':False]['text':' Isolate this from the other tests because we save additional tokens/etc','line_number':271,'multiline':False]['text':' Isolate this from the other tests because we save additional tokens/etc','line_number':290,'multiline':False]['text':' default case -> no attention_mask is returned','line_number':341,'multiline':False]['text':' wav2vec2-lv60 -> return attention_mask','line_number':346,'multiline':False]['text':' this test makes sure that models that are using','line_number':357,'multiline':False]['text':' group norm don't have their tokenizer return the','line_number':358,'multiline':False]['text':' attention_mask','line_number':359,'multiline':False]['text':' only "layer" feature extraction norm should make use of','line_number':364,'multiline':False]['text':' attention_mask','line_number':365,'multiline':False]['text':' check adding a single token','line_number':393,'multiline':False]['text':' check adding a single token','line_number':409,'multiline':False]['text':' fmt: off','line_number':437,'multiline':False]['text':' fmt: on','line_number':446,'multiline':False]['text':' fmt: off','line_number':458,'multiline':False]['text':' fmt: on','line_number':463,'multiline':False]['text':' , unk_token="<unk>")','line_number':477,'multiline':False]['text':' fmt: off','line_number':496,'multiline':False]['text':' HEEEEE||LLL<pad>LO<unk> => HE LLO<unk>','line_number':497,'multiline':False]['text':' 1H + 5E + 2| + 3L + 1<pad> + 1L + 1O + 1<unk>','line_number':498,'multiline':False]['text':' fmt: on','line_number':500,'multiline':False]['text':' check Wav2Vec2CTCTokenizerOutput keys for char','line_number':503,'multiline':False]['text':' check Wav2Vec2CTCTokenizerOutput keys for word','line_number':510,'multiline':False]['text':' check Wav2Vec2CTCTokenizerOutput keys for both','line_number':517,'multiline':False]['text':' check that order of chars is correct and identical for both outputs','line_number':524,'multiline':False]['text':' check that order of words is correct and identical to both outputs','line_number':534,'multiline':False]['text':' check that offsets are actually correct for char','line_number':542,'multiline':False]['text':' 0 is H, 1 is E, 6 is | (" "),  8 is 1st L,  12 is 2nd L, 13 is O, 14 is <unk>','line_number':543,'multiline':False]['text':' 1 is H, 6 is E, 8 is | (" "),  11 is 1st L (note due to <pad>','line_number':545,'multiline':False]['text':' different begin of 2nd L), 13 is 2nd L, 14 is O, 15 is <unk>','line_number':546,'multiline':False]['text':' check that offsets are actually correct for word','line_number':549,'multiline':False]['text':' H is at 1st position of first word, first L is at 8th position of second word','line_number':550,'multiline':False]['text':' last E is at 6th position of first word, first L is at last (15th) position of second word','line_number':552,'multiline':False]['text':' Double spaces don't get counted','line_number':572,'multiline':False]['text':' transform list to ModelOutput','line_number':598,'multiline':False]['text':' fmt: off','line_number':614,'multiline':False]['text':' fmt: on','line_number':619,'multiline':False]['text':' We assume that `decode` works as expected. All we will check now is','line_number':621,'multiline':False]['text':' the output type is correct and the output is identical to `decode`','line_number':622,'multiline':False]['text':' char','line_number':624,'multiline':False]['text':' word','line_number':629,'multiline':False]['text':' both','line_number':634,'multiline':False]['text':' pred_ids correspond to the following code','line_number':641,'multiline':False]['text':' ```','line_number':642,'multiline':False]['text':'        from transformers import AutoTokenizer, AutoFeatureExtractor, AutoModelForCTC','line_number':643,'multiline':False]['text':'        from datasets import load_dataset','line_number':644,'multiline':False]['text':'        import datasets','line_number':645,'multiline':False]['text':'        import torch','line_number':646,'multiline':False]['text':'        model = AutoModelForCTC.from_pretrained("facebook/wav2vec2-base-960h")','line_number':647,'multiline':False]['text':'        feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")','line_number':648,'multiline':False]['text':'','line_number':649,'multiline':False]['text':'        ds = load_dataset("common_voice", "en", split="train", streaming=True)','line_number':650,'multiline':False]['text':'        ds = ds.cast_column("audio", datasets.Audio(sampling_rate=16_000))','line_number':651,'multiline':False]['text':'        ds_iter = iter(ds)','line_number':652,'multiline':False]['text':'        sample = next(ds_iter)','line_number':653,'multiline':False]['text':'','line_number':654,'multiline':False]['text':'        input_values = feature_extractor(sample["audio"]["array"], return_tensors="pt").input_values','line_number':655,'multiline':False]['text':'        logits = model(input_values).logits','line_number':656,'multiline':False]['text':'        pred_ids = torch.argmax(logits, axis=-1).cpu().tolist()','line_number':657,'multiline':False]['text':' ```','line_number':658,'multiline':False]['text':' fmt: off','line_number':659,'multiline':False]['text':' wav2vec2-base downsamples input audio by a factor of 320','line_number':662,'multiline':False]['text':' sampling rate for wav2vec2-base is 16_000','line_number':663,'multiline':False]['text':' fmt: on','line_number':673,'multiline':False]['text':' let's transform offsets to time stamps in seconds','line_number':685,'multiline':False]['text':' NOTE: you can verify the above results by checking out the dataset viewer','line_number':692,'multiline':False]['text':' on https://huggingface.co/datasets/common_voice/viewer/en/train and','line_number':693,'multiline':False]['text':' downloading / playing the sample `common_voice_en_100038.mp3`. As','line_number':694,'multiline':False]['text':' you can hear the time-stamps match more or less','line_number':695,'multiline':False]['text':' Wav2Vec2Model has no max model length => no testing','line_number':706,'multiline':False]['text':' overwrite from test_tokenization_common','line_number':709,'multiline':False]['text':' We usually have added tokens from the start in tests because our vocab fixtures are','line_number':719,'multiline':False]['text':' smaller than the original vocabs - let's not assert this','line_number':720,'multiline':False]['text':' self.assertEqual(vocab_size, all_size)','line_number':721,'multiline':False]['text':' The default common tokenizer tests assumes that the output of `convert_tokens_to_string` is a string which','line_number':773,'multiline':False]['text':' is not the case for Wav2vec2.','line_number':774,'multiline':False]['text':' should have saved target lang as "ita" since it was last one','line_number':821,'multiline':False]