['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2021 The HuggingFace Inc. team.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' We have a SentencePiece fixture for testing','line_number':100,'multiline':False]['text':' override test in `test_tokenization_common.py` because of the required input format of the `__call__`` method of','line_number':109,'multiline':False]['text':' this tokenizer','line_number':110,'multiline':False]['text':' We want to verify that we will be able to save the tokenizer even if the original files that were used to','line_number':114,'multiline':False]['text':' build the tokenizer have been deleted in the meantime.','line_number':115,'multiline':False]['text':' We usually have added tokens from the start in tests because our vocab fixtures are','line_number':231,'multiline':False]['text':' smaller than the original vocabs - let's not assert this','line_number':232,'multiline':False]['text':' self.assertEqual(vocab_size, all_size)','line_number':233,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':305,'multiline':False]['text':' Test 'longest' and 'no_padding' don't do anything','line_number':316,'multiline':False]['text':' Test right padding','line_number':349,'multiline':False]['text':' Test left padding','line_number':368,'multiline':False]['text':' test 1: single sequence','line_number':440,'multiline':False]['text':' Method is implemented (e.g. not GPT-2)','line_number':446,'multiline':False]['text':' test 2: two sequences','line_number':452,'multiline':False]['text':' Method is implemented (e.g. not GPT-2)','line_number':458,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':472,'multiline':False]['text':' Check that it correctly pads when a maximum length is specified along with the padding flag set to True','line_number':477,'multiline':False]['text':' FIXME: the next line should be padding(max_length) to avoid warning','line_number':481,'multiline':False]['text':' Check that nothing is done when a maximum length is not specified','line_number':489,'multiline':False]['text':' Encode - Simple input','line_number':508,'multiline':False]['text':' Encode - Pair input','line_number':521,'multiline':False]['text':' Encode_plus - Simple input','line_number':537,'multiline':False]['text':' Encode_plus - Pair input','line_number':556,'multiline':False]['text':' Batch_encode_plus - Simple input','line_number':581,'multiline':False]['text':' Batch_encode_plus - Pair input','line_number':630,'multiline':False]['text':' Using pad on single examples after tokenization','line_number':665,'multiline':False]['text':' Using pad on single examples after tokenization','line_number':677,'multiline':False]['text':' Using pad after tokenization','line_number':686,'multiline':False]['text':' Using pad after tokenization','line_number':702,'multiline':False]['text':' We want to assert there are no warnings, but the 'assertLogs' method does not support that.','line_number':751,'multiline':False]['text':' Therefore, we are adding a dummy warning, and then we will assert it is the only warning.','line_number':752,'multiline':False]['text':' Tests that all call wrap to encode_plus and batch_encode_plus','line_number':762,'multiline':False]['text':' Test not batched','line_number':766,'multiline':False]['text':' Test not batched pairs','line_number':772,'multiline':False]['text':' Test batched','line_number':778,'multiline':False]['text':' Tests that all encoded values have the correct size','line_number':785,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':804,'multiline':False]['text':' check 'longest' is unsensitive to a max length','line_number':822,'multiline':False]['text':' check 'no_padding' is unsensitive to a max length','line_number':835,'multiline':False]['text':' Test that padded sequences are equivalent between batch_encode_plus and encode_plus','line_number':853,'multiline':False]['text':' Right padding tests','line_number':855,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':863,'multiline':False]['text':' Left padding tests','line_number':879,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':888,'multiline':False]['text':' empty_tokens = tokenizer([""], [[]], padding=True, pad_to_multiple_of=8)','line_number':913,'multiline':False]['text':' for key, value in empty_tokens.items():','line_number':915,'multiline':False]['text':'     self.assertEqual(len(value) % 8, 0, f"BatchEncoding.{key} is not multiple of 8")','line_number':916,'multiline':False]['text':' Should also work with truncation','line_number':924,'multiline':False]['text':' truncation to something which is not a multiple of pad_to_multiple_of raises an error','line_number':929,'multiline':False]['text':' as we don't have a slow version, we can't compare the outputs between slow and fast versions','line_number':951,'multiline':False]['text':' Input tokens id','line_number':959,'multiline':False]['text':' Generate output','line_number':964,'multiline':False]['text':' Generate pair output','line_number':969,'multiline':False]['text':' add_prefix_space=False,','line_number':985,'multiline':False]['text':' Testing single inputs','line_number':1002,'multiline':False]['text':' safety check on max_len default value so we are sure the test works','line_number':1015,'multiline':False]['text':' Now let's start the test','line_number':1021,'multiline':False]['text':' Isolate this from the other tests because we save additional tokens/etc','line_number':1025,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':1053,'multiline':False]['text':' RIGHT PADDING - Check that it correctly pads when a maximum length is specified along with the padding flag set to True','line_number':1058,'multiline':False]['text':' LEFT PADDING - Check that it correctly pads when a maximum length is specified along with the padding flag set to True','line_number':1069,'multiline':False]['text':' RIGHT & LEFT PADDING - Check that nothing is done for 'longest' and 'no_padding'','line_number':1080,'multiline':False]['text':' test 1: single sequence','line_number':1112,'multiline':False]['text':' Assert that the token type IDs have the same length as the input IDs','line_number':1117,'multiline':False]['text':' Assert that the token type IDs have the same length as the attention mask','line_number':1120,'multiline':False]['text':' test 2: two sequences (question + words)','line_number':1126,'multiline':False]['text':' Assert that the token type IDs have the same length as the input IDs','line_number':1131,'multiline':False]['text':' Assert that the token type IDs have the same length as the attention mask','line_number':1134,'multiline':False]['text':' No pair','line_number':1148,'multiline':False]['text':' Assert there is the same number of tokens and offsets','line_number':1159,'multiline':False]['text':' Assert there is online added_tokens special_tokens','line_number':1162,'multiline':False]['text':' Pairs','line_number':1165,'multiline':False]['text':' Assert there is the same number of tokens and offsets','line_number':1180,'multiline':False]['text':' Assert there is online added_tokens special_tokens','line_number':1183,'multiline':False]['text':' Make sure the model contains at least the full vocabulary size in its embedding matrix','line_number':1209,'multiline':False]['text':' Build sequence','line_number':1217,'multiline':False]['text':' This should not fail','line_number':1223,'multiline':False]['text':' saves some time','line_number':1225,'multiline':False]['text':' as we don't have a slow version, we can't compare the outputs between slow and fast versions','line_number':1234,'multiline':False]['text':' as we don't have a slow version, we can't compare the outputs between slow and fast versions','line_number':1252,'multiline':False]['text':' Ensure basic input match','line_number':1262,'multiline':False]['text':' Ensure truncation match','line_number':1282,'multiline':False]['text':' Ensure truncation with stride match','line_number':1291,'multiline':False]['text':' as we don't have a slow version, we can't compare the outputs between slow and fast versions','line_number':1306,'multiline':False]['text':' tokenize()','line_number':1343,'multiline':False]['text':' encode()','line_number':1348,'multiline':False]['text':' encode_plus()','line_number':1353,'multiline':False]['text':' # batch_encode_plus','line_number':1362,'multiline':False]['text':' Ensure that the input IDs are less than the max length defined.','line_number':1380,'multiline':False]['text':' Ensure that the input IDs are still truncated when no max_length is specified','line_number':1387,'multiline':False]['text':' A Tensor cannot be build by sequences which are not the same size','line_number':1398,'multiline':False]['text':' We want to have sequence 0 and sequence 1 are tagged','line_number':1443,'multiline':False]['text':' respectively with 0 and 1 token_ids','line_number':1444,'multiline':False]['text':' (regardless of whether the model use token type ids)','line_number':1445,'multiline':False]['text':' We use this assumption in the QA pipeline among other place','line_number':1446,'multiline':False]['text':' This feature only exists for fast tokenizers','line_number':1495,'multiline':False]['text':' Test we can use the new tokenizer with something not seen during training','line_number':1502,'multiline':False]['text':' We check that the parameters of the tokenizer remained the same','line_number':1514,'multiline':False]['text':' Check we have the same number of added_tokens for both pair and non-pair inputs.','line_number':1515,'multiline':False]['text':' Check we have the correct max_length for both pair and non-pair inputs.','line_number':1519,'multiline':False]['text':' Assert the set of special tokens match as we didn't ask to change them','line_number':1523,'multiline':False]['text':' This feature only exists for fast tokenizers','line_number':1532,'multiline':False]['text':' Test with a special tokens map','line_number':1537,'multiline':False]['text':' Create a new mapping from the special tokens defined in the original tokenizer','line_number':1547,'multiline':False]['text':' Get the private one to avoid unnecessary warnings.','line_number':1552,'multiline':False]['text':' Train new tokenizer','line_number':1557,'multiline':False]['text':' Check the changes','line_number':1562,'multiline':False]['text':' Get the private one to avoid unnecessary warnings.','line_number':1564,'multiline':False]['text':' Check if the AddedToken / string format has been kept','line_number':1575,'multiline':False]['text':' The special token must appear identically in the list of the new tokenizer.','line_number':1578,'multiline':False]['text':' The special token must appear in the list of the new tokenizer as an object of type AddedToken with','line_number':1584,'multiline':False]['text':' the same parameters as the old AddedToken except the content that the user has requested to change.','line_number':1585,'multiline':False]['text':' The special token must appear identically in the list of the new tokenizer.','line_number':1608,'multiline':False]['text':' The special token must appear in the list of the new tokenizer as an object of type string.','line_number':1615,'multiline':False]['text':' Test we can use the new tokenizer with something not seen during training','line_number':1618,'multiline':False]['text':' only test prepare_for_model for the slow tokenizer','line_number':1633,'multiline':False]['text':' as we don't have a slow version, we can't compare the outputs between slow and fast versions','line_number':1646,'multiline':False]['text':' rename encoded batch to "inputs"','line_number':1661,'multiline':False]['text':' Renaming `input_ids` to `inputs`','line_number':1668,'multiline':False]['text':' Single example','line_number':1702,'multiline':False]['text':' Batch of examples','line_number':1720,'multiline':False]['text':' For these 2 examples, 3 training examples will be created','line_number':1721,'multiline':False]['text':' overwrite from test_tokenization_common to speed up test','line_number':1741,'multiline':False]['text':' as we don't have a slow version, we can't compare the outputs between slow and fast versions','line_number':1744,'multiline':False]['text':' Checks it save with the same files + the tokenizer.json file for the fast one','line_number':1758,'multiline':False]['text':' Checks everything loads correctly in the same way','line_number':1763,'multiline':False]['text':' Check special tokens are set accordingly on Rust and Python','line_number':1767,'multiline':False]['text':' self.assertEqual(getattr(tokenizer_rp, key), getattr(tokenizer_pp, key))','line_number':1770,'multiline':False]['text':' self.assertEqual(getattr(tokenizer_rp, key + "_id"), getattr(tokenizer_pp, key + "_id"))','line_number':1771,'multiline':False]['text':' Save tokenizer rust, legacy_format=True','line_number':1775,'multiline':False]['text':' Checks it save with the same files','line_number':1781,'multiline':False]['text':' Checks everything loads correctly in the same way','line_number':1784,'multiline':False]['text':' Check special tokens are set accordingly on Rust and Python','line_number':1788,'multiline':False]['text':' Save tokenizer rust, legacy_format=False','line_number':1794,'multiline':False]['text':' Checks it saved the tokenizer.json file','line_number':1800,'multiline':False]['text':' Checks everything loads correctly in the same way','line_number':1803,'multiline':False]['text':' Check special tokens are set accordingly on Rust and Python','line_number':1807,'multiline':False]['text':' test slow tokenizer','line_number':1843,'multiline':False]['text':' test fast tokenizer','line_number':1852,'multiline':False]['text':' There are 3 cases:','line_number':1866,'multiline':False]['text':' CASE 1: document image classification (training + inference), document image token classification (inference),','line_number':1867,'multiline':False]['text':' in which case only words and normalized bounding boxes are provided to the tokenizer','line_number':1868,'multiline':False]['text':' CASE 2: document image token classification (training),','line_number':1869,'multiline':False]['text':' in which case one also provides word labels to the tokenizer','line_number':1870,'multiline':False]['text':' CASE 3: document image visual question answering (inference),','line_number':1871,'multiline':False]['text':' in which case one also provides a question to the tokenizer','line_number':1872,'multiline':False]['text':' We need to test all 3 cases both on batched and non-batched inputs.','line_number':1874,'multiline':False]['text':' CASE 1: not batched','line_number':1876,'multiline':False]['text':' fmt: skip','line_number':1879,'multiline':False]['text':' CASE 1: batched','line_number':1886,'multiline':False]['text':' fmt: skip','line_number':1889,'multiline':False]['text':' CASE 2: not batched','line_number':1896,'multiline':False]['text':' fmt: skip','line_number':1900,'multiline':False]['text':' CASE 2: batched','line_number':1907,'multiline':False]['text':' fmt: skip','line_number':1911,'multiline':False]['text':' CASE 3: not batched','line_number':1918,'multiline':False]['text':' fmt: skip','line_number':1921,'multiline':False]['text':' CASE 3: batched','line_number':1928,'multiline':False]['text':' fmt: skip','line_number':1931,'multiline':False]