['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2020 The HuggingFace Inc. team.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' Make sure the model contains at least the full vocabulary size in its embedding matrix','line_number':170,'multiline':False]['text':' Build sequence','line_number':173,'multiline':False]['text':' This should not fail','line_number':180,'multiline':False]['text':' With lower casing','line_number':206,'multiline':False]['text':' Example taken from the issue https://github.com/huggingface/tokenizers/issues/340','line_number':334,'multiline':False]['text':' We usually have added tokens from the start in tests because our vocab fixtures are','line_number':430,'multiline':False]['text':' smaller than the original vocabs - let's not assert this','line_number':431,'multiline':False]['text':' self.assertEqual(vocab_size, all_size)','line_number':432,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':499,'multiline':False]['text':' Test 'longest' and 'no_padding' don't do anything','line_number':511,'multiline':False]['text':' Test right padding','line_number':544,'multiline':False]['text':' Test left padding','line_number':563,'multiline':False]['text':' Method is implemented (e.g. not GPT-2)','line_number':648,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':663,'multiline':False]['text':' Check that it correctly pads when a maximum length is specified along with the padding flag set to True','line_number':668,'multiline':False]['text':' FIXME: the next line should be padding(max_length) to avoid warning','line_number':672,'multiline':False]['text':' Check that nothing is done when a maximum length is not specified','line_number':680,'multiline':False]['text':' Tests that all call wrap to encode_plus and batch_encode_plus','line_number':691,'multiline':False]['text':' Test not batched','line_number':701,'multiline':False]['text':' Test not batched pairs','line_number':707,'multiline':False]['text':' Test batched','line_number':713,'multiline':False]['text':' Tests that all encoded values have the correct size','line_number':720,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':741,'multiline':False]['text':' check 'longest' is unsensitive to a max length','line_number':755,'multiline':False]['text':' check 'no_padding' is unsensitive to a max length','line_number':766,'multiline':False]['text':' Test that padded sequences are equivalent between batch_encode_plus and encode_plus','line_number':782,'multiline':False]['text':' Right padding tests','line_number':784,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':797,'multiline':False]['text':' Left padding tests','line_number':811,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':824,'multiline':False]['text':' Should also work with truncation','line_number':857,'multiline':False]['text':' add_prefix_space=False,','line_number':888,'multiline':False]['text':' Testing single inputs','line_number':906,'multiline':False]['text':' safety check on max_len default value so we are sure the test works','line_number':919,'multiline':False]['text':' Now let's start the test','line_number':925,'multiline':False]['text':' Isolate this from the other tests because we save additional tokens/etc','line_number':929,'multiline':False]['text':' check correct behaviour if no pad_token_id exists and add it eventually','line_number':958,'multiline':False]['text':' RIGHT PADDING - Check that it correctly pads when a maximum length is specified along with the padding flag set to True','line_number':963,'multiline':False]['text':' LEFT PADDING - Check that it correctly pads when a maximum length is specified along with the padding flag set to True','line_number':974,'multiline':False]['text':' RIGHT & LEFT PADDING - Check that nothing is done for 'longest' and 'no_padding'','line_number':985,'multiline':False]['text':' We want to have sequence 0 and sequence 1 are tagged','line_number':1020,'multiline':False]['text':' respectively with 0 and 1 token_ids','line_number':1021,'multiline':False]['text':' (regardless of whether the model use token type ids)','line_number':1022,'multiline':False]['text':' We use this assumption in the QA pipeline among other place','line_number':1023,'multiline':False]['text':' Assert that the token type IDs have the same length as the input IDs','line_number':1026,'multiline':False]['text':' Assert that each token type ID has 7 values','line_number':1029,'multiline':False]['text':' Do the same test as modeling common.','line_number':1032,'multiline':False]['text':' Make sure the model contains at least the full vocabulary size in its embedding matrix','line_number':1059,'multiline':False]['text':' Build sequence','line_number':1067,'multiline':False]['text':' This should not fail','line_number':1073,'multiline':False]['text':' saves some time','line_number':1075,'multiline':False]['text':' The table cannot even encode the headers, so raise an error','line_number':1101,'multiline':False]['text':' Ensure that the input IDs are less than the max length defined.','line_number':1110,'multiline':False]['text':' Ensure that the input IDs are still truncated when no max_length is specified','line_number':1117,'multiline':False]['text':' test max_question_length','line_number':1132,'multiline':False]['text':' query should not be tokenized as it's longer than the specified max_question_length','line_number':1137,'multiline':False]['text':' test min_question_length','line_number':1142,'multiline':False]['text':' query should not be tokenized as it's shorter than the specified min_question_length','line_number':1147,'multiline':False]['text':' A Tensor cannot be build by sequences which are not the same size','line_number':1165,'multiline':False]['text':' fmt: skip','line_number':1217,'multiline':False]['text':' fmt: skip','line_number':1259,'multiline':False]