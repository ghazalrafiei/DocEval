['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2022 The HuggingFace Team Inc.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a clone of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' We keep the constants inside the init function and model loading inside setUp function','line_number':77,'multiline':False]['text':' We need to test on relatively large models (aka >1b parameters otherwise the quantiztion may not work as expected)','line_number':79,'multiline':False]['text':' Therefore here we use only bloom-1b3 to test our module','line_number':80,'multiline':False]['text':' Constant values','line_number':83,'multiline':False]['text':' This was obtained on a RTX Titan so the number might slightly change','line_number':85,'multiline':False]['text':' Models and tokenizer','line_number':96,'multiline':False]['text':' Models and tokenizer','line_number':104,'multiline':False]['text':' 4-bit parameters are packed in uint8 variables','line_number':180,'multiline':False]['text':' Tries with `str`','line_number':256,'multiline':False]['text':' Tries with a `dtype``','line_number':260,'multiline':False]['text':' Tries with a `device`','line_number':264,'multiline':False]['text':' Tries with a `device`','line_number':268,'multiline':False]['text':' Tries with a `device`','line_number':272,'multiline':False]['text':' Test if we did not break anything','line_number':275,'multiline':False]['text':' Check this does not throw an error','line_number':281,'multiline':False]['text':' Check this does not throw an error','line_number':284,'multiline':False]['text':' Check this does not throw an error','line_number':287,'multiline':False]['text':' flan-t5 uses dense-act instead of dense-relu-dense','line_number':307,'multiline':False]['text':' test with `t5-small`','line_number':330,'multiline':False]['text':' test with `flan-t5-small`','line_number':335,'multiline':False]['text':' test with `t5-small`','line_number':353,'multiline':False]['text':' there was a bug with decoders - this test checks that it is fixed','line_number':356,'multiline':False]['text':' test with `flan-t5-small`','line_number':362,'multiline':False]['text':' model_name','line_number':373,'multiline':False]['text':' Different types of model','line_number':377,'multiline':False]['text':' Sequence classification model','line_number':380,'multiline':False]['text':' CausalLM model','line_number':384,'multiline':False]['text':' Seq2seq model','line_number':386,'multiline':False]['text':' Other heads should be nn.Parameter','line_number':413,'multiline':False]['text':' self._clear_cuda_cache()','line_number':439,'multiline':False]['text':' Real second forward pass','line_number':447,'multiline':False]['text':' Check correct device map','line_number':467,'multiline':False]['text':' Check that inference pass works on the model','line_number':470,'multiline':False]['text':' Second real batch','line_number':473,'multiline':False]['text':' Step 1: freeze all parameters','line_number':487,'multiline':False]['text':' freeze the model - train adapters later','line_number':493,'multiline':False]['text':' cast the small parameters (e.g. layernorm) to fp32 for stability','line_number':495,'multiline':False]['text':' Step 2: add adapters','line_number':498,'multiline':False]['text':' Step 3: dummy batch','line_number':505,'multiline':False]['text':' Step 4: Check if the gradient is not None','line_number':508,'multiline':False]