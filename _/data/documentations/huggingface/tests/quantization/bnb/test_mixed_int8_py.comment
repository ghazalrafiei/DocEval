['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2022 The HuggingFace Team Inc.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a clone of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' We keep the constants inside the init function and model loading inside setUp function','line_number':86,'multiline':False]['text':' We need to test on relatively large models (aka >1b parameters otherwise the quantiztion may not work as expected)','line_number':88,'multiline':False]['text':' Therefore here we use only bloom-1b3 to test our module','line_number':89,'multiline':False]['text':' Constant values','line_number':92,'multiline':False]['text':' This was obtained on a Quadro RTX 8000 so the number might slightly change','line_number':94,'multiline':False]['text':' Models and tokenizer','line_number':102,'multiline':False]['text':' Models and tokenizer','line_number':110,'multiline':False]['text':' The order of the keys does not matter, so we sort them before comparing, same for the other tests.','line_number':158,'multiline':False]['text':' Tries with `str`','line_number':304,'multiline':False]['text':' Tries with a `dtype``','line_number':308,'multiline':False]['text':' Tries with a `device`','line_number':312,'multiline':False]['text':' Tries with a `device`','line_number':316,'multiline':False]['text':' Tries with a `device`','line_number':320,'multiline':False]['text':' Test if we did not break anything','line_number':323,'multiline':False]['text':' Check this does not throw an error','line_number':329,'multiline':False]['text':' Check this does not throw an error','line_number':332,'multiline':False]['text':' Check this does not throw an error','line_number':335,'multiline':False]['text':' check that the file `quantization_config` is present','line_number':354,'multiline':False]['text':' generate','line_number':364,'multiline':False]['text':' check that the file `quantization_config` is present','line_number':381,'multiline':False]['text':' generate','line_number':391,'multiline':False]['text':' check that the file `quantization_config` is present','line_number':408,'multiline':False]['text':' generate','line_number':418,'multiline':False]['text':' generate','line_number':440,'multiline':False]['text':' flan-t5 uses dense-act instead of dense-relu-dense','line_number':456,'multiline':False]['text':' test with `t5-small`','line_number':479,'multiline':False]['text':' test with `flan-t5-small`','line_number':484,'multiline':False]['text':' test with `t5-small`','line_number':502,'multiline':False]['text':' there was a bug with decoders - this test checks that it is fixed','line_number':505,'multiline':False]['text':' test with `flan-t5-small`','line_number':511,'multiline':False]['text':' test with `t5-small`','line_number':529,'multiline':False]['text':' there was a bug with decoders - this test checks that it is fixed','line_number':537,'multiline':False]['text':' test with `flan-t5-small`','line_number':543,'multiline':False]['text':' model_name','line_number':554,'multiline':False]['text':' Different types of model','line_number':558,'multiline':False]['text':' Sequence classification model','line_number':561,'multiline':False]['text':' CausalLM model','line_number':565,'multiline':False]['text':' Seq2seq model','line_number':567,'multiline':False]['text':' last param of a base model should be a linear8bit module','line_number':592,'multiline':False]['text':' Other heads should be nn.Parameter','line_number':595,'multiline':False]['text':' self._clear_cuda_cache()','line_number':621,'multiline':False]['text':' Real second forward pass','line_number':629,'multiline':False]['text':' Check correct device map','line_number':649,'multiline':False]['text':' Check that inference pass works on the model','line_number':652,'multiline':False]['text':' Second real batch','line_number':655,'multiline':False]['text':' Check that inference pass works on the model','line_number':666,'multiline':False]['text':' Check the exactness of the results','line_number':669,'multiline':False]['text':' Get the generation','line_number':672,'multiline':False]['text':' Check that the model has been correctly set on device 0, 1, and `cpu`.','line_number':719,'multiline':False]['text':' Load model','line_number':739,'multiline':False]['text':' Check that the model has been correctly set on device 0, 1, and `cpu`.','line_number':746,'multiline':False]['text':' Load model','line_number':765,'multiline':False]['text':' Check that the model has been correctly set on device 0, 1, and `cpu`.','line_number':773,'multiline':False]['text':' Load model','line_number':791,'multiline':False]['text':' Check that the model has been correctly set on device 0, 1, and `cpu`.','line_number':800,'multiline':False]['text':' Step 1: freeze all parameters','line_number':815,'multiline':False]['text':' freeze the model - train adapters later','line_number':821,'multiline':False]['text':' cast the small parameters (e.g. layernorm) to fp32 for stability','line_number':823,'multiline':False]['text':' Step 2: add adapters','line_number':826,'multiline':False]['text':' Step 3: dummy batch','line_number':833,'multiline':False]['text':' Step 4: Check if the gradient is not None','line_number':836,'multiline':False]['text':' generate','line_number':868,'multiline':False]