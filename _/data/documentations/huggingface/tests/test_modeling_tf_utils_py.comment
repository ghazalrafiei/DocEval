['text':' coding=utf-8','line_number':1,'multiline':False]['text':' Copyright 2019 HuggingFace Inc.','line_number':2,'multiline':False]['text':'','line_number':3,'multiline':False]['text':' Licensed under the Apache License, Version 2.0 (the "License");','line_number':4,'multiline':False]['text':' you may not use this file except in compliance with the License.','line_number':5,'multiline':False]['text':' You may obtain a copy of the License at','line_number':6,'multiline':False]['text':'','line_number':7,'multiline':False]['text':'     http://www.apache.org/licenses/LICENSE-2.0','line_number':8,'multiline':False]['text':'','line_number':9,'multiline':False]['text':' Unless required by applicable law or agreed to in writing, software','line_number':10,'multiline':False]['text':' distributed under the License is distributed on an "AS IS" BASIS,','line_number':11,'multiline':False]['text':' WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.','line_number':12,'multiline':False]['text':' See the License for the specific language governing permissions and','line_number':13,'multiline':False]['text':' limitations under the License.','line_number':14,'multiline':False]['text':' noqa: F401','line_number':33,'multiline':False]['text':' Restrict TensorFlow to only allocate x GB of memory on the GPUs','line_number':75,'multiline':False]['text':' Virtual devices must be set before GPUs have been initialized','line_number':83,'multiline':False]['text':' A mock response for an HTTP head request to emulate server down','line_number':93,'multiline':False]['text':' Download this model to make sure it's in the cache.','line_number':100,'multiline':False]['text':' Under the mock environment we get a 500 error when trying to reach the model.','line_number':103,'multiline':False]['text':' This check we did call the fake head request','line_number':106,'multiline':False]['text':' This test is for deprecated behavior and can be removed in v5','line_number':121,'multiline':False]['text':' tests whether the unpack_inputs function behaves as expected','line_number':127,'multiline':False]['text':' test case 1: Pass inputs as keyword arguments; Booleans are inherited from the config.','line_number':155,'multiline':False]['text':' test case 2: Same as above, but with positional arguments.','line_number':163,'multiline':False]['text':' test case 3: We can also pack everything in the first input.','line_number':171,'multiline':False]['text':' test case 4: Explicit boolean arguments should override the config.','line_number':179,'multiline':False]['text':' test case 5: Unexpected arguments should raise an exception.','line_number':189,'multiline':False]['text':' test case 6: the decorator is independent from `main_input_name` -- it treats the first argument of the','line_number':193,'multiline':False]['text':' decorated function as its main input.','line_number':194,'multiline':False]['text':' Tests whether the stable softmax is stable on CPU, with and without XLA','line_number':201,'multiline':False]['text':' Same outcome regardless of the boolean mask here','line_number':216,'multiline':False]['text':' We can randomly mask a random numerical input OUTSIDE XLA','line_number':220,'multiline':False]['text':' The stable softmax has the same output as the original softmax','line_number':227,'multiline':False]['text':' We can randomly mask a random numerical input INSIDE XLA','line_number':231,'multiline':False]['text':' the model above is the same as the model below, just a sharded version.','line_number':238,'multiline':False]['text':' If this doesn't throw an error then the test passes','line_number':252,'multiline':False]['text':' the model above is the same as the model below, just a sharded pytorch version.','line_number':260,'multiline':False]['text':' the model above is the same as the model below, just a sharded pytorch version.','line_number':278,'multiline':False]['text':' This is the model we will use, total size 340,000 bytes.','line_number':284,'multiline':False]['text':' size 80,000','line_number':287,'multiline':False]['text':' size 160,000','line_number':288,'multiline':False]['text':' size 80,000','line_number':289,'multiline':False]['text':' size 20,000','line_number':290,'multiline':False]['text':' Split is first two layers then last two.','line_number':304,'multiline':False]['text':' Split is first layer, second layer then last 2.','line_number':324,'multiline':False]['text':' We use the same folder for various sizes to make sure a new save erases the old checkpoint.','line_number':366,'multiline':False]['text':' Get each shard file and its size','line_number':370,'multiline':False]['text':' Check there is an index but no regular weight file','line_number':378,'multiline':False]['text':' Check a file is bigger than max_size only when it has a single weight','line_number':382,'multiline':False]['text':' Note: pickle adds some junk so the weight of the file can end up being slightly bigger than','line_number':388,'multiline':False]['text':' the size asked for (since we count parameters)','line_number':389,'multiline':False]['text':' Check the index and the shard files found match','line_number':394,'multiline':False]['text':' Finally, check the model can be reloaded','line_number':402,'multiline':False]['text':' Short custom TF signature function.','line_number':415,'multiline':False]['text':' `input_signature` is specific to BERT.','line_number':416,'multiline':False]['text':' Using default signature (default behavior) overrides 'serving_default'','line_number':429,'multiline':False]['text':' Providing custom signature function','line_number':435,'multiline':False]['text':' Providing multiple custom signature function','line_number':441,'multiline':False]['text':' No tf_model.h5 file, only a model.safetensors','line_number':457,'multiline':False]['text':' Check models are equal','line_number':463,'multiline':False]['text':' Check we have a model.safetensors file','line_number':473,'multiline':False]['text':' Check models are equal','line_number':478,'multiline':False]['text':' Can load from the TF-formatted checkpoint','line_number':486,'multiline':False]['text':' Check models are equal','line_number':489,'multiline':False]['text':' Can load from the PyTorch-formatted checkpoint','line_number':493,'multiline':False]['text':' Check models are equal','line_number':496,'multiline':False]['text':' This should not raise even if there are two types of sharded weights','line_number':529,'multiline':False]['text':' This should not raise even if there are two types of sharded weights','line_number':534,'multiline':False]['text':' This should discard the safetensors weights in favor of the .h5 sharded weights','line_number':535,'multiline':False]['text':' Can load from the PyTorch-formatted checkpoint','line_number':562,'multiline':False]['text':' Can load from the PyTorch-formatted checkpoint','line_number':577,'multiline':False]['text':' Make sure model is properly initialized','line_number':634,'multiline':False]['text':' Check the model card was created and uploaded.','line_number':642,'multiline':False]['text':' Reset repo','line_number':653,'multiline':False]['text':' Push to hub via save_pretrained','line_number':656,'multiline':False]['text':' Make sure model is properly initialized','line_number':703,'multiline':False]['text':' Reset repo','line_number':716,'multiline':False]['text':' Push to hub via save_pretrained','line_number':719,'multiline':False]